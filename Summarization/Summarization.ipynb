{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9587bbdb-666e-4076-8682-1814ac68eabc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e992932-eef5-4f38-8af7-c5070a2f1692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import openai\n",
    "import re\n",
    "from openai import OpenAI\n",
    "import spacy\n",
    "import requests\n",
    "from tqdm import tqdm  # ‚úÖ Add this for progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497b553e-5ca3-439f-8cf6-b4de41136e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f519c7f-1069-4e40-8f26-11994dbda9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"my_key1\"\n",
    "ANTHROPIC_API_KEY = \"my_key2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a6a793c-2d60-43db-a604-5f8360251c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# üîß Configuration\n",
    "# ----------------------------------------\n",
    "API_KEY = OPENAI_API_KEY  # Replace with your actual key\n",
    "MODEL = \"gpt-4.1-mini\"\n",
    "INPUT_CSV = \"../Extraction/stage 3/methods_with_verified_methods_list.csv\"\n",
    "OUTPUT_CSV = \"stage 1/Masked Research Idea & Objective Extraction.csv\"\n",
    "SLEEP_BETWEEN_REQUESTS = 1\n",
    "\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "# ----------------------------------------\n",
    "# üß† Prompt Generator\n",
    "# ----------------------------------------\n",
    "def make_masked_summary_prompt(abstract, extracted_methods, domain):\n",
    "    clean_methods = re.findall(r\"<method>(.*?)</method>\", extracted_methods)\n",
    "    methods_str = \", \".join(clean_methods) if clean_methods else \"none\"\n",
    "\n",
    "    return f\"\"\"\n",
    "As a research assistant, your task is to extract the research idea and research objective from an abstract which is from the {domain} domain. The extracted content must contain the:\n",
    "\n",
    "1. Research Idea: Write 2-4 sentences that capture the overarching motivation or problem the study addresses, using the text from the abstract.\n",
    "2. Research Objective: Write 2-4 sentences that directly state the study‚Äôs primary aim or objective, using the text from the abstract.\n",
    "3. Your response should not mention any Computer Science (CS), Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL) related terms, words or phrases including vague or generic statements such as \"algorithm,\" \"model,\" \"computational,\" \"data-driven,\" \"predictive,\" \"system,\" or \"analysis.\"\n",
    "4. Your response should not mention any methods, techniques, or tools related to CS/AI/ML/DL, even if they are mentioned in the abstract.\n",
    "5. Focus exclusively on the {domain}-specific context, problem, or purpose of the research for both the research idea and research objective.\n",
    "6. If the abstract does not explicitly state the idea or objective, extract the closest equivalent statement describing the study‚Äôs motivation (for idea) or primary aim (for objective), staying as close to the original wording as possible.\n",
    "\n",
    "Here is the abstract: {abstract}\n",
    "\n",
    "Provide the extracted content below in the following format as a whole paragraph.\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------------------------\n",
    "# üöÄ OpenAI API Wrapper\n",
    "# ----------------------------------------\n",
    "def generate_summary(prompt, model=MODEL, temperature=0.1):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=temperature,\n",
    "        max_tokens=800\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# ----------------------------------------\n",
    "# üîÅ Main Processing Loop with Progress Bar\n",
    "# ----------------------------------------\n",
    "def summarize_dataset(input_path, output_path):\n",
    "    df = pd.read_csv(input_path)\n",
    "    results = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"üîÑ Processing\"):  # ‚úÖ Added tqdm\n",
    "        abstract = str(row[\"abstract\"])\n",
    "        methods = str(row[\"verified_methods_list\"])\n",
    "        domain = str(row[\"domain\"])\n",
    "\n",
    "        try:\n",
    "            prompt = make_masked_summary_prompt(abstract, methods, domain)\n",
    "            masked_extraction = generate_summary(prompt)\n",
    "\n",
    "            results.append({\n",
    "                \"domain\": domain,\n",
    "                \"title\": row[\"title\"],\n",
    "                \"abstract\": abstract,\n",
    "                \"verified methods list\": methods,\n",
    "                \"masked extraction\": masked_extraction\n",
    "            })\n",
    "\n",
    "            time.sleep(SLEEP_BETWEEN_REQUESTS)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error on row {idx}: {e}\")\n",
    "            continue\n",
    "\n",
    "    df_out = pd.DataFrame(results)\n",
    "    df_out.to_csv(output_path, index=False)\n",
    "    print(f\"\\n‚úÖ All done! Saved summaries to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "888b56d2-9332-4aa3-86fb-65225b1b0431",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÑ Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 792/792 [41:11<00:00,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ All done! Saved summaries to: stage 1/Masked Research Idea & Objective Extraction.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------\n",
    "# üé¨ Run\n",
    "# ----------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    summarize_dataset(INPUT_CSV, OUTPUT_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc4bf09-6a2e-4c55-8315-4222241c7bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a7a3ce-7a3b-4051-8f72-3d4c82125585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fe1639-ad7c-40d5-abe5-caa04b462356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c16c8e-2a9f-419b-90c3-d9a09c5a8c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092ae989-778f-4a1f-a91d-5dabc12c2705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308a7ff6-3ee7-48ee-8f00-a1a241b1dc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# üîß Configuration\n",
    "# -------------------------------\n",
    "API_KEY = \"my_key2\"\n",
    "API_URL = \"https://api.anthropic.com/v1/messages\"\n",
    "HEADERS = {\n",
    "    \"x-api-key\": API_KEY,\n",
    "    \"anthropic-version\": \"2023-06-01\",\n",
    "    \"content-type\": \"application/json\"\n",
    "}\n",
    "\n",
    "MODEL = \"claude-3-7-sonnet-20250219\"\n",
    "INPUT_CSV = \"stage 1/Masked Research Idea & Objective Extraction.csv\"\n",
    "OUTPUT_CSV_ALL = \"stage 2/rewritten Masked Extraction.csv\"\n",
    "OUTPUT_CSV_CLEAN = \"stage 2/leakage free summaries only.csv\"\n",
    "OUTPUT_CSV_LEAKED = \"stage 2/leaked summaries only.csv\"\n",
    "SLEEP_BETWEEN_REQUESTS = 1\n",
    "\n",
    "# -------------------------------\n",
    "# üß† AI/ML/DL Vocabulary List\n",
    "# -------------------------------\n",
    "term_list = [\n",
    "    \"Support Vector Machine\", \"Decision Tree\", \"Random Forest\", \"Naive Bayes\",\n",
    "    \"K-Nearest Neighbors\", \"Logistic Regression\", \"Linear Regression\", \"Gradient Boosting\",\n",
    "    \"XGBoost\", \"LightGBM\", \"CatBoost\", \"AdaBoost\", \"K-Means\", \"DBSCAN\",\n",
    "    \"Hierarchical Clustering\", \"PCA\", \"LDA\", \"Q-Learning\", \"DQN\",\n",
    "    \"GAN\", \"VAE\", \"CNN\", \"RNN\", \"LSTM\", \"GRU\", \"Transformer\", \"BERT\",\n",
    "    \"GPT\", \"T5\", \"LLaMA\", \"Mistral\", \"Claude\", \"Autoencoder\", \"MLP\",\n",
    "    \"ResNet\", \"Inception\", \"VGG\", \"EfficientNet\", \"YOLO\", \"SSD\", \"Faster R-CNN\",\n",
    "    \"Deep Reinforcement Learning\", \"Meta-learning\", \"Few-shot Learning\", \"Zero-shot Learning\",\n",
    "    \"Federated Learning\", \"Self-supervised Learning\", \"Semi-supervised Learning\",\n",
    "    \"Supervised Learning\", \"Unsupervised Learning\", \"Transfer Learning\", \"Representation Learning\",\n",
    "    \"learning algorithm\", \"computational model\", \"prediction model\", \"automated method\",\n",
    "    \"data-driven technique\", \"neural approach\", \"intelligent system\", \"adaptive model\",\n",
    "    \"classification technique\", \"regression approach\", \"optimization-based method\",\n",
    "    \"probabilistic framework\", \"generative model\", \"discriminative model\", \"hybrid system\",\n",
    "    \"data analytics\", \"pattern recognition technique\", \"predictive pipeline\",\n",
    "    \"algorithmic solution\", \"high-capacity model\", \"state-of-the-art method\",\n",
    "    \"novel approach\", \"ensemble method\", \"custom architecture\", \"algorithmic strategy\",\n",
    "    \"smart system\", \"scalable framework\", \"dynamic learning scheme\", \"decision-making model\",\n",
    "    \"analytical model\", \"computational strategy\",\n",
    "    \"advanced computing\", \"intelligent analysis\", \"automated detection\",\n",
    "    \"computational intelligence\", \"smart detection\", \"enhanced recognition\",\n",
    "    \"autonomous system\", \"technology-driven approach\", \"model-based analysis\",\n",
    "    \"hybrid learning\", \"deep representation\", \"intelligent estimation\",\n",
    "    \"self-learning mechanism\", \"automatic classification\", \"high-performance model\",\n",
    "    \"synthetic model generation\", \"context-aware learning\", \"domain adaptation\",\n",
    "    \"feature extraction technique\", \"latent variable model\",\n",
    "    \"probabilistic inference\", \"statistical modeling\", \"parameter tuning\",\n",
    "    \"optimization routine\", \"hyperparameter selection\", \"loss minimization\",\n",
    "    \"backpropagation\", \"likelihood estimation\", \"training and testing phase\",\n",
    "    \"evaluation metrics\", \"convergence behavior\", \"stochastic process\",\n",
    "    \"sampling techniques\", \"cross-validation\", \"gradient descent\",\n",
    "    \"regularization method\", \"overfitting prevention\", \"feature engineering\",\n",
    "    \"dimensionality reduction\", \"noise reduction technique\"\n",
    "]\n",
    "\n",
    "# -------------------------------\n",
    "# üß† Rewrite Prompt Template\n",
    "# -------------------------------\n",
    "def make_rewrite_prompt(summary, term_list):\n",
    "    terms = \", \".join(term_list)\n",
    "    return f\"\"\"\n",
    "You are reviewing an extracted summary describing the research idea and objective of a paper. The summary should be free of references related to Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL), or any related computational terms/phrases.\n",
    "\n",
    "These references can be direct, vague, euphemisms, or synonyms terms/phrases such as: {terms}\n",
    "\n",
    "Your task:\n",
    "1. Go sentence by sentence.\n",
    "2. If a sentence contains any such reference, rewrite it to remove or neutralize the term while keeping the original research idea or objective intact.\n",
    "3. If a sentence is already clean of any Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL) language, keep it unchanged.\n",
    "4. At the end, return a clean paragraph that captures the same research idea and objective without any AI/ML/DL-related language.\n",
    "\n",
    "Only return the final cleaned paragraph. Do not explain your changes.\n",
    "\n",
    "Here is the summary:\n",
    "{summary}\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------------\n",
    "# üîÅ Main Processing Loop\n",
    "# -------------------------------\n",
    "def detect_and_rewrite(input_csv, output_csv_all, output_csv_clean, output_csv_leaked):\n",
    "    df = pd.read_csv(input_csv)\n",
    "    results = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"üîÅ Rewriting Summaries\"):  # ‚úÖ Add progress bar\n",
    "        abstract = str(row[\"abstract\"])\n",
    "        methods = str(row[\"verified methods list\"])\n",
    "        masked_extraction = str(row[\"masked extraction\"])\n",
    "\n",
    "        try:\n",
    "            prompt = make_rewrite_prompt(masked_extraction, term_list)\n",
    "            payload = {\n",
    "                \"model\": MODEL,\n",
    "                \"max_tokens\": 1024,\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "            }\n",
    "\n",
    "            response = requests.post(API_URL, headers=HEADERS, json=payload)\n",
    "            response.raise_for_status()\n",
    "            cleaned_summary = response.json()[\"content\"][0][\"text\"].strip()\n",
    "\n",
    "            leakage_detected = masked_extraction.strip() != cleaned_summary\n",
    "\n",
    "            results.append({\n",
    "                \"domain\": row.get(\"domain\", \"\"),\n",
    "                \"title\": row.get(\"title\", \"\"),\n",
    "                \"abstract\": abstract,\n",
    "                \"verified methods list\": methods,\n",
    "                \"inital masked extraction\": masked_extraction,\n",
    "                \"final masked extraction\": cleaned_summary,\n",
    "                \"leakage detected\": leakage_detected\n",
    "            })\n",
    "\n",
    "            time.sleep(SLEEP_BETWEEN_REQUESTS)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error on row {idx}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Save all results\n",
    "    df_out = pd.DataFrame(results)\n",
    "    df_out.to_csv(output_csv_all, index=False)\n",
    "    print(f\"\\n‚úÖ All results saved to: {output_csv_all}\")\n",
    "\n",
    "    # Save clean summaries\n",
    "    clean_df = df_out[df_out[\"leakage detected\"] == False]\n",
    "    clean_df.to_csv(output_csv_clean, index=False)\n",
    "    print(f\"‚úÖ Clean summaries saved to: {output_csv_clean} ({len(clean_df)} rows)\")\n",
    "\n",
    "    # Save rewritten summaries\n",
    "    leaked_df = df_out[df_out[\"leakage detected\"] == True]\n",
    "    leaked_df.to_csv(output_csv_leaked, index=False)\n",
    "    print(f\"üö® Rewritten (previously leaked) summaries saved to: {output_csv_leaked} ({len(leaked_df)} rows)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc4e4983-41ad-4700-9771-69e96f51bb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Rewriting Summaries:   6%|‚ñà‚ñà‚ñà‚ñç                                                   | 49/792 [04:38<1:00:34,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error on row 48: 529 Server Error:  for url: https://api.anthropic.com/v1/messages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Rewriting Summaries:  29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                      | 229/792 [22:44<1:25:09,  9.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error on row 228: 529 Server Error:  for url: https://api.anthropic.com/v1/messages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÅ Rewriting Summaries: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 792/792 [1:12:06<00:00,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ All results saved to: stage 2/Rewritten Masked Extraction.csv\n",
      "‚úÖ Clean summaries saved to: stage 2/leakage free summaries only.csv (377 rows)\n",
      "üö® Rewritten (previously leaked) summaries saved to: stage 2/leaked summaries only.csv (413 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# üé¨ Run\n",
    "# -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    detect_and_rewrite(INPUT_CSV, OUTPUT_CSV_ALL, OUTPUT_CSV_CLEAN, OUTPUT_CSV_LEAKED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d38cf9-8f82-4ca1-9cc1-e965bc218449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c31c900-561e-44d4-9616-3f0dc55e0d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05480e4-7fb4-40c4-a03f-c2eec6c492f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1615af03-1924-4d52-b319-7dd8ced3761a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7a2708-57f6-4f55-a633-524c6ccdab02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22a3b59-f642-4220-886d-d885fd246e50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# üîß Configuration\n",
    "# -------------------------------\n",
    "API_KEY = \"my_key2\"\n",
    "API_URL = \"https://api.anthropic.com/v1/messages\"\n",
    "HEADERS = {\n",
    "    \"x-api-key\": API_KEY,\n",
    "    \"anthropic-version\": \"2023-06-01\",\n",
    "    \"content-type\": \"application/json\"\n",
    "}\n",
    "\n",
    "MODEL = \"claude-3-7-sonnet-20250219\"\n",
    "INPUT_CSV = \"stage 1/Masked Research Idea & Objective Extraction.csv\"\n",
    "OUTPUT_CSV_ALL = \"stage 2/Rewritten Masked Extraction.csv\"\n",
    "OUTPUT_CSV_CLEAN = \"stage 2/leakage free summaries only.csv\"\n",
    "OUTPUT_CSV_LEAKED = \"stage 2/leaked summaries only.csv\"\n",
    "SLEEP_BETWEEN_REQUESTS = 1\n",
    "\n",
    "# -------------------------------\n",
    "# üß† AI/ML/DL Vocabulary List\n",
    "# -------------------------------\n",
    "term_list = [\n",
    "    \"Support Vector Machine\", \"Decision Tree\", \"Random Forest\", \"Naive Bayes\",\n",
    "    \"K-Nearest Neighbors\", \"Logistic Regression\", \"Linear Regression\", \"Gradient Boosting\",\n",
    "    \"XGBoost\", \"LightGBM\", \"CatBoost\", \"AdaBoost\", \"K-Means\", \"DBSCAN\",\n",
    "    \"Hierarchical Clustering\", \"PCA\", \"LDA\", \"Q-Learning\", \"DQN\",\n",
    "    \"GAN\", \"VAE\", \"CNN\", \"RNN\", \"LSTM\", \"GRU\", \"Transformer\", \"BERT\",\n",
    "    \"GPT\", \"T5\", \"LLaMA\", \"Mistral\", \"Claude\", \"Autoencoder\", \"MLP\",\n",
    "    \"ResNet\", \"Inception\", \"VGG\", \"EfficientNet\", \"YOLO\", \"SSD\", \"Faster R-CNN\",\n",
    "    \"Deep Reinforcement Learning\", \"Meta-learning\", \"Few-shot Learning\", \"Zero-shot Learning\",\n",
    "    \"Federated Learning\", \"Self-supervised Learning\", \"Semi-supervised Learning\",\n",
    "    \"Supervised Learning\", \"Unsupervised Learning\", \"Transfer Learning\", \"Representation Learning\",\n",
    "    \"learning algorithm\", \"computational model\", \"prediction model\", \"automated method\",\n",
    "    \"data-driven technique\", \"neural approach\", \"intelligent system\", \"adaptive model\",\n",
    "    \"classification technique\", \"regression approach\", \"optimization-based method\",\n",
    "    \"probabilistic framework\", \"generative model\", \"discriminative model\", \"hybrid system\",\n",
    "    \"data analytics\", \"pattern recognition technique\", \"predictive pipeline\",\n",
    "    \"algorithmic solution\", \"high-capacity model\", \"state-of-the-art method\",\n",
    "    \"novel approach\", \"ensemble method\", \"custom architecture\", \"algorithmic strategy\",\n",
    "    \"smart system\", \"scalable framework\", \"dynamic learning scheme\", \"decision-making model\",\n",
    "    \"analytical model\", \"computational strategy\",\n",
    "    \"advanced computing\", \"intelligent analysis\", \"automated detection\",\n",
    "    \"computational intelligence\", \"smart detection\", \"enhanced recognition\",\n",
    "    \"autonomous system\", \"technology-driven approach\", \"model-based analysis\",\n",
    "    \"hybrid learning\", \"deep representation\", \"intelligent estimation\",\n",
    "    \"self-learning mechanism\", \"automatic classification\", \"high-performance model\",\n",
    "    \"synthetic model generation\", \"context-aware learning\", \"domain adaptation\",\n",
    "    \"feature extraction technique\", \"latent variable model\",\n",
    "    \"probabilistic inference\", \"statistical modeling\", \"parameter tuning\",\n",
    "    \"optimization routine\", \"hyperparameter selection\", \"loss minimization\",\n",
    "    \"backpropagation\", \"likelihood estimation\", \"training and testing phase\",\n",
    "    \"evaluation metrics\", \"convergence behavior\", \"stochastic process\",\n",
    "    \"sampling techniques\", \"cross-validation\", \"gradient descent\",\n",
    "    \"regularization method\", \"overfitting prevention\", \"feature engineering\",\n",
    "    \"dimensionality reduction\", \"noise reduction technique\"\n",
    "]\n",
    "\n",
    "# -------------------------------\n",
    "# üß† Rewrite Prompt Template\n",
    "# -------------------------------\n",
    "def make_rewrite_prompt(summary, term_list):\n",
    "    terms = \", \".join(term_list)\n",
    "    return f\"\"\"\n",
    "You are reviewing an extracted summary describing the research idea and objective of a paper. The summary should be free of references related to Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL), or any related computational terms/phrases.\n",
    "\n",
    "These references can be direct, vague, euphemisms, or synonyms terms/phrases such as: {terms}\n",
    "\n",
    "Your task:\n",
    "1. Go sentence by sentence.\n",
    "2. If a sentence contains any such reference, rewrite it to remove or neutralize the term while keeping the original research idea or objective intact.\n",
    "3. If a sentence is already clean of any Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL) language, keep it unchanged.\n",
    "4. At the end, return a clean paragraph that captures the same research idea and objective without any AI/ML/DL-related language.\n",
    "\n",
    "Only return the final cleaned paragraph. Do not explain your changes.\n",
    "\n",
    "Here is the summary:\n",
    "{summary}\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------------\n",
    "# üîÅ Main Processing Loop\n",
    "# -------------------------------\n",
    "def detect_and_rewrite(input_csv, output_csv_all, output_csv_clean, output_csv_leaked):\n",
    "    df = pd.read_csv(input_csv)\n",
    "    results = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        abstract = str(row[\"abstract\"])\n",
    "        methods = str(row[\"verified methods list\"])\n",
    "        masked_extraction = str(row[\"masked extraction\"])\n",
    "\n",
    "        try:\n",
    "            print(f\"üîç [{idx}] Rewriting if needed...\")\n",
    "\n",
    "            prompt = make_rewrite_prompt(masked_extraction, term_list)\n",
    "            # Claude API call\n",
    "            payload = {\n",
    "                \"model\": MODEL,\n",
    "                \"max_tokens\": 1024,\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "            }\n",
    "\n",
    "            response = requests.post(API_URL, headers=HEADERS, json=payload)\n",
    "            response.raise_for_status()\n",
    "            cleaned_summary = response.json()[\"content\"][0][\"text\"].strip()\n",
    "\n",
    "            # Detect if any rewrite occurred\n",
    "            leakage_detected = masked_extraction.strip() != cleaned_summary\n",
    "\n",
    "            results.append({\n",
    "                \"domain\": row.get(\"domain\", \"\"),\n",
    "                \"title\": row.get(\"title\", \"\"),\n",
    "                \"abstract\": abstract,\n",
    "                \"verified methods list\": methods,\n",
    "                \"inital masked extraction\": masked_extraction,\n",
    "                \"final masked extraction\": cleaned_summary,\n",
    "                \"leakage detected\": leakage_detected\n",
    "            })\n",
    "\n",
    "            time.sleep(SLEEP_BETWEEN_REQUESTS)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error on row {idx}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Save all results\n",
    "    df_out = pd.DataFrame(results)\n",
    "    df_out.to_csv(output_csv_all, index=False)\n",
    "    print(f\"\\n‚úÖ All results saved to: {output_csv_all}\")\n",
    "\n",
    "    # Save clean summaries\n",
    "    clean_df = df_out[df_out[\"leakage detected\"] == False]\n",
    "    clean_df.to_csv(output_csv_clean, index=False)\n",
    "    print(f\"‚úÖ Clean summaries saved to: {output_csv_clean} ({len(clean_df)} rows)\")\n",
    "\n",
    "    # Save rewritten summaries\n",
    "    leaked_df = df_out[df_out[\"leakage detected\"] == True]\n",
    "    leaked_df.to_csv(output_csv_leaked, index=False)\n",
    "    print(f\"üö® Rewritten (previously leaked) summaries saved to: {output_csv_leaked} ({len(leaked_df)} rows)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80d95c6e-d755-434f-9336-c97752e3f548",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç [0] Rewriting if needed...\n",
      "\n",
      "---------------------\n",
      "\n",
      "You are reviewing an extracted summary describing the research idea and objective of a paper. The summary should be free of references related to Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL), or any related computational terms/phrases.\n",
      "\n",
      "These references can be direct, vague, euphemisms, or synonyms terms/phrases such as: Support Vector Machine, Decision Tree, Random Forest, Naive Bayes, K-Nearest Neighbors, Logistic Regression, Linear Regression, Gradient Boosting, XGBoost, LightGBM, CatBoost, AdaBoost, K-Means, DBSCAN, Hierarchical Clustering, PCA, LDA, Q-Learning, DQN, GAN, VAE, CNN, RNN, LSTM, GRU, Transformer, BERT, GPT, T5, LLaMA, Mistral, Claude, Autoencoder, MLP, ResNet, Inception, VGG, EfficientNet, YOLO, SSD, Faster R-CNN, Deep Reinforcement Learning, Meta-learning, Few-shot Learning, Zero-shot Learning, Federated Learning, Self-supervised Learning, Semi-supervised Learning, Supervised Learning, Unsupervised Learning, Transfer Learning, Representation Learning, learning algorithm, computational model, prediction model, automated method, data-driven technique, neural approach, intelligent system, adaptive model, classification technique, regression approach, optimization-based method, probabilistic framework, generative model, discriminative model, hybrid system, data analytics, pattern recognition technique, predictive pipeline, algorithmic solution, high-capacity model, state-of-the-art method, novel approach, ensemble method, custom architecture, algorithmic strategy, smart system, scalable framework, dynamic learning scheme, decision-making model, analytical model, computational strategy, advanced computing, intelligent analysis, automated detection, computational intelligence, smart detection, enhanced recognition, autonomous system, technology-driven approach, model-based analysis, hybrid learning, deep representation, intelligent estimation, self-learning mechanism, automatic classification, high-performance model, synthetic model generation, context-aware learning, domain adaptation, feature extraction technique, latent variable model, probabilistic inference, statistical modeling, parameter tuning, optimization routine, hyperparameter selection, loss minimization, backpropagation, likelihood estimation, training and testing phase, evaluation metrics, convergence behavior, stochastic process, sampling techniques, cross-validation, gradient descent, regularization method, overfitting prevention, feature engineering, dimensionality reduction, noise reduction technique\n",
      "\n",
      "Your task:\n",
      "1. Go sentence by sentence.\n",
      "2. If a sentence contains any such reference, rewrite it to remove or neutralize the term while keeping the original research idea or objective intact.\n",
      "3. If a sentence is already clean of any Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL) language, keep it unchanged.\n",
      "4. At the end, return a clean paragraph that captures the same research idea and objective without any AI/ML/DL-related language.\n",
      "\n",
      "Only return the final cleaned paragraph. Do not explain your changes.\n",
      "\n",
      "Here is the summary:\n",
      "The research idea centers on the challenge of continual learning, which involves the ability to incrementally acquire, update, accumulate, and exploit knowledge over time while addressing the problem of catastrophic forgetting, where learning new information can lead to a significant decline in previously acquired knowledge. This issue highlights the complexity and significance of maintaining a balance between retaining old knowledge and integrating new information effectively. The primary objective of the study is to provide a comprehensive overview of continual learning by summarizing its general goals, such as achieving an appropriate balance between stability and adaptability and ensuring effective generalization within and across tasks, all while considering resource efficiency. The study aims to offer a detailed classification and analysis of existing strategies to address continual learning challenges and to discuss promising future directions to advance understanding and application in this area.\n",
      "\n",
      "---------------------\n",
      "\n",
      "üîç [1] Rewriting if needed...\n",
      "\n",
      "---------------------\n",
      "\n",
      "You are reviewing an extracted summary describing the research idea and objective of a paper. The summary should be free of references related to Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL), or any related computational terms/phrases.\n",
      "\n",
      "These references can be direct, vague, euphemisms, or synonyms terms/phrases such as: Support Vector Machine, Decision Tree, Random Forest, Naive Bayes, K-Nearest Neighbors, Logistic Regression, Linear Regression, Gradient Boosting, XGBoost, LightGBM, CatBoost, AdaBoost, K-Means, DBSCAN, Hierarchical Clustering, PCA, LDA, Q-Learning, DQN, GAN, VAE, CNN, RNN, LSTM, GRU, Transformer, BERT, GPT, T5, LLaMA, Mistral, Claude, Autoencoder, MLP, ResNet, Inception, VGG, EfficientNet, YOLO, SSD, Faster R-CNN, Deep Reinforcement Learning, Meta-learning, Few-shot Learning, Zero-shot Learning, Federated Learning, Self-supervised Learning, Semi-supervised Learning, Supervised Learning, Unsupervised Learning, Transfer Learning, Representation Learning, learning algorithm, computational model, prediction model, automated method, data-driven technique, neural approach, intelligent system, adaptive model, classification technique, regression approach, optimization-based method, probabilistic framework, generative model, discriminative model, hybrid system, data analytics, pattern recognition technique, predictive pipeline, algorithmic solution, high-capacity model, state-of-the-art method, novel approach, ensemble method, custom architecture, algorithmic strategy, smart system, scalable framework, dynamic learning scheme, decision-making model, analytical model, computational strategy, advanced computing, intelligent analysis, automated detection, computational intelligence, smart detection, enhanced recognition, autonomous system, technology-driven approach, model-based analysis, hybrid learning, deep representation, intelligent estimation, self-learning mechanism, automatic classification, high-performance model, synthetic model generation, context-aware learning, domain adaptation, feature extraction technique, latent variable model, probabilistic inference, statistical modeling, parameter tuning, optimization routine, hyperparameter selection, loss minimization, backpropagation, likelihood estimation, training and testing phase, evaluation metrics, convergence behavior, stochastic process, sampling techniques, cross-validation, gradient descent, regularization method, overfitting prevention, feature engineering, dimensionality reduction, noise reduction technique\n",
      "\n",
      "Your task:\n",
      "1. Go sentence by sentence.\n",
      "2. If a sentence contains any such reference, rewrite it to remove or neutralize the term while keeping the original research idea or objective intact.\n",
      "3. If a sentence is already clean of any Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL) language, keep it unchanged.\n",
      "4. At the end, return a clean paragraph that captures the same research idea and objective without any AI/ML/DL-related language.\n",
      "\n",
      "Only return the final cleaned paragraph. Do not explain your changes.\n",
      "\n",
      "Here is the summary:\n",
      "The research idea centers on the need for personalized interventions in cardiovascular diseases (CVDs) due to their complex characteristics, progression, genetic makeup, and diversity. Understanding and identifying significant biomarkers are crucial for improving personalized treatment and early detection of CVDs. The study‚Äôs primary objective is to identify significant transcriptomic biomarkers that can differentiate between healthy individuals and CVD patients. This aims to provide potential indicators for early detection and to enhance the ability to identify patients with CVDs based on their biomarker profiles.\n",
      "\n",
      "---------------------\n",
      "\n",
      "üîç [2] Rewriting if needed...\n",
      "\n",
      "---------------------\n",
      "\n",
      "You are reviewing an extracted summary describing the research idea and objective of a paper. The summary should be free of references related to Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL), or any related computational terms/phrases.\n",
      "\n",
      "These references can be direct, vague, euphemisms, or synonyms terms/phrases such as: Support Vector Machine, Decision Tree, Random Forest, Naive Bayes, K-Nearest Neighbors, Logistic Regression, Linear Regression, Gradient Boosting, XGBoost, LightGBM, CatBoost, AdaBoost, K-Means, DBSCAN, Hierarchical Clustering, PCA, LDA, Q-Learning, DQN, GAN, VAE, CNN, RNN, LSTM, GRU, Transformer, BERT, GPT, T5, LLaMA, Mistral, Claude, Autoencoder, MLP, ResNet, Inception, VGG, EfficientNet, YOLO, SSD, Faster R-CNN, Deep Reinforcement Learning, Meta-learning, Few-shot Learning, Zero-shot Learning, Federated Learning, Self-supervised Learning, Semi-supervised Learning, Supervised Learning, Unsupervised Learning, Transfer Learning, Representation Learning, learning algorithm, computational model, prediction model, automated method, data-driven technique, neural approach, intelligent system, adaptive model, classification technique, regression approach, optimization-based method, probabilistic framework, generative model, discriminative model, hybrid system, data analytics, pattern recognition technique, predictive pipeline, algorithmic solution, high-capacity model, state-of-the-art method, novel approach, ensemble method, custom architecture, algorithmic strategy, smart system, scalable framework, dynamic learning scheme, decision-making model, analytical model, computational strategy, advanced computing, intelligent analysis, automated detection, computational intelligence, smart detection, enhanced recognition, autonomous system, technology-driven approach, model-based analysis, hybrid learning, deep representation, intelligent estimation, self-learning mechanism, automatic classification, high-performance model, synthetic model generation, context-aware learning, domain adaptation, feature extraction technique, latent variable model, probabilistic inference, statistical modeling, parameter tuning, optimization routine, hyperparameter selection, loss minimization, backpropagation, likelihood estimation, training and testing phase, evaluation metrics, convergence behavior, stochastic process, sampling techniques, cross-validation, gradient descent, regularization method, overfitting prevention, feature engineering, dimensionality reduction, noise reduction technique\n",
      "\n",
      "Your task:\n",
      "1. Go sentence by sentence.\n",
      "2. If a sentence contains any such reference, rewrite it to remove or neutralize the term while keeping the original research idea or objective intact.\n",
      "3. If a sentence is already clean of any Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL) language, keep it unchanged.\n",
      "4. At the end, return a clean paragraph that captures the same research idea and objective without any AI/ML/DL-related language.\n",
      "\n",
      "Only return the final cleaned paragraph. Do not explain your changes.\n",
      "\n",
      "Here is the summary:\n",
      "The research idea centers on addressing the challenge of accurately extracting meaningful clinical information, such as medical problems, treatments, and adverse events, from complex clinical data with minimal reliance on extensive annotated datasets. This study highlights the need to improve the performance of clinical named entity recognition tasks to facilitate better processing of clinical notes and safety reports. The primary objective of the study is to quantify the capabilities of specific language models for clinical named entity recognition tasks and to propose task-specific strategies that enhance their performance in extracting relevant clinical concepts from clinical notes and adverse event reports. The study aims to demonstrate that incorporating medical knowledge and carefully designed task-specific instructions can significantly improve the feasibility of these models for potential clinical applications.\n",
      "\n",
      "---------------------\n",
      "\n",
      "üîç [3] Rewriting if needed...\n",
      "\n",
      "---------------------\n",
      "\n",
      "You are reviewing an extracted summary describing the research idea and objective of a paper. The summary should be free of references related to Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL), or any related computational terms/phrases.\n",
      "\n",
      "These references can be direct, vague, euphemisms, or synonyms terms/phrases such as: Support Vector Machine, Decision Tree, Random Forest, Naive Bayes, K-Nearest Neighbors, Logistic Regression, Linear Regression, Gradient Boosting, XGBoost, LightGBM, CatBoost, AdaBoost, K-Means, DBSCAN, Hierarchical Clustering, PCA, LDA, Q-Learning, DQN, GAN, VAE, CNN, RNN, LSTM, GRU, Transformer, BERT, GPT, T5, LLaMA, Mistral, Claude, Autoencoder, MLP, ResNet, Inception, VGG, EfficientNet, YOLO, SSD, Faster R-CNN, Deep Reinforcement Learning, Meta-learning, Few-shot Learning, Zero-shot Learning, Federated Learning, Self-supervised Learning, Semi-supervised Learning, Supervised Learning, Unsupervised Learning, Transfer Learning, Representation Learning, learning algorithm, computational model, prediction model, automated method, data-driven technique, neural approach, intelligent system, adaptive model, classification technique, regression approach, optimization-based method, probabilistic framework, generative model, discriminative model, hybrid system, data analytics, pattern recognition technique, predictive pipeline, algorithmic solution, high-capacity model, state-of-the-art method, novel approach, ensemble method, custom architecture, algorithmic strategy, smart system, scalable framework, dynamic learning scheme, decision-making model, analytical model, computational strategy, advanced computing, intelligent analysis, automated detection, computational intelligence, smart detection, enhanced recognition, autonomous system, technology-driven approach, model-based analysis, hybrid learning, deep representation, intelligent estimation, self-learning mechanism, automatic classification, high-performance model, synthetic model generation, context-aware learning, domain adaptation, feature extraction technique, latent variable model, probabilistic inference, statistical modeling, parameter tuning, optimization routine, hyperparameter selection, loss minimization, backpropagation, likelihood estimation, training and testing phase, evaluation metrics, convergence behavior, stochastic process, sampling techniques, cross-validation, gradient descent, regularization method, overfitting prevention, feature engineering, dimensionality reduction, noise reduction technique\n",
      "\n",
      "Your task:\n",
      "1. Go sentence by sentence.\n",
      "2. If a sentence contains any such reference, rewrite it to remove or neutralize the term while keeping the original research idea or objective intact.\n",
      "3. If a sentence is already clean of any Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL) language, keep it unchanged.\n",
      "4. At the end, return a clean paragraph that captures the same research idea and objective without any AI/ML/DL-related language.\n",
      "\n",
      "Only return the final cleaned paragraph. Do not explain your changes.\n",
      "\n",
      "Here is the summary:\n",
      "The research addresses the challenge of accurately diagnosing and triaging medical conditions, highlighting the difficulty in achieving reliable performance comparable to physicians, especially across varying levels of case severity. It focuses on understanding how well a general-purpose approach can perform these critical healthcare tasks relative to both medical professionals and laypeople. The primary aim of the study is to evaluate the diagnostic and triage accuracy of a general-purpose language model on a set of validated synthetic medical cases, comparing its performance to that of practicing physicians and lay individuals. The study seeks to determine the model‚Äôs effectiveness in correctly identifying diagnoses and appropriate triage categories, as well as to assess its confidence calibration and error patterns in triage decisions.\n",
      "\n",
      "---------------------\n",
      "\n",
      "üîç [4] Rewriting if needed...\n",
      "\n",
      "---------------------\n",
      "\n",
      "You are reviewing an extracted summary describing the research idea and objective of a paper. The summary should be free of references related to Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL), or any related computational terms/phrases.\n",
      "\n",
      "These references can be direct, vague, euphemisms, or synonyms terms/phrases such as: Support Vector Machine, Decision Tree, Random Forest, Naive Bayes, K-Nearest Neighbors, Logistic Regression, Linear Regression, Gradient Boosting, XGBoost, LightGBM, CatBoost, AdaBoost, K-Means, DBSCAN, Hierarchical Clustering, PCA, LDA, Q-Learning, DQN, GAN, VAE, CNN, RNN, LSTM, GRU, Transformer, BERT, GPT, T5, LLaMA, Mistral, Claude, Autoencoder, MLP, ResNet, Inception, VGG, EfficientNet, YOLO, SSD, Faster R-CNN, Deep Reinforcement Learning, Meta-learning, Few-shot Learning, Zero-shot Learning, Federated Learning, Self-supervised Learning, Semi-supervised Learning, Supervised Learning, Unsupervised Learning, Transfer Learning, Representation Learning, learning algorithm, computational model, prediction model, automated method, data-driven technique, neural approach, intelligent system, adaptive model, classification technique, regression approach, optimization-based method, probabilistic framework, generative model, discriminative model, hybrid system, data analytics, pattern recognition technique, predictive pipeline, algorithmic solution, high-capacity model, state-of-the-art method, novel approach, ensemble method, custom architecture, algorithmic strategy, smart system, scalable framework, dynamic learning scheme, decision-making model, analytical model, computational strategy, advanced computing, intelligent analysis, automated detection, computational intelligence, smart detection, enhanced recognition, autonomous system, technology-driven approach, model-based analysis, hybrid learning, deep representation, intelligent estimation, self-learning mechanism, automatic classification, high-performance model, synthetic model generation, context-aware learning, domain adaptation, feature extraction technique, latent variable model, probabilistic inference, statistical modeling, parameter tuning, optimization routine, hyperparameter selection, loss minimization, backpropagation, likelihood estimation, training and testing phase, evaluation metrics, convergence behavior, stochastic process, sampling techniques, cross-validation, gradient descent, regularization method, overfitting prevention, feature engineering, dimensionality reduction, noise reduction technique\n",
      "\n",
      "Your task:\n",
      "1. Go sentence by sentence.\n",
      "2. If a sentence contains any such reference, rewrite it to remove or neutralize the term while keeping the original research idea or objective intact.\n",
      "3. If a sentence is already clean of any Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL) language, keep it unchanged.\n",
      "4. At the end, return a clean paragraph that captures the same research idea and objective without any AI/ML/DL-related language.\n",
      "\n",
      "Only return the final cleaned paragraph. Do not explain your changes.\n",
      "\n",
      "Here is the summary:\n",
      "The study addresses the challenge of obtaining comprehensive traffic flow data for effective traffic control and management, highlighting the impracticality of placing sensors on every network link and the inability of sensors to directly measure origin‚Äìdestination demand flows. It emphasizes the need to identify optimal locations for deploying traffic sensors and to enhance the information gathered from limited link flow measurements to estimate the complete traffic flow across the network. The primary objective of the research is to accurately estimate the entire origin‚Äìdestination flows within a traffic network using available link flow data, thereby reversing the conventional traffic assignment problem. Additionally, the study aims to determine the most important links for sensor placement to improve the estimation of traffic flows while minimizing the number of sensors required.\n",
      "\n",
      "---------------------\n",
      "\n",
      "üîç [5] Rewriting if needed...\n",
      "\n",
      "---------------------\n",
      "\n",
      "You are reviewing an extracted summary describing the research idea and objective of a paper. The summary should be free of references related to Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL), or any related computational terms/phrases.\n",
      "\n",
      "These references can be direct, vague, euphemisms, or synonyms terms/phrases such as: Support Vector Machine, Decision Tree, Random Forest, Naive Bayes, K-Nearest Neighbors, Logistic Regression, Linear Regression, Gradient Boosting, XGBoost, LightGBM, CatBoost, AdaBoost, K-Means, DBSCAN, Hierarchical Clustering, PCA, LDA, Q-Learning, DQN, GAN, VAE, CNN, RNN, LSTM, GRU, Transformer, BERT, GPT, T5, LLaMA, Mistral, Claude, Autoencoder, MLP, ResNet, Inception, VGG, EfficientNet, YOLO, SSD, Faster R-CNN, Deep Reinforcement Learning, Meta-learning, Few-shot Learning, Zero-shot Learning, Federated Learning, Self-supervised Learning, Semi-supervised Learning, Supervised Learning, Unsupervised Learning, Transfer Learning, Representation Learning, learning algorithm, computational model, prediction model, automated method, data-driven technique, neural approach, intelligent system, adaptive model, classification technique, regression approach, optimization-based method, probabilistic framework, generative model, discriminative model, hybrid system, data analytics, pattern recognition technique, predictive pipeline, algorithmic solution, high-capacity model, state-of-the-art method, novel approach, ensemble method, custom architecture, algorithmic strategy, smart system, scalable framework, dynamic learning scheme, decision-making model, analytical model, computational strategy, advanced computing, intelligent analysis, automated detection, computational intelligence, smart detection, enhanced recognition, autonomous system, technology-driven approach, model-based analysis, hybrid learning, deep representation, intelligent estimation, self-learning mechanism, automatic classification, high-performance model, synthetic model generation, context-aware learning, domain adaptation, feature extraction technique, latent variable model, probabilistic inference, statistical modeling, parameter tuning, optimization routine, hyperparameter selection, loss minimization, backpropagation, likelihood estimation, training and testing phase, evaluation metrics, convergence behavior, stochastic process, sampling techniques, cross-validation, gradient descent, regularization method, overfitting prevention, feature engineering, dimensionality reduction, noise reduction technique\n",
      "\n",
      "Your task:\n",
      "1. Go sentence by sentence.\n",
      "2. If a sentence contains any such reference, rewrite it to remove or neutralize the term while keeping the original research idea or objective intact.\n",
      "3. If a sentence is already clean of any Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL) language, keep it unchanged.\n",
      "4. At the end, return a clean paragraph that captures the same research idea and objective without any AI/ML/DL-related language.\n",
      "\n",
      "Only return the final cleaned paragraph. Do not explain your changes.\n",
      "\n",
      "Here is the summary:\n",
      "The research addresses the significant global public health challenge posed by sexually transmitted infections (STIs), emphasizing the importance of early diagnosis and treatment to reduce transmission. A key problem is the reliance on recognizing symptoms and individual care-seeking behavior, which can delay timely intervention. Improving the ability to distinguish STI-related skin conditions from non-STI conditions could enhance health-seeking behavior and facilitate earlier diagnosis. The primary aim of the study is to develop and evaluate a method to differentiate STIs from non-STIs based on clinical images and associated patient information. The study seeks to improve the accuracy of distinguishing these conditions to support better screening and diagnosis in clinical settings.\n",
      "\n",
      "---------------------\n",
      "\n",
      "üîç [6] Rewriting if needed...\n",
      "\n",
      "---------------------\n",
      "\n",
      "You are reviewing an extracted summary describing the research idea and objective of a paper. The summary should be free of references related to Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL), or any related computational terms/phrases.\n",
      "\n",
      "These references can be direct, vague, euphemisms, or synonyms terms/phrases such as: Support Vector Machine, Decision Tree, Random Forest, Naive Bayes, K-Nearest Neighbors, Logistic Regression, Linear Regression, Gradient Boosting, XGBoost, LightGBM, CatBoost, AdaBoost, K-Means, DBSCAN, Hierarchical Clustering, PCA, LDA, Q-Learning, DQN, GAN, VAE, CNN, RNN, LSTM, GRU, Transformer, BERT, GPT, T5, LLaMA, Mistral, Claude, Autoencoder, MLP, ResNet, Inception, VGG, EfficientNet, YOLO, SSD, Faster R-CNN, Deep Reinforcement Learning, Meta-learning, Few-shot Learning, Zero-shot Learning, Federated Learning, Self-supervised Learning, Semi-supervised Learning, Supervised Learning, Unsupervised Learning, Transfer Learning, Representation Learning, learning algorithm, computational model, prediction model, automated method, data-driven technique, neural approach, intelligent system, adaptive model, classification technique, regression approach, optimization-based method, probabilistic framework, generative model, discriminative model, hybrid system, data analytics, pattern recognition technique, predictive pipeline, algorithmic solution, high-capacity model, state-of-the-art method, novel approach, ensemble method, custom architecture, algorithmic strategy, smart system, scalable framework, dynamic learning scheme, decision-making model, analytical model, computational strategy, advanced computing, intelligent analysis, automated detection, computational intelligence, smart detection, enhanced recognition, autonomous system, technology-driven approach, model-based analysis, hybrid learning, deep representation, intelligent estimation, self-learning mechanism, automatic classification, high-performance model, synthetic model generation, context-aware learning, domain adaptation, feature extraction technique, latent variable model, probabilistic inference, statistical modeling, parameter tuning, optimization routine, hyperparameter selection, loss minimization, backpropagation, likelihood estimation, training and testing phase, evaluation metrics, convergence behavior, stochastic process, sampling techniques, cross-validation, gradient descent, regularization method, overfitting prevention, feature engineering, dimensionality reduction, noise reduction technique\n",
      "\n",
      "Your task:\n",
      "1. Go sentence by sentence.\n",
      "2. If a sentence contains any such reference, rewrite it to remove or neutralize the term while keeping the original research idea or objective intact.\n",
      "3. If a sentence is already clean of any Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL) language, keep it unchanged.\n",
      "4. At the end, return a clean paragraph that captures the same research idea and objective without any AI/ML/DL-related language.\n",
      "\n",
      "Only return the final cleaned paragraph. Do not explain your changes.\n",
      "\n",
      "Here is the summary:\n",
      "The research idea centers on the limitations of current computational methods in addressing complex scientific challenges due to their extensive time and resource requirements, highlighting the potential of emerging technologies to overcome these barriers. It recognizes that while traditional approaches struggle with problems of immense complexity, alternative computational paradigms offer promising advantages that could transform fields such as finance, chemistry, and pattern recognition. The study‚Äôs primary objective is to review and categorize recent scholarly work published between 2017 and 2023 that explores the application of these emerging computational approaches within the context of learning and classification tasks. It aims to identify the various types of strategies employed, their practical implementations, and the extent to which they have been applied to solve problems traditionally addressed by classical methods, while also acknowledging the current limitations that prevent these approaches from reaching their full potential.\n",
      "\n",
      "---------------------\n",
      "\n",
      "\n",
      "‚úÖ All results saved to: stage 2/Rewritten Masked Extraction.csv\n",
      "‚úÖ Clean summaries saved to: stage 2/leakage free summaries only.csv (2 rows)\n",
      "üö® Rewritten (previously leaked) summaries saved to: stage 2/leaked summaries only.csv (5 rows)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# üé¨ Run\n",
    "# -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    detect_and_rewrite(INPUT_CSV, OUTPUT_CSV_ALL, OUTPUT_CSV_CLEAN, OUTPUT_CSV_LEAKED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d586cb75-3c0a-47e5-a7f9-0441cea39356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba63ac7-7463-404b-a698-49b5260412ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
