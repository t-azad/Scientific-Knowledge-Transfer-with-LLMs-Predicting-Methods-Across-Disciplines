domain,title,abstract,verified methods list,masked extraction
Biology,"A Comprehensive Survey of Continual Learning: Theory, Method and Application","To cope with real-world dynamics, an intelligent system needs to incrementally acquire, update, accumulate, and exploit knowledge throughout its lifetime. This ability, known as continual learning, provides a foundation for AI systems to develop themselves adaptively. In a general sense, continual learning is explicitly limited by catastrophic forgetting, where learning a new task usually results in a dramatic performance drop of the old tasks. Beyond this, increasingly numerous advances have emerged in recent years that largely extend the understanding and application of continual learning. The growing and widespread interest in this direction demonstrates its realistic significance as well as complexity. In this work, we present a comprehensive survey of continual learning, seeking to bridge the basic settings, theoretical foundations, representative methods, and practical applications. Based on existing theoretical and empirical results, we summarize the general objectives of continual learning as ensuring a proper stability-plasticity trade-off and an adequate intra/inter-task generalizability in the context of resource efficiency. Then we provide a state-of-the-art and elaborated taxonomy, extensively analyzing how representative strategies address continual learning, and how they are adapted to particular challenges in various applications. Through an in-depth discussion of promising directions, we believe that such a holistic perspective can greatly facilitate subsequent exploration in this field and beyond.",['continual learning'],"The research idea centers on the challenge of continually acquiring, updating, and utilizing knowledge over time without losing previously learned information, a problem known as catastrophic forgetting. This issue is significant because learning new tasks often leads to a decline in performance on earlier tasks, highlighting the complexity of maintaining both stability and adaptability in dynamic environments. The study’s primary objective is to comprehensively summarize and categorize existing approaches to continual learning, focusing on achieving a balance between retaining old knowledge and integrating new information effectively. Additionally, it aims to analyze how different strategies address these challenges and to provide insights that can guide future research in this area."
Biology,Genotype by Environment Interaction and Adaptation in Barley Breeding: Basic Concepts and Methods of Analysis,"Genotype by environment interaction (GE) has important consequences in barley breeding. It often complicates testing and selection of superior genotypes, reducing genetic progress in breeding programs. This drawback may be overcome by a better understanding of the genetic and environmental factors that determine GE and adaptation of genotypes. An important array of statistical techniques is nowadays available to breeders and researchers to cope with the presence of relevant GE in multi-environment trials. This paper begins with a review of recent literature on the latest barley studies on GE and adaptation, including potential biotic and abiotic causes underlying GE. Most studies reported are empirical, describing postdictively genotypic performance across environments. As an alternative, methods allowing a more analytical approach are proposed, in which genotypes and environments are characterized in terms of external variables that affect genotypic performance. These methods are applied to a real barley data set. After data description, a number of selected multiplicative models are developed, namely the additive main effects and multiplicative interaction (AMMI) model, and the factorial regression model. Finally, the implications of GE in barley breeding are discussed. As an appendix, the SAS programs are given for the models described. Key-words: genotype by environment interaction, adaptation, AMMI, factorial regression, breeding programs",['additive main effects and multiplicative interaction (AMMI) model'],"The research idea centers on the significant impact of genotype by environment interaction (GE) in barley breeding, which complicates the testing and selection of superior genotypes and consequently reduces genetic progress in breeding programs. Understanding the genetic and environmental factors that influence GE and the adaptation of genotypes is crucial to overcoming these challenges. The primary objective of the study is to review recent barley research on GE and adaptation, including the biotic and abiotic causes underlying GE, and to propose an analytical approach that characterizes genotypes and environments based on external variables affecting genotypic performance. This approach aims to improve the understanding of GE and its implications for barley breeding programs."
Biology,"Revolutionizing agriculture with artificial intelligence: plant disease detection methods, applications, and their limitations","Accurate and rapid plant disease detection is critical for enhancing long-term agricultural yield. Disease infection poses the most significant challenge in crop production, potentially leading to economic losses. Viruses, fungi, bacteria, and other infectious organisms can affect numerous plant parts, including roots, stems, and leaves. Traditional techniques for plant disease detection are time-consuming, require expertise, and are resource-intensive. Therefore, automated leaf disease diagnosis using artificial intelligence (AI) with Internet of Things (IoT) sensors methodologies are considered for the analysis and detection. This research examines four crop diseases: tomato, chilli, potato, and cucumber. It also highlights the most prevalent diseases and infections in these four types of vegetables, along with their symptoms. This review provides detailed predetermined steps to predict plant diseases using AI. Predetermined steps include image acquisition, preprocessing, segmentation, feature selection, and classification. Machine learning (ML) and deep understanding (DL) detection models are discussed. A comprehensive examination of various existing ML and DL-based studies to detect the disease of the following four crops is discussed, including the datasets used to evaluate these studies. We also provided the list of plant disease detection datasets. Finally, different ML and DL application problems are identified and discussed, along with future research prospects, by combining AI with IoT platforms like smart drones for field-based disease detection and monitoring. This work will help other practitioners in surveying different plant disease detection strategies and the limits of present systems.","['machine learning (ML)', 'deep learning (DL)']","The research addresses the critical need for accurate and rapid detection of plant diseases to enhance long-term agricultural yield, as disease infections pose significant challenges in crop production and can lead to economic losses. Various infectious organisms such as viruses, fungi, and bacteria affect multiple parts of plants, including roots, stems, and leaves, making timely and effective disease identification essential. The study focuses on four important crops—tomato, chilli, potato, and cucumber—and highlights the most prevalent diseases and their symptoms in these vegetables. The primary objective of the research is to examine and review existing approaches for detecting diseases in these four crops, providing detailed steps and insights into disease diagnosis, as well as identifying current challenges and future prospects in plant disease detection to support practitioners in improving detection strategies."
Biology,Deep-STP: a deep learning-based approach to predict snake toxin proteins by using word embeddings,"Snake venom contains many toxic proteins that can destroy the circulatory system or nervous system of prey. Studies have found that these snake venom proteins have the potential to treat cardiovascular and nervous system diseases. Therefore, the study of snake venom protein is conducive to the development of related drugs. The research technologies based on traditional biochemistry can accurately identify these proteins, but the experimental cost is high and the time is long. Artificial intelligence technology provides a new means and strategy for large-scale screening of snake venom proteins from the perspective of computing. In this paper, we developed a sequence-based computational method to recognize snake toxin proteins. Specially, we utilized three different feature descriptors, namely g-gap , natural vector and word 2 vector, to encode snake toxin protein sequences. The analysis of variance (ANOVA), gradient-boost decision tree algorithm (GBDT) combined with incremental feature selection (IFS) were used to optimize the features, and then the optimized features were input into the deep learning model for model training. The results show that our model can achieve a prediction performance with an accuracy of 82.00% in 10-fold cross-validation. The model is further verified on independent data, and the accuracy rate reaches to 81.14%, which demonstrated that our model has excellent prediction performance and robustness.","['gradient-boost decision tree algorithm (GBDT)', 'incremental feature selection (IFS)', 'deep learning model']","The study addresses the presence of toxic proteins in snake venom that can damage the circulatory or nervous systems of prey, highlighting their potential use in treating cardiovascular and nervous system diseases. Understanding and identifying these snake venom proteins is important for the development of related drugs. The primary aim of the study is to recognize and accurately identify snake toxin proteins to facilitate their study and potential therapeutic application. This research seeks to improve the identification process of these proteins to support drug development efforts."
Biology,Can large language models replace humans in systematic reviews? Evaluating <scp>GPT</scp>‐4's efficacy in screening and extracting data from peer‐reviewed and grey literature in multiple languages,"Systematic reviews are vital for guiding practice, research and policy, although they are often slow and labour-intensive. Large language models (LLMs) could speed up and automate systematic reviews, but their performance in such tasks has yet to be comprehensively evaluated against humans, and no study has tested Generative Pre-Trained Transformer (GPT)-4, the biggest LLM so far. This pre-registered study uses a ""human-out-of-the-loop"" approach to evaluate GPT-4's capability in title/abstract screening, full-text review and data extraction across various literature types and languages. Although GPT-4 had accuracy on par with human performance in some tasks, results were skewed by chance agreement and dataset imbalance. Adjusting for these caused performance scores to drop across all stages: for data extraction, performance was moderate, and for screening, it ranged from none in highly balanced literature datasets (~1:1) to moderate in those datasets where the ratio of inclusion to exclusion in studies was imbalanced (~1:3). When screening full-text literature using highly reliable prompts, GPT-4's performance was more robust, reaching ""human-like"" levels. Although our findings indicate that, currently, substantial caution should be exercised if LLMs are being used to conduct systematic reviews, they also offer preliminary evidence that, for certain review tasks delivered under specific conditions, LLMs can rival human performance.",['Generative Pre-Trained Transformer (GPT)-4'],"The research idea centers on the importance of systematic reviews for guiding practice, research, and policy, while highlighting the challenges posed by their slow and labor-intensive nature. The study addresses the need to evaluate new approaches that could potentially accelerate and automate the process of conducting systematic reviews. The primary objective of the study is to comprehensively assess the capability of GPT-4 in performing key tasks involved in systematic reviews, including title and abstract screening, full-text review, and data extraction across various types of literature and languages. The study aims to determine how well GPT-4’s performance compares to human reviewers in these tasks and to identify the conditions under which it may achieve human-like accuracy."
Biology,Feature reduction for hepatocellular carcinoma prediction using machine learning algorithms,"Abstract Hepatocellular carcinoma (HCC) is a highly prevalent form of liver cancer that necessitates accurate prediction models for early diagnosis and effective treatment. Machine learning algorithms have demonstrated promising results in various medical domains, including cancer prediction. In this study, we propose a comprehensive approach for HCC prediction by comparing the performance of different machine learning algorithms before and after applying feature reduction methods. We employ popular feature reduction techniques, such as weighting features, hidden features correlation, feature selection, and optimized selection, to extract a reduced feature subset that captures the most relevant information related to HCC. Subsequently, we apply multiple algorithms, including Naive Bayes, support vector machines (SVM), Neural Networks, Decision Tree, and K nearest neighbors (KNN), to both the original high-dimensional dataset and the reduced feature set. By comparing the predictive accuracy, precision, F Score, recall, and execution time of each algorithm, we assess the effectiveness of feature reduction in enhancing the performance of HCC prediction models. Our experimental results, obtained using a comprehensive dataset comprising clinical features of HCC patients, demonstrate that feature reduction significantly improves the performance of all examined algorithms. Notably, the reduced feature set consistently outperforms the original high-dimensional dataset in terms of prediction accuracy and execution time. After applying feature reduction techniques, the employed algorithms, namely decision trees, Naive Bayes, KNN, neural networks, and SVM achieved accuracies of 96%, 97.33%, 94.67%, 96%, and 96.00%, respectively.","['Naive Bayes', 'support vector machines (SVM)', 'Neural Networks', 'Decision Tree', 'K nearest neighbors (KNN)']","The study addresses the challenge of accurately predicting hepatocellular carcinoma (HCC), a highly prevalent form of liver cancer, which is crucial for early diagnosis and effective treatment. Improving prediction accuracy is essential to better identify patients at risk and enhance clinical outcomes. The primary aim of the study is to evaluate and compare the effectiveness of different approaches in predicting HCC by identifying the most relevant clinical features associated with the disease. This involves assessing how reducing the number of features impacts the accuracy and efficiency of HCC prediction, ultimately aiming to improve the reliability of diagnostic methods for this type of liver cancer."
Biology,CIFAKE: Image Classification and Explainable Identification of AI-Generated Synthetic Images,"Recent advances in synthetic data have enabled the generation of images with such high quality that human beings cannot tell the difference between real-life photographs and Artificial Intelligence (AI) generated images. Given the critical necessity of data reliability and authentication, this article proposes to enhance our ability to recognise AI-generated images through computer vision. Initially, a synthetic dataset is generated that mirrors the ten classes of the already available CIFAR-10 dataset with latent diffusion, providing a contrasting set of images for comparison to real photographs. The model is capable of generating complex visual attributes, such as photorealistic reflections in water. The two sets of data present as a binary classification problem with regard to whether the photograph is real or generated by AI. This study then proposes the use of a Convolutional Neural Network (CNN) to classify the images into two categories; Real or Fake. Following hyperparameter tuning and the training of 36 individual network topologies, the optimal approach could correctly classify the images with 92.98% accuracy. Finally, this study implements explainable AI via Gradient Class Activation Mapping to explore which features within the images are useful for classification. Interpretation reveals interesting concepts within the image, in particular, noting that the actual entity itself does not hold useful information for classification; instead, the model focuses on small visual imperfections in the background of the images. The complete dataset engineered for this study, referred to as the CIFAKE dataset, is made publicly available to the research community for future work.","['latent diffusion', 'Convolutional Neural Network (CNN)', 'Gradient Class Activation Mapping']","The research idea addresses the challenge of distinguishing between real-life photographs and synthetic images that are generated with such high quality that they are indistinguishable to the human eye. Given the critical necessity of data reliability and authentication, the study focuses on enhancing the ability to recognize artificially generated images. The primary objective of the study is to develop a method to classify images into real or AI-generated categories by comparing synthetic images that mirror established photographic classes with authentic photographs. Additionally, the study aims to identify specific visual features that differentiate real images from synthetic ones, thereby improving understanding of the distinguishing characteristics between these two types of images."
Biology,Optimization of hepatological clinical guidelines interpretation by large language models: a retrieval augmented generation-based framework,"Abstract Large language models (LLMs) can potentially transform healthcare, particularly in providing the right information to the right provider at the right time in the hospital workflow. This study investigates the integration of LLMs into healthcare, specifically focusing on improving clinical decision support systems (CDSSs) through accurate interpretation of medical guidelines for chronic Hepatitis C Virus infection management. Utilizing OpenAI’s GPT-4 Turbo model, we developed a customized LLM framework that incorporates retrieval augmented generation (RAG) and prompt engineering. Our framework involved guideline conversion into the best-structured format that can be efficiently processed by LLMs to provide the most accurate output. An ablation study was conducted to evaluate the impact of different formatting and learning strategies on the LLM’s answer generation accuracy. The baseline GPT-4 Turbo model’s performance was compared against five experimental setups with increasing levels of complexity: inclusion of in-context guidelines, guideline reformatting, and implementation of few-shot learning. Our primary outcome was the qualitative assessment of accuracy based on expert review, while secondary outcomes included the quantitative measurement of similarity of LLM-generated responses to expert-provided answers using text-similarity scores. The results showed a significant improvement in accuracy from 43 to 99% ( p &lt; 0.001), when guidelines were provided as context in a coherent corpus of text and non-text sources were converted into text. In addition, few-shot learning did not seem to improve overall accuracy. The study highlights that structured guideline reformatting and advanced prompt engineering (data quality vs. data quantity) can enhance the efficacy of LLM integrations to CDSSs for guideline delivery.","['OpenAI’s GPT-4 Turbo model', 'retrieval augmented generation (RAG)', 'few-shot learning']",The study addresses the challenge of improving clinical decision support systems for the management of chronic Hepatitis C Virus infection by ensuring accurate interpretation and delivery of medical guidelines within healthcare settings. It focuses on the need to provide the right information to healthcare providers at the right time to enhance patient care and treatment outcomes. The primary aim of the study is to investigate how the structuring and presentation of clinical guidelines can improve the accuracy of guideline interpretation and support clinical decision-making for chronic Hepatitis C Virus infection management. The study seeks to evaluate the impact of different guideline formatting strategies on the accuracy of clinical recommendations to ultimately enhance the effectiveness of guideline delivery in healthcare workflows.
Biology,Survival Prediction Across Diverse Cancer Types Using Neural Networks,"Gastric cancer and Colon adenocarcinoma represent widespread and challenging malignancies with high mortality rates and complex treatment landscapes. In response to the critical need for accurate prognosis in cancer patients, the medical community has embraced the 5-year survival rate as a vital metric for estimating patient outcomes. This study introduces a pioneering approach to enhance survival prediction models for gastric and Colon adenocarcinoma patients. Leveraging advanced image analysis techniques, we sliced whole slide images (WSI) of these cancers, extracting comprehensive features to capture nuanced tumor characteristics. Subsequently, we constructed patient-level graphs, encapsulating intricate spatial relationships within tumor tissues. These graphs served as inputs for a sophisticated 4-layer graph convolutional neural network (GCN), designed to exploit the inherent connectivity of the data for comprehensive analysis and prediction. By integrating patients' total survival time and survival status, we computed C-index values for gastric cancer and Colon adenocarcinoma, yielding 0.57 and 0.64, respectively. Significantly surpassing previous convolutional neural network models, these results underscore the efficacy of our approach in accurately predicting patient survival outcomes. This research holds profound implications for both the medical and AI communities, offering insights into cancer biology and progression while advancing personalized treatment strategies. Ultimately, our study represents a significant stride in leveraging AI-driven methodologies to revolutionize cancer prognosis and improve patient outcomes on a global scale.","['graph convolutional neural network (GCN)', 'convolutional neural network']","The study addresses the critical challenge of accurately predicting survival outcomes for patients with gastric cancer and colon adenocarcinoma, two malignancies characterized by high mortality rates and complex treatment options. Given the importance of the 5-year survival rate as a key metric for estimating patient prognosis, there is a pressing need to improve the precision of survival predictions in these cancers. The primary objective of this research is to enhance survival prediction for gastric and colon adenocarcinoma patients by capturing detailed tumor characteristics and spatial relationships within tumor tissues. This aims to provide more accurate estimates of patient outcomes, thereby contributing to better-informed clinical decision-making and personalized treatment strategies."
Biology,Aspect-based drug review classification through a hybrid model with ant colony optimization using deep learning,"Abstract The task of aspect-level sentiment analysis is intricately designed to determine the sentiment polarity directed towards a specific target within a sentence. With the increasing availability of online reviews and the growing importance of healthcare decisions, analyzing drug reviews has become a critical task. Traditional sentiment analysis, which categorizes a whole review as positive, negative, or neutral, provides limited insights for consumers and healthcare professionals. Aspect-based sentiment analysis (ABSA) aims to overcome these limitations by identifying and evaluating the sentiment associated with specific aspects or attributes of drugs mentioned in the reviews. Various fields, including business, politics, and medicine, have been explored in the context of sentiment analysis. Automation of online user reviews allows pharmaceutical companies to assess large amounts of user feedback. This helps extract pharmacological efficacy and side effect insights. The data collected could improve pharmacovigilance. Reviewing user comments can provide valuable data that can be used to improve drug safety and efficacy monitoring procedures. This improves pharmacovigilance processes, improving pharmaceutical outcomes understanding and corporate decision-making. Therefore, we propose a pre-trained RoBERTa with a Bi-LSTM model to categorise drug reviews from online sources and pre-process the text data. Ant Colony Optimization can be used in feature selection for ABSA, helping to identify the most relevant aspects and sentiments. Further, RoBERTa is fine-tuned to perform ABSA on the dataset, enabling the system to categorize aspects and determine the associated sentiment. The outcomes reveal that the suggested framework has achieved higher accuracy (96.78%) and F1 score (98.29%) on druglib.com, and 95.02% on the drugs.com dataset, than several prior state-of-the-art methods.","['pre-trained RoBERTa', 'Bi-LSTM model', 'fine-tuned RoBERTa']","The research addresses the challenge of understanding specific sentiments expressed toward particular aspects of drugs within online reviews, which is crucial given the increasing reliance on such reviews for healthcare decisions. Traditional methods that classify entire reviews as simply positive, negative, or neutral fail to provide detailed insights needed by consumers and healthcare professionals. This study focuses on improving the extraction of nuanced sentiment information related to distinct drug attributes to enhance pharmacovigilance and drug safety monitoring. The primary objective of the study is to categorize drug reviews from online sources by identifying and evaluating the sentiment associated with specific drug aspects mentioned in the reviews. This aims to provide more detailed and actionable insights into pharmacological efficacy and side effects, thereby supporting improved drug safety and efficacy monitoring procedures."
Biology,"A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection in Industrial Time Series: Methods, Applications, and Directions","Automating the monitoring of industrial processes has the potential to enhance efficiency and optimize quality by promptly detecting abnormal events and thus facilitating timely interventions. Deep learning, with its capacity to discern non-trivial patterns within large datasets, plays a pivotal role in this process. Standard deep learning methods are suitable to solve a specific task given a specific type of data. During training, deep learning demands large volumes of labeled data. However, due to the dynamic nature of the industrial processes and environment, it is impractical to acquire large-scale labeled data for standard deep learning training for every slightly different case anew. Deep transfer learning offers a solution to this problem. By leveraging knowledge from related tasks and accounting for variations in data distributions, the transfer learning framework solves new tasks with little or even no additional labeled data. The approach bypasses the need to retrain a model from scratch for every new setup and dramatically reduces the labeled data requirement. This survey first provides an in-depth review of deep transfer learning, examining the problem settings of transfer learning and classifying the prevailing deep transfer learning methods. Moreover, we delve into applications of deep transfer learning in the context of a broad spectrum of time series anomaly detection tasks prevalent in primary industrial domains, e.g., manufacturing process monitoring, predictive maintenance, energy management, and infrastructure facility monitoring. We discuss the challenges and limitations of deep transfer learning in industrial contexts and conclude the survey with practical directions and actionable suggestions to address the need to leverage diverse time series data for anomaly detection in an increasingly dynamic production environment.","['deep learning', 'deep transfer learning', 'transfer learning framework']","The research idea centers on the challenge of monitoring industrial processes efficiently by detecting abnormal events promptly to enhance operational quality and enable timely interventions. Due to the dynamic nature of industrial environments, acquiring large-scale labeled data for every variation in the process is impractical, creating a need for approaches that can adapt to changing conditions with limited new data. The primary objective of the study is to review and classify existing methods that address this challenge by leveraging knowledge from related tasks to detect anomalies in time series data across various industrial domains. Additionally, the study aims to discuss the challenges and limitations of these methods in industrial settings and provide practical recommendations for improving anomaly detection in dynamic production environments."
Biology,Enhancing precision agriculture: A comprehensive review of machine learning and AI vision applications in all-terrain vehicle for farm automation,"The automation of all-terrain vehicles (ATVs) through the integration of advanced technologies such as machine learning (ML) and artificial intelligence (AI) vision has significantly changed precision agriculture. This paper aims to analyse and develop trends to provide comprehensive knowledge of the current state of ATV-based precision agriculture and the future possibilities of ML and AI. A bibliometric analysis was conducted through network diagram with keywords taken from previous publications in the domain. This review comprehensively analyses the potential of machine learning and artificial intelligence in transforming farming operations through the automation of tasks and the deployment of all-terrain vehicles. The research extensively analyses how machine learning methods have influenced several aspects of agricultural activities, such as planting, harvesting, spraying, weeding, crop monitoring, and others. AI vision systems are being researched for their ability to enhance precise and prompt decision-making in ATV-driven agricultural automation. These technologies have been thoroughly tested to show how they can improve crop yield, reducing overall investment, and make farming more efficient. Examples include machine learning-based seeding accuracy, AI-enabled crop health monitoring, and the use of AI vision for accurate pesticide application. The assessment examines challenges such as data privacy problems and scalability constraints, along with potential advancements and future prospects in the field. This will assist researchers and practitioners in making well-informed judgments regarding farming practices that are efficient, sustainable, and technologically robust.",['machine learning'],"The study addresses the evolving role of all-terrain vehicles (ATVs) in precision agriculture and the impact of integrating advanced technologies to transform farming operations. It highlights the motivation to understand how these innovations can improve various agricultural activities such as planting, harvesting, spraying, weeding, and crop monitoring, ultimately aiming to enhance crop yield and farming efficiency. The primary objective of the research is to provide a comprehensive overview of the current state and future possibilities of ATV-based precision agriculture, focusing on how these advancements can automate tasks and support precise decision-making in agricultural practices. The study also aims to identify challenges and potential developments to guide researchers and practitioners toward more efficient, sustainable, and effective farming methods."
Biology,An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing: Algorithm Development and Validation Study,"Background Large language models (LLMs) have shown remarkable capabilities in natural language processing (NLP), especially in domains where labeled data are scarce or expensive, such as the clinical domain. However, to unlock the clinical knowledge hidden in these LLMs, we need to design effective prompts that can guide them to perform specific clinical NLP tasks without any task-specific training data. This is known as in-context learning, which is an art and science that requires understanding the strengths and weaknesses of different LLMs and prompt engineering approaches. Objective The objective of this study is to assess the effectiveness of various prompt engineering techniques, including 2 newly introduced types—heuristic and ensemble prompts, for zero-shot and few-shot clinical information extraction using pretrained language models. Methods This comprehensive experimental study evaluated different prompt types (simple prefix, simple cloze, chain of thought, anticipatory, heuristic, and ensemble) across 5 clinical NLP tasks: clinical sense disambiguation, biomedical evidence extraction, coreference resolution, medication status extraction, and medication attribute extraction. The performance of these prompts was assessed using 3 state-of-the-art language models: GPT-3.5 (OpenAI), Gemini (Google), and LLaMA-2 (Meta). The study contrasted zero-shot with few-shot prompting and explored the effectiveness of ensemble approaches. Results The study revealed that task-specific prompt tailoring is vital for the high performance of LLMs for zero-shot clinical NLP. In clinical sense disambiguation, GPT-3.5 achieved an accuracy of 0.96 with heuristic prompts and 0.94 in biomedical evidence extraction. Heuristic prompts, alongside chain of thought prompts, were highly effective across tasks. Few-shot prompting improved performance in complex scenarios, and ensemble approaches capitalized on multiple prompt strengths. GPT-3.5 consistently outperformed Gemini and LLaMA-2 across tasks and prompt types. Conclusions This study provides a rigorous evaluation of prompt engineering methodologies and introduces innovative techniques for clinical information extraction, demonstrating the potential of in-context learning in the clinical domain. These findings offer clear guidelines for future prompt-based clinical NLP research, facilitating engagement by non-NLP experts in clinical NLP advancements. To the best of our knowledge, this is one of the first works on the empirical evaluation of different prompt engineering approaches for clinical NLP in this era of generative artificial intelligence, and we hope that it will inspire and inform future research in this area.","['in-context learning', 'few-shot prompting', 'zero-shot prompting']","The research idea addresses the challenge of extracting valuable clinical knowledge from large language models without relying on task-specific training data, focusing on how to effectively guide these models to perform various clinical information extraction tasks. This study is motivated by the need to improve clinical natural language processing in scenarios where labeled clinical data are scarce or expensive, emphasizing the importance of designing appropriate prompts to unlock the potential of these models for clinical applications. The primary objective of the study is to evaluate the effectiveness of different prompt engineering techniques, including newly introduced heuristic and ensemble prompts, for zero-shot and few-shot clinical information extraction across multiple clinical tasks. The study aims to provide a comprehensive assessment of these approaches to enhance clinical information extraction performance and offer practical guidelines for future research in clinical natural language processing."
Biology,A systematic review of hyperspectral imaging in precision agriculture: Analysis of its current state and future prospects,"Hyperspectral sensor adaptability in precision agriculture to digital images is still at its nascent stage. Hyperspectral imaging (HSI) is data rich in solving agricultural problems like disease detection, weed detection, stress detection, crop monitoring, nutrient application, soil mineralogy, yield estimation, and sorting applications. With modern precision agriculture, the challenge now is to bring these applications to the field for real-time solutions, where machines are enabled to conduct analyses without expert supervision and communicate the results to users for better management of farmlands; a necessary step to gain complete autonomy in agricultural farmlands. Significant advancements in HSI technology for precision agriculture are required to fully realize its potential. As a wide-ranging collection of the status of HSI and analysis in precision agriculture is lacking, this review endeavors to provide a comprehensive overview of the recent advancements and trends of HSI in precision agriculture for real-time applications. In this study, a systematic review of 163 scientific articles published over the past twenty years (2003–2023) was conducted. Of these, 97 were selected for further analysis based on their relevance to the topic at hand. Topics include conventional data preprocessing techniques, hyperspectral data acquisition, data compression methods, and segmentation methods. The hardware implementation of field-programmable gate arrays (FPGAs) and graphics processing units (GPUs) for high-speed data processing and application of machine learning and deep learning technologies were explored. This review highlights the potential of HSI as a powerful tool for precision agriculture, particularly in real-time applications, discusses limitations, and provides insights into future research directions.","['machine learning', 'deep learning']","The research idea centers on the emerging role of hyperspectral imaging (HSI) in precision agriculture, particularly its potential to address critical agricultural challenges such as disease detection, weed detection, stress detection, crop monitoring, nutrient application, soil mineralogy, yield estimation, and sorting. Despite its promise, the adaptation of hyperspectral sensors for real-time field applications remains in the early stages, and significant advancements are needed to fully harness HSI technology for autonomous and efficient farmland management. The primary objective of this study is to provide a comprehensive overview of recent advancements and trends in the use of hyperspectral imaging within precision agriculture, focusing on real-time applications. This review aims to synthesize current knowledge, highlight the potential and limitations of HSI, and offer insights into future research directions to support the development of effective real-time solutions in agricultural practices."
Biology,Critical review on water quality analysis using IoT and machine learning models,"Water quality and its management are the most precise concerns confronting humanity globally. This article evaluates the various sensors used for water quality monitoring and focuses on the water quality index considering the multiple physical, chemical, and biological parameters. A Review of Internet of Things (IoT) research for water quality monitoring and analysis, sensors used for water quality can help remote monitoring of the water quality parameters using various IoT-based sensors that convey the assembled estimations utilizing Low-Power Wide Area Network innovations. Overall, the IoT system was 95 % accurate in measuring pH, Turbidity, TDS, and Temperature, while the traditional method was only 85 % accurate. Also, this study reviewed the different A.I. techniques used to assess water quality, including conventional machine learning techniques, Support Vector Machines, Deep Neural Networks, and K-nearest neighbors. Compared to traditional methods, machine learning and deep learning can significantly increase the accuracy of measurements of groundwater quality. However, various variables, such as the caliber of the training data, the water quality metrics' complexity, and the monitoring frequency, will affect the accuracy. The geographical information system (GIS) is used for spatial data analysis and managing water resources. The quality of its data is also reviewed in the paper. Based on these analyses, the study has forecasted the future sensors, Geospatial Technology, and machine learning techniques for water quality monitoring and analysis.","['Support Vector Machines', 'Deep Neural Networks', 'K-nearest neighbors']","The research idea centers on the critical global concern of water quality and its management, emphasizing the importance of monitoring multiple physical, chemical, and biological parameters to assess water quality accurately. The study addresses the need for effective evaluation and management of water quality to ensure environmental safety and public health. The primary objective of the study is to evaluate various sensors used for water quality monitoring, focusing on the water quality index derived from multiple parameters, and to review the effectiveness of different approaches for measuring and managing water quality. The study aims to provide insights into improving the accuracy and reliability of water quality assessment methods to support better water resource management."
Biology,A novel framework for developing environmentally sustainable and cost-effective ultra-high-performance concrete (UHPC) using advanced machine learning and multi-objective optimization techniques,"This study aims to propose a novel framework for strength prediction and multi-objective optimization (MOO) of economical and environmentally sustainable ultra-high-performance concrete (UHPC) which aids in intelligent, sustainable, and resilient construction. Different tree- and boosting ensemble-based machine learning (ML) models are integrated to form an accurate and reliable prediction model for the uniaxial compressive strength of UHPC. The optimized models are integrated into a super learner model, resulting in a robust predictive model that is used as one of the objective functions in the MOO problem. A total of 19 objective functions are considered, including cost, uniaxial compressive strength, and 17 environmental impact categories that comprehensively evaluate the environmental sustainability of the UHPC mix. The resulting impacts from the mid-point indicators were calculated using the Eco-invent v3.7 Life Cycle Inventory database. The results showed that the super learner model accurately predicted the uniaxial compressive strength of UHPC. The MOO resulted in Pareto fronts, demonstrating the trade-off among the uniaxial compressive strength, cost, and environmental sustainability of the mix and a broad range of solutions that can be obtained for the 19 objectives. The study provides a useful tool for designers and decision-makers to select the optimal UHPC mixture that meets specific project requirements. Finally, for the practical application of the ML predictive model and MOO algorithm for UHPC, a graphical user interface-based software tool, FAI-OSUSCONCRET, was developed. This software tool offers fast, accurate, and intelligent predictions and multi-objective optimizations tailored to specific project requirements, thus resulting in a UHPC mixture that perfectly meets project needs.","['tree-based ensemble machine learning models', 'boosting ensemble-based machine learning models', 'super learner model']","The study addresses the challenge of developing ultra-high-performance concrete (UHPC) that is both economically viable and environmentally sustainable, focusing on achieving a balance between strength, cost, and environmental impact. It highlights the need for optimizing UHPC mixtures to support sustainable and resilient construction practices by considering multiple objectives including mechanical performance and environmental sustainability. The primary aim of the study is to accurately predict the uniaxial compressive strength of UHPC and to perform multi-objective optimization that evaluates trade-offs among strength, cost, and various environmental impact categories. This enables the identification of optimal UHPC mixtures that meet specific project requirements while promoting sustainability in construction."
Biology,Utilizing Hybrid Machine Learning and Soft Computing Techniques for Landslide Susceptibility Mapping in a Drainage Basin,"The hydrological system of thebasin of Lake Urmia is complex, deriving its supply from a network comprising 13 perennial rivers, along withnumerous small springs and direct precipitation onto the lake’s surface. Among these contributors, approximately half of the inflow is attributed to the Zarrineh River and the Simineh River. Remarkably, Lake Urmia lacks a natural outlet, with its water loss occurring solely through evaporation processes. This study employed a comprehensive methodology integrating ground surveys, remote sensing analyses, and meticulous documentation of historical landslides within the basin as primary information sources. Through this investigative approach, we preciselyidentified and geolocated a total of 512 historical landslide occurrences across the Urmia Lake drainage basin, leveraging GPS technology for precision. Thisarticle introduces a suite of hybrid machine learning predictive models, such as support-vector machine (SVM), random forest (RF), decision trees (DT), logistic regression (LR), fuzzy logic (FL), and the technique for order of preference by similarity to the ideal solution (TOPSIS). These models were strategically deployed to assess landslide susceptibility within the region. The outcomes of the landslide susceptibility assessment reveal that the main high susceptible zones for landslide occurrence are concentrated in the northwestern, northern, northeastern, and some southern and southeastern areas of the region. Moreover, when considering the implementation of predictions using different algorithms, it became evident that SVM exhibited superior performance regardingboth accuracy (0.89) and precision (0.89), followed by RF, with and accuracy of 0.83 and a precision of 0.83. However, it is noteworthy that TOPSIS yielded the lowest accuracy value among the algorithms assessed.","['support-vector machine (SVM)', 'random forest (RF)', 'decision trees (DT)', 'logistic regression (LR)']","The hydrological system of the Lake Urmia basin is complex, relying on inflows from 13 perennial rivers, numerous small springs, and direct precipitation, with approximately half of the inflow coming from the Zarrineh and Simineh Rivers. Lake Urmia lacks a natural outlet, and its water loss occurs solely through evaporation, making the basin's environmental dynamics particularly sensitive. Understanding the spatial distribution and susceptibility to landslides within this basin is crucial due to the potential impacts on the hydrological system and surrounding ecosystems. The study aims to identify and precisely locate historical landslide occurrences across the Urmia Lake drainage basin to assess landslide susceptibility in the region. By documenting 512 historical landslides and analyzing their spatial patterns, the research seeks to determine the main zones prone to landslide occurrence, thereby contributing to better management and mitigation strategies for the basin’s environmental stability."
Biology,Comparison of Random Forest and XGBoost Classifiers Using Integrated Optical and SAR Features for Mapping Urban Impervious Surface,"The integration of optical and SAR datasets through ensemble machine learning models shows promising results in urban remote sensing applications. The integration of multi-sensor datasets enhances the accuracy of information extraction. This research presents a comparison of two ensemble machine learning classifiers (random forest and extreme gradient boost (XGBoost)) classifiers using an integration of optical and SAR features and simple layer stacking (SLS) techniques. Therefore, Sentinel-1 (SAR) and Landsat 8 (optical) datasets were used with SAR textures and enhanced modified indices to extract features for the year 2023. The classification process utilized two machine learning algorithms, random forest and XGBoost, for urban impervious surface extraction. The study focused on three significant East Asian cities with diverse urban dynamics: Jakarta, Manila, and Seoul. This research proposed a novel index called the Normalized Blue Water Index (NBWI), which distinguishes water from other features and was utilized as an optical feature. Results showed an overall accuracy of 81% for UIS classification using XGBoost and 77% with RF while classifying land use land cover into four major classes (water, vegetation, bare soil, and urban impervious). However, the proposed framework with the XGBoost classifier outperformed the RF algorithm and Dynamic World (DW) data product and comparatively showed higher classification accuracy. Still, all three results show poor separability with bare soil class compared to ground truth data. XGBoost outperformed random forest and Dynamic World in classification accuracy, highlighting its potential use in urban remote sensing applications.","['ensemble machine learning models', 'random forest', 'extreme gradient boost (XGBoost)']","The study addresses the challenge of accurately extracting urban impervious surfaces and distinguishing land cover types in rapidly changing urban environments, particularly in East Asian cities with diverse urban dynamics. Improving the classification of land use and land cover, including water, vegetation, bare soil, and urban impervious surfaces, is essential for effective urban remote sensing applications. The research aims to compare the effectiveness of different approaches for integrating optical and radar satellite data to enhance the accuracy of urban land cover classification. Specifically, the primary objective is to evaluate and compare the performance of classification methods in extracting urban impervious surfaces and other land cover classes in Jakarta, Manila, and Seoul, while introducing a novel index to better distinguish water features from other land cover types."
Biology,Estimating compressive strength of concrete containing rice husk ash using interpretable machine learning-based models,"The construction sector is a major contributor to global greenhouse gas emissions. Using recycled and waste materials in concrete is a practical solution to address environmental challenges. Currently, agricultural waste is widely used as a substitute for cement in the production of eco-friendly concrete. However, traditional methods for assessing the strength of such materials are both expensive and time-consuming. Therefore, this study uses machine learning techniques to develop prediction models for the compressive strength (CS) of rice husk ash (RHA) concrete. The ML techniques used in the present study include random forest (RF), light gradient boosting machine (LightGBM), ridge regression, and extreme gradient boosting (XGBoost). A total of 348 values of CS were collected from the experimental studies, and five characteristics of RHA concrete were taken as input variables. For the performance assessment of the models, multiple statistical metrics were used. During the training phase, the correlation coefficients (R) obtained for ridge regression, RF, XGBoost, and LightGBM were 0.943, 0.981, 0.985, and 0.996, respectively. In the testing set, these values demonstrated even higher performance, with correlation coefficients of 0.971, 0.993, 0.992, and 0.998 for ridge regression, RF, XGBoost, and LightGBM, respectively. The statistical analysis revealed that the LightGBM model outperformed other models, whereas the ridge regression model exhibited comparatively lower accuracy. SHapley Additive exPlanation (SHAP) method was employed for the interpretability of the developed model. The SHAP analysis revealed that water-to-cement is a controlling parameter in estimating the CS of RHA concrete. In conclusion, this study provides valuable guidance for builders and researchers to estimate the CS of RHA concrete. However, it is suggested that more input variables be incorporated and hybrid models utilized to further enhance the reliability and precision of the models.","['random forest (RF)', 'light gradient boosting machine (LightGBM)', 'ridge regression', 'extreme gradient boosting (XGBoost)', 'SHapley Additive exPlanation (SHAP)']","The construction sector significantly contributes to global greenhouse gas emissions, prompting the need for sustainable alternatives in building materials. Using recycled and waste materials, such as agricultural waste, as substitutes for cement in concrete production offers an eco-friendly solution to reduce environmental impact. However, traditional methods for assessing the strength of such materials are costly and time-consuming, creating a barrier to their widespread adoption. This study aims to develop reliable approaches to predict the compressive strength of rice husk ash concrete, an eco-friendly material derived from agricultural waste. The primary objective of the study is to establish accurate prediction models for the compressive strength of rice husk ash concrete based on key material characteristics, thereby providing valuable guidance for builders and researchers in estimating its performance."
Biology,Improving Thyroid Disorder Diagnosis via Ensemble Stacking and Bidirectional Feature Selection,"Thyroid disorders represent a significant global health challenge with hypothyroidism and hyperthyroidism as two common conditions arising from dysfunction in the thyroid gland.Accurate and timely diagnosis of these disorders is crucial for effective treatment and patient care.This research introduces a comprehensive approach to improve the accuracy of thyroid disorder diagnosis through the integration of ensemble stacking and advanced feature selection techniques.Sequential forward feature selection, sequential backward feature elimination, and bidirectional feature elimination are investigated in this study.In ensemble learning, random forest, adaptive boosting, and bagging classifiers are employed.The effectiveness of these techniques is evaluated using two different datasets obtained from the University of California Irvine-Machine Learning Repository, both of which undergo preprocessing steps, including outlier removal, addressing missing data, data cleansing, and feature reduction.Extensive experimentation demonstrates the remarkable success of proposed ensemble stacking and bidirectional feature elimination achieving 100% and 99.86% accuracy in identifying hyperthyroidism and hypothyroidism, respectively.Beyond enhancing detection accuracy, the ensemble stacking model also demonstrated a streamlined computational complexity which is pivotal for practical medical applications.It significantly outperformed existing studies with similar objectives underscoring the viability and effectiveness of the proposed scheme.This research offers an innovative perspective and sets the platform for improved thyroid disorder diagnosis with broader implications for healthcare and patient well-being.","['ensemble stacking', 'sequential forward feature selection', 'sequential backward feature elimination', 'random forest', 'adaptive boosting', 'bagging classifiers']","Thyroid disorders, including hypothyroidism and hyperthyroidism, represent a significant global health challenge due to dysfunction in the thyroid gland. Accurate and timely diagnosis of these conditions is crucial for effective treatment and patient care. The primary aim of this study is to improve the accuracy of thyroid disorder diagnosis by exploring and integrating various feature selection techniques and classification approaches. This research seeks to enhance the identification of hyperthyroidism and hypothyroidism, ultimately contributing to better healthcare outcomes and patient well-being."
Biology,Enhancing crop recommendation systems with explainable artificial intelligence: a study on agricultural decision-making,"Abstract Crop Recommendation Systems are invaluable tools for farmers, assisting them in making informed decisions about crop selection to optimize yields. These systems leverage a wealth of data, including soil characteristics, historical crop performance, and prevailing weather patterns, to provide personalized recommendations. In response to the growing demand for transparency and interpretability in agricultural decision-making, this study introduces XAI-CROP an innovative algorithm that harnesses eXplainable artificial intelligence (XAI) principles. The fundamental objective of XAI-CROP is to empower farmers with comprehensible insights into the recommendation process, surpassing the opaque nature of conventional machine learning models. The study rigorously compares XAI-CROP with prominent machine learning models, including Gradient Boosting (GB), Decision Tree (DT), Random Forest (RF), Gaussian Naïve Bayes (GNB), and Multimodal Naïve Bayes (MNB). Performance evaluation employs three essential metrics: Mean Squared Error (MSE), Mean Absolute Error (MAE), and R-squared (R2). The empirical results unequivocally establish the superior performance of XAI-CROP. It achieves an impressively low MSE of 0.9412, indicating highly accurate crop yield predictions. Moreover, with an MAE of 0.9874, XAI-CROP consistently maintains errors below the critical threshold of 1, reinforcing its reliability. The robust R 2 value of 0.94152 underscores XAI-CROP's ability to explain 94.15% of the data's variability, highlighting its interpretability and explanatory power.","['Gradient Boosting (GB)', 'Decision Tree (DT)', 'Random Forest (RF)', 'Gaussian Naïve Bayes (GNB)']","The study addresses the challenge of assisting farmers in making informed decisions about crop selection to optimize yields by utilizing various factors such as soil characteristics, historical crop performance, and prevailing weather patterns. There is a growing need for transparency and interpretability in agricultural decision-making to help farmers better understand the basis of crop recommendations. The primary objective of the study is to develop a method that provides farmers with comprehensible insights into the crop recommendation process, improving upon the lack of clarity in conventional approaches. This aims to empower farmers with clearer explanations to support their crop selection decisions and ultimately enhance agricultural productivity."
Biology,Assessing water quality of an ecologically critical urban canal incorporating machine learning approaches,"This study assessed water quality (WQ) in Tongi Canal, an ecologically critical and economically important urban canal in Bangladesh. The researchers employed the Root Mean Square Water Quality Index (RMS-WQI) model, utilizing seven WQ indicators, including temperature, dissolve oxygen, electrical conductivity, lead, cadmium, and iron to calculate the water quality index (WQI) score. The results showed that most of the water sampling locations showed poor WQ, with many indicators violating Bangladesh's environmental conservation regulations. This study employed eight machine learning algorithms, where the Gaussian process regression (GPR) model demonstrated superior performance (training RMSE = 1.77, testing RMSE = 0.0006) in predicting WQI scores. To validate the GPR model's performance, several performance measures, including the coefficient of determination (R2), the Nash-Sutcliffe efficiency (NSE), the model efficiency factor (MEF), Z statistics, and Taylor diagram analysis, were employed. The GPR model exhibited higher sensitivity (R2 = 1.0) and efficiency (NSE = 1.0, MEF = 0.0) in predicting WQ. The analysis of model uncertainty (standard uncertainty = 7.08 ± 0.9025; expanded uncertainty = 7.08 ± 1.846) indicates that the RMS-WQI model holds potential for assessing the WQ of inland waterbodies. These findings indicate that the RMS-WQI model could be an effective approach for assessing inland waters across Bangladesh. The study's results showed that most of the WQ indicators did not meet the recommended guidelines, indicating that the water in the Tongi Canal is unsafe and unsuitable for various purposes. The study's implications extend beyond the Tongi Canal and could contribute to WQ management initiatives across Bangladesh.",['Gaussian process regression (GPR)'],"The study addresses the critical issue of water quality in Tongi Canal, an ecologically important and economically significant urban waterbody in Bangladesh. It highlights concerns about the poor condition of the canal’s water, with many indicators exceeding the limits set by environmental conservation regulations, posing risks to its safety and suitability for various uses. The primary aim of the study is to assess the water quality of Tongi Canal by calculating a comprehensive water quality index based on multiple indicators such as temperature, dissolved oxygen, electrical conductivity, and heavy metals like lead, cadmium, and iron. The research seeks to evaluate the current status of the canal’s water quality and provide insights that could support water quality management efforts not only for Tongi Canal but also for inland waterbodies across Bangladesh."
Biology,Compressive strength prediction of sustainable concrete incorporating rice husk ash (RHA) using hybrid machine learning algorithms and parametric analyses,"The construction industry is making efforts to reduce the environmental impact of cement production in concrete by incorporating alternative and supplementary cementitious materials, as well as lowering carbon emissions. One such material that has gained popularity in this context is rice husk ash (RHA) due to its pozzolanic reactions. This study aims to forecast the compressive strength (CS) of RHA-based concrete (RBC) by examining the effects of several factors such as cement, RHA content, curing age, water usage, aggregate amount, and superplasticizer content. To accomplish this, the study collected and analyzed data from literature, resulting in a dataset of 1404 observations. Several machine learning (ML) models, such as light gradient boosting (LGB), extreme gradient boosting (XGB), and random forest (RF), as well as hybrid machine learning (HML) approaches like XGB-LGB and XGB-RF were employed to thoroughly analyze these parameters and assess their impact on strength. The dataset was split into training and testing groups, and statistical analyses were performed to determine the relationships between the input parameters and CS. Moreover, the performance of all the models was evaluated using various statistical evaluation criteria, including mean absolute percentage error (MAPE), coefficient of efficiency (CE), root mean square error (RMSE), and coefficient of determination (R2). The hybrid XGB-LGB model was found to have higher precision (R2 = 0.95, and RMSE = 5.255 MPa) as compared to other models. SHAP (SHapley Additive exPlanations) analysis revealed that cement, RHA, and superplasticizer had a positive effect on strength. Overall, the study's findings suggest that the hybrid XGB-LGB model with the identified input parameters can be used to accurately predict the CS of RBC. The application of such technologies in the construction sector can facilitate the rapid and low-cost identification of material qualities and the impact of input parameters.","['light gradient boosting (LGB)', 'extreme gradient boosting (XGB)', 'random forest (RF)']","The research idea centers on addressing the environmental impact of cement production in concrete by incorporating alternative materials such as rice husk ash (RHA), which is valued for its pozzolanic properties. The study is motivated by the need to understand how various factors, including cement, RHA content, curing age, water usage, aggregate amount, and superplasticizer content, influence the compressive strength of RHA-based concrete (RBC). The primary objective of the study is to examine the effects of these factors on the compressive strength of RBC and to accurately forecast its strength by analyzing a comprehensive dataset compiled from existing literature. This aims to provide insights that can support the development of more sustainable concrete materials with reduced environmental impact."
Biology,"Assessing Chilgoza Pine (Pinus gerardiana) forest fire severity: Remote sensing analysis, correlations, and predictive modeling for enhanced management strategies","Forest fires represent a critical global threat to both humans and ecosystems. This study examines the intensity and impacts of Chilgoza (Pinus gerardiana) Pine Forest fires by using advanced remote sensing techniques comprising Normalized Burn Ratio (NBR) and Difference Normalized Burn Ratio (dNBR) analyses based on Landsat 9 datasets. The study highlights the severe effect of these fires, resulting in noteworthy losses of livestock and private properties and widespread damage to 10,156.53 acres of the Chilgoza Pine Forest. A comprehensive variable correlation analysis is conducted to gain deeper insights into the influencing factors causing forest fires. Spearman's Rank Correlation Coefficient was used to assess the association between burnt and unburnt areas and various independent factors. The analysis reveals compelling evidence of significant correlations with forest fire prevalence. This study found moderate negative (-0.532, p < 0.05) and positive (0.513, p < 0.05) correlations with elevation and Land Surface Temperature (LST), respectively, and a weak positive correlation (0.252, p < 0.05) with a Wind Speed (V). To predict forest fire susceptibility and better understand the contributing factors, three machine learning models, Random Forest (RF), XGBoost, and logistic regression, are applied to assess variable importance scores. Among the considered factors, LST is the most critical variable, with consistently high variable importance scores (100%, 96%, and 59%) across all three models. Wind Speed (V) also proved influential in all models, with variable importance scores of 78%, 83%, and 61% for RF, XGBoost, and logistic regression, respectively. Moreover, elevation significantly influences the frequency of forest fires, as evidenced by variable importance scores ranging from 26% to 100%. Comparatively, the Random Forest model outperforms XGBoost and Logistic Regression in predicting forest fire vulnerability. During the training stage, the Random Forest (RF) model achieves an impressive classification accuracy of 99.1%, followed by XGBoost with 94.5% and Logistic Regression with 85.6%. On evaluation with the validation dataset, the accuracies remain promising, with RF at 96.4%, XGBoost at 91.1%, and Logistic Regression at 84.6%. Based on the Random Forest model, the identified high-risk sites offer valuable insights for proactive fire management and prevention strategies. This study provides a robust predictive model and a comprehensive understanding of forest fire severity and impacts. Future research should consider climate change scenarios and account for human activities to enhance fire behavior predictions and risk assessment models.","['Random Forest (RF)', 'XGBoost', 'logistic regression']","The research idea centers on addressing the critical global threat posed by forest fires to both human communities and ecosystems, with a specific focus on the Chilgoza (Pinus gerardiana) Pine Forest. The study is motivated by the severe effects of these fires, which have caused significant losses of livestock, private properties, and extensive damage to over 10,000 acres of forest. Understanding the factors influencing forest fire occurrence is essential for mitigating these impacts and protecting this valuable forest ecosystem. The primary objective of the study is to examine the intensity and impacts of Chilgoza Pine Forest fires and to investigate the relationships between burnt and unburnt areas and various environmental factors such as elevation, land surface temperature, and wind speed. By identifying the most critical variables associated with forest fire prevalence, the study aims to provide insights that can inform proactive fire management and prevention strategies."
Biology,Cognition-Driven Structural Prior for Instance-Dependent Label Transition Matrix Estimation,"The label transition matrix has emerged as a widely accepted method for mitigating label noise in machine learning. In recent years, numerous studies have centered on leveraging deep neural networks to estimate the label transition matrix for individual instances within the context of instance-dependent noise. However, these methods suffer from low search efficiency due to the large space of feasible solutions. Behind this drawback, we have explored that the real murderer lies in the invalid class transitions, that is, the actual transition probability between certain classes is zero but is estimated to have a certain value. To mask the <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">invalid class transitions</i> , we introduced a human-cognition-assisted method with structural information from human cognition. Specifically, we introduce a structured transition matrix network ( <bold xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">STMN</b> ) designed with an adversarial learning process to balance instance features and prior information from human cognition. The proposed method offers two advantages: 1) better estimation effectiveness is obtained by sparing the transition matrix and 2) better estimation accuracy is obtained with the assistance of human cognition. By exploiting these two advantages, our method parametrically estimates a sparse label transition matrix, effectively converting noisy labels into true labels. The efficiency and superiority of our proposed method are substantiated through comprehensive comparisons with state-of-the-art methods on three synthetic datasets and a real-world dataset. Our code will be available at https://github.com/WheatCao/STMN-Pytorch.","['deep neural networks', 'adversarial learning process']","The research idea addresses the challenge of accurately estimating the transition probabilities between classes in the presence of label noise, particularly focusing on the issue of invalid class transitions where the actual transition probability is zero but is incorrectly estimated as nonzero. This problem affects the effectiveness of correcting noisy labels in biological data classification and hampers the ability to recover true labels from noisy observations. The study aims to improve the accuracy of label correction by incorporating structural information derived from human cognition to better identify and mask these invalid transitions. The primary objective of the study is to develop a method that leverages human cognitive insights to produce a sparse and more accurate label transition matrix, thereby enhancing the conversion of noisy labels into true labels and improving the reliability of biological data interpretation."
Biology,Data-driven evolution of water quality models: An in-depth investigation of innovative outlier detection approaches-A case study of Irish Water Quality Index (IEWQI) model,"Recently, there has been a significant advancement in the water quality index (WQI) models utilizing data-driven approaches, especially those integrating machine learning and artificial intelligence (ML/AI) technology. Although, several recent studies have revealed that the data-driven model has produced inconsistent results due to the data outliers, which significantly impact model reliability and accuracy. The present study was carried out to assess the impact of data outliers on a recently developed Irish Water Quality Index (IEWQI) model, which relies on data-driven techniques. To the author's best knowledge, there has been no systematic framework for evaluating the influence of data outliers on such models. For the purposes of assessing the outlier impact of the data outliers on the water quality (WQ) model, this was the first initiative in research to introduce a comprehensive approach that combines machine learning with advanced statistical techniques. The proposed framework was implemented in Cork Harbour, Ireland, to evaluate the IEWQI model's sensitivity to outliers in input indicators to assess the water quality. In order to detect the data outlier, the study utilized two widely used ML techniques, including Isolation Forest (IF) and Kernel Density Estimation (KDE) within the dataset, for predicting WQ with and without these outliers. For validating the ML results, the study used five commonly used statistical measures. The performance metric (R2) indicates that the model performance improved slightly (R2 increased from 0.92 to 0.95) in predicting WQ after removing the data outlier from the input. But the IEWQI scores revealed that there were no statistically significant differences among the actual values, predictions with outliers, and predictions without outliers, with a 95% confidence interval at p < 0.05. The results of model uncertainty also revealed that the model contributed <1% uncertainty to the final assessment results for using both datasets (with and without outliers). In addition, all statistical measures indicated that the ML techniques provided reliable results that can be utilized for detecting outliers and their impacts on the IEWQI model. The findings of the research reveal that although the data outliers had no significant impact on the IEWQI model architecture, they had moderate impacts on the rating schemes' of the model. This finding indicated that detecting the data outliers could improve the accuracy of the IEWQI model in rating WQ as well as be helpful in mitigating the model eclipsing problem. In addition, the results of the research provide evidence of how the data outliers influenced the data-driven model in predicting WQ and reliability, particularly since the study confirmed that the IEWQI model's could be effective for accurately rating WQ despite the presence of the data outliers in the input. It could occur due to the spatio-temporal variability inherent in WQ indicators. However, the research assesses the influence of data input outliers on the IEWQI model and underscores important areas for future investigation. These areas include expanding temporal analysis using multi-year data, examining spatial outlier patterns, and evaluating detection methods. Moreover, it is essential to explore the real-world impacts of revised rating categories, involve stakeholders in outlier management, and fine-tune model parameters. Analysing model performance across varying temporal and spatial resolutions and incorporating additional environmental data can significantly enhance the accuracy of WQ assessment. Consequently, this study offers valuable insights to strengthen the IEWQI model's robustness and provides avenues for enhancing its utility in broader WQ assessment applications. Moreover, the study successfully adopted the framework for evaluating how data input outliers affect the data-driven model, such as the IEWQI model. The current study has been carried out in Cork Harbour for only a single year of WQ data. The framework should be tested across various domains for evaluating the response of the IEWQI model's in terms of the spatio-temporal resolution of the domain. Nevertheless, the study recommended that future research should be conducted to adjust or revise the IEWQI model's rating schemes and investigate the practical effects of data outliers on updated rating categories. However, the study provides potential recommendations for enhancing the IEWQI model's adaptability and reveals its effectiveness in expanding its applicability in more general WQ assessment scenarios.",['Isolation Forest (IF)'],"The study addresses the challenge of assessing water quality accurately in the presence of data outliers, which can affect the reliability and accuracy of water quality index models. Specifically, it focuses on understanding how these outliers influence the recently developed Irish Water Quality Index (IEWQI) model, given that no systematic framework has previously been established to evaluate their impact. The research aims to assess the effect of data outliers on the IEWQI model’s performance in rating water quality, particularly by evaluating the model’s sensitivity to outliers in input indicators. The primary objective is to determine whether the presence of data outliers significantly affects the accuracy and reliability of the IEWQI model in predicting water quality and to provide insights for improving the model’s rating schemes and overall robustness in water quality assessment."
Biology,Real-Time Plant Disease Dataset Development and Detection of Plant Disease Using Deep Learning,"Agriculture plays a significant role in meeting food needs and providing food security for the increasingly growing global population, which has increased by 0.88% since 2022. Plant diseases can reduce food production and affect food security. Worldwide crop loss due to plant disease is estimated to be around 14.1%. The lack of proper identification of plant disease at the early stages of infection can result in inappropriate disease control measures. Therefore, the automatic identification and diagnosis of plant diseases are highly recommended. Lack of availability of large amounts of data that are not processed to a large extent is one of the main challenges in plant disease diagnosis. In the current manuscript, we developed datasets for food grains specifically for rice, wheat, and maize to address the identified challenges. The developed datasets consider the common diseases (two bacterial diseases and two fungal diseases of rice, four fungal diseases of maize, and four fungal diseases of wheat) that affect crop yields and cause damage to the whole plant. The datasets developed were applied to eight fine-tuned deep learning models with the same training hyperparameters. The experimental results based on eight fine-tuned deep learning models show that, while recognizing maize leaf diseases, the models Xception and MobileNet performed best with a testing accuracy of 0.9580 and 0.9464 respectively. Similarly, while recognizing the wheat leaf diseases, the models MobileNetV2 and MobileNet performed best with a testing accuracy of 0.9632 and 0.9628 respectively. The Xception and Inception V3 models performed best, with a testing accuracy of 0.9728 and 0.9620, respectively, for recognizing rice leaf diseases. The research also proposes a new convolutional neural network (CNN) model trained from scratch on all three food grain datasets developed. The proposed model performs well and shows a testing accuracy of 0.9704, 0.9706, and 0.9808 respectively on the maize, rice, and wheat datasets.","['fine-tuned deep learning models', 'Xception', 'MobileNet', 'MobileNetV2', 'Inception V3', 'convolutional neural network (CNN) model trained from scratch']","The study addresses the critical issue of plant diseases reducing food production and threatening food security for the growing global population. Early and accurate identification of plant diseases is essential to implement appropriate disease control measures and minimize crop loss, which is estimated to be around 14.1% worldwide. The lack of properly processed and extensive data on plant diseases poses a significant challenge in effective disease diagnosis. The primary aim of the study is to develop comprehensive datasets for major food grains—rice, wheat, and maize—focusing on common bacterial and fungal diseases that affect crop yields and cause extensive damage. These datasets are intended to improve the identification and diagnosis of plant diseases at early stages to support better disease management and enhance food security."
Biology,Vision–language foundation model for echocardiogram interpretation,"Abstract The development of robust artificial intelligence models for echocardiography has been limited by the availability of annotated clinical data. Here, to address this challenge and improve the performance of cardiac imaging models, we developed EchoCLIP, a vision–language foundation model for echocardiography, that learns the relationship between cardiac ultrasound images and the interpretations of expert cardiologists across a wide range of patients and indications for imaging. After training on 1,032,975 cardiac ultrasound videos and corresponding expert text, EchoCLIP performs well on a diverse range of benchmarks for cardiac image interpretation, despite not having been explicitly trained for individual interpretation tasks. EchoCLIP can assess cardiac function (mean absolute error of 7.1% when predicting left ventricular ejection fraction in an external validation dataset) and identify implanted intracardiac devices (area under the curve (AUC) of 0.84, 0.92 and 0.97 for pacemakers, percutaneous mitral valve repair and artificial aortic valves, respectively). We also developed a long-context variant (EchoCLIP-R) using a custom tokenizer based on common echocardiography concepts. EchoCLIP-R accurately identified unique patients across multiple videos (AUC of 0.86), identified clinical transitions such as heart transplants (AUC of 0.79) and cardiac surgery (AUC 0.77) and enabled robust image-to-text search (mean cross-modal retrieval rank in the top 1% of candidate text reports). These capabilities represent a substantial step toward understanding and applying foundation models in cardiovascular imaging for preliminary interpretation of echocardiographic findings.",['vision–language foundation model'],"The research addresses the challenge of limited availability of annotated clinical data for echocardiography, which has hindered the development of robust methods for cardiac imaging interpretation. There is a need to improve the understanding and assessment of cardiac ultrasound images in relation to expert cardiologists' interpretations across diverse patient populations and imaging indications. The primary objective of the study is to develop a comprehensive approach that learns the relationship between cardiac ultrasound images and expert clinical interpretations to enhance the accuracy and scope of echocardiographic assessment. This includes the ability to evaluate cardiac function, identify implanted intracardiac devices, and recognize significant clinical transitions such as heart transplants and cardiac surgeries."
Biology,Machine learning-assisted in-situ adaptive strategies for the control of defects and anomalies in metal additive manufacturing,"In metal additive manufacturing (AM), the material microstructure and part geometry are formed incrementally. Consequently, the resulting part could be defect- and anomaly-free if sufficient care is taken to deposit each layer under optimal process conditions. Conventional closed-loop control (CLC) engineering solutions which sought to achieve this were deterministic and rule-based, thus resulting in limited success in the stochastic environment experienced in the highly dynamic AM process. On the other hand, emerging machine learning (ML) based strategies are better suited to providing the robustness, scope, flexibility, and scalability required for process control in an uncertain environment. Offline ML models that help optimise AM process parameters before a build begins and online ML models that efficiently processed in-situ sensory data to detect and diagnose flaws in real-time (or near-real-time) have been developed. However, ML models that enable a process to take evasive or corrective actions in relation to flaws via on the fly decision-making are only emerging. These models must possess prognostic capabilities to provide context-sensitive recommendations for in-situ process control based on real-time diagnostics. In this article, we pinpoint the shortcomings in traditional CLC strategies, and provide a framework for defect and anomaly control through ML-assisted CLC in AM. We discuss flaws in terms of their causes, in-situ detectability, and controllability, and examine their management under three scenarios: avoidance, mitigation, and repair. Then, we summarise the research into ML models developed for offline optimisation and in-situ diagnosis before initiating a detailed conversation on the implementation of ML-assisted in-situ process control. We found that researchers favoured reinforcement learning approaches or inverse ML models for making rapid, situation-aware control decisions. We also observed that, to-date, the defects addressed were those that may be quantified relatively easily autonomously, and that mitigation (rather than avoidance or repair) was the aim of ML-assisted in-situ control strategies. Additionally, we highlight the various technologies that must seamlessly combine to advance the field of autonomous in-situ control so that it becomes a reality in industrial settings. Finally, we raise awareness of seldom discussed, yet highly pertinent, topics relevant to adaptive control. Our work closes a significant gap in the current AM literature by broaching wide-ranging discussions on matters relevant to in-situ adaptive control in AM.","['online ML models', 'reinforcement learning approaches']","The research idea centers on the challenge of producing defect- and anomaly-free parts in metal additive manufacturing, where material microstructure and part geometry are formed incrementally under highly dynamic and stochastic conditions. Traditional control methods have shown limited success in managing these complexities, highlighting the need for more robust and flexible approaches to ensure optimal process conditions during layer deposition. The study addresses the shortcomings of existing strategies in controlling defects and anomalies in real-time during the manufacturing process. The primary objective of the study is to provide a comprehensive framework for defect and anomaly control in metal additive manufacturing by examining flaws in terms of their causes, detectability, and controllability, and exploring their management through avoidance, mitigation, and repair. The study aims to advance the understanding and implementation of adaptive in-situ process control to improve the quality and reliability of manufactured parts, thereby closing a significant gap in the current literature on in-situ adaptive control in additive manufacturing."
Biology,Performance assessment of machine learning algorithms for mapping of land use/land cover using remote sensing data,"The rapid increase in population accelerates the rate of change of Land use/Land cover (LULC) in various parts of the world. This phenomenon caused a huge strain for natural resources. Hence, continues monitoring of LULC changes gained a significant importance for management of natural resources and assessing the climate change impacts. Recently, application of machine learning algorithms on RS (remote sensing) data for rapid and accurate mapping of LULC gained significant importance due to growing need of LULC estimation for ecosystem services, natural resource management and environmental management. Hence, it is crucial to access and compare the performance of different machine learning classifiers for accurate mapping of LULC. The primary objective of this study was to compare the performance of CART (Classification and Regression Tree), RF (Random Forest) and SVM (Support Vector Machine) for LULC estimation by processing RS data on Google Earth Engine (GEE). In total four classes of LULC (Water Bodies, Vegetation Cover, Urban Land and Barren Land) for city of Lahore were extracted using satellite images from Landsat-7, Landsat-8 and Landsat-9 for years 2008, 2015 and 2022, respectively. According to results, RF is the best performing classifier with maximum overall accuracy of 95.2% and highest Kappa coefficient value of 0.87, SVM achieved maximum accuracy of 89.8% with highest Kappa of 0.84 and CART showed maximum overall accuracy of 89.7% with Kappa value of 0.79. Results from this study can give assistance for decision makers, planners and RS experts to choose a suitable machine learning algorithm for LULC classification in an unplanned urbanized city like Lahore.","['Classification and Regression Tree (CART)', 'Random Forest (RF)', 'Support Vector Machine (SVM)']","The rapid increase in population accelerates the rate of change of Land use/Land cover (LULC) in various parts of the world, causing significant strain on natural resources. Continuous monitoring of LULC changes has become critically important for the management of natural resources and for assessing the impacts of climate change. The primary objective of this study was to compare the performance of different approaches for accurate mapping of LULC by processing satellite imagery data. Specifically, the study aimed to evaluate and compare the effectiveness of various classification methods in estimating four classes of LULC—Water Bodies, Vegetation Cover, Urban Land, and Barren Land—in the city of Lahore using satellite images from different years."
Biology,Groundwater Quality Assessment and Irrigation Water Quality Index Prediction Using Machine Learning Algorithms,"The evaluation of groundwater quality is crucial for irrigation purposes; however, due to financial constraints in developing countries, such evaluations suffer from insufficient sampling frequency, hindering comprehensive assessments. Therefore, associated with machine learning approaches and the irrigation water quality index (IWQI), this research aims to evaluate the groundwater quality in Naama, a region in southwest Algeria. Hydrochemical parameters (cations, anions, pH, and EC), qualitative indices (SAR,RSC,Na%,MH,and PI), as well as geospatial representations were used to determine the groundwater’s suitability for irrigation in the study area. In addition, efficient machine learning approaches for forecasting IWQI utilizing Extreme Gradient Boosting (XGBoost), Support vector regression (SVR), and K-Nearest Neighbours (KNN) models were implemented. In this research, 166 groundwater samples were used to calculate the irrigation index. The results showed that 42.18% of them were of excellent quality, 34.34% were of very good quality, 6.63% were good quality, 9.64% were satisfactory, and 4.21% were considered unsuitable for irrigation. On the other hand, results indicate that XGBoost excels in accuracy and stability, with a low RMSE (of 2.8272 and a high R of 0.9834. SVR with only four inputs (Ca2+, Mg2+, Na+, and K) demonstrates a notable predictive capability with a low RMSE of 2.6925 and a high R of 0.98738, while KNN showcases robust performance. The distinctions between these models have important implications for making informed decisions in agricultural water management and resource allocation within the region.","['Extreme Gradient Boosting (XGBoost)', 'Support vector regression (SVR)', 'K-Nearest Neighbours (KNN)']","The evaluation of groundwater quality is crucial for irrigation purposes, especially in developing countries where financial constraints limit sampling frequency and hinder comprehensive assessments. This study addresses the need for a thorough assessment of groundwater suitability for irrigation in the Naama region of southwest Algeria by examining various hydrochemical parameters and qualitative indices. The primary aim of the research is to evaluate the groundwater quality in the study area using these parameters and indices to determine its suitability for irrigation. The study also seeks to provide insights that can inform agricultural water management and resource allocation decisions within the region."
Biology,CCL-DTI: contributing the contrastive loss in drug–target interaction prediction,"Abstract Background The Drug–Target Interaction (DTI) prediction uses a drug molecule and a protein sequence as inputs to predict the binding affinity value. In recent years, deep learning-based models have gotten more attention. These methods have two modules: the feature extraction module and the task prediction module. In most deep learning-based approaches, a simple task prediction loss (i.e., categorical cross entropy for the classification task and mean squared error for the regression task) is used to learn the model. In machine learning, contrastive-based loss functions are developed to learn more discriminative feature space. In a deep learning-based model, extracting more discriminative feature space leads to performance improvement for the task prediction module. Results In this paper, we have used multimodal knowledge as input and proposed an attention-based fusion technique to combine this knowledge. Also, we investigate how utilizing contrastive loss function along the task prediction loss could help the approach to learn a more powerful model. Four contrastive loss functions are considered: (1) max-margin contrastive loss function, (2) triplet loss function, (3) Multi-class N-pair Loss Objective, and (4) NT-Xent loss function. The proposed model is evaluated using four well-known datasets: Wang et al. dataset, Luo's dataset, Davis, and KIBA datasets. Conclusions Accordingly, after reviewing the state-of-the-art methods, we developed a multimodal feature extraction network by combining protein sequences and drug molecules, along with protein–protein interaction networks and drug–drug interaction networks. The results show it performs significantly better than the comparable state-of-the-art approaches.","['contrastive loss function', 'max-margin contrastive loss function', 'triplet loss function', 'Multi-class N-pair Loss Objective', 'NT-Xent loss function']","The research idea centers on improving the prediction of drug–target interactions by enhancing the representation of drug molecules and protein sequences to better understand their binding affinity. Current approaches often rely on simple loss functions that may limit the ability to learn discriminative features necessary for accurate prediction. By addressing the challenge of extracting more informative and distinct biological features, the study aims to advance the understanding of how drugs interact with their protein targets. The primary objective of the study is to develop a method that integrates multiple biological data sources, including protein sequences, drug molecules, protein–protein interaction networks, and drug–drug interaction networks, to improve the prediction of drug–target binding affinity. The study specifically aims to investigate how combining these diverse biological inputs can enhance the learning of more powerful representations that lead to better predictive performance compared to existing approaches."
Biology,Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning,"Recent development in computing power has resulted in performance improvements on holistic(none-occluded) person Re-Identification (ReID) tasks. Nevertheless, the precision of the recent research will diminish when a pedestrian is obstructed by obstacles. Within the realm of 2D space, the loss of information from obstructed objects continues to pose significant challenges in the context of person ReID. Person is a 3D non-grid object, and thus semantic representation learning in only 2D space limits the understanding of occluded person. In the present work, we propose a network based on 3D multi-view learning, allowing it to acquire geometric and shape details of an occluded pedestrian from 3D space. Simultaneously, it capitalizes on advancements in 2D-based networks to extract semantic representations from 3D multi-views. Specifically, the surface random selection strategy is proposed to convert images of 2D RGB into 3D multi-views. Using this strategy, we build four extensive 3D multi-view data collections for person ReID. After that, Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning(MV-3DSReID), is proposed for identifying the person by learning person geometry and structure representation from the groups of multi-view images. In comparison to alternative data formats (e.g., 2D RGB, 3D point cloud), multi-view images complement each other's detailed features of the 3D object by adjusting rendering viewpoints, thus facilitating a more comprehensive understanding of the person for both holistic and occluded ReID situations. Experiments on occluded and holistic ReID tasks demonstrate performance levels comparable to state-of-the-art methods, validating the effectiveness of our proposed approach in tackling challenges related to occlusion. The code is available at https://github.com/hangjiaqi1/MV-TransReID.",['3D multi-view learning'],"The research idea addresses the challenge of accurately identifying pedestrians when they are partially obstructed by obstacles, which leads to loss of information in traditional 2D representations. Since a person is a three-dimensional object, relying solely on 2D semantic representations limits the understanding of occluded individuals. This study focuses on overcoming the difficulties posed by occlusion in person identification by enhancing the representation of pedestrian geometry and structure.

The primary objective of the study is to improve person re-identification by learning geometric and shape details of occluded pedestrians through multi-view 3D representations. The research aims to capture comprehensive features of individuals by integrating information from multiple viewpoints, thereby facilitating better identification in both occluded and unobstructed scenarios."
Biology,A Critical Review of Artificial Intelligence Based Approaches in Intrusion Detection: A Comprehensive Analysis,"Intrusion detection (ID) is critical in securing computer networks against various malicious attacks. Recent advancements in machine learning (ML), deep learning (DL), federated learning (FL), and explainable artificial intelligence (XAI) have drawn significant attention as potential approaches for ID. DL-based approaches have shown impressive performance in ID by automatically learning relevant features from data but require significant labelled data and computational resources to train complex models. ML-based approaches require fewer computational resources and labelled data, but their ability to generalize to unseen data is limited. FL is a relatively new approach that enables multiple entities to train a model collectively without exchanging their data, providing privacy and security benefits, making it an attractive option for ID. However, FL-based approaches require more communication resources and additional computation to aggregate models from different entities. XAI is critical for understanding how AI models make decisions, improving interpretability and transparency. While existing literature has explored the strengths and weaknesses of DL, ML, FL, and XAI-based approaches for ID, a significant gap exists in providing a comprehensive analysis of the specific use cases and scenarios where each approach is most suitable. This paper seeks to fill this void by delivering an in-depth review that not only highlights strengths and weaknesses but also offers guidance for selecting the appropriate approach based on the unique ID context and available resources. The selection of an appropriate approach depends on the specific use case, and this work provides insights into which method is best suited for various network sizes, data availability, privacy, and security concerns, thus aiding practitioners in making informed decisions for their ID needs.","['machine learning (ML)', 'deep learning (DL)', 'federated learning (FL)']","The study addresses the critical need for effective intrusion detection to secure computer networks against various malicious attacks. It highlights the challenges associated with existing approaches, such as the requirement for significant labeled data, computational resources, and the ability to generalize to unseen data, as well as concerns related to privacy, security, and communication resources. The research aims to provide a comprehensive analysis of different intrusion detection approaches by examining their strengths and weaknesses in specific use cases and scenarios. The primary objective is to offer guidance for selecting the most appropriate intrusion detection method based on factors such as network size, data availability, privacy, and security concerns, thereby assisting practitioners in making informed decisions tailored to their unique contexts."
Biology,"admetSAR3.0: a comprehensive platform for exploration, prediction and optimization of chemical ADMET properties","Abstract Absorption, distribution, metabolism, excretion and toxicity (ADMET) properties play a crucial role in drug discovery and chemical safety assessment. Built on the achievements of admetSAR and its successor, admetSAR2.0, this paper introduced the new version of the series, admetSAR3.0, as a comprehensive platform for chemical ADMET assessment, including search, prediction and optimization modules. In the search module, admetSAR3.0 hosted over 370 000 high-quality experimental ADMET data for 104 652 unique compounds, and supplemented chemical structure similarity search function to facilitate read-across. In the prediction module, we introduced comprehensive ADMET endpoints and two new sections for environmental and cosmetic risk assessments, empowering admetSAR3.0 to provide prediction for 119 endpoints, more than double numbers compared to the previous version. Furthermore, the advanced multi-task graph neural network framework offered robust and reliable support for ADMET prediction. In particular, a module named ADMETopt was added to automatically optimize the ADMET properties of query molecules through transformation rules or scaffold hopping. Finally, admetSAR3.0 provides user-friendly interfaces for multiple types of input data, such as SMILES string, chemical structure and batch molecule file, and supports various output types, including digital, chart displays and file downloads. In summary, admetSAR3.0 is anticipated to be a valuable and powerful tool in drug discovery and chemical safety assessment at http://lmmd.ecust.edu.cn/admetsar3/.",['multi-task graph neural network framework'],"The research idea centers on the critical importance of absorption, distribution, metabolism, excretion, and toxicity (ADMET) properties in drug discovery and chemical safety assessment. Understanding and accurately assessing these properties is essential for evaluating the safety and efficacy of chemical compounds. The study aims to enhance the capability to assess chemical ADMET properties comprehensively, addressing the need for reliable and extensive experimental data to support these evaluations. The primary objective of the study is to present an updated and comprehensive platform that integrates a vast collection of high-quality experimental ADMET data for numerous unique compounds and expands the scope of ADMET endpoints, including environmental and cosmetic risk assessments. This platform is designed to facilitate the search, prediction, and optimization of ADMET properties, thereby supporting more effective drug discovery and chemical safety evaluations."
Biology,Monthly climate prediction using deep convolutional neural network and long short-term memory,"Climate change affects plant growth, food production, ecosystems, sustainable socio-economic development, and human health. The different artificial intelligence models are proposed to simulate climate parameters of Jinan city in China, include artificial neural network (ANN), recurrent NN (RNN), long short-term memory neural network (LSTM), deep convolutional NN (CNN), and CNN-LSTM. These models are used to forecast six climatic factors on a monthly ahead. The climate data for 72 years (1 January 1951–31 December 2022) used in this study include monthly average atmospheric temperature, extreme minimum atmospheric temperature, extreme maximum atmospheric temperature, precipitation, average relative humidity, and sunlight hours. The time series of 12 month delayed data are used as input signals to the models. The efficiency of the proposed models are examined utilizing diverse evaluation criteria namely mean absolute error, root mean square error (RMSE), and correlation coefficient (R). The modeling result inherits that the proposed hybrid CNN-LSTM model achieves a greater accuracy than other compared models. The hybrid CNN-LSTM model significantly reduces the forecasting error compared to the models for the one month time step ahead. For instance, the RMSE values of the ANN, RNN, LSTM, CNN, and CNN-LSTM models for monthly average atmospheric temperature in the forecasting stage are 2.0669, 1.4416, 1.3482, 0.8015 and 0.6292 °C, respectively. The findings of climate simulations shows the potential of CNN-LSTM models to improve climate forecasting. Climate prediction will contribute to meteorological disaster prevention and reduction, as well as flood control and drought resistance.","['artificial neural network (ANN)', 'recurrent NN (RNN)', 'long short-term memory neural network (LSTM)', 'deep convolutional NN (CNN)', 'CNN-LSTM']","The research idea centers on the significant impact of climate change on plant growth, food production, ecosystems, sustainable socio-economic development, and human health. Understanding and accurately forecasting climatic factors is crucial for addressing these challenges and mitigating adverse effects. The study aims to improve the prediction of key climate parameters to support better preparedness and response to climate-related issues. The primary objective of the study is to forecast six climatic factors, including atmospheric temperature, precipitation, relative humidity, and sunlight hours, on a monthly basis for Jinan city in China using historical climate data spanning 72 years. This forecasting aims to enhance climate prediction accuracy, which can contribute to meteorological disaster prevention, flood control, and drought resistance."
Biology,Improving Forest Above-Ground Biomass Estimation by Integrating Individual Machine Learning Models,"The accurate estimation of forest above-ground biomass (AGB) is crucial for sustainable forest management and tracking the carbon cycle of forest ecosystem. Machine learning algorithms have been proven to have great potential in forest AGB estimation with remote sensing data. Though many studies have demonstrated that a single machine learning model can produce highly accurate estimations of forest AGB in many situations, efforts are still required to explore the possible improvement in forest AGB estimation for a specific scenario under study. This study aims to investigate the performance of novel ensemble machine learning methods for forest AGB estimation and analyzes whether these methods are affected by forest types, independent variables, and spatial autocorrelation. Four well-known machine learning models (CatBoost, LightGBM, random forest (RF), and XGBoost) were compared for forest AGB estimation in the study using eight scenarios devised on the basis of two study regions, two variable types, and two validation strategies. Subsequently, a hybrid model combining the strengths of these individual models was proposed for forest AGB estimation. The findings indicated that no individual model outperforms the others in all scenarios. The RF model demonstrates superior performance in scenarios 5, 6, and 7, while the CatBoost model shows the best performance in the remaining scenarios. Moreover, the proposed hybrid model consistently has the best performance in all scenarios in spite of some uncertainties. The ensemble strategy developed in this study for the hybrid model substantially improves estimation accuracy and exhibits greater stability, effectively addressing the challenge of model selection encountered in the forest AGB forecasting process.","['CatBoost', 'LightGBM', 'random forest (RF)', 'XGBoost', 'ensemble machine learning methods']","The accurate estimation of forest above-ground biomass (AGB) is crucial for sustainable forest management and tracking the carbon cycle of forest ecosystems. Although previous studies have shown that individual approaches can produce highly accurate estimations of forest AGB, there remains a need to explore potential improvements in estimation accuracy for specific scenarios. This study aims to investigate the performance of different methods for estimating forest AGB and to analyze how factors such as forest types, variable selection, and spatial autocorrelation influence these estimations. The primary objective is to evaluate and compare multiple approaches for forest AGB estimation across various scenarios and to develop a combined strategy that enhances estimation accuracy and stability, thereby addressing challenges in selecting the most effective method for forest biomass assessment."
Biology,GAN based augmentation using a hybrid loss function for dermoscopy images,"Dermatology is the most appropriate field to utilize pattern recognition-based automated techniques for objective, accurate, and rapid diagnosis because diagnosis mainly relies on visual examinations of skin lesions. Recent approaches utilizing deep learning techniques have shown remarkable results in this field. However, they necessitate a substantial quantity of images and the availability of dermoscopy images is often limited. Also, even if enough images are available, their labeling requires expert knowledge and is time-consuming. To overcome these issues, an efficient augmentation approach is needed to expand training datasets from input images. Therefore, in this work, a generative adversarial network has been developed using a new hybrid loss function constructed with traditional loss functions to enhance the generation power of the architecture. Also, the effect of the proposed approach and different generative network-based augmentations, which have been used with dermoscopy images in the literature, on the classification of skin lesions has been investigated. Therefore, the main contributions of this work are: (i) introducing a new generative model for the augmentation of dermoscopy images; (ii) presenting the effect of the proposed model on the classification of the images; (iii) comparative evaluations of the effectiveness of different generative network-based augmentations in the classification of seven forms of skin lesions. The classification accuracy when the proposed augmentation is used is 93.12%, which is higher than its counterparts. Experimental results indicate the significance of augmentation techniques in the classification of skin lesions and the efficiency of the proposed structure in improving the classification accuracy.",['generative adversarial network'],"The research idea centers on the challenge of diagnosing skin lesions in dermatology, which primarily depends on visual examination but is limited by the availability and labeling of dermoscopy images. Since obtaining a large number of expert-labeled images is difficult and time-consuming, there is a need for methods to effectively expand the dataset of skin lesion images to improve diagnostic accuracy. The study’s primary objective is to develop and evaluate a new approach for augmenting dermoscopy images to enhance the classification of different types of skin lesions. Specifically, the research aims to introduce a novel generative model for image augmentation, assess its impact on the classification accuracy of skin lesions, and compare its effectiveness with other augmentation methods across seven forms of skin lesions."
Biology,"Machine Learning and Deep Learning in Synthetic Biology: Key Architectures, Applications, and Challenges","Machine learning (ML), particularly deep learning (DL), has made rapid and substantial progress in synthetic biology in recent years. Biotechnological applications of biosystems, including pathways, enzymes, and whole cells, are being probed frequently with time. The intricacy and interconnectedness of biosystems make it challenging to design them with the desired properties. ML and DL have a synergy with synthetic biology. Synthetic biology can be employed to produce large data sets for training models (for instance, by utilizing DNA synthesis), and ML/DL models can be employed to inform design (for example, by generating new parts or advising unrivaled experiments to perform). This potential has recently been brought to light by research at the intersection of engineering biology and ML/DL through achievements like the design of novel biological components, best experimental design, automated analysis of microscopy data, protein structure prediction, and biomolecular implementations of ANNs (Artificial Neural Networks). I have divided this review into three sections. In the first section, I describe predictive potential and basics of ML along with myriad applications in synthetic biology, especially in engineering cells, activity of proteins, and metabolic pathways. In the second section, I describe fundamental DL architectures and their applications in synthetic biology. Finally, I describe different challenges causing hurdles in the progress of ML/DL and synthetic biology along with their solutions.","['machine learning (ML)', 'deep learning (DL)', 'Artificial Neural Networks (ANNs)']","The study addresses the complexity and interconnectedness of biosystems, which pose significant challenges in designing biological components, pathways, enzymes, and whole cells with desired properties. There is a growing need to improve the understanding and engineering of these biosystems to enhance biotechnological applications. The primary aim of the study is to review the recent advancements and applications in synthetic biology, particularly focusing on the engineering of cells, protein activity, and metabolic pathways. Additionally, the study seeks to discuss the challenges encountered in the progress of synthetic biology and explore potential solutions to overcome these hurdles."
Biology,A machine learning approach to predict the efficiency of corrosion inhibition by natural product-based organic inhibitors,"Abstract This paper presents a quantitative structure–property relationship (QSPR)-based machine learning (ML) framework designed for predicting corrosion inhibition efficiency (CIE) values in natural organic inhibitor compounds. The modeling dataset comprises 50 natural organic compounds, with 11 quantum chemical properties (QCP) serving as input features, and the target variable being the corrosion inhibition efficiency (CIE) value. To enhance the predictive accuracy of the ML model, the kernel density estimation (KDE) function is employed to generate virtual samples during the training process, with the overarching goal of refining the precision of the ML model. Three distinct models, namely random forest (RF), gradient boosting (GB), and k-nearest neighbor (KNN), are tested in the study. The results demonstrate a noteworthy enhancement in the prediction performance of the models, attributable to the incorporation of virtual samples that effectively improve the correlation between input features and target values. Consequently, the accuracy of the predicted CIE values is significantly augmented, aligning more closely with the actual CIE values. Performance improvements were evident across all models after the incorporation of virtual samples. The GB, RF, and KNN models exhibited increments in R 2 values from 0.557 to 0.996, 0.522 to 0.999, and 0.415 to 0.994, respectively, concomitant with the introduction of 500 virtual samples. Additionally, each model demonstrated a notable reduction in RMSE values, transitioning from 1.41 to 0.19, 1.27 to 0.10, and 1.22 to 0.16, respectively. While the GB model initially outperformed others before the addition of virtual samples, the performance of the model exhibited fluctuation as the number of virtual samples varied. This behavior suggests that the KDE function provides a certain level of resilience against model variations. The proposed approach contributes to the effective design and exploration of corrosion inhibitor candidates, offering a reliable and accurate predictive tool that bridges the gap between theoretical studies and experimental synthesis.","['random forest (RF)', 'gradient boosting (GB)', 'k-nearest neighbor (KNN)']","The research idea centers on addressing the challenge of accurately predicting the corrosion inhibition efficiency (CIE) of natural organic compounds, which is crucial for the effective design and exploration of corrosion inhibitors. Understanding and improving the prediction of CIE values can significantly aid in bridging the gap between theoretical studies and experimental synthesis of corrosion inhibitor candidates. The study aims to enhance the precision of CIE value predictions to better support the development of natural organic inhibitors. The primary objective of the study is to develop a reliable and accurate approach for predicting the corrosion inhibition efficiency of natural organic compounds, thereby facilitating the identification and design of effective corrosion inhibitors. This objective focuses on improving the correlation between chemical properties of compounds and their inhibition performance to advance the exploration of corrosion inhibitor candidates."
Biology,Assessing ChatGPT 4.0’s test performance and clinical diagnostic accuracy on USMLE STEP 2 CK and clinical case reports,"Abstract While there is data assessing the test performance of artificial intelligence (AI) chatbots, including the Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0), there is scarce data on its diagnostic accuracy of clinical cases. We assessed the large language model (LLM), ChatGPT 4.0, on its ability to answer questions from the United States Medical Licensing Exam (USMLE) Step 2, as well as its ability to generate a differential diagnosis based on corresponding clinical vignettes from published case reports. A total of 109 Step 2 Clinical Knowledge (CK) practice questions were inputted into both ChatGPT 3.5 and ChatGPT 4.0, asking ChatGPT to pick the correct answer. Compared to its previous version, ChatGPT 3.5, we found improved accuracy of ChatGPT 4.0 when answering these questions, from 47.7 to 87.2% ( p = 0.035) respectively. Utilizing the topics tested on Step 2 CK questions, we additionally found 63 corresponding published case report vignettes and asked ChatGPT 4.0 to come up with its top three differential diagnosis. ChatGPT 4.0 accurately created a shortlist of differential diagnoses in 74.6% of the 63 case reports (74.6%). We analyzed ChatGPT 4.0’s confidence in its diagnosis by asking it to rank its top three differentials from most to least likely. Out of the 47 correct diagnoses, 33 were the first (70.2%) on the differential diagnosis list, 11 were second (23.4%), and three were third (6.4%). Our study shows the continued iterative improvement in ChatGPT’s ability to answer standardized USMLE questions accurately and provides insights into ChatGPT’s clinical diagnostic accuracy.","['Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0)', 'large language model (LLM)']","The research idea centers on the need to evaluate the diagnostic accuracy of clinical case assessments, as there is limited data on how well current tools perform in this area despite existing information on their general test performance. This study addresses the gap in understanding the ability to accurately generate differential diagnoses based on clinical vignettes and answer standardized medical licensing exam questions. The primary objective of the study is to assess the accuracy of clinical case diagnosis by evaluating performance on United States Medical Licensing Exam Step 2 Clinical Knowledge questions and the ability to generate appropriate differential diagnoses from published clinical case reports. The study aims to determine the accuracy and ranking of differential diagnoses in clinical vignettes to provide insights into diagnostic performance improvements."
Biology,Remote sensing based forest cover classification using machine learning,"Abstract Pakistan falls significantly below the recommended forest coverage level of 20 to 30 percent of total area, with less than 6 percent of its land under forest cover. This deficiency is primarily attributed to illicit deforestation for wood and charcoal, coupled with a failure to embrace advanced techniques for forest estimation, monitoring, and supervision. Remote sensing techniques leveraging Sentinel-2 satellite images were employed. Both single-layer stacked images and temporal layer stacked images from various dates were utilized for forest classification. The application of an artificial neural network (ANN) supervised classification algorithm yielded notable results. Using a single-layer stacked image from Sentinel-2, an impressive 91.37% training overall accuracy and 0.865 kappa coefficient were achieved, along with 93.77% testing overall accuracy and a 0.902 kappa coefficient. Furthermore, the temporal layer stacked image approach demonstrated even better results. This method yielded 98.07% overall training accuracy, 97.75% overall testing accuracy, and kappa coefficients of 0.970 and 0.965, respectively. The random forest (RF) algorithm, when applied, achieved 99.12% overall training accuracy, 92.90% testing accuracy, and kappa coefficients of 0.986 and 0.882. Notably, with the temporal layer stacked image of the Sentinel-2 satellite, the RF algorithm reached exceptional performance with 99.79% training accuracy, 96.98% validation accuracy, and kappa coefficients of 0.996 and 0.954. In terms of forest cover estimation, the ANN algorithm identified 31.07% total forest coverage in the District Abbottabad region. In comparison, the RF algorithm recorded a slightly higher 31.17% of the total forested area. This research highlights the potential of advanced remote sensing techniques and machine learning algorithms in improving forest cover assessment and monitoring strategies.","['artificial neural network (ANN) supervised classification algorithm', 'random forest (RF) algorithm']","The research addresses the critical issue of Pakistan having significantly less forest coverage than the recommended 20 to 30 percent of its total land area, with less than 6 percent currently under forest cover. This deficiency is largely due to illicit deforestation for wood and charcoal, as well as inadequate methods for accurate forest estimation, monitoring, and supervision. The study aims to improve the assessment and monitoring of forest cover in Pakistan, particularly in the District Abbottabad region. Its primary objective is to provide a more accurate estimation of forest coverage to support better forest management and conservation efforts."
Biology,Traffic Sign Detection and Recognition Using YOLO Object Detection Algorithm: A Systematic Review,"Context: YOLO (You Look Only Once) is an algorithm based on deep neural networks with real-time object detection capabilities. This state-of-the-art technology is widely available, mainly due to its speed and precision. Since its conception, YOLO has been applied to detect and recognize traffic signs, pedestrians, traffic lights, vehicles, and so on. Objective: The goal of this research is to systematically analyze the YOLO object detection algorithm, applied to traffic sign detection and recognition systems, from five relevant aspects of this technology: applications, datasets, metrics, hardware, and challenges. Method: This study performs a systematic literature review (SLR) of studies on traffic sign detection and recognition using YOLO published in the years 2016–2022. Results: The search found 115 primary studies relevant to the goal of this research. After analyzing these investigations, the following relevant results were obtained. The most common applications of YOLO in this field are vehicular security and intelligent and autonomous vehicles. The majority of the sign datasets used to train, test, and validate YOLO-based systems are publicly available, with an emphasis on datasets from Germany and China. It has also been discovered that most works present sophisticated detection, classification, and processing speed metrics for traffic sign detection and recognition systems by using the different versions of YOLO. In addition, the most popular desktop data processing hardwares are Nvidia RTX 2080 and Titan Tesla V100 and, in the case of embedded or mobile GPU platforms, Jetson Xavier NX. Finally, seven relevant challenges that these systems face when operating in real road conditions have been identified. With this in mind, research has been reclassified to address these challenges in each case. Conclusions: This SLR is the most relevant and current work in the field of technology development applied to the detection and recognition of traffic signs using YOLO. In addition, insights are provided about future work that could be conducted to improve the field.",['YOLO (You Look Only Once)'],"The research idea addresses the need for effective detection and recognition of traffic signs, which is crucial for vehicular security and the development of intelligent and autonomous vehicles. Accurate identification of traffic signs in real road conditions presents several challenges that impact the safety and efficiency of transportation systems. The study aims to systematically analyze existing approaches to traffic sign detection and recognition to better understand their applications, datasets, performance metrics, hardware requirements, and the challenges they face. The primary objective of this research is to comprehensively review and categorize the current state of traffic sign detection and recognition technologies, focusing on identifying key challenges and providing insights for future improvements in this field."
Biology,Reliable water quality prediction and parametric analysis using explainable AI models,"Abstract The consumption of water constitutes the physical health of most of the living species and hence management of its purity and quality is extremely essential as contaminated water has to potential to create adverse health and environmental consequences. This creates the dire necessity to measure, control and monitor the quality of water. The primary contaminant present in water is Total Dissolved Solids (TDS), which is hard to filter out. There are various substances apart from mere solids such as potassium, sodium, chlorides, lead, nitrate, cadmium, arsenic and other pollutants. The proposed work aims to provide the automation of water quality estimation through Artificial Intelligence and uses Explainable Artificial Intelligence (XAI) for the explanation of the most significant parameters contributing towards the potability of water and the estimation of the impurities. XAI has the transparency and justifiability as a white-box model since the Machine Learning (ML) model is black-box and unable to describe the reasoning behind the ML classification. The proposed work uses various ML models such as Logistic Regression, Support Vector Machine (SVM), Gaussian Naive Bayes, Decision Tree (DT) and Random Forest (RF) to classify whether the water is drinkable. The various representations of XAI such as force plot, test patch, summary plot, dependency plot and decision plot generated in SHAPELY explainer explain the significant features, prediction score, feature importance and justification behind the water quality estimation. The RF classifier is selected for the explanation and yields optimum Accuracy and F1-Score of 0.9999, with Precision and Re-call of 0.9997 and 0.998 respectively. Thus, the work is an exploratory analysis of the estimation and management of water quality with indicators associated with their significance. This work is an emerging research at present with a vision of addressing the water quality for the future as well.","['Logistic Regression', 'Support Vector Machine (SVM)', 'Gaussian Naive Bayes', 'Decision Tree (DT)', 'Random Forest (RF)']","The consumption of water is vital for the physical health of most living species, making the management of its purity and quality extremely important due to the adverse health and environmental consequences caused by contaminated water. Total Dissolved Solids (TDS) and various pollutants such as potassium, sodium, chlorides, lead, nitrate, cadmium, and arsenic are primary contaminants that affect water quality and are difficult to remove. The study aims to estimate and monitor water quality by identifying the most significant parameters contributing to water potability and impurity levels. Its primary objective is to provide an accurate assessment of water drinkability by evaluating key indicators associated with water contamination and their relative significance in determining water quality."
Biology,Multi-task aquatic toxicity prediction model based on multi-level features fusion,"With the escalating menace of organic compounds in environmental pollution imperiling the survival of aquatic organisms, the investigation of organic compound toxicity across diverse aquatic species assumes paramount significance for environmental protection. Understanding how different species respond to these compounds helps assess the potential ecological impact of pollution on aquatic ecosystems as a whole. Compared with traditional experimental methods, deep learning methods have higher accuracy in predicting aquatic toxicity, faster data processing speed and better generalization ability. This article presents ATFPGT-multi, an advanced multi-task deep neural network prediction model for organic toxicity. The model integrates molecular fingerprints and molecule graphs to characterize molecules, enabling the simultaneous prediction of acute toxicity for the same organic compound across four distinct fish species. Furthermore, to validate the advantages of multi-task learning, we independently construct prediction models, named ATFPGT-single, for each fish species. We employ cross-validation in our experiments to assess the performance and generalization ability of ATFPGT-multi. The experimental results indicate, first, that ATFPGT-multi outperforms ATFPGT-single on four fish datasets with AUC improvements of 9.8%, 4%, 4.8%, and 8.2%, respectively, demonstrating the superiority of multi-task learning over single-task learning. Furthermore, in comparison with previous algorithms, ATFPGT-multi outperforms comparative methods, emphasizing that our approach exhibits higher accuracy and reliability in predicting aquatic toxicity. Moreover, ATFPGT-multi utilizes attention scores to identify molecular fragments associated with fish toxicity in organic molecules, as demonstrated by two organic molecule examples in the main text, demonstrating the interpretability of ATFPGT-multi. In summary, ATFPGT-multi provides important support and reference for the further development of aquatic toxicity assessment. All of codes and datasets are freely available online at https://github.com/zhaoqi106/ATFPGT-multi.","['deep learning methods', 'multi-task deep neural network prediction model', 'multi-task learning', 'single-task learning']","The research addresses the growing threat posed by organic compounds in environmental pollution, which endangers the survival of aquatic organisms. Investigating the toxicity of these organic compounds across various aquatic species is crucial for understanding and protecting aquatic ecosystems from ecological harm. The primary aim of the study is to predict the acute toxicity of the same organic compounds across four different fish species, thereby providing a more comprehensive assessment of their potential ecological impact. This work seeks to enhance the accuracy and reliability of aquatic toxicity prediction to support environmental protection efforts."
Biology,A survey on training challenges in generative adversarial networks for biomedical image analysis,"Abstract In biomedical image analysis, the applicability of deep learning methods is directly impacted by the quantity of image data available. This is due to deep learning models requiring large image datasets to provide high-level performance. Generative Adversarial Networks (GANs) have been widely utilized to address data limitations through the generation of synthetic biomedical images. GANs consist of two models. The generator, a model that learns how to produce synthetic images based on the feedback it receives. The discriminator, a model that classifies an image as synthetic or real and provides feedback to the generator. Throughout the training process, a GAN can experience several technical challenges that impede the generation of suitable synthetic imagery. First, the mode collapse problem whereby the generator either produces an identical image or produces a uniform image from distinct input features. Second, the non-convergence problem whereby the gradient descent optimizer fails to reach a Nash equilibrium. Thirdly, the vanishing gradient problem whereby unstable training behavior occurs due to the discriminator achieving optimal classification performance resulting in no meaningful feedback being provided to the generator. These problems result in the production of synthetic imagery that is blurry, unrealistic, and less diverse. To date, there has been no survey article outlining the impact of these technical challenges in the context of the biomedical imagery domain. This work presents a review and taxonomy based on solutions to the training problems of GANs in the biomedical imaging domain. This survey highlights important challenges and outlines future research directions about the training of GANs in the domain of biomedical imagery.","['deep learning', 'Generative Adversarial Networks (GANs)', 'discriminator', 'gradient descent optimizer']","The research idea addresses the challenge of limited availability of biomedical image data, which affects the ability to generate high-quality synthetic biomedical images. The study highlights the technical difficulties encountered during the generation of synthetic images, such as producing blurry, unrealistic, and less diverse images due to specific training problems. The research objective is to review and categorize the existing solutions to these training challenges in the context of biomedical image generation. This work aims to highlight important challenges and propose future research directions for improving the generation of synthetic biomedical imagery."
Biology,A new intelligently optimized model reference adaptive controller using GA and WOA-based MPPT techniques for photovoltaic systems,"Recently, the integration of renewable energy sources, specifically photovoltaic (PV) systems, into power networks has grown in significance for sustainable energy generation. Researchers have investigated different control algorithms for maximum power point tracking (MPPT) to enhance the efficiency of PV systems. This article presents an innovative method to address the problem of maximum power point tracking in photovoltaic systems amidst swiftly changing weather conditions. MPPT techniques supply maximum power to the load during irradiance fluctuations and ambient temperatures. A novel optimal model reference adaptive controller is developed and designed based on the MIT rule to seek global maximum power without ripples rapidly. The suggested controller is also optimized through two popular meta-heuristic algorithms: The genetic algorithm (GA) and the whale optimization algorithm (WOA). These meta-heuristic approaches have been exploited to overcome the difficulty of selecting the adaptation gain of the MRAC controller. The reference voltage for MPPT is generated in the study through an adaptive neuro-fuzzy inference system. The suggested controller's performance is tested via MATLAB/Simulink software under varying temperature and radiation circumstances. Simulation is carried out using a Soltech 1sth-215-p module coupled to a boost converter, which powers a resistive load. Furthermore, to emphasize the recommended algorithm's performance, a comparative study was done between the optimal MRAC using GA and WOA and the conventional incremental conductance (INC) method.","['genetic algorithm (GA)', 'whale optimization algorithm (WOA)', 'adaptive neuro-fuzzy inference system']","The research idea centers on the challenge of maximizing power output from photovoltaic (PV) systems under rapidly changing weather conditions, such as fluctuations in irradiance and ambient temperature. Ensuring that PV systems can consistently supply maximum power to the load is crucial for improving the efficiency and reliability of sustainable energy generation. The study addresses the problem of tracking the maximum power point in PV systems to enhance their performance despite environmental variability. The primary objective of the study is to develop and optimize a control approach that can rapidly and accurately track the global maximum power point of photovoltaic systems without power fluctuations. The aim is to improve the efficiency of power extraction from PV modules under varying temperature and radiation conditions, thereby supporting more effective integration of renewable energy sources into power networks."
Biology,Assessment of technical water quality in mining based on machine learning methods,"Introduction. Mining requires water treatment and wastewater processing, abstraction and discharge during mining increases consumption several times. Since water consumption in mining and processing is usually associated with domestic, industrial and technical needs, the need for water supply systems required for water treatment increases. Water from different sources can be used for treatment: incoming water, process and reused water, and wastewater. But the water obtained from any of the sources must meet all the norms and requirements. Water quality is determined by physical, chemical and bacteriological properties. The main directions for improving water consumption by mining enterprises are to reduce the consumption of drinking water from rivers, lakes and municipal water supply, as well as to expand the use of mine and quarry water for domestic and technical needs. Materials and methods. As training data for training the neural network, a dataset that includes water quality data obtained from fresh water sources was selected for the methods work, and using machine learning, develops a model that predicts whether the water is suitable for technical use in mines. This dataset includes 2293 values (samples) as well as 9 attributes. Correlation, neural network, and decision tree methods were used to build the models in this study. Results. Various machine learning methods (neural network and decision trees) were used to build a predictive model to assess the quality of water that would be suitable for use in the mining industry for technical purposes. With the help of the built models were processed data obtained from public sources, when analyzing which it was found that the method of decision trees was more accurate. The constructed model, for determining dependencies, thus, has high accuracy (small error). To increase the practical significance of the study, a number of transformations of the initial data set were carried out, in particular, an experiment with the division of attributes into groups of importance, in relation to the data, taking into account the subject area. The results obtained made it clear that checking only for hazardous impurities does not guarantee the suitability of water, but almost completely excludes (low significance factor) samples with impurities that do not meet the requirements, and the model can have practical significance. Allocation of the group for rapid quality determination, showed that for the express test, in an emergency situation or under time constraints, the possibility of practical use of the obtained model, has a justification, due to the small error. In general, the conducted experiments have shown that when taking into account the costs (total) for data collection, it makes sense to use models, taking into account the reduction of collected data, on the parameters (factors) of technical water. Discussion. In general, on the basis of the conducted research, we can talk about the successful application of machine learning methods in determining the suitability of technical water in the mining industry. During the experiments, the decision tree method performed particularly well, with the lowest error values. In addition, further work can be carried out to reduce the error in the models, in particular, by possibly increasing the number of attributes, as well as more fine-tuning of the applied machine learning methods. Conclusions. The authors conclude that machine learning techniques can be successfully integrated to determine the quality and suitability of process water in the mining industry in today’s world. Resume. The paper compares machine learning methods such as decision trees and neural network method. The comparative analysis of these methods and their quality of information processing is shown on the example of a set of data on water quality in the mining industry. With the help of built models were processed data obtained from open sources, when analyzing which it was found that the method of decision trees was more accurate. The constructed model for determining dependencies has high accuracy (small error). Suggestions for practical applications and future research directions. This study can form the basis for research in this or related fields to conduct further studies on the reliability and accuracy of using machine learning to predict the quality of water used in the mining industry. Continued work in the above direction may be the rationale for wider use of the above methods to improve various meaningful production performance in this or related areas.","['neural network', 'decision tree']","The research addresses the challenge of managing water consumption and ensuring water quality in the mining industry, where water is required for domestic, industrial, and technical needs. Since mining activities significantly increase water use and involve water from various sources, it is crucial to determine whether this water meets the necessary physical, chemical, and bacteriological standards for safe and effective use. The study focuses on improving water consumption practices by reducing reliance on drinking water sources and expanding the use of mine and quarry water for technical purposes. The primary objective of the study is to assess the quality and suitability of water from different sources for technical use in mining operations, aiming to identify water that meets all required norms and requirements. This involves evaluating water quality parameters to ensure that water used in mining processes is safe and appropriate for its intended technical applications."
Biology,A Convolutional Neural Network approach for image-based anomaly detection in smart agriculture,"The recent technological advances and their applications to agriculture provide leverage for the new paradigm of smart agriculture. Remote sensing applications can help optimize resources, making agriculture more ecological, increasing productivity and helping farmers to anticipate events that could not otherwise be avoided. Considering that losses caused by anomalies such as diseases, weeds and pests account for 20-40 % of overall agricultural productivity, a successful research effort in this area would be a breakthrough for agriculture. In this paper, we propose a methodology with which to discover and classify anomalies in images of crops, taken from a wide range of distances, using different Convolutional Neural Network architectures. This methodology also deals with several difficulties that usually appear in this kind of problems, such as class imbalance, the insufficient and small variety of images, overtraining or lack of models generalisation. We have implemented four convolutional neural network architectures in a high-performance computing environment, and propose a methodology based on data augmentation with the addition of Gaussian noise to the images to solve the above problems. Our approach was tested using two well-established open datasets that are unalike: DeepWeeds, which provides a classification of 8 weed species native to Australia using images that were taken at a distance of 1 m, and Agriculture-Vision, which classifies 6 types of crop anomalies using multispectral satellite imagery. Our methodology attained accuracies of 98 % and 95.3% respectively, improving the state-of-the-art by several points. In order to ease reproducibility and model selection, we have provided a comparison in terms of computational time and other metrics, thus enabling the choice between architectures to be made according to the resources available. The complete code is available in an open repository in order to encourage reproducibility and promote scientific advances in sustainable agriculture.","['Convolutional Neural Network architectures', 'data augmentation with the addition of Gaussian noise']","The study addresses the significant impact of anomalies such as diseases, weeds, and pests on agricultural productivity, which can cause losses of 20-40% in overall yield. It highlights the importance of optimizing agricultural resources to make farming more ecological and productive, as well as helping farmers anticipate and manage adverse events that threaten crop health. The primary aim of the study is to develop a methodology for discovering and classifying anomalies in crop images taken from various distances, thereby improving the detection and management of these agricultural threats. This objective focuses on enhancing the identification of different types of crop anomalies and weed species to support sustainable agriculture and reduce productivity losses."
Biology,Machine learning for the management of biochar yield and properties of biomass sources for sustainable energy,"Abstract Biochar is emerging as a potential solution for biomass conversion to meet the ever increasing demand for sustainable energy. Efficient management systems are needed in order to exploit fully the potential of biochar. Modern machine learning (ML) techniques, and in particular ensemble approaches and explainable AI methods, are valuable for forecasting the properties and efficiency of biochar properly. Machine‐learning‐based forecasts, optimization, and feature selection are critical for improving biomass management techniques. In this research, we explore the influences of these techniques on the accurate forecasting of biochar yield and properties for a range of biomass sources. We emphasize the importance of the interpretability of a model, as this improves human comprehension and trust in ML predictions. Sensitivity analysis is shown to be an effective technique for finding crucial biomass characteristics that influence the synthesis of biochar. Precision prognostics have far‐reaching ramifications, influencing industries such as biomass logistics, conversion technologies, and the successful use of biomass as renewable energy. These advances can make a substantial contribution to a greener future and can encourage the development of a circular biobased economy. This work emphasizes the importance of using sophisticated data‐driven methodologies such as ML in biochar synthesis, to usher in ecologically friendly energy solutions. These breakthroughs hold the key to a more sustainable and environmentally friendly future.","['ensemble approaches', 'feature selection']","The research idea centers on addressing the growing need for sustainable energy by improving the conversion of biomass into biochar, a promising renewable energy source. Efficient management and understanding of biochar properties are essential to fully exploit its potential in biomass conversion. The study highlights the significance of accurately forecasting biochar yield and properties from various biomass sources to enhance biomass management and conversion technologies. This is important for advancing sustainable energy solutions and supporting the development of a circular biobased economy.

The primary objective of the study is to explore the factors influencing the accurate prediction of biochar yield and properties across different biomass sources. The research aims to identify key biomass characteristics that affect biochar synthesis and to improve the understanding of these relationships. Ultimately, the study seeks to contribute to more effective biomass management and conversion strategies that promote environmentally friendly and sustainable energy production."
Biology,Effective lung nodule detection using deep CNN with dual attention mechanisms,"Abstract Novel methods are required to enhance lung cancer detection, which has overtaken other cancer-related causes of death as the major cause of cancer-related mortality. Radiologists have long-standing methods for locating lung nodules in patients with lung cancer, such as computed tomography (CT) scans. Radiologists must manually review a significant amount of CT scan pictures, which makes the process time-consuming and prone to human error. Computer-aided diagnosis (CAD) systems have been created to help radiologists with their evaluations in order to overcome these difficulties. These systems make use of cutting-edge deep learning architectures. These CAD systems are designed to improve lung nodule diagnosis efficiency and accuracy. In this study, a bespoke convolutional neural network (CNN) with a dual attention mechanism was created, which was especially crafted to concentrate on the most important elements in images of lung nodules. The CNN model extracts informative features from the images, while the attention module incorporates both channel attention and spatial attention mechanisms to selectively highlight significant features. After the attention module, global average pooling is applied to summarize the spatial information. To evaluate the performance of the proposed model, extensive experiments were conducted using benchmark dataset of lung nodules. The results of these experiments demonstrated that our model surpasses recent models and achieves state-of-the-art accuracy in lung nodule detection and classification tasks.","['convolutional neural network (CNN)', 'dual attention mechanism', 'channel attention', 'spatial attention', 'global average pooling']","The study addresses the critical need for improved methods to enhance lung cancer detection, given that lung cancer has become the leading cause of cancer-related mortality. Traditional approaches, such as manual review of computed tomography (CT) scans by radiologists, are time-consuming and susceptible to human error, highlighting the necessity for more efficient and accurate diagnostic techniques. The primary aim of the study is to develop a specialized approach that focuses on identifying and highlighting the most important features in lung nodule images to improve the accuracy and efficiency of lung nodule diagnosis. This objective is pursued by creating a method that enhances the detection and classification of lung nodules, ultimately supporting better lung cancer diagnosis."
Biology,Plant disease recognition in a low data scenario using few-shot learning,"Plant disease is one of the major problems in agriculture. Diseases damage plants, reduce yields and lower the quality of the produce. Traditional approaches to detecting plant diseases are usually based on visual inspection and laboratory testing, which can be expensive and time-consuming. They require trained plant pathologists as well as specialised equipment. Several studies demonstrate that artificial intelligence (AI) methods can produce promising results. However, AI methods are generally data-hungry and require large annotated datasets, and the collection and annotation of such datasets can be a limiting factor. It often appears that only a small amount of data is available for certain disease types. Whereas the performance of typical AI methods drops significantly when they are trained with inadequate data. This paper proposes a novel few-shot learning (FSL) method to detect plant diseases and alleviate the data scarcity problem. The proposed method uses as few as five images per class in the machine learning process. Our method is based on a state-of-the-art FSL pipeline called pre-training, meta-learning, and fine-tuning (PMF), integrated with a novel feature attention (FA) module; we call the overall method PMF+FA. The FA module emphasises the discriminative parts in the image and reduces the impact of complicated backgrounds and undesired objects. We used ResNet50 and Vision Transformers (ViT) as the feature learner. Two publicly available plant disease datasets were repurposed to meet the FSL requirements. We thoroughly evaluated the proposed method on the PlantDoc dataset, which contains disease samples in field environments with complex backgrounds and unwanted objects. The PMF+FA method with ViT achieved an average accuracy of 90.12% in disease recognition. The results demonstrate that the PMF+FA pipeline consistently outperforms the baseline PMF. The results also highlight that the method using ViT generates better results than ResNet50 for diagnosing complex data. ViT and ResNet50 implementations are computationally efficient, taking 1.11 and 0.57 ms on average per image to evaluate the test set respectively. The high throughput and high-quality performance with only a small training dataset indicate that the proposed technique can be used for real-time disease detection in digital farming systems.","['few-shot learning (FSL)', 'ResNet50', 'Vision Transformers (ViT)']","The study addresses the significant challenge of plant disease detection in agriculture, which is crucial because diseases damage plants, reduce yields, and lower the quality of produce. Traditional methods for detecting plant diseases rely on visual inspection and laboratory testing, which are often expensive, time-consuming, and require specialized expertise and equipment. Additionally, there is a problem of limited availability of annotated data for certain disease types, which hampers effective disease identification.

The primary aim of the study is to develop a method for detecting plant diseases that can operate effectively even with a very small number of images per disease class. The objective is to overcome the issue of data scarcity in plant disease recognition and improve the accuracy of disease detection in complex field environments with limited training samples."
Biology,An ensemble penalized regression method for multi-ancestry polygenic risk prediction,"Abstract Great efforts are being made to develop advanced polygenic risk scores (PRS) to improve the prediction of complex traits and diseases. However, most existing PRS are primarily trained on European ancestry populations, limiting their transferability to non-European populations. In this article, we propose a novel method for generating multi-ancestry Polygenic Risk scOres based on enSemble of PEnalized Regression models (PROSPER). PROSPER integrates genome-wide association studies (GWAS) summary statistics from diverse populations to develop ancestry-specific PRS with improved predictive power for minority populations. The method uses a combination of $${{{{{{\mathscr{L}}}}}}}_{1}$$ <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""> <mml:msub> <mml:mrow> <mml:mi>L</mml:mi> </mml:mrow> <mml:mrow> <mml:mn>1</mml:mn> </mml:mrow> </mml:msub> </mml:math> (lasso) and $${{{{{{\mathscr{L}}}}}}}_{2}$$ <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""> <mml:msub> <mml:mrow> <mml:mi>L</mml:mi> </mml:mrow> <mml:mrow> <mml:mn>2</mml:mn> </mml:mrow> </mml:msub> </mml:math> (ridge) penalty functions, a parsimonious specification of the penalty parameters across populations, and an ensemble step to combine PRS generated across different penalty parameters. We evaluate the performance of PROSPER and other existing methods on large-scale simulated and real datasets, including those from 23andMe Inc., the Global Lipids Genetics Consortium, and All of Us. Results show that PROSPER can substantially improve multi-ancestry polygenic prediction compared to alternative methods across a wide variety of genetic architectures. In real data analyses, for example, PROSPER increased out-of-sample prediction R 2 for continuous traits by an average of 70% compared to a state-of-the-art Bayesian method (PRS-CSx) in the African ancestry population. Further, PROSPER is computationally highly scalable for the analysis of large SNP contents and many diverse populations.","['lasso', 'ridge', 'ensemble']","The study addresses the challenge that most existing polygenic risk scores (PRS) are primarily developed using data from European ancestry populations, which limits their effectiveness and transferability to non-European populations. This limitation hinders accurate prediction of complex traits and diseases in diverse populations, particularly minority groups. The research is motivated by the need to improve the predictive power of PRS across multiple ancestries to enable better genetic risk assessment for a broader range of populations. The primary objective of the study is to develop a novel approach for generating multi-ancestry polygenic risk scores by integrating genome-wide association study summary statistics from diverse populations, aiming to produce ancestry-specific PRS with enhanced predictive accuracy for minority populations. The study seeks to demonstrate that this approach can substantially improve polygenic prediction across various genetic architectures compared to existing methods."
Biology,Semantic segmentation of microbial alterations based on SegFormer,"Introduction Precise semantic segmentation of microbial alterations is paramount for their evaluation and treatment. This study focuses on harnessing the SegFormer segmentation model for precise semantic segmentation of strawberry diseases, aiming to improve disease detection accuracy under natural acquisition conditions. Methods Three distinct Mix Transformer encoders - MiT-B0, MiT-B3, and MiT-B5 - were thoroughly analyzed to enhance disease detection, targeting diseases such as Angular leaf spot, Anthracnose rot, Blossom blight, Gray mold, Leaf spot, Powdery mildew on fruit, and Powdery mildew on leaves. The dataset consisted of 2,450 raw images, expanded to 4,574 augmented images. The Segment Anything Model integrated into the Roboflow annotation tool facilitated efficient annotation and dataset preparation. Results The results reveal that MiT-B0 demonstrates balanced but slightly overfitting behavior, MiT-B3 adapts rapidly with consistent training and validation performance, and MiT-B5 offers efficient learning with occasional fluctuations, providing robust performance. MiT-B3 and MiT-B5 consistently outperformed MiT-B0 across disease types, with MiT-B5 achieving the most precise segmentation in general. Discussion The findings provide key insights for researchers to select the most suitable encoder for disease detection applications, propelling the field forward for further investigation. The success in strawberry disease analysis suggests potential for extending this approach to other crops and diseases, paving the way for future research and interdisciplinary collaboration.","['SegFormer segmentation model', 'Mix Transformer encoders - MiT-B0', 'Mix Transformer encoders - MiT-B3', 'Mix Transformer encoders - MiT-B5', 'Segment Anything Model']","The study addresses the critical need for precise semantic segmentation of microbial alterations to enable accurate evaluation and treatment of strawberry diseases under natural acquisition conditions. It focuses on improving the detection accuracy of various strawberry diseases, including Angular leaf spot, Anthracnose rot, Blossom blight, Gray mold, Leaf spot, and Powdery mildew on both fruit and leaves. The primary aim of the study is to enhance disease detection accuracy by thoroughly analyzing different segmentation approaches to identify the most effective method for precise semantic segmentation of strawberry diseases. This objective seeks to provide valuable insights for selecting suitable techniques for disease detection, ultimately contributing to better management and treatment of strawberry crop diseases."
Biology,A Survey of Text Classification With Transformers: How Wide? How Large? How Long? How Accurate? How Expensive? How Safe?,"Text classification is a basic task in natural language processing (NLP) with applications from sentiment analysis to question-answering with chat bots. In recent years, transformer-based models have emerged as the prevailing framework in NLP, demonstrating excellent results across many benchmarks. This paper recommends an expanded taxonomy of applications and provides a review of the performance of different models across these applications. The use of traditional research techniques plus co-citation and bibliographic coupling provides a comprehensive view of the current and past research in this area. The study begins by providing an overview of the history of transformer-based models with an emphasis on recent large language models (LLM). Next, uni-modal (text only) inputs and the emerging area of multi-modal classification are discussed to provide a comparison of current and emerging research in this area. Gaps are highlighted in the use of multi-modal text/numeric/columnar data and recommendations for future research are provided. Finally, the length of text input variables (tokens) is reviewed to explore the evolution from short-text to longer document applications. Furthermore, the accuracy on 358 datasets across 20 applications is reviewed and unexpected results emerge which show that LLMs are not always the most accurate or least expensive option. In addition to model performance, the safety implications of transformer-based models are reviewed, and a summary of issues related to ethics, bias, social implications, and copyright are explored.",['transformer-based models'],"The research idea addresses the broad application of text classification within natural language processing, highlighting its importance across various tasks such as sentiment analysis and question-answering. The study is motivated by the need to understand the performance and evolution of different approaches in this area, including the challenges and gaps related to multi-modal data and varying lengths of text inputs. The primary objective of the study is to provide a comprehensive review of the performance of different models across multiple applications, identify gaps in current research particularly concerning multi-modal data, and offer recommendations for future investigations. Additionally, the study aims to examine the implications of these models in terms of safety, ethics, bias, social impact, and copyright considerations."
Biology,"A stacking ANN ensemble model of ML models for stream water quality prediction of Godavari River Basin, India","The importance of water quality models has increased as their inputs are critical to the development of risk assessment framework for environmental management and monitoring of rivers. However, with the advent of a plethora of recent advances in ML algorithms better predictions are possible. This study proposes a causal and effect model by considering climatological such as temperature and precipitation along with geospatial information related to the agricultural land use factor (ALUF), the forest land use factor (FLUF), the grassland usage factor (GLUF), the shrub land use factor (SLUF), and the urban land use factor (ULUF). All these factors are included in the input data, whereas four Stream Water Quality parameters (SWQPs) such as Electrical Conductivity (EC), Biochemical Oxygen Demand (BOD), Nitrate, and Dissolved Oxygen (DO) from 2019 to 2021 are taken as outputs to predict the Godavari River Basin water quality. In the preliminary investigation, out of these four SWQPs, nitrate's coefficient of variation (CV) is high, revealing a close association with climate parameters and land use practices across the sampling stations. In the authors' earlier study, a model using a single-layer Feed-Forward Neural Network (FFNN) showed improved performance in predicting cause and effect factors linked to water quality metrics. To achieve better prediction, a stacked ANN meta-model and nine conventional machine learning (ML) models, including Extreme Gradient Boosting (XGB), Extra Trees (ET), Bagging (BG), Random Forest (RF), AdaBoost or Adaptive Boosting (ADB), Decision Tree (DT), Highest Gradient Boosting (HGB), Light Gradient Boosting Method (LGBM), and Gradient Boosting (GB), were compared in this study. According to the study's findings, Bagging and Boosting models outperformed stand-alone earlier FFNN for the same dataset and showed superior predictive capabilities in terms of accuracy in forecasting the variable of interest. For instance, during testing, the coefficient of determination (R2) of Biochemical Oxygen Demand (BOD) increased from 0.72 to 0.87. Furthermore, a stacked Artificial Neural Network (ANN) meta model that was reinforced using Extreme Gradient Boosting (XGB), Random Forest (RF), and Extra Trees (ET) as base models performed better than the individual ML models (from R2 = 0.87 to 0.91 for BOD in testing). By using this new framework, the effort for hyperparameter tuning can be minimized.","['Feed-Forward Neural Network (FFNN)', 'stacked ANN meta-model', 'Extreme Gradient Boosting (XGB)', 'Extra Trees (ET)', 'Bagging (BG)', 'Random Forest (RF)', 'AdaBoost or Adaptive Boosting (ADB)', 'Decision Tree (DT)', 'Light Gradient Boosting Method (LGBM)', 'Gradient Boosting (GB)', 'stacked Artificial Neural Network (ANN) meta model']","The study addresses the critical need for accurate water quality assessment in river ecosystems, emphasizing the importance of understanding how climatological factors such as temperature and precipitation, along with various land use types including agricultural, forest, grassland, shrub, and urban areas, influence stream water quality parameters. This is essential for developing effective risk assessment frameworks for environmental management and monitoring of rivers like the Godavari River Basin. The primary objective of the study is to improve the prediction of key stream water quality parameters—Electrical Conductivity, Biochemical Oxygen Demand, Nitrate, and Dissolved Oxygen—by examining their relationships with climate variables and land use factors over the period from 2019 to 2021. The study aims to enhance the accuracy of forecasting these water quality metrics to better understand the cause-and-effect dynamics affecting river health."
Biology,Advancements in Imaging Sensors and AI for Plant Stress Detection: A Systematic Literature Review,"Integrating imaging sensors and artificial intelligence (AI) have contributed to detecting plant stress symptoms, yet data analysis remains a key challenge. Data challenges include standardized data collection, analysis protocols, selection of imaging sensors and AI algorithms, and finally, data sharing. Here, we present a systematic literature review (SLR) scrutinizing plant imaging and AI for identifying stress responses. We performed a scoping review using specific keywords, namely abiotic and biotic stress, machine learning, plant imaging and deep learning. Next, we used programmable bots to retrieve relevant papers published since 2006. In total, 2,704 papers from 4 databases (Springer, ScienceDirect, PubMed, and Web of Science) were found, accomplished by using a second layer of keywords (e.g., hyperspectral imaging and supervised learning). To bypass the limitations of search engines, we selected OneSearch to unify keywords. We carefully reviewed 262 studies, summarizing key trends in AI algorithms and imaging sensors. We demonstrated that the increased availability of open-source imaging repositories such as PlantVillage or Kaggle has strongly contributed to a widespread shift to deep learning, requiring large datasets to train in stress symptom interpretation. Our review presents current trends in AI-applied algorithms to develop effective methods for plant stress detection using image-based phenotyping. For example, regression algorithms have seen substantial use since 2021. Ultimately, we offer an overview of the course ahead for AI and imaging technologies to predict stress responses. Altogether, this SLR highlights the potential of AI imaging in both biotic and abiotic stress detection to overcome challenges in plant data analysis.","['machine learning', 'deep learning', 'supervised learning', 'regression algorithms']","The research idea centers on addressing the challenges in detecting plant stress symptoms, particularly those caused by abiotic and biotic factors, through the use of imaging sensors. Despite advances in imaging technologies, difficulties remain in standardizing data collection, analysis protocols, sensor selection, and data sharing, which hinder effective identification of plant stress responses. The study aims to understand and overcome these obstacles to improve the detection and interpretation of stress symptoms in plants. The primary objective of the study is to systematically review existing literature on plant imaging for stress detection, summarizing key trends and developments in the field to provide an overview of current methods and future directions for identifying plant stress responses using image-based phenotyping."
Biology,CAR-Toner: an AI-driven approach for CAR tonic signaling prediction and optimization,"2][3] Our previous work has elucidated that positively charged patches (PCPs) on the surface of the CAR antigenbinding domain facilitate CAR clustering, thereby triggering CAR tonic signals.To quantify these PCPs, which are indicative of CAR tonic signaling, we previously developed a bioinformatic method to determine the PCP score. 1 This calculation method starts with constructing three-dimensional (3D) homology models for CAR's single-chain variable fragments (scFvs) using the SWISS homology modeler.Subsequently, the BindUP web server is used to determine the total count of residues within the top three largest patches containing continuous positively charged residues on the surface of CAR scFv.However, this PCP score calculation method has several limitations: 1. reliance on two external servers; 2. each calculation taking a few days, significantly hindering efficiency; 3. lack of batch calculation capability; 4. no optimization strategies provided for finetuning PCP scores.Given these constraints, we aimed to develop an artificial intelligence (AI)-based PCP score calculator and optimizer to overcome these bottlenecks.Protein databases, structural biology, and advanced deep learning models are all integrated into our AI-based PCP score calculator (Fig. 1a).A comprehensive protein structure database consisting of over 170,000 entries was established by extracting 3D structural information from the Protein Data Bank (PDB) and AlphaFold predictions, followed by stringent quality control procedures.We further developed an in-house algorithm tailored for calculating PCP scores based on the obtained 3D structure information (Supplementary Information), subsequently generating a dataset comprising approximately 170,000 protein sequences along with their associated PCP scores.For model training and evaluation, 70% of the data are allocated as the training dataset, while the remaining 30% serve as the test dataset.The ESM2 model, developed by the FAIR (Meta Fundamental AI Research Protein Team), is utilized for fine-tuning tasks related to PCP prediction. 4,5SM2 is a transformer-based language model using an attention mechanism to learn interaction patterns between pairs of amino acids in the input sequence.Pre-trained on over 60 million protein sequences from the UniProt Reference Clusters (UniRef) database, ESM2 demonstrates strong adaptability to downstream protein structure-related tasks. 5The ESM2-8M model was used to fine-tune the training dataset.Following updating parameters, the ESM2 model was transformed into the PCP-AI prediction model, referred to as CAR-Tonic Signal Tuner (abbreviated as CAR-Toner; http://cartfitness.slst.shanghaitech.edu.cn/CAR-fitness/).This model encompasses three key functionalities: proficient PCP calculation for individual proteins, streamlined batch processing, and an integrated optimization strategy for refining PCP scores (Fig. 1b).","['ESM2 model', 'transformer-based language model using an attention mechanism', 'fine-tuning']","The research idea centers on the role of positively charged patches (PCPs) on the surface of the CAR antigen-binding domain, which facilitate CAR clustering and trigger CAR tonic signaling. Quantifying these PCPs is important because they serve as indicators of CAR tonic signaling, a critical factor in understanding CAR function. However, existing methods for calculating PCP scores have significant limitations, including reliance on external resources, lengthy processing times, lack of batch processing, and absence of optimization strategies, which hinder efficient and effective analysis. The study aims to address these challenges to improve the quantification of PCPs.

The primary objective of the study is to develop a more efficient and optimized approach for calculating PCP scores that overcomes the limitations of previous methods. This includes enabling faster and batch processing of PCP calculations and incorporating strategies to refine PCP scores for better accuracy. The goal is to facilitate improved quantification of positively charged patches on CAR antigen-binding domains to better understand and potentially modulate CAR tonic signaling."
Biology,Accuracy of GPT-4 in histopathological image detection and classification of colorectal adenomas,"Aims To evaluate the accuracy of Chat Generative Pre-trained Transformer (ChatGPT) powered by GPT-4 in histopathological image detection and classification of colorectal adenomas using the diagnostic consensus provided by pathologists as a reference standard. Methods A study was conducted with 100 colorectal polyp photomicrographs, comprising an equal number of adenomas and non-adenomas, classified by two pathologists. These images were analysed by classic GPT-4 for 1 time in October 2023 and custom GPT-4 for 20 times in December 2023. GPT-4’s responses were compared against the reference standard through statistical measures to evaluate its proficiency in histopathological diagnosis, with the pathologists further assessing the model’s descriptive accuracy. Results GPT-4 demonstrated a median sensitivity of 74% and specificity of 36% for adenoma detection. The median accuracy of polyp classification varied, ranging from 16% for non-specific changes to 36% for tubular adenomas. Its diagnostic consistency, indicated by low kappa values ranging from 0.06 to 0.11, suggested only poor to slight agreement. All of the microscopic descriptions corresponded with their diagnoses. GPT-4 also commented about the limitations in its diagnoses (eg, slide diagnosis best done by pathologists, the inadequacy of single-image diagnostic conclusions, the need for clinical data and a higher magnification view). Conclusions GPT-4 showed high sensitivity but low specificity in detecting adenomas and varied accuracy for polyp classification. However, its diagnostic consistency was low. This artificial intelligence tool acknowledged its diagnostic limitations, emphasising the need for a pathologist’s expertise and additional clinical context.",['Chat Generative Pre-trained Transformer (ChatGPT) powered by GPT-4'],"The research idea addresses the challenge of accurately detecting and classifying colorectal adenomas through histopathological examination, highlighting the importance of reliable diagnostic methods in pathology. Given the critical role of pathologists in providing consensus diagnoses, there is a need to evaluate alternative approaches that could assist or complement traditional histopathological analysis. The study aims to assess the accuracy and consistency of colorectal polyp classification, which is essential for effective diagnosis and treatment planning. The primary objective of the study is to evaluate the accuracy of histopathological image detection and classification of colorectal adenomas by comparing diagnostic results against the consensus provided by expert pathologists. The study seeks to determine the sensitivity, specificity, and overall diagnostic consistency in identifying adenomas and non-adenomas, as well as to understand the limitations inherent in single-image diagnoses and the necessity of clinical context and expert interpretation."
Biology,A domain adaptation approach to damage classification with an application to bridge monitoring,"Data-driven machine-learning algorithms generally suffer from a lack of labelled health-state data, mainly those referring to damage conditions. To address such an issue, population-based structural health monitoring seeks to enrich the original dataset by transferring knowledge from a population of monitored structures. Within this context, this paper presents a transfer learning approach, based on domain adaptation, to leverage information from completely-labelled bridge structure data to accurately predict new instances of an unknown target domain. Since intrinsic structural differences may cause distribution shifts, domain adaptation attempts to minimise the distance between the domains and to learn a mapping within a shared feature space. Specifically, the methodology involves the long-term acquisition of natural frequencies from several structural scenarios. Such damage-sensitive features are then aligned via domain adaptation so that a machine-learning algorithm can effectively utilise the labelled source domain data and generalise well to the unlabelled target-domain data. The described procedure is applied to two case studies, including the Z24 and the S101 benchmark bridges and their finite element models, respectively. The results demonstrate the successful exchange of health-state labels to identify the damage class within a population of bridges equipped with SHM systems, showing potential to reduce computational efforts and to deal with scarce or poor data sets in application to bridge network monitoring.","['transfer learning', 'domain adaptation']","The research idea addresses the challenge of limited labeled health-state data related to damage conditions in structural health monitoring of bridges. This scarcity hinders accurate identification and assessment of structural damage across different bridge structures. The study is motivated by the need to improve damage detection by leveraging information from a population of monitored bridges to enhance the understanding of health states in structures with insufficient data. The primary objective of the study is to develop an approach that enables the transfer of health-state information from fully labeled bridge data to new, unlabeled bridge instances, thereby improving the identification of damage classes within a population of bridges. This aims to facilitate more effective monitoring of bridge networks despite variations in structural characteristics and limited availability of damage-related data."
Biology,Discovering Consensus Regions for Interpretable Identification of RNA N6-Methyladenosine Modification Sites via Graph Contrastive Clustering,"As a pivotal post-transcriptional modification of RNA, N6-methyladenosine (m6A) has a substantial influence on gene expression modulation and cellular fate determination. Although a variety of computational models have been developed to accurately identify potential m6A modification sites, few of them are capable of interpreting the identification process with insights gained from consensus knowledge. To overcome this problem, we propose a deep learning model, namely M6A-DCR, by discovering consensus regions for interpretable identification of m6A modification sites. In particular, M6A-DCR first constructs an instance graph for each RNA sequence by integrating specific positions and types of nucleotides. The discovery of consensus regions is then formulated as a graph clustering problem in light of aggregating all instance graphs. After that, M6A-DCR adopts a motif-aware graph reconstruction optimization process to learn high-quality embeddings of input RNA sequences, thus achieving the identification of m6A modification sites in an end-to-end manner. Experimental results demonstrate the superior performance of M6A-DCR by comparing it with several state-of-the-art identification models. The consideration of consensus regions empowers our model to make interpretable predictions at the motif level. The analysis of cross validation through different species and tissues further verifies the consistency between the identification results of M6A-DCR and the evolutionary relationships among species","['deep learning model', 'graph clustering']","The study addresses the important role of N6-methyladenosine (m6A) as a key post-transcriptional modification of RNA that significantly influences gene expression regulation and cellular fate determination. Despite the existence of various approaches to identify potential m6A modification sites, there remains a challenge in interpreting the identification process with insights derived from consensus biological knowledge. The primary aim of the study is to improve the identification of m6A modification sites by discovering consensus regions that allow for interpretable predictions at the motif level. Additionally, the study seeks to validate the consistency of these identification results across different species and tissues, reflecting evolutionary relationships."
Biology,The SAFE procedure: a practical stopping heuristic for active learning-based screening in systematic reviews and meta-analyses,"Abstract Active learning has become an increasingly popular method for screening large amounts of data in systematic reviews and meta-analyses. The active learning process continually improves its predictions on the remaining unlabeled records, with the goal of identifying all relevant records as early as possible. However, determining the optimal point at which to stop the active learning process is a challenge. The cost of additional labeling of records by the reviewer must be balanced against the cost of erroneous exclusions. This paper introduces the SAFE procedure, a practical and conservative set of stopping heuristics that offers a clear guideline for determining when to end the active learning process in screening software like ASReview. The eclectic mix of stopping heuristics helps to minimize the risk of missing relevant papers in the screening process. The proposed stopping heuristic balances the costs of continued screening with the risk of missing relevant records, providing a practical solution for reviewers to make informed decisions on when to stop screening. Although active learning can significantly enhance the quality and efficiency of screening, this method may be more applicable to certain types of datasets and problems. Ultimately, the decision to stop the active learning process depends on careful consideration of the trade-off between the costs of additional record labeling against the potential errors of the current model for the specific dataset and context.",['active learning'],"The research idea addresses the challenge of efficiently screening large volumes of scientific literature in systematic reviews and meta-analyses, focusing on the difficulty of determining the optimal point to stop the screening process to balance thoroughness and resource expenditure. The study highlights the need to minimize the risk of missing relevant records while managing the costs associated with continued manual review. The primary objective of the study is to introduce a practical and conservative set of guidelines that help reviewers decide when to end the screening process, thereby balancing the cost of additional record evaluation against the risk of excluding important studies. This approach aims to provide clear decision-making criteria to improve the efficiency and reliability of literature screening in biological research contexts."
Biology,"Machine learning models for gully erosion susceptibility assessment in the Tensift catchment, Haouz Plain, Morocco for sustainable development","Gully erosion is a widespread environmental danger, threatening global socio-economic stability and sustainable development. This study comprehensively applied seven machine learning (ML) models including SVM, KNN, RF, XGBoost, ANN, DT, and LR, and evaluated gully erosion susceptibility in the Tensift catchment and predict it within the Haouz plain, Morocco. To ensure the reliability of the findings, the study employed a robust combination of gully erosion inventory, sentinel images, and Digital Surface Model. Eighteen predictors, encompassing topographical, geomorphological, environmental, and hydrological factors, were selected after multicollinearity analyses. The gully erosion susceptibility of the study revealed that approximately 28.18% of the Tensift catchment is at a very high risk of erosion. Furthermore, 15.13% and 31.28% of the catchment are categorized as low and very low respectively. These findings extend to the Haouz plain, where 7.84% of the surface area are very highly risking erosion, while 18.25% and 55.18% are characterized as low and very low risk areas. To gauge the performance of the ML models, an array of metrics including specificity, precision, sensitivity, and accuracy were employed. The study highlights XGBoost and KNN as the most promising models, achieving AUC ROC values of 0.96 and 0.93 in the test phase. The remaining models namely RF (AUC ROC = 0.89), LR (AUC ROC = 0.80), SVM (AUC ROC = 0.81), DT (AUC ROC = 0.86), and ANN (AUC ROC = 0.78), also displayed commendable performance. The novelty of this research is its innovative approach to combat gully erosion through cutting edge ML models, offering practical solutions for watershed conservation, sustainable management, and the prevention of land degradation. These insights are invaluable for addressing the challenges posed by gully erosion within the region, and beyond its geographical boundaries and can be used for defining appropriate mitigation strategies at local to national scale.","['SVM', 'KNN', 'RF', 'XGBoost', 'ANN', 'DT', 'LR']","The study addresses the widespread environmental threat of gully erosion, which poses significant risks to global socio-economic stability and sustainable development. Gully erosion leads to land degradation, impacting watershed conservation and the overall health of affected ecosystems. The primary aim of the study is to evaluate gully erosion susceptibility in the Tensift catchment and predict it within the Haouz plain, Morocco, by identifying areas at varying levels of erosion risk. This research seeks to provide valuable insights for defining appropriate mitigation strategies to prevent land degradation and promote sustainable management of the affected regions."
Biology,A Deep Bidirectional LSTM Model Enhanced by Transfer-Learning-Based Feature Extraction for Dynamic Human Activity Recognition,"Dynamic human activity recognition (HAR) is a domain of study that is currently receiving considerable attention within the fields of computer vision and pattern recognition. The growing need for artificial-intelligence (AI)-driven systems to evaluate human behaviour and bolster security underscores the timeliness of this research. Despite the strides made by numerous researchers in developing dynamic HAR frameworks utilizing diverse pre-trained architectures for feature extraction and classification, persisting challenges include suboptimal performance accuracy and the computational intricacies inherent in existing systems. These challenges arise due to the vast video-based datasets and the inherent similarity in the data. To address these challenges, we propose an innovative, dynamic HAR technique employing a deep-learning-based, deep bidirectional long short-term memory (Deep BiLSTM) model facilitated by a pre-trained transfer-learning-based feature-extraction approach. Our approach begins with the utilization of Convolutional Neural Network (CNN) models, specifically MobileNetV2, for extracting deep-level features from video frames. Subsequently, these features are fed into an optimized deep bidirectional long short-term memory (Deep BiLSTM) network to discern dependencies and process data, enabling optimal predictions. During the testing phase, an iterative fine-tuning procedure is introduced to update the high parameters of the trained model, ensuring adaptability to varying scenarios. The proposed model’s efficacy was rigorously evaluated using three benchmark datasets, namely UCF11, UCF Sport, and JHMDB, achieving notable accuracies of 99.20%, 93.3%, and 76.30%, respectively. This high-performance accuracy substantiates the superiority of our proposed model, signaling a promising advancement in the domain of activity recognition.","['deep bidirectional long short-term memory (Deep BiLSTM)', 'pre-trained transfer-learning-based feature-extraction approach', 'Convolutional Neural Network (CNN)', 'MobileNetV2']","The study addresses the challenge of accurately recognizing dynamic human activities, which is important for evaluating human behavior and enhancing security. Despite previous efforts, existing approaches face difficulties due to the complexity of video-based datasets and the similarity within the data, leading to suboptimal performance. The primary objective of the study is to develop a novel technique for dynamic human activity recognition that improves accuracy and adaptability across different scenarios. This approach aims to effectively capture and interpret human activity patterns to achieve superior recognition performance on benchmark datasets."
Biology,A multimodal graph neural network framework for cancer molecular subtype classification,"Abstract Background The recent development of high-throughput sequencing has created a large collection of multi-omics data, which enables researchers to better investigate cancer molecular profiles and cancer taxonomy based on molecular subtypes. Integrating multi-omics data has been proven to be effective for building more precise classification models. Most current multi-omics integrative models use either an early fusion in the form of concatenation or late fusion with a separate feature extractor for each omic, which are mainly based on deep neural networks. Due to the nature of biological systems, graphs are a better structural representation of bio-medical data. Although few graph neural network (GNN) based multi-omics integrative methods have been proposed, they suffer from three common disadvantages. One is most of them use only one type of connection, either inter-omics or intra-omic connection; second, they only consider one kind of GNN layer, either graph convolution network (GCN) or graph attention network (GAT); and third, most of these methods have not been tested on a more complex classification task, such as cancer molecular subtypes. Results In this study, we propose a novel end-to-end multi-omics GNN framework for accurate and robust cancer subtype classification. The proposed model utilizes multi-omics data in the form of heterogeneous multi-layer graphs, which combine both inter-omics and intra-omic connections from established biological knowledge. The proposed model incorporates learned graph features and global genome features for accurate classification. We tested the proposed model on the Cancer Genome Atlas (TCGA) Pan-cancer dataset and TCGA breast invasive carcinoma (BRCA) dataset for molecular subtype and cancer subtype classification, respectively. The proposed model shows superior performance compared to four current state-of-the-art baseline models in terms of accuracy, F1 score, precision, and recall. The comparative analysis of GAT-based models and GCN-based models reveals that GAT-based models are preferred for smaller graphs with less information and GCN-based models are preferred for larger graphs with extra information.","['deep neural networks', 'graph neural network (GNN)', 'graph convolution network (GCN)', 'graph attention network (GAT)']","The research idea centers on the challenge of accurately classifying cancer molecular subtypes by integrating multi-omics data, which provides comprehensive insights into cancer molecular profiles and taxonomy. Current approaches to multi-omics integration often rely on limited types of biological connections and have not been thoroughly tested on complex classification tasks such as cancer subtyping. The study addresses the need for improved methods that better represent the structural complexity of biological systems to enhance cancer subtype classification. The primary objective of the study is to develop and evaluate a novel framework that integrates multi-omics data using heterogeneous multi-layer graphs combining both inter-omics and intra-omic connections based on established biological knowledge. This framework aims to improve the accuracy and robustness of cancer molecular subtype classification by leveraging combined graph features and global genome features, with validation performed on large cancer datasets to demonstrate superior performance over existing methods."
Biology,Geographically weighted machine learning for modeling spatial heterogeneity in traffic crash frequency and determinants in US,"Spatial analyses of traffic crashes have drawn much interest due to the nature of the spatial dependence and spatial heterogeneity in the crash data. This study makes the best of Geographically Weighted Random Forest (GW-RF) model to explore the local associations between crash frequency and various influencing factors in the US, including road network attributes, socio-economic characteristics, and land use factors collected from multiple data sources. Special emphasis is put on modeling the spatial heterogeneity in the effects of a factor on crash frequency in different geographical areas in a data-driven way. The GW-RF model outperforms global models (e.g. Random Forest) and conventional geographically weighted regression, demonstrating superior predictive accuracy and elucidating spatial variations. The GW-RF model reveals spatial distinctions in the effects of certain factors on crash frequency. For example, the importance of intersection density varies significantly across regions, with high significance in the southern and northeastern areas. Low-grade road density emerges as influential in specific cities. The findings highlight the significance of different factors in influencing crash frequency across zones. Road network factors, particularly intersection density, exhibit high importance universally, while socioeconomic variables demonstrate moderate effects. Interestingly, land use variables show relatively lower importance. The outcomes could help to allocate resources and implement tailored interventions to reduce the likelihood of crashes.","['Geographically Weighted Random Forest (GW-RF)', 'Random Forest']","The research idea centers on understanding the spatial dependence and heterogeneity in traffic crash data, recognizing that the frequency of crashes is influenced by various local factors such as road network attributes, socio-economic characteristics, and land use. The study addresses the need to explore how these factors differently affect crash frequency across diverse geographical areas in the United States. The primary objective of the study is to investigate the local associations between crash frequency and multiple influencing factors, with a focus on identifying spatial variations in their effects. This aims to highlight the significance of different factors in various regions to better inform resource allocation and the implementation of targeted interventions to reduce crash occurrences."
Biology,An artificial intelligence-assisted microfluidic colorimetric wearable sensor system for monitoring of key tear biomarkers,"Abstract The precise, simultaneous, and rapid detection of essential biomarkers in human tears is imperative for monitoring both ocular and systemic health. The utilization of a wearable colorimetric biochemical sensor exhibits potential in achieving swift and concurrent detection of pivotal biomarkers in tears. Nevertheless, challenges arise in the collection, interpretation, and sharing of data from the colorimetric sensor, thereby restricting the practical implementation of this technology. To overcome these challenges, this research introduces an artificial intelligence-assisted wearable microfluidic colorimetric sensor system (AI-WMCS) for rapid, non-invasive, and simultaneous detection of key biomarkers in human tears, including vitamin C, H + (pH), Ca 2+ , and proteins. The sensor consists of a flexible microfluidic epidermal patch that collects tears and facilitates the colorimetric reaction, and a deep-learning neural network-based cloud server data analysis system (CSDAS) embedded in a smartphone enabling color data acquisition, interpretation, auto-correction, and display. To enhance accuracy, a well-trained multichannel convolutional recurrent neural network (CNN-GRU) corrects errors in the interpreted concentration data caused by varying pH and color temperature in different measurements. The test set determination coefficients (R 2 ) of 1D-CNN-GRU for predicting pH and 3D-CNN-GRU for predicting the other three biomarkers were as high as 0.998 and 0.994, respectively. This correction significantly improves the accuracy of the predicted concentration, enabling accurate, simultaneous, and quick detection of four critical tear biomarkers using only minute amounts of tears ( ~ 20 μL). This research demonstrates the powerful integration of a flexible microfluidic colorimetric biosensor and deep-learning algorithm, which holds immense potential to revolutionize the fields of health monitoring.","['multichannel convolutional recurrent neural network (CNN-GRU)', '1D-CNN-GRU', '3D-CNN-GRU']","The research addresses the critical need for precise, simultaneous, and rapid detection of essential biomarkers in human tears to monitor both ocular and systemic health. Current challenges in collecting, interpreting, and sharing data from colorimetric sensors limit the practical application of this technology for tear biomarker detection. The primary objective of the study is to develop a wearable microfluidic colorimetric sensor capable of rapid, non-invasive, and simultaneous detection of key biomarkers in human tears, including vitamin C, pH, calcium ions, and proteins. This aims to enable accurate and quick monitoring of these critical tear biomarkers using only minute amounts of tears."
Biology,A comprehensive review of critical analysis of biodegradable waste PCM for thermal energy storage systems using machine learning and deep learning to predict dynamic behavior,"This article explores the use of phase change materials (PCMs) derived from waste, in energy storage systems. It emphasizes the potential of these PCMs in addressing concerns related to fossil fuel usage and environmental impact. This article also highlights the aspects of these PCMs including reduced reliance on renewable resources minimized greenhouse gas emissions and waste reduction. The study also discusses approaches such as integrating nanotechnology to enhance thermal conductivity and utilizing machine learning and deep learning techniques for predicting dynamic behavior. The article provides an overall view of research on biodegradable waste-based PCMs and how they can play a promising role in achieving energy-efficient and sustainable thermal storage systems. However, specific conclusions drawn from the presented results are not explicitly outlined, leaving room, for investigation and exploration in this evolving field. Artificial neural network (ANN) predictive models for thermal energy storage devices perform differently. With a 4% adjusted mean absolute error, the Gaussian radial basis function kernel Support Vector Regression (SVR) model captured heat-related charging and discharging issues. The ANN model predicted finned tube heat and heat flux better than the numerical model. SVM models outperformed ANN and ANFIS in some datasets. Material property predictions favored gradient boosting, but Linear Regression and SVR models performed better, emphasizing application- and dataset-specific model selection. These predictive models provide insights into the complex thermal performance of building structures, aiding in the design and operation of energy-efficient systems. Biodegradable waste-based PCMs' sustainability includes carbon footprint, waste reduction, biodegradability, and circular economy alignment. Nanotechnology, machine learning, and deep learning improve thermal conductivity and prediction. Circular economy principles include waste reduction and carbon footprint reduction. Specific results-based conclusions are not stated. Presenting a comprehensive overview of current research highlights biodegradable waste-based PCMs' potential for energy-efficient and sustainable thermal storage systems.","['machine learning', 'deep learning', 'Artificial neural network (ANN)', 'Gaussian radial basis function kernel Support Vector Regression (SVR)', 'Support Vector Machine (SVM)', 'Adaptive Neuro-Fuzzy Inference System (ANFIS)', 'gradient boosting', 'Linear Regression']","The research idea centers on exploring phase change materials (PCMs) derived from biodegradable waste as a sustainable solution for energy storage, addressing environmental concerns related to fossil fuel consumption, greenhouse gas emissions, and waste management. The study emphasizes the potential of these waste-based PCMs to reduce reliance on non-renewable resources while contributing to a circular economy through waste reduction and biodegradability. The primary objective of the study is to provide a comprehensive overview of current research on biodegradable waste-based PCMs and their role in achieving energy-efficient and sustainable thermal storage systems. It aims to highlight the benefits of these materials in minimizing environmental impact and promoting sustainable thermal energy storage."
Biology,Coupling Deep Learning and Physically Based Hydrological Models for Monthly Streamflow Predictions,"Abstract This study proposes a new hybrid model for monthly streamflow predictions by coupling a physically based distributed hydrological model with a deep learning (DL) model. Specifically, a simplified hydrological model is first developed by optimally selecting grid cells from a distributed hydrological model according to their soil moisture characteristics. It is then driven by bias corrected general circulation model (GCM) predictions to generate soil moistures for the forecasting months. Finally, model‐simulated soil moisture along with other predictors from multiple sources are used as inputs of the DL model to predict future monthly streamflows. The proposed hybrid model, using the simplified Variable Infiltration Capacity (VIC) as the hydrological model and the combination of Convolutional Neural Network and Gated Recurrent Unit (CNN‐GRU) as the DL model, is applied to predict 1‐, 3‐, and 6‐month ahead reservoir inflows for the Danjiangkou Reservoir in China. The results show that the hybrid model consistently performs better than VIC and CNN‐GRU models with great improvement in Kling‐Gupta efficiency (KGE) values for lead times up to 6 months. Additional tests indicate that hybrid models based on CNN‐GRU outperform those based on LASSO, XGBoost, CNN, and GRU models. Moreover, compared with the distributed hydrological model, the hybrid model greatly reduces the computation burden of rolling prediction. It also saves decision‐makers the time and effort of trying different combinations of predictors, which is indispensable when building DL models. Overall, the new hybrid model demonstrates great potential for monthly streamflow prediction where training data are limited.","['Convolutional Neural Network (CNN)', 'Gated Recurrent Unit (GRU)', 'CNN-GRU', 'LASSO', 'XGBoost', 'CNN', 'GRU']","The research addresses the challenge of accurately predicting monthly streamflow, which is crucial for effective water resource management and reservoir inflow forecasting. Traditional hydrological models can be complex and computationally demanding, while there is a need to improve prediction accuracy over various lead times. The study aims to develop a new approach that enhances monthly streamflow predictions by integrating soil moisture characteristics and multiple environmental predictors. The primary objective of the study is to improve the accuracy and efficiency of monthly streamflow forecasts for the Danjiangkou Reservoir in China by combining soil moisture information generated from a simplified hydrological model with additional environmental predictors to better predict reservoir inflows up to six months in advance."
Biology,MTMol-GPT: De novo multi-target molecular generation with transformer-based generative adversarial imitation learning,"De novo drug design is crucial in advancing drug discovery, which aims to generate new drugs with specific pharmacological properties. Recently, deep generative models have achieved inspiring progress in generating drug-like compounds. However, the models prioritize a single target drug generation for pharmacological intervention, neglecting the complicated inherent mechanisms of diseases, and influenced by multiple factors. Consequently, developing novel multi-target drugs that simultaneously target specific targets can enhance anti-tumor efficacy and address issues related to resistance mechanisms. To address this issue and inspired by Generative Pre-trained Transformers (GPT) models, we propose an upgraded GPT model with generative adversarial imitation learning for multi-target molecular generation called MTMol-GPT. The multi-target molecular generator employs a dual discriminator model using the Inverse Reinforcement Learning (IRL) method for a concurrently multi-target molecular generation. Extensive results show that MTMol-GPT generates various valid, novel, and effective multi-target molecules for various complex diseases, demonstrating robustness and generalization capability. In addition, molecular docking and pharmacophore mapping experiments demonstrate the drug-likeness properties and effectiveness of generated molecules potentially improve neuropsychiatric interventions. Furthermore, our model’s generalizability is exemplified by a case study focusing on the multi-targeted drug design for breast cancer. As a broadly applicable solution for multiple targets, MTMol-GPT provides new insight into future directions to enhance potential complex disease therapeutics by generating high-quality multi-target molecules in drug discovery.","['Generative Pre-trained Transformers (GPT)', 'generative adversarial imitation learning', 'Inverse Reinforcement Learning (IRL)']","The research idea centers on the challenge of developing novel multi-target drugs that can simultaneously interact with specific biological targets to enhance anti-tumor efficacy and overcome resistance mechanisms inherent in complex diseases. Traditional approaches often focus on single-target drug generation, which may not adequately address the multifaceted nature of disease mechanisms influenced by multiple factors. The study aims to improve therapeutic outcomes by generating multi-target molecules that can better address these complexities. The primary objective of the study is to develop a method for generating diverse, valid, and effective multi-target molecules that demonstrate drug-like properties and potential efficacy against complex diseases, including neuropsychiatric disorders and breast cancer. This approach seeks to provide new insights and solutions for advancing drug discovery focused on multi-target therapeutics."
Biology,AI-Driven Deep Learning Techniques in Protein Structure Prediction,"Protein structure prediction is important for understanding their function and behavior. This review study presents a comprehensive review of the computational models used in predicting protein structure. It covers the progression from established protein modeling to state-of-the-art artificial intelligence (AI) frameworks. The paper will start with a brief introduction to protein structures, protein modeling, and AI. The section on established protein modeling will discuss homology modeling, ab initio modeling, and threading. The next section is deep learning-based models. It introduces some state-of-the-art AI models, such as AlphaFold (AlphaFold, AlphaFold2, AlphaFold3), RoseTTAFold, ProteinBERT, etc. This section also discusses how AI techniques have been integrated into established frameworks like Swiss-Model, Rosetta, and I-TASSER. The model performance is compared using the rankings of CASP14 (Critical Assessment of Structure Prediction) and CASP15. CASP16 is ongoing, and its results are not included in this review. Continuous Automated Model EvaluatiOn (CAMEO) complements the biennial CASP experiment. Template modeling score (TM-score), global distance test total score (GDT_TS), and Local Distance Difference Test (lDDT) score are discussed too. This paper then acknowledges the ongoing difficulties in predicting protein structure and emphasizes the necessity of additional searches like dynamic protein behavior, conformational changes, and protein-protein interactions. In the application section, this paper introduces some applications in various fields like drug design, industry, education, and novel protein development. In summary, this paper provides a comprehensive overview of the latest advancements in established protein modeling and deep learning-based models for protein structure predictions. It emphasizes the significant advancements achieved by AI and identifies potential areas for further investigation.","['AlphaFold', 'AlphaFold2', 'RoseTTAFold', 'ProteinBERT']","The study addresses the importance of protein structure prediction for understanding protein function and behavior, highlighting the ongoing challenges in accurately determining protein structures. It emphasizes the need to explore dynamic protein behavior, conformational changes, and protein-protein interactions to improve the understanding of protein structures. The primary aim of the study is to provide a comprehensive overview of the advancements in protein structure prediction methods, covering both established protein modeling techniques and recent developments. Additionally, the study seeks to identify potential areas for further investigation to enhance the accuracy and applicability of protein structure predictions."
Biology,An Empirical Study on Correlations Between Deep Neural Network Fairness and Neuron Coverage Criteria,"Recently, with the widespread use of deep neural networks (DNNs) in high-stakes decision-making systems (such as fraud detection and prison sentencing), concerns have arisen about the fairness of DNNs in terms of the potential negative impact they may have on individuals and society. Therefore, fairness testing has become an important research topic in DNN testing. At the same time, the neural network coverage criteria (such as criteria based on neuronal activation) is considered as an adequacy test for DNN white-box testing. It is implicitly assumed that improving the coverage can enhance the quality of test suites. Nevertheless, the correlation between DNN fairness (a test property) and coverage criteria (a test method) has not been adequately explored. To address this issue, we conducted a systematic empirical study on seven coverage criteria, six fairness metrics, three fairness testing techniques, and five bias mitigation methods on five DNN models and nine fairness datasets to assess the correlation between coverage criteria and DNN fairness. Our study achieved the following findings: 1) with the increase in the size of the test suite, some of the coverage and fairness metrics changed significantly, as the size of the test suite increased; 2) the statistical correlation between coverage criteria and DNN fairness is limited; and 3) after bias mitigation for improving the fairness of DNN, the change pattern in coverage criteria is different; 4) Models debiased by different bias mitigation methods have a lower correlation between coverage and fairness compared to the original models. Our findings cast doubt on the validity of coverage criteria concerning DNN fairness (i.e., increasing the coverage may even have a negative impact on the fairness of DNNs). Therefore, we warn DNN testers against blindly pursuing higher coverage of coverage criteria at the cost of test properties of DNNs (such as fairness).","['deep neural networks (DNNs)', 'bias mitigation methods']","The research idea addresses concerns about fairness in decision-making systems that use deep neural networks, highlighting the potential negative impacts these systems may have on individuals and society. It emphasizes the importance of fairness testing in evaluating these systems and questions the assumed relationship between test coverage criteria and fairness. The study aims to investigate whether improving test coverage actually correlates with enhanced fairness in these networks. The primary objective of the study is to systematically assess the correlation between various coverage criteria and fairness metrics across multiple models and datasets. It seeks to determine how changes in test suite size and bias mitigation methods affect both coverage and fairness, ultimately evaluating the validity of using coverage criteria as an indicator of fairness in these systems."
Biology,An Early and Smart Detection of Corn Plant Leaf Diseases Using IoT and Deep Learning Multi-Models,"Plant leaf diseases have various causes, leading to severe disorders. The early and accurate detection and classification of these diseases are fundamental for fostering healthy crop production. In recent years, smart agricultural systems have garnered significant attention due to their capability to enhance efficiency by deploying sensor networks and Internet of Things (IoT) devices that collect and analyze environmental data. However, traditional plant disease detection methods are manual, time-consuming, and often need help handling the data's complexity and dynamism. These manual methods do not use heterogeneous data to make better decisions. Corn holds significant importance yet it faces numerous diseases that include main three diseases such as blight, common rust, and grey leaf spot. The advancement of computer technology has led to a pivotal focus on corn leaf diseases classification application based on deep learning. Convolutional Neural Networks (CNNs) have revealed remarkable achievements within Precision Agriculture (PA) due to their ability to enhance information. To this end, this work introduces a CNN-based architecture, the Multi-Model Fusion Network (MMF-Net). Its primary objective is to classify diseases within the realm of PA. MMF-Net integrates multi-contextual features using RL-block and PL-blocks 1 & 2, thus effectively combining different model streams trained on heterogeneous data. The RL-block uses spatial range to process coarse grained images to convolve the local context, while PL-block 1 extracts fine-grained global context by expanding the perceptual area of images. PL-block 2 deals with real-life environmental parameters as features. The extracted features are syndicated using multiple classifiers that ensemble three individual blocks at the decision level to improve the accuracy. After fusion, it uses adaptively the majority voting scheme to generate the final decision probability score of the base model. Multiple experiments are conducted involving the corn leaf diseases dataset and a real-life numerical dataset, generating an impressive 99.23% accuracy in the classification of corn leaf diseases. Overall, MMF-Net provides a promising and smart solution to identify plant leaf diseases in PA effectively.","['Convolutional Neural Networks (CNNs)', 'multiple classifiers ensemble']","The study addresses the problem of plant leaf diseases, which have various causes and lead to severe disorders affecting crop health. Early and accurate detection and classification of these diseases are essential for promoting healthy crop production, particularly in important crops like corn that suffer from diseases such as blight, common rust, and grey leaf spot. Traditional manual methods for detecting plant diseases are time-consuming and often inadequate in handling the complexity and variability of disease symptoms. The primary objective of this study is to improve the classification of corn leaf diseases by developing an approach that effectively integrates multiple contextual features and environmental parameters to enhance the accuracy of disease identification, thereby supporting better management and control of these diseases in agricultural settings."
Biology,Investigating the Impact of Train / Test Split Ratio on the Performance of Pre-Trained Models with Custom Datasets,"The proper allocation of data between training and testing is a critical factor influencing the performance of deep learning models, especially those built upon pre-trained architectures. Having the suitable training set size is an important factor for the classification model’s generalization performance. The main goal of this study is to find the appropriate training set size for three pre-trained networks using different custom datasets. For this aim, the study presented in this paper explores the effect of varying the train / test split ratio on the performance of three popular pre-trained models, namely MobileNetV2, ResNet50v2 and VGG19, with a focus on image classification task. In this work, three balanced datasets never seen by the models have been used, each containing 1000 images divided into two classes. The train / test split ratios used for this study are: 60-40, 70-30, 80-20 and 90-10. The focus was on the critical metrics of sensitivity, specificity and overall accuracy to evaluate the performance of the classifiers under the different ratios. Experimental results show that, the performance of the classifiers is affected by varying the training / testing split ratio for the three custom datasets. Moreover, with the three pre-trained models, using more than 70% of the dataset images for the training task gives better performance.","['MobileNetV2', 'ResNet50v2', 'VGG19']","The study addresses the challenge of determining the appropriate allocation of data between training and testing to optimize the performance of classification models in biological image analysis. Proper training set size is crucial for achieving good generalization performance when classifying biological images. The primary aim of the study is to identify the suitable training set size by examining the effect of different train/test split ratios on the classification performance using three balanced biological image datasets. The research focuses on evaluating how varying the proportion of training data influences sensitivity, specificity, and overall accuracy in classifying images into two classes."
Biology,"Comparative performance analysis of Boruta, SHAP, and Borutashap for disease diagnosis: A study with multiple machine learning algorithms","Interpretable machine learning models are instrumental in disease diagnosis and clinical decision-making, shedding light on relevant features. Notably, Boruta, SHAP (SHapley Additive exPlanations), and BorutaShap were employed for feature selection, each contributing to the identification of crucial features. These selected features were then utilized to train six machine learning algorithms, including LR, SVM, ETC, AdaBoost, RF, and LR, using diverse medical datasets obtained from public sources after rigorous preprocessing. The performance of each feature selection technique was evaluated across multiple ML models, assessing accuracy, precision, recall, and F1-score metrics. Among these, SHAP showcased superior performance, achieving average accuracies of 80.17%, 85.13%, 90.00%, and 99.55% across diabetes, cardiovascular, statlog, and thyroid disease datasets, respectively. Notably, the LGBM emerged as the most effective algorithm, boasting an average accuracy of 91.00% for most disease states. Moreover, SHAP enhanced the interpretability of the models, providing valuable insights into the underlying mechanisms driving disease diagnosis. This comprehensive study contributes significant insights into feature selection techniques and machine learning algorithms for disease diagnosis, benefiting researchers and practitioners in the medical field. Further exploration of feature selection methods and algorithms holds promise for advancing disease diagnosis methodologies, paving the way for more accurate and interpretable diagnostic models.","['Boruta', 'SHAP (SHapley Additive exPlanations)', 'LR', 'SVM', 'AdaBoost', 'RF', 'LGBM']","The study addresses the challenge of identifying crucial features that contribute to accurate disease diagnosis and clinical decision-making. It highlights the importance of selecting relevant biological markers to improve understanding of the underlying mechanisms driving various diseases. The primary aim of the research is to evaluate different feature selection techniques in order to identify key features associated with diseases such as diabetes, cardiovascular conditions, statlog, and thyroid disorders. By comparing these techniques, the study seeks to enhance the accuracy and interpretability of disease diagnosis, ultimately benefiting medical research and practice."
Biology,Machinability investigation of natural fibers reinforced polymer matrix composite under drilling: Leveraging machine learning in bioengineering applications,"The growing demand for fiber-reinforced polymer (FRP) in industrial applications has prompted the exploration of natural fiber-based composites as a viable alternative to synthetic fibers. Using jute–rattan fiber-reinforced composite offers the potential for environmentally sustainable waste material decomposition and cost reduction compared to conventional fiber materials. This article focuses on the impact of different machining constraints on surface roughness and delamination during the drilling process of the jute–rattan FRP composite. Inspired by this unexplored research area, this article emphasizes the influence of various machining constraints on surface roughness and delamination in drilling jute–rattan FRP composite. Response surface methodology designs the experiment using drill bit material, spindle speed, and feed rate as input variables to measure surface roughness and delamination factors. The technique of order of preference by similarity to the ideal solution method is used to optimize the machining parameters, and for predicting surface roughness and delamination, two machine learning-based models named random forest (RF) and support vector machine (SVM) are utilized. To evaluate the accuracy of the predicted values, the correlation coefficient (R2), mean absolute percentage error, and mean squared error were used. RF performed better in comparison with SVM, with a higher value of R2 for both testing and training datasets, which is 0.997, 0.981, and 0.985 for surface roughness, entry delamination, and exit delamination, respectively. Hence, this study presents an innovative methodology for predicting surface roughness and delamination through machine learning techniques.","['random forest (RF)', 'support vector machine (SVM)']","The research idea centers on addressing the increasing demand for fiber-reinforced polymer (FRP) materials in industrial applications by exploring natural fiber-based composites, specifically jute–rattan fiber-reinforced composites, as environmentally sustainable and cost-effective alternatives to synthetic fibers. The study highlights the importance of understanding how different machining constraints affect surface roughness and delamination during the drilling process of these natural fiber composites. The primary objective of the study is to investigate the influence of various machining parameters, such as drill bit material, spindle speed, and feed rate, on surface roughness and delamination in the drilling of jute–rattan FRP composites. The research aims to optimize these machining parameters to improve the quality and performance of the drilled composite materials."
Biology,Artificial intelligence alphafold model for molecular biology and drug discovery: a machine-learning-driven informatics investigation,"AlphaFold model has reshaped biological research. However, vast unstructured data in the entire AlphaFold field requires further analysis to fully understand the current research landscape and guide future exploration. Thus, this scientometric analysis aimed to identify critical research clusters, track emerging trends, and highlight underexplored areas in this field by utilizing machine-learning-driven informatics methods. Quantitative statistical analysis reveals that the AlphaFold field is enjoying an astonishing development trend (Annual Growth Rate = 180.13%) and global collaboration (International Co-authorship = 33.33%). Unsupervised clustering algorithm, time series tracking, and global impact assessment point out that Cluster 3 (Artificial Intelligence-Powered Advancements in AlphaFold for Structural Biology) has the greatest influence (Average Citation = 48.36 ± 184.98). Additionally, regression curve and hotspot burst analysis highlight ""structure prediction"" (s = 12.40, R2 = 0.9480, p = 0.0051), ""artificial intelligence"" (s = 5.00, R2 = 0.8096, p = 0.0375), ""drug discovery"" (s = 1.90, R2 = 0.7987, p = 0.0409), and ""molecular dynamics"" (s = 2.40, R2 = 0.8000, p = 0.0405) as core hotspots driving the research frontier. More importantly, the Walktrap algorithm further reveals that ""structure prediction, artificial intelligence, molecular dynamics"" (Relevance Percentage[RP] = 100%, Development Percentage[DP] = 25.0%), ""sars-cov-2, covid-19, vaccine design"" (RP = 97.8%, DP = 37.5%), and ""homology modeling, virtual screening, membrane protein"" (RP = 89.9%, DP = 26.1%) are closely intertwined with the AlphaFold model but remain underexplored, which implies a broad exploration space. In conclusion, through the machine-learning-driven informatics methods, this scientometric analysis offers an objective and comprehensive overview of global AlphaFold research, identifying critical research clusters and hotspots while prospectively pointing out underexplored critical areas.",['unsupervised clustering algorithm'],"The research idea centers on the need to better understand the rapidly growing field of AlphaFold-related biological research by examining the vast and unstructured body of work to clarify the current research landscape and guide future scientific exploration. Despite significant advancements in protein structure prediction and related areas, there remain critical underexplored topics that could benefit from further investigation. The primary objective of the study is to identify key research clusters, track emerging trends, and highlight underexplored areas within the AlphaFold field to provide a comprehensive overview of global research efforts. This aims to facilitate a clearer understanding of influential topics and potential directions for future biological research involving protein structure prediction and related applications."
Biology,Exploring the role of skin temperature in thermal sensation and thermal comfort: A comprehensive review,"The role of skin temperature as a determinant of human thermal sensation and comfort has gained increasing recognition, prompting a need for a systematic review. This review examines the relationship between skin temperature and thermal sensation, synthesizing insights from 172 studies published since 2000. It uniquely focuses on the indispensable roles of local and mean skin temperatures, a perspective not comprehensively explored in previous literature. The review reveals that the most common measurement points for skin temperature are the face and hands, attributed to their higher thermal sensitivity and the practical ease of measurement. It establishes a clear linear relationship between mean skin temperature and user thermal sensation, though affected by the choice of measurement locations and number of points. A notable finding is the varying impact of local skin temperature on overall thermal sensation in changing environments, with local heating less influential than cooling. The review also uncovers significant demographic variations in thermal sensation, strongly influenced by differing skin temperatures across age groups, genders, and climatic regions. For example, elderly populations exhibit a decreased temperature sensitivity, especially towards warmth. Gender differences are also significant, with females experiencing higher skin temperatures in warmer environments and lower in colder ones. Machine learning (ML)-based methods, especially classification tree-based and support vector machine (SVM) techniques, dominate in predicting thermal sensation and comfort, leveraging skin temperature data. While ML methods are prevalent, statistical regression-based approaches offer valuable empirical insights. Thermo-physiological model-based methods provide reliable results by incorporating detailed skin temperature dynamics. The review identifies a gap in understanding how gender, age, and regional differences influence thermal comfort in diverse environments. The study recommends conducting more nuanced experiments to dissect the impact of these factors and proposes the integration of individual demographic variables into ML models to personalize thermal comfort predictions.","['support vector machine (SVM)', 'statistical regression-based approaches']","The research idea centers on the increasing recognition of skin temperature as a key determinant of human thermal sensation and comfort, highlighting the need to systematically understand the relationship between skin temperature and thermal perception. This study addresses gaps in previous literature by focusing on the distinct roles of local and mean skin temperatures and their influence on thermal sensation across different body regions. It also considers demographic variations, such as age, gender, and climatic region, which significantly affect skin temperature and consequently thermal comfort. The primary objective of the study is to review and synthesize findings from numerous studies to clarify how local and mean skin temperatures relate to human thermal sensation, with particular attention to demographic differences and environmental conditions. Additionally, the study aims to identify gaps in current knowledge regarding the influence of gender, age, and regional factors on thermal comfort and to recommend further research to better understand these effects."
Biology,Motif-Aware miRNA-Disease Association Prediction via Hierarchical Attention Network,"As post-transcriptional regulators of gene expression, micro-ribonucleic acids (miRNAs) are regarded as potential biomarkers for a variety of diseases. Hence, the prediction of miRNA-disease associations (MDAs) is of great significance for an in-depth understanding of disease pathogenesis and progression. Existing prediction models are mainly concentrated on incorporating different sources of biological information to perform the MDA prediction task while failing to consider the fully potential utility of MDA network information at the motif-level. To overcome this problem, we propose a novel motif-aware MDA prediction model, namely MotifMDA, by fusing a variety of high- and low-order structural information. In particular, we first design several motifs of interest considering their ability to characterize how miRNAs are associated with diseases through different network structural patterns. Then, MotifMDA adopts a two-layer hierarchical attention to identify novel MDAs. Specifically, the first attention layer learns high-order motif preferences based on their occurrences in the given MDA network, while the second one learns the final embeddings of miRNAs and diseases through coupling high- and low-order preferences. Experimental results on two benchmark datasets have demonstrated the superior performance of MotifMDA over several state-of-the-art prediction models. This strongly indicates that accurate MDA prediction can be achieved by relying solely on MDA network information. Furthermore, our case studies indicate that the incorporation of motif-level structure information allows MotifMDA to discover novel MDAs from different perspectives. The data and codes are available at <uri xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">https://github.com/stevejobws/MotifMDA.</uri>",['two-layer hierarchical attention'],"The study addresses the importance of micro-ribonucleic acids (miRNAs) as post-transcriptional regulators of gene expression and their potential role as biomarkers for various diseases. Understanding the associations between miRNAs and diseases is crucial for gaining deeper insights into disease pathogenesis and progression. The primary aim of the study is to improve the prediction of miRNA-disease associations by exploring the utility of network information at the motif level, which characterizes how miRNAs are linked to diseases through different structural patterns. This approach seeks to identify novel miRNA-disease associations to enhance the understanding of their biological relationships."
Biology,"Artificial intelligence in lung cancer screening: Detection, classification, prediction, and prognosis","Abstract Background The exceptional capabilities of artificial intelligence (AI) in extracting image information and processing complex models have led to its recognition across various medical fields. With the continuous evolution of AI technologies based on deep learning, particularly the advent of convolutional neural networks (CNNs), AI presents an expanded horizon of applications in lung cancer screening, including lung segmentation, nodule detection, false‐positive reduction, nodule classification, and prognosis. Methodology This review initially analyzes the current status of AI technologies. It then explores the applications of AI in lung cancer screening, including lung segmentation, nodule detection, and classification, and assesses the potential of AI in enhancing the sensitivity of nodule detection and reducing false‐positive rates. Finally, it addresses the challenges and future directions of AI in lung cancer screening. Results AI holds substantial prospects in lung cancer screening. It demonstrates significant potential in improving nodule detection sensitivity, reducing false‐positive rates, and classifying nodules, while also showing value in predicting nodule growth and pathological/genetic typing. Conclusions AI offers a promising supportive approach to lung cancer screening, presenting considerable potential in enhancing nodule detection sensitivity, reducing false‐positive rates, and classifying nodules. However, the universality and interpretability of AI results need further enhancement. Future research should focus on the large‐scale validation of new deep learning‐based algorithms and multi‐center studies to improve the efficacy of AI in lung cancer screening.","['deep learning', 'convolutional neural networks (CNNs)']","The study addresses the critical challenge of improving lung cancer screening by enhancing the detection and classification of lung nodules, which are essential for early diagnosis and effective treatment. Lung cancer screening currently faces limitations in sensitivity and false-positive rates, impacting the accuracy and reliability of identifying malignant nodules. The research aims to explore approaches that can increase the sensitivity of nodule detection, reduce false-positive findings, and improve the classification of lung nodules. Additionally, the study seeks to evaluate methods for predicting nodule growth and understanding pathological and genetic characteristics to support better clinical decision-making in lung cancer screening."
Biology,Distributed Hydrological Modeling With Physics‐Encoded Deep Learning: A General Framework and Its Application in the Amazon,"Abstract While deep learning (DL) models exhibit superior simulation accuracy over traditional distributed hydrological models (DHMs), their main limitations lie in opacity and the absence of underlying physical mechanisms. The pursuit of synergies between DL and DHMs is an engaging research domain, yet a definitive roadmap remains elusive. In this study, a novel framework that seamlessly integrates a process‐based hydrological model encoded as a neural network (NN), an additional NN for mapping spatially distributed and physically meaningful parameters from watershed attributes, and NN‐based replacement models representing inadequately understood processes is developed. Multi‐source observations are used as training data, and the framework is fully differentiable, enabling fast parameter tuning by backpropagation. A hybrid DL model of the Amazon Basin (∼6 × 10 6 km 2 ) was established based on the framework, and HydroPy, a global‐scale DHM, was encoded as its physical backbone. Trained simultaneously with streamflow observations and Gravity Recovery and Climate Experiment satellite data, the hybrid model yielded median Nash‐Sutcliffe efficiencies of 0.83 and 0.77 for dynamic and distributed simulations of streamflow and total water storage, respectively, 41% and 35% higher than those of the original HydroPy model. Replacing the original Penman‒Monteith formulation in HydroPy with a replacement NN produces more plausible potential evapotranspiration (PET) estimates, and unravels the spatial pattern of PET in this giant basin. The NN used for parameterization was interpreted to identify the factors controlling the spatial variability in key parameters. Overall, this study lays out a feasible technical roadmap for distributed hydrological modeling in the big data era.","['deep learning (DL) models', 'neural network (NN)', 'NN-based replacement models', 'backpropagation']","The research idea centers on addressing the limitations of traditional distributed hydrological models, which often lack accuracy and fail to fully capture underlying physical mechanisms in simulating hydrological processes. There is a need to improve the representation of complex watershed dynamics and better understand spatial variability in hydrological parameters across large basins such as the Amazon. The study aims to enhance hydrological modeling by integrating physically meaningful watershed attributes and improving the estimation of key processes like potential evapotranspiration. The primary objective of the study is to develop a comprehensive framework that improves the simulation accuracy of hydrological variables, such as streamflow and total water storage, across the Amazon Basin by incorporating spatially distributed parameters and refining poorly understood processes. The study also seeks to identify the factors controlling spatial variability in key hydrological parameters and to provide a more plausible estimation of potential evapotranspiration patterns within the basin."
Biology,Characterizing land use/land cover change dynamics by an enhanced random forest machine learning model: a Google Earth Engine implementation,"Abstract Land use and land cover (LULC) analysis is crucial for understanding societal development and assessing changes during the Anthropocene era. Conventional LULC mapping faces challenges in capturing changes under cloud cover and limited ground truth data. To enhance the accuracy and comprehensiveness of the descriptions of LULC changes, this investigation employed a combination of advanced techniques. Specifically, multitemporal 30 m resolution Landsat-8 satellite imagery was utilized, in addition to the cloud computing capabilities of the Google Earth Engine (GEE) platform. Additionally, the study incorporated the random forest (RF) algorithm. This study aimed to generate continuous LULC maps for 2014 and 2020 for the Shrirampur area of Maharashtra, India. A novel multiple composite RF approach based on LULC classification was utilized to generate the final LULC classification maps utilizing the RF-50 and RF-100 tree models. Both RF models utilized seven input bands (B1 to B7) as the dataset for LULC classification. By incorporating these bands, the models were able to influence the spectral information captured by each band to classify the LULC categories accurately. The inclusion of multiple bands enhanced the discrimination capabilities of the classifiers, increasing the comprehensiveness of the assessment of the LULC classes. The analysis indicated that RF-100 exhibited higher training and validation/testing accuracy for 2014 and 2020 (0.99 and 0.79/0.80, respectively). The study further revealed that agricultural land, built-up land, and water bodies have changed adequately and have undergone substantial variation among the LULC classes in the study area. Overall, this research provides novel insights into the application of machine learning (ML) models for LULC mapping and emphasizes the importance of selecting the optimal tree combination for enhancing the accuracy and reliability of LULC maps based on the GEE and different RF tree models. The present investigation further enabled the interpretation of pixel-level LULC interactions while improving image classification accuracy and suggested the best models for the classification of LULC maps through the identification of changes in LULC classes.",['random forest (RF) algorithm'],"The study addresses the challenge of accurately mapping land use and land cover (LULC) changes, which is essential for understanding societal development and environmental transformations during the Anthropocene era. Conventional methods face difficulties in capturing changes due to factors like cloud cover and limited ground truth data, which can hinder comprehensive assessments of LULC dynamics. The research focuses on improving the accuracy and comprehensiveness of LULC change descriptions in the Shrirampur area of Maharashtra, India, by generating continuous LULC maps for the years 2014 and 2020. The primary objective of the study is to produce detailed and reliable LULC classification maps that reveal substantial variations in agricultural land, built-up land, and water bodies, thereby enhancing the understanding of spatial and temporal changes in land cover within the study region."
Biology,DeepKEGG: a multi-omics data integration framework with biological insights for cancer recurrence prediction and biomarker discovery,"Abstract Deep learning-based multi-omics data integration methods have the capability to reveal the mechanisms of cancer development, discover cancer biomarkers and identify pathogenic targets. However, current methods ignore the potential correlations between samples in integrating multi-omics data. In addition, providing accurate biological explanations still poses significant challenges due to the complexity of deep learning models. Therefore, there is an urgent need for a deep learning-based multi-omics integration method to explore the potential correlations between samples and provide model interpretability. Herein, we propose a novel interpretable multi-omics data integration method (DeepKEGG) for cancer recurrence prediction and biomarker discovery. In DeepKEGG, a biological hierarchical module is designed for local connections of neuron nodes and model interpretability based on the biological relationship between genes/miRNAs and pathways. In addition, a pathway self-attention module is constructed to explore the correlation between different samples and generate the potential pathway feature representation for enhancing the prediction performance of the model. Lastly, an attribution-based feature importance calculation method is utilized to discover biomarkers related to cancer recurrence and provide a biological interpretation of the model. Experimental results demonstrate that DeepKEGG outperforms other state-of-the-art methods in 5-fold cross validation. Furthermore, case studies also indicate that DeepKEGG serves as an effective tool for biomarker discovery. The code is available at https://github.com/lanbiolab/DeepKEGG.","['deep learning-based multi-omics data integration methods', 'attribution-based feature importance calculation method']","The study addresses the challenge of understanding cancer development by integrating multi-omics data, with a focus on revealing mechanisms of cancer recurrence and identifying relevant biomarkers. It highlights the limitations of current approaches that overlook potential correlations between samples and struggle to provide accurate biological explanations due to the complexity of existing models. The primary aim of the study is to develop a method for multi-omics data integration that explores the correlations between samples and enhances interpretability to improve cancer recurrence prediction and biomarker discovery. This approach seeks to provide meaningful biological insights into cancer recurrence and facilitate the identification of pathogenic targets."
Biology,Hyperspectral Image Analysis and Machine Learning Techniques for Crop Disease Detection and Identification: A Review,"Originally, the use of hyperspectral images was for military applications, but their use has been extended to precision agriculture. In particular, they are used for activities related to crop classification or disease detection, combining these hyperspectral images with machine learning techniques and algorithms. The study of hyperspectral images has a wide range of wavelengths for observation. These wavelengths allow for monitoring agricultural crops such as cereals, oilseeds, vegetables, and fruits, and other applications. In the ranges of these wavelengths, crop conditions such as maturity index and nutrient status, or the early detection of some diseases that cause losses in crops, can be studied and diagnosed. Therefore, this article proposes a technical review of the main applications of hyperspectral images in agricultural crops and perspectives and challenges that combine artificial intelligence algorithms such as machine learning and deep learning in the classification and detection of diseases of crops such as cereals, oilseeds, fruits, and vegetables. A systematic review of the scientific literature was carried out using a 10-year observation window to determine the evolution of the integration of these technological tools that support sustainable agriculture; among the findings, information on the most documented crops is highlighted, among which are some cereals and citrus fruits due to their high demand and large cultivation areas, as well as information on the main fruits and vegetables that are integrating these technologies. Also, the main artificial intelligence algorithms that are being worked on are summarized and classified, as well as the wavelength ranges for the prediction, disease detection, and analysis of other tasks of physiological characteristics used for sustainable production. This review can be useful as a reference for future research, based mainly on detection, classification, and other tasks in agricultural crops and decision making, to implement the most appropriate artificial intelligence algorithms.","['machine learning', 'deep learning']","The research idea centers on the expanding use of hyperspectral images beyond their original military applications to precision agriculture, particularly for monitoring and managing crop health. These images cover a wide range of wavelengths that enable the study of various crop conditions such as maturity index, nutrient status, and early disease detection, which are critical for reducing losses in crops like cereals, oilseeds, vegetables, and fruits. The primary objective of the study is to provide a comprehensive review of the main applications of hyperspectral imaging in agricultural crops, highlighting the evolution and current state of their use in crop classification and disease detection. This review aims to summarize the documented crops, wavelength ranges, and key findings related to sustainable agricultural production, serving as a reference for future research focused on improving crop monitoring and management."
Biology,Optimizing cancer classification: a hybrid RDO-XGBoost approach for feature selection and predictive insights,"The identification of relevant biomarkers from high-dimensional cancer data remains a significant challenge due to the complexity and heterogeneity inherent in various cancer types. Conventional feature selection methods often struggle to effectively navigate the vast solution space while maintaining high predictive accuracy. In response to these challenges, we introduce a novel feature selection approach that integrates Random Drift Optimization (RDO) with XGBoost, specifically designed to enhance the performance of cancer classification tasks. Our proposed framework not only improves classification accuracy but also offers valuable insights into the underlying biological mechanisms driving cancer progression. Through comprehensive experiments conducted on real-world cancer datasets, including Central Nervous System (CNS), Leukemia, Breast, and Ovarian cancers, we demonstrate the efficacy of our method in identifying a smaller subset of unique and relevant genes. This selection results in significantly improved classification efficiency and accuracy. When compared with popular classifiers such as Support Vector Machine, K-Nearest Neighbor, and Naive Bayes, our approach consistently outperforms these models in terms of both accuracy and F-measure metrics. For instance, our framework achieved an accuracy of 97.24% in the CNS dataset, 99.14% in Leukemia, 95.21% in Ovarian, and 87.62% in Breast cancer, showcasing its robustness and effectiveness across different types of cancer data. These results underline the potential of our RDO-XGBoost framework as a promising solution for feature selection in cancer data analysis, offering enhanced predictive performance and valuable biological insights.","['XGBoost', 'Support Vector Machine', 'K-Nearest Neighbor', 'Naive Bayes']","The identification of relevant biomarkers from high-dimensional cancer data remains a significant challenge due to the complexity and heterogeneity inherent in various cancer types. Conventional methods often struggle to effectively navigate the vast solution space while maintaining high accuracy in cancer classification. The primary aim of this study is to improve the identification of a smaller subset of unique and relevant genes that can enhance classification efficiency and accuracy across different types of cancer, including Central Nervous System, Leukemia, Breast, and Ovarian cancers. This objective seeks to provide valuable insights into the underlying biological mechanisms driving cancer progression and to demonstrate the effectiveness of the proposed approach in cancer data analysis."
Biology,Cross-Domain Class Incremental Broad Network for Continuous Diagnosis of Rotating Machinery Faults Under Variable Operating Conditions,"Machine learning models have been widely successful in the field of intelligent fault diagnosis. Most of the existing machine learning models are deployed in static environments and rely on precollected datasets for offline training, which makes it impossible to update the models further once they are established. However, in the open and dynamic environment in reality, there is always incoming data in the form of streams, including new categories of data that are constantly generated over time. In addition, the operating conditions of mechanical equipment are time-varying, which results in continuous stream data that are nonindependently and homogeneously distributed. In industrial applications, the diagnosis problem of nonindependent and identically distributed continuous streaming data is referred to as the cross-domain class incremental diagnosis problem. To address the cross-domain class incremental problem, a novel cross-domain class incremental broad network (CDCIBN) is proposed. Specifically, to solve the nonindependent identically distributed problem, a novel domain-adaptation learning loss function is first designed, which enables the conventional broad network to handle the category increment task well. Then, a cross-domain class incremental learning mechanism is designed, which learns new categories while retaining the knowledge of old categories well enough without replaying old category data. The effectiveness of the proposed method is evaluated through multiple mechanical failure increment cases. Experimental analysis demonstrates that the designed CDCIBN has significant advantages in the variable working condition class incremental application.",['cross-domain class incremental learning mechanism'],"The research idea addresses the challenge of diagnosing faults in mechanical equipment operating under dynamic and continuously changing conditions, where data are received as streams that include new and evolving categories over time. Traditional approaches rely on static datasets and cannot adapt to new information once established, which limits their effectiveness in real-world environments with time-varying operating conditions and nonindependently distributed data. The study focuses on the problem of diagnosing faults when data distributions change across different domains and new fault categories emerge incrementally. The primary objective of the study is to develop a method that can effectively handle the diagnosis of mechanical faults in such cross-domain, class-incremental scenarios by learning new fault categories while retaining knowledge of previously learned categories, without requiring access to old data. The aim is to improve fault diagnosis performance under variable working conditions and continuous data streams in industrial applications."
Biology,Real-life data-driven model predictive control for building energy systems comparing different machine learning models,"By considering forecasts and exploiting storage effects, model predictive control can achieve significant energy and cost savings in the building sector. However, due to the high individual modeling effort, model predictive control lacks practical applicability. For that reason, data-driven process models, approximating the system behavior based on measurements, have become increasingly popular in recent years. Still, scientific literature lacks consent about the most promising model types and efficient workflows to integrate different machine learning models into a model predictive controller. With this work, we present a workflow to provide efficient model predictive controllers based on measurement data automatically. The main idea is to translate different machine learning models into optimization syntax to enable efficient optimization with full access to gradients. We currently consider artificial neural networks, gaussian process regression, and simple linear regression process models. We use a generic model ontology to automatize the controller generation further and test the methodology on two real-life use cases. The first use case is the application of five office rooms with smart thermostat valves. The second use case is a test hall with an air handling unit and a concrete core activation. Using only two days of initial training data, we deploy controllers based on the different model types for six weeks in the offices and apply online learning to improve the models continuously. We observe only minor differences in controller performance despite the artificial neural networks showing the highest prediction accuracy. The second use case shows that the simple linear models require less controller tuning effort. Thus, for practical applications, we recommend linear regression models.","['artificial neural networks', 'gaussian process regression', 'linear regression']","The research idea addresses the challenge of achieving significant energy and cost savings in the building sector through advanced control strategies, while highlighting the practical limitations caused by the high individual modeling effort required. There is a need to identify the most effective approaches to represent system behavior based on measurements to improve the applicability of these control strategies in real-world settings. The primary objective of the study is to develop and evaluate a workflow that enables the automatic generation of efficient control strategies based on measurement data, comparing different types of process models in real-life building use cases. The study aims to determine which model types offer the best balance between prediction accuracy and practical implementation effort to guide recommendations for their use in building energy management."
Biology,Enhancing MPPT performance for partially shaded photovoltaic arrays through backstepping control with Genetic Algorithm-optimized gains,"As the significance and complexity of solar panel performance, particularly at their maximum power point (MPP), continue to grow, there is a demand for improved monitoring systems. The presence of variable weather conditions in Maroua, including potential partial shadowing caused by cloud cover or urban buildings, poses challenges to the efficiency of solar systems. This study introduces a new approach to tracking the Global Maximum Power Point (GMPP) in photovoltaic systems within the context of solar research conducted in Cameroon. The system utilizes Genetic Algorithm (GA) and Backstepping Controller (BSC) methodologies. The Backstepping Controller (BSC) dynamically adjusts the duty cycle of the Single Ended Primary Inductor Converter (SEPIC) to align with the reference voltage of the Genetic Algorithm (GA) in Maroua's dynamic environment. This environment, characterized by intermittent sunlight and the impact of local factors and urban shadowing, affects the production of energy. The Genetic Algorithm is employed to enhance the efficiency of BSC gains in Maroua's solar environment. This optimization technique expedites the tracking process and minimizes oscillations in the GMPP. The adaptability of the learning algorithm to specific conditions improves energy generation, even in the challenging environment of Maroua. This study introduces a novel approach to enhance the efficiency of photovoltaic systems in Maroua, Cameroon, by tailoring them to the specific solar dynamics of the region. In terms of performance, our approach surpasses the INC-BSC, P&O-BSC, GA-BSC, and PSO-BSC methodologies. In practice, the stabilization period following shadowing typically requires fewer than three iterations. Additionally, our Maximum Power Point Tracking (MPPT) technology is based on the Global Maximum Power Point (GMPP) methodology, contrasting with alternative technologies that prioritize the Local Maximum Power Point (LMPP). This differentiation is particularly relevant in areas with partial shading, such as Maroua, where the use of LMPP-based technologies can result in power losses. The proposed method demonstrates significant performance by achieving a minimum 33% reduction in power losses.",['Genetic Algorithm (GA)'],"The research idea centers on addressing the challenges posed by variable weather conditions and partial shadowing from cloud cover or urban buildings on the efficiency of solar panel performance, particularly in the context of Maroua, Cameroon. The complexity of maintaining optimal energy production at the maximum power point (MPP) under these dynamic environmental factors motivates the need for improved approaches tailored to the specific solar dynamics of the region. The primary objective of the study is to enhance the efficiency of photovoltaic systems in Maroua by developing a novel approach for tracking the Global Maximum Power Point (GMPP) that reduces power losses caused by partial shading. This approach aims to improve energy generation stability and performance in the region’s challenging solar environment, achieving significant reductions in power losses compared to existing methods."
Biology,"funspace: An R package to build, analyse and plot functional trait spaces","Abstract Aim Functional trait space analyses are pivotal to describe and compare organisms' functional diversity across the tree of life. Yet, there is no single application that streamlines the many sometimes‐troublesome steps needed to build and analyse functional trait spaces. Innovation To fill this gap, we propose funspace , an R package to easily handle bivariate and multivariate functional trait space analyses. The six functions that constitute the package can be grouped in three modules: ‘Building and exploring’, ‘Mapping’ and ‘Plotting’. The building and exploring module defines the main features of a functional trait space (e.g. functional diversity metrics) by leveraging kernel density‐based methods. The mapping module uses general additive models to map how a target variable distributes within a trait space. The plotting module provides many options for creating flexible and publication‐ready figures representing the outputs obtained from previous modules. We provide a worked example to demonstrate a complete funspace workflow. Main Conclusions funspace will provide researchers working with functional traits across the tree of life with a new tool to easily explore: (i) the main features of any functional trait space, (ii) the relationship between a functional trait space and any other biological or non‐biological factor that might contribute to shaping species' functional diversity.","['kernel density-based methods', 'general additive models']","The study addresses the challenge of describing and comparing organisms' functional diversity across the tree of life through functional trait space analyses, which currently involve multiple complex and sometimes troublesome steps. There is a need for a streamlined approach to facilitate these analyses and better understand the main features of functional trait spaces and their relationship with various biological or non-biological factors. The primary aim of the study is to provide researchers with a comprehensive tool that enables easy exploration of functional trait spaces, including defining their main characteristics and examining how different factors contribute to shaping species' functional diversity. This objective is demonstrated through a complete workflow that highlights the utility of the proposed approach in studying functional traits across diverse organisms."
Biology,GAM-MDR: probing miRNA–drug resistance using a graph autoencoder based on random path masking,"Abstract MicroRNAs (miRNAs) are found ubiquitously in biological cells and play a pivotal role in regulating the expression of numerous target genes. Therapies centered around miRNAs are emerging as a promising strategy for disease treatment, aiming to intervene in disease progression by modulating abnormal miRNA expressions. The accurate prediction of miRNA–drug resistance (MDR) is crucial for the success of miRNA therapies. Computational models based on deep learning have demonstrated exceptional performance in predicting potential MDRs. However, their effectiveness can be compromised by errors in the data acquisition process, leading to inaccurate node representations. To address this challenge, we introduce the GAM-MDR model, which combines the graph autoencoder (GAE) with random path masking techniques to precisely predict potential MDRs. The reliability and effectiveness of the GAM-MDR model are mainly reflected in two aspects. Firstly, it efficiently extracts the representations of miRNA and drug nodes in the miRNA–drug network. Secondly, our designed random path masking strategy efficiently reconstructs critical paths in the network, thereby reducing the adverse impact of noisy data. To our knowledge, this is the first time that a random path masking strategy has been integrated into a GAE to infer MDRs. Our method was subjected to multiple validations on public datasets and yielded promising results. We are optimistic that our model could offer valuable insights for miRNA therapeutic strategies and deepen the understanding of the regulatory mechanisms of miRNAs. Our data and code are publicly available at GitHub:https://github.com/ZZCrazy00/GAM-MDR.","['deep learning', 'graph autoencoder (GAE)']","The study addresses the critical role of microRNAs (miRNAs) in regulating gene expression and the emerging potential of miRNA-centered therapies for disease treatment by modulating abnormal miRNA expressions. A key challenge in advancing these therapies is the accurate prediction of miRNA–drug resistance (MDR), which is essential for their success. The primary aim of the study is to improve the prediction of potential miRNA–drug resistance to support the development of effective miRNA therapeutic strategies. This objective seeks to enhance the understanding of the regulatory mechanisms of miRNAs and contribute valuable insights for intervening in disease progression."
Biology,Integrative analysis of AI-driven optimization in HIV treatment regimens,"The integration of artificial intelligence (AI) into HIV treatment regimens has revolutionized the approach to personalized care and optimization strategies. This study presents an in-depth analysis of the role of AI in transforming HIV treatment, focusing on its ability to tailor therapy to individual patient needs and enhance treatment outcomes. AI-driven optimization in HIV treatment involves the utilization of advanced algorithms and computational techniques to analyze vast amounts of patient data, including genetic information, viral load measurements, and treatment history. By harnessing the power of machine learning and predictive analytics, AI algorithms can identify patterns and trends in patient data that may not be readily apparent to human clinicians. One of the key benefits of AI-driven optimization is its ability to personalize treatment regimens based on individual patient characteristics and disease progression. By considering factors such as drug resistance profiles, comorbidities, and lifestyle factors, AI algorithms can recommend the most effective and well-tolerated treatment options for each patient, leading to improved adherence and clinical outcomes. Furthermore, AI enables continuous monitoring and adjustment of treatment regimens in real time, allowing healthcare providers to respond rapidly to changes in patient status and evolving viral dynamics. This proactive approach to HIV management can help prevent treatment failure and the development of drug resistance, ultimately leading to better long-term outcomes for patients. Despite its transformative potential, AI-driven optimization in HIV treatment is not without challenges. Ethical considerations, data privacy concerns, and the need for robust validation and regulatory oversight are all important factors that must be addressed to ensure the safe and effective implementation of AI algorithms in clinical practice. In conclusion, the integrative analysis presented in this study underscores the significant impact of AI-driven optimization on the personalization and optimization of HIV treatment regimens. By leveraging AI technologies, healthcare providers can tailor treatment approaches to individual patient needs, leading to improved outcomes and quality of life for people living with HIV. Keywords: Integrative Analysis, AI- Driven, Optimization, HIV Treatment, Regimens.",['machine learning'],"The study addresses the challenge of improving HIV treatment by focusing on the need for personalized care that accounts for individual patient characteristics and disease progression. It highlights the importance of tailoring therapy to optimize treatment outcomes and manage factors such as drug resistance, comorbidities, and lifestyle influences. The research aims to explore how treatment regimens can be customized to enhance adherence and clinical results for people living with HIV. Specifically, the study’s primary objective is to examine approaches that enable continuous monitoring and adjustment of HIV therapies in response to changes in patient status and viral dynamics, ultimately preventing treatment failure and improving long-term patient outcomes."
Biology,Short-Term Load Forecasting: A Comprehensive Review and Simulation Study With CNN-LSTM Hybrids Approach,"Short-term load forecasting (STLF) is vital in effectively managing the reserve requirement in modern power grids. Subsequently, it supports the grid operator in making effective and economical decisions during the power balancing operation. Therefore, this study comprehensively reviews STLF methods, including time series analysis, regression-based frameworks, artificial neural networks (ANNs), and hybrid models that employ different forecasting approaches. Detailed mathematical and graphical analyses and a comparative evaluation of these methods are provided, highlighting their advantages and disadvantages. Further, the study proposes a hybrid CNN-LSTM model comprised of Convolutional neural networks (CNN) for feature extraction of high dimensional data and Long short-term memory (LSTM) networks to boost the model's efficiency for temporal sequence prediction. This study assessed the model using a comprehensive dataset from Pakistan's NTDC national grid. The analysis revealed superior performance in short-term load prediction, achieving enhanced accuracy. For single-step forecasting, the model yielded an RMSE of 538.71, MAE of 371.97, and MAPE of 2.72. In 24-hour forecasting, it achieved an RMSE of 951.94, MAE of 656.35, and MAPE of 4.72 on the NTDC dataset. Moreover, the model has outperformed previous models in comparison using the AEP dataset, demonstrating its superiority in enhancing reserve management and balancing supply and demand in modern electricity networks.","['regression-based frameworks', 'artificial neural networks (ANNs)', 'hybrid models', 'Convolutional neural networks (CNN)', 'Long short-term memory (LSTM) networks', 'hybrid CNN-LSTM model']","The study addresses the critical need for accurate short-term load forecasting to effectively manage reserve requirements in modern power grids, which is essential for supporting grid operators in making efficient and economical decisions during power balancing operations. Accurate forecasting plays a vital role in maintaining the stability and reliability of electricity networks by balancing supply and demand. The primary objective of the study is to evaluate and improve methods for short-term load forecasting to enhance prediction accuracy. Specifically, the study aims to assess forecasting approaches using comprehensive datasets to identify solutions that can better support reserve management and the balancing of supply and demand in modern electricity grids."
Biology,A comprehensive review of model compression techniques in machine learning,"Abstract This paper critically examines model compression techniques within the machine learning (ML) domain, emphasizing their role in enhancing model efficiency for deployment in resource-constrained environments, such as mobile devices, edge computing, and Internet of Things (IoT) systems. By systematically exploring compression techniques and lightweight design architectures, it is provided a comprehensive understanding of their operational contexts and effectiveness. The synthesis of these strategies reveals a dynamic interplay between model performance and computational demand, highlighting the balance required for optimal application. As machine learning (ML) models grow increasingly complex and data-intensive, the demand for computational resources and memory has surged accordingly. This escalation presents significant challenges for the deployment of artificial intelligence (AI) systems in real-world applications, particularly where hardware capabilities are limited. Therefore, model compression techniques are not merely advantageous but essential for ensuring that these models can be utilized across various domains, maintaining high performance without prohibitive resource requirements. Furthermore, this review underscores the importance of model compression in sustainable artificial intelligence (AI) development. The introduction of hybrid methods, which combine multiple compression techniques, promises to deliver superior performance and efficiency. Additionally, the development of intelligent frameworks capable of selecting the most appropriate compression strategy based on specific application needs is crucial for advancing the field. The practical examples and engineering applications discussed demonstrate the real-world impact of these techniques. By optimizing the balance between model complexity and computational efficiency, model compression ensures that the advancements in AI technology remain sustainable and widely applicable. This comprehensive review thus contributes to the academic discourse and guides innovative solutions for efficient and responsible machine learning practices, paving the way for future advancements in the field. Graphical abstract","['model compression techniques', 'hybrid methods']","The study addresses the increasing complexity and data intensity of models, which leads to heightened demands for computational resources and memory, posing significant challenges for deploying advanced technologies in environments with limited hardware capabilities. This issue is critical for ensuring that such technologies can be effectively utilized across various domains without excessive resource consumption. The primary aim of the study is to provide a comprehensive understanding of techniques that enhance efficiency while maintaining high performance, thereby enabling the practical application of these technologies in resource-constrained settings. The research also seeks to highlight strategies that balance complexity and efficiency to support sustainable development and broad applicability in real-world scenarios."
Biology,Application of deep learning to fault diagnosis of rotating machineries,"Abstract Deep learning (DL) has attained remarkable achievements in diagnosing faults for rotary machineries. Capitalizing on the formidable learning capacity of DL, it has the potential to automate human labor and augment the efficiency of fault diagnosis in rotary machinery. These advantages have engendered escalating interest over the past decade. Although recent reviews of the literature have encapsulated the utilization of DL in diagnosing faults in rotating machinery, they no longer encompass the introduction of novel methodologies and emerging directions as DL methodologies continually evolve. Moreover, in practical application, novel issues and trajectories perpetually manifest, demanding a comprehensive exegesis. To rectify this lacuna, this article amalgamates current research trends and avant-garde methodologies while systematizing the utilization of anterior DL techniques. The evolution and extant status of DL in diagnosing faults for rotary machinery were delineated, with the intent of providing orientation for prospective research. Over the bygone decade, archetypal DL theory has empowered the diagnosis of faults in rotating machinery by directly establishing the nexus between mechanical data and fault conditions. In recent years, meta learning methods aimed at solving small sample scenarios and large model transformers aimed at mining big data features have both received widespread attention and development in the field of fault diagnosis of rotating machinery equipment. Although excellent results have been achieved in these two directions, there is no review and summary article yet, so it is necessary to update the review literature in the field of fault diagnosis of rotating machinery equipment. Lastly, predicated on a survey of the literature and the current developmental landscape, the challenges and prospective orientations of DL in rotary machinery fault diagnosis are presented.","['deep learning (DL)', 'meta learning methods']","The research idea centers on addressing the ongoing challenges and evolving needs in diagnosing faults in rotary machinery, a field that has seen significant advancements over the past decade. Despite previous reviews summarizing existing approaches, there remains a gap in capturing the latest developments and emerging directions in this area, especially as new issues continually arise in practical applications. The study aims to provide a comprehensive overview of current research trends and novel methodologies to better understand the progression and current state of fault diagnosis in rotary machinery. The primary objective of the study is to update and systematize the literature on fault diagnosis in rotary machinery by incorporating recent advancements and emerging challenges, thereby offering guidance for future research and development in this domain."
Biology,Empowering Cyberattack Identification in IoHT Networks With Neighborhood-Component-Based Improvised Long Short-Term Memory,"Cybersecurity has become an inevitable concern in the healthcare industry due to the rapid growth of the Internet of Health Things (IoHT). The IoHT is revolutionizing healthcare by enabling remote access to hospital equipment, real-time patient monitoring, and urgent alerts to patients and hospitals. However, the convenience of these systems also makes them vulnerable to cyberattacks, with hackers seeking to disrupt health services or extort money through ransomware attacks. Efficiently detecting multiple threats is a challenging task because IoHT generates large temporal data and system log information. In this paper, we propose time series classification models for the identification of potential cyberattacks in IoHT networks. First, we introduce Neighborhood Component Analysis (NCA) with modifications of the regularization parameter to select the vital input features. With the selected features, we propose two LSTM-based models: Directed Acyclic Graph-based Long Short-Term Memory (DAG-LSTM) and Projected Layer-based Long Short-Term Memory (PL-LSTM) for detecting cyberattacks. We evaluate the existing time series classification models (i.e., GRU, LSTM, and Bi-LSTM) and proposed models (i.e., DAG-LSTM and PL-LSTM) using real-world IoHT data. We also validate the models by applying a non-parametric statistical test, Friedman test. Our evaluation results show that the proposed DAG-LSTM achieves the highest accuracy with 99.89% training and 92.04% an average testing accuracy.","['Neighborhood Component Analysis (NCA)', 'Directed Acyclic Graph-based Long Short-Term Memory (DAG-LSTM)', 'Gated Recurrent Unit (GRU)', 'Long Short-Term Memory (LSTM)', 'Bidirectional Long Short-Term Memory (Bi-LSTM)']","The research idea addresses the growing concern of cybersecurity threats within the healthcare industry due to the rapid expansion of the Internet of Health Things (IoHT). While IoHT enhances healthcare by enabling remote access to hospital equipment, real-time patient monitoring, and urgent alerts, it also introduces vulnerabilities that can be exploited by cyberattacks, potentially disrupting health services or causing financial harm. Efficient detection of multiple cyber threats is challenging because of the large volume of temporal data and system logs generated by IoHT devices. The primary objective of the study is to identify potential cyberattacks in IoHT networks by developing effective methods for detecting these threats, thereby improving the security and reliability of healthcare systems that rely on IoHT technologies."
Biology,Advancing real-time plant disease detection: A lightweight deep learning approach and novel dataset for pigeon pea crop,"Plant disease detection and early disease treatment are essential for sustainable crop production. Computer vision for crop science is overgrowing with the advancement in deep learning. Real time plant disease detection poses a challenge due to the unpredictable spread of diseases within the plant, environmental factors, and the scarcity of real field datasets. The proposed work systematically addresses these issues through three key components: (a) Collaboratively generating the novel pigeon pea image dataset from agricultural fields, in partnership with 20 Agricultural Research Centers (ARS) and governmental agencies spanning 18 Indian states. (b) The design of lightweight and high-performance models for real-time plant disease detection in resource-constrained devices. (c) The extraction of multiscale feature of plant diseases using Multi-kernel Depthwise separable Convolutions. The proposed lightweight Lite-MDC architecture uses the Multi-kernel Depthwise separable Convolutions (MDsConv). The MDsConv module captures spatial features across various scales while maintaining a lightweight design. It effectively extract multi-scale information to characterize plant diseases, accommodating their diverse scale. Proposed architectural approach significantly reduces computational complexity, employing only 2.2 million parameters, which is a 62% reduction compared to the standard VGG16 architecture. The proposed method outperforms the state-of-the-art networks such as InceptionV3, VGG16, ResNet50, DenseNet, MobileNet, MobileNetV3, NASNet, and EfficieNetB0 on the proposed pigeon pea dataset with 94.14% accuracy. Notably, the method achieves a 34 Frames Per Second (FPS) inference on an NVIDIA P100 GPU. Furthermore, its performance is validated across publicly available datasets, including the plant village dataset, Cassava, and apple leaf datasets, yielding 99.78%, 86.4%, and 97.2% accuracy, respectively. The Lite-MDC model exhibits the potential for real-time plant disease detection on resource-constrained edge devices such as Agriculture robots and drones.","['InceptionV3', 'VGG16', 'ResNet50', 'DenseNet', 'MobileNet', 'MobileNetV3', 'NASNet', 'EfficientNetB0']","The study addresses the critical need for effective plant disease detection and early treatment to ensure sustainable crop production. It highlights the challenges posed by the unpredictable spread of diseases within plants, environmental factors, and the lack of comprehensive real field datasets for accurate disease identification. The research is motivated by the importance of timely and accurate detection of plant diseases, particularly in pigeon pea crops, to mitigate crop losses and support agricultural productivity.

The primary objective of the study is to develop a novel pigeon pea image dataset collected from diverse agricultural fields across multiple Indian states to facilitate plant disease detection. The study aims to characterize plant diseases by capturing multiscale spatial features to accommodate their diverse manifestations. Additionally, it seeks to enhance real-time detection capabilities suitable for resource-constrained environments, thereby supporting timely disease management in agricultural settings."
Biology,Deep Learning-Based Mask Identification System Using ResNet Transfer Learning Architecture,"Recently, the coronavirus disease 2019 has shown excellent attention in the global community regarding health and the economy.World Health Organization (WHO) and many others advised controlling Corona Virus Disease in 2019.The limited treatment resources, medical resources, and unawareness of immunity is an essential horizon to unfold.Among all resources, wearing a mask is the primary non-pharmaceutical intervention to stop the spreading of the virus caused by Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) droplets.All countries made masks mandatory to prevent infection.For such enforcement, automatic and effective face detection systems are crucial.This study presents a face mask identification approach for static photos and real-time movies that distinguishes between images with and without masks.To contribute to society, we worked on mask detection of an individual to adhere to the rule and provide awareness to the public or organization.The paper aims to get detection accuracy using transfer learning from Residual Neural Network 50 (ResNet-50) architecture and works on detection localization.The experiment is tested with other popular pre-trained models such as Deep Convolutional Neural Networks (AlexNet), Residual Neural Networks (ResNet), and Visual Geometry Group Networks (VGG-Net) advanced architecture.The proposed system generates an accuracy of 98.4% when modeled using Residual Neural Network 50 (ResNet-50).Also, the precision and recall values are proved as better when compared to the existing models.This outstanding work also can be used in video surveillance applications.","['transfer learning', 'Residual Neural Network 50 (ResNet-50)', 'Deep Convolutional Neural Networks (AlexNet)', 'Residual Neural Networks (ResNet)', 'Visual Geometry Group Networks (VGG-Net)']","The research idea centers on addressing the global health challenge posed by the coronavirus disease 2019 (COVID-19), particularly focusing on the importance of wearing masks as a primary non-pharmaceutical intervention to prevent the spread of the virus caused by SARS-CoV-2 droplets. Given the limited treatment and medical resources, as well as public unawareness regarding immunity, enforcing mask-wearing has become essential worldwide. The study aims to support this enforcement by identifying whether individuals are wearing masks, thereby contributing to public health awareness and compliance with safety measures. The primary objective of the study is to develop an approach that can accurately distinguish between images of individuals with and without masks in both static photos and real-time videos, facilitating adherence to mask-wearing rules and enhancing public or organizational awareness."
Biology,A hyperspectral deep learning attention model for predicting lettuce chlorophyll content,"Abstract Background The phenotypic traits of leaves are the direct reflection of the agronomic traits in the growth process of leafy vegetables, which plays a vital role in the selection of high-quality leafy vegetable varieties. The current image-based phenotypic traits extraction research mainly focuses on the morphological and structural traits of plants or leaves, and there are few studies on the phenotypes of physiological traits of leaves. The current research has developed a deep learning model aimed at predicting the total chlorophyll of greenhouse lettuce directly from the full spectrum of hyperspectral images. Results A CNN-based one-dimensional deep learning model with spectral attention module was utilized for the estimate of the total chlorophyll of greenhouse lettuce from the full spectrum of hyperspectral images. Experimental results demonstrate that the deep neural network with spectral attention module outperformed the existing standard approaches, including partial least squares regression (PLSR) and random forest (RF), with an average R 2 of 0.746 and an average RMSE of 2.018. Conclusions This study unveils the capability of leveraging deep attention networks and hyperspectral imaging for estimating lettuce chlorophyll levels. This approach offers a convenient, non-destructive, and effective estimation method for the automatic monitoring and production management of leafy vegetables.","['CNN-based one-dimensional deep learning model with spectral attention module', 'partial least squares regression (PLSR)', 'random forest (RF)']","The phenotypic traits of leaves directly reflect the agronomic traits during the growth process of leafy vegetables and play a vital role in selecting high-quality leafy vegetable varieties. While most research has focused on morphological and structural traits, there is a lack of studies on the physiological phenotypes of leaves, such as chlorophyll content. The primary aim of this study is to develop a method for predicting the total chlorophyll content of greenhouse lettuce leaves using spectral information. This approach seeks to provide a convenient, non-destructive, and effective way to estimate chlorophyll levels for automatic monitoring and production management of leafy vegetables."
Biology,African Journal of Environmental Science and Technology,"The aim of the present study is to test ESA's Sentinel-2 (S2) satellites (S2A and S2B) for an efficient quantification of land cover (LC) and forest compositions in a tropical environment southwest of Mount Kenya.Furthermore, outcome of the research is used to validate ESA's S2 prototype LC 20 m map of Africa that was produced in 2016.A decision tree that is based on significant altitudinal ranges was used to discriminate four natural tree compositions that occur within the investigation area.In addition, the classification process was supported by Google Earth images, and land use (LU) data that were provided by the local Kenyan Forest Service (KFS).Final classification products include four LC classes and five subclasses of forest (four natural forest subclasses plus one non-natural forest class).Results of the Jeffries-Matusita (JM) distance test show significant differences in spectral separability between all classes.Furthermore, the study identifies spectral signatures and significant wavelengths for a classification of all LC classes and forest subclasses where wavelengths of SWIR and the rededge domain show highest importance for the discrimination of tree compositions.Finally, considerable differences can be seen between the utilized multi-temporal classification set (total of 39 bands from three acquisition dates) and ESA's S2 prototype LC 20 m map of Africa 2016.A visual comparison of ESA's prototype map within the investigation area indicates an overrepresentation of tree cover areas (as confirmed in previous studies) and also an underrepresentation of water.",['decision tree'],"The research idea centers on evaluating the effectiveness of ESA's Sentinel-2 satellites for accurately quantifying land cover and forest compositions in a tropical region southwest of Mount Kenya. This study addresses the need for reliable mapping of natural tree compositions and land cover classes in this environment, which is essential for understanding forest distribution and land use patterns. The research objective is to test the capability of Sentinel-2 satellite data to discriminate between different natural tree compositions and land cover classes within the study area, and to validate the existing ESA Sentinel-2 prototype land cover map of Africa produced in 2016. The study aims to identify distinct spectral characteristics of forest subclasses and assess discrepancies between newly classified land cover products and the prototype map, particularly regarding the representation of tree cover and water bodies."
Biology,"A Comprehensive Survey of Continual Learning: Theory, Method and Application","To cope with real-world dynamics, an intelligent system needs to incrementally acquire, update, accumulate, and exploit knowledge throughout its lifetime. This ability, known as continual learning, provides a foundation for AI systems to develop themselves adaptively. In a general sense, continual learning is explicitly limited by catastrophic forgetting, where learning a new task usually results in a dramatic performance drop of the old tasks. Beyond this, increasingly numerous advances have emerged in recent years that largely extend the understanding and application of continual learning. The growing and widespread interest in this direction demonstrates its realistic significance as well as complexity. In this work, we present a comprehensive survey of continual learning, seeking to bridge the basic settings, theoretical foundations, representative methods, and practical applications. Based on existing theoretical and empirical results, we summarize the general objectives of continual learning as ensuring a proper stability-plasticity trade-off and an adequate intra/inter-task generalizability in the context of resource efficiency. Then we provide a state-of-the-art and elaborated taxonomy, extensively analyzing how representative strategies address continual learning, and how they are adapted to particular challenges in various applications. Through an in-depth discussion of promising directions, we believe that such a holistic perspective can greatly facilitate subsequent exploration in this field and beyond.",['continual learning'],"The research idea centers on the challenge of continual learning, which involves the ability to incrementally acquire, update, accumulate, and exploit knowledge over time while coping with real-world dynamics. A key problem addressed is catastrophic forgetting, where learning new information causes a significant decline in performance on previously learned tasks. The study highlights the growing importance and complexity of understanding continual learning in biological and cognitive contexts. The primary objective of the study is to comprehensively summarize and analyze the fundamental principles, challenges, and strategies related to continual learning, aiming to ensure a proper balance between stability and adaptability, as well as effective generalization across tasks within resource constraints."
Biology,Chatbots and Large Language Models in Radiology: A Practical Primer for Clinical and Research Applications,"Although chatbots have existed for decades, the emergence of transformer-based large language models (LLMs) has captivated the world through the most recent wave of artificial intelligence chatbots, including ChatGPT. Transformers are a type of neural network architecture that enables better contextual understanding of language and efficient training on massive amounts of unlabeled data, such as unstructured text from the internet. As LLMs have increased in size, their improved performance and emergent abilities have revolutionized natural language processing. Since language is integral to human thought, applications based on LLMs have transformative potential in many industries. In fact, LLM-based chatbots have demonstrated human-level performance on many professional benchmarks, including in radiology. LLMs offer numerous clinical and research applications in radiology, several of which have been explored in the literature with encouraging results. Multimodal LLMs can simultaneously interpret text and images to generate reports, closely mimicking current diagnostic pathways in radiology. Thus, from requisition to report, LLMs have the opportunity to positively impact nearly every step of the radiology journey. Yet, these impressive models are not without limitations. This article reviews the limitations of LLMs and mitigation strategies, as well as potential uses of LLMs, including multimodal models. Also reviewed are existing LLM-based applications that can enhance efficiency in supervised settings.","['transformer-based large language models (LLMs)', 'Transformers', 'Multimodal LLMs']","The research idea centers on the transformative potential of advanced language models in the field of radiology, highlighting their ability to understand and generate human-like language and to interpret both text and images in a manner that closely mimics current diagnostic workflows. This advancement offers the possibility to positively impact nearly every step of the radiology process, from requisition to report generation, thereby enhancing clinical and research applications. The study acknowledges that despite these promising capabilities, there are notable limitations that need to be addressed. The primary objective of the study is to review the limitations and mitigation strategies of these language models, explore their potential uses including multimodal applications, and examine existing implementations that can improve efficiency within supervised radiology settings."
Biology,Fingerprint Based Gender Classification,"Male-female classification from a fingerprint is an important step in forensic science, anthropological and medical studies to reduce the efforts required for searching a person.The aim of this research is to establish a relationship between gender and the fingerprint using some special features such as ridge density, ridge thickness to valley thickness ratio (RTVTR) and ridge width.showed that male-female classification can be done correctly up to 88.5% based on white lines count, RTVTR & ridge count using Neural Network as Classifier.We have used RTVTR, ridge width and ridge density for classification and SVM as classifier.We have found male-female can be correctly classified up to 91%.Gender classification plays an active role in several applications such as biometrics, criminology, surveillance, human computer interaction, commercial profiling.Though biometric traits such as face, gait, iris and hand shape are used for gender classification in the past, majority of the work is based on face as it contains more prominent features than others.In this paper we have analyzed fingerprints for gender classification with a hope that it has great potential for future research.We have employed a three convolutional layer CNN with rectified linear and activation functions on NIST database which contains a set of 4000 images and achieved 99% accuracy.Performance of the proposed system demonstrated that fingerprints contains vital features to discriminate gender of a person.Humans have distinctive and unique traits which can be used to distinguish them thus, acting as a form of identification.Biometrics identify people by measuring some aspect of individual's anatomy or physiology such as hand geometry or fingerprint which consists of a pattern of interleaved ridges and valleys.The year 2015 election in Nigeria was greeted by some petitions including under-aged voters.The need for an age and gender detector system is a major concern for organizations at all levels where integrity of information cannot be compromised.This work developed a system that determines human age-range and gender using fingerprint analysis trained with Back Propagation Neural Network (for gender classification) and DWT+PCA (for age classification).A total of 280 fingerprint samples of people with various age and gender were collected.140 of these samples were used for training the system""s Database; 70 males and 70 females respectively.This was done for age groups 1-10, 11-20, 21-30, 31-40, 41-50, 51-60 and 61-70 accordingly.In order to determine the gender of an individual, the Ridge Thickness Valley Thickness Ratio (RTVTR) of the person was put into consideration.Result showed 80.00 % classification accuracy for females and 72.86 % for males while 115 subjects out of 140 (82.14%)were correctly classified in age.","['Neural Network', 'SVM', 'CNN', 'Back Propagation Neural Network']","The research addresses the importance of accurately classifying male and female individuals based on fingerprint characteristics, which is a significant task in forensic science, anthropological, and medical studies to streamline the identification process. It highlights the potential of fingerprint features such as ridge density and ridge thickness to valley thickness ratio (RTVTR) as reliable indicators for gender determination, emphasizing the need for effective gender classification methods in various applications including biometrics and criminology. The primary aim of the study is to establish a clear relationship between gender and fingerprint features by analyzing specific characteristics like ridge density, RTVTR, and ridge width to improve the accuracy of male-female classification. Additionally, the research seeks to develop a system capable of determining both age range and gender from fingerprint samples, thereby contributing to the integrity of identification processes in contexts where accurate demographic information is crucial."
Biology,Genomic selection in plant breeding: Key factors shaping two decades of progress,"Genomic selection, the application of genomic prediction (GP) models to select candidate individuals, has significantly advanced in the past two decades, effectively accelerating genetic gains in plant breeding.This article provides a holistic overview of key factors that have influenced GP in plant breeding during this period.We delved into the pivotal roles of training population size and genetic diversity, and their relationship with the breeding population, in determining GP accuracy.Special emphasis was placed on optimizing training population size.We explored its benefits and the associated diminishing returns beyond an optimum size.This was done while considering the balance between resource allocation and maximizing prediction accuracy through current optimization algorithms.The density and distribution of single-nucleotide polymorphisms, level of linkage disequilibrium, genetic complexity, trait heritability, statistical machine-learning methods, and non-additive effects are the other vital factors.Using wheat, maize, and potato as examples, we summarize the effect of these factors on the accuracy of GP for various traits.The search for high accuracy in GP-theoretically reaching one when using the Pearson's correlation as a metric-is an active research area as yet far from optimal for various traits.We hypothesize that with ultra-high sizes of genotypic and phenotypic datasets, effective training population optimization methods and support from other omics approaches (transcriptomics, metabolomics and proteomics) coupled with deep-learning algorithms could overcome the boundaries of current limitations to achieve the highest possible prediction accuracy, making genomic selection an effective tool in plant breeding.",['statistical machine-learning methods'],"The research idea centers on the significant advancements in genomic selection over the past two decades, which have accelerated genetic gains in plant breeding. The study addresses the critical factors influencing the accuracy of genomic prediction in plant breeding, such as training population size, genetic diversity, and their relationship with the breeding population. It highlights the importance of optimizing training population size to balance resource allocation and maximize prediction accuracy, while also considering other factors like single-nucleotide polymorphism density, linkage disequilibrium, genetic complexity, and trait heritability. The ongoing challenge is to achieve the highest possible accuracy in genomic prediction for various traits across crops like wheat, maize, and potato. The primary objective of the study is to provide a comprehensive overview of the key factors that have influenced genomic prediction in plant breeding during the last twenty years. It aims to explore the roles of training population size and genetic diversity in determining prediction accuracy, with special emphasis on optimizing training population size. Additionally, the study seeks to summarize the effects of various genetic and trait-related factors on prediction accuracy, using examples from important crop species."
Biology,"Revolutionizing agriculture with artificial intelligence: plant disease detection methods, applications, and their limitations","Accurate and rapid plant disease detection is critical for enhancing long-term agricultural yield. Disease infection poses the most significant challenge in crop production, potentially leading to economic losses. Viruses, fungi, bacteria, and other infectious organisms can affect numerous plant parts, including roots, stems, and leaves. Traditional techniques for plant disease detection are time-consuming, require expertise, and are resource-intensive. Therefore, automated leaf disease diagnosis using artificial intelligence (AI) with Internet of Things (IoT) sensors methodologies are considered for the analysis and detection. This research examines four crop diseases: tomato, chilli, potato, and cucumber. It also highlights the most prevalent diseases and infections in these four types of vegetables, along with their symptoms. This review provides detailed predetermined steps to predict plant diseases using AI. Predetermined steps include image acquisition, preprocessing, segmentation, feature selection, and classification. Machine learning (ML) and deep understanding (DL) detection models are discussed. A comprehensive examination of various existing ML and DL-based studies to detect the disease of the following four crops is discussed, including the datasets used to evaluate these studies. We also provided the list of plant disease detection datasets. Finally, different ML and DL application problems are identified and discussed, along with future research prospects, by combining AI with IoT platforms like smart drones for field-based disease detection and monitoring. This work will help other practitioners in surveying different plant disease detection strategies and the limits of present systems.","['machine learning (ML)', 'deep learning (DL)']","The research addresses the critical need for accurate and rapid detection of plant diseases to enhance long-term agricultural yield, as disease infections caused by viruses, fungi, bacteria, and other infectious organisms pose significant challenges in crop production and can lead to economic losses. Traditional methods for detecting plant diseases are time-consuming, require specialized expertise, and demand considerable resources, highlighting the importance of improving disease diagnosis approaches. The primary aim of the study is to examine and review the most prevalent diseases and infections affecting four key crops—tomato, chilli, potato, and cucumber—along with their symptoms. Additionally, the research seeks to provide a comprehensive overview of existing strategies for plant disease detection, including the evaluation of various approaches and datasets, to support future advancements in effective disease monitoring and management."
Biology,Deep-STP: a deep learning-based approach to predict snake toxin proteins by using word embeddings,"Snake venom contains many toxic proteins that can destroy the circulatory system or nervous system of prey. Studies have found that these snake venom proteins have the potential to treat cardiovascular and nervous system diseases. Therefore, the study of snake venom protein is conducive to the development of related drugs. The research technologies based on traditional biochemistry can accurately identify these proteins, but the experimental cost is high and the time is long. Artificial intelligence technology provides a new means and strategy for large-scale screening of snake venom proteins from the perspective of computing. In this paper, we developed a sequence-based computational method to recognize snake toxin proteins. Specially, we utilized three different feature descriptors, namely g-gap , natural vector and word 2 vector, to encode snake toxin protein sequences. The analysis of variance (ANOVA), gradient-boost decision tree algorithm (GBDT) combined with incremental feature selection (IFS) were used to optimize the features, and then the optimized features were input into the deep learning model for model training. The results show that our model can achieve a prediction performance with an accuracy of 82.00% in 10-fold cross-validation. The model is further verified on independent data, and the accuracy rate reaches to 81.14%, which demonstrated that our model has excellent prediction performance and robustness.","['gradient-boost decision tree algorithm (GBDT)', 'incremental feature selection (IFS)', 'deep learning model']","The research idea centers on the fact that snake venom contains many toxic proteins capable of destroying the circulatory or nervous systems of prey, and these proteins have potential therapeutic applications for treating cardiovascular and nervous system diseases. Studying snake venom proteins is important for the development of related drugs. The primary objective of the study is to accurately identify snake venom proteins to facilitate drug development, addressing the limitations of traditional biochemical methods that are costly and time-consuming. This study aims to improve the recognition of snake toxin proteins to support large-scale screening efforts."
Biology,Can large language models replace humans in systematic reviews? Evaluating <scp>GPT</scp>‐4's efficacy in screening and extracting data from peer‐reviewed and grey literature in multiple languages,"Systematic reviews are vital for guiding practice, research and policy, although they are often slow and labour-intensive. Large language models (LLMs) could speed up and automate systematic reviews, but their performance in such tasks has yet to be comprehensively evaluated against humans, and no study has tested Generative Pre-Trained Transformer (GPT)-4, the biggest LLM so far. This pre-registered study uses a ""human-out-of-the-loop"" approach to evaluate GPT-4's capability in title/abstract screening, full-text review and data extraction across various literature types and languages. Although GPT-4 had accuracy on par with human performance in some tasks, results were skewed by chance agreement and dataset imbalance. Adjusting for these caused performance scores to drop across all stages: for data extraction, performance was moderate, and for screening, it ranged from none in highly balanced literature datasets (~1:1) to moderate in those datasets where the ratio of inclusion to exclusion in studies was imbalanced (~1:3). When screening full-text literature using highly reliable prompts, GPT-4's performance was more robust, reaching ""human-like"" levels. Although our findings indicate that, currently, substantial caution should be exercised if LLMs are being used to conduct systematic reviews, they also offer preliminary evidence that, for certain review tasks delivered under specific conditions, LLMs can rival human performance.",['Generative Pre-Trained Transformer (GPT)-4'],"The research idea centers on the importance of systematic reviews for guiding practice, research, and policy, while highlighting the challenges posed by their slow and labor-intensive nature. The study addresses the need to evaluate new approaches that could potentially accelerate and automate the process of conducting systematic reviews. The primary objective of the study is to comprehensively assess the capability of a large language model, GPT-4, in performing key tasks involved in systematic reviews, including title/abstract screening, full-text review, and data extraction across various types of literature and languages. The study aims to determine how well GPT-4’s performance compares to human reviewers in these tasks and to identify the conditions under which it may achieve human-like accuracy."
Biology,MemBrain v2: an end-to-end tool for the analysis of membranes in cryo-electron tomography,"A bstract MemBrain v2 is a deep learning-enabled program aimed at the efficient analysis of membranes in cryo-electron tomography (cryo-ET). The final v2 release of MemBrain will comprise three main modules: 1) MemBrain-seg, which provides automated membrane segmentation, 2) MemBrain-pick, which provides automated picking of particles along segmented membranes, and 3) MemBrain-stats, which provides quantitative statistics of particle distributions and membrane morphometrics. This initial version of the manuscript is focused on the beta release of MemBrain-seg, which combines iterative training with diverse data and specialized Fourier-based data augmentations. These augmentations are specifically designed to enhance the tool’s adaptability to a variety of tomographic data and address common challenges in cryo-ET analysis. A key feature of MemBrain-seg is the implementation of the Surface-Dice loss function, which improves the network’s focus on membrane connectivity and allows for the effective incorporation of manual annotations from different sources. This function is beneficial in handling the variability inherent in membrane structures and annotations. Our ongoing collaboration with the cryo-ET community plays an important role in continually improving MemBrain v2 with a wide array of training data. This collaborative approach ensures that MemBrain v2 remains attuned to the field’s needs, enhancing its robustness and generalizability across different types of tomographic data. The current version of MemBrain-seg is available at https://github.com/teamtomo/membrain-seg , and the predecessor of MemBrain-pick (also called MemBrain v1) is deposited at https://github.com/CellArchLab/MemBrain . This preprint will be updated concomitantly with the code until the three integrated modules of MemBrain v2 are complete.","['deep learning', 'Surface-Dice loss function']","The research addresses the challenge of accurately analyzing membranes in cryo-electron tomography (cryo-ET), which is complicated by the variability and complexity of membrane structures and the need for reliable segmentation and particle identification along membranes. Efficient and precise membrane analysis is crucial for understanding membrane morphology and the distribution of particles associated with membranes in biological samples. The primary aim of the study is to develop and improve a tool that enables automated and robust membrane segmentation, particle picking along membranes, and quantitative assessment of particle distributions and membrane morphometrics in cryo-ET data. This version of the study focuses on enhancing membrane segmentation by incorporating strategies that improve the handling of membrane connectivity and variability in manual annotations, thereby supporting more accurate and adaptable analysis of membrane structures."
Biology,Foundation Models for Generalist Geospatial Artificial Intelligence,"Much of the progress in the development of highly adaptable and reusable artificial intelligence (AI) models is expected to have a profound impact on Earth science and remote sensing. Foundation models are pre-trained on large unlabeled datasets through self-supervision, and then fine-tuned for various downstream tasks with small labeled datasets. There is an increasing interest within the scientific community to investigate how to effectively build generalist AI models that exploit multi-sensor data in Earth observation applications. This paper introduces a first-of-its-kind framework for efficient pre-training and fine-tuning of foundational models on extensive geospatial data. We have utilized this framework to create Prithvi, a transformer-based geospatial foundational model pre-trained on more than 1 TB of multispectral satellite imagery from the Harmonized Landsat Sentinel-2 (HLS) dataset. Our study demonstrates the efficacy of our framework in successfully fine-tuning Prithvi to a range of Earth observation applications not previously analyzed by foundation models. Applications for which results are presented in this paper include multi-temporal cloud gap imputation, flood mapping, wildfire scar segmentation, and multi-temporal crop segmentation. We assessed the effect of Prithvi's pre-trained weights on downstream tasks and compared learning curves for (1) fine-tuning the entire model, (2) fine-tuning solely the decoder for the downstream task, and (3) training the model without utilizing Prithvi's pre-trained weights. Our experiments showed that the pre-trained model accelerates the fine-tuning process compared to leveraging randomly initialized weights. In addition, pre-trained Prithvi compared well against the state-of-the-art on downstream tasks; e.g., the model outperformed a conditional GAN model in multi-temporal cloud imputation by up to 5pp (or 5.7%) in the structural similarity index. Further, given the cost and time required for collecting labeled training data, we gradually reduced the quantity of available labeled data for refining the model to evaluate data efficiency. We found that labeled training data can be decreased substantially without affecting the model's accuracy. The pre-trained 100 million parameter model and corresponding fine-tuning workflows have been released publicly as open source contributions to the global Earth sciences community through Hugging Face","['foundation models', 'self-supervision', 'fine-tuning', 'transformer-based model', 'conditional GAN model']","The research idea centers on addressing the challenge of effectively utilizing extensive multispectral satellite imagery to improve Earth observation applications such as cloud gap imputation, flood mapping, wildfire scar segmentation, and crop segmentation. There is a growing need within the scientific community to develop generalist approaches that can leverage multi-sensor geospatial data to enhance the analysis and monitoring of environmental phenomena. The study aims to explore how pre-training on large-scale geospatial datasets can benefit various downstream Earth science tasks by improving accuracy and reducing the reliance on large amounts of labeled data. The primary objective of the study is to create and evaluate a foundational geospatial model pre-trained on a vast collection of satellite imagery to demonstrate its effectiveness across multiple Earth observation applications. The research seeks to assess the impact of pre-trained model weights on task performance and data efficiency, ultimately aiming to facilitate more accurate and resource-efficient environmental monitoring and analysis."
Biology,Face mask identification with enhanced cuckoo optimization and deep learning-based faster regional neural network,"Abstract A mask identification and social distance monitoring system using Unmanned Aerial Vehicles (UAV) in the outdoors has been proposed for a health establishment. The above approach performed surveillance of the surrounding area using cameras installed in UAVs and internet of things technologies, and the captured images seem useful for tracking the entire environment. However, innate images from unmanned aerial vehicles show an adaptable visual effect in an uncontrolled environment, making face-mask detection and recognition harder. The UAV picture first had to be converted to grayscale, then its contrast was amplified. Image contrast was improved using Optimum Wavelet-Based Masking and the Enhanced Cuckoo Methodology (ECM). According to the contrast-enhanced image, Gabor-Transform (GT) and Stroke Width Transform (SWT) methods are used to derive attributes that help categorise mask-wearers and non-mask-wearers. Using the retrieved attributes, a Weighted Naive Bayes Classification (WNBC) detected masks in the images. Additionally, a deep neural network-based, the faster Region-Based Convolutional Neural Networks (R-CNN) algorithm combined with Adaptive Galactic Swarm Optimization (AGSO) is being used to identify appropriate and incorrect face mask wear in images, as well as to monitor social distancing among individuals in crowded areas. When the system recognises unmasked individuals, it sends their information to the doctor and the nearby police station. One unmanned aerial vehicle’s automated system alert people via speakers, ensuring social spacing. The problem involves a large percentage of appropriate and incorrect face mask wear using data from GitHub and Kaggle, including a training repository of 16,000 images and a testing data set of 12,751 images. To enhance the performance of the model’s learning, the methodology of 10-fold cross-validation will be used. Precision, recall, F1-score, and speed are then measured to determine the efficacy of the suggested approach.","['Weighted Naive Bayes Classification (WNBC)', 'faster Region-Based Convolutional Neural Networks (R-CNN)']","The research idea addresses the challenge of monitoring face mask usage and social distancing in outdoor environments, particularly in health establishments, to help control the spread of infectious diseases. The study recognizes the difficulty of detecting face masks and maintaining social distance due to variable visual conditions in images captured by unmanned aerial vehicles. The primary objective of the study is to develop a system capable of accurately identifying individuals wearing masks correctly or incorrectly and monitoring social distancing in crowded outdoor areas. This system aims to provide timely alerts to health authorities and law enforcement to ensure compliance with public health measures."
Biology,Feature reduction for hepatocellular carcinoma prediction using machine learning algorithms,"Abstract Hepatocellular carcinoma (HCC) is a highly prevalent form of liver cancer that necessitates accurate prediction models for early diagnosis and effective treatment. Machine learning algorithms have demonstrated promising results in various medical domains, including cancer prediction. In this study, we propose a comprehensive approach for HCC prediction by comparing the performance of different machine learning algorithms before and after applying feature reduction methods. We employ popular feature reduction techniques, such as weighting features, hidden features correlation, feature selection, and optimized selection, to extract a reduced feature subset that captures the most relevant information related to HCC. Subsequently, we apply multiple algorithms, including Naive Bayes, support vector machines (SVM), Neural Networks, Decision Tree, and K nearest neighbors (KNN), to both the original high-dimensional dataset and the reduced feature set. By comparing the predictive accuracy, precision, F Score, recall, and execution time of each algorithm, we assess the effectiveness of feature reduction in enhancing the performance of HCC prediction models. Our experimental results, obtained using a comprehensive dataset comprising clinical features of HCC patients, demonstrate that feature reduction significantly improves the performance of all examined algorithms. Notably, the reduced feature set consistently outperforms the original high-dimensional dataset in terms of prediction accuracy and execution time. After applying feature reduction techniques, the employed algorithms, namely decision trees, Naive Bayes, KNN, neural networks, and SVM achieved accuracies of 96%, 97.33%, 94.67%, 96%, and 96.00%, respectively.","['Naive Bayes', 'support vector machines (SVM)', 'Neural Networks', 'Decision Tree', 'K nearest neighbors (KNN)']","The study addresses the challenge of accurately predicting hepatocellular carcinoma (HCC), a highly prevalent form of liver cancer, which is crucial for early diagnosis and effective treatment. Improving prediction accuracy is essential to better understand and manage this disease. The primary aim of the study is to evaluate and compare the effectiveness of different approaches in enhancing the prediction of HCC by identifying the most relevant clinical features associated with the disease. The objective is to determine how reducing the number of features influences the accuracy and efficiency of HCC prediction using clinical data from patients."
Biology,Recent advancements and challenges of NLP-based sentiment analysis: A state-of-the-art review,"Sentiment analysis is a method within natural language processing that evaluates and identifies the emotional tone or mood conveyed in textual data. Scrutinizing words and phrases categorizes them into positive, negative, or neutral sentiments. The significance of sentiment analysis lies in its capacity to derive valuable insights from extensive textual data, empowering businesses to grasp customer sentiments, make informed choices, and enhance their offerings. For the further advancement of sentiment analysis, gaining a deep understanding of its algorithms, applications, current performance, and challenges is imperative. Therefore, in this extensive survey, we began exploring the vast array of application domains for sentiment analysis, scrutinizing them within the context of existing research. We then delved into prevalent pre-processing techniques, datasets, and evaluation metrics to enhance comprehension. We also explored Machine Learning, Deep Learning, Large Language Models and Pre-trained models in sentiment analysis, providing insights into their advantages and drawbacks. Subsequently, we precisely reviewed the experimental results and limitations of recent state-of-the-art articles. Finally, we discussed the diverse challenges encountered in sentiment analysis and proposed future research directions to mitigate these concerns. This extensive review provides a complete understanding of sentiment analysis, covering its models, application domains, results analysis, challenges, and research directions.","['Machine Learning', 'Deep Learning']","The research idea centers on the importance of understanding the emotional tone or mood conveyed in textual data, which can provide valuable insights into sentiments expressed in various contexts. This understanding is crucial for interpreting large volumes of text to better grasp underlying attitudes and opinions. The primary objective of the study is to comprehensively review the current state of sentiment analysis by examining its application domains, performance, challenges, and future directions. The study aims to provide a thorough understanding of sentiment analysis by exploring existing research, evaluating results, and identifying limitations to guide further advancements in the field."
Biology,FI-NPI: Exploring Optimal Control in Parallel Platform Systems,"Typically, the current and speed loop closure of servo motor of the parallel platform is accomplished with incremental PI regulation. The control method has strong robustness, but the parameter tuning process is cumbersome, and it is difficult to achieve the optimal control state. In order to further optimize the performance, this paper proposes a double-loop control structure based on fuzzy integral and neuron proportional integral (FI-NPI). The structure makes full use of the control advantages of the fuzzy controller and integrator to improve the performance of speed closed-loop control. And through the feedforward branch, the speed error is used as the teacher signal for neuron supervised learning, which improves the effect of current closed-loop control. Through comparative simulation experiments, this paper verifies that the FI-NPI controller has a faster dynamic response speed than the traditional PI controller. Finally, in this paper, the FI-NPI controller is implemented in C language in the servo-driven lower computer, and the speed closed-loop test of the BLDC motor is carried out. The experimental results show that the FI-NPI double-loop controller is better than the traditional double-PI controller in performance indicators such as convergence rate and RMSE, which confirms that the FI-NPI double-loop controller is more suitable for BLDC servo control.",['fuzzy integral'],"The research addresses the challenge of optimizing the current and speed loop closure of servo motors in parallel platforms, where traditional incremental PI regulation methods, despite their robustness, involve a cumbersome parameter tuning process and struggle to achieve optimal control performance. The study is motivated by the need to enhance the control performance and dynamic response speed of servo motor systems, particularly for brushless DC (BLDC) motors. The primary objective of the study is to develop and evaluate a double-loop control structure that improves speed closed-loop control performance and current closed-loop control effectiveness, ultimately demonstrating superior performance compared to traditional double-PI controllers in terms of convergence rate and error metrics during BLDC motor speed closed-loop tests."
Biology,CIFAKE: Image Classification and Explainable Identification of AI-Generated Synthetic Images,"Recent advances in synthetic data have enabled the generation of images with such high quality that human beings cannot tell the difference between real-life photographs and Artificial Intelligence (AI) generated images. Given the critical necessity of data reliability and authentication, this article proposes to enhance our ability to recognise AI-generated images through computer vision. Initially, a synthetic dataset is generated that mirrors the ten classes of the already available CIFAR-10 dataset with latent diffusion, providing a contrasting set of images for comparison to real photographs. The model is capable of generating complex visual attributes, such as photorealistic reflections in water. The two sets of data present as a binary classification problem with regard to whether the photograph is real or generated by AI. This study then proposes the use of a Convolutional Neural Network (CNN) to classify the images into two categories; Real or Fake. Following hyperparameter tuning and the training of 36 individual network topologies, the optimal approach could correctly classify the images with 92.98% accuracy. Finally, this study implements explainable AI via Gradient Class Activation Mapping to explore which features within the images are useful for classification. Interpretation reveals interesting concepts within the image, in particular, noting that the actual entity itself does not hold useful information for classification; instead, the model focuses on small visual imperfections in the background of the images. The complete dataset engineered for this study, referred to as the CIFAKE dataset, is made publicly available to the research community for future work.","['latent diffusion', 'Convolutional Neural Network (CNN)', 'Gradient Class Activation Mapping']","The research idea addresses the challenge of distinguishing between real-life photographs and synthetic images that are generated with such high quality that they are indistinguishable to the human eye. Given the critical necessity of data reliability and authentication, the study focuses on improving the ability to recognize artificially generated images. The primary objective of the study is to develop a method to classify images into real or AI-generated categories by creating a synthetic dataset that mirrors existing photographic classes and analyzing visual features that differentiate real photographs from generated images. The study aims to identify specific visual attributes, particularly subtle imperfections in the background, that can be used to reliably distinguish between authentic and synthetic images."
Biology,Optimization of hepatological clinical guidelines interpretation by large language models: a retrieval augmented generation-based framework,"Abstract Large language models (LLMs) can potentially transform healthcare, particularly in providing the right information to the right provider at the right time in the hospital workflow. This study investigates the integration of LLMs into healthcare, specifically focusing on improving clinical decision support systems (CDSSs) through accurate interpretation of medical guidelines for chronic Hepatitis C Virus infection management. Utilizing OpenAI’s GPT-4 Turbo model, we developed a customized LLM framework that incorporates retrieval augmented generation (RAG) and prompt engineering. Our framework involved guideline conversion into the best-structured format that can be efficiently processed by LLMs to provide the most accurate output. An ablation study was conducted to evaluate the impact of different formatting and learning strategies on the LLM’s answer generation accuracy. The baseline GPT-4 Turbo model’s performance was compared against five experimental setups with increasing levels of complexity: inclusion of in-context guidelines, guideline reformatting, and implementation of few-shot learning. Our primary outcome was the qualitative assessment of accuracy based on expert review, while secondary outcomes included the quantitative measurement of similarity of LLM-generated responses to expert-provided answers using text-similarity scores. The results showed a significant improvement in accuracy from 43 to 99% ( p &lt; 0.001), when guidelines were provided as context in a coherent corpus of text and non-text sources were converted into text. In addition, few-shot learning did not seem to improve overall accuracy. The study highlights that structured guideline reformatting and advanced prompt engineering (data quality vs. data quantity) can enhance the efficacy of LLM integrations to CDSSs for guideline delivery.","['OpenAI’s GPT-4 Turbo model', 'retrieval augmented generation (RAG)', 'few-shot learning']",The study addresses the challenge of accurately interpreting medical guidelines for the management of chronic Hepatitis C Virus infection within clinical decision support systems. There is a need to improve the delivery of guideline-based information to healthcare providers to enhance clinical decision-making in hospital workflows. The primary aim of the study is to investigate how the integration and structured presentation of clinical guidelines can improve the accuracy of guideline interpretation for chronic Hepatitis C Virus infection management. The study focuses on evaluating the impact of guideline formatting and contextual presentation on the quality and accuracy of clinical recommendations provided to healthcare professionals.
Biology,Survival Prediction Across Diverse Cancer Types Using Neural Networks,"Gastric cancer and Colon adenocarcinoma represent widespread and challenging malignancies with high mortality rates and complex treatment landscapes. In response to the critical need for accurate prognosis in cancer patients, the medical community has embraced the 5-year survival rate as a vital metric for estimating patient outcomes. This study introduces a pioneering approach to enhance survival prediction models for gastric and Colon adenocarcinoma patients. Leveraging advanced image analysis techniques, we sliced whole slide images (WSI) of these cancers, extracting comprehensive features to capture nuanced tumor characteristics. Subsequently, we constructed patient-level graphs, encapsulating intricate spatial relationships within tumor tissues. These graphs served as inputs for a sophisticated 4-layer graph convolutional neural network (GCN), designed to exploit the inherent connectivity of the data for comprehensive analysis and prediction. By integrating patients' total survival time and survival status, we computed C-index values for gastric cancer and Colon adenocarcinoma, yielding 0.57 and 0.64, respectively. Significantly surpassing previous convolutional neural network models, these results underscore the efficacy of our approach in accurately predicting patient survival outcomes. This research holds profound implications for both the medical and AI communities, offering insights into cancer biology and progression while advancing personalized treatment strategies. Ultimately, our study represents a significant stride in leveraging AI-driven methodologies to revolutionize cancer prognosis and improve patient outcomes on a global scale.","['graph convolutional neural network (GCN)', 'convolutional neural network']","The research idea centers on addressing the high mortality rates and complex treatment challenges associated with gastric cancer and colon adenocarcinoma. There is a critical need for accurate prognosis in patients with these malignancies, with the 5-year survival rate serving as an essential metric for estimating patient outcomes. The study aims to improve the prediction of survival outcomes by capturing detailed tumor characteristics and spatial relationships within tumor tissues. The primary objective of the study is to enhance survival prediction for gastric and colon adenocarcinoma patients by developing a method that integrates comprehensive tumor features and patient survival data to provide more accurate estimates of patient prognosis, ultimately contributing to better-informed treatment strategies."
Biology,"Benchmarking Micro-Action Recognition: Dataset, Methods, and Applications","Micro-action is an imperceptible non-verbal behaviour characterised by low-intensity movement. It offers insights into the feelings and intentions of individuals and is important for human-oriented applications such as emotion recognition and psychological assessment. However, the identification, differentiation, and understanding of micro-actions pose challenges due to the imperceptible and inaccessible nature of these subtle human behaviors in everyday life. In this study, we innovatively collect a new micro-action dataset designated as Micro-action-52 (MA-52), and propose a benchmark named micro-action network (MANet) for micro-action recognition (MAR) task. Uniquely, MA-52 provides the whole-body perspective including gestures, upper- and lower-limb movements, attempting to reveal comprehensive micro-action cues. In detail, MA-52 contains 52 micro-action categories along with seven body part labels, and encompasses a full array of realistic and natural micro-actions, accounting for 205 participants and 22,422 video instances collated from the psychological interviews. Based on the proposed dataset, we assess MANet and other nine prevalent action recognition methods. MANet incorporates squeeze-and-excitation (SE) and temporal shift module (TSM) into the ResNet architecture for modeling the spatiotemporal characteristics of micro-actions. Then a joint-embedding loss is designed for semantic matching between video and action labels; the loss is used to better distinguish between visually similar yet distinct micro-action categories. The extended application in emotion recognition has demonstrated one of the important values of our proposed dataset and method. In the future, further exploration of human behaviour, emotion, and psychological assessment will be conducted in depth. The dataset and source code are released at https://github.com/VUT-HFUT/Micro-Action.","['squeeze-and-excitation (SE)', 'temporal shift module (TSM)', 'ResNet architecture', 'joint-embedding loss']","The study addresses the challenge of identifying, differentiating, and understanding micro-actions, which are imperceptible non-verbal behaviors characterized by low-intensity movements that provide insights into individuals' feelings and intentions. These subtle human behaviors are difficult to observe and analyze in everyday life, yet they are important for applications such as emotion recognition and psychological assessment. The primary aim of the study is to comprehensively capture and categorize micro-actions from a whole-body perspective, including gestures and limb movements, by creating a new dataset with diverse micro-action categories and body part labels. This effort seeks to reveal detailed micro-action cues to enhance the understanding of subtle human behaviors in natural and realistic settings."
Biology,Aspect-based drug review classification through a hybrid model with ant colony optimization using deep learning,"Abstract The task of aspect-level sentiment analysis is intricately designed to determine the sentiment polarity directed towards a specific target within a sentence. With the increasing availability of online reviews and the growing importance of healthcare decisions, analyzing drug reviews has become a critical task. Traditional sentiment analysis, which categorizes a whole review as positive, negative, or neutral, provides limited insights for consumers and healthcare professionals. Aspect-based sentiment analysis (ABSA) aims to overcome these limitations by identifying and evaluating the sentiment associated with specific aspects or attributes of drugs mentioned in the reviews. Various fields, including business, politics, and medicine, have been explored in the context of sentiment analysis. Automation of online user reviews allows pharmaceutical companies to assess large amounts of user feedback. This helps extract pharmacological efficacy and side effect insights. The data collected could improve pharmacovigilance. Reviewing user comments can provide valuable data that can be used to improve drug safety and efficacy monitoring procedures. This improves pharmacovigilance processes, improving pharmaceutical outcomes understanding and corporate decision-making. Therefore, we propose a pre-trained RoBERTa with a Bi-LSTM model to categorise drug reviews from online sources and pre-process the text data. Ant Colony Optimization can be used in feature selection for ABSA, helping to identify the most relevant aspects and sentiments. Further, RoBERTa is fine-tuned to perform ABSA on the dataset, enabling the system to categorize aspects and determine the associated sentiment. The outcomes reveal that the suggested framework has achieved higher accuracy (96.78%) and F1 score (98.29%) on druglib.com, and 95.02% on the drugs.com dataset, than several prior state-of-the-art methods.","['pre-trained RoBERTa', 'Bi-LSTM model', 'fine-tuned RoBERTa']","The study addresses the challenge of understanding specific sentiments expressed towards different aspects of drugs within online reviews, which is important due to the increasing availability of such reviews and their impact on healthcare decisions. Traditional methods that classify entire reviews as positive, negative, or neutral offer limited insights for consumers and healthcare professionals, highlighting the need for more detailed sentiment evaluation related to particular drug attributes. This detailed understanding can enhance pharmacovigilance by providing valuable information on drug efficacy and side effects from user feedback. The primary aim of the study is to improve the categorization of drug reviews by identifying and evaluating sentiments associated with specific drug aspects mentioned in online user comments, thereby contributing to better monitoring of drug safety and efficacy."
Biology,"A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection in Industrial Time Series: Methods, Applications, and Directions","Automating the monitoring of industrial processes has the potential to enhance efficiency and optimize quality by promptly detecting abnormal events and thus facilitating timely interventions. Deep learning, with its capacity to discern non-trivial patterns within large datasets, plays a pivotal role in this process. Standard deep learning methods are suitable to solve a specific task given a specific type of data. During training, deep learning demands large volumes of labeled data. However, due to the dynamic nature of the industrial processes and environment, it is impractical to acquire large-scale labeled data for standard deep learning training for every slightly different case anew. Deep transfer learning offers a solution to this problem. By leveraging knowledge from related tasks and accounting for variations in data distributions, the transfer learning framework solves new tasks with little or even no additional labeled data. The approach bypasses the need to retrain a model from scratch for every new setup and dramatically reduces the labeled data requirement. This survey first provides an in-depth review of deep transfer learning, examining the problem settings of transfer learning and classifying the prevailing deep transfer learning methods. Moreover, we delve into applications of deep transfer learning in the context of a broad spectrum of time series anomaly detection tasks prevalent in primary industrial domains, e.g., manufacturing process monitoring, predictive maintenance, energy management, and infrastructure facility monitoring. We discuss the challenges and limitations of deep transfer learning in industrial contexts and conclude the survey with practical directions and actionable suggestions to address the need to leverage diverse time series data for anomaly detection in an increasingly dynamic production environment.","['deep learning', 'deep transfer learning', 'transfer learning framework']","The study addresses the challenge of monitoring industrial processes to enhance efficiency and optimize quality by detecting abnormal events promptly, which facilitates timely interventions. A significant problem is the dynamic nature of industrial environments that makes it impractical to acquire large-scale labeled data for each new or slightly different case. The primary aim of the study is to review and classify methods that can leverage knowledge from related tasks to solve new monitoring challenges with minimal additional labeled data. It also seeks to explore applications of these approaches in various industrial domains and discuss the challenges and limitations associated with their use in dynamic production environments."
Biology,Enhancing precision agriculture: A comprehensive review of machine learning and AI vision applications in all-terrain vehicle for farm automation,"The automation of all-terrain vehicles (ATVs) through the integration of advanced technologies such as machine learning (ML) and artificial intelligence (AI) vision has significantly changed precision agriculture. This paper aims to analyse and develop trends to provide comprehensive knowledge of the current state of ATV-based precision agriculture and the future possibilities of ML and AI. A bibliometric analysis was conducted through network diagram with keywords taken from previous publications in the domain. This review comprehensively analyses the potential of machine learning and artificial intelligence in transforming farming operations through the automation of tasks and the deployment of all-terrain vehicles. The research extensively analyses how machine learning methods have influenced several aspects of agricultural activities, such as planting, harvesting, spraying, weeding, crop monitoring, and others. AI vision systems are being researched for their ability to enhance precise and prompt decision-making in ATV-driven agricultural automation. These technologies have been thoroughly tested to show how they can improve crop yield, reducing overall investment, and make farming more efficient. Examples include machine learning-based seeding accuracy, AI-enabled crop health monitoring, and the use of AI vision for accurate pesticide application. The assessment examines challenges such as data privacy problems and scalability constraints, along with potential advancements and future prospects in the field. This will assist researchers and practitioners in making well-informed judgments regarding farming practices that are efficient, sustainable, and technologically robust.",['machine learning'],"The research idea centers on the transformation of precision agriculture through the automation of all-terrain vehicles (ATVs), focusing on improving farming operations such as planting, harvesting, spraying, weeding, and crop monitoring. The study addresses the need to enhance crop yield, reduce investment costs, and increase the efficiency and sustainability of agricultural practices by integrating advanced technologies into ATV-driven farming. The primary objective of the study is to analyze and develop trends in ATV-based precision agriculture to provide comprehensive knowledge of the current state and future possibilities in this field. It aims to assist researchers and practitioners in making well-informed decisions regarding efficient, sustainable, and technologically advanced farming practices."
Biology,An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing: Algorithm Development and Validation Study,"Background Large language models (LLMs) have shown remarkable capabilities in natural language processing (NLP), especially in domains where labeled data are scarce or expensive, such as the clinical domain. However, to unlock the clinical knowledge hidden in these LLMs, we need to design effective prompts that can guide them to perform specific clinical NLP tasks without any task-specific training data. This is known as in-context learning, which is an art and science that requires understanding the strengths and weaknesses of different LLMs and prompt engineering approaches. Objective The objective of this study is to assess the effectiveness of various prompt engineering techniques, including 2 newly introduced types—heuristic and ensemble prompts, for zero-shot and few-shot clinical information extraction using pretrained language models. Methods This comprehensive experimental study evaluated different prompt types (simple prefix, simple cloze, chain of thought, anticipatory, heuristic, and ensemble) across 5 clinical NLP tasks: clinical sense disambiguation, biomedical evidence extraction, coreference resolution, medication status extraction, and medication attribute extraction. The performance of these prompts was assessed using 3 state-of-the-art language models: GPT-3.5 (OpenAI), Gemini (Google), and LLaMA-2 (Meta). The study contrasted zero-shot with few-shot prompting and explored the effectiveness of ensemble approaches. Results The study revealed that task-specific prompt tailoring is vital for the high performance of LLMs for zero-shot clinical NLP. In clinical sense disambiguation, GPT-3.5 achieved an accuracy of 0.96 with heuristic prompts and 0.94 in biomedical evidence extraction. Heuristic prompts, alongside chain of thought prompts, were highly effective across tasks. Few-shot prompting improved performance in complex scenarios, and ensemble approaches capitalized on multiple prompt strengths. GPT-3.5 consistently outperformed Gemini and LLaMA-2 across tasks and prompt types. Conclusions This study provides a rigorous evaluation of prompt engineering methodologies and introduces innovative techniques for clinical information extraction, demonstrating the potential of in-context learning in the clinical domain. These findings offer clear guidelines for future prompt-based clinical NLP research, facilitating engagement by non-NLP experts in clinical NLP advancements. To the best of our knowledge, this is one of the first works on the empirical evaluation of different prompt engineering approaches for clinical NLP in this era of generative artificial intelligence, and we hope that it will inspire and inform future research in this area.","['in-context learning', 'ensemble approaches', 'zero-shot prompting', 'few-shot prompting']","The research idea addresses the challenge of extracting valuable clinical knowledge from large language models without relying on task-specific training data, focusing on the need to design effective prompts that guide these models to perform specific clinical information extraction tasks. This is motivated by the scarcity and expense of labeled clinical data and the importance of unlocking hidden clinical insights to improve various clinical natural language processing tasks. The primary objective of the study is to assess the effectiveness of various prompt engineering techniques, including newly introduced heuristic and ensemble prompts, for zero-shot and few-shot clinical information extraction across multiple clinical tasks such as clinical sense disambiguation, biomedical evidence extraction, coreference resolution, medication status extraction, and medication attribute extraction. The study aims to provide a rigorous evaluation of these approaches to inform and guide future clinical information extraction research."
Biology,A systematic review of hyperspectral imaging in precision agriculture: Analysis of its current state and future prospects,"Hyperspectral sensor adaptability in precision agriculture to digital images is still at its nascent stage. Hyperspectral imaging (HSI) is data rich in solving agricultural problems like disease detection, weed detection, stress detection, crop monitoring, nutrient application, soil mineralogy, yield estimation, and sorting applications. With modern precision agriculture, the challenge now is to bring these applications to the field for real-time solutions, where machines are enabled to conduct analyses without expert supervision and communicate the results to users for better management of farmlands; a necessary step to gain complete autonomy in agricultural farmlands. Significant advancements in HSI technology for precision agriculture are required to fully realize its potential. As a wide-ranging collection of the status of HSI and analysis in precision agriculture is lacking, this review endeavors to provide a comprehensive overview of the recent advancements and trends of HSI in precision agriculture for real-time applications. In this study, a systematic review of 163 scientific articles published over the past twenty years (2003–2023) was conducted. Of these, 97 were selected for further analysis based on their relevance to the topic at hand. Topics include conventional data preprocessing techniques, hyperspectral data acquisition, data compression methods, and segmentation methods. The hardware implementation of field-programmable gate arrays (FPGAs) and graphics processing units (GPUs) for high-speed data processing and application of machine learning and deep learning technologies were explored. This review highlights the potential of HSI as a powerful tool for precision agriculture, particularly in real-time applications, discusses limitations, and provides insights into future research directions.","['machine learning', 'deep learning']","The research idea centers on the emerging potential of hyperspectral imaging (HSI) technology in precision agriculture, particularly its ability to address critical agricultural challenges such as disease detection, weed detection, stress detection, crop monitoring, nutrient application, soil mineralogy, yield estimation, and sorting. Despite its promise, the adaptation of HSI for real-time, field-level applications remains underdeveloped, limiting its practical use for autonomous farmland management. The study’s primary objective is to provide a comprehensive overview of recent advancements and trends in the use of hyperspectral imaging within precision agriculture, focusing on its application for real-time solutions. This review aims to highlight the current status, potential, limitations, and future research directions of HSI technology to better realize its benefits in agricultural practices."
Biology,Critical review on water quality analysis using IoT and machine learning models,"Water quality and its management are the most precise concerns confronting humanity globally. This article evaluates the various sensors used for water quality monitoring and focuses on the water quality index considering the multiple physical, chemical, and biological parameters. A Review of Internet of Things (IoT) research for water quality monitoring and analysis, sensors used for water quality can help remote monitoring of the water quality parameters using various IoT-based sensors that convey the assembled estimations utilizing Low-Power Wide Area Network innovations. Overall, the IoT system was 95 % accurate in measuring pH, Turbidity, TDS, and Temperature, while the traditional method was only 85 % accurate. Also, this study reviewed the different A.I. techniques used to assess water quality, including conventional machine learning techniques, Support Vector Machines, Deep Neural Networks, and K-nearest neighbors. Compared to traditional methods, machine learning and deep learning can significantly increase the accuracy of measurements of groundwater quality. However, various variables, such as the caliber of the training data, the water quality metrics' complexity, and the monitoring frequency, will affect the accuracy. The geographical information system (GIS) is used for spatial data analysis and managing water resources. The quality of its data is also reviewed in the paper. Based on these analyses, the study has forecasted the future sensors, Geospatial Technology, and machine learning techniques for water quality monitoring and analysis.","['Support Vector Machines', 'Deep Neural Networks', 'K-nearest neighbors']","The research idea centers on the critical global concern of water quality and its management, emphasizing the importance of monitoring multiple physical, chemical, and biological parameters to assess water quality accurately. The study addresses the need for effective evaluation of water quality through various sensors and indices to ensure safe and sustainable water resources. The primary objective of the study is to evaluate the different sensors used for water quality monitoring, focusing on the water quality index and the assessment of multiple parameters such as pH, turbidity, total dissolved solids, and temperature. Additionally, the study aims to review the quality of spatial data related to water resources and forecast future advancements in sensor technology and geospatial methods for improved water quality monitoring."
Biology,A novel and dynamic land use/cover change research framework based on an improved PLUS model and a fuzzy multiobjective programming model,"Spatial reconstruction and scenario simulation of historical processes and future trends of land use/cover change (LUCC) can help to reveal the historical background of land conversion and the spatial distribution of future land. Moreover, there is a close relationship between the spatiotemporal dynamics of land use/cover and changes in different ecosystem services (ESs). Using this relationship to simulate future land use scenarios is important. In this study, an LUCC dynamic analysis framework (LSTM-PLUS-FMOP) was constructed based on a deep learning time series forecasting model (LSTM), a parallelized urban land use simulation (PLUS) model and a fuzzy multiobjective programming (FMOP) model. The PLUS model was used to analyze the driving mechanism of land expansion and explore the land conversion pattern. In addition, three land conversion scenarios were established: natural land expansion (NLE), economic development priority (EDP) and regional sustainable development (RSD). The FMOP model and the relationship between LUCC and ES were used to perform a spatial simulation of land conversion. The uncertainty parameters in the model were treated by intuitionistic fuzzy numbers (IFSs). This study applied the constructed framework to the Yellow River Basin of Shaanxi Province (YRB-SX). The results showed that (1) from 2000 to 2020, the cropland area of the YRB-SX continuously decreased by 12.67 × 104 ha, while the built-up area continuously increased by 28.25 × 104 ha. The net reduction in woodland and grassland area was 13.90 × 104 ha. (2) The relative error range of land prediction using the LSTM model was 0.0003– 0.0042. This model had better accuracy than the Markov chain prediction model. (3) The cropland area decreased by 0.26% (NLE), 0.85% (EDP) and 1.68% (RSD) under the three scenarios. The built-up area increased by 25.01%, 32.76% and 14.72%, respectively. The RSD scenario followed the principles of ecological protection and spatial constraints, which mitigated the degradation of the ecosystem to some extent. This coupled simulation framework will help to obtain land allocation schemes that meet the requirements of ecological protection and provide solutions for rational land management.",['LSTM'],"The study addresses the problem of understanding the historical processes and future trends of land use and land cover change (LUCC) and their impact on ecosystem services (ESs). It highlights the importance of revealing the spatial distribution of land conversion and the close relationship between LUCC dynamics and changes in different ecosystem services. This understanding is crucial for simulating future land use scenarios that can inform ecological protection and sustainable land management. The primary aim of the study is to analyze the driving mechanisms of land expansion and land conversion patterns in the Yellow River Basin of Shaanxi Province, and to simulate future land use scenarios under different conditions, including natural land expansion, economic development priority, and regional sustainable development. The study seeks to provide land allocation schemes that balance ecological protection with land use demands, thereby offering solutions for rational land management."
Biology,Utilizing Hybrid Machine Learning and Soft Computing Techniques for Landslide Susceptibility Mapping in a Drainage Basin,"The hydrological system of thebasin of Lake Urmia is complex, deriving its supply from a network comprising 13 perennial rivers, along withnumerous small springs and direct precipitation onto the lake’s surface. Among these contributors, approximately half of the inflow is attributed to the Zarrineh River and the Simineh River. Remarkably, Lake Urmia lacks a natural outlet, with its water loss occurring solely through evaporation processes. This study employed a comprehensive methodology integrating ground surveys, remote sensing analyses, and meticulous documentation of historical landslides within the basin as primary information sources. Through this investigative approach, we preciselyidentified and geolocated a total of 512 historical landslide occurrences across the Urmia Lake drainage basin, leveraging GPS technology for precision. Thisarticle introduces a suite of hybrid machine learning predictive models, such as support-vector machine (SVM), random forest (RF), decision trees (DT), logistic regression (LR), fuzzy logic (FL), and the technique for order of preference by similarity to the ideal solution (TOPSIS). These models were strategically deployed to assess landslide susceptibility within the region. The outcomes of the landslide susceptibility assessment reveal that the main high susceptible zones for landslide occurrence are concentrated in the northwestern, northern, northeastern, and some southern and southeastern areas of the region. Moreover, when considering the implementation of predictions using different algorithms, it became evident that SVM exhibited superior performance regardingboth accuracy (0.89) and precision (0.89), followed by RF, with and accuracy of 0.83 and a precision of 0.83. However, it is noteworthy that TOPSIS yielded the lowest accuracy value among the algorithms assessed.","['support-vector machine (SVM)', 'random forest (RF)', 'decision trees (DT)', 'logistic regression (LR)']","The hydrological system of the Lake Urmia basin is complex, relying on inflows from 13 perennial rivers, numerous small springs, and direct precipitation, with approximately half of the inflow coming from the Zarrineh and Simineh Rivers. Lake Urmia lacks a natural outlet, and its water loss occurs solely through evaporation, making the understanding of environmental factors such as landslides within the basin critical. The study aims to identify and geolocate historical landslide occurrences across the Urmia Lake drainage basin to better understand their spatial distribution. The primary objective is to assess landslide susceptibility within the region, focusing on identifying high-risk zones to inform environmental management and hazard mitigation efforts."
Biology,Comparison of Random Forest and XGBoost Classifiers Using Integrated Optical and SAR Features for Mapping Urban Impervious Surface,"The integration of optical and SAR datasets through ensemble machine learning models shows promising results in urban remote sensing applications. The integration of multi-sensor datasets enhances the accuracy of information extraction. This research presents a comparison of two ensemble machine learning classifiers (random forest and extreme gradient boost (XGBoost)) classifiers using an integration of optical and SAR features and simple layer stacking (SLS) techniques. Therefore, Sentinel-1 (SAR) and Landsat 8 (optical) datasets were used with SAR textures and enhanced modified indices to extract features for the year 2023. The classification process utilized two machine learning algorithms, random forest and XGBoost, for urban impervious surface extraction. The study focused on three significant East Asian cities with diverse urban dynamics: Jakarta, Manila, and Seoul. This research proposed a novel index called the Normalized Blue Water Index (NBWI), which distinguishes water from other features and was utilized as an optical feature. Results showed an overall accuracy of 81% for UIS classification using XGBoost and 77% with RF while classifying land use land cover into four major classes (water, vegetation, bare soil, and urban impervious). However, the proposed framework with the XGBoost classifier outperformed the RF algorithm and Dynamic World (DW) data product and comparatively showed higher classification accuracy. Still, all three results show poor separability with bare soil class compared to ground truth data. XGBoost outperformed random forest and Dynamic World in classification accuracy, highlighting its potential use in urban remote sensing applications.","['ensemble machine learning models', 'random forest', 'extreme gradient boost (XGBoost)']","The study addresses the challenge of accurately extracting urban impervious surfaces and distinguishing land cover types in rapidly changing urban environments, particularly in diverse East Asian cities such as Jakarta, Manila, and Seoul. Improving the integration of multi-sensor datasets, including optical and synthetic aperture radar (SAR) data, is crucial for enhancing the precision of urban land use and land cover classification. The primary aim of the research is to compare the effectiveness of different classification approaches using integrated optical and SAR features to improve the accuracy of urban impervious surface extraction. Additionally, the study proposes a novel index, the Normalized Blue Water Index (NBWI), to better differentiate water bodies from other land cover types, with the goal of achieving higher classification accuracy across major land cover classes including water, vegetation, bare soil, and urban impervious surfaces."
Biology,Enhancing plasticity in optoelectronic artificial synapses: A pathway to efficient neuromorphic computing,"The continuous growth in artificial intelligence and high-performance computing has necessitated the development of efficient optoelectronic artificial synapses crucial for neuromorphic computing (NC). Ga2O3 is an emerging wide-bandgap semiconductor with high deep ultraviolet absorption, tunable persistent photoconductivity, and excellent stability toward electric fields, making it a promising component for optoelectronic artificial synapses. Currently reported Ga2O3 optoelectronic artificial synapses often suffer from complex fabrication processes and potential room for improvement due to plasticity. To address the issue of low device plasticity and practical application scenarios, we present an amorphous Ga2O3 (α-GaOx) flexible optoelectronic artificial synapse. This synapse modulates light stimulus signals using electron/oxygen vacancies and optical stimulation and operates as a visual storage device for information processing. We investigate the improvement of the optoelectronic synapses' plasticity by controlling the number of oxygen vacancies via a plasma treatment method and demonstrate its effective application in a three-layer backpropagation neural network for handwritten digit classification. Under the same stimulus conditions, the synaptic weight of samples treated with Ar plasma exhibits a higher rate of change, with the current levels increasing by 2–3 orders of magnitude, achieving greater plasticity. The improved optoelectronic synapses achieved an accuracy of 93.34%/94%, demonstrating their potential as efficient computing solutions and insights for future applications in NC chips.",['backpropagation neural network'],"The study addresses the challenge of developing efficient optoelectronic components based on Ga2O3, a wide-bandgap semiconductor with desirable properties such as high deep ultraviolet absorption and excellent stability, for use in devices that mimic synaptic functions. Current Ga2O3-based devices face limitations including complex fabrication and insufficient plasticity, which restrict their practical applications. The primary aim of the research is to enhance the plasticity of amorphous Ga2O3 flexible optoelectronic synapses by controlling oxygen vacancies, thereby improving their performance as visual storage devices for information processing. The study seeks to demonstrate the improved functionality of these synapses under light stimulation and their potential application in information processing tasks."
Biology,Garlic Origin Traceability and Identification Based on Fusion of Multi-Source Heterogeneous Spectral Information,"The chemical composition and nutritional content of garlic are greatly impacted by its production location, leading to distinct flavor profiles and functional properties among garlic varieties from diverse origins. Consequently, these variations determine the preference and acceptance among diverse consumer groups. In this study, purple-skinned garlic samples were collected from five regions in China: Yunnan, Shandong, Henan, Anhui, and Jiangsu Provinces. Mid-infrared spectroscopy and ultraviolet spectroscopy were utilized to analyze the components of garlic cells. Three preprocessing methods, including Multiple Scattering Correction (MSC), Savitzky–Golay Smoothing (SG Smoothing), and Standard Normalized Variate (SNV), were applied to reduce the background noise of spectroscopy data. Following variable feature extraction by Genetic Algorithm (GA), a variety of machine learning algorithms, including XGboost, Support Vector Classification (SVC), Random Forest (RF), and Artificial Neural Network (ANN), were used according to the fusion of spectral data to obtain the best processing results. The results showed that the best-performing model for ultraviolet spectroscopy data was SNV-GA-ANN, with an accuracy of 99.73%. The best-performing model for mid-infrared spectroscopy data was SNV-GA-RF, with an accuracy of 97.34%. After the fusion of ultraviolet and mid-infrared spectroscopy data, the SNV-GA-SVC, SNV-GA-RF, SNV-GA-ANN, and SNV-GA-XGboost models achieved 100% accuracy in both training and test sets. Although there were some differences in the accuracy of the four models under different preprocessing methods, the fusion of ultraviolet and mid-infrared spectroscopy data yielded the best outcomes, with an accuracy of 100%. Overall, the combination of ultraviolet and mid-infrared spectroscopy data fusion and chemometrics established in this study provides a theoretical foundation for identifying the origin of garlic, as well as that of other agricultural products.","['Genetic Algorithm (GA)', 'XGboost', 'Support Vector Classification (SVC)', 'Random Forest (RF)', 'Artificial Neural Network (ANN)']","The chemical composition and nutritional content of garlic vary significantly depending on its production location, resulting in distinct flavor profiles and functional properties among garlic varieties from different regions. These variations influence consumer preference and acceptance across diverse groups. The primary aim of this study was to analyze purple-skinned garlic samples collected from five regions in China to identify differences in their chemical components. The study sought to establish a theoretical foundation for accurately determining the geographical origin of garlic and potentially other agricultural products based on their chemical characteristics."
Biology,Estimating compressive strength of concrete containing rice husk ash using interpretable machine learning-based models,"The construction sector is a major contributor to global greenhouse gas emissions. Using recycled and waste materials in concrete is a practical solution to address environmental challenges. Currently, agricultural waste is widely used as a substitute for cement in the production of eco-friendly concrete. However, traditional methods for assessing the strength of such materials are both expensive and time-consuming. Therefore, this study uses machine learning techniques to develop prediction models for the compressive strength (CS) of rice husk ash (RHA) concrete. The ML techniques used in the present study include random forest (RF), light gradient boosting machine (LightGBM), ridge regression, and extreme gradient boosting (XGBoost). A total of 348 values of CS were collected from the experimental studies, and five characteristics of RHA concrete were taken as input variables. For the performance assessment of the models, multiple statistical metrics were used. During the training phase, the correlation coefficients (R) obtained for ridge regression, RF, XGBoost, and LightGBM were 0.943, 0.981, 0.985, and 0.996, respectively. In the testing set, these values demonstrated even higher performance, with correlation coefficients of 0.971, 0.993, 0.992, and 0.998 for ridge regression, RF, XGBoost, and LightGBM, respectively. The statistical analysis revealed that the LightGBM model outperformed other models, whereas the ridge regression model exhibited comparatively lower accuracy. SHapley Additive exPlanation (SHAP) method was employed for the interpretability of the developed model. The SHAP analysis revealed that water-to-cement is a controlling parameter in estimating the CS of RHA concrete. In conclusion, this study provides valuable guidance for builders and researchers to estimate the CS of RHA concrete. However, it is suggested that more input variables be incorporated and hybrid models utilized to further enhance the reliability and precision of the models.","['random forest (RF)', 'light gradient boosting machine (LightGBM)', 'ridge regression', 'extreme gradient boosting (XGBoost)', 'SHapley Additive exPlanation (SHAP)']","The construction sector significantly contributes to global greenhouse gas emissions, prompting the need for sustainable building materials. Using recycled and waste materials, such as agricultural waste, as substitutes for cement in concrete production offers an eco-friendly solution to reduce environmental impact. However, traditional methods for assessing the strength of such materials are costly and time-consuming, creating a challenge in efficiently evaluating their performance. This study aims to develop reliable approaches to predict the compressive strength of rice husk ash concrete, an eco-friendly material made by incorporating agricultural waste. The primary objective of the study is to establish accurate prediction models for the compressive strength of rice husk ash concrete based on key material characteristics, thereby providing valuable guidance for builders and researchers in estimating its performance. Additionally, the study seeks to identify the most influential factors affecting compressive strength, with the goal of improving the reliability and precision of strength estimation for sustainable concrete materials."
Biology,Improving Thyroid Disorder Diagnosis via Ensemble Stacking and Bidirectional Feature Selection,"Thyroid disorders represent a significant global health challenge with hypothyroidism and hyperthyroidism as two common conditions arising from dysfunction in the thyroid gland.Accurate and timely diagnosis of these disorders is crucial for effective treatment and patient care.This research introduces a comprehensive approach to improve the accuracy of thyroid disorder diagnosis through the integration of ensemble stacking and advanced feature selection techniques.Sequential forward feature selection, sequential backward feature elimination, and bidirectional feature elimination are investigated in this study.In ensemble learning, random forest, adaptive boosting, and bagging classifiers are employed.The effectiveness of these techniques is evaluated using two different datasets obtained from the University of California Irvine-Machine Learning Repository, both of which undergo preprocessing steps, including outlier removal, addressing missing data, data cleansing, and feature reduction.Extensive experimentation demonstrates the remarkable success of proposed ensemble stacking and bidirectional feature elimination achieving 100% and 99.86% accuracy in identifying hyperthyroidism and hypothyroidism, respectively.Beyond enhancing detection accuracy, the ensemble stacking model also demonstrated a streamlined computational complexity which is pivotal for practical medical applications.It significantly outperformed existing studies with similar objectives underscoring the viability and effectiveness of the proposed scheme.This research offers an innovative perspective and sets the platform for improved thyroid disorder diagnosis with broader implications for healthcare and patient well-being.","['ensemble stacking', 'sequential forward feature selection', 'sequential backward feature elimination', 'random forest', 'adaptive boosting', 'bagging classifiers']","Thyroid disorders, including hypothyroidism and hyperthyroidism, represent a significant global health challenge due to dysfunction in the thyroid gland. Accurate and timely diagnosis of these conditions is crucial for effective treatment and improving patient care. The primary aim of this study is to enhance the accuracy of thyroid disorder diagnosis by investigating and integrating various feature selection techniques and classification approaches. This research seeks to improve the identification of hyperthyroidism and hypothyroidism, ultimately contributing to better healthcare outcomes and patient well-being."
Biology,Large Language Models are Few-Shot Summarizers: Multi-Intent Comment Generation via In-Context Learning,"Code comment generation aims at generating natural language descriptions for a code snippet to facilitate developers' program comprehension activities. Despite being studied for a long time, a bottleneck for existing approaches is that given a code snippet, they can only generate one comment while developers usually need to know information from diverse perspectives such as what is the functionality of this code snippet and how to use it. To tackle this limitation, this study empirically investigates the feasibility of utilizing large language models (LLMs) to generate comments that can fulfill developers' diverse intents. Our intuition is based on the facts that (1) the code and its pairwise comment are used during the pre-training process of LLMs to build the semantic connection between the natural language and programming language, and (2) comments in the real-world projects, which are collected for the pre-training, usually contain different developers' intents. We thus postulate that the LLMs can already understand the code from different perspectives after the pre-training. Indeed, experiments on two large-scale datasets demonstrate the rationale of our insights: by adopting the in-context learning paradigm and giving adequate prompts to the LLM (e.g., providing it with ten or more examples), the LLM can significantly outperform a state-of-the-art supervised learning approach on generating comments with multiple intents. Results also show that customized strategies for constructing the prompts and post-processing strategies for reranking the results can both boost the LLM's performances, which shed light on future research directions for using LLMs to achieve comment generation.","['in-context learning paradigm', 'supervised learning approach']","The research idea addresses the challenge of generating natural language descriptions for code snippets that capture diverse perspectives, such as the functionality and usage of the code, which is important for developers' program comprehension. Existing approaches are limited because they typically produce only one comment per code snippet, whereas developers require information from multiple viewpoints to fully understand the code. The study aims to explore whether it is possible to generate comments that fulfill these diverse informational needs. The primary objective of the study is to empirically investigate the feasibility of generating multi-intent comments for code snippets that reflect different developers' perspectives, thereby enhancing the usefulness of code comments for program comprehension."
Biology,Enhancing crop recommendation systems with explainable artificial intelligence: a study on agricultural decision-making,"Abstract Crop Recommendation Systems are invaluable tools for farmers, assisting them in making informed decisions about crop selection to optimize yields. These systems leverage a wealth of data, including soil characteristics, historical crop performance, and prevailing weather patterns, to provide personalized recommendations. In response to the growing demand for transparency and interpretability in agricultural decision-making, this study introduces XAI-CROP an innovative algorithm that harnesses eXplainable artificial intelligence (XAI) principles. The fundamental objective of XAI-CROP is to empower farmers with comprehensible insights into the recommendation process, surpassing the opaque nature of conventional machine learning models. The study rigorously compares XAI-CROP with prominent machine learning models, including Gradient Boosting (GB), Decision Tree (DT), Random Forest (RF), Gaussian Naïve Bayes (GNB), and Multimodal Naïve Bayes (MNB). Performance evaluation employs three essential metrics: Mean Squared Error (MSE), Mean Absolute Error (MAE), and R-squared (R2). The empirical results unequivocally establish the superior performance of XAI-CROP. It achieves an impressively low MSE of 0.9412, indicating highly accurate crop yield predictions. Moreover, with an MAE of 0.9874, XAI-CROP consistently maintains errors below the critical threshold of 1, reinforcing its reliability. The robust R 2 value of 0.94152 underscores XAI-CROP's ability to explain 94.15% of the data's variability, highlighting its interpretability and explanatory power.","['Gradient Boosting (GB)', 'Decision Tree (DT)', 'Random Forest (RF)', 'Gaussian Naïve Bayes (GNB)']","The study addresses the challenge faced by farmers in selecting the most suitable crops to optimize agricultural yields, emphasizing the need for transparent and understandable decision-making tools in crop recommendation. It highlights the importance of incorporating factors such as soil characteristics, historical crop performance, and weather patterns to provide personalized guidance for crop selection. The primary objective of the study is to develop a crop recommendation approach that offers farmers clear and comprehensible insights into the decision-making process, improving upon the lack of transparency found in traditional methods. This approach aims to enhance the accuracy and reliability of crop yield predictions while making the recommendation process more interpretable for end users."
Biology,"Making food systems more resilient to food safety risks by including artificial intelligence, big data, and internet of things into food safety early warning and emerging risk identification tools","Abstract To enhance the resilience of food systems to food safety risks, it is vitally important for national authorities and international organizations to be able to identify emerging food safety risks and to provide early warning signals in a timely manner. This review provides an overview of existing and experimental applications of artificial intelligence (AI), big data, and internet of things as part of early warning and emerging risk identification tools and methods in the food safety domain. There is an ongoing rapid development of systems fed by numerous, real‐time, and diverse data with the aim of early warning and identification of emerging food safety risks. The suitability of big data and AI to support such systems is illustrated by two cases in which climate change drives the emergence of risks, namely, harmful algal blooms affecting seafood and fungal growth and mycotoxin formation in crops. Automation and machine learning are crucial for the development of future real‐time food safety risk early warning systems. Although these developments increase the feasibility and effectiveness of prospective early warning and emerging risk identification tools, their implementation may prove challenging, particularly for low‐ and middle‐income countries due to low connectivity and data availability. It is advocated to overcome these challenges by improving the capability and capacity of national authorities, as well as by enhancing their collaboration with the private sector and international organizations.",['machine learning'],"The research idea centers on the critical need to enhance the resilience of food systems against food safety risks by enabling national authorities and international organizations to identify emerging food safety threats and provide timely early warning signals. This need is underscored by the increasing challenges posed by climate change, which drives the emergence of risks such as harmful algal blooms affecting seafood and fungal growth with mycotoxin formation in crops. The study highlights the importance of developing effective early warning and emerging risk identification tools to address these evolving threats. The primary objective of the study is to review and provide an overview of current and experimental approaches used for early warning and identification of emerging food safety risks, with a focus on illustrating their application through cases related to climate change-driven risks. Additionally, the study aims to discuss the challenges faced by low- and middle-income countries in implementing these tools and advocates for improving the capacity of national authorities and fostering collaboration with the private sector and international organizations to overcome these obstacles."
Biology,Assessing water quality of an ecologically critical urban canal incorporating machine learning approaches,"This study assessed water quality (WQ) in Tongi Canal, an ecologically critical and economically important urban canal in Bangladesh. The researchers employed the Root Mean Square Water Quality Index (RMS-WQI) model, utilizing seven WQ indicators, including temperature, dissolve oxygen, electrical conductivity, lead, cadmium, and iron to calculate the water quality index (WQI) score. The results showed that most of the water sampling locations showed poor WQ, with many indicators violating Bangladesh's environmental conservation regulations. This study employed eight machine learning algorithms, where the Gaussian process regression (GPR) model demonstrated superior performance (training RMSE = 1.77, testing RMSE = 0.0006) in predicting WQI scores. To validate the GPR model's performance, several performance measures, including the coefficient of determination (R2), the Nash-Sutcliffe efficiency (NSE), the model efficiency factor (MEF), Z statistics, and Taylor diagram analysis, were employed. The GPR model exhibited higher sensitivity (R2 = 1.0) and efficiency (NSE = 1.0, MEF = 0.0) in predicting WQ. The analysis of model uncertainty (standard uncertainty = 7.08 ± 0.9025; expanded uncertainty = 7.08 ± 1.846) indicates that the RMS-WQI model holds potential for assessing the WQ of inland waterbodies. These findings indicate that the RMS-WQI model could be an effective approach for assessing inland waters across Bangladesh. The study's results showed that most of the WQ indicators did not meet the recommended guidelines, indicating that the water in the Tongi Canal is unsafe and unsuitable for various purposes. The study's implications extend beyond the Tongi Canal and could contribute to WQ management initiatives across Bangladesh.",['Gaussian process regression (GPR)'],"The study addresses the critical issue of water quality deterioration in Tongi Canal, an ecologically important and economically significant urban waterbody in Bangladesh. The motivation stems from concerns that many water quality indicators in the canal violate environmental conservation regulations, rendering the water unsafe and unsuitable for various uses. The primary aim of the study is to assess the water quality of Tongi Canal by calculating a comprehensive water quality index based on multiple indicators such as temperature, dissolved oxygen, electrical conductivity, and heavy metals like lead, cadmium, and iron. The study seeks to evaluate the current status of the canal’s water quality and provide insights that could support water quality management efforts across Bangladesh."
Biology,Comparing YOLOv8 and Mask R-CNN for instance segmentation in complex orchard environments,"Instance segmentation, an important image processing operation for automation in agriculture, is used to precisely delineate individual objects of interest within images, which provides foundational information for various automated or robotic tasks such as selective harvesting and precision pruning. This study compares the one-stage YOLOv8 and the two-stage Mask R-CNN machine learning models for instance segmentation under varying orchard conditions across two datasets. Dataset 1, collected in dormant season, includes images of dormant apple trees, which were used to train multi-object segmentation models delineating tree branches and trunks. Dataset 2, collected in the early growing season, includes images of apple tree canopies with green foliage and immature (green) apples (also called fruitlet), which were used to train single-object segmentation models delineating only immature green apples. The results showed that YOLOv8 performed better than Mask R-CNN, achieving good precision and near-perfect recall across both datasets at a confidence threshold of 0.5. Specifically, for Dataset 1, YOLOv8 achieved a precision of 0.90 and a recall of 0.95 for all classes. In comparison, Mask R-CNN demonstrated a precision of 0.81 and a recall of 0.81 for the same dataset. With Dataset 2, YOLOv8 achieved a precision of 0.93 and a recall of 0.97. Mask R-CNN, in this single-class scenario, achieved a precision of 0.85 and a recall of 0.88. Additionally, the inference times for YOLOv8 were 10.9 ms for multi-class segmentation (Dataset 1) and 7.8 ms for single-class segmentation (Dataset 2), compared to 15.6 ms and 12.8 ms achieved by Mask R-CNN's, respectively. These findings show YOLOv8's superior accuracy and efficiency in machine learning applications compared to two-stage models, specifically Mask-R-CNN, which suggests its suitability in developing smart and automated orchard operations, particularly when real-time applications are necessary in such cases as robotic harvesting and robotic immature green fruit thinning.","['YOLOv8', 'Mask R-CNN']","The research addresses the challenge of accurately identifying and delineating individual components of apple trees, such as branches, trunks, and immature green apples, under varying orchard conditions to support automation in agricultural practices like selective harvesting and precision pruning. Precise segmentation of these tree parts is essential for enabling effective and efficient orchard management through automated or robotic interventions. The primary objective of the study is to evaluate and compare the performance of different instance segmentation approaches in accurately detecting and segmenting multiple tree structures during the dormant season and immature green apples during the early growing season. This comparison aims to determine the most suitable method for enhancing smart and automated orchard operations, particularly for real-time applications such as robotic harvesting and fruit thinning."
Biology,Cognition-Driven Structural Prior for Instance-Dependent Label Transition Matrix Estimation,"The label transition matrix has emerged as a widely accepted method for mitigating label noise in machine learning. In recent years, numerous studies have centered on leveraging deep neural networks to estimate the label transition matrix for individual instances within the context of instance-dependent noise. However, these methods suffer from low search efficiency due to the large space of feasible solutions. Behind this drawback, we have explored that the real murderer lies in the invalid class transitions, that is, the actual transition probability between certain classes is zero but is estimated to have a certain value. To mask the <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">invalid class transitions</i> , we introduced a human-cognition-assisted method with structural information from human cognition. Specifically, we introduce a structured transition matrix network ( <bold xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">STMN</b> ) designed with an adversarial learning process to balance instance features and prior information from human cognition. The proposed method offers two advantages: 1) better estimation effectiveness is obtained by sparing the transition matrix and 2) better estimation accuracy is obtained with the assistance of human cognition. By exploiting these two advantages, our method parametrically estimates a sparse label transition matrix, effectively converting noisy labels into true labels. The efficiency and superiority of our proposed method are substantiated through comprehensive comparisons with state-of-the-art methods on three synthetic datasets and a real-world dataset. Our code will be available at https://github.com/WheatCao/STMN-Pytorch.","['deep neural networks', 'adversarial learning process']","The research addresses the challenge of accurately estimating label transitions in the presence of noise, particularly focusing on the problem of invalid class transitions where the actual transition probability between certain classes is zero but is incorrectly estimated as nonzero. This issue leads to inefficiencies and inaccuracies in correcting noisy labels, which is a significant obstacle in improving the reliability of labeled biological data. The primary aim of the study is to improve the estimation of the label transition matrix by incorporating structural information derived from human cognition to mask invalid class transitions. By doing so, the study seeks to achieve more effective and accurate conversion of noisy labels into true labels, thereby enhancing the quality of biological data annotation."
Biology,Data-driven evolution of water quality models: An in-depth investigation of innovative outlier detection approaches-A case study of Irish Water Quality Index (IEWQI) model,"Recently, there has been a significant advancement in the water quality index (WQI) models utilizing data-driven approaches, especially those integrating machine learning and artificial intelligence (ML/AI) technology. Although, several recent studies have revealed that the data-driven model has produced inconsistent results due to the data outliers, which significantly impact model reliability and accuracy. The present study was carried out to assess the impact of data outliers on a recently developed Irish Water Quality Index (IEWQI) model, which relies on data-driven techniques. To the author's best knowledge, there has been no systematic framework for evaluating the influence of data outliers on such models. For the purposes of assessing the outlier impact of the data outliers on the water quality (WQ) model, this was the first initiative in research to introduce a comprehensive approach that combines machine learning with advanced statistical techniques. The proposed framework was implemented in Cork Harbour, Ireland, to evaluate the IEWQI model's sensitivity to outliers in input indicators to assess the water quality. In order to detect the data outlier, the study utilized two widely used ML techniques, including Isolation Forest (IF) and Kernel Density Estimation (KDE) within the dataset, for predicting WQ with and without these outliers. For validating the ML results, the study used five commonly used statistical measures. The performance metric (R2) indicates that the model performance improved slightly (R2 increased from 0.92 to 0.95) in predicting WQ after removing the data outlier from the input. But the IEWQI scores revealed that there were no statistically significant differences among the actual values, predictions with outliers, and predictions without outliers, with a 95% confidence interval at p < 0.05. The results of model uncertainty also revealed that the model contributed <1% uncertainty to the final assessment results for using both datasets (with and without outliers). In addition, all statistical measures indicated that the ML techniques provided reliable results that can be utilized for detecting outliers and their impacts on the IEWQI model. The findings of the research reveal that although the data outliers had no significant impact on the IEWQI model architecture, they had moderate impacts on the rating schemes' of the model. This finding indicated that detecting the data outliers could improve the accuracy of the IEWQI model in rating WQ as well as be helpful in mitigating the model eclipsing problem. In addition, the results of the research provide evidence of how the data outliers influenced the data-driven model in predicting WQ and reliability, particularly since the study confirmed that the IEWQI model's could be effective for accurately rating WQ despite the presence of the data outliers in the input. It could occur due to the spatio-temporal variability inherent in WQ indicators. However, the research assesses the influence of data input outliers on the IEWQI model and underscores important areas for future investigation. These areas include expanding temporal analysis using multi-year data, examining spatial outlier patterns, and evaluating detection methods. Moreover, it is essential to explore the real-world impacts of revised rating categories, involve stakeholders in outlier management, and fine-tune model parameters. Analysing model performance across varying temporal and spatial resolutions and incorporating additional environmental data can significantly enhance the accuracy of WQ assessment. Consequently, this study offers valuable insights to strengthen the IEWQI model's robustness and provides avenues for enhancing its utility in broader WQ assessment applications. Moreover, the study successfully adopted the framework for evaluating how data input outliers affect the data-driven model, such as the IEWQI model. The current study has been carried out in Cork Harbour for only a single year of WQ data. The framework should be tested across various domains for evaluating the response of the IEWQI model's in terms of the spatio-temporal resolution of the domain. Nevertheless, the study recommended that future research should be conducted to adjust or revise the IEWQI model's rating schemes and investigate the practical effects of data outliers on updated rating categories. However, the study provides potential recommendations for enhancing the IEWQI model's adaptability and reveals its effectiveness in expanding its applicability in more general WQ assessment scenarios.",['Isolation Forest (IF)'],"The research idea centers on addressing the challenges posed by data outliers in assessing water quality using the Irish Water Quality Index (IEWQI) model. Although recent advancements have improved water quality assessment, inconsistent results caused by outliers affect the reliability and accuracy of these evaluations. This study highlights the need for a systematic approach to understand how outliers influence water quality models and their rating schemes. The motivation is to improve the robustness and accuracy of water quality assessments despite the inherent variability in water quality indicators.

The primary objective of the study is to assess the impact of data outliers on the IEWQI model’s performance and rating schemes in evaluating water quality. The research aims to evaluate the sensitivity of the IEWQI model to outliers in input indicators by applying a comprehensive framework in Cork Harbour, Ireland. Additionally, the study seeks to provide insights into how outliers affect the model’s reliability and to offer recommendations for refining the model’s rating categories to enhance its applicability in broader water quality assessment scenarios."
Biology,DeepAVP-TPPred: identification of antiviral peptides using transformed image-based localized descriptors and binary tree growth algorithm,"Abstract Motivation Despite the extensive manufacturing of antiviral drugs and vaccination, viral infections continue to be a major human ailment. Antiviral peptides (AVPs) have emerged as potential candidates in the pursuit of novel antiviral drugs. These peptides show vigorous antiviral activity against a diverse range of viruses by targeting different phases of the viral life cycle. Therefore, the accurate prediction of AVPs is an essential yet challenging task. Lately, many machine learning-based approaches have developed for this purpose; however, their limited capabilities in terms of feature engineering, accuracy, and generalization make these methods restricted. Results In the present study, we aim to develop an efficient machine learning-based approach for the identification of AVPs, referred to as DeepAVP-TPPred, to address the aforementioned problems. First, we extract two new transformed feature sets using our designed image-based feature extraction algorithms and integrate them with an evolutionary information-based feature. Next, these feature sets were optimized using a novel feature selection approach called binary tree growth Algorithm. Finally, the optimal feature space from the training dataset was fed to the deep neural network to build the final classification model. The proposed model DeepAVP-TPPred was tested using stringent 5-fold cross-validation and two independent dataset testing methods, which achieved the maximum performance and showed enhanced efficiency over existing predictors in terms of both accuracy and generalization capabilities. Availability and implementation https://github.com/MateeullahKhan/DeepAVP-TPPred.",['deep neural network'],The study addresses the ongoing challenge of viral infections as a major human health issue despite the widespread use of antiviral drugs and vaccines. Antiviral peptides (AVPs) have emerged as promising candidates for developing new antiviral therapies due to their strong activity against a variety of viruses by targeting different stages of the viral life cycle. The accurate identification of AVPs is crucial but remains a difficult task. The primary aim of this study is to improve the identification of antiviral peptides to facilitate the discovery of novel antiviral agents.
Biology,Real-Time Plant Disease Dataset Development and Detection of Plant Disease Using Deep Learning,"Agriculture plays a significant role in meeting food needs and providing food security for the increasingly growing global population, which has increased by 0.88% since 2022. Plant diseases can reduce food production and affect food security. Worldwide crop loss due to plant disease is estimated to be around 14.1%. The lack of proper identification of plant disease at the early stages of infection can result in inappropriate disease control measures. Therefore, the automatic identification and diagnosis of plant diseases are highly recommended. Lack of availability of large amounts of data that are not processed to a large extent is one of the main challenges in plant disease diagnosis. In the current manuscript, we developed datasets for food grains specifically for rice, wheat, and maize to address the identified challenges. The developed datasets consider the common diseases (two bacterial diseases and two fungal diseases of rice, four fungal diseases of maize, and four fungal diseases of wheat) that affect crop yields and cause damage to the whole plant. The datasets developed were applied to eight fine-tuned deep learning models with the same training hyperparameters. The experimental results based on eight fine-tuned deep learning models show that, while recognizing maize leaf diseases, the models Xception and MobileNet performed best with a testing accuracy of 0.9580 and 0.9464 respectively. Similarly, while recognizing the wheat leaf diseases, the models MobileNetV2 and MobileNet performed best with a testing accuracy of 0.9632 and 0.9628 respectively. The Xception and Inception V3 models performed best, with a testing accuracy of 0.9728 and 0.9620, respectively, for recognizing rice leaf diseases. The research also proposes a new convolutional neural network (CNN) model trained from scratch on all three food grain datasets developed. The proposed model performs well and shows a testing accuracy of 0.9704, 0.9706, and 0.9808 respectively on the maize, rice, and wheat datasets.","['fine-tuned deep learning models', 'Xception', 'MobileNet', 'MobileNetV2', 'Inception V3', 'convolutional neural network (CNN) model trained from scratch']","The study addresses the critical issue of plant diseases reducing food production and threatening food security for the growing global population. Early and accurate identification of plant diseases is essential to implement appropriate disease control measures and minimize crop loss, which is estimated to be around 14.1% worldwide. The lack of properly processed and extensive data on plant diseases poses a significant challenge in effective disease diagnosis. The primary aim of the study is to develop comprehensive datasets for major food grains—rice, wheat, and maize—focusing on common bacterial and fungal diseases that affect crop yields and cause extensive damage. These datasets are intended to improve the identification and diagnosis of plant diseases, thereby supporting better management and control strategies to protect crop health and enhance food security."
Biology,Vision–language foundation model for echocardiogram interpretation,"Abstract The development of robust artificial intelligence models for echocardiography has been limited by the availability of annotated clinical data. Here, to address this challenge and improve the performance of cardiac imaging models, we developed EchoCLIP, a vision–language foundation model for echocardiography, that learns the relationship between cardiac ultrasound images and the interpretations of expert cardiologists across a wide range of patients and indications for imaging. After training on 1,032,975 cardiac ultrasound videos and corresponding expert text, EchoCLIP performs well on a diverse range of benchmarks for cardiac image interpretation, despite not having been explicitly trained for individual interpretation tasks. EchoCLIP can assess cardiac function (mean absolute error of 7.1% when predicting left ventricular ejection fraction in an external validation dataset) and identify implanted intracardiac devices (area under the curve (AUC) of 0.84, 0.92 and 0.97 for pacemakers, percutaneous mitral valve repair and artificial aortic valves, respectively). We also developed a long-context variant (EchoCLIP-R) using a custom tokenizer based on common echocardiography concepts. EchoCLIP-R accurately identified unique patients across multiple videos (AUC of 0.86), identified clinical transitions such as heart transplants (AUC of 0.79) and cardiac surgery (AUC 0.77) and enabled robust image-to-text search (mean cross-modal retrieval rank in the top 1% of candidate text reports). These capabilities represent a substantial step toward understanding and applying foundation models in cardiovascular imaging for preliminary interpretation of echocardiographic findings.",['vision–language foundation model'],"The research addresses the challenge of limited availability of annotated clinical data for echocardiography, which has hindered the development of robust methods for cardiac imaging interpretation. The study is motivated by the need to improve the understanding and assessment of cardiac ultrasound images across a wide range of patients and clinical indications. The primary objective of the study is to develop a comprehensive approach that learns the relationship between cardiac ultrasound images and expert cardiologists’ interpretations, enabling accurate assessment of cardiac function and identification of implanted intracardiac devices. Additionally, the study aims to enhance the ability to recognize unique patients, detect clinical transitions such as heart transplants and cardiac surgery, and facilitate effective retrieval of echocardiographic findings."
Biology,Groundwater level prediction using an improved SVR model integrated with hybrid particle swarm optimization and firefly algorithm,"The demand for water resources has increased due to rapid increase of metropolitan areas brought on by growth in population and industrialisation. In addition, the groundwater recharge is being afftected by shifting land use pattern caused by urban development. Using precise and trustworthy estimates of groundwater level is vital for the sustainable groundwater resources management in the face of changing climatic circumstances. In this context, machine learning (ML) methods offer a new and promising approach for accurately forecasting long-term changes in the groundwater level (GWL) without computational effort of developing a comprehensive flow model. In order to simulate GWL, five data-driven (DD) models, including the hybridization of support vector regression (SVR) with two optimisation algorithms i.e., firefly algorithm and particle swarm optimisation (FFAPSO), SVR-FFA, SVR-PSO, SVR and Multilayer perception (MLP), have been examined in the present study. Spatial clustering was utilised to choose four observation wells within Cuttack district in order to study and assess the water levels. Six scenarios were created by incorporating numerous variables, such as GWL in the previous months, evapotranspiration, temperature, precipitation, and river discharge. The goal was to identify the variables that were most efficient in predicting GWL. The SVR-FFAPSO model performs best in GWL forecasting for Khuntuni station, according to the quantitative analysis with correlation coefficient (R) = 0.9978, Nash–Sutcliffe efficiency (NSE) = 0.9933, mean absolute error (MAE) = 0.00025 (m), root mean squared error (RMSE) = 0.00775 (m) during the training phase. It is advised that groundwater monitoring network and data collecting system are strengthen in India for ensuring effective modelling of long-term management of groundwater resources.","['support vector regression (SVR)', 'firefly algorithm', 'SVR-PSO']","The study addresses the increasing demand for water resources driven by rapid urbanization, population growth, and industrialization, which have also altered groundwater recharge due to changing land use patterns. Accurate estimation of groundwater levels is crucial for sustainable management of groundwater resources, especially under changing climatic conditions. The primary aim of the study is to simulate and forecast long-term changes in groundwater levels by identifying the most effective variables influencing groundwater fluctuations. This is intended to support improved groundwater resource management and monitoring in the Cuttack district of India."
Biology,Assessing ChatGPT’s Mastery of Bloom’s Taxonomy Using Psychosomatic Medicine Exam Questions: Mixed-Methods Study,"Background Large language models such as GPT-4 (Generative Pre-trained Transformer 4) are being increasingly used in medicine and medical education. However, these models are prone to “hallucinations” (ie, outputs that seem convincing while being factually incorrect). It is currently unknown how these errors by large language models relate to the different cognitive levels defined in Bloom’s taxonomy. Objective This study aims to explore how GPT-4 performs in terms of Bloom’s taxonomy using psychosomatic medicine exam questions. Methods We used a large data set of psychosomatic medicine multiple-choice questions (N=307) with real-world results derived from medical school exams. GPT-4 answered the multiple-choice questions using 2 distinct prompt versions: detailed and short. The answers were analyzed using a quantitative approach and a qualitative approach. Focusing on incorrectly answered questions, we categorized reasoning errors according to the hierarchical framework of Bloom’s taxonomy. Results GPT-4’s performance in answering exam questions yielded a high success rate: 93% (284/307) for the detailed prompt and 91% (278/307) for the short prompt. Questions answered correctly by GPT-4 had a statistically significant higher difficulty than questions answered incorrectly (P=.002 for the detailed prompt and P&lt;.001 for the short prompt). Independent of the prompt, GPT-4’s lowest exam performance was 78.9% (15/19), thereby always surpassing the “pass” threshold. Our qualitative analysis of incorrect answers, based on Bloom’s taxonomy, showed that errors were primarily in the “remember” (29/68) and “understand” (23/68) cognitive levels; specific issues arose in recalling details, understanding conceptual relationships, and adhering to standardized guidelines. Conclusions GPT-4 demonstrated a remarkable success rate when confronted with psychosomatic medicine multiple-choice exam questions, aligning with previous findings. When evaluated through Bloom’s taxonomy, our data revealed that GPT-4 occasionally ignored specific facts (remember), provided illogical reasoning (understand), or failed to apply concepts to a new situation (apply). These errors, which were confidently presented, could be attributed to inherent model biases and the tendency to generate outputs that maximize likelihood.",['GPT-4 (Generative Pre-trained Transformer 4)'],"The research idea addresses the challenge of understanding how errors made by large language models relate to different cognitive levels defined in Bloom’s taxonomy, particularly in the context of medical education and psychosomatic medicine exam questions. There is a need to investigate the nature of these errors, especially since such models can produce outputs that appear convincing but may be factually incorrect. The study aims to explore the performance of GPT-4 on psychosomatic medicine multiple-choice questions by examining its responses through the lens of Bloom’s taxonomy. The primary objective of the study is to evaluate GPT-4’s performance across various cognitive levels of Bloom’s taxonomy using a large set of psychosomatic medicine exam questions, with a focus on categorizing and understanding the reasoning errors in incorrectly answered questions according to this hierarchical framework."
Biology,Machine learning-assisted in-situ adaptive strategies for the control of defects and anomalies in metal additive manufacturing,"In metal additive manufacturing (AM), the material microstructure and part geometry are formed incrementally. Consequently, the resulting part could be defect- and anomaly-free if sufficient care is taken to deposit each layer under optimal process conditions. Conventional closed-loop control (CLC) engineering solutions which sought to achieve this were deterministic and rule-based, thus resulting in limited success in the stochastic environment experienced in the highly dynamic AM process. On the other hand, emerging machine learning (ML) based strategies are better suited to providing the robustness, scope, flexibility, and scalability required for process control in an uncertain environment. Offline ML models that help optimise AM process parameters before a build begins and online ML models that efficiently processed in-situ sensory data to detect and diagnose flaws in real-time (or near-real-time) have been developed. However, ML models that enable a process to take evasive or corrective actions in relation to flaws via on the fly decision-making are only emerging. These models must possess prognostic capabilities to provide context-sensitive recommendations for in-situ process control based on real-time diagnostics. In this article, we pinpoint the shortcomings in traditional CLC strategies, and provide a framework for defect and anomaly control through ML-assisted CLC in AM. We discuss flaws in terms of their causes, in-situ detectability, and controllability, and examine their management under three scenarios: avoidance, mitigation, and repair. Then, we summarise the research into ML models developed for offline optimisation and in-situ diagnosis before initiating a detailed conversation on the implementation of ML-assisted in-situ process control. We found that researchers favoured reinforcement learning approaches or inverse ML models for making rapid, situation-aware control decisions. We also observed that, to-date, the defects addressed were those that may be quantified relatively easily autonomously, and that mitigation (rather than avoidance or repair) was the aim of ML-assisted in-situ control strategies. Additionally, we highlight the various technologies that must seamlessly combine to advance the field of autonomous in-situ control so that it becomes a reality in industrial settings. Finally, we raise awareness of seldom discussed, yet highly pertinent, topics relevant to adaptive control. Our work closes a significant gap in the current AM literature by broaching wide-ranging discussions on matters relevant to in-situ adaptive control in AM.","['online ML models', 'reinforcement learning approaches']","The research idea centers on the challenge of producing defect- and anomaly-free parts in metal additive manufacturing, where material microstructure and part geometry are formed incrementally under highly dynamic and stochastic conditions. Traditional control methods have shown limited success in managing these complexities, highlighting the need for more robust and flexible approaches to ensure optimal process conditions during layer deposition. The study addresses the shortcomings of existing strategies in controlling defects and anomalies in real-time during the manufacturing process.

The primary objective of the study is to provide a comprehensive framework for defect and anomaly control in metal additive manufacturing through advanced in-situ process control strategies. It aims to examine flaws in terms of their causes, detectability, and controllability, and to explore their management via avoidance, mitigation, and repair. The study also seeks to advance the understanding and implementation of adaptive control mechanisms that enable real-time decision-making to improve part quality and process reliability in industrial settings."
Biology,Performance assessment of machine learning algorithms for mapping of land use/land cover using remote sensing data,"The rapid increase in population accelerates the rate of change of Land use/Land cover (LULC) in various parts of the world. This phenomenon caused a huge strain for natural resources. Hence, continues monitoring of LULC changes gained a significant importance for management of natural resources and assessing the climate change impacts. Recently, application of machine learning algorithms on RS (remote sensing) data for rapid and accurate mapping of LULC gained significant importance due to growing need of LULC estimation for ecosystem services, natural resource management and environmental management. Hence, it is crucial to access and compare the performance of different machine learning classifiers for accurate mapping of LULC. The primary objective of this study was to compare the performance of CART (Classification and Regression Tree), RF (Random Forest) and SVM (Support Vector Machine) for LULC estimation by processing RS data on Google Earth Engine (GEE). In total four classes of LULC (Water Bodies, Vegetation Cover, Urban Land and Barren Land) for city of Lahore were extracted using satellite images from Landsat-7, Landsat-8 and Landsat-9 for years 2008, 2015 and 2022, respectively. According to results, RF is the best performing classifier with maximum overall accuracy of 95.2% and highest Kappa coefficient value of 0.87, SVM achieved maximum accuracy of 89.8% with highest Kappa of 0.84 and CART showed maximum overall accuracy of 89.7% with Kappa value of 0.79. Results from this study can give assistance for decision makers, planners and RS experts to choose a suitable machine learning algorithm for LULC classification in an unplanned urbanized city like Lahore.","['Classification and Regression Tree (CART)', 'Random Forest (RF)', 'Support Vector Machine (SVM)']","The rapid increase in population has accelerated changes in land use and land cover (LULC) across various regions, placing significant strain on natural resources. Continuous monitoring of LULC changes is therefore essential for effective management of natural resources and for assessing the impacts of climate change. The primary objective of this study was to compare the performance of different approaches for estimating LULC by analyzing satellite imagery to classify four major land cover types—Water Bodies, Vegetation Cover, Urban Land, and Barren Land—in the city of Lahore over multiple years. This comparison aims to identify the most accurate method for mapping LULC changes to support decision-making in urban planning and environmental management."
Biology,Joint Optimization Risk Factor and Energy Consumption in IoT Networks With TinyML-Enabled Internet of UAVs,"The high mobility of Internet of Unmanned Aerial Vehicles (IUAVs) has attracted attention in the field of data collection. With the rapid development of the Internet of Things (IoT), more and more data are generated by IoT networks. IUAV-aided IoT networks can efficiently collect data in specific areas, which is of great significance in disaster relief. In the data collection task, it is necessary to plan the flight trajectory for the data collector—IUAV, so that the IUAV can collect data efficiently. However, existing research basically only considers the efficiency of data collection by IUAVs, but rarely considers the safety of IUAVs during flight. Therefore, this paper proposes an IUAV trajectory planning algorithm that integrates energy efficiency and safety using local search to address the issues mentioned above. At the same time, a Tiny Machine Learning (TinyML) algorithm is designed to assist the IUAV in making real-time decisions during flight. First, we build a general mathematical model that describes the risk in a particular region. Then consider guiding the IUAV to a safer trajectory by introducing virtual nodes in the flight trajectory. Furthermore, we designed a local search algorithm for the three tasks of IUAV access sequence, IoT Networks cluster heads selection and virtual nodes selection, and solved them through iterative optimization. We also consider the unreachable situation of the virtual nodes and use TinyML technology to help the IUAV adjust the position of the virtual nodes in real time in case of an emergency.In the end, an IUAV trajectory is obtained that can efficiently collect IoT networks' data and fly safely. We have conducted a large number of simulation experiments to demonstrate the efficiency of the proposed algorithm compared to the baseline algorithm.",['Tiny Machine Learning (TinyML)'],"The study addresses the challenge of efficiently collecting data in specific areas using unmanned aerial vehicles (UAVs) within Internet of Things (IoT) networks, which is particularly important for applications such as disaster relief. While previous research has focused primarily on the efficiency of data collection, the safety of UAVs during flight has been largely overlooked. The primary aim of this study is to develop a method for planning UAV flight trajectories that balances both energy efficiency and flight safety. This involves creating a model to assess risk in certain regions and guiding UAVs along safer paths to ensure effective and secure data collection from IoT networks."
Biology,Groundwater Quality Assessment and Irrigation Water Quality Index Prediction Using Machine Learning Algorithms,"The evaluation of groundwater quality is crucial for irrigation purposes; however, due to financial constraints in developing countries, such evaluations suffer from insufficient sampling frequency, hindering comprehensive assessments. Therefore, associated with machine learning approaches and the irrigation water quality index (IWQI), this research aims to evaluate the groundwater quality in Naama, a region in southwest Algeria. Hydrochemical parameters (cations, anions, pH, and EC), qualitative indices (SAR,RSC,Na%,MH,and PI), as well as geospatial representations were used to determine the groundwater’s suitability for irrigation in the study area. In addition, efficient machine learning approaches for forecasting IWQI utilizing Extreme Gradient Boosting (XGBoost), Support vector regression (SVR), and K-Nearest Neighbours (KNN) models were implemented. In this research, 166 groundwater samples were used to calculate the irrigation index. The results showed that 42.18% of them were of excellent quality, 34.34% were of very good quality, 6.63% were good quality, 9.64% were satisfactory, and 4.21% were considered unsuitable for irrigation. On the other hand, results indicate that XGBoost excels in accuracy and stability, with a low RMSE (of 2.8272 and a high R of 0.9834. SVR with only four inputs (Ca2+, Mg2+, Na+, and K) demonstrates a notable predictive capability with a low RMSE of 2.6925 and a high R of 0.98738, while KNN showcases robust performance. The distinctions between these models have important implications for making informed decisions in agricultural water management and resource allocation within the region.","['Extreme Gradient Boosting (XGBoost)', 'Support Vector Regression (SVR)', 'K-Nearest Neighbours (KNN)']","The evaluation of groundwater quality is crucial for irrigation purposes, especially in developing countries where financial constraints limit the frequency of sampling and hinder comprehensive assessments. This study addresses the need for a thorough assessment of groundwater suitability for irrigation in the Naama region of southwest Algeria by examining various hydrochemical parameters and qualitative indices. The primary aim of the research is to evaluate the groundwater quality in the study area using hydrochemical data and irrigation water quality indices to determine its suitability for agricultural use. The study seeks to classify the groundwater samples based on their quality for irrigation and provide insights that can inform water management and resource allocation decisions in the region."
Biology,CCL-DTI: contributing the contrastive loss in drug–target interaction prediction,"Abstract Background The Drug–Target Interaction (DTI) prediction uses a drug molecule and a protein sequence as inputs to predict the binding affinity value. In recent years, deep learning-based models have gotten more attention. These methods have two modules: the feature extraction module and the task prediction module. In most deep learning-based approaches, a simple task prediction loss (i.e., categorical cross entropy for the classification task and mean squared error for the regression task) is used to learn the model. In machine learning, contrastive-based loss functions are developed to learn more discriminative feature space. In a deep learning-based model, extracting more discriminative feature space leads to performance improvement for the task prediction module. Results In this paper, we have used multimodal knowledge as input and proposed an attention-based fusion technique to combine this knowledge. Also, we investigate how utilizing contrastive loss function along the task prediction loss could help the approach to learn a more powerful model. Four contrastive loss functions are considered: (1) max-margin contrastive loss function, (2) triplet loss function, (3) Multi-class N-pair Loss Objective, and (4) NT-Xent loss function. The proposed model is evaluated using four well-known datasets: Wang et al. dataset, Luo's dataset, Davis, and KIBA datasets. Conclusions Accordingly, after reviewing the state-of-the-art methods, we developed a multimodal feature extraction network by combining protein sequences and drug molecules, along with protein–protein interaction networks and drug–drug interaction networks. The results show it performs significantly better than the comparable state-of-the-art approaches.","['contrastive loss function', 'max-margin contrastive loss function', 'triplet loss function', 'Multi-class N-pair Loss Objective', 'NT-Xent loss function']","The research idea centers on improving the prediction of drug–target interactions, which involves determining the binding affinity between drug molecules and protein sequences. Accurate prediction of these interactions is crucial for understanding drug efficacy and facilitating drug discovery. The study addresses the challenge of enhancing the discriminative power of features used to represent drugs and proteins to improve prediction performance. The primary objective of the study is to develop a method that effectively integrates multiple types of biological information, including protein sequences, drug molecules, protein–protein interaction networks, and drug–drug interaction networks, to improve the accuracy of drug–target interaction predictions. The study aims to demonstrate that combining these diverse biological data sources leads to significantly better predictive performance compared to existing approaches."
Biology,Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning,"Recent development in computing power has resulted in performance improvements on holistic(none-occluded) person Re-Identification (ReID) tasks. Nevertheless, the precision of the recent research will diminish when a pedestrian is obstructed by obstacles. Within the realm of 2D space, the loss of information from obstructed objects continues to pose significant challenges in the context of person ReID. Person is a 3D non-grid object, and thus semantic representation learning in only 2D space limits the understanding of occluded person. In the present work, we propose a network based on 3D multi-view learning, allowing it to acquire geometric and shape details of an occluded pedestrian from 3D space. Simultaneously, it capitalizes on advancements in 2D-based networks to extract semantic representations from 3D multi-views. Specifically, the surface random selection strategy is proposed to convert images of 2D RGB into 3D multi-views. Using this strategy, we build four extensive 3D multi-view data collections for person ReID. After that, Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning(MV-3DSReID), is proposed for identifying the person by learning person geometry and structure representation from the groups of multi-view images. In comparison to alternative data formats (e.g., 2D RGB, 3D point cloud), multi-view images complement each other's detailed features of the 3D object by adjusting rendering viewpoints, thus facilitating a more comprehensive understanding of the person for both holistic and occluded ReID situations. Experiments on occluded and holistic ReID tasks demonstrate performance levels comparable to state-of-the-art methods, validating the effectiveness of our proposed approach in tackling challenges related to occlusion. The code is available at https://github.com/hangjiaqi1/MV-TransReID.",['3D multi-view learning'],"The research idea addresses the challenge of accurately identifying pedestrians when they are partially obstructed by obstacles, which leads to a loss of information in traditional 2D representations. Since a person is a three-dimensional object, relying solely on 2D semantic representations limits the understanding of occluded individuals. This study recognizes the need for a more comprehensive approach that captures geometric and shape details in 3D space to improve identification under occlusion conditions. The research objective is to develop a method that leverages multiple views of a pedestrian in 3D space to learn their geometry and structural features, thereby enhancing person identification accuracy for both occluded and unobstructed cases. The study aims to build extensive multi-view data collections and utilize these to better represent and understand the 3D shape of pedestrians, ultimately improving performance in person re-identification tasks despite occlusions."
Biology,Sequence Training and Data Shuffling to Enhance the Accuracy of Recurrent Neural Network Based Battery Voltage Models,"&lt;div class=""section abstract""&gt;&lt;div class=""htmlview paragraph""&gt;Battery terminal voltage modelling is crucial for various applications, including electric vehicles, renewable energy systems, and portable electronics. Terminal voltage models are used to determine how a battery will respond under load and can be used to calculate run-time, power capability, and heat generation and as a component of state estimation approaches, such as for state of charge. Previous studies have shown better voltage modelling accuracy for long short-term memory (LSTM) recurrent neural networks than other traditional methods (e.g., equivalent circuit and electrochemical models). This study presents two new approaches – sequence training and data shuffling – to improve LSTM battery voltage models further, making them an even better candidate for the high-accuracy modelling of lithium-ion batteries. Because the LSTM memory captures information from past time steps, it must typically be trained using one series of continuous data. Instead, the proposed sequence training approach feeds a fixed window of prior data (e.g., 100 seconds) into the LSTM at each time step to initialize the memory states properly and then only uses the output at the current time step. With this method, the LSTM just requires the prior data window to be continuous, thereby allowing the handling of discontinuities. This also means that during the training process, the data can be shuffled randomly, enabling mini-batches to speed up the training significantly. When these approaches were applied, LSTM voltage estimation error was reduced by 22%, from 28.5 mV to 22.3 mV RMS error over four drive cycles and temperatures from -20 to 25°C.&lt;/div&gt;&lt;/div&gt;","['long short-term memory (LSTM) recurrent neural networks', 'sequence training']","The research addresses the critical need for accurate battery terminal voltage modeling, which is essential for understanding battery performance under load in applications such as electric vehicles, renewable energy systems, and portable electronics. Accurate voltage models help determine run-time, power capability, and heat generation, and contribute to estimating the state of charge of lithium-ion batteries. The primary objective of the study is to improve the accuracy of lithium-ion battery terminal voltage models by introducing new approaches that enhance the modeling process, ultimately reducing voltage estimation errors across various operating conditions. This aims to make voltage modeling more reliable for practical applications involving lithium-ion batteries."
Biology,AlphaFold predictions of fold-switched conformations are driven by structure memorization,"Abstract Recent work suggests that AlphaFold (AF)–a deep learning-based model that can accurately infer protein structure from sequence–may discern important features of folded protein energy landscapes, defined by the diversity and frequency of different conformations in the folded state. Here, we test the limits of its predictive power on fold-switching proteins, which assume two structures with regions of distinct secondary and/or tertiary structure. We find that (1) AF is a weak predictor of fold switching and (2) some of its successes result from memorization of training-set structures rather than learned protein energetics. Combining &gt;280,000 models from several implementations of AF2 and AF3, a 35% success rate was achieved for fold switchers likely in AF’s training sets. AF2’s confidence metrics selected against models consistent with experimentally determined fold-switching structures and failed to discriminate between low and high energy conformations. Further, AF captured only one out of seven experimentally confirmed fold switchers outside of its training sets despite extensive sampling of an additional ~280,000 models. Several observations indicate that AF2 has memorized structural information during training, and AF3 misassigns coevolutionary restraints. These limitations constrain the scope of successful predictions, highlighting the need for physically based methods that readily predict multiple protein conformations.","['AlphaFold (AF)', 'AF2']","The research idea centers on understanding the ability to predict protein fold switching, a phenomenon where proteins adopt multiple distinct conformations with different secondary or tertiary structures, which is important for comprehending protein energy landscapes and functional diversity. The study addresses the challenge of accurately identifying fold-switching proteins and the limitations of current predictive approaches in capturing the full range of protein conformations. The primary objective of the study is to evaluate the effectiveness of existing predictive methods in identifying fold-switching proteins and to assess their ability to distinguish between different experimentally confirmed protein conformations. The study aims to highlight the constraints of these methods and emphasize the need for approaches that can reliably predict multiple protein structures based on physical principles."
Biology,A comprehensive analysis of the emerging modern trends in research on photovoltaic systems and desalination in the era of artificial intelligence and machine learning,"Integration of photovoltaic (PV) systems, desalination technologies, and Artificial Intelligence (AI) combined with Machine Learning (ML) has introduced a new era of remarkable research and innovation. This review article thoroughly examines the recent advancements in the field, focusing on the interplay between PV systems and water desalination within the framework of AI and ML applications, along with it analyses current research to identify significant patterns, obstacles, and prospects in this interdisciplinary field. Furthermore, review examines the incorporation of AI and ML methods in improving the performance of PV systems. This includes raising their efficiency, implementing predictive maintenance strategies, and enabling real-time monitoring. It also explores the transformative influence of intelligent algorithms on desalination techniques, specifically addressing concerns pertaining to energy usage, scalability, and environmental sustainability. This article provides a thorough analysis of the current literature, identifying areas where research is lacking and suggesting potential future avenues for investigation. These advancements have resulted in increased efficiency, decreased expenses, and improved sustainability of PV system. By utilizing artificial intelligence technologies, freshwater productivity can increase by 10 % and efficiency. This review offers significant and informative perspectives for researchers, engineers, and policymakers involved in renewable energy and water technology. It sheds light on the latest advancements in photovoltaic systems and desalination, which are facilitated by AI and ML. The review aims to guide towards a more sustainable and technologically advanced future.",['Machine Learning (ML)'],"The research idea centers on the integration of photovoltaic systems and water desalination technologies to address challenges related to energy usage, scalability, and environmental sustainability in freshwater production. The study highlights the importance of improving the efficiency and sustainability of these systems to meet growing demands for renewable energy and clean water. The primary objective of the study is to review recent advancements in the interplay between photovoltaic systems and desalination technologies, identifying significant patterns, obstacles, and prospects in this field. Additionally, the study aims to provide insights into enhancing the performance and sustainability of these technologies to support a more sustainable and technologically advanced future."
Biology,A Critical Review of Artificial Intelligence Based Approaches in Intrusion Detection: A Comprehensive Analysis,"Intrusion detection (ID) is critical in securing computer networks against various malicious attacks. Recent advancements in machine learning (ML), deep learning (DL), federated learning (FL), and explainable artificial intelligence (XAI) have drawn significant attention as potential approaches for ID. DL-based approaches have shown impressive performance in ID by automatically learning relevant features from data but require significant labelled data and computational resources to train complex models. ML-based approaches require fewer computational resources and labelled data, but their ability to generalize to unseen data is limited. FL is a relatively new approach that enables multiple entities to train a model collectively without exchanging their data, providing privacy and security benefits, making it an attractive option for ID. However, FL-based approaches require more communication resources and additional computation to aggregate models from different entities. XAI is critical for understanding how AI models make decisions, improving interpretability and transparency. While existing literature has explored the strengths and weaknesses of DL, ML, FL, and XAI-based approaches for ID, a significant gap exists in providing a comprehensive analysis of the specific use cases and scenarios where each approach is most suitable. This paper seeks to fill this void by delivering an in-depth review that not only highlights strengths and weaknesses but also offers guidance for selecting the appropriate approach based on the unique ID context and available resources. The selection of an appropriate approach depends on the specific use case, and this work provides insights into which method is best suited for various network sizes, data availability, privacy, and security concerns, thus aiding practitioners in making informed decisions for their ID needs.","['machine learning (ML)', 'deep learning (DL)', 'federated learning (FL)']","The study addresses the critical need for effective intrusion detection to secure computer networks against various malicious attacks. It highlights the challenges associated with existing approaches, such as the requirement for significant labeled data, computational resources, and the ability to generalize to unseen data, as well as concerns related to privacy, security, and communication resources. The research is motivated by the lack of comprehensive guidance on selecting the most suitable intrusion detection approach based on specific use cases and scenarios. The primary objective of the study is to provide an in-depth review that not only outlines the strengths and weaknesses of different intrusion detection methods but also offers practical guidance for choosing the appropriate approach according to network size, data availability, privacy, and security considerations."
Biology,Generative artificial intelligence in manufacturing: opportunities for actualizing Industry 5.0 sustainability goals,"Purpose This study offers practical insights into how generative artificial intelligence (AI) can enhance responsible manufacturing within the context of Industry 5.0. It explores how manufacturers can strategically maximize the potential benefits of generative AI through a synergistic approach. Design/methodology/approach The study developed a strategic roadmap by employing a mixed qualitative-quantitative research method involving case studies, interviews and interpretive structural modeling (ISM). This roadmap visualizes and elucidates the mechanisms through which generative AI can contribute to advancing the sustainability goals of Industry 5.0. Findings Generative AI has demonstrated the capability to promote various sustainability objectives within Industry 5.0 through ten distinct functions. These multifaceted functions address multiple facets of manufacturing, ranging from providing data-driven production insights to enhancing the resilience of manufacturing operations. Practical implications While each identified generative AI function independently contributes to responsible manufacturing under Industry 5.0, leveraging them individually is a viable strategy. However, they synergistically enhance each other when systematically employed in a specific order. Manufacturers are advised to strategically leverage these functions, drawing on their complementarities to maximize their benefits. Originality/value This study pioneers by providing early practical insights into how generative AI enhances the sustainability performance of manufacturers within the Industry 5.0 framework. The proposed strategic roadmap suggests prioritization orders, guiding manufacturers in decision-making processes regarding where and for what purpose to integrate generative AI.",['generative artificial intelligence (generative AI)'],"The study addresses the challenge of enhancing responsible manufacturing practices to achieve sustainability goals within the context of Industry 5.0. It focuses on how manufacturers can effectively improve sustainability performance by leveraging various functions that contribute to different aspects of manufacturing, including production insights and operational resilience. The primary aim of the study is to provide practical insights and a strategic framework that guides manufacturers in prioritizing and integrating these functions to maximize their contributions toward responsible and sustainable manufacturing under Industry 5.0. This includes offering recommendations on how to systematically employ these functions to enhance their combined impact on sustainability outcomes."
Biology,Fractional order PID controller for load frequency control in a deregulated hybrid power system using Aquila Optimization,"This paper presents an innovative approach for automatic generation control for power system under a deregulated setting. The main objective of this work is to optimally tune the parameters of the fractional-order controller using the newly developed Aquila Optimizer (AO) to enhance system performance. A test system comprising a thermal power plant, a hydroelectric system, a gas turbine-based power plant, and wind energy sources is examined under deregulated environment. The study emphasizes the minimization of frequency variations, tie line deviations, and area control errors during diverse operational shifts. The proposed control strategy explores the response of generators in a hybrid deregulated power system, emphasizing the critical role of properly tuned Fractional Order Proportional-Integral-Derivative (FOPID) controllers in ensuring system stability. The potential and effectiveness of the proposed algorithm are compared with particle swarm optimization (PSO) and whale optimization algorithm (WOA) based controller performance for the same test system. The objective function for optimization is set as the minimization of the integral time and absolute error (ITAE) performance index. Furthermore, the efficacy of the proposed technique is compared with the Unified Power Flow Controller (UPFC) and its superiority is validated. Performance evaluation of the hybrid power system is conducted under Poolco agreement, bilateral agreement, and varying operating conditions. Comparative assessments reveal the superiority of the AO-driven FOPID over other techniques, demonstrating improved system metrics, including frequencies across different areas, tie-line power variations, and generator outputs.","['Aquila Optimizer (AO)', 'whale optimization algorithm (WOA)']","The research idea addresses the challenge of maintaining stable and efficient operation of a hybrid power system composed of thermal, hydroelectric, gas turbine, and wind energy sources under a deregulated environment. It focuses on minimizing frequency variations, tie line deviations, and area control errors during different operational conditions to ensure system stability. The study highlights the importance of properly tuned controllers in managing the dynamic responses of generators within such complex power systems. The primary objective of the study is to optimally tune the parameters of a fractional-order controller to enhance the performance of the power system by reducing frequency fluctuations and control errors. The research aims to evaluate the effectiveness of this tuning approach in improving system stability and operational metrics across various agreements and operating scenarios in a deregulated power system setting."
Biology,Integrating artificial intelligence to assess emotions in learning environments: a systematic literature review,"Introduction Artificial Intelligence (AI) is transforming multiple sectors within our society, including education. In this context, emotions play a fundamental role in the teaching-learning process given that they influence academic performance, motivation, information retention, and student well-being. Thus, the integration of AI in emotional assessment within educational environments offers several advantages that can transform how we understand and address the socio-emotional development of students. However, there remains a lack of comprehensive approach that systematizes advancements, challenges, and opportunities in this field. Aim This systematic literature review aims to explore how artificial intelligence (AI) is used to evaluate emotions within educational settings. We provide a comprehensive overview of the current state of research, focusing on advancements, challenges, and opportunities in the domain of AI-driven emotional assessment within educational settings. Method The review involved a search across the following academic databases: Pubmed, Web of Science, PsycINFO and Scopus. Forty-one articles were selected that meet the established inclusion criteria. These articles were analyzed to extract key insights related to the integration of AI and emotional assessment within educational environments. Results The findings reveal a variety of AI-driven approaches that were developed to capture and analyze students’ emotional states during learning activities. The findings are summarized in four fundamental topics: (1) emotion recognition in education, (2) technology integration and learning outcomes, (3) special education and assistive technology, (4) affective computing. Among the key AI techniques employed are machine learning and facial recognition, which are used to assess emotions. These approaches demonstrate promising potential in enhancing pedagogical strategies and creating adaptive learning environments that cater to individual emotional needs. The review identified emerging factors that, while important, require further investigation to understand their relationships and implications fully. These elements could significantly enhance the use of AI in assessing emotions within educational settings. Specifically, we are referring to: (1) federated learning, (2) convolutional neural network (CNN), (3) recurrent neural network (RNN), (4) facial expression databases, and (5) ethics in the development of intelligent systems. Conclusion This systematic literature review showcases the significance of AI in revolutionizing educational practices through emotion assessment. While advancements are evident, challenges related to accuracy, privacy, and cross-cultural validity were also identified. The synthesis of existing research highlights the need for further research into refining AI models for emotion recognition and emphasizes the importance of ethical considerations in implementing AI technologies within educational contexts.","['machine learning', 'federated learning', 'convolutional neural network (CNN)', 'recurrent neural network (RNN)']","The research idea centers on the fundamental role emotions play in the teaching-learning process, influencing academic performance, motivation, information retention, and student well-being. There is a recognized need to better understand and address the socio-emotional development of students within educational environments. The study aims to explore how emotions are evaluated within educational settings, focusing on advancements, challenges, and opportunities related to emotional assessment. Specifically, the primary objective is to provide a comprehensive overview of the current state of research on emotional assessment in education, highlighting key factors that impact the effectiveness and ethical considerations of these approaches."
Biology,Monthly climate prediction using deep convolutional neural network and long short-term memory,"Climate change affects plant growth, food production, ecosystems, sustainable socio-economic development, and human health. The different artificial intelligence models are proposed to simulate climate parameters of Jinan city in China, include artificial neural network (ANN), recurrent NN (RNN), long short-term memory neural network (LSTM), deep convolutional NN (CNN), and CNN-LSTM. These models are used to forecast six climatic factors on a monthly ahead. The climate data for 72 years (1 January 1951–31 December 2022) used in this study include monthly average atmospheric temperature, extreme minimum atmospheric temperature, extreme maximum atmospheric temperature, precipitation, average relative humidity, and sunlight hours. The time series of 12 month delayed data are used as input signals to the models. The efficiency of the proposed models are examined utilizing diverse evaluation criteria namely mean absolute error, root mean square error (RMSE), and correlation coefficient (R). The modeling result inherits that the proposed hybrid CNN-LSTM model achieves a greater accuracy than other compared models. The hybrid CNN-LSTM model significantly reduces the forecasting error compared to the models for the one month time step ahead. For instance, the RMSE values of the ANN, RNN, LSTM, CNN, and CNN-LSTM models for monthly average atmospheric temperature in the forecasting stage are 2.0669, 1.4416, 1.3482, 0.8015 and 0.6292 °C, respectively. The findings of climate simulations shows the potential of CNN-LSTM models to improve climate forecasting. Climate prediction will contribute to meteorological disaster prevention and reduction, as well as flood control and drought resistance.","['artificial neural network (ANN)', 'recurrent NN (RNN)', 'long short-term memory neural network (LSTM)', 'deep convolutional NN (CNN)', 'CNN-LSTM']","The study addresses the impact of climate change on plant growth, food production, ecosystems, sustainable socio-economic development, and human health, highlighting the importance of accurately forecasting climatic factors to better understand and mitigate these effects. It emphasizes the need for reliable climate predictions to support meteorological disaster prevention, flood control, and drought resistance. The primary aim of the study is to forecast six key climatic factors—monthly average atmospheric temperature, extreme minimum and maximum atmospheric temperatures, precipitation, average relative humidity, and sunlight hours—for Jinan city in China, using historical climate data spanning 72 years. This forecasting is intended to improve the accuracy of climate simulations to aid in environmental and socio-economic planning related to climate change impacts."
Biology,Pattern recognition in the nucleation kinetics of non-equilibrium self-assembly,"Abstract Inspired by biology’s most sophisticated computer, the brain, neural networks constitute a profound reformulation of computational principles 1–3 . Analogous high-dimensional, highly interconnected computational architectures also arise within information-processing molecular systems inside living cells, such as signal transduction cascades and genetic regulatory networks 4–7 . Might collective modes analogous to neural computation be found more broadly in other physical and chemical processes, even those that ostensibly play non-information-processing roles? Here we examine nucleation during self-assembly of multicomponent structures, showing that high-dimensional patterns of concentrations can be discriminated and classified in a manner similar to neural network computation. Specifically, we design a set of 917 DNA tiles that can self-assemble in three alternative ways such that competitive nucleation depends sensitively on the extent of colocalization of high-concentration tiles within the three structures. The system was trained in silico to classify a set of 18 grayscale 30 × 30 pixel images into three categories. Experimentally, fluorescence and atomic force microscopy measurements during and after a 150 hour anneal established that all trained images were correctly classified, whereas a test set of image variations probed the robustness of the results. Although slow compared to previous biochemical neural networks, our approach is compact, robust and scalable. Our findings suggest that ubiquitous physical phenomena, such as nucleation, may hold powerful information-processing capabilities when they occur within high-dimensional multicomponent systems.",['neural networks'],"The research idea centers on exploring whether collective behaviors similar to neural computation, typically associated with the brain, can be found more broadly in physical and chemical processes that are not traditionally considered information-processing, such as nucleation during self-assembly of multicomponent structures. The study is motivated by the observation that complex, high-dimensional, and interconnected molecular systems inside living cells, like signal transduction cascades and genetic regulatory networks, exhibit computational-like properties. The research objective is to investigate how nucleation in self-assembling DNA tile systems can discriminate and classify high-dimensional concentration patterns, demonstrating that competitive nucleation depends on the spatial colocalization of specific components. The study aims to experimentally validate that these self-assembling structures can correctly classify different input patterns, thereby revealing that physical phenomena like nucleation may possess inherent information-processing capabilities within complex multicomponent systems."
Biology,Automated Tool Support for Glaucoma Identification With Explainability Using Fundus Images,"Glaucoma is a progressive eye condition that causes irreversible vision loss due to damage to the optic nerve. Recent developments in deep learning and the accessibility of computing resources have provided tool support for automated glaucoma diagnosis. Despite deep learning's advances in disease diagnosis using medical images, generic convolutional neural networks are still not widely used in medical practices due to the limited trustworthiness of these models. Although deep learning-based glaucoma classification has gained popularity in recent years, only a few of them have addressed the explainability and interpretability of the models, which increases confidence in using such applications. This study presents state-of-the-art deep learning techniques to segment and classify fundus images to predict glaucoma conditions and applies visualization techniques to explain the results to ease understandability. Our predictions are based on U-Net with attention mechanisms with ResNet50 for the segmentation process and a modified Inception V3 architecture for the classification. Attention U-Net with modified ResNet50 backbone obtained 99.58% and 98.05% accuracies for optic disc segmentation and optic cup segmentation, respectively for the RIM-ONE dataset. Additionally, we generate heatmaps that highlight the regions that impacted the glaucoma diagnosis using both Gradient-weighted Class Activation Mapping (Grad-CAM) and Grad-CAM++. Our model that classifies the segmented images achieves accuracy, sensitivity, and specificity values of 98.97%, 99.42%, and 95.59%, respectively, with the RIM-ONE dataset. This model can be used as a support tool for automated glaucoma identification using fundus images.","['U-Net with attention mechanisms', 'ResNet50', 'modified Inception V3 architecture', 'Attention U-Net with modified ResNet50 backbone', 'Gradient-weighted Class Activation Mapping (Grad-CAM)', 'Grad-CAM++']","The research idea addresses the challenge of diagnosing glaucoma, a progressive eye disease that leads to irreversible vision loss due to optic nerve damage. Despite advances in automated glaucoma diagnosis using medical images, there remains limited trust and acceptance of these methods in clinical practice, partly because of a lack of explainability and interpretability in the diagnostic process. The study recognizes the need to improve confidence in automated glaucoma detection by making the diagnostic results more understandable to users. The primary objective of the study is to develop an approach for segmenting and classifying fundus images to predict glaucoma conditions accurately, while also providing visual explanations of the diagnostic results to enhance their interpretability and ease of understanding."
Biology,"Generative artificial intelligence in drug discovery: basic framework, recent advances, challenges, and opportunities","There are two main ways to discover or design small drug molecules. The first involves fine-tuning existing molecules or commercially successful drugs through quantitative structure-activity relationships and virtual screening. The second approach involves generating new molecules through de novo drug design or inverse quantitative structure-activity relationship. Both methods aim to get a drug molecule with the best pharmacokinetic and pharmacodynamic profiles. However, bringing a new drug to market is an expensive and time-consuming endeavor, with the average cost being estimated at around $2.5 billion. One of the biggest challenges is screening the vast number of potential drug candidates to find one that is both safe and effective. The development of artificial intelligence in recent years has been phenomenal, ushering in a revolution in many fields. The field of pharmaceutical sciences has also significantly benefited from multiple applications of artificial intelligence, especially drug discovery projects. Artificial intelligence models are finding use in molecular property prediction, molecule generation, virtual screening, synthesis planning, repurposing, among others. Lately, generative artificial intelligence has gained popularity across domains for its ability to generate entirely new data, such as images, sentences, audios, videos, novel chemical molecules, etc. Generative artificial intelligence has also delivered promising results in drug discovery and development. This review article delves into the fundamentals and framework of various generative artificial intelligence models in the context of drug discovery via de novo drug design approach. Various basic and advanced models have been discussed, along with their recent applications. The review also explores recent examples and advances in the generative artificial intelligence approach, as well as the challenges and ongoing efforts to fully harness the potential of generative artificial intelligence in generating novel drug molecules in a faster and more affordable manner. Some clinical-level assets generated form generative artificial intelligence have also been discussed in this review to show the ever-increasing application of artificial intelligence in drug discovery through commercial partnerships.",['inverse quantitative structure-activity relationship'],"The research idea centers on the challenge of discovering or designing small drug molecules that possess optimal pharmacokinetic and pharmacodynamic properties, a process that is costly and time-consuming, with significant difficulty in screening the vast number of potential drug candidates to identify those that are both safe and effective. The study addresses the need for more efficient approaches to drug discovery, particularly through methods that can generate novel molecules beyond fine-tuning existing drugs. The primary objective of the study is to review the fundamentals, frameworks, and recent advances in approaches for generating new drug molecules via de novo drug design, highlighting recent examples, challenges, and ongoing efforts to accelerate and reduce the cost of drug discovery. The study also aims to showcase clinical-level assets developed through these approaches to demonstrate their growing impact in pharmaceutical sciences."
Biology,Improved random forest algorithms for increasing the accuracy of forest aboveground biomass estimation using Sentinel-2 imagery,"A simpler, unbiased, and comprehensive random forest (RF) model is needed to improve the accuracy of aboveground biomass (AGB) estimation. In this study, data were obtained from 128 sample plots of Pinus yunnanensis forest located in Chuxiong prefecture, Yunnan province, China. Sentinel-2 imagery data were applied to extract the important predictors of forest AGB, which were screened using the Boruta algorithm. We compared the fitting performance of two modified random forest models − regularized random forest (RRF) and quantile random forest (QRF) − with the random forest model. Moreover, we combined the smallest mean error of each quantile model as the best QRF (QRFb). The result showed: (1) Window sizes of 3 × 3 pixels and 5 × 5 pixels demonstrated greater sensitivity and suitability for estimating AGB than the 7 × 7 pixels window size. Enhanced vegetation indices derived from Red Edge 1 (B5) and Near-Infrared bands (B8A) were strongly correlated with AGB, indicating the heightened sensitivity of B5 and B8A bands to biomass and their potential in AGB estimation. (2) The RRF model outperformed both the standard RF and QRF in fitting performance, with an R2 of 0.56 and RMSE 57.14 Mg/ha. (3) The QRFb model exhibited the highest R2 of 0.88 and lowest RMSE of 29.56 Mg/ha, significantly reducing overestimation and underestimation issues. The modified RF regression supplies new insights into improving forest AGB estimation, which will be helpful for future research addressing carbon cycling.","['random forest (RF)', 'Boruta algorithm', 'regularized random forest (RRF)', 'quantile random forest (QRF)']","The study addresses the need for a simpler, unbiased, and comprehensive approach to improve the accuracy of estimating aboveground biomass (AGB) in forests. Accurate AGB estimation is crucial for understanding forest carbon storage and dynamics, which are important for ecological research and carbon cycling assessments. The primary aim of the study is to enhance the estimation of AGB in Pinus yunnanensis forests by identifying important predictors from satellite imagery and evaluating different modeling approaches to improve the precision and reliability of biomass estimates. This research seeks to provide improved methods for AGB estimation that can support future studies related to forest carbon cycling."
Biology,GAN based augmentation using a hybrid loss function for dermoscopy images,"Dermatology is the most appropriate field to utilize pattern recognition-based automated techniques for objective, accurate, and rapid diagnosis because diagnosis mainly relies on visual examinations of skin lesions. Recent approaches utilizing deep learning techniques have shown remarkable results in this field. However, they necessitate a substantial quantity of images and the availability of dermoscopy images is often limited. Also, even if enough images are available, their labeling requires expert knowledge and is time-consuming. To overcome these issues, an efficient augmentation approach is needed to expand training datasets from input images. Therefore, in this work, a generative adversarial network has been developed using a new hybrid loss function constructed with traditional loss functions to enhance the generation power of the architecture. Also, the effect of the proposed approach and different generative network-based augmentations, which have been used with dermoscopy images in the literature, on the classification of skin lesions has been investigated. Therefore, the main contributions of this work are: (i) introducing a new generative model for the augmentation of dermoscopy images; (ii) presenting the effect of the proposed model on the classification of the images; (iii) comparative evaluations of the effectiveness of different generative network-based augmentations in the classification of seven forms of skin lesions. The classification accuracy when the proposed augmentation is used is 93.12%, which is higher than its counterparts. Experimental results indicate the significance of augmentation techniques in the classification of skin lesions and the efficiency of the proposed structure in improving the classification accuracy.",['generative adversarial network'],"The research idea centers on the challenge of diagnosing skin lesions in dermatology, which primarily depends on visual examination and requires objective, accurate, and rapid methods. However, the limited availability of dermoscopy images and the time-consuming process of expert labeling hinder the development of effective diagnostic approaches. To address these limitations, there is a need to expand the available image datasets to improve the diagnosis of skin lesions. The primary objective of the study is to develop a new approach for augmenting dermoscopy images to enhance the classification of different types of skin lesions. The study aims to introduce a novel generative model for image augmentation, evaluate its impact on the classification accuracy of skin lesions, and compare its effectiveness with other augmentation methods used for seven forms of skin lesions."
Biology,Automated localization of mandibular landmarks in the construction of mandibular median sagittal plane,"Abstract Objective To use deep learning to segment the mandible and identify three-dimensional (3D) anatomical landmarks from cone-beam computed tomography (CBCT) images, the planes constructed from the mandibular midline landmarks were compared and analyzed to find the best mandibular midsagittal plane (MMSP). Methods A total of 400 participants were randomly divided into a training group ( n = 360) and a validation group ( n = 40). Normal individuals were used as the test group ( n = 50). The PointRend deep learning mechanism segmented the mandible from CBCT images and accurately identified 27 anatomic landmarks via PoseNet. 3D coordinates of 5 central landmarks and 2 pairs of side landmarks were obtained for the test group. Every 35 combinations of 3 midline landmarks were screened using the template mapping technique. The asymmetry index (AI) was calculated for each of the 35 mirror planes. The template mapping technique plane was used as the reference plane; the top four planes with the smallest AIs were compared through distance, volume difference, and similarity index to find the plane with the fewest errors. Results The mandible was segmented automatically in 10 ± 1.5 s with a 0.98 Dice similarity coefficient. The mean landmark localization error for the 27 landmarks was 1.04 ± 0.28 mm. MMSP should use the plane made by B (supramentale), Gn (gnathion), and F (mandibular foramen). The average AI grade was 1.6 (min–max: 0.59–3.61). There was no significant difference in distance or volume ( P &gt; 0.05); however, the similarity index was significantly different ( P &lt; 0.01). Conclusion Deep learning can automatically segment the mandible, identify anatomic landmarks, and address medicinal demands in people without mandibular deformities. The most accurate MMSP was the B-Gn-F plane.","['PointRend deep learning mechanism', 'PoseNet']","The research idea centers on the need to accurately segment the mandible and identify three-dimensional anatomical landmarks from cone-beam computed tomography (CBCT) images to improve the understanding and analysis of mandibular structure. Establishing the best mandibular midsagittal plane (MMSP) is important for assessing mandibular symmetry and anatomical relationships. The study addresses the challenge of determining the most precise plane constructed from mandibular midline landmarks for clinical and anatomical applications. The primary objective of the study is to identify the most accurate mandibular midsagittal plane by comparing and analyzing planes constructed from various combinations of mandibular midline landmarks using CBCT images. The study aims to segment the mandible, locate specific anatomical landmarks, and evaluate different candidate planes to find the one with the fewest errors in terms of asymmetry and anatomical accuracy in individuals without mandibular deformities."
Biology,Predicting transient wind loads on tall buildings in three-dimensional spatial coordinates using machine learning,"Machine learning (ML) as a subset of artificial intelligence (AI), has gained significant attention in wind engineering applications over the past decade. Wind load predictions for tall buildings using ML studies presented in literature have always been limited to static pressure measurements or time history measurements without considering the spatial coordinates system. To design wind-sensitive tall buildings, ML models must be capable of estimating transient wind flow quantities along with its spatial distribution. Thus, in this study, for the first time, the authors used ML to model the transient wind pressure on a tall building using a three-dimensional (3D) spatial coordinates system. A series of Boundary Layer Wind Tunnel tests were performed to obtain the transient pressure readings on building surfaces, which were used to validate the Computational Fluid Dynamics (CFD) models. Turbulence was modelled using large eddy simulations and the data obtained through CFD simulations were utilised to generate the ML models. The popular Extreme Gradient Boosting (XGBoost) model was selected as the ML model due to its capability of efficient data handling. The trained XGBoost model accurately predicted the transient wind pressure throughout the flow time. The XGBoost model has captured the extreme values well, closely following the flow patterns. In addition, special flow features like flow separation, reattachment, and steep pressure gradients have been well captured over the corresponding surfaces. Therefore, this study showcases the ability to use ML to predict pressures on tall buildings, capturing all key flow features time-efficiently.",['Extreme Gradient Boosting (XGBoost)'],"The study addresses the challenge of accurately predicting transient wind pressures on tall buildings, emphasizing the importance of considering the spatial distribution of wind flow rather than relying solely on static or time history pressure measurements. Understanding these transient wind flow quantities and their spatial variation is crucial for designing wind-sensitive tall structures that can withstand complex aerodynamic forces. The primary objective of the study is to model the transient wind pressure on a tall building using a three-dimensional spatial coordinate system, aiming to capture key flow features such as flow separation, reattachment, and steep pressure gradients over building surfaces. This approach seeks to improve the prediction of wind pressures throughout the flow time to better inform the design and safety assessment of tall buildings."
Biology,"Machine Learning and Deep Learning in Synthetic Biology: Key Architectures, Applications, and Challenges","Machine learning (ML), particularly deep learning (DL), has made rapid and substantial progress in synthetic biology in recent years. Biotechnological applications of biosystems, including pathways, enzymes, and whole cells, are being probed frequently with time. The intricacy and interconnectedness of biosystems make it challenging to design them with the desired properties. ML and DL have a synergy with synthetic biology. Synthetic biology can be employed to produce large data sets for training models (for instance, by utilizing DNA synthesis), and ML/DL models can be employed to inform design (for example, by generating new parts or advising unrivaled experiments to perform). This potential has recently been brought to light by research at the intersection of engineering biology and ML/DL through achievements like the design of novel biological components, best experimental design, automated analysis of microscopy data, protein structure prediction, and biomolecular implementations of ANNs (Artificial Neural Networks). I have divided this review into three sections. In the first section, I describe predictive potential and basics of ML along with myriad applications in synthetic biology, especially in engineering cells, activity of proteins, and metabolic pathways. In the second section, I describe fundamental DL architectures and their applications in synthetic biology. Finally, I describe different challenges causing hurdles in the progress of ML/DL and synthetic biology along with their solutions.","['machine learning (ML)', 'deep learning (DL)', 'Artificial Neural Networks (ANNs)']","The study addresses the complexity and interconnectedness of biosystems, which pose significant challenges in designing biological components, pathways, enzymes, and whole cells with desired properties. There is a growing need to better understand and manipulate these biosystems to advance biotechnological applications. The primary aim of the study is to review the recent progress and applications in synthetic biology, particularly focusing on engineering cells, protein activity, and metabolic pathways. It also seeks to highlight the challenges faced in advancing synthetic biology and explore potential solutions to overcome these obstacles."
Biology,A machine learning approach to predict the efficiency of corrosion inhibition by natural product-based organic inhibitors,"Abstract This paper presents a quantitative structure–property relationship (QSPR)-based machine learning (ML) framework designed for predicting corrosion inhibition efficiency (CIE) values in natural organic inhibitor compounds. The modeling dataset comprises 50 natural organic compounds, with 11 quantum chemical properties (QCP) serving as input features, and the target variable being the corrosion inhibition efficiency (CIE) value. To enhance the predictive accuracy of the ML model, the kernel density estimation (KDE) function is employed to generate virtual samples during the training process, with the overarching goal of refining the precision of the ML model. Three distinct models, namely random forest (RF), gradient boosting (GB), and k-nearest neighbor (KNN), are tested in the study. The results demonstrate a noteworthy enhancement in the prediction performance of the models, attributable to the incorporation of virtual samples that effectively improve the correlation between input features and target values. Consequently, the accuracy of the predicted CIE values is significantly augmented, aligning more closely with the actual CIE values. Performance improvements were evident across all models after the incorporation of virtual samples. The GB, RF, and KNN models exhibited increments in R 2 values from 0.557 to 0.996, 0.522 to 0.999, and 0.415 to 0.994, respectively, concomitant with the introduction of 500 virtual samples. Additionally, each model demonstrated a notable reduction in RMSE values, transitioning from 1.41 to 0.19, 1.27 to 0.10, and 1.22 to 0.16, respectively. While the GB model initially outperformed others before the addition of virtual samples, the performance of the model exhibited fluctuation as the number of virtual samples varied. This behavior suggests that the KDE function provides a certain level of resilience against model variations. The proposed approach contributes to the effective design and exploration of corrosion inhibitor candidates, offering a reliable and accurate predictive tool that bridges the gap between theoretical studies and experimental synthesis.","['random forest (RF)', 'gradient boosting (GB)', 'k-nearest neighbor (KNN)']","The study addresses the challenge of accurately predicting the corrosion inhibition efficiency (CIE) of natural organic compounds, which is crucial for the effective design and exploration of corrosion inhibitor candidates. Understanding and improving the prediction of CIE values can help bridge the gap between theoretical studies and experimental synthesis in the development of corrosion inhibitors. The primary objective of the research is to enhance the precision of CIE value predictions for natural organic inhibitor compounds, thereby providing a reliable and accurate means to evaluate their effectiveness in preventing corrosion. This aims to facilitate the identification and optimization of potential corrosion inhibitors based on their chemical properties."
Biology,Assessing ChatGPT 4.0’s test performance and clinical diagnostic accuracy on USMLE STEP 2 CK and clinical case reports,"Abstract While there is data assessing the test performance of artificial intelligence (AI) chatbots, including the Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0), there is scarce data on its diagnostic accuracy of clinical cases. We assessed the large language model (LLM), ChatGPT 4.0, on its ability to answer questions from the United States Medical Licensing Exam (USMLE) Step 2, as well as its ability to generate a differential diagnosis based on corresponding clinical vignettes from published case reports. A total of 109 Step 2 Clinical Knowledge (CK) practice questions were inputted into both ChatGPT 3.5 and ChatGPT 4.0, asking ChatGPT to pick the correct answer. Compared to its previous version, ChatGPT 3.5, we found improved accuracy of ChatGPT 4.0 when answering these questions, from 47.7 to 87.2% ( p = 0.035) respectively. Utilizing the topics tested on Step 2 CK questions, we additionally found 63 corresponding published case report vignettes and asked ChatGPT 4.0 to come up with its top three differential diagnosis. ChatGPT 4.0 accurately created a shortlist of differential diagnoses in 74.6% of the 63 case reports (74.6%). We analyzed ChatGPT 4.0’s confidence in its diagnosis by asking it to rank its top three differentials from most to least likely. Out of the 47 correct diagnoses, 33 were the first (70.2%) on the differential diagnosis list, 11 were second (23.4%), and three were third (6.4%). Our study shows the continued iterative improvement in ChatGPT’s ability to answer standardized USMLE questions accurately and provides insights into ChatGPT’s clinical diagnostic accuracy.","['Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0)', 'large language model (LLM)']","The research idea centers on the need to evaluate the diagnostic accuracy of clinical case assessments, as there is limited data on how well current tools perform in generating accurate clinical diagnoses. Specifically, the study addresses the gap in understanding the ability to correctly answer clinical knowledge questions and generate differential diagnoses based on clinical vignettes. The research objective is to assess the performance of a large language model in answering United States Medical Licensing Exam Step 2 Clinical Knowledge questions and its ability to generate accurate differential diagnoses from published clinical case vignettes. The study aims to measure the accuracy of the model’s responses and its confidence in ranking differential diagnoses to provide insights into its clinical diagnostic capabilities."
Biology,Remote sensing based forest cover classification using machine learning,"Abstract Pakistan falls significantly below the recommended forest coverage level of 20 to 30 percent of total area, with less than 6 percent of its land under forest cover. This deficiency is primarily attributed to illicit deforestation for wood and charcoal, coupled with a failure to embrace advanced techniques for forest estimation, monitoring, and supervision. Remote sensing techniques leveraging Sentinel-2 satellite images were employed. Both single-layer stacked images and temporal layer stacked images from various dates were utilized for forest classification. The application of an artificial neural network (ANN) supervised classification algorithm yielded notable results. Using a single-layer stacked image from Sentinel-2, an impressive 91.37% training overall accuracy and 0.865 kappa coefficient were achieved, along with 93.77% testing overall accuracy and a 0.902 kappa coefficient. Furthermore, the temporal layer stacked image approach demonstrated even better results. This method yielded 98.07% overall training accuracy, 97.75% overall testing accuracy, and kappa coefficients of 0.970 and 0.965, respectively. The random forest (RF) algorithm, when applied, achieved 99.12% overall training accuracy, 92.90% testing accuracy, and kappa coefficients of 0.986 and 0.882. Notably, with the temporal layer stacked image of the Sentinel-2 satellite, the RF algorithm reached exceptional performance with 99.79% training accuracy, 96.98% validation accuracy, and kappa coefficients of 0.996 and 0.954. In terms of forest cover estimation, the ANN algorithm identified 31.07% total forest coverage in the District Abbottabad region. In comparison, the RF algorithm recorded a slightly higher 31.17% of the total forested area. This research highlights the potential of advanced remote sensing techniques and machine learning algorithms in improving forest cover assessment and monitoring strategies.","['artificial neural network (ANN) supervised classification algorithm', 'random forest (RF) algorithm']","The research idea centers on addressing Pakistan's significant shortfall in forest coverage, which is currently less than 6 percent compared to the recommended 20 to 30 percent of total land area. This deficiency is largely due to illicit deforestation for wood and charcoal, as well as inadequate methods for accurate forest estimation, monitoring, and supervision. The study is motivated by the need to improve forest cover assessment to better manage and conserve forest resources. The primary objective of the study is to estimate and monitor forest cover in the District Abbottabad region more accurately, aiming to provide reliable measurements of total forested area to support better forest management and conservation efforts."
Biology,Improving River Routing Using a Differentiable Muskingum‐Cunge Model and Physics‐Informed Machine Learning,"Abstract Recently, rainfall‐runoff simulations in small headwater basins have been improved by methodological advances such as deep neural networks (NNs) and hybrid physics‐NN models—particularly, a genre called differentiable modeling that intermingles NNs with physics to learn relationships between variables. However, hydrologic routing simulations, necessary for simulating floods in stem rivers downstream of large heterogeneous basins, had not yet benefited from these advances and it was unclear if the routing process could be improved via coupled NNs. We present a novel differentiable routing method ( δ MC‐Juniata‐hydroDL2) that mimics the classical Muskingum‐Cunge routing model over a river network but embeds an NN to infer parameterizations for Manning's roughness ( n ) and channel geometries from raw reach‐scale attributes like catchment areas and sinuosity. The NN was trained solely on downstream hydrographs. Synthetic experiments show that while the channel geometry parameter was unidentifiable, n can be identified with moderate precision. With real‐world data, the trained differentiable routing model produced more accurate long‐term routing results for both the training gage and untrained inner gages for larger subbasins (&gt;2,000 km 2 ) than either a machine learning model assuming homogeneity, or simply using the sum of runoff from subbasins. The n parameterization trained on short periods gave high performance in other periods, despite significant errors in runoff inputs. The learned n pattern was consistent with literature expectations, demonstrating the framework's potential for knowledge discovery, but the absolute values can vary depending on training periods. The trained n parameterization can be coupled with traditional models to improve national‐scale hydrologic flood simulations.","['deep neural networks (NNs)', 'hybrid physics‐NN models', 'differentiable modeling']","The research idea addresses the challenge of improving hydrologic routing simulations necessary for simulating floods in stem rivers downstream of large heterogeneous basins, an area that had not yet benefited from recent advances in rainfall-runoff modeling. The study focuses on enhancing the representation of channel characteristics such as Manning's roughness and channel geometries to achieve more accurate flood routing over river networks. The primary objective of the study is to develop and evaluate a novel routing method that mimics classical hydrologic routing models while inferring parameterizations for channel roughness and geometry from physical attributes of river reaches. The aim is to produce more accurate long-term routing results for large subbasins and demonstrate the potential for improved flood simulations at national scales by coupling the inferred parameterizations with traditional hydrologic models."
Biology,Traffic Sign Detection and Recognition Using YOLO Object Detection Algorithm: A Systematic Review,"Context: YOLO (You Look Only Once) is an algorithm based on deep neural networks with real-time object detection capabilities. This state-of-the-art technology is widely available, mainly due to its speed and precision. Since its conception, YOLO has been applied to detect and recognize traffic signs, pedestrians, traffic lights, vehicles, and so on. Objective: The goal of this research is to systematically analyze the YOLO object detection algorithm, applied to traffic sign detection and recognition systems, from five relevant aspects of this technology: applications, datasets, metrics, hardware, and challenges. Method: This study performs a systematic literature review (SLR) of studies on traffic sign detection and recognition using YOLO published in the years 2016–2022. Results: The search found 115 primary studies relevant to the goal of this research. After analyzing these investigations, the following relevant results were obtained. The most common applications of YOLO in this field are vehicular security and intelligent and autonomous vehicles. The majority of the sign datasets used to train, test, and validate YOLO-based systems are publicly available, with an emphasis on datasets from Germany and China. It has also been discovered that most works present sophisticated detection, classification, and processing speed metrics for traffic sign detection and recognition systems by using the different versions of YOLO. In addition, the most popular desktop data processing hardwares are Nvidia RTX 2080 and Titan Tesla V100 and, in the case of embedded or mobile GPU platforms, Jetson Xavier NX. Finally, seven relevant challenges that these systems face when operating in real road conditions have been identified. With this in mind, research has been reclassified to address these challenges in each case. Conclusions: This SLR is the most relevant and current work in the field of technology development applied to the detection and recognition of traffic signs using YOLO. In addition, insights are provided about future work that could be conducted to improve the field.",['YOLO (You Only Look Once)'],"The research idea centers on the need to improve the detection and recognition of traffic signs, which is crucial for enhancing vehicular security and the development of intelligent and autonomous vehicles. Accurate and efficient traffic sign recognition systems are essential for safe navigation and real-time decision-making in road environments. The study aims to systematically analyze existing approaches to traffic sign detection and recognition to better understand their applications, datasets, performance metrics, hardware requirements, and the challenges faced in real-world conditions. The primary objective of this research is to conduct a comprehensive review of studies focused on traffic sign detection and recognition, with the goal of identifying key aspects and challenges in the field to guide future improvements and developments."
Biology,Avoiding fusion plasma tearing instability with deep reinforcement learning,"Abstract For stable and efficient fusion energy production using a tokamak reactor, it is essential to maintain a high-pressure hydrogenic plasma without plasma disruption. Therefore, it is necessary to actively control the tokamak based on the observed plasma state, to manoeuvre high-pressure plasma while avoiding tearing instability, the leading cause of disruptions. This presents an obstacle-avoidance problem for which artificial intelligence based on reinforcement learning has recently shown remarkable performance 1–4 . However, the obstacle here, the tearing instability, is difficult to forecast and is highly prone to terminating plasma operations, especially in the ITER baseline scenario. Previously, we developed a multimodal dynamic model that estimates the likelihood of future tearing instability based on signals from multiple diagnostics and actuators 5 . Here we harness this dynamic model as a training environment for reinforcement-learning artificial intelligence, facilitating automated instability prevention. We demonstrate artificial intelligence control to lower the possibility of disruptive tearing instabilities in DIII-D 6 , the largest magnetic fusion facility in the United States. The controller maintained the tearing likelihood under a given threshold, even under relatively unfavourable conditions of low safety factor and low torque. In particular, it allowed the plasma to actively track the stable path within the time-varying operational space while maintaining H-mode performance, which was challenging with traditional preprogrammed control. This controller paves the path to developing stable high-performance operational scenarios for future use in ITER.",['reinforcement learning'],"The study addresses the challenge of maintaining a high-pressure hydrogenic plasma in a tokamak reactor without experiencing plasma disruptions, which are primarily caused by tearing instability. This instability is difficult to predict and poses a significant obstacle to stable and efficient fusion energy production, especially in the ITER baseline scenario. The research focuses on overcoming the difficulty of controlling plasma behavior to prevent disruptions and sustain high-performance operational conditions. The primary aim of the study is to develop and demonstrate a control approach that can actively manage the plasma state to reduce the likelihood of disruptive tearing instabilities, thereby enabling stable high-performance plasma operation in tokamak reactors such as DIII-D and paving the way for future applications in ITER."
Biology,Advancing entity recognition in biomedicine via instruction tuning of large language models,"Abstract Motivation Large Language Models (LLMs) have the potential to revolutionize the field of Natural Language Processing, excelling not only in text generation and reasoning tasks but also in their ability for zero/few-shot learning, swiftly adapting to new tasks with minimal fine-tuning. LLMs have also demonstrated great promise in biomedical and healthcare applications. However, when it comes to Named Entity Recognition (NER), particularly within the biomedical domain, LLMs fall short of the effectiveness exhibited by fine-tuned domain-specific models. One key reason is that NER is typically conceptualized as a sequence labeling task, whereas LLMs are optimized for text generation and reasoning tasks. Results We developed an instruction-based learning paradigm that transforms biomedical NER from a sequence labeling task into a generation task. This paradigm is end-to-end and streamlines the training and evaluation process by automatically repurposing pre-existing biomedical NER datasets. We further developed BioNER-LLaMA using the proposed paradigm with LLaMA-7B as the foundational LLM. We conducted extensive testing on BioNER-LLaMA across three widely recognized biomedical NER datasets, consisting of entities related to diseases, chemicals, and genes. The results revealed that BioNER-LLaMA consistently achieved higher F1-scores ranging from 5% to 30% compared to the few-shot learning capabilities of GPT-4 on datasets with different biomedical entities. We show that a general-domain LLM can match the performance of rigorously fine-tuned PubMedBERT models and PMC-LLaMA, biomedical-specific language model. Our findings underscore the potential of our proposed paradigm in developing general-domain LLMs that can rival SOTA performances in multi-task, multi-domain scenarios in biomedical and health applications. Availability and implementation Datasets and other resources are available at https://github.com/BIDS-Xu-Lab/BioNER-LLaMA.","['few-shot learning', 'LLaMA-7B', 'GPT-4 few-shot learning', 'PubMedBERT fine-tuning']","The research addresses the challenge of effectively recognizing named entities within the biomedical domain, such as diseases, chemicals, and genes, which is crucial for advancing biomedical and healthcare applications. Traditional approaches conceptualize Named Entity Recognition (NER) as a sequence labeling task, but existing models optimized for text generation and reasoning do not perform as well in this context. The study aims to improve the performance of biomedical NER by transforming it into a generation task, thereby enhancing the ability to identify various biomedical entities across multiple datasets. The primary objective is to develop and evaluate a new paradigm that enables general-domain models to achieve competitive or superior results compared to specialized biomedical models in recognizing named entities related to diseases, chemicals, and genes."
Biology,Reliable water quality prediction and parametric analysis using explainable AI models,"Abstract The consumption of water constitutes the physical health of most of the living species and hence management of its purity and quality is extremely essential as contaminated water has to potential to create adverse health and environmental consequences. This creates the dire necessity to measure, control and monitor the quality of water. The primary contaminant present in water is Total Dissolved Solids (TDS), which is hard to filter out. There are various substances apart from mere solids such as potassium, sodium, chlorides, lead, nitrate, cadmium, arsenic and other pollutants. The proposed work aims to provide the automation of water quality estimation through Artificial Intelligence and uses Explainable Artificial Intelligence (XAI) for the explanation of the most significant parameters contributing towards the potability of water and the estimation of the impurities. XAI has the transparency and justifiability as a white-box model since the Machine Learning (ML) model is black-box and unable to describe the reasoning behind the ML classification. The proposed work uses various ML models such as Logistic Regression, Support Vector Machine (SVM), Gaussian Naive Bayes, Decision Tree (DT) and Random Forest (RF) to classify whether the water is drinkable. The various representations of XAI such as force plot, test patch, summary plot, dependency plot and decision plot generated in SHAPELY explainer explain the significant features, prediction score, feature importance and justification behind the water quality estimation. The RF classifier is selected for the explanation and yields optimum Accuracy and F1-Score of 0.9999, with Precision and Re-call of 0.9997 and 0.998 respectively. Thus, the work is an exploratory analysis of the estimation and management of water quality with indicators associated with their significance. This work is an emerging research at present with a vision of addressing the water quality for the future as well.","['Logistic Regression', 'Support Vector Machine (SVM)', 'Gaussian Naive Bayes', 'Decision Tree (DT)', 'Random Forest (RF)']","The consumption of water is vital for the physical health of most living species, making the management of its purity and quality extremely important due to the potential adverse health and environmental consequences caused by contaminated water. Total Dissolved Solids (TDS) and various other substances such as potassium, sodium, chlorides, lead, nitrate, cadmium, and arsenic are primary contaminants that affect water quality and are difficult to remove. The study aims to estimate and monitor water quality by identifying the most significant parameters contributing to water potability and impurity levels. The primary objective is to classify whether water is drinkable based on these key indicators and to provide an explanation of their significance in assessing water quality for better management and future sustainability."
Biology,Multi-task aquatic toxicity prediction model based on multi-level features fusion,"With the escalating menace of organic compounds in environmental pollution imperiling the survival of aquatic organisms, the investigation of organic compound toxicity across diverse aquatic species assumes paramount significance for environmental protection. Understanding how different species respond to these compounds helps assess the potential ecological impact of pollution on aquatic ecosystems as a whole. Compared with traditional experimental methods, deep learning methods have higher accuracy in predicting aquatic toxicity, faster data processing speed and better generalization ability. This article presents ATFPGT-multi, an advanced multi-task deep neural network prediction model for organic toxicity. The model integrates molecular fingerprints and molecule graphs to characterize molecules, enabling the simultaneous prediction of acute toxicity for the same organic compound across four distinct fish species. Furthermore, to validate the advantages of multi-task learning, we independently construct prediction models, named ATFPGT-single, for each fish species. We employ cross-validation in our experiments to assess the performance and generalization ability of ATFPGT-multi. The experimental results indicate, first, that ATFPGT-multi outperforms ATFPGT-single on four fish datasets with AUC improvements of 9.8%, 4%, 4.8%, and 8.2%, respectively, demonstrating the superiority of multi-task learning over single-task learning. Furthermore, in comparison with previous algorithms, ATFPGT-multi outperforms comparative methods, emphasizing that our approach exhibits higher accuracy and reliability in predicting aquatic toxicity. Moreover, ATFPGT-multi utilizes attention scores to identify molecular fragments associated with fish toxicity in organic molecules, as demonstrated by two organic molecule examples in the main text, demonstrating the interpretability of ATFPGT-multi. In summary, ATFPGT-multi provides important support and reference for the further development of aquatic toxicity assessment. All of codes and datasets are freely available online at https://github.com/zhaoqi106/ATFPGT-multi.","['deep learning methods', 'multi-task deep neural network prediction model', 'multi-task learning', 'single-task learning']","The research addresses the growing threat posed by organic compounds in environmental pollution, which endangers the survival of aquatic organisms. Investigating the toxicity of these organic compounds across various aquatic species is crucial for understanding and protecting aquatic ecosystems from ecological harm. The study aims to predict the acute toxicity of the same organic compounds across four different fish species to better assess their potential ecological impact. The primary objective is to develop a method that enables simultaneous prediction of organic compound toxicity in multiple fish species, thereby providing important support and reference for advancing aquatic toxicity assessment."
Biology,A survey on training challenges in generative adversarial networks for biomedical image analysis,"Abstract In biomedical image analysis, the applicability of deep learning methods is directly impacted by the quantity of image data available. This is due to deep learning models requiring large image datasets to provide high-level performance. Generative Adversarial Networks (GANs) have been widely utilized to address data limitations through the generation of synthetic biomedical images. GANs consist of two models. The generator, a model that learns how to produce synthetic images based on the feedback it receives. The discriminator, a model that classifies an image as synthetic or real and provides feedback to the generator. Throughout the training process, a GAN can experience several technical challenges that impede the generation of suitable synthetic imagery. First, the mode collapse problem whereby the generator either produces an identical image or produces a uniform image from distinct input features. Second, the non-convergence problem whereby the gradient descent optimizer fails to reach a Nash equilibrium. Thirdly, the vanishing gradient problem whereby unstable training behavior occurs due to the discriminator achieving optimal classification performance resulting in no meaningful feedback being provided to the generator. These problems result in the production of synthetic imagery that is blurry, unrealistic, and less diverse. To date, there has been no survey article outlining the impact of these technical challenges in the context of the biomedical imagery domain. This work presents a review and taxonomy based on solutions to the training problems of GANs in the biomedical imaging domain. This survey highlights important challenges and outlines future research directions about the training of GANs in the domain of biomedical imagery.","['deep learning', 'Generative Adversarial Networks (GANs)', 'discriminator', 'gradient descent optimizer']","The research idea addresses the challenge of limited biomedical image data, which affects the ability to generate high-quality synthetic biomedical images necessary for advancing biomedical image analysis. The study highlights that technical difficulties in generating suitable synthetic images, such as producing blurry, unrealistic, and less diverse imagery, hinder progress in this area. The research objective is to review and categorize the existing solutions to these technical challenges encountered during the generation of synthetic biomedical images. This work aims to highlight important challenges and propose future research directions to improve the generation of synthetic biomedical imagery."
Psychology,Can large language models replace humans in systematic reviews? Evaluating <scp>GPT</scp>‐4's efficacy in screening and extracting data from peer‐reviewed and grey literature in multiple languages,"Systematic reviews are vital for guiding practice, research and policy, although they are often slow and labour-intensive. Large language models (LLMs) could speed up and automate systematic reviews, but their performance in such tasks has yet to be comprehensively evaluated against humans, and no study has tested Generative Pre-Trained Transformer (GPT)-4, the biggest LLM so far. This pre-registered study uses a ""human-out-of-the-loop"" approach to evaluate GPT-4's capability in title/abstract screening, full-text review and data extraction across various literature types and languages. Although GPT-4 had accuracy on par with human performance in some tasks, results were skewed by chance agreement and dataset imbalance. Adjusting for these caused performance scores to drop across all stages: for data extraction, performance was moderate, and for screening, it ranged from none in highly balanced literature datasets (~1:1) to moderate in those datasets where the ratio of inclusion to exclusion in studies was imbalanced (~1:3). When screening full-text literature using highly reliable prompts, GPT-4's performance was more robust, reaching ""human-like"" levels. Although our findings indicate that, currently, substantial caution should be exercised if LLMs are being used to conduct systematic reviews, they also offer preliminary evidence that, for certain review tasks delivered under specific conditions, LLMs can rival human performance.",['Generative Pre-Trained Transformer (GPT)-4'],"The research idea centers on the importance of systematic reviews for guiding practice, research, and policy, while highlighting the challenges posed by their slow and labor-intensive nature. The study addresses the need to evaluate alternative approaches that could potentially expedite these reviews without compromising quality. The primary objective of the study is to comprehensively assess the capability of a novel approach in performing key tasks involved in systematic reviews, such as screening and data extraction, across various types of literature and languages. The study aims to determine how well this approach performs compared to human reviewers, particularly under different conditions and dataset characteristics."
Psychology,TRANSFORMING FINTECH FRAUD DETECTION WITH ADVANCED ARTIFICIAL INTELLIGENCE ALGORITHMS,"The rapid evolution of financial technology (fintech) platforms has exponentially increased the volume and sophistication of financial transactions, concurrently elevating the risk and complexity of fraudulent activities. This necessitates a paradigm shift in fraud detection methodologies towards more agile, accurate, and predictive solutions. This paper presents a comprehensive study on the transformative potential of advanced Artificial Intelligence (AI) algorithms in enhancing fintech fraud detection mechanisms. By leveraging cutting-edge AI techniques including deep learning, machine learning, and natural language processing, this research aims to develop a robust fraud detection framework capable of identifying, analyzing, and preventing fraudulent transactions in real-time.&#x0D; Our methodology encompasses the deployment of several AI algorithms on extensive datasets comprising genuine and fraudulent financial transactions. Through a comparative analysis, we identify the most effective algorithms in terms of accuracy, efficiency, and scalability. Key findings reveal that deep learning models, particularly those employing neural networks, outperform traditional machine learning models in detecting complex and nuanced fraudulent activities. Furthermore, the integration of natural language processing enables the extraction and analysis of unstructured data, significantly enhancing the detection capabilities.&#x0D; Conclusively, this paper underscores the critical role of advanced AI algorithms in revolutionizing fintech fraud detection. It highlights the superior performance of AI-based models over conventional methods, offering fintech platforms a more dynamic and predictive approach to fraud prevention. This research not only contributes to the academic discourse on financial security but also provides practical insights for fintech companies striving to safeguard their operations against fraud.&#x0D; Keywords: Artificial Intelligence, Fintech, Fraud Detection, Ethical Ai, Regulatory Compliance, Data Privacy, Algorithmic Bias, Predictive Analytics, Blockchain Technology, Quantum Computing, Interdisciplinary Collaboration, Innovation, Transparency, Accountability, Continuous Learning, Ethical Principles, Real-Time Processing, Financial Sector.","['deep learning', 'machine learning', 'neural networks']","The study addresses the increasing complexity and risk of fraudulent activities within the rapidly evolving financial technology environment, highlighting the need for more effective and responsive approaches to fraud detection. It emphasizes the challenges posed by the growing volume and sophistication of financial transactions, which demand improved methods to identify and prevent fraud. The primary aim of the research is to explore and evaluate innovative approaches that enhance the ability to detect, analyze, and prevent fraudulent financial transactions in real-time. This study seeks to provide insights that can improve the accuracy and efficiency of fraud detection mechanisms, ultimately contributing to the security and integrity of financial technology platforms."
Psychology,Applying large language models and chain-of-thought for automatic scoring,"This study investigates the application of large language models (LLMs), specifically GPT-3.5 and GPT-4, with Chain-of-Though (CoT) in the automatic scoring of student-written responses to science assessments. We focused on overcoming the challenges of accessibility, technical complexity, and lack of explainability that have previously limited the use of artificial intelligence-based automatic scoring tools among researchers and educators. With a testing dataset comprising six assessment tasks (three binomial and three trinomial) with 1650 student responses, we employed six prompt engineering strategies to automatically score student responses. The six strategies combined zero-shot or few-shot learning with CoT, either alone or alongside item stem and scoring rubrics, developed based on a novel approach, WRVRT (prompt writing, reviewing, validating, revising, and testing). Results indicated that few-shot (acc = 0.67) outperformed zero-shot learning (acc = 0.60), with 12.6% increase. CoT, when used without item stem and scoring rubrics, did not significantly affect scoring accuracy (acc = 0.60). However, CoT prompting paired with contextual item stems and rubrics proved to be a significant contributor to scoring accuracy (13.44% increase for zero-shot; 3.7% increase for few-shot). We found a more balanced accuracy across different proficiency categories when CoT was used with a scoring rubric, highlighting the importance of domain-specific reasoning in enhancing the effectiveness of LLMs in scoring tasks. We also found that GPT-4 demonstrated superior performance over GPT -3.5 in various scoring tasks when combined with the single-call greedy sampling or ensemble voting nucleus sampling strategy, showing 8.64% difference. Particularly, the single-call greedy sampling strategy with GPT-4 outperformed other approaches. This study also demonstrates the potential of LLMs in facilitating explainable and interpretable automatic scoring, emphasizing that CoT enhances accuracy and transparency, particularly when used with item stem and scoring rubrics.","['GPT-3.5', 'GPT-4', 'Chain-of-Thought (CoT)', 'zero-shot learning', 'few-shot learning']","The research idea centers on addressing the challenges of accessibility, technical complexity, and lack of explainability that have limited the use of automatic scoring tools for student-written responses in science assessments. The study is motivated by the need to improve the accuracy and transparency of scoring methods to better support researchers and educators in evaluating student performance. The primary objective of the study is to investigate how different prompting strategies, particularly those incorporating domain-specific reasoning through item stems and scoring rubrics, can enhance the accuracy and interpretability of automatic scoring of student responses. The study aims to evaluate the effectiveness of these strategies in producing more balanced and explainable scoring outcomes across various proficiency levels."
Psychology,Transformative Breast Cancer Diagnosis using CNNs with Optimized ReduceLROnPlateau and Early Stopping Enhancements,"Abstract Breast cancer stands as a paramount public health concern worldwide, underscoring an imperative necessity within the research sphere for precision-driven and efficacious methodologies facilitating accurate detection. The existing diagnostic approaches in breast cancer often suffer from limitations in accuracy and efficiency, leading to delayed detection and subsequent challenges in personalized treatment planning. The primary focus of this research is to overcome these shortcomings by harnessing the power of advanced deep learning techniques, thereby revolutionizing the precision and reliability of breast cancer classification. This research addresses the critical need for improved breast cancer diagnostics by introducing a novel Convolutional Neural Network (CNN) model integrated with an Early Stopping callback and ReduceLROnPlateau callback. By enhancing the precision and reliability of breast cancer classification, the study aims to overcome the limitations of existing diagnostic methods, ultimately leading to better patient outcomes and reduced mortality rates. The comprehensive methodology includes diverse datasets, meticulous image preprocessing, robust model training, and validation strategies, emphasizing the model's adaptability and reliability in varied clinical contexts. The findings showcase the CNN model's exceptional performance, achieving a 95.2% accuracy rate in distinguishing cancerous and non-cancerous breast tissue in the integrated dataset, thereby demonstrating its potential for enhancing clinical decision-making and fostering the development of AI-driven diagnostic solutions.","['Convolutional Neural Network (CNN)', 'Early Stopping callback']","The research idea centers on the significant public health challenge posed by breast cancer and the urgent need for more accurate and efficient diagnostic approaches. Current methods often lack precision, leading to delayed detection and difficulties in tailoring personalized treatment plans. The study is motivated by the necessity to improve the reliability of breast cancer classification to enhance patient outcomes and reduce mortality rates. The primary objective of the study is to address the limitations of existing diagnostic techniques by developing a more precise and dependable method for distinguishing cancerous from non-cancerous breast tissue. This aims to facilitate earlier detection and support better clinical decision-making in breast cancer care."
Psychology,Investigating Spatial Effects through Machine Learning and Leveraging Explainable AI for Child Malnutrition in Pakistan,"While socioeconomic gradients in regional health inequalities are firmly established, the synergistic interactions between socioeconomic deprivation and climate vulnerability within convenient proximity and neighbourhood locations with health disparities remain poorly explored and thus require deep understanding within a regional context. Furthermore, disregarding the importance of spatial spillover effects and nonlinear effects of covariates on childhood stunting are inevitable in dealing with an enduring issue of regional health inequalities. The present study aims to investigate the spatial inequalities in childhood stunting at the district level in Pakistan and validate the importance of spatial lag in predicting childhood stunting. Furthermore, it examines the presence of any nonlinear relationships among the selected independent features with childhood stunting. The study utilized data related to socioeconomic features from MICS 2017–2018 and climatic data from Integrated Contextual Analysis. A multi-model approach was employed to address the research questions, which included Ordinary Least Squares Regression (OLS), various Spatial Models, Machine Learning Algorithms and Explainable Artificial Intelligence methods. Firstly, OLS was used to analyse and test the linear relationships among selected variables. Secondly, Spatial Durbin Error Model (SDEM) was used to detect and capture the impact of spatial spillover on childhood stunting. Third, XGBoost and Random Forest machine learning algorithms were employed to examine and validate the importance of the spatial lag component. Finally, EXAI methods such as SHapley were utilized to identify potential nonlinear relationships. The study found a clear pattern of spatial clustering and geographical disparities in childhood stunting, with multidimensional poverty, high climate vulnerability and early marriage worsening childhood stunting. In contrast, low climate vulnerability, high exposure to mass media and high women’s literacy were found to reduce childhood stunting. The use of machine learning algorithms, specifically XGBoost and Random Forest, highlighted the significant role played by the average value in the neighbourhood in predicting childhood stunting in nearby districts, confirming that the spatial spillover effect is not bounded by geographical boundaries. Furthermore, EXAI methods such as partial dependency plot reveal the existence of a nonlinear relationship between multidimensional poverty and childhood stunting. The study’s findings provide valuable insights into the spatial distribution of childhood stunting in Pakistan, emphasizing the importance of considering spatial effects in predicting childhood stunting. Individual and household-level factors such as exposure to mass media and women’s literacy have shown positive implications for childhood stunting. It further provides a justification for the usage of EXAI methods to draw better insights and propose customised intervention policies accordingly.","['XGBoost', 'Random Forest', 'partial dependency plot']","The research idea centers on addressing the insufficient understanding of how socioeconomic deprivation and climate vulnerability interact within local neighborhoods to influence regional health disparities, particularly childhood stunting. Despite established socioeconomic gradients in health inequalities, the combined effects of these factors and the role of spatial spillover and nonlinear relationships in childhood stunting remain underexplored in a regional context. The study aims to investigate spatial inequalities in childhood stunting at the district level in Pakistan, emphasizing the importance of spatial influences and nonlinear associations among relevant socioeconomic and climatic factors. Its primary objective is to examine the spatial distribution and clustering of childhood stunting, validate the significance of spatial spillover effects, and identify any nonlinear relationships between selected independent variables and childhood stunting, thereby providing insights to inform targeted intervention policies."
Psychology,Cognition-Driven Structural Prior for Instance-Dependent Label Transition Matrix Estimation,"The label transition matrix has emerged as a widely accepted method for mitigating label noise in machine learning. In recent years, numerous studies have centered on leveraging deep neural networks to estimate the label transition matrix for individual instances within the context of instance-dependent noise. However, these methods suffer from low search efficiency due to the large space of feasible solutions. Behind this drawback, we have explored that the real murderer lies in the invalid class transitions, that is, the actual transition probability between certain classes is zero but is estimated to have a certain value. To mask the <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">invalid class transitions</i> , we introduced a human-cognition-assisted method with structural information from human cognition. Specifically, we introduce a structured transition matrix network ( <bold xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">STMN</b> ) designed with an adversarial learning process to balance instance features and prior information from human cognition. The proposed method offers two advantages: 1) better estimation effectiveness is obtained by sparing the transition matrix and 2) better estimation accuracy is obtained with the assistance of human cognition. By exploiting these two advantages, our method parametrically estimates a sparse label transition matrix, effectively converting noisy labels into true labels. The efficiency and superiority of our proposed method are substantiated through comprehensive comparisons with state-of-the-art methods on three synthetic datasets and a real-world dataset. Our code will be available at https://github.com/WheatCao/STMN-Pytorch.","['deep neural networks', 'adversarial learning process']","The research idea centers on addressing the challenge of inaccurate estimation of class transitions in the presence of label noise, particularly when certain class transitions are invalid but are mistakenly assigned nonzero probabilities. This issue hampers the effectiveness of correcting noisy labels, which is crucial for improving the reliability of labeled data in psychological research contexts. The study aims to improve the accuracy of identifying true class transitions by incorporating insights from human cognition to better distinguish valid from invalid transitions. The primary objective of the study is to develop a method that leverages structural information derived from human cognition to more accurately estimate the relationships between classes, thereby enhancing the correction of noisy labels and improving the quality of data used in psychological investigations."
Psychology,Multiple Classification of Brain MRI Autism Spectrum Disorder by Age and Gender Using Deep Learning,"Abstract The fact that the rapid and definitive diagnosis of autism cannot be made today and that autism cannot be treated provides an impetus to look into novel technological solutions. To contribute to the resolution of this problem through multiple classifications by considering age and gender factors, in this study, two quadruple and one octal classifications were performed using a deep learning (DL) approach. Gender in one of the four classifications and age groups in the other were considered. In the octal classification, classes were created considering gender and age groups. In addition to the diagnosis of ASD (Autism Spectrum Disorders), another goal of this study is to find out the contribution of gender and age factors to the diagnosis of ASD by making multiple classifications based on age and gender for the first time. Brain structural MRI (sMRI) scans of participators with ASD and TD (Typical Development) were pre-processed in the system originally designed for this purpose. Using the Canny Edge Detection (CED) algorithm, the sMRI image data was cropped in the data pre-processing stage, and the data set was enlarged five times with the data augmentation (DA) techniques. The most optimal convolutional neural network (CNN) models were developed using the grid search optimization (GSO) algorism. The proposed DL prediction system was tested with the five-fold cross-validation technique. Three CNN models were designed to be used in the system. The first of these models is the quadruple classification model created by taking gender into account (model 1), the second is the quadruple classification model created by taking into account age (model 2), and the third is the eightfold classification model created by taking into account both gender and age (model 3). ). The accuracy rates obtained for all three designed models are 80.94, 85.42 and 67.94, respectively. These obtained accuracy rates were compared with pre-trained models by using the transfer learning approach. As a result, it was revealed that age and gender factors were effective in the diagnosis of ASD with the system developed for ASD multiple classifications, and higher accuracy rates were achieved compared to pre-trained models.","['convolutional neural network (CNN) models', 'transfer learning approach']","The research idea centers on the challenge that autism cannot currently be diagnosed rapidly and definitively, nor can it be treated effectively, which motivates the exploration of new approaches to improve diagnosis. This study addresses the need to understand how age and gender factors contribute to the diagnosis of Autism Spectrum Disorders (ASD), recognizing that these factors may influence diagnostic accuracy. The primary objective of the study is to investigate the contribution of gender and age to the diagnosis of ASD by performing multiple classifications based on these factors for the first time. Specifically, the study aims to assess how considering age and gender separately and together affects the accuracy of ASD diagnosis."
Psychology,Counterfactual Explanations and Algorithmic Recourses for Machine Learning: A Review,"Machine learning plays a role in many deployed decision systems, often in ways that are difficult or impossible to understand by human stakeholders. Explaining, in a human-understandable way, the relationship between the input and output of machine learning models is essential to the development of trustworthy machine learning based systems. A burgeoning body of research seeks to define the goals and methods of explainability in machine learning. In this article, we seek to review and categorize research on counterfactual explanations , a specific class of explanation that provides a link between what could have happened had input to a model been changed in a particular way. Modern approaches to counterfactual explainability in machine learning draw connections to the established legal doctrine in many countries, making them appealing to fielded systems in high-impact areas such as finance and healthcare. Thus, we design a rubric with desirable properties of counterfactual explanation algorithms and comprehensively evaluate all currently proposed algorithms against that rubric. Our rubric provides easy comparison and comprehension of the advantages and disadvantages of different approaches and serves as an introduction to major research themes in this field. We also identify gaps and discuss promising research directions in the space of counterfactual explainability.","['counterfactual explanations', 'counterfactual explanation algorithms']","The research idea centers on the importance of providing explanations that are understandable to humans regarding the relationship between inputs and outputs in decision-making processes. This need arises from the challenge that many decision systems operate in ways that are difficult or impossible for human stakeholders to comprehend, which impacts trustworthiness. The study addresses the broader motivation to clarify and categorize how explanations, particularly counterfactual explanations, can enhance understanding and trust in decision outcomes. The primary objective of the study is to review and categorize existing research on counterfactual explanations, which illustrate what could have happened if certain inputs had been different. Additionally, the study aims to design a framework with desirable properties for these explanations and to evaluate current approaches against this framework, thereby identifying gaps and suggesting future directions for research in this area."
Psychology,An Explainable AI Paradigm for Alzheimer’s Diagnosis Using Deep Transfer Learning,"Alzheimer’s disease (AD) is a progressive neurodegenerative disorder that affects millions of individuals worldwide, causing severe cognitive decline and memory impairment. The early and accurate diagnosis of AD is crucial for effective intervention and disease management. In recent years, deep learning techniques have shown promising results in medical image analysis, including AD diagnosis from neuroimaging data. However, the lack of interpretability in deep learning models hinders their adoption in clinical settings, where explainability is essential for gaining trust and acceptance from healthcare professionals. In this study, we propose an explainable AI (XAI)-based approach for the diagnosis of Alzheimer’s disease, leveraging the power of deep transfer learning and ensemble modeling. The proposed framework aims to enhance the interpretability of deep learning models by incorporating XAI techniques, allowing clinicians to understand the decision-making process and providing valuable insights into disease diagnosis. By leveraging popular pre-trained convolutional neural networks (CNNs) such as VGG16, VGG19, DenseNet169, and DenseNet201, we conducted extensive experiments to evaluate their individual performances on a comprehensive dataset. The proposed ensembles, Ensemble-1 (VGG16 and VGG19) and Ensemble-2 (DenseNet169 and DenseNet201), demonstrated superior accuracy, precision, recall, and F1 scores compared to individual models, reaching up to 95%. In order to enhance interpretability and transparency in Alzheimer’s diagnosis, we introduced a novel model achieving an impressive accuracy of 96%. This model incorporates explainable AI techniques, including saliency maps and grad-CAM (gradient-weighted class activation mapping). The integration of these techniques not only contributes to the model’s exceptional accuracy but also provides clinicians and researchers with visual insights into the neural regions influencing the diagnosis. Our findings showcase the potential of combining deep transfer learning with explainable AI in the realm of Alzheimer’s disease diagnosis, paving the way for more interpretable and clinically relevant AI models in healthcare.","['deep learning', 'explainable AI (XAI)', 'deep transfer learning', 'ensemble modeling', 'pre-trained convolutional neural networks (CNNs)', 'VGG16', 'VGG19', 'DenseNet169', 'DenseNet201', 'saliency maps', 'grad-CAM (gradient-weighted class activation mapping)']","The research idea centers on addressing the challenge of early and accurate diagnosis of Alzheimer’s disease, a progressive neurodegenerative disorder characterized by severe cognitive decline and memory impairment. Despite advances in diagnostic approaches, there remains a critical need for methods that are not only accurate but also interpretable to gain trust and acceptance from healthcare professionals in clinical settings. The study highlights the importance of enhancing the transparency and explainability of diagnostic processes to improve disease management and intervention outcomes. The primary objective of the study is to develop an approach that improves the interpretability of Alzheimer’s disease diagnosis, enabling clinicians to better understand the decision-making process behind diagnostic outcomes. This objective aims to provide valuable insights into the neural regions influencing the diagnosis, thereby facilitating more informed clinical decisions and advancing the relevance of diagnostic tools in healthcare."
Psychology,Larger and more instructable language models become less reliable,"Abstract The prevailing methods to make large language models more powerful and amenable have been based on continuous scaling up (that is, increasing their size, data volume and computational resources 1 ) and bespoke shaping up (including post-filtering 2,3 , fine tuning or use of human feedback 4,5 ). However, larger and more instructable large language models may have become less reliable. By studying the relationship between difficulty concordance, task avoidance and prompting stability of several language model families, here we show that easy instances for human participants are also easy for the models, but scaled-up, shaped-up models do not secure areas of low difficulty in which either the model does not err or human supervision can spot the errors. We also find that early models often avoid user questions but scaled-up, shaped-up models tend to give an apparently sensible yet wrong answer much more often, including errors on difficult questions that human supervisors frequently overlook. Moreover, we observe that stability to different natural phrasings of the same question is improved by scaling-up and shaping-up interventions, but pockets of variability persist across difficulty levels. These findings highlight the need for a fundamental shift in the design and development of general-purpose artificial intelligence, particularly in high-stakes areas for which a predictable distribution of errors is paramount.","['post-filtering', 'fine tuning', 'use of human feedback']","The research idea centers on understanding the reliability and error patterns of increasingly large and refined language models, particularly in relation to how these models handle tasks of varying difficulty compared to human participants. The study addresses concerns that while scaling and shaping these models improve certain aspects, they may also lead to more frequent and less detectable errors, especially on challenging questions. The primary objective of the study is to investigate the relationship between task difficulty, task avoidance, and response stability in different language model families, with a focus on identifying areas where models fail or succeed relative to human supervision. The aim is to highlight the limitations of current approaches and emphasize the need for a fundamental change in designing systems that require predictable and reliable performance, especially in high-stakes contexts."
Psychology,Evaluating the ChatGPT family of models for biomedical reasoning and classification,"Abstract Objective Large language models (LLMs) have shown impressive ability in biomedical question-answering, but have not been adequately investigated for more specific biomedical applications. This study investigates ChatGPT family of models (GPT-3.5, GPT-4) in biomedical tasks beyond question-answering. Materials and Methods We evaluated model performance with 11 122 samples for two fundamental tasks in the biomedical domain—classification (n = 8676) and reasoning (n = 2446). The first task involves classifying health advice in scientific literature, while the second task is detecting causal relations in biomedical literature. We used 20% of the dataset for prompt development, including zero- and few-shot settings with and without chain-of-thought (CoT). We then evaluated the best prompts from each setting on the remaining dataset, comparing them to models using simple features (BoW with logistic regression) and fine-tuned BioBERT models. Results Fine-tuning BioBERT produced the best classification (F1: 0.800-0.902) and reasoning (F1: 0.851) results. Among LLM approaches, few-shot CoT achieved the best classification (F1: 0.671-0.770) and reasoning (F1: 0.682) results, comparable to the BoW model (F1: 0.602-0.753 and 0.675 for classification and reasoning, respectively). It took 78 h to obtain the best LLM results, compared to 0.078 and 0.008 h for the top-performing BioBERT and BoW models, respectively. Discussion The simple BoW model performed similarly to the most complex LLM prompting. Prompt engineering required significant investment. Conclusion Despite the excitement around viral ChatGPT, fine-tuning for two fundamental biomedical natural language processing tasks remained the best strategy.","['ChatGPT family of models (GPT-3.5, GPT-4)', 'zero-shot prompting', 'few-shot prompting', 'chain-of-thought (CoT) prompting', 'Bag of Words (BoW) with logistic regression', 'fine-tuned BioBERT models']","The research idea centers on addressing the need to evaluate the effectiveness of advanced language models in specific biomedical applications beyond general question-answering, particularly focusing on tasks related to understanding and interpreting scientific health advice and causal relationships in biomedical literature. This study is motivated by the gap in knowledge regarding how well these models perform in fundamental biomedical tasks that are crucial for accurate information classification and reasoning within the psychological and health sciences context. The primary objective of the study is to investigate the performance of different approaches in classifying health advice and detecting causal relations in biomedical texts, aiming to determine which method yields the most accurate and reliable results for these essential tasks. The study seeks to compare various strategies to identify the best approach for supporting biomedical understanding and decision-making in psychological research and practice."
Psychology,Machine Learning and Digital Biomarkers Can Detect Early Stages of Neurodegenerative Diseases,"Neurodegenerative diseases (NDs) such as Alzheimer’s Disease (AD) and Parkinson’s Disease (PD) are devastating conditions that can develop without noticeable symptoms, causing irreversible damage to neurons before any signs become clinically evident. NDs are a major cause of disability and mortality worldwide. Currently, there are no cures or treatments to halt their progression. Therefore, the development of early detection methods is urgently needed to delay neuronal loss as soon as possible. Despite advancements in Medtech, the early diagnosis of NDs remains a challenge at the intersection of medical, IT, and regulatory fields. Thus, this review explores “digital biomarkers” (tools designed for remote neurocognitive data collection and AI analysis) as a potential solution. The review summarizes that recent studies combining AI with digital biomarkers suggest the possibility of identifying pre-symptomatic indicators of NDs. For instance, research utilizing convolutional neural networks for eye tracking has achieved significant diagnostic accuracies. ROC-AUC scores reached up to 0.88, indicating high model performance in differentiating between PD patients and healthy controls. Similarly, advancements in facial expression analysis through tools have demonstrated significant potential in detecting emotional changes in ND patients, with some models reaching an accuracy of 0.89 and a precision of 0.85. This review follows a structured approach to article selection, starting with a comprehensive database search and culminating in a rigorous quality assessment and meaning for NDs of the different methods. The process is visualized in 10 tables with 54 parameters describing different approaches and their consequences for understanding various mechanisms in ND changes. However, these methods also face challenges related to data accuracy and privacy concerns. To address these issues, this review proposes strategies that emphasize the need for rigorous validation and rapid integration into clinical practice. Such integration could transform ND diagnostics, making early detection tools more cost-effective and globally accessible. In conclusion, this review underscores the urgent need to incorporate validated digital health tools into mainstream medical practice. This integration could indicate a new era in the early diagnosis of neurodegenerative diseases, potentially altering the trajectory of these conditions for millions worldwide. Thus, by highlighting specific and statistically significant findings, this review demonstrates the current progress in this field and the potential impact of these advancements on the global management of NDs.",['convolutional neural networks'],"The research idea centers on the urgent need for early detection methods for neurodegenerative diseases such as Alzheimer’s Disease and Parkinson’s Disease, which often develop without noticeable symptoms and cause irreversible neuronal damage before clinical signs appear. These diseases are a major cause of disability and mortality worldwide, and currently, there are no cures or treatments to halt their progression. Early diagnosis is crucial to delay neuronal loss and improve patient outcomes, yet it remains a significant challenge in the medical field. The study addresses the potential of emerging approaches to identify pre-symptomatic indicators and improve understanding of disease mechanisms.

The research objective of this review is to explore and summarize recent advancements in tools designed for remote neurocognitive data collection and their potential to facilitate early diagnosis of neurodegenerative diseases. It aims to evaluate the effectiveness and challenges of these approaches, highlight statistically significant findings, and propose strategies for rigorous validation and integration into clinical practice. Ultimately, the study seeks to demonstrate how these advancements could transform diagnostics, making early detection more accessible and cost-effective, thereby potentially altering the trajectory of neurodegenerative diseases on a global scale."
Psychology,Reliability of ChatGPT for performing triage task in the emergency department using the Korean Triage and Acuity Scale,"Background Artificial intelligence (AI) technology can enable more efficient decision-making in healthcare settings. There is a growing interest in improving the speed and accuracy of AI systems in providing responses for given tasks in healthcare settings. Objective This study aimed to assess the reliability of ChatGPT in determining emergency department (ED) triage accuracy using the Korean Triage and Acuity Scale (KTAS). Methods Two hundred and two virtual patient cases were built. The gold standard triage classification for each case was established by an experienced ED physician. Three other human raters (ED paramedics) were involved and rated the virtual cases individually. The virtual cases were also rated by two different versions of the chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0). Inter-rater reliability was examined using Fleiss’ kappa and intra-class correlation coefficient (ICC). Results The kappa values for the agreement between the four human raters and ChatGPTs were .523 (version 4.0) and .320 (version 3.5). Of the five levels, the performance was poor when rating patients at levels 1 and 5, as well as case scenarios with additional text descriptions. There were differences in the accuracy of the different versions of GPTs. The ICC between version 3.5 and the gold standard was .520, and that between version 4.0 and the gold standard was .802. Conclusions A substantial level of inter-rater reliability was revealed when GPTs were used as KTAS raters. The current study showed the potential of using GPT in emergency healthcare settings. Considering the shortage of experienced manpower, this AI method may help improve triaging accuracy.","['chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0)']","The research idea centers on addressing the challenge of accurately and efficiently determining triage levels in emergency department settings, which is critical for patient care prioritization. There is a recognized need to improve the speed and accuracy of triage decisions to enhance healthcare outcomes, especially given the shortage of experienced personnel in emergency departments. The study’s primary objective is to assess the reliability of a specific approach in determining emergency department triage accuracy using the Korean Triage and Acuity Scale (KTAS). It aims to evaluate how well this approach agrees with expert human raters in classifying patient cases according to established triage levels."
Psychology,Deep Reinforcement Learning Unleashing the Power of AI in Decision-Making,"Deep Reinforcement Learning (DRL) has emerged as a transformative paradigm in the field of artificial intelligence (AI), offering unprecedented capabilities in decision-making across diverse domains. This article explores the profound impact of DRL on enhancing the decision-making capabilities of AI systems, elucidating its underlying principles, applications, and implications.DRL represents a fusion of deep learning and reinforcement learning, enabling machines to learn complex behaviors and make decisions by interacting with their environment. The utilization of neural networks allows DRL algorithms to handle high-dimensional input spaces, making it well-suited for tasks that involve intricate decision-making processes.One of the key strengths of DRL lies in its ability to address problems with sparse and delayed rewards, common challenges in traditional reinforcement learning. Through a process of trial and error, DRL algorithms can learn optimal decision strategies by navigating through a vast decision space, adapting to dynamic environments, and maximizing cumulative rewards over time.The applications of DRL span various domains, including robotics, finance, healthcare, gaming, and autonomous systems. In robotics, DRL facilitates the development of intelligent agents capable of autonomously navigating complex environments, performing intricate tasks, and adapting to unforeseen circumstances. In finance, DRL is leveraged for portfolio optimization, algorithmic trading, and risk management, demonstrating its potential to revolutionize traditional financial strategies.","['Deep Reinforcement Learning (DRL)', 'deep learning', 'reinforcement learning']","The research idea centers on the challenge of enhancing decision-making capabilities in complex and dynamic environments, particularly where outcomes are influenced by sparse and delayed feedback. The study addresses the need for approaches that enable adaptive behavior and optimal strategy development through interaction with the environment. The primary objective of the study is to explore how decision-making processes can be improved by learning from experience in situations involving intricate and high-dimensional inputs. It aims to understand mechanisms that support the development of intelligent agents capable of navigating complex tasks and adapting to changing circumstances over time."
Psychology,3WC-GBNRS++: A novel three-way classifier with granular-ball neighborhood rough sets based on uncertainty,"Three-way decision with neighborhood rough sets (3WDNRS) is adept at addressing uncertain problems involving continuous data by configuring the neighborhood radius. However, on one hand, the inputs of 3WDNRS are individual neighborhood granules, which reduce the decision efficiency and generality; on other hand, the thresholds of 3WDNRS require prior knowledge to be approximately set in advance, making it difficult to apply in cases where such knowledge is unavailable. To address these issues, we introduce granular-ball computing (GBC) into 3WDNRS from the perspective of uncertainty. Firstly, we propose an enhanced granular-ball generation method based on DBSCAN called DBGBC. Subsequently, we present an improved granular-ball neighborhood rough sets model (GBNRS++) by combining DBGBC with a quality index. Furthermore, we construct a three-way classifier with granular-ball neighborhood rough sets (3WC-GBNRS++) based on the principle of minimum fuzziness loss. This approach provides an objective and efficient way to determine the thresholds. To further enhance classification accuracy, we design an adaptive granular-ball neighborhood within the subsequent classification process of 3WC-GBNRS++. Finally, experimental results demonstrate that, 3WC-GBNRS++ almost outperformed other comparison methods in terms of effectiveness and robustness, including 4 state-of-the-art granular-balls-based classifiers and 5 classical machine learning classifiers on 12 public benchmark datasets. Moreover, we discuss the limitations of our work and the outlook for future research.","['three-way decision with neighborhood rough sets (3WDNRS)', 'DBSCAN']","The study addresses the challenge of making accurate and efficient decisions in situations involving uncertainty and continuous data, particularly when prior knowledge required for setting decision thresholds is unavailable. It highlights the limitations of existing approaches that rely on individual neighborhood granules, which reduce decision efficiency and generality. The primary aim of the study is to develop a more objective and efficient method for determining decision thresholds in uncertain environments, thereby improving classification accuracy and robustness. This is achieved by introducing a novel approach that enhances the handling of uncertainty and adapts neighborhood structures to better support decision-making processes."
Psychology,MentaLLaMA: Interpretable Mental Health Analysis on Social Media with Large Language Models,"As an integral part of people's daily lives, social media is becoming a rich source for automatic mental health analysis.As traditional discriminative methods bear poor generalization ability and low interpretability, the recent large language models (LLMs) have been explored for interpretable mental health analysis on social media, which aims to provide detailed explanations along with predictions in zero-shot or few-shot settings.The results show that LLMs still achieve unsatisfactory classification performance in a zero-shot/few-shot manner, which further significantly affects the quality of the generated explanations.Domain-specific finetuning is an effective solution, but faces two critical challenges: 1) lack of high-quality training data.2) no open-source foundation LLMs.To alleviate these problems, we formally model interpretable mental health analysis as a text generation task, and build the first multi-task and multi-source interpretable mental health instruction (IMHI) dataset with 105K data samples to support LLM instruction tuning and evaluation.The raw social media data are collected from 10 existing sources covering 8 mental health analysis tasks.We prompt ChatGPT with expert-designed few-shot prompts to obtain explanations.To ensure the reliability of the explanations, we perform strict automatic and human evaluations on the correctness, consistency, and quality of generated data.Based on the IMHI dataset and LLaMA2 foundation models, we train MentaLLaMA, the first open-source instruction-following LLM series for interpretable mental health analysis on social media.We evaluate Men-taLLaMA and other advanced methods on the IMHI benchmark, the first holistic evaluation benchmark for interpretable mental health analysis.The results show that MentaLLaMA approaches state-of-the-art discriminative methods in correctness and generates human-level explanations.MentaLLaMA models also show strong generalizability to unseen tasks.The project is available at https://github.com/SteveKGYang/MentaLLaMA.","['zero-shot learning', 'few-shot learning', 'domain-specific finetuning', 'instruction tuning']","The research idea centers on the increasing importance of social media as a source for understanding mental health, highlighting the challenges in achieving accurate and interpretable mental health analysis from social media content. Traditional methods have limitations in generalization and interpretability, which affects the quality of mental health assessments and explanations derived from social media data. The study addresses the need for more reliable and interpretable approaches to analyze mental health indicators in social media posts.

The primary objective of the study is to develop a comprehensive and interpretable framework for mental health analysis on social media by creating a large, multi-task, and multi-source dataset that supports detailed explanations alongside mental health predictions. The study aims to improve the reliability and quality of mental health assessments by providing human-level explanations and ensuring strong generalizability across different mental health tasks."
Psychology,Automated Classification of Cognitive Visual Objects Using Multivariate Swarm Sparse Decomposition From Multichannel EEG-MEG Signals,"In visual object decoding, magnetoencephalogram (MEG) and electroencephalogram (EEG) activation patterns demonstrate the utmost discriminative cognitive analysis due to their multivariate oscillatory nature. However, high noise in the recorded EEG-MEG signals and subject-specific variability make it extremely difficult to classify subject's cognitive responses to different visual stimuli. The proposed method is a multivariate extension of the swarm sparse decomposition method (MSSDM) for multivariate pattern analysis of EEG-MEG-based visual activation signals. In comparison, it is an advanced technique for decomposing nonstationary multicomponent signals into a finite number of channel-aligned oscillatory components that significantly enhance visual activation-related sub-bands. The MSSDM method adopts multivariate swarm filtering and sparse spectrum to automatically deliver optimal frequency bands in channel-specific sparse spectrums, resulting in improved filter banks. By combining the advantages of the multivariate SSDM and Riemann's correlation-assisted fusion feature (RCFF), the MSSDM-RCFF algorithm is investigated to improve the visual object recognition ability of EEG-MEG signals. We have also proposed time–frequency representation based on MSSDM to analyze discriminative cognitive patterns of different visual object classes from multichannel EEG-MEG signals. A proposed MSSDM is evaluated on multivariate synthetic signals and multivariate EEG-MEG signals using five classifiers. The proposed fusion feature and linear discriminant analysis classifier-based framework outperformed all existing state-of-the-art methods used for visual object detection and achieved the highest accuracy of 86.42% using tenfold cross-validation on EEG-MEG multichannel signals.","['sparse spectrum', 'linear discriminant analysis classifier']","The research idea centers on the challenge of accurately classifying cognitive responses to different visual stimuli using brain activation patterns recorded through EEG and MEG, which are often hindered by high noise levels and individual variability. This difficulty limits the understanding of how the brain processes and discriminates between various visual objects. The study’s primary objective is to enhance the ability to decode and recognize visual object-related cognitive patterns from EEG-MEG signals by improving the identification of discriminative neural activation associated with different visual stimuli. The aim is to achieve more precise classification of cognitive responses to visual objects despite the complexities introduced by signal noise and subject-specific differences."
Psychology,CLARUS: An interactive explainable AI platform for manual counterfactuals in graph neural networks,"Lack of trust in artificial intelligence (AI) models in medicine is still the key blockage for the use of AI in clinical decision support systems (CDSS). Although AI models are already performing excellently in systems medicine, their black-box nature entails that patient-specific decisions are incomprehensible for the physician. Explainable AI (XAI) algorithms aim to ""explain"" to a human domain expert, which input features influenced a specific recommendation. However, in the clinical domain, these explanations must lead to some degree of causal understanding by a clinician. We developed the CLARUS platform, aiming to promote human understanding of graph neural network (GNN) predictions. CLARUS enables the visualisation of patient-specific networks, as well as, relevance values for genes and interactions, computed by XAI methods, such as GNNExplainer. This enables domain experts to gain deeper insights into the network and more importantly, the expert can interactively alter the patient-specific network based on the acquired understanding and initiate re-prediction or retraining. This interactivity allows us to ask manual counterfactual questions and analyse the effects on the GNN prediction. We present the first interactive XAI platform prototype, CLARUS, that allows not only the evaluation of specific human counterfactual questions based on user-defined alterations of patient networks and a re-prediction of the clinical outcome but also a retraining of the entire GNN after changing the underlying graph structures. The platform is currently hosted by the GWDG on https://rshiny.gwdg.de/apps/clarus/.","['graph neural network (GNN)', 'GNNExplainer']","The research idea addresses the challenge of lack of trust in clinical decision support systems due to the incomprehensibility of patient-specific decisions made by complex models in medicine. Although these models perform well, their opaque nature prevents physicians from understanding the rationale behind recommendations, which is crucial for clinical acceptance. The study emphasizes the need for explanations that lead to a causal understanding by clinicians to improve trust and usability in medical decision-making.

The primary objective of the study is to develop a platform that promotes human understanding of patient-specific predictions by enabling visualization and interactive exploration of relevant features influencing clinical outcomes. This platform aims to allow domain experts to gain deeper insights, modify patient-specific information based on their understanding, and observe the effects of these changes on clinical predictions. Ultimately, the goal is to facilitate a more transparent and interpretable decision-making process for clinicians."
Psychology,Multimodal data integration for oncology in the era of deep neural networks: a review,"Cancer research encompasses data across various scales, modalities, and resolutions, from screening and diagnostic imaging to digitized histopathology slides to various types of molecular data and clinical records. The integration of these diverse data types for personalized cancer care and predictive modeling holds the promise of enhancing the accuracy and reliability of cancer screening, diagnosis, and treatment. Traditional analytical methods, which often focus on isolated or unimodal information, fall short of capturing the complex and heterogeneous nature of cancer data. The advent of deep neural networks has spurred the development of sophisticated multimodal data fusion techniques capable of extracting and synthesizing information from disparate sources. Among these, Graph Neural Networks (GNNs) and Transformers have emerged as powerful tools for multimodal learning, demonstrating significant success. This review presents the foundational principles of multimodal learning including oncology data modalities, taxonomy of multimodal learning, and fusion strategies. We delve into the recent advancements in GNNs and Transformers for the fusion of multimodal data in oncology, spotlighting key studies and their pivotal findings. We discuss the unique challenges of multimodal learning, such as data heterogeneity and integration complexities, alongside the opportunities it presents for a more nuanced and comprehensive understanding of cancer. Finally, we present some of the latest comprehensive multimodal pan-cancer data sources. By surveying the landscape of multimodal data integration in oncology, our goal is to underline the transformative potential of multimodal GNNs and Transformers. Through technological advancements and the methodological innovations presented in this review, we aim to chart a course for future research in this promising field. This review may be the first that highlights the current state of multimodal modeling applications in cancer using GNNs and transformers, presents comprehensive multimodal oncology data sources, and sets the stage for multimodal evolution, encouraging further exploration and development in personalized cancer care.","['deep neural networks', 'Graph Neural Networks (GNNs)', 'Transformers']","The research idea centers on addressing the complexity and heterogeneity of cancer by integrating diverse types of data from various scales and modalities to improve personalized cancer care. Traditional approaches that focus on isolated information are insufficient for capturing the multifaceted nature of cancer, highlighting the need for more comprehensive methods to enhance the accuracy and reliability of cancer screening, diagnosis, and treatment. The study is motivated by the potential to achieve a more nuanced and thorough understanding of cancer through the fusion of multimodal data. The primary objective of the study is to review and present the foundational principles and recent advancements in the integration of diverse oncology data types, emphasizing the challenges and opportunities in multimodal data fusion. It aims to highlight key findings from recent research, provide an overview of comprehensive multimodal cancer data sources, and set a direction for future research to advance personalized cancer care."
Psychology,Role of machine learning and deep learning techniques in EEG-based BCI emotion recognition system: a review,"Abstract Emotion is a subjective psychophysiological reaction coming from external stimuli which impacts every aspect of our daily lives. Due to the continuing development of non-invasive and portable sensor technologies, such as brain-computer interfaces (BCI), intellectuals from several fields have been interested in emotion recognition techniques. Human emotions can be recognised using a variety of behavioural cues, including gestures and body language, voice, and physiological markers. The first three, however, might be ineffective because people sometimes conceal their genuine emotions either intentionally or unknowingly. More precise and objective emotion recognition can be accomplished using physiological signals. Among other physiological signals, Electroencephalogram (EEG) is more responsive and sensitive to variation in affective states. Various EEG-based emotion recognition methods have recently been introduced. This study reviews EEG-based BCIs for emotion identification and gives an outline of the progress made in this field. A summary of the datasets and techniques utilised to evoke human emotions and various emotion models is also given. We discuss several EEG feature extractions, feature selection/reduction, machine learning, and deep learning algorithms in accordance with standard emotional identification process. We provide an overview of the human brain's EEG rhythms, which are closely related to emotional states. We also go over a number of EEG-based emotion identification research and compare numerous machine learning and deep learning techniques. In conclusion, this study highlights the applications, challenges and potential areas for future research in identification and classification of human emotional states.",['feature selection/reduction'],"The research idea centers on the importance of accurately recognizing human emotions, which are subjective psychophysiological reactions influenced by external stimuli and affect many aspects of daily life. Traditional behavioral cues such as gestures, body language, and voice may be unreliable because individuals can consciously or unconsciously conceal their true emotions. Therefore, there is a need for more precise and objective methods of emotion recognition using physiological signals, with a particular focus on brain activity that is sensitive to changes in affective states. The study addresses the progress and challenges in identifying human emotions through these physiological markers.

The primary objective of the study is to review the current advancements in emotion identification using physiological signals, specifically focusing on brain activity related to emotional states. It aims to summarize the various approaches used to evoke and model human emotions and to provide an overview of research efforts in this area. Additionally, the study seeks to highlight the applications, challenges, and potential directions for future research in the identification and classification of human emotional states."
Psychology,Crafting personalized learning paths with AI for lifelong learning: a systematic literature review,"The rapid evolution of knowledge requires constantly acquiring and updating skills, making lifelong learning crucial. Despite decades of artificial intelligence, recent advances promote new solutions to personalize learning in this context. The purpose of this article is to explore the current state of research on the development of artificial intelligence-mediated solutions for the design of personalized learning paths. To achieve this, a systematic literature review (SRL) of 78 articles published between 2019 and 2024 from the Scopus and Web or Science databases was conducted, answering seven questions grouped into three themes: characteristics of the published research, context of the research, and type of solution analyzed. This study identified that: (a) the greatest production of scientific research on the topic is developed in China, India and the United States, (b) the focus is mainly directed towards the educational context at the higher education level with areas of opportunity for application in the work context, and (c) the development of adaptive learning technologies predominates; however, there is a growing interest in the application of generative language models. This article contributes to the growing interest and literature related to personalized learning under artificial intelligence mediated solutions that will serve as a basis for academic institutions and organizations to design programs under this model.",['generative language models'],"The research idea centers on the importance of lifelong learning due to the rapid evolution of knowledge, highlighting the need for personalized learning approaches to effectively acquire and update skills. The study addresses the growing interest in developing solutions that tailor learning paths to individual needs, particularly within educational and work contexts. The research objective is to explore the current state of research on the development of personalized learning paths, focusing on understanding the characteristics, contexts, and types of solutions proposed in recent studies. This exploration aims to provide a comprehensive overview that can inform academic institutions and organizations in designing personalized learning programs."
Psychology,Unlocking the Potential of XAI for Improved Alzheimer’s Disease Detection and Classification Using a ViT-GRU Model,"Alzheimer's Disease (AD) is a significant cause of dementia worldwide, and its progression from mild to severe affects an individual's ability to perform daily activities independently. The accurate and early diagnosis of AD is crucial for effective clinical intervention. However, interpreting AD from medical images can be challenging, even for experienced radiologists. Therefore, there is a need for an automatic diagnosis of AD, and researchers have investigated the potential of utilizing Artificial Intelligence (AI) techniques, particularly deep learning models, to address this challenge. This study proposes a framework that combines a Vision Transformer (ViT) and a Gated Recurrent Unit (GRU) to detect AD characteristics from Magnetic Resonance Imaging (MRI) images accurately and reliably. The ViT identifies crucial features from the input image, and the GRU establishes clear correlations between these features. The proposed model overcomes the class imbalance issue in the MRI image dataset and achieves superior accuracy and performance compared to existing methods. The model was trained on the Alzheimer's MRI Preprocessed Dataset obtained from Kaggle, achieving notable accuracies of 99.53% for 4-class and 99.69% for binary classification. It also demonstrated a high accuracy of 99.26% for 3-class on the AD Neuroimaging Initiative (ADNI) Baseline Database. These results were validated through a thorough 10-fold cross-validation process. Furthermore, Explainable AI (XAI) techniques were incorporated to make the model interpretable and explainable. This allows clinicians to understand the model's decision-making process and gain insights into the underlying factors driving the AD diagnosis.","['Vision Transformer (ViT)', 'Gated Recurrent Unit (GRU)']","The research idea centers on the significant impact of Alzheimer's Disease (AD) as a leading cause of dementia worldwide and the challenges associated with its progression from mild to severe stages, which impair an individual's ability to perform daily activities independently. Early and accurate diagnosis of AD is essential for effective clinical intervention, yet interpreting the disease from medical images remains difficult even for experienced radiologists. The study addresses the need for improved diagnostic approaches to facilitate timely and reliable identification of AD characteristics. The primary objective of the study is to develop a method that can accurately detect features indicative of Alzheimer's Disease from medical imaging, thereby enhancing the reliability and accuracy of diagnosis. This aims to support clinicians in making informed decisions by providing clearer insights into the disease’s progression and characteristics."
Psychology,A fast and robust method for detecting trend turning points in InSAR displacement time series,"Ground deformation monitoring is a crucial task in geohazard management to ensure the safety of lives and infrastructure. Persistent scatterer interferometric synthetic aperture radar (PS-InSAR) is an advanced technique for measuring small displacements on the Earth's surface. Estimated PS-InSAR time series acquired by Sentinel-1 satellites provide a great opportunity for effective monitoring of ground deformation in recent years. However, challenges arise when processing these time series due to their non-uniform sampling, noise from atmosphere and preprocessing issues including phase unwrapping and others. Therefore, estimating the location and direction of trend turning in such time series, as an indicator of ground deformation, is not an easy task. In this work, a sequential turning point detection method (STPD) is proposed and compared with other change point detection methods. Using a large set of simulated time series with various noise types, it is shown that STPD outperforms other methods in terms of overall accuracy and root mean square error for location and direction of trend turnings. As a case study, STPD is applied to detect turning points within PS-InSAR time series for the province of Frosinone in Italy and classified using topography and land cover/use. In addition, an area susceptible to landslides is selected to estimate the starting dates of potential slow-moving landslides. It is also shown that the turning points in the local precipitation time series have a high correlation with the ones in the PS-InSAR time series, indicating that precipitation is a major triggering factor of the displacements in the area. The STPD can rapidly and effectively detect locations and directions of trend turnings and is freely available online in both MATLAB and python.",['change point detection methods'],"The research idea centers on the importance of monitoring ground deformation to manage geohazards and protect lives and infrastructure. The study addresses the challenges involved in accurately identifying changes in ground movement trends due to irregular data sampling and environmental noise. The primary objective of the study is to develop and evaluate a method for detecting turning points in ground deformation time series, which serve as indicators of changes in displacement trends. Additionally, the study aims to apply this method to real-world data to identify potential landslide activity and explore the relationship between precipitation and ground displacement in a specific region."
Psychology,Machine Learning–Based Prediction of Suicidality in Adolescents With Allergic Rhinitis: Derivation and Validation in 2 Independent Nationwide Cohorts,"Background Given the additional risk of suicide-related behaviors in adolescents with allergic rhinitis (AR), it is important to use the growing field of machine learning (ML) to evaluate this risk. Objective This study aims to evaluate the validity and usefulness of an ML model for predicting suicide risk in patients with AR. Methods We used data from 2 independent survey studies, Korea Youth Risk Behavior Web-based Survey (KYRBS; n=299,468) for the original data set and Korea National Health and Nutrition Examination Survey (KNHANES; n=833) for the external validation data set, to predict suicide risks of AR in adolescents aged 13 to 18 years, with 3.45% (10,341/299,468) and 1.4% (12/833) of the patients attempting suicide in the KYRBS and KNHANES studies, respectively. The outcome of interest was the suicide attempt risks. We selected various ML-based models with hyperparameter tuning in the discovery and performed an area under the receiver operating characteristic curve (AUROC) analysis in the train, test, and external validation data. Results The study data set included 299,468 (KYRBS; original data set) and 833 (KNHANES; external validation data set) patients with AR recruited between 2005 and 2022. The best-performing ML model was the random forest model with a mean AUROC of 84.12% (95% CI 83.98%-84.27%) in the original data set. Applying this result to the external validation data set revealed the best performance among the models, with an AUROC of 89.87% (sensitivity 83.33%, specificity 82.58%, accuracy 82.59%, and balanced accuracy 82.96%). While looking at feature importance, the 5 most important features in predicting suicide attempts in adolescent patients with AR are depression, stress status, academic achievement, age, and alcohol consumption. Conclusions This study emphasizes the potential of ML models in predicting suicide risks in patients with AR, encouraging further application of these models in other conditions to enhance adolescent health and decrease suicide rates.",['random forest'],"The research addresses the increased risk of suicide-related behaviors among adolescents with allergic rhinitis (AR), highlighting the importance of evaluating this risk to improve adolescent health outcomes. Given the serious implications of suicide attempts in this population, understanding the factors that contribute to suicide risk is crucial for prevention efforts. The primary objective of the study is to assess the validity and usefulness of approaches for predicting suicide risk in adolescents with AR. Specifically, the study aims to identify key factors associated with suicide attempts in this group to better inform strategies that could reduce suicide rates among affected adolescents."
Psychology,Finding the Right XAI Method—A Guide for the Evaluation and Ranking of Explainable AI Methods in Climate Science,"Abstract Explainable artificial intelligence (XAI) methods shed light on the predictions of machine learning algorithms. Several different approaches exist and have already been applied in climate science. However, usually missing ground truth explanations complicate their evaluation and comparison, subsequently impeding the choice of the XAI method. Therefore, in this work, we introduce XAI evaluation in the climate context and discuss different desired explanation properties, namely, robustness, faithfulness, randomization, complexity, and localization. To this end, we chose previous work as a case study where the decade of annual-mean temperature maps is predicted. After training both a multilayer perceptron (MLP) and a convolutional neural network (CNN), multiple XAI methods are applied and their skill scores in reference to a random uniform explanation are calculated for each property. Independent of the network, we find that XAI methods such as Integrated Gradients, layerwise relevance propagation, and input times gradients exhibit considerable robustness, faithfulness, and complexity while sacrificing randomization performance. Sensitivity methods, gradient, SmoothGrad, NoiseGrad, and FusionGrad, match the robustness skill but sacrifice faithfulness and complexity for the randomization skill. We find architecture-dependent performance differences regarding robustness, complexity, and localization skills of different XAI methods, highlighting the necessity for research task-specific evaluation. Overall, our work offers an overview of different evaluation properties in the climate science context and shows how to compare and benchmark different explanation methods, assessing their suitability based on strengths and weaknesses, for the specific research problem at hand. By that, we aim to support climate researchers in the selection of a suitable XAI method. Significance Statement Explainable artificial intelligence (XAI) helps to understand the reasoning behind the prediction of a neural network. XAI methods have been applied in climate science to validate networks and provide new insight into physical processes. However, the increasing number of XAI methods can overwhelm practitioners, making it difficult to choose an explanation method. Since XAI methods’ results can vary, uninformed choices might cause misleading conclusions about the network decision. In this work, we introduce XAI evaluation to compare and assess the performance of explanation methods based on five desirable properties. We demonstrate that XAI evaluation reveals the strengths and weaknesses of different XAI methods. Thus, our work provides climate researchers with the tools to compare, analyze, and subsequently choose explanation methods.","['multilayer perceptron (MLP)', 'convolutional neural network (CNN)', 'Integrated Gradients', 'layerwise relevance propagation', 'SmoothGrad']","The research idea centers on the challenge of evaluating and comparing different explanation methods used to interpret complex predictive models in climate science, where the absence of definitive ground truth explanations complicates this process. This difficulty hinders researchers’ ability to select the most appropriate explanation approach, potentially leading to misleading interpretations of model decisions. The study aims to address this gap by introducing a framework for evaluating explanation methods based on key desirable properties such as robustness, faithfulness, and complexity. The primary objective of the study is to provide climate researchers with a systematic way to compare and assess the performance of various explanation methods, thereby supporting informed selection tailored to specific research problems and enhancing the understanding of model predictions in the climate context."
Psychology,An Empirical Study on Correlations Between Deep Neural Network Fairness and Neuron Coverage Criteria,"Recently, with the widespread use of deep neural networks (DNNs) in high-stakes decision-making systems (such as fraud detection and prison sentencing), concerns have arisen about the fairness of DNNs in terms of the potential negative impact they may have on individuals and society. Therefore, fairness testing has become an important research topic in DNN testing. At the same time, the neural network coverage criteria (such as criteria based on neuronal activation) is considered as an adequacy test for DNN white-box testing. It is implicitly assumed that improving the coverage can enhance the quality of test suites. Nevertheless, the correlation between DNN fairness (a test property) and coverage criteria (a test method) has not been adequately explored. To address this issue, we conducted a systematic empirical study on seven coverage criteria, six fairness metrics, three fairness testing techniques, and five bias mitigation methods on five DNN models and nine fairness datasets to assess the correlation between coverage criteria and DNN fairness. Our study achieved the following findings: 1) with the increase in the size of the test suite, some of the coverage and fairness metrics changed significantly, as the size of the test suite increased; 2) the statistical correlation between coverage criteria and DNN fairness is limited; and 3) after bias mitigation for improving the fairness of DNN, the change pattern in coverage criteria is different; 4) Models debiased by different bias mitigation methods have a lower correlation between coverage and fairness compared to the original models. Our findings cast doubt on the validity of coverage criteria concerning DNN fairness (i.e., increasing the coverage may even have a negative impact on the fairness of DNNs). Therefore, we warn DNN testers against blindly pursuing higher coverage of coverage criteria at the cost of test properties of DNNs (such as fairness).","['deep neural networks (DNNs)', 'bias mitigation methods']","The research idea centers on concerns about fairness in decision-making systems that impact individuals and society, highlighting the importance of fairness testing to address potential negative consequences. There is a need to understand how measures used to evaluate the thoroughness of testing relate to fairness outcomes, as this relationship has not been sufficiently explored. The study aims to investigate the connection between testing adequacy and fairness in these systems. The primary objective of the study is to assess the correlation between testing coverage criteria and fairness metrics, examining how changes in testing practices influence fairness outcomes. Additionally, the study seeks to evaluate the effects of bias mitigation methods on this relationship to provide insights into whether increasing testing coverage improves or undermines fairness."
Psychology,Generative Large Language Models for Detection of Speech Recognition Errors in Radiology Reports,"This study evaluated the ability of generative large language models (LLMs) to detect speech recognition errors in radiology reports. A dataset of 3233 CT and MRI reports was assessed by radiologists for speech recognition errors. Errors were categorized as clinically significant or not clinically significant. Performances of five generative LLMs—GPT-3.5-turbo, GPT-4, text-davinci-003, Llama-v2–70B-chat, and Bard—were compared in detecting these errors, using manual error detection as the reference standard. Prompt engineering was used to optimize model performance. GPT-4 demonstrated high accuracy in detecting clinically significant errors (precision, 76.9%; recall, 100%; F1 score, 86.9%) and not clinically significant errors (precision, 93.9%; recall, 94.7%; F1 score, 94.3%). Text-davinci-003 achieved F1 scores of 72% and 46.6% for clinically significant and not clinically significant errors, respectively. GPT-3.5-turbo obtained 59.1% and 32.2% F1 scores, while Llama-v2–70B-chat scored 72.8% and 47.7%. Bard showed the lowest accuracy, with F1 scores of 47.5% and 20.9%. GPT-4 effectively identified challenging errors of nonsense phrases and internally inconsistent statements. Longer reports, resident dictation, and overnight shifts were associated with higher error rates. In conclusion, advanced generative LLMs show potential for automatic detection of speech recognition errors in radiology reports. Keywords: CT, Large Language Model, Machine Learning, MRI, Natural Language Processing, Radiology Reports, Speech, Unsupervised Learning Supplemental material is available for this article. © RSNA, 2024","['generative large language models (LLMs)', 'GPT-3.5-turbo', 'GPT-4', 'text-davinci-003', 'Llama-v2–70B-chat']","The research idea centers on addressing the challenge of identifying speech recognition errors in radiology reports, which can impact the accuracy and reliability of medical documentation. Detecting these errors, especially those that are clinically significant, is crucial for ensuring patient safety and effective clinical communication. The study recognizes that speech recognition errors vary in severity and occur more frequently under certain conditions, such as longer reports, resident dictation, and overnight shifts. The research objective is to evaluate the effectiveness of different approaches in detecting speech recognition errors in CT and MRI radiology reports, with a focus on distinguishing between clinically significant and not clinically significant errors. The study aims to compare the accuracy of various methods against manual error detection performed by radiologists, ultimately assessing the potential for improving error identification in medical reporting."
Psychology,Predictors for estimating subcortical EEG responses to continuous speech,"Perception of sounds and speech involves structures in the auditory brainstem that rapidly process ongoing auditory stimuli. The role of these structures in speech processing can be investigated by measuring their electrical activity using scalp-mounted electrodes. However, typical analysis methods involve averaging neural responses to many short repetitive stimuli that bear little relevance to daily listening environments. Recently, subcortical responses to more ecologically relevant continuous speech were detected using linear encoding models. These methods estimate the temporal response function (TRF), which is a regression model that minimises the error between the measured neural signal and a predictor derived from the stimulus. Using predictors that model the highly non-linear peripheral auditory system may improve linear TRF estimation accuracy and peak detection. Here, we compare predictors from both simple and complex peripheral auditory models for estimating brainstem TRFs on electroencephalography (EEG) data from 24 participants listening to continuous speech. We also investigate the data length required for estimating subcortical TRFs, and find that around 12 minutes of data is sufficient for clear wave V peaks (&gt;3 dB SNR) to be seen in nearly all participants. Interestingly, predictors derived from simple filterbank-based models of the peripheral auditory system yield TRF wave V peak SNRs that are not significantly different from those estimated using a complex model of the auditory nerve, provided that the nonlinear effects of adaptation in the auditory system are appropriately modelled. Crucially, computing predictors from these simpler models is more than 50 times faster compared to the complex model. This work paves the way for efficient modelling and detection of subcortical processing of continuous speech, which may lead to improved diagnosis metrics for hearing impairment and assistive hearing technology.","['linear encoding models', 'temporal response function (TRF)', 'regression model']","The research idea centers on understanding how structures in the auditory brainstem rapidly process ongoing auditory stimuli, particularly speech, and the challenge of studying these processes using typical methods that rely on repetitive stimuli not representative of everyday listening environments. There is a need to investigate subcortical responses to more ecologically relevant continuous speech to better reflect natural auditory processing. The primary objective of the study is to compare different predictors derived from simple and complex models of the peripheral auditory system for estimating brainstem responses to continuous speech, and to determine the amount of data required to reliably detect these responses. The study aims to identify efficient approaches for modeling and detecting subcortical processing of continuous speech, which could enhance diagnostic measures for hearing impairment and improve assistive hearing technologies."
Psychology,"A Survey of Imitation Learning: Algorithms, Recent Developments, and Challenges","In recent years, the development of robotics and artificial intelligence (AI) systems has been nothing short of remarkable. As these systems continue to evolve, they are being utilized in increasingly complex and unstructured environments, such as autonomous driving, aerial robotics, and natural language processing. As a consequence, programming their behaviors manually or defining their behavior through the reward functions as done in reinforcement learning (RL) has become exceedingly difficult. This is because such environments require a high degree of flexibility and adaptability, making it challenging to specify an optimal set of rules or reward signals that can account for all the possible situations. In such environments, learning from an expert's behavior through imitation is often more appealing. This is where imitation learning (IL) comes into play -a process where desired behavior is learned by imitating an expert's behavior, which is provided through demonstrations.This article aims to provide an introduction to IL and an overview of its underlying assumptions and approaches. It also offers a detailed description of recent advances and emerging areas of research in the field. Additionally, this article discusses how researchers have addressed common challenges associated with IL and provides potential directions for future research. Overall, the goal of this article is to provide a comprehensive guide to the growing field of IL in robotics and AI.","['reinforcement learning (RL)', 'imitation learning (IL)']","The research idea centers on the challenge of enabling flexible and adaptable behavior in complex and unstructured environments, where manually programming or defining optimal rules for behavior is difficult. The study addresses the problem of how to effectively learn desired behaviors by observing and imitating expert behavior, which is considered a more appealing approach in such settings. The primary objective of the study is to provide an introduction and comprehensive overview of the process of learning behavior through imitation, including its underlying assumptions, recent advances, and emerging areas of research. Additionally, the study aims to discuss common challenges encountered in this approach and suggest potential directions for future research."
Psychology,Exploring the role of skin temperature in thermal sensation and thermal comfort: A comprehensive review,"The role of skin temperature as a determinant of human thermal sensation and comfort has gained increasing recognition, prompting a need for a systematic review. This review examines the relationship between skin temperature and thermal sensation, synthesizing insights from 172 studies published since 2000. It uniquely focuses on the indispensable roles of local and mean skin temperatures, a perspective not comprehensively explored in previous literature. The review reveals that the most common measurement points for skin temperature are the face and hands, attributed to their higher thermal sensitivity and the practical ease of measurement. It establishes a clear linear relationship between mean skin temperature and user thermal sensation, though affected by the choice of measurement locations and number of points. A notable finding is the varying impact of local skin temperature on overall thermal sensation in changing environments, with local heating less influential than cooling. The review also uncovers significant demographic variations in thermal sensation, strongly influenced by differing skin temperatures across age groups, genders, and climatic regions. For example, elderly populations exhibit a decreased temperature sensitivity, especially towards warmth. Gender differences are also significant, with females experiencing higher skin temperatures in warmer environments and lower in colder ones. Machine learning (ML)-based methods, especially classification tree-based and support vector machine (SVM) techniques, dominate in predicting thermal sensation and comfort, leveraging skin temperature data. While ML methods are prevalent, statistical regression-based approaches offer valuable empirical insights. Thermo-physiological model-based methods provide reliable results by incorporating detailed skin temperature dynamics. The review identifies a gap in understanding how gender, age, and regional differences influence thermal comfort in diverse environments. The study recommends conducting more nuanced experiments to dissect the impact of these factors and proposes the integration of individual demographic variables into ML models to personalize thermal comfort predictions.","['support vector machine (SVM)', 'statistical regression-based approaches']","The research idea centers on the growing recognition of skin temperature as a key factor influencing human thermal sensation and comfort, highlighting the need for a comprehensive synthesis of existing studies to better understand this relationship. Despite previous research, there remains a lack of thorough exploration regarding the distinct roles of local and mean skin temperatures and how demographic factors such as age, gender, and climatic region affect thermal sensation. The primary objective of the study is to systematically review and synthesize findings from numerous studies to clarify the relationship between skin temperature and thermal sensation, with particular attention to the influence of measurement locations and demographic variations. Additionally, the study aims to identify gaps in understanding how individual differences impact thermal comfort and to recommend further research that considers these demographic factors in diverse environmental contexts."
Psychology,Seeking in Ride-on-Demand Service: A Reinforcement Learning Model With Dynamic Price Prediction,"Recent years witness the increasing popularity of ride-on-demand (RoD) services such as Uber and Didi. Compared with traditional taxi, RoD service is more ""data-driven"" and adopts dynamic pricing to manipulate the supply and demand in real time. Dynamic price could be viewed as an accurate and quantitative indicator of the supply and demand, and could provide clues to drivers, passengers, and the service providers, possibly reshaping the ways in which some problems are solved. In this paper, we focus on the seeking route recommendation problem that aims at increasing driver revenue by recommending highly profitable seeking routes to drivers of vacant cars with the help of dynamic prices. We first justify our motivation by showing the importance of route recommendation and answering why it is necessary to consider dynamic prices, based on the analysis of real service data. We then design a dynamic price prediction model to generate the dynamic prices at any given time and location based on multi-source urban data. After that, a reinforcement learning model is adopted to perform seeking route recommendation based on predicted dynamic prices. We conduct extensive experiments in different spatio-temporal combinations and make comparisons with multiple baselines. Results first show that our dynamic price prediction model achieves an accuracy ranging from 83.82% to 90.67% under different settings. It also proves that considering the real-time predicted dynamic prices significantly increases driver revenue by, for example, 12% and 47.5% during weekday evening rush hours, than merely using the average prices or completely ignoring dynamic prices.",['reinforcement learning model'],"The research idea centers on the growing use of ride-on-demand services and how dynamic pricing serves as a precise and quantitative indicator of supply and demand, influencing the behaviors of drivers, passengers, and service providers. This dynamic pricing has the potential to reshape problem-solving approaches within the context of ride services, particularly in relation to route selection for drivers. The study’s primary objective is to address the problem of recommending seeking routes that increase driver revenue by leveraging dynamic price information. It aims to demonstrate the importance of considering dynamic prices in route recommendations and to show how incorporating real-time price fluctuations can significantly enhance drivers’ earnings compared to relying on average prices or ignoring dynamic pricing altogether."
Psychology,Deciphering Digital Social Dynamics: A Comparative Study of Logistic Regression and Random Forest in Predicting E-Commerce Customer Behavior,"This study compares Logistic Regression and Random Forest in predicting e-commerce customer churn. Utilizing the E-commerce Customer dataset, it navigates the complexities of customer interactions and behaviors, offering a rich context for analysis. The methodology focuses on meticulous data preprocessing to ensure data integrity, setting the stage for applying and evaluating Logistic Regression and Random Forest. Both models were assessed using accuracy, precision, recall, F1-Score, and AUC-ROC. Logistic Regression showed an accuracy of 90%, precision of 91% for class 0 and 82% for class 1, recall of 98% for class 0 and 50% for class 1, F1-Score of 94% for class 0 and 62% for class 1, and AUC-ROC of 0.88. Random Forest, with its ability to handle complex patterns, demonstrated higher overall performance with an accuracy of 95%, precision of 95% for class 0 and 93% for class 1, recall of 99% for class 0 and 74% for class 1, F1-Score of 97% for class 0 and 82% for class 1, and an AUC-ROC of 0.97. This comparative analysis offers insights into each model's strengths and suitability for predicting customer churn. The findings contribute to a deeper understanding of machine learning applications in e-commerce, guiding stakeholders in enhancing customer retention strategies. This research provides a foundation for further exploration into the digital social dynamics that shape customer behavior in the evolving digital marketplace.","['Logistic Regression', 'Random Forest']","The study addresses the challenge of understanding and predicting customer churn within the e-commerce context, highlighting the complexities of customer interactions and behaviors that influence retention. It emphasizes the importance of accurately identifying factors that lead to customers discontinuing their engagement with online platforms, which is critical for improving customer retention strategies. The primary aim of the study is to compare different approaches in predicting e-commerce customer churn to determine their effectiveness and suitability. By evaluating these approaches, the research seeks to provide insights that contribute to a deeper understanding of the social dynamics influencing customer behavior in the digital marketplace."
Psychology,The power of Deep Learning techniques for predicting student performance in Virtual Learning Environments: A systematic literature review,"With the advances in Artificial Intelligence (AI) and the increasing volume of online educational data, Deep Learning techniques have played a critical role in predicting student performance. Recent developments have assisted instructors in determining the strengths and weaknesses of student achievement. This understanding will benefit from adopting the necessary interventions to assist students in improving their performance, helping at-risk of failure students, and preventing dropout rates. The review analyzed 46 studies between 2019 and 2023 that apply one or more Deep Learning (DL) techniques, either single or in combination with Machine Learning (ML) or Ensemble Learning techniques. Moreover, the review utilized datasets from public Massive Open Online Courses (MOOCs), private Learning Management Systems (LMSs), and other platforms. Four categories were used to group the features: demographic, previous academic performance, current academic performance, and learning behavior/activity features. The analysis revealed that the DNNs and CNN-LSTM models were the most common techniques. Moreover, the studies that used DL techniques, such as CNNs, DNNs, and LSTMs, performed well by achieving high prediction accuracy above 90%; other studies achieved accuracy ranging (60 to 90)%. For datasets used within the reviewed studies, even though 44% of the studies used LMSs datasets, Open University Learning Analytics Dataset (OULAD) was the most used dataset from MOOCs. The analysis of grouped features shows that among the various categories examined, learning behavior and activity features stand out as the most significant predictors, suggesting that students engagement with their learning environment through their overall participation offers crucial insights into their success. The educational prediction findings hopefully serve as a strong foundation for administrators and instructors to observe student performance and provide a suitable educational adaptation that can meet their needs to protect them from failure and prevent their dropout.","['Ensemble Learning techniques', 'DNNs', 'CNN-LSTM models', 'CNNs', 'DNNs', 'LSTMs']","The research idea centers on understanding student performance in educational settings by identifying strengths and weaknesses in achievement to support timely interventions. This understanding is crucial for assisting students in improving their outcomes, particularly those at risk of failure, and for preventing dropout rates. The study addresses the importance of examining various factors that influence student success, including demographic information, academic performance, and learning behaviors. The motivation lies in enhancing educational support by closely monitoring and responding to student engagement and participation.

The primary objective of the study is to analyze existing research on factors that predict student performance, with a focus on identifying the most significant predictors of success. The study aims to provide insights that can help educators and administrators observe student progress and implement appropriate educational adaptations tailored to individual needs. Ultimately, the goal is to support students in achieving better academic outcomes and reduce the likelihood of failure and dropout."
Psychology,Integrative analysis of AI-driven optimization in HIV treatment regimens,"The integration of artificial intelligence (AI) into HIV treatment regimens has revolutionized the approach to personalized care and optimization strategies. This study presents an in-depth analysis of the role of AI in transforming HIV treatment, focusing on its ability to tailor therapy to individual patient needs and enhance treatment outcomes. AI-driven optimization in HIV treatment involves the utilization of advanced algorithms and computational techniques to analyze vast amounts of patient data, including genetic information, viral load measurements, and treatment history. By harnessing the power of machine learning and predictive analytics, AI algorithms can identify patterns and trends in patient data that may not be readily apparent to human clinicians. One of the key benefits of AI-driven optimization is its ability to personalize treatment regimens based on individual patient characteristics and disease progression. By considering factors such as drug resistance profiles, comorbidities, and lifestyle factors, AI algorithms can recommend the most effective and well-tolerated treatment options for each patient, leading to improved adherence and clinical outcomes. Furthermore, AI enables continuous monitoring and adjustment of treatment regimens in real time, allowing healthcare providers to respond rapidly to changes in patient status and evolving viral dynamics. This proactive approach to HIV management can help prevent treatment failure and the development of drug resistance, ultimately leading to better long-term outcomes for patients. Despite its transformative potential, AI-driven optimization in HIV treatment is not without challenges. Ethical considerations, data privacy concerns, and the need for robust validation and regulatory oversight are all important factors that must be addressed to ensure the safe and effective implementation of AI algorithms in clinical practice. In conclusion, the integrative analysis presented in this study underscores the significant impact of AI-driven optimization on the personalization and optimization of HIV treatment regimens. By leveraging AI technologies, healthcare providers can tailor treatment approaches to individual patient needs, leading to improved outcomes and quality of life for people living with HIV. Keywords: Integrative Analysis, AI- Driven, Optimization, HIV Treatment, Regimens.",['machine learning'],"The study addresses the challenge of improving HIV treatment by focusing on the need for personalized care that accounts for individual patient characteristics and disease progression. It highlights the importance of tailoring therapy to enhance treatment outcomes and adherence, considering factors such as drug resistance, comorbidities, and lifestyle. The motivation stems from the goal of preventing treatment failure and drug resistance through continuous monitoring and adjustment of treatment regimens. The primary aim of the study is to explore how personalized treatment approaches can be optimized to better meet the unique needs of people living with HIV, ultimately improving their clinical outcomes and quality of life."
Psychology,Artificial intelligence for oral squamous cell carcinoma detection based on oral photographs: A comprehensive literature review,"Abstract Introduction Oral squamous cell carcinoma (OSCC) presents a significant global health challenge. The integration of artificial intelligence (AI) and computer vision holds promise for the early detection of OSCC through the analysis of digitized oral photographs. This literature review explores the landscape of AI‐driven OSCC automatic detection, assessing both the performance and limitations of the current state of the art. Materials and Methods An electronic search using several data base was conducted, and a systematic review performed in accordance with PRISMA guidelines (CRD42023441416). Results Several studies have demonstrated remarkable results for this task, consistently achieving sensitivity rates exceeding 85% and accuracy rates surpassing 90%, often encompassing around 1000 images. The review scrutinizes these studies, shedding light on their methodologies, including the use of recent machine learning and pattern recognition approaches coupled with different supervision strategies. However, comparing the results from different papers is challenging due to variations in the datasets used. Discussion Considering these findings, this review underscores the urgent need for more robust and reliable datasets in the field of OSCC detection. Furthermore, it highlights the potential of advanced techniques such as multi‐task learning, attention mechanisms, and ensemble learning as crucial tools in enhancing the accuracy and sensitivity of OSCC detection through oral photographs. Conclusion These insights collectively emphasize the transformative impact of AI‐driven approaches on early OSCC diagnosis, with the potential to significantly improve patient outcomes and healthcare practices.","['machine learning', 'multi-task learning', 'attention mechanisms', 'ensemble learning']","The research idea centers on addressing the significant global health challenge posed by oral squamous cell carcinoma (OSCC) and the importance of early detection to improve patient outcomes. The study recognizes the current limitations in reliably identifying OSCC through oral photographs and the variability in existing datasets that complicate consistent detection efforts. The primary objective of the study is to explore and evaluate the current landscape of automatic OSCC detection methods, focusing on their performance and limitations. It aims to highlight the need for more robust and reliable datasets and to emphasize approaches that could enhance the accuracy and sensitivity of early OSCC diagnosis through oral photographic assessment."
Psychology,A deep learning model for brain age prediction using minimally preprocessed T1w images as input,"Introduction In the last few years, several models trying to calculate the biological brain age have been proposed based on structural magnetic resonance imaging scans (T1-weighted MRIs, T1w) using multivariate methods and machine learning. We developed and validated a convolutional neural network (CNN)-based biological brain age prediction model that uses one T1w MRI preprocessing step when applying the model to external datasets to simplify implementation and increase accessibility in research settings. Our model only requires rigid image registration to the MNI space, which is an advantage compared to previous methods that require more preprocessing steps, such as feature extraction. Methods We used a multicohort dataset of cognitively healthy individuals (age range = 32.0–95.7 years) comprising 17,296 MRIs for training and evaluation. We compared our model using hold-out (CNN1) and cross-validation (CNN2–4) approaches. To verify generalisability, we used two external datasets with different populations and MRI scan characteristics to evaluate the model. To demonstrate its usability, we included the external dataset’s images in the cross-validation training (CNN3). To ensure that our model used only the brain signal on the image, we also predicted brain age using skull-stripped images (CNN4). Results: The trained models achieved a mean absolute error of 2.99, 2.67, 2.67, and 3.08 years for CNN1–4, respectively. The model’s performance in the external dataset was in the typical range of mean absolute error (MAE) found in the literature for testing sets. Adding the external dataset to the training set (CNN3), overall, MAE is unaffected, but individual cohort MAE improves (5.63–2.25 years). Salience maps of predictions reveal that periventricular, temporal, and insular regions are the most important for age prediction. Discussion We provide indicators for using biological (predicted) brain age as a metric for age correction in neuroimaging studies as an alternative to the traditional chronological age. In conclusion, using different approaches, our CNN-based model showed good performance using one T1w brain MRI preprocessing step. The proposed CNN model is made publicly available for the research community to be easily implemented and used to study ageing and age-related disorders.","['machine learning', 'convolutional neural network (CNN)', 'hold-out approach']","The research idea centers on the challenge of accurately estimating biological brain age as a meaningful metric that reflects brain health and aging beyond chronological age. Existing approaches often require complex preprocessing steps, which can limit accessibility and implementation in research settings. This study addresses the need for a simplified yet reliable method to predict biological brain age using structural brain imaging data. The primary objective of the study is to develop and validate a biological brain age prediction approach that requires minimal preprocessing of brain images, thereby enhancing usability and accessibility for studying brain aging and age-related disorders. The study aims to demonstrate the model’s performance and generalizability across diverse populations and imaging conditions, ultimately providing a practical tool for age correction in neuroimaging research."
Psychology,Detection of epileptic seizure in EEG signals using machine learning and deep learning techniques,"Abstract Around 50 million individuals worldwide suffer from epilepsy, a chronic, non-communicable brain disorder. Several screening methods, including electroencephalography, have been proposed to identify epileptic episodes. EEG data, which are frequently utilised to enhance epilepsy analysis, offer essential information on the electrical processes of the brain. Prior to the emergence of deep learning (DL), feature extraction was accomplished by standard machine learning techniques. As a result, they were only as good as the people who made the features by hand. But with DL, both feature extraction and classification are fully automated. These methods have significantly advanced several fields of medicine, including the diagnosis of epilepsy. In this paper, the works focused on automated epileptic seizure detection using ML and DL techniques are presented as well as their comparative analysis is done. The UCI-Epileptic Seizure Recognition dataset is used for training and validation. Some of the conventional ML and DL algorithms are used with a proposed model which uses long short-term memory (LSTM) to find the best approach. Post that comparative analysis is performed on these algorithms to find the best approach for epileptic seizure detection. As a result, the proposed model LSTM gives a validation accuracy of 97% giving the most appropriate and precise result as compared to other mentioned algorithms used in this study.","['machine learning', 'deep learning', 'long short-term memory (LSTM)']","The study addresses the significant challenge of accurately identifying epileptic episodes in individuals suffering from epilepsy, a chronic brain disorder affecting around 50 million people worldwide. It highlights the importance of electroencephalography (EEG) data in providing essential information about the brain's electrical activity to improve epilepsy analysis. The primary objective of the study is to evaluate and compare different approaches for detecting epileptic seizures, aiming to find the most appropriate and precise method for seizure identification based on EEG data. The study seeks to determine which approach yields the highest accuracy in recognizing epileptic episodes to enhance diagnostic capabilities."
Psychology,Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models,"Suicidal ideation detection is a vital research area that holds great potential for improving mental health support systems. However, the sensitivity surrounding suicide-related data poses challenges in accessing large-scale, annotated datasets necessary for training effective machine learning models. To address this limitation, we introduce an innovative strategy that leverages the capabilities of generative AI models, such as ChatGPT, Flan-T5, and Llama, to create synthetic data for suicidal ideation detection. Our data generation approach is grounded in social factors extracted from psychology literature and aims to ensure coverage of essential information related to suicidal ideation. In our study, we benchmarked against state-of-the-art NLP classification models, specifically, those centered around the BERT family structures. When trained on the real-world dataset, UMD, these conventional models tend to yield F1-scores ranging from 0.75 to 0.87. Our synthetic data-driven method, informed by social factors, offers consistent F1-scores of 0.82 for both models, suggesting that the richness of topics in synthetic data can bridge the performance gap across different model complexities. Most impressively, when we combined a mere 30% of the UMD dataset with our synthetic data, we witnessed a substantial increase in performance, achieving an F1-score of 0.88 on the UMD test set. Such results underscore the cost-effectiveness and potential of our approach in confronting major challenges in the field, such as data scarcity and the quest for diversity in data representation.","['generative AI models', 'Flan-T5', 'Llama']","The research idea centers on the critical importance of detecting suicidal ideation to enhance mental health support, while recognizing the challenges posed by the sensitive nature of suicide-related data that limit access to large, annotated datasets. This scarcity of data hinders the development of effective approaches for identifying suicidal thoughts, highlighting the need for alternative strategies that can capture essential psychological and social factors related to suicidal ideation. The primary objective of the study is to develop and evaluate a novel approach that generates synthetic data informed by social factors from psychology literature to improve the detection of suicidal ideation. The study aims to demonstrate that incorporating this synthetic data can address data scarcity and enhance the performance of suicidal ideation detection, ultimately contributing to more effective mental health interventions."
Psychology,Prevalence and risk factors analysis of postpartum depression at early stage using hybrid deep learning model,"Postpartum Depression Disorder (PPDD) is a prevalent mental health condition and results in severe depression and suicide attempts in the social community. Prompt actions are crucial in tackling PPDD, which requires a quick recognition and accurate analysis of the probability factors associated with this condition. This concern requires attention. The primary aim of our research is to investigate the feasibility of anticipating an individual's mental state by categorizing individuals with depression from those without depression using a dataset consisting of text along with audio recordings from patients diagnosed with PPDD. This research proposes a hybrid PPDD framework that combines Improved Bi-directional Long Short-Term Memory (IBi-LSTM) with Transfer Learning (TL) based on two Convolutional Neural Network (CNN) architectures, respectively CNN-text and CNN audio. In the proposed model, the CNN section efficiently utilizes TL to obtain crucial knowledge from text and audio characteristics, whereas the improved Bi-LSTM module combines written material and sound data to obtain intricate chronological interpersonal relationships. The proposed model incorporates an attention technique to augment the effectiveness of the Bi-LSTM scheme. An experimental analysis is conducted on the PPDD online textual and speech audio dataset collected from UCI. It includes textual features such as age, women's health tracks, medical histories, demographic information, daily life metrics, psychological evaluations, and 'speech records' of PPDD patients. Data pre-processing is applied to maintain the data integrity and achieve reliable model performance. The proposed model demonstrates a great performance in better precision, recall, accuracy, and F1-score over existing deep learning models, including VGG-16, Base-CNN, and CNN-LSTM. These metrics indicate the model's ability to differentiate among women at risk of PPDD vs. non-PPDD. In addition, the feature importance analysis demonstrates that specific risk factors substantially impact the prediction of PPDD. The findings of this research establish a basis for improved precision and promptness in assessing the risk of PPDD, which may ultimately result in earlier implementation of interventions and the establishment of support networks for women who are susceptible to PPDD.","['Transfer Learning (TL)', 'Convolutional Neural Network (CNN)', 'Attention technique', 'VGG-16', 'CNN-LSTM']","The research addresses the significant mental health issue of Postpartum Depression Disorder (PPDD), which is prevalent and can lead to severe depression and suicide attempts within the community. There is a critical need for prompt recognition and accurate identification of the factors associated with PPDD to enable timely intervention. The primary objective of the study is to investigate the feasibility of anticipating an individual's mental state by distinguishing between those with depression and those without, using a dataset comprising text and audio recordings from patients diagnosed with PPDD. This aims to improve the precision and promptness in assessing the risk of PPDD, ultimately facilitating earlier interventions and the development of support networks for women vulnerable to this condition."
Psychology,Collective Constitutional AI: Aligning a Language Model with Public Input,"There is growing consensus that language model (LM) developers should not be the sole deciders of LM behavior, creating a need for methods that enable the broader public to collectively shape the behavior of LM systems that affect them. To address this need, we present Collective Constitutional AI (CCAI): a multi-stage process for sourcing and integrating public input into LMs—from identifying a target population to sourcing principles to training and evaluating a model. We demonstrate the real-world practicality of this approach by creating what is, to our knowledge, the first LM fine-tuned with collectively sourced public input and evaluating this model against a baseline model trained with established principles from a LM developer. Our quantitative evaluations demonstrate several benefits of our approach: the CCAI-trained model shows lower bias across nine social dimensions compared to the baseline model, while maintaining equivalent performance on language, math, and helpful-harmless evaluations. Qualitative comparisons of the models suggest that the models differ on the basis of their respective constitutions, e.g., when prompted with contentious topics, the CCAI-trained model tends to generate responses that reframe the matter positively instead of a refusal. These results demonstrate a promising, tractable pathway toward publicly informed development of language models.",['fine-tuning'],"The research idea centers on the growing recognition that developers should not be the sole decision-makers regarding the behavior of language models, highlighting the need for approaches that allow the broader public to collectively influence systems that impact them. This reflects a broader motivation to democratize the shaping of such technologies to better align with diverse societal values and reduce biases. The primary objective of the study is to explore a process for incorporating public input into the development of language models, aiming to create a model that reflects collectively sourced principles rather than solely developer-established guidelines. The study seeks to evaluate whether this approach can reduce bias across various social dimensions while maintaining comparable performance on standard assessments."
Psychology,Graph Autoencoders for Embedding Learning in Brain Networks and Major Depressive Disorder Identification,"Brain functional connectivity (FC) networks inferred from functional magnetic resonance imaging (fMRI) have shown altered or aberrant brain functional connectome in various neuropsychiatric disorders. Recent application of deep neural networks to connectome-based classification mostly relies on traditional convolutional neural networks (CNNs) using input FCs on a regular Euclidean grid to learn spatial maps of brain networks neglecting the topological information of the brain networks, leading to potentially sub-optimal performance in brain disorder identification. We propose a novel graph deep learning framework that leverages non-Euclidean information inherent in the graph structure for classifying brain networks in major depressive disorder (MDD). We introduce a novel graph autoencoder (GAE) architecture, built upon graph convolutional networks (GCNs), to embed the topological structure and node content of large fMRI networks into low-dimensional representations. For constructing the brain networks, we employ the Ledoit-Wolf (LDW) shrinkage method to efficiently estimate high-dimensional FC metrics from fMRI data. We explore both supervised and unsupervised techniques for graph embedding learning. The resulting embeddings serve as feature inputs for a deep fully-connected neural network (FCNN) to distinguish MDD from healthy controls (HCs). Evaluating our model on resting-state fMRI MDD dataset, we observe that the GAE-FCNN outperforms several state-of-the-art methods for brain connectome classification, achieving the highest accuracy when using LDW-FC edges as node features. The graph embeddings of fMRI FC networks also reveal significant group differences between MDD and HCs. Our framework demonstrates the feasibility of learning graph embeddings from brain networks, providing valuable discriminative information for diagnosing brain disorders.","['deep neural networks', 'convolutional neural networks (CNNs)', 'graph autoencoder (GAE)', 'graph convolutional networks (GCNs)', 'supervised techniques for graph embedding learning', 'unsupervised techniques for graph embedding learning', 'deep fully-connected neural network (FCNN)']","The study addresses the problem of identifying altered brain functional connectivity patterns associated with major depressive disorder (MDD) using brain networks derived from functional magnetic resonance imaging (fMRI). It highlights the challenge that traditional approaches may overlook important topological information of brain networks, which could limit the effectiveness of distinguishing MDD from healthy controls. The primary aim of the study is to develop a framework that captures the topological structure and node content of brain networks to improve the classification of MDD. The objective is to explore representations of brain functional connectivity that reveal significant differences between individuals with MDD and healthy controls, thereby enhancing the ability to diagnose brain disorders based on brain network characteristics."
Psychology,Do large language models show decision heuristics similar to humans? A case study using GPT-3.5.,"A Large Language Model (LLM) is an artificial intelligence system trained on vast amounts of natural language data, enabling it to generate human-like responses to written or spoken language input. Generative Pre-Trained Transformer (GPT)-3.5 is an example of an LLM that supports a conversational agent called ChatGPT. In this work, we used a series of novel prompts to determine whether ChatGPT shows heuristics and other context-sensitive responses. We also tested the same prompts on human participants. Across four studies, we found that ChatGPT was influenced by random anchors in making estimates (anchoring, Study 1); it judged the likelihood of two events occurring together to be higher than the likelihood of either event occurring alone, and it was influenced by anecdotal information (representativeness and availability heuristic, Study 2); it found an item to be more efficacious when its features were presented positively rather than negatively-even though both presentations contained statistically equivalent information (framing effect, Study 3); and it valued an owned item more than a newly found item even though the two items were objectively identical (endowment effect, Study 4). In each study, human participants showed similar effects. Heuristics and context-sensitive responses in humans are thought to be driven by cognitive and affective processes such as loss aversion and effort reduction. The fact that an LLM-which lacks these processes-also shows such responses invites consideration of the possibility that language is sufficiently rich to carry these effects and may play a role in generating these effects in humans. (PsycInfo Database Record (c) 2024 APA, all rights reserved).",['Generative Pre-Trained Transformer (GPT)-3.5'],"The research idea centers on understanding whether certain cognitive biases and heuristics, typically observed in human judgment and decision-making, can also be exhibited by a language-based system that lacks human cognitive and affective processes. This raises questions about the role of language itself in shaping these psychological effects, suggesting that language may be sufficiently rich to carry and generate such biases in humans. The primary objective of the study is to investigate whether a conversational agent demonstrates heuristics and context-sensitive responses similar to those found in human participants across various cognitive phenomena, including anchoring, representativeness, availability heuristic, framing effect, and the endowment effect. By comparing responses between the agent and humans, the study aims to explore the possibility that language contributes to the emergence of these cognitive biases in human psychology."
Psychology,Detecting ChatGPT-Generated Code Submissions in a CS1 Course Using Machine Learning Models,"The emergence of publicly accessible large language models (LLMs) such as ChatGPT poses unprecedented risks of new types of plagiarism and cheating where students use LLMs to solve exercises for them. Detecting this behavior will be a necessary component in introductory computer science (CS1) courses, and educators should be well-equipped with detection tools when the need arises. However, ChatGPT generates code non-deterministically, and thus, traditional similarity detectors might not suffice to detect AI-created code. In this work, we explore the affordances of Machine Learning (ML) models for the detection task. We used an openly available dataset of student programs for CS1 assignments and had ChatGPT generate code for the same assignments, and then evaluated the performance of both traditional machine learning models and Abstract Syntax Tree-based (AST-based) deep learning models in detecting ChatGPT code from student code submissions. Our results suggest that both traditional machine learning models and AST-based deep learning models are effective in identifying ChatGPT-generated code with accuracy above 90%. Since the deployment of such models requires ML knowledge and resources that are not always accessible to instructors, we also explore the patterns detected by deep learning models that indicate possible ChatGPT code signatures, which instructors could possibly use to detect LLM-based cheating manually. We also explore whether explicitly asking ChatGPT to impersonate a novice programmer affects the code produced. We further discuss the potential applications of our proposed models for enhancing introductory computer science instruction.",['Abstract Syntax Tree-based (AST-based) deep learning models'],"The research idea centers on the emerging challenge of plagiarism and cheating in educational settings due to students using advanced language models to complete assignments, which poses new risks that educators must address. This issue is particularly relevant in introductory courses where detecting such behavior is crucial to maintaining academic integrity. The study’s primary objective is to investigate ways to identify instances where students use these language models to generate assignment solutions, aiming to equip educators with effective means to recognize and address this form of academic dishonesty. Additionally, the research seeks to understand whether prompting the language model to mimic novice behavior influences the nature of the generated work, thereby informing detection strategies."
Psychology,Enhancing End-to-End Multi-Task Dialogue Systems: A Study on Intrinsic Motivation Reinforcement Learning Algorithms for Improved Training and Adaptability,"End-to-end multi-task dialogue systems are usually designed with separate modules for the dialogue pipeline. Among these, the policy module is essential for deciding what to do in response to user input. This policy is trained by reinforcement learning algorithms by taking advantage of an environment in which an agent receives feedback in the form of a reward signal. The current dialogue systems, however, only provide meagre and simplistic rewards. Investigating intrinsic motivation reinforcement learning algorithms is the goal of this study. Through this, the agent can quickly accelerate training and improve its capacity to judge the quality of its actions by teaching it an internal incentive system. In particular, we adapt techniques for random network distillation and curiosity-driven reinforcement learning to measure the frequency of state visits and encourage exploration by using semantic similarity between utterances. Experimental results on MultiWOZ, a heterogeneous dataset, show that intrinsic motivation-based debate systems outperform policies that depend on extrinsic incentives. By adopting random network distillation, for example, which is trained using semantic similarity between user-system dialogues, an astounding average success rate of 73% is achieved. This is a significant improvement over the baseline Proximal Policy optimization (PPO), which has an average success rate of 60%. In addition, performance indicators such as booking rates and completion rates show a 10% rise over the baseline. Furthermore, these intrinsic incentive models help improve the system's policy's resilience in an increasing amount of domains. This implies that they could be useful in scaling up to settings that cover a wider range of domains.","['reinforcement learning algorithms', 'intrinsic motivation reinforcement learning algorithms', 'random network distillation', 'curiosity-driven reinforcement learning', 'Proximal Policy Optimization (PPO)']","The research idea centers on addressing the limitations of current dialogue systems in providing only simplistic and insufficient rewards, which hinders their ability to effectively learn and respond to user input. The study is motivated by the need to enhance the decision-making capacity of dialogue policies by incorporating an internal incentive system that can better evaluate the quality of actions and accelerate learning. The primary objective of the study is to investigate intrinsic motivation approaches to improve the training and performance of dialogue policies, aiming to increase success rates, booking rates, and completion rates across multiple domains. Specifically, the study seeks to demonstrate that intrinsic incentives can lead to more resilient and scalable dialogue policies that perform better than those relying solely on external rewards."
Psychology,An efficient Parkinson's disease detection framework: Leveraging time-frequency representation and AlexNet convolutional neural network,"Parkinson's disease (PD) is a progressive neurodegenerative disorder affecting the quality of life of over 10 million individuals worldwide. Early diagnosis is crucial for timely intervention and better patient outcomes. Electroencephalogram (EEG) signals are commonly used for early PD diagnosis due to their potential in monitoring disease progression. But traditional EEG-based methods lack exploration of brain regions that provide essential information about PD, and their performance falls short for real-time applications. To address these limitations, this study proposes a novel approach using a Time-Frequency Representation (TFR) based AlexNet Convolutional Neural Network (CNN) model to explore EEG channel-based analysis and identify critical brain regions efficiently diagnosing PD from EEG data. The Wavelet Scattering Transform (WST) is employed to capture distinct temporal and spectral characteristics, while AlexNet CNN is utilized to detect complex spatial patterns at different scales, accurately identifying intricate EEG patterns associated with PD. The experiment results on two real-time EEG PD datasets: San Diego dataset and the Iowa dataset demonstrate that frontal and central brain regions, including AF4 and AFz electrodes, contribute significantly to providing more representative features compared to other regions for PD detection. The proposed architecture achieves an impressive accuracy of 99.84% for the San Diego dataset and 95.79% for the Iowa dataset, outperforming existing EEG-based PD detection methods. The findings of this research will assist to create an essential technology for efficient PD diagnosis, enhancing patient care and quality of life.","['Wavelet Scattering Transform (WST)', 'AlexNet CNN']","The research idea centers on the challenge of early diagnosis of Parkinson's disease (PD), a progressive neurodegenerative disorder that significantly impacts the quality of life for millions worldwide. Early detection is vital for timely intervention and improved patient outcomes, yet existing EEG-based methods have limitations in exploring brain regions that provide critical information about PD and often underperform in real-time applications. The study aims to address these gaps by identifying key brain regions involved in PD through EEG analysis. The primary objective of the study is to explore EEG channel-based analysis to identify critical brain regions that contribute to the efficient diagnosis of Parkinson's disease. Specifically, the research seeks to determine which brain regions provide the most representative features for PD detection, thereby enhancing the accuracy and effectiveness of early diagnosis to ultimately improve patient care and quality of life."
Psychology,Multimodal diagnosis model of Alzheimer’s disease based on improved Transformer,"Abstract Purpose Recent technological advancements in data acquisition tools allowed neuroscientists to acquire different modality data to diagnosis Alzheimer’s disease (AD). However, how to fuse these enormous amount different modality data to improve recognizing rate and find significance brain regions is still challenging. Methods The algorithm used multimodal medical images [structural magnetic resonance imaging (sMRI) and positron emission tomography (PET)] as experimental data. Deep feature representations of sMRI and PET images are extracted by 3D convolution neural network (3DCNN). An improved Transformer is then used to progressively learn global correlation information among features. Finally, the information from different modalities is fused for identification. A model-based visualization method is used to explain the decisions of the model and identify brain regions related to AD. Results The model attained a noteworthy classification accuracy of 98.1% for Alzheimer’s disease (AD) using the Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset. Upon examining the visualization results, distinct brain regions associated with AD diagnosis were observed across different image modalities. Notably, the left parahippocampal region emerged consistently as a prominent and significant brain area. Conclusions A large number of comparative experiments have been carried out for the model, and the experimental results verify the reliability of the model. In addition, the model adopts a visualization analysis method based on the characteristics of the model, which improves the interpretability of the model. Some disease-related brain regions were found in the visualization results, which provides reliable information for AD clinical research.",['3D convolution neural network (3DCNN)'],"The research idea centers on the challenge of effectively integrating multiple types of brain imaging data to enhance the recognition of Alzheimer’s disease and to identify significant brain regions associated with the condition. Despite advancements in acquiring diverse neuroimaging data, combining these different modalities to improve diagnostic accuracy and understand the neural underpinnings of Alzheimer’s remains difficult. The primary objective of the study is to improve the identification of Alzheimer’s disease by utilizing multimodal brain imaging data and to pinpoint brain regions that are significantly related to the diagnosis. Additionally, the study aims to provide interpretable findings that can offer reliable information for clinical research on Alzheimer’s disease."
Psychology,Factors influencing academic performance and dropout rates in higher education,"The aim of this study was to identify and evaluate the most frequently used research methods and factors influencing academic performance, based on a pool of 95 studies, published after 2012. We considered only peer-reviewed papers containing 78 empirical and 17 meta-analytic studies. Our theoretical background lies in the different approaches of the terms 'university dropout' and 'academic performance'. After the systematic analysis we ascertained the most commonly used methods are Educational Data Mining (EDM) algorithms (decision tree, logistic regression and neural networks) and Structural Equation Modelling (SEM). The strength of the predictive power depends on the dataset, however Support Vector Machines, Multilayer Perceptron, Naïve Bayes algorithm were found to be the most precise in prediction. Regarding factors influencing academic performance we derived our results based on 600,000 university students. Considering the data from meta-analyses and systematic reviews, reaching up to 900 studies, we found grade point average (GPA), obtained credits (ECTS) and gender to be the most consistent and decisive predictors of academic performance. Nevertheless, GPA and ECTS (as output variables) are mediated by student factors (intrinsic motivation, self-regulated learning strategies, self-efficacy, prior education) and throughput factors (work, finances, academic engagement). We had contradictory results on age and family background.","['decision tree', 'logistic regression', 'neural networks', 'Support Vector Machines', 'Multilayer Perceptron', 'Naïve Bayes algorithm']","The research idea centers on understanding the factors that influence academic performance and university dropout by examining a wide range of studies published after 2012. The study addresses the need to clarify the different conceptual approaches to academic performance and dropout, as well as to identify the most frequently investigated predictors within the higher education context. The research objective is to identify and evaluate the most commonly used research methods and the key factors influencing academic performance based on a comprehensive review of empirical and meta-analytic studies. Specifically, the study aims to determine which student-related and throughput factors consistently predict academic outcomes such as grade point average and obtained credits, while also exploring the role of demographic variables like gender, age, and family background."
Psychology,Learners’ continuance intention in multimodal language learning education: An innovative multiple linear regression model,"Confronted with the unprecedented COVID-19 pandemic, millions of learners have received, are receiving, or will receive multimodal language learning education. This study aims to explore the relationships between various factors influencing learners' continuance intention by proposing an innovative multiple linear regression model in multimodal language learning education. Participants were randomly recruited (N = 334) in China who had received multimodal language learning education by combining Massive Open Online Courses, Rain Classroom, and WeChat. The research instrument, a comprehensive questionnaire, was sent through the online system named Questionnaire Star developed by technical experts. A multiple linear regression analysis was adopted to test the proposed hypotheses and fit the research model. This study confirms the relationships between the Technology Acceptance Model-inclusive constructs such as perceived ease of use, perceived usefulness, attitudes toward multimodal language learning education, and continuance intention of participating in multimodal language learning education. The Technology Acceptance Model is also associated with other constructs, e.g. Task-technology fit, Individual-technology fit, Openness, and Reputation of multimodal language learning educational institutes, and personal investment in multimodal language learning education. However, personal investment neither directly nor indirectly predicts continuance intention. Educators and designers could make every effort to improve multimodal language learning education to enhance personal investment and foster its association with continuance intention of learners.",['multiple linear regression'],"The research idea centers on understanding the factors that influence learners' continued engagement with multimodal language learning education, especially in the context of the widespread shift to such educational formats during the COVID-19 pandemic. The study addresses the need to explore how various psychological and contextual elements relate to learners' intentions to persist in this mode of education. The primary objective of the study is to examine the relationships between constructs such as perceived ease of use, perceived usefulness, attitudes toward multimodal language learning, and continuance intention among learners. Additionally, the study aims to investigate how factors like task fit, individual fit, openness, reputation of educational institutes, and personal investment relate to learners' ongoing participation in multimodal language learning education."
Psychology,An interpretable model based on graph learning for diagnosis of Parkinson’s disease with voice-related EEG,"Abstract Parkinson’s disease (PD) exhibits significant clinical heterogeneity, presenting challenges in the identification of reliable electroencephalogram (EEG) biomarkers. Machine learning techniques have been integrated with resting-state EEG for PD diagnosis, but their practicality is constrained by the interpretable features and the stochastic nature of resting-state EEG. The present study proposes a novel and interpretable deep learning model, graph signal processing-graph convolutional networks (GSP-GCNs), using event-related EEG data obtained from a specific task involving vocal pitch regulation for PD diagnosis. By incorporating both local and global information from single-hop and multi-hop networks, our proposed GSP-GCNs models achieved an averaged classification accuracy of 90.2%, exhibiting a significant improvement of 9.5% over other deep learning models. Moreover, the interpretability analysis revealed discriminative distributions of large-scale EEG networks and topographic map of microstate MS5 learned by our models, primarily located in the left ventral premotor cortex, superior temporal gyrus, and Broca’s area that are implicated in PD-related speech disorders, reflecting our GSP-GCN models’ ability to provide interpretable insights identifying distinctive EEG biomarkers from large-scale networks. These findings demonstrate the potential of interpretable deep learning models coupled with voice-related EEG signals for distinguishing PD patients from healthy controls with accuracy and elucidating the underlying neurobiological mechanisms.",['graph signal processing-graph convolutional networks (GSP-GCNs)'],"The research idea addresses the significant clinical heterogeneity of Parkinson’s disease (PD), which creates challenges in identifying reliable biomarkers for diagnosis. Specifically, the study focuses on the difficulty of finding interpretable and consistent features from brain activity related to PD, particularly in the context of speech and vocal pitch regulation. The motivation lies in improving the understanding and detection of PD-related neurobiological mechanisms through brain signals associated with vocal tasks. The primary objective of the study is to investigate event-related brain activity during a vocal pitch regulation task to identify distinctive neural patterns that can differentiate individuals with PD from healthy controls. The study aims to provide interpretable insights into the brain regions involved in PD-related speech disorders and to enhance the accuracy of PD diagnosis by examining large-scale brain network activity linked to vocal function."
Psychology,The Utility of AI in Writing a Scientific Review Article on the Impacts of COVID-19 on Musculoskeletal Health,"Abstract Purpose of Review There were two primary purposes to our reviews. First, to provide an update to the scientific community about the impacts of COVID-19 on musculoskeletal health. Second, was to determine the value of using a large language model, ChatGPT 4.0, in the process of writing a scientific review article. To accomplish these objectives, we originally set out to write three review articles on the topic using different methods to produce the initial drafts of the review articles. The first review article was written in the traditional manner by humans, the second was to be written exclusively using ChatGPT (AI-only or AIO), and the third approach was to input the outline and references selected by humans from approach 1 into ChatGPT, using the AI to assist in completing the writing (AI-assisted or AIA). All review articles were extensively fact-checked and edited by all co-authors leading to the final drafts of the manuscripts, which were significantly different from the initial drafts. Recent Findings Unfortunately, during this process, it became clear that approach 2 was not feasible for a very recent topic like COVID-19 as at the time, ChatGPT 4.0 had a cutoff date of September 2021 and all articles published after this date had to be provided to ChatGPT, making approaches 2 and 3 virtually identical. Therefore, only two approaches and two review articles were written (human and AI-assisted). Here we found that the human-only approach took less time to complete than the AI-assisted approach. This was largely due to the number of hours required to fact-check and edit the AI-assisted manuscript. Of note, the AI-assisted approach resulted in inaccurate attributions of references (about 20%) and had a higher similarity index suggesting an increased risk of plagiarism. Summary The main aim of this project was to determine whether the use of AI could improve the process of writing a scientific review article. Based on our experience, with the current state of technology, it would not be advised to solely use AI to write a scientific review article, especially on a recent topic.","['large language model, ChatGPT 4.0']","The research idea centers on understanding the impacts of COVID-19 on musculoskeletal health and exploring the effectiveness of different approaches to writing scientific review articles on this topic. The study addresses the challenges associated with producing accurate and timely scientific reviews during a rapidly evolving health crisis. The primary objective of the study was to evaluate whether the use of an assisted writing approach could improve the process of composing a scientific review article on COVID-19 and musculoskeletal health. The study aimed to compare traditional human-only writing with an assisted approach to determine the feasibility, accuracy, and efficiency of these methods in producing reliable scientific reviews."
Psychology,"Uncertainty Reduction in Flood Susceptibility Mapping Using Random Forest and eXtreme Gradient Boosting Algorithms in Two Tropical Desert Cities, Shibam and Marib, Yemen","Flooding is a natural disaster that coexists with human beings and causes severe loss of life and property worldwide. Although numerous studies for flood susceptibility modelling have been introduced, a notable gap has been the overlooked or reduced consideration of the uncertainty in the accuracy of the produced maps. Challenges such as limited data, uncertainty due to confidence bounds, and the overfitting problem are critical areas for improving accurate models. We focus on the uncertainty in susceptibility mapping, mainly when there is a significant variation in the predictive relevance of the predictor factors. It is also noted that the receiver operating characteristic (ROC) curve may not accurately depict the sensitivity of the resulting susceptibility map to overfitting. Therefore, reducing the overfitting problem was targeted to increase accuracy and improve processing time in flood prediction. This study created a spatial repository to test the models, containing data from historical flooding and twelve topographic and geo-environmental flood conditioning variables. Then, we applied random forest (RF) and extreme gradient boosting (XGB) algorithms to map flood susceptibility, incorporating a variable drop-off in the empirical loop function. The results showed that the drop-off loop function was a crucial method to resolve the model uncertainty associated with the conditioning factors of the susceptibility modelling and methods. The results showed that approximately 8.42% to 9.89% of Marib City and 9.93% to 15.69% of Shibam City areas were highly vulnerable to floods. Furthermore, this study significantly contributes to worldwide endeavors focused on reducing the hazards linked to natural disasters. The approaches used in this study can offer valuable insights and strategies for reducing natural disaster risks, particularly in Yemen.","['random forest (RF)', 'extreme gradient boosting (XGB)']","The research idea centers on addressing the significant challenge of uncertainty in flood susceptibility mapping, particularly the variability in the predictive relevance of factors influencing flood risk. Despite numerous studies on flood susceptibility, there has been limited attention to the accuracy and reliability of the resulting maps, especially concerning overfitting and confidence bounds. This gap highlights the need to improve the precision of flood risk assessments to better understand and mitigate the impact of flooding on vulnerable areas. The study aims to reduce the overfitting problem in flood susceptibility models to enhance their accuracy and reliability. The primary objective of the study is to improve flood susceptibility mapping by focusing on the uncertainty associated with predictor factors and to identify highly vulnerable areas to floods. By doing so, the research seeks to contribute valuable insights and strategies for reducing natural disaster risks, with a particular emphasis on flood hazards in specific regions such as Marib City and Shibam City in Yemen."
Psychology,Machine learning model (RG-DMML) and ensemble algorithm for prediction of students’ retention and graduation in education,"Automated prediction of students' retention and graduation in education using advanced analytical methods such as artificial intelligence (AI), has recently attracted the attention of educators, both in theory and in practice. Whereas invaluable insights and theories for measuring and testing the topic have been proposed, most of the existing methods do not technically highlight the non-trivial factors behind the renowned challenges and attrition. To this effect, by making use of two categories of data collected in a higher education setting about students (i) retention (n = 52262) and (ii) graduation (n = 53639); this study proposes a machine learning model - RG-DMML (retention and graduation data mining and machine learning) and ensemble algorithm for prediction of students' retention and graduation status in education. This was done by training and testing key features that are technically deemed suitable for measuring the constructs (retention and graduation), such as (i) the Average grade of the previous high school, and (ii) the Entry/admission score. The proposed model (RG-DMML) is designed based on the cross industry standard process for data mining (CRISP-DM) methodology, implemented using supervised machine learning technique such as K-Nearest Neighbor (KNN), and validated using the k-fold cross-validation method. The results show that the executed model and algorithm based on the Bagging method and 10-fold cross-validation are efficient and effective for predicting the student's retention and graduation status, with Precision (retention = 0.909, graduation = 0.822), Recall (retention = 1.000, graduation = 0.957), Accuracy (retention = 0.909, graduation = 0.817), F1-Score (retention = 0.952, graduation = 0.885) showing significant high accuracy levels or performance rate, and low Error-rate (retention = 0.090, graduation = 0.182), respectively. In addition, by considering the individual features selected through the Wrapper method in predicting the outputs, the proposed model proved more effective for predicting the students' retention status in comparison to the graduation data. The implications of the models' output and factors that impact the effective prediction or identification of at-risk students, e.g., for timely intervention, counselling, decision-making, and sustainable educational practice are empirically discussed in the study.","['ensemble algorithm', 'supervised machine learning technique', 'K-Nearest Neighbor (KNN)', 'Wrapper method']","The research idea centers on addressing the challenges related to student retention and graduation in higher education, highlighting that existing approaches often overlook the complex factors contributing to these issues. There is a recognized need to better understand and measure the key influences affecting students' continuation and completion of their studies. The primary objective of the study is to predict students' retention and graduation status by examining important features such as previous academic performance and admission scores. This aims to provide insights that can support timely intervention, counseling, and decision-making to improve educational outcomes and promote sustainable practices within educational settings."
Psychology,Diagnosis of Alzheimer's disease via optimized lightweight convolution-attention and structural MRI,"Alzheimer's disease (AD) poses a substantial public health challenge, demanding accurate screening and diagnosis. Identifying AD in its early stages, including mild cognitive impairment (MCI) and healthy control (HC), is crucial given the global aging population. Structural magnetic resonance imaging (sMRI) is essential for understanding the brain's structural changes due to atrophy. While current deep learning networks overlook voxel long-term dependencies, vision transformers (ViT) excel at recognizing such dependencies in images, making them valuable in AD diagnosis. Our proposed method integrates convolution-attention mechanisms in transformer-based classifiers for AD brain datasets, enhancing performance without excessive computing resources. Replacing multi-head attention with lightweight multi-head self-attention (LMHSA), employing inverted residual (IRU) blocks, and introducing local feed-forward networks (LFFN) yields exceptional results. Training on AD datasets with a gradient-centralized optimizer and Adam achieves an impressive accuracy rate of 94.31% for multi-class classification, rising to 95.37% for binary classification (AD vs. HC) and 92.15% for HC vs. MCI. These outcomes surpass existing AD diagnosis approaches, showcasing the model's efficacy. Identifying key brain regions aids future clinical solutions for AD and neurodegenerative diseases. However, this study focused exclusively on the AD Neuroimaging Initiative (ADNI) cohort, emphasizing the need for a more robust, generalizable approach incorporating diverse databases beyond ADNI in future research.","['vision transformers (ViT)', 'convolution-attention mechanisms in transformer-based classifiers', 'lightweight multi-head self-attention (LMHSA)', 'Adam']","The research idea centers on the significant public health challenge posed by Alzheimer's disease (AD) and the critical need for accurate screening and diagnosis, particularly in the early stages such as mild cognitive impairment (MCI) and distinguishing healthy controls (HC). Given the global aging population, understanding structural brain changes associated with AD through imaging techniques is essential for improving early detection. The primary objective of the study is to enhance the identification of AD and its early stages by improving diagnostic accuracy, thereby aiding in the recognition of key brain regions involved in the disease. This focus aims to support future clinical solutions for AD and other neurodegenerative diseases, with an emphasis on developing approaches that can be generalized beyond the current study cohort."
Psychology,Variation in social media sensitivity across people and contexts,"Abstract Social media impacts people’s wellbeing in different ways, but relatively little is known about why this is the case. Here we introduce the construct of “social media sensitivity” to understand how social media and wellbeing associations differ across people and the contexts in which these platforms are used. In a month-long large-scale intensive longitudinal study (total n = 1632; total number of observations = 120,599), we examined for whom and under which circumstances social media was associated with positive and negative changes in social and affective wellbeing. Applying a combination of frequentist and Bayesian multilevel models, we found a small negative average association between social media use AND subsequent wellbeing, but the associations were heterogenous across people. People with psychologically vulnerable dispositions (e.g., those who were depressed, lonely, not satisfied with life) tended to experience heightened negative social media sensitivity in comparison to people who were not psychologically vulnerable. People also experienced heightened negative social media sensitivity when in certain types of places (e.g., in social places, in nature) and while around certain types of people (e.g., around family members, close ties), as compared to using social media in other contexts. Our results suggest that an understanding of the effects of social media on wellbeing should account for the psychological dispositions of social media users, and the physical and social contexts surrounding their use. We discuss theoretical and practical implications of social media sensitivity for scholars, policymakers, and those in the technology industry.",['Bayesian multilevel models'],"The research idea centers on understanding why social media impacts people’s wellbeing in different ways, highlighting the need to explore individual differences and contextual factors that influence these effects. The study introduces the concept of “social media sensitivity” to explain how associations between social media use and wellbeing vary across individuals and the environments in which social media is used. The research objective is to examine for whom and under which circumstances social media use is associated with positive and negative changes in social and affective wellbeing. Specifically, the study aims to identify how psychological vulnerability and different physical and social contexts contribute to variations in social media sensitivity and its impact on wellbeing."
Psychology,Imagined Speech-EEG Detection Using Multivariate Swarm Sparse Decomposition-Based Joint Time-Frequency Analysis for Intuitive BCI,"In brain-computer interface (BCI) applications, imagined speech (IMS) decoding based on electroencephalography (EEG) has established a new neuro-paradigm that offers an intuitive communication tool for physically impaired patients.However, existing IMS-EEG-based BCI systems have introduced difficulties in feasible deployment due to nonstationary EEG signals, suboptimal feature extraction, and constrained multi-class scalability.To address these challenges, we have presented a novel approach using the multivariate swarm-sparse decomposition method (MSSDM) for joint time-frequency (JTF) analysis and further developed a feasible end-to-end framework from multichannel IMS-EEG signals for imagined speech detection.MSSDM employs improved multivariate swarm filtering and sparse spectrum techniques to design optimal filter banks for extracting an ensemble of channel-aligned oscillatory components (CAOCs), significantly enhancing IMS activation-related sub-bands.To enhance channelaligned information, multivariate JTF images have been constructed using joint instantaneous frequency and instantaneous amplitude across channels from the obtained CAOCs.Further, JTFbased deep features (JTFDF) were computed using different pretrained neural networks and mapped most discriminant features using two well-known feature correlation techniques: Canonical correlation analysis and Hellinger distance-based correlation.The proposed method has been tested on the 5-class BCI Competition DB and 6-class Coretto DB IMS datasets.The experimental findings on cross-subject reveal that the novel JTFDF feature-based classification model, MSSDM-SqueezeNet-JTFDF, achieved the highest classification performance against all other existing state-of-theart methods in imagined speech recognition.","['sparse spectrum techniques', 'pretrained neural networks', 'Canonical correlation analysis']","The research idea centers on the challenges faced in developing effective imagined speech decoding systems using brain signals, which hold promise as intuitive communication tools for individuals with physical impairments. Current approaches encounter difficulties due to the variability of brain signals, limitations in extracting meaningful features, and challenges in scaling to multiple speech categories. The study aims to overcome these obstacles to improve the feasibility and accuracy of imagined speech recognition. The primary objective of the study is to develop a novel approach that enhances the detection of imagined speech from brain signals by optimizing the extraction and representation of relevant neural components. This approach seeks to improve classification performance across multiple speech categories and demonstrate superior recognition accuracy compared to existing methods."
Psychology,ERTNet: an interpretable transformer-based framework for EEG emotion recognition,"Background Emotion recognition using EEG signals enables clinicians to assess patients’ emotional states with precision and immediacy. However, the complexity of EEG signal data poses challenges for traditional recognition methods. Deep learning techniques effectively capture the nuanced emotional cues within these signals by leveraging extensive data. Nonetheless, most deep learning techniques lack interpretability while maintaining accuracy. Methods We developed an interpretable end-to-end EEG emotion recognition framework rooted in the hybrid CNN and transformer architecture. Specifically, temporal convolution isolates salient information from EEG signals while filtering out potential high-frequency noise. Spatial convolution discerns the topological connections between channels. Subsequently, the transformer module processes the feature maps to integrate high-level spatiotemporal features, enabling the identification of the prevailing emotional state. Results Experiments’ results demonstrated that our model excels in diverse emotion classification, achieving an accuracy of 74.23% ± 2.59% on the dimensional model (DEAP) and 67.17% ± 1.70% on the discrete model (SEED-V). These results surpass the performances of both CNN and LSTM-based counterparts. Through interpretive analysis, we ascertained that the beta and gamma bands in the EEG signals exert the most significant impact on emotion recognition performance. Notably, our model can independently tailor a Gaussian-like convolution kernel, effectively filtering high-frequency noise from the input EEG data. Discussion Given its robust performance and interpretative capabilities, our proposed framework is a promising tool for EEG-driven emotion brain-computer interface.","['hybrid CNN and transformer architecture', 'temporal convolution', 'spatial convolution', 'transformer module', 'CNN', 'LSTM']","The research idea centers on the challenge of accurately recognizing emotional states from EEG signals, which is important for clinicians to assess patients’ emotions with precision and immediacy. Traditional methods struggle with the complexity of EEG data, and while advanced approaches can capture nuanced emotional cues, they often lack interpretability despite maintaining accuracy. The study aims to address the need for a method that not only effectively identifies emotional states from EEG signals but also provides meaningful insights into the underlying neural features involved. The primary objective of the study is to develop an interpretable framework for emotion recognition using EEG signals that can accurately classify diverse emotional states while highlighting the significant neural frequency bands contributing to emotion recognition performance. This framework seeks to improve both the precision and understanding of emotional state assessment through EEG data."
Psychology,A study on smart home use intention of elderly consumers based on technology acceptance models,"Purpose Smart home devices have great potential to improve the quality of life and independence of older people, positively impacting their health, safety, and comfort. However, Chinese research in this field is still in its early stages. Therefore, more comprehensive and in-depth studies are needed to comprehend the various aspects influencing the acceptance and use of smart homes by older users. Patients and methods This study adopted the Technology Acceptance Model (TAM) and included perceived usefulness, perceived ease of use, usage intention, intergenerational technology support, perceived value, and perceived risk as extension variables to delve deeper into the behavioral intentions of older users in smart home services. The study used a convenience sampling method to randomly distribute 236 questionnaires among older adults over the age of 60 in the school’s community and neighboring urban communities who have experience in smart home use and who can complete human-computer interactions either independently or with the help of others, mainly focusing on the four sections: user characteristics, family situation, experience of use, and usage intention. The study used structural equation modeling (SEM) and factor analysis to analyze the completion of questionnaires. Finally, we conducted a validation analysis of the rationality and scientificity of the model and derived the six dimensions of the model of the influencing factors on the use of smart home products by the elderly and the weight sizes of their corresponding 13 influencing factors. Results The results show that perceived usefulness and perceived ease of use have a positive effect on users’ intention to use smart homes. Perceived ease of use has a positive effect on the perceived usefulness of smart homes. In addition, intergenerational technology support, perceived value, and perceived risk impact users’ perceived usefulness and perceived ease of use of the smart home. Conclusion This research aims to describe the factors influencing older users’ willingness to use smart homes. The findings are not only significant for the elderly in China but also of broad value to other regions and countries facing similar demographic challenges. The development of smart homes not only involves the elderly but is also closely related to all segments of society. The government should increase policy support and guide more social forces to participate in the development of the smart home industry. Service providers and designers should fully understand the demand situation and user experience of target users to develop easy-to-use smart home solutions. At the same time, smart homes, as intelligent products for the elderly, need to focus not only on the basic needs of the elderly such as material life and home safety, but also on the spiritual needs of elderly users. Children or caregivers should always pay attention to the psychological state of the elderly and actively guide them to use smart homes to help them realize their self-worth. We look forward to more research focusing on this area in the future and further exploring the specific issues and solutions involved.",['factor analysis'],"The research idea centers on the potential of smart home devices to enhance the quality of life, independence, health, safety, and comfort of older adults, while recognizing that research on the acceptance and use of such technology among the elderly in China remains limited and underdeveloped. There is a need for more comprehensive and in-depth studies to understand the various factors influencing older users’ willingness to adopt smart home services. The primary objective of the study is to identify and describe the factors that affect older adults’ behavioral intentions to use smart home products, focusing on dimensions such as perceived usefulness, perceived ease of use, intergenerational support, perceived value, and perceived risk. This aims to provide insights that are valuable not only for the elderly population in China but also for other regions facing similar demographic challenges, ultimately guiding the development of smart home solutions that address both the practical and psychological needs of older users."
Psychology,Enhancing Brain Tumor Classification by a Comprehensive Study on Transfer Learning Techniques and Model Efficiency Using MRI Datasets,"Brain tumors, a significant health concern, are a leading cause of mortality globally, with an annual projected increase of 5% by the World Health Organization. This work aims to comprehensively analyze the performance of transfer learning methods in identifying the types of brain tumors, with a particular emphasis on the necessity of prompt identification. The study demonstrates how useful it is to use pre-trained models, including models VGG-16, VGG-19, Inception-v3, ResNet-50, DenseNet, and MobileNet—on MRI datasets and used to obtain a precise classification. Using these methods model accuracy and efficiency have been enhanced. The research aims to contribute to improved treatment planning and patient outcomes by implementing optimal methodologies for precise and automated brain tumor analysis, evaluation framework encompasses vital metrics such as confusion matrices, ROC curves, and the achieved Area Under the Curve (AUC) for each approach. The comprehensive methodology outlined in this paper serves as a systematic guide for the implementation and evaluation of brain tumor classification models utilizing deep learning techniques. The integration of visual representations, code snippets, and performance metrics significantly enhances the clarity and understanding of the proposed approach. Among our proposed algorithms, VGG-16 attains the highest accuracy at 97% and consumes only 22% of time as compared to our previous proposed methodology.","['transfer learning', 'VGG-16', 'VGG-19', 'Inception-v3', 'ResNet-50', 'DenseNet', 'MobileNet']","The research idea addresses the significant health concern posed by brain tumors, which are a leading cause of mortality worldwide and are projected to increase annually. The study highlights the critical need for prompt and accurate identification of brain tumor types to improve patient outcomes. The research objective is to evaluate and enhance the accuracy and efficiency of methods for identifying different types of brain tumors, with the aim of contributing to improved treatment planning and patient care through precise classification. The study seeks to establish an effective approach for brain tumor analysis that supports timely and accurate diagnosis."
Psychology,Building typology classification using convolutional neural networks utilizing multiple ground-level image process for city-scale rapid seismic vulnerability assessment,"Several studies have focused on generating seismic vulnerability maps for earthquake-prone areas, particularly in Indonesia. Building typologies are a key factor in determining vulnerability to earthquakes. However, conducting large-scale field surveys to determine the spatial distribution of building typologies in a city is uneconomical. This paper explores the use of a convolutional neural network (CNN) to automatically detect building typologies from diverse regions in Indonesia, utilizing both conventional and automated building image acquisition processes. In this study, datasets from three distinct image acquisition methods are trained with four unique CNN architectures to identify the best-performing model to classify building typologies. The sample size effect on CNN performance is also investigated. The results showed that randomly sampled Google Street View (GSV) images are the most effective dataset for the CNN model, achieving an f1-score of 84.33%. Among the network architectures tested, MobileNet demonstrated superior performance on the majority of evaluated datasets. As the sample size increases by about 350% in the dataset, there is a positive correlation with up to 2.3% f1-score improvement. Using the best-performing CNN model, two building vulnerability models were employed to assess the spatial distribution of building damage in the urban area of Bandung, considering a hypothetical scenario of an M7 earthquake. Incorporating local construction data, one of the generated maps estimated that approximately 55% of buildings in Bandung would experience moderate to severe structural damage. This study showcases the potential of CNN models in automating regional seismic assessments and providing valuable insights for comprehensive seismic mitigation strategies.","['convolutional neural network (CNN)', 'CNN architectures', 'MobileNet']","The research idea centers on the challenge of assessing seismic vulnerability in earthquake-prone areas, particularly focusing on the importance of building typologies in determining vulnerability. Large-scale field surveys to map the spatial distribution of building types are costly and impractical, creating a need for more efficient approaches to understand and predict earthquake damage. The study aims to address this gap by exploring alternative means to identify building typologies across diverse regions. The primary objective of the study is to evaluate different approaches for detecting building typologies to improve the accuracy of seismic vulnerability assessments. By identifying the spatial distribution of building types, the study seeks to estimate the potential extent of structural damage in urban areas under hypothetical earthquake scenarios, thereby contributing to more effective seismic mitigation strategies."
Psychology,Brain structure ages—A new biomarker for multi‐disease classification,"Age is an important variable to describe the expected brain's anatomy status across the normal aging trajectory. The deviation from that normative aging trajectory may provide some insights into neurological diseases. In neuroimaging, predicted brain age is widely used to analyze different diseases. However, using only the brain age gap information (i.e., the difference between the chronological age and the estimated age) can be not enough informative for disease classification problems. In this paper, we propose to extend the notion of global brain age by estimating brain structure ages using structural magnetic resonance imaging. To this end, an ensemble of deep learning models is first used to estimate a 3D aging map (i.e., voxel-wise age estimation). Then, a 3D segmentation mask is used to obtain the final brain structure ages. This biomarker can be used in several situations. First, it enables to accurately estimate the brain age for the purpose of anomaly detection at the population level. In this situation, our approach outperforms several state-of-the-art methods. Second, brain structure ages can be used to compute the deviation from the normal aging process of each brain structure. This feature can be used in a multi-disease classification task for an accurate differential diagnosis at the subject level. Finally, the brain structure age deviations of individuals can be visualized, providing some insights about brain abnormality and helping clinicians in real medical contexts.",['ensemble of deep learning models'],"The research idea centers on the importance of age as a variable to describe the expected status of brain anatomy throughout the normal aging process, with deviations from this normative trajectory potentially offering insights into neurological diseases. The study addresses the limitation that using only the difference between chronological age and estimated brain age may not provide sufficient information for disease classification. The primary objective of the study is to extend the concept of global brain age by estimating the ages of specific brain structures, enabling more accurate detection of anomalies at the population level and improving differential diagnosis of multiple diseases at the individual level. Additionally, the study aims to provide visualizations of brain structure age deviations to offer insights into brain abnormalities and assist clinicians in medical contexts."
Psychology,"Machine learning in physical activity, sedentary, and sleep behavior research","Abstract The nature of human movement and non-movement behaviors is complex and multifaceted, making their study complicated and challenging. Thanks to the availability of wearable activity monitors, we can now monitor the full spectrum of physical activity, sedentary, and sleep behaviors better than ever before—whether the subjects are elite athletes, children, adults, or individuals with pre-existing medical conditions. The increasing volume of generated data, combined with the inherent complexities of human movement and non-movement behaviors, necessitates the development of new data analysis methods for the research of physical activity, sedentary, and sleep behaviors. The characteristics of machine learning (ML) methods, including their ability to deal with complicated data, make them suitable for such analysis and thus can be an alternative tool to deal with data of this nature. ML can potentially be an excellent tool for solving many traditional problems related to the research of physical activity, sedentary, and sleep behaviors such as activity recognition, posture detection, profile analysis, and correlates research. However, despite this potential, ML has not yet been widely utilized for analyzing and studying these behaviors. In this review, we aim to introduce experts in physical activity, sedentary behavior, and sleep research—individuals who may possess limited familiarity with ML—to the potential applications of these techniques for analyzing their data. We begin by explaining the underlying principles of the ML modeling pipeline, highlighting the challenges and issues that need to be considered when applying ML. We then present the types of ML: supervised and unsupervised learning, and introduce a few ML algorithms frequently used in supervised and unsupervised learning. Finally, we highlight three research areas where ML methodologies have already been used in physical activity, sedentary behavior, and sleep behavior research, emphasizing their successes and challenges. This paper serves as a resource for ML in physical activity, sedentary, and sleep behavior research, offering guidance and resources to facilitate its utilization.","['supervised learning', 'unsupervised learning']","The study addresses the complexity and multifaceted nature of human movement and non-movement behaviors, including physical activity, sedentary behavior, and sleep, which makes their study challenging. With the availability of wearable activity monitors, there is now an unprecedented ability to monitor these behaviors across diverse populations such as elite athletes, children, adults, and individuals with pre-existing medical conditions. However, the increasing volume and complexity of behavioral data require new approaches to better understand these behaviors.

The primary aim of the study is to introduce experts in physical activity, sedentary behavior, and sleep research to novel approaches that can enhance the analysis of their data. The study seeks to highlight the potential applications, successes, and challenges of these approaches in advancing research on physical activity, sedentary behavior, and sleep, thereby providing guidance and resources to facilitate their utilization in this field."
Psychology,A dynamic Bayesian optimized active recommender system for curiosity-driven partially Human-in-the-loop automated experiments,"Abstract Optimization of experimental materials synthesis and characterization through active learning methods has been growing over the last decade, with examples ranging from measurements of diffraction on combinatorial alloys at synchrotrons, to searches through chemical space with automated synthesis robots for perovskites. In virtually all cases, the target property of interest for optimization is defined a priori with the ability to shift the trajectory of the optimization based on human-identified findings during the experiment is lacking. Thus, to highlight the best of both human operators and AI-driven experiments, here we present the development of a human–AI collaborated experimental workflow, via a Bayesian optimized active recommender system (BOARS), to shape targets on the fly with human real-time feedback. Here, the human guidance overpowers AI at early iteration when prior knowledge (uncertainty) is minimal (higher), while the AI overpowers the human during later iterations to accelerate the process with the human-assessed goal. We showcase examples of this framework applied to pre-acquired piezoresponse force spectroscopy of a ferroelectric thin film, and in real-time on an atomic force microscope, with human assessment to find symmetric hysteresis loops. It is found that such features appear more affected by subsurface defects than the local domain structure. This work shows the utility of human–AI approaches for curiosity driven exploration of systems across experimental domains.",['active learning'],"The research idea centers on the challenge of optimizing experimental materials synthesis and characterization by integrating human insight with automated processes, addressing the limitation that target properties are typically predefined without the flexibility to adjust based on human observations during experiments. The study highlights the importance of combining human expertise and real-time feedback with experimental workflows to improve the exploration and understanding of material properties. The primary objective of the study is to develop and demonstrate an experimental workflow that incorporates human guidance alongside automated processes to dynamically shape experimental targets based on real-time human feedback. This approach aims to leverage human knowledge in early stages when uncertainty is high and to enhance the efficiency of the experimental process in later stages, ultimately facilitating curiosity-driven exploration of material systems."
Psychology,Designing AI for mental health diagnosis: challenges from sub-Saharan African value-laden judgements on mental health disorders,"Recently clinicians have become more reliant on technologies such as artificial intelligence (AI) and machine learning (ML) for effective and accurate diagnosis and prognosis of diseases, especially mental health disorders. These remarks, however, apply primarily to Europe, the USA, China and other technologically developed nations. Africa is yet to leverage the potential applications of AI and ML within the medical space. Sub-Saharan African countries are currently disadvantaged economically and infrastructure-wise. Yet precisely, these circumstances create significant opportunities for the deployment of medical AI, which has already been deployed in some places in the continent. However, while AI and ML have come with enormous promises in Africa, there are still challenges when it comes to successfully applying AI and ML designed elsewhere within the African context, especially in diagnosing mental health disorders. We argue, in this paper, that there ought not to be a homogeneous/generic design of AI and ML used in diagnosing mental health disorders. Our claim is grounded on the premise that mental health disorders cannot be diagnosed solely on 'factual evidence' but on both factual evidence and value-laden judgements of what constitutes mental health disorders in sub-Saharan Africa. For ML to play a successful role in diagnosing mental health disorders in sub-Saharan African medical spaces, with a precise focus on South Africa, we allude that it ought to understand what sub-Saharan Africans consider as mental health disorders, that is, the value-laden judgements of some conditions.",['machine learning (ML)'],"The research idea centers on the challenge of accurately diagnosing mental health disorders in sub-Saharan Africa, where economic and infrastructural disadvantages exist compared to more technologically developed regions. The study highlights that mental health diagnoses in this context cannot rely solely on factual evidence but must also incorporate culturally specific, value-laden judgments about what constitutes mental health disorders. The motivation arises from the recognition that existing diagnostic approaches developed elsewhere may not be fully applicable or effective within the African context due to these cultural and contextual differences. The research objective is to emphasize the need for diagnostic frameworks that reflect the unique perspectives and values of sub-Saharan African populations, particularly in South Africa, to improve the understanding and identification of mental health disorders in this region. The study aims to advocate for approaches that integrate both factual evidence and culturally informed judgments in the diagnosis of mental health conditions."
Psychology,EEG-based brain-computer interface methods with the aim of rehabilitating advanced stage ALS patients,"Amyotrophic Lateral Sclerosis (ALS) is a neurodegenerative disease that leads to progressive muscle weakness and paralysis, ultimately resulting in the loss of ability to communicate and control the environment. EEG-based Brain-Computer Interface (BCI) methods have shown promise in providing communication and control with the aim of rehabilitating ALS patients. In particular, P300-based BCI has been widely studied and used for ALS rehabilitation. Other EEG-based BCI methods, such as Motor Imagery (MI) based BCI and Hybrid BCI, have also shown promise in ALS rehabilitation. Nonetheless, EEG-based BCI methods hold great potential for improvement. This review article introduces and reviews FFT, WPD, CSP, CSSP, CSP, and GC feature extraction methods. The Common Spatial Pattern (CSP) is an efficient and common technique for extracting data properties used in BCI systems. In addition, Linear Discriminant Analysis (LDA), Support Vector Machine (SVM), Neural Networks (NN), and Deep Learning (DL) classification methods were introduced and reviewed. SVM is the most appropriate classifier due to its insensitivity to the curse of dimensionality. Also, DL is used in the design of BCI systems and is a good choice for BCI systems based on motor imagery with big datasets. Despite the progress made in the field, there are still challenges to overcome, such as improving the accuracy and reliability of EEG signal detection and developing more intuitive and user-friendly interfaces By using BCI, disabled patients can communicate with their caregivers and control their environment using various devices, including wheelchairs, and robotic arms.","['Linear Discriminant Analysis (LDA)', 'Support Vector Machine (SVM)', 'Neural Networks (NN)', 'Deep Learning (DL)']","The research idea centers on addressing the challenges faced by individuals with Amyotrophic Lateral Sclerosis (ALS), a neurodegenerative disease that causes progressive muscle weakness and paralysis, ultimately leading to the loss of communication and environmental control. The study highlights the potential of brain-based communication methods to aid in the rehabilitation of ALS patients by enabling them to communicate with caregivers and control assistive devices. The motivation lies in improving these communication methods to enhance the quality of life for disabled patients. The primary objective of the study is to review and evaluate existing approaches aimed at facilitating communication and environmental control for ALS patients, with a focus on identifying ways to improve the accuracy, reliability, and user-friendliness of these methods to better support patient rehabilitation and interaction."
Psychology,Brain Tumor Detection for Efficient Adaptation and Superior Diagnostic Precision by Utilizing MBConv-Finetuned-B0 and Advanced Deep Learning,"In the rapidly evolving landscape of medical imaging, our proposed work presents an innovative and efficient approach to brain tumor detection through advanced deep learning methodologies.Central to our methodology is the strategic utilization of pre-trained weights from the formidable MBConv-Finetuned-B0 model, initially honed on the expansive ImageNet dataset, providing a foundation rich in general visual knowledge.Our subsequent fine-tuning process targets specific layers relevant to brain tumor detection, introducing two distinct convolutional layers, MBConv 6, 55, and MBConv 6, 30, meticulously added to the MBConv-Finetuned-B0 base model.These layers are intricately designed to extract and refine features specific to brain tumors, ensuring a nuanced understanding of pathology and enhancing the model's discrimination and accuracy.The flexibility of our methodology is exemplified by the thoughtful consideration of two fine-tuning options: one that adjusts all layers of the model and another that selectively fine-tunes only the proposed layers.We conduct a detailed comparative analysis, including homogeneity and median feature values, placing our work in direct comparison with established techniques such as Ensemble Transfer Learning and Quantum Variational Classifier (ETL & QVC), Ultra-Light Deep Learning (ULDL) Model, Deep Convolutional Neural Network (DCNN), and Deep Learning and Image Processing (DLIP).The results showcase the model's proficiency, achieving an accuracy of 94%, precision of 84%, recall of 92%, F1 score of 88%, and an AUC-ROC of 96%.Notably, our model demonstrates superior performance in terms of homogeneity (vE Homogeneity: 0.93, vN Homogeneity: 0.91, Enhancement Homogeneity: 0.97) and median feature values (Median vE Feature Value: 0.82, Median vN Feature Value: 0.87, Median Enhancement Feature Value: 0.80), providing a comprehensive understanding of its effectiveness in capturing subtle nuances in brain tumor images.","['fine-tuning', 'Quantum Variational Classifier (QVC)', 'Deep Convolutional Neural Network (DCNN)']","The research idea centers on addressing the challenge of accurately detecting brain tumors, which is critical for effective diagnosis and treatment planning. The study is motivated by the need to improve the understanding and identification of subtle pathological features in brain tumor images to enhance diagnostic precision. The primary objective of the study is to develop and evaluate an approach that improves the detection of brain tumors by refining the extraction of tumor-specific features, thereby increasing the accuracy and reliability of tumor identification in medical imaging. This objective aims to provide a more nuanced understanding of brain tumor pathology to support better clinical outcomes."
Psychology,Revisiting drug–protein interaction prediction: a novel global–local perspective,"Abstract Motivation Accurate inference of potential drug–protein interactions (DPIs) aids in understanding drug mechanisms and developing novel treatments. Existing deep learning models, however, struggle with accurate node representation in DPI prediction, limiting their performance. Results We propose a new computational framework that integrates global and local features of nodes in the drug–protein bipartite graph for efficient DPI inference. Initially, we employ pre-trained models to acquire fundamental knowledge of drugs and proteins and to determine their initial features. Subsequently, the MinHash and HyperLogLog algorithms are utilized to estimate the similarity and set cardinality between drug and protein subgraphs, serving as their local features. Then, an energy-constrained diffusion mechanism is integrated into the transformer architecture, capturing interdependencies between nodes in the drug–protein bipartite graph and extracting their global features. Finally, we fuse the local and global features of nodes and employ multilayer perceptrons to predict the likelihood of potential DPIs. A comprehensive and precise node representation guarantees efficient prediction of unknown DPIs by the model. Various experiments validate the accuracy and reliability of our model, with molecular docking results revealing its capability to identify potential DPIs not present in existing databases. This approach is expected to offer valuable insights for furthering drug repurposing and personalized medicine research. Availability and implementation Our code and data are accessible at: https://github.com/ZZCrazy00/DPI.","['transformer architecture', 'multilayer perceptrons']","The research idea centers on the importance of accurately inferring potential drug–protein interactions to enhance the understanding of drug mechanisms and support the development of novel treatments. There is a recognized challenge in achieving precise representation of the relationships between drugs and proteins, which limits the effectiveness of current approaches in predicting these interactions. The primary objective of the study is to improve the inference of drug–protein interactions by integrating both global and local features of the relationships between drugs and proteins. This aims to provide a more comprehensive and precise representation that can facilitate the identification of unknown interactions, ultimately contributing valuable insights for drug repurposing and personalized medicine research."
Psychology,Exploring the frontier: Transformer-based models in EEG signal analysis for brain-computer interfaces,"This review systematically explores the application of transformer-based models in EEG signal processing and brain-computer interface (BCI) development, with a distinct focus on ensuring methodological rigour and adhering to empirical validations within the existing literature. By examining various transformer architectures, such as the Temporal Spatial Transformer Network (TSTN) and EEG Conformer, this review delineates their capabilities in mitigating challenges intrinsic to EEG data, such as noise and artifacts, and their subsequent implications on decoding and classification accuracies across disparate mental tasks. The analytical scope extends to a meticulous examination of attention mechanisms within transformer models, delineating their role in illuminating critical temporal and spatial EEG features and facilitating interpretability in model decision-making processes. The discourse additionally encapsulates emerging works that substantiate the efficacy of transformer models in noise reduction of EEG signals and diversifying applications beyond the conventional motor imagery paradigm. Furthermore, this review elucidates evident gaps and propounds exploratory avenues in the applications of pre-trained transformers in EEG analysis and the potential expansion into real-time and multi-task BCI applications. Collectively, this review distils extant knowledge, navigates through the empirical findings, and puts forward a structured synthesis, thereby serving as a conduit for informed future research endeavours in transformer-enhanced, EEG-based BCI systems.","['transformer-based models', 'attention mechanisms within transformer models']","The research idea centers on addressing the challenges inherent in processing EEG signals, such as noise and artifacts, which affect the accuracy of decoding and classification across various mental tasks. There is a need to ensure methodological rigor and empirical validation in the study of EEG signal processing to improve the interpretability and reliability of findings. The study aims to systematically explore existing approaches that enhance the understanding and application of EEG data in brain-computer interface development. The primary objective of the study is to review and synthesize current knowledge on advanced methods used to mitigate EEG signal challenges, highlight their implications for mental task classification, and identify gaps and future directions for expanding EEG applications beyond traditional paradigms."
Psychology,A Novel EEG-Based Parkinson’s Disease Detection Model Using Multiscale Convolutional Prototype Networks,"Objective and accurate detection of Parkinson's disease (PD) is crucial for timely intervention and treatment. Electroencephalography (EEG) has been proven to characterize PD by measuring brain activity. In recent years, deep learning methods have gained great attention in automated PD detection, but their performance is limited by insufficient data samples. In this article, we propose a novel PD automated detection model named the multiscale convolutional prototype network (MCPNet), which integrates and improves upon multiscale convolutional neural networks (CNNs) and prototype learning. On the one hand, it employs multiscale CNNs to extract brain features from different scales, enhancing feature diversity and utilization. On the other hand, a prototype calibration strategy is introduced to mitigate the effect of data noise on prototype generation, improving the generalization performance of model. Multiple within-dataset and cross-dataset experiments on three different datasets demonstrate the effectiveness of our model in PD detection. The leave-one-subject-out (LOSO) results of within-dataset experiments show that MCPNet achieves an accuracy of 92.5%, a sensitivity of 93.1%, a specificity of 91.9%, and an AUC of 92.4% in cross-subject classification between PD patients and healthy controls. In the cross-dataset classification, the performance of MCPNet is somewhat weakened due to dataset variations. However, this weakening is partially compensated by introducing the prototype calibration strategy. With the introduction of the calibration strategy, the accuracy of cross-dataset classification increases to 90.2%, a 4.0% improvement compared to when it is not used. These results indicate that the proposed model may be a promising tool for automated PD diagnosis.","['multiscale convolutional neural networks (CNNs)', 'prototype learning']","The research idea centers on the critical need for objective and accurate detection of Parkinson's disease (PD) to enable timely intervention and treatment. Since brain activity measured through electroencephalography (EEG) has been shown to characterize PD, improving detection methods based on these measurements is essential. The study addresses challenges related to limited data samples that affect the performance of current automated PD detection approaches. The primary objective of the study is to develop and evaluate a novel approach that enhances the detection of Parkinson's disease by effectively capturing brain features across different scales and improving the reliability of classification despite data variability. This aims to provide a more accurate and generalizable tool for distinguishing PD patients from healthy individuals."
Psychology,DiffMDD: A Diffusion-Based Deep Learning Framework for MDD Diagnosis Using EEG,"Major Depression Disorder (MDD) is a common yet destructive mental disorder that affects millions of people worldwide. Making early and accurate diagnosis of it is very meaningful. Recently, EEG, a non-invasive technique of recording spontaneous electrical activity of brains, has been widely used for MDD diagnosis. However, there are still some challenges in data quality and data size of EEG: (1) A large amount of noise is inevitable during EEG collection, making it difficult to extract discriminative features from raw EEG; (2) It is difficult to recruit a large number of subjects to collect sufficient and diverse data for model training. Both of the challenges cause the overfitting problem, especially for deep learning methods. In this paper, we propose DiffMDD, a diffusion-based deep learning framework for MDD diagnosis using EEG. Specifically, we extract more noise-irrelevant features to improve the model's robustness by designing the Forward Diffusion Noisy Training Module. Then we increase the size and diversity of data to help the model learn more generalized features by designing the Reverse Diffusion Data Augmentation Module. Finally, we re-train the classifier on the augmented dataset for MDD diagnosis. We conducted comprehensive experiments to test the overall performance and each module's effectiveness. The framework was validated on two public MDD diagnosis datasets, achieving the state-of-the-art performance.",['diffusion-based deep learning framework'],"The study addresses the significant challenge of early and accurate diagnosis of Major Depression Disorder (MDD), a common and destructive mental health condition affecting millions globally. It highlights difficulties related to the quality and quantity of EEG data used for diagnosing MDD, including the presence of noise during data collection and the limited availability of diverse subject data. These challenges hinder the extraction of reliable features necessary for effective diagnosis. The primary aim of the study is to improve the robustness and generalizability of MDD diagnosis by enhancing the quality of EEG features and increasing the diversity of data available for analysis, ultimately facilitating more accurate identification of the disorder."
Psychology,Predicting University Student Graduation Using Academic Performance and Machine Learning: A Systematic Literature Review,"Predicting university student graduation is a beneficial tool for both students and institutions. With the help of this predictive capacity, students may make well-informed decisions about their academic and career paths, and institutions can proactively identify students who may not graduate and offer tailored support to ensure their success. The use of machine learning for predicting university student graduation has drawn more attention in recent years. Large datasets of student academic performance data can be used to train machine learning algorithms to identify patterns that are applicable in predicting future outcomes. In accordance with some studies, this approach predicts student graduation with an accuracy rate as high as 90%. Many SLRs have been conducted in this field, but there are still limitations, including not discussing the predictive models and algorithms used, a lack of coverage of the machine learning algorithms applied, small database coverage, keyword selection that does not cover all synonyms relevant to the investigation, and less specific data collection transparency. By delving into the limitations of existing SLRs on this topic, this research not only enhances the understanding of machine learning applications in forecasting student graduation but also fills a crucial gap in the literature. The inclusion of weaknesses in current SLRs provides a foundation for justifying the need for this study, emphasizing the necessity of a more nuanced and comprehensive review to advance the field and guide future research efforts in smart learning environments. This research conducts a thorough systematic review of the existing literature on machine learning-based student graduation prediction models from 70 journal articles from 2018 through 2023 that are pertinent. This review includes the various machine learning algorithms that have been implemented, the various academic performance data that was obtained from students, and the effectiveness of the models that have been developed. It also discusses the difficulties and potential advantages of utilizing machine learning to predict student graduation. The review indicates that the most common approach employed is the prediction of students' academic performance, which relies on data obtained from the Learning Management System and Student Information System. The primary data utilized for prediction purposes consists Student retention and time of academic and behavioral information. Among the various algorithms employed, Support Vector Machine and Random Forest are the most commonly utilized. This study makes a significant contribution to the advancement of learner modules within the smart learning environment.","['Support Vector Machine', 'Random Forest']","The research idea centers on the importance of predicting university student graduation to benefit both students and educational institutions. Accurate prediction enables students to make informed decisions about their academic and career paths, while institutions can identify at-risk students early and provide tailored support to improve graduation outcomes. Despite existing studies, there remain limitations in the current literature reviews, such as insufficient discussion of predictive approaches and incomplete data coverage, highlighting a need for a more comprehensive understanding of this area. The study addresses these gaps to enhance knowledge about factors influencing student graduation and to support efforts aimed at improving student success.

The primary objective of this study is to conduct a thorough systematic review of the existing literature on student graduation prediction, focusing on academic performance and related factors influencing graduation outcomes. It aims to evaluate the effectiveness of various approaches used to forecast student graduation, discuss challenges and potential benefits associated with these predictions, and provide a clearer understanding of how academic and behavioral information contributes to student retention and timely graduation. Through this comprehensive review, the study seeks to advance knowledge that can inform future research and support interventions designed to improve student success in higher education."
Psychology,Combining artificial and human intelligence to manage cross-cultural knowledge in humanitarian logistics: a Yin–Yang dialectic systems view of knowledge creation,"Purpose Aiming to resolve cross-cultural paradoxes in combining artificial intelligence (AI) with human intelligence (HI) for international humanitarian logistics, this paper aims to adopt an unorthodox Yin–Yang dialectic approach to address how AI–HI interactions can be interpreted as a sophisticated cross-cultural knowledge creation (KC) system that enables more effective decision-making for providing humanitarian relief across borders. Design/methodology/approach This paper is conceptual and pragmatic in nature, whereas its structure design follows the requirements of a real impact study. Findings Based on experimental information and logical reasoning, the authors first identify three critical cross-cultural challenges in AI–HI collaboration: paradoxes of building a cross-cultural KC system, paradoxes of integrative AI and HI in moral judgement and paradoxes of processing moral-related information with emotions in AI–HI collaboration. Then applying the Yin–Yang dialectic to interpret Klir’s epistemological frame (1993), the authors propose an unconventional stratified system of cross-cultural KC for understanding integrative AI–HI decision-making for humanitarian logistics across cultures. Practical implications This paper aids not only in deeply understanding complex issues stemming from human emotions and cultural cognitions in the context of cross-border humanitarian logistics, but also equips culturally-diverse stakeholders to effectively navigate these challenges and their potential ramifications. It enhances the decision-making process and optimizes the synergy between AI and HI for cross-cultural humanitarian logistics. Originality/value The originality lies in the use of a cognitive methodology of the Yin–Yang dialectic to metaphorize the dynamic genesis of integrative AI-HI KC for international humanitarian logistics. Based on system science and knowledge management, this paper applies game theory, multi-objective optimization and Markov decision process to operationalize the conceptual framework in the context of cross-cultural humanitarian logistics.",['Markov decision process'],"The research idea centers on addressing the complex challenges that arise from cross-cultural interactions in international humanitarian logistics, particularly focusing on how human intelligence and cultural cognition influence decision-making processes across borders. The study highlights paradoxes related to moral judgment and emotional processing within diverse cultural contexts, emphasizing the need to better understand these dynamics to improve humanitarian relief efforts. The primary objective of the study is to explore how cross-cultural knowledge creation can be interpreted and enhanced to enable more effective decision-making in humanitarian logistics. It aims to provide a deeper understanding of the emotional and cultural factors affecting collaboration among culturally diverse stakeholders to optimize decision-making in cross-border humanitarian contexts."
Psychology,Chatbots and Large Language Models in Radiology: A Practical Primer for Clinical and Research Applications,"Although chatbots have existed for decades, the emergence of transformer-based large language models (LLMs) has captivated the world through the most recent wave of artificial intelligence chatbots, including ChatGPT. Transformers are a type of neural network architecture that enables better contextual understanding of language and efficient training on massive amounts of unlabeled data, such as unstructured text from the internet. As LLMs have increased in size, their improved performance and emergent abilities have revolutionized natural language processing. Since language is integral to human thought, applications based on LLMs have transformative potential in many industries. In fact, LLM-based chatbots have demonstrated human-level performance on many professional benchmarks, including in radiology. LLMs offer numerous clinical and research applications in radiology, several of which have been explored in the literature with encouraging results. Multimodal LLMs can simultaneously interpret text and images to generate reports, closely mimicking current diagnostic pathways in radiology. Thus, from requisition to report, LLMs have the opportunity to positively impact nearly every step of the radiology journey. Yet, these impressive models are not without limitations. This article reviews the limitations of LLMs and mitigation strategies, as well as potential uses of LLMs, including multimodal models. Also reviewed are existing LLM-based applications that can enhance efficiency in supervised settings.","['transformer-based large language models (LLMs)', 'Transformers', 'Multimodal LLMs']","The research idea centers on the transformative potential of advanced language-based technologies in understanding and processing human language, which is fundamental to human thought and communication. These technologies have shown promising applications in professional fields such as radiology, where they can mimic diagnostic processes and improve various stages of the clinical workflow. However, despite their impressive capabilities, there are notable limitations that need to be addressed to fully realize their benefits. The primary objective of the study is to review the limitations and mitigation strategies of these language-based technologies, explore their potential uses including multimodal applications, and examine existing implementations that enhance efficiency in supervised clinical settings."
Psychology,Detecting hallucinations in large language models using semantic entropy,"Abstract Large language model (LLM) systems, such as ChatGPT 1 or Gemini 2 , can show impressive reasoning and question-answering capabilities but often ‘hallucinate’ false outputs and unsubstantiated answers 3,4 . Answering unreliably or without the necessary information prevents adoption in diverse fields, with problems including fabrication of legal precedents 5 or untrue facts in news articles 6 and even posing a risk to human life in medical domains such as radiology 7 . Encouraging truthfulness through supervision or reinforcement has been only partially successful 8 . Researchers need a general method for detecting hallucinations in LLMs that works even with new and unseen questions to which humans might not know the answer. Here we develop new methods grounded in statistics, proposing entropy-based uncertainty estimators for LLMs to detect a subset of hallucinations—confabulations—which are arbitrary and incorrect generations. Our method addresses the fact that one idea can be expressed in many ways by computing uncertainty at the level of meaning rather than specific sequences of words. Our method works across datasets and tasks without a priori knowledge of the task, requires no task-specific data and robustly generalizes to new tasks not seen before. By detecting when a prompt is likely to produce a confabulation, our method helps users understand when they must take extra care with LLMs and opens up new possibilities for using LLMs that are otherwise prevented by their unreliability.",['entropy-based uncertainty estimators'],"The research idea centers on the problem of unreliable and false outputs produced by large language models, which hinder their adoption in critical fields such as law, journalism, and medicine due to the risk of fabricating untrue information. This issue of hallucination, where models generate arbitrary and incorrect content, poses significant challenges for ensuring truthfulness and safety in various applications. The study is motivated by the need for a general approach to detect these hallucinations, especially in situations involving new or unseen questions that even humans might find difficult to answer. The primary objective of the study is to develop a method that can identify when such false or confabulated responses are likely to occur, thereby helping users recognize when extra caution is necessary. This approach aims to improve the reliability of responses across different tasks and domains without requiring prior knowledge or task-specific information, ultimately facilitating safer and more trustworthy use of language-based systems."
Psychology,Comparing the quality of human and ChatGPT feedback of students’ writing,"Offering students formative feedback on their writing is an effective way to facilitate writing development. Recent advances in AI (i.e., ChatGPT) may function as an automated writing evaluation tool, increasing the amount of feedback students receive and diminishing the burden on teachers to provide frequent feedback to large classes. We examined the ability of generative AI (ChatGPT) to provide formative feedback. We compared the quality of human and AI feedback by scoring the feedback each provided on secondary student essays. We scored the degree to which feedback (a) was criteria-based, (b) provided clear directions for improvement, (c) was accurate, (d) prioritized essential features, and (e) used a supportive tone. 200 pieces of human-generated formative feedback and 200 pieces of AI-generated formative feedback for the same essays. We examined whether ChatGPT and human feedback differed in quality for the whole sample, for compositions that differed in overall quality, and for native English speakers and English learners by comparing descriptive statistics and effect sizes. Human raters were better at providing high-quality feedback to students in all categories other than criteria-based. AI and humans showed differences in feedback quality based on essay quality. Feedback did not vary by language status for humans or AI. Well-trained evaluators provided higher quality feedback than ChatGPT. Considering the ease of generating feedback through ChatGPT and its overall quality, generative AI may still be useful in some contexts, particularly in formative early drafts or instances where a well-trained educator is unavailable.",['generative AI (ChatGPT)'],"The research idea centers on the importance of providing students with formative feedback to support their writing development and the challenge teachers face in delivering frequent, high-quality feedback to large classes. The study addresses the potential role of automated tools in increasing the amount of feedback students receive while reducing the burden on educators. The primary objective of the study is to evaluate and compare the quality of formative feedback provided by humans and an automated source on secondary student essays. Specifically, the study aims to assess differences in feedback quality across various criteria, essay quality levels, and language backgrounds to determine the effectiveness and potential utility of automated feedback in educational contexts."
Psychology,Application of generative artificial intelligence (GenAI) in language teaching and learning: A scoping literature review,"This scoping literature review examines the application of Generative Artificial Intelligence (GenAI), a disruptive technology, in language teaching and learning. Since its launch in November 2022, GenAI has captured global attention with OpenAI's ChatGPT, powered by the generative pre-trained transformer-3 (GPT-3) large-language model. The emergence of GenAI holds immense implications across various domains, including language education. This review aims to provide an overview of the current state of research and identify research gaps and future directions in this emerging field. The review follows the PRISMA-ScR guidelines and includes eligible publications published between 2017 and July 2023. Four electronic databases were searched and 41 of the 224 initial papers were eventually selected for review. The findings reveal key terms related to GenAI in language education, the most researched language study and education levels, areas of research, attitudes towards GenAI, and the potential benefits and challenges of GenAI application. The review highlights several research gaps, including the need for more empirical studies to assess the effectiveness and impact of GenAI tools, discussion of ethical considerations, targeted interventions for specific language skills, and stakeholder engagement in responsible integration. Educators are encouraged to incorporate GenAI tools into their teaching practices while remaining vigilant about potential risks. Continuous professional development for educators is crucial to ensure informed decision-making and effective integration of GenAI tools. This scoping review contributes to the existing knowledge on the use of GenAI in language education and informs future research and practice in this disruptive and rapidly evolving field.",['generative pre-trained transformer-3 (GPT-3)'],"The research idea centers on the significant impact and emerging role of new technologies in language teaching and learning, highlighting the need to understand their implications within educational contexts. There is a recognized gap in empirical studies assessing the effectiveness and impact of these technologies, as well as a need to address ethical considerations and develop targeted interventions for specific language skills. The primary objective of the study is to provide an overview of the current state of research on the application of these technologies in language education, identify existing research gaps, and suggest future directions. The study aims to inform educators and researchers by highlighting key areas such as attitudes toward these tools, potential benefits and challenges, and the importance of professional development for effective and responsible integration in teaching practices."
Psychology,Can large language models replace humans in systematic reviews? Evaluating <scp>GPT</scp>‐4's efficacy in screening and extracting data from peer‐reviewed and grey literature in multiple languages,"Systematic reviews are vital for guiding practice, research and policy, although they are often slow and labour-intensive. Large language models (LLMs) could speed up and automate systematic reviews, but their performance in such tasks has yet to be comprehensively evaluated against humans, and no study has tested Generative Pre-Trained Transformer (GPT)-4, the biggest LLM so far. This pre-registered study uses a ""human-out-of-the-loop"" approach to evaluate GPT-4's capability in title/abstract screening, full-text review and data extraction across various literature types and languages. Although GPT-4 had accuracy on par with human performance in some tasks, results were skewed by chance agreement and dataset imbalance. Adjusting for these caused performance scores to drop across all stages: for data extraction, performance was moderate, and for screening, it ranged from none in highly balanced literature datasets (~1:1) to moderate in those datasets where the ratio of inclusion to exclusion in studies was imbalanced (~1:3). When screening full-text literature using highly reliable prompts, GPT-4's performance was more robust, reaching ""human-like"" levels. Although our findings indicate that, currently, substantial caution should be exercised if LLMs are being used to conduct systematic reviews, they also offer preliminary evidence that, for certain review tasks delivered under specific conditions, LLMs can rival human performance.",['Generative Pre-Trained Transformer (GPT)-4'],"The research idea centers on the importance of systematic reviews for guiding practice, research, and policy, while highlighting the challenges posed by their slow and labor-intensive nature. The study addresses the need to evaluate alternative approaches that could potentially expedite these reviews without compromising quality. The primary objective of the study is to comprehensively assess the capability of a new approach in performing key tasks involved in systematic reviews, such as screening and data extraction, across various types of literature and languages. The study aims to determine how well this approach performs compared to human reviewers and to identify the conditions under which it may achieve human-like levels of accuracy."
Psychology,Exploring AI-mediated informal digital learning of English (AI-IDLE): a mixed-method investigation of Chinese EFL learners’ AI adoption and experiences,"Recent advancements in natural language processing and large language models have ushered language learning into the age of artificial intelligence (AI). Recognizing the affordances of generative AI tools, this paper aims to examine the degree to which L2 learners accepted and leveraged large language model platforms (e.g. ChatGPT, Bing Chat) for the informal digital learning of English (IDLE) purposes. Employing an explanatory sequential mixed-method design, this study draws on the technology acceptance model (TAM) and collects data via an adapted TAM questionnaire and an interview guide. A total of 867 Chinese EFL (English as a foreign language) learners answered the online survey, while 20 attended the post-survey interviews. Drawing on a validated structural model that elucidates the inter-factor relationships of perceived ease of use, perceived usefulness, intention to use, and actual use, the quantitative analysis provides statistical accounts for EFL learners' adoption of Generative Pre-trained Transformer (GPT) technologies. The qualitative findings, derived from the interview data, reveal three key themes: (1) how perceived usefulness of chatbots for IDLE emerges from hands-on experimentation with these tools; (2) how intention to use increases as learners negotiate chatbot affordances and constraints; and (3) how actual use of chatbots for IDLE involves using these tools as tutors or conversation partners. Connections between quantitative and qualitative findings enhance our understanding of how EFL learners negotiate the affordances and constraints of highly capable AI technologies to participate in creative IDLE practices. By understanding these practices, this study draws attention to the attitudes and practices that constitute AI literacies, ultimately offering implications for future classroom practices and research.",['Generative Pre-trained Transformer (GPT)'],"The research idea centers on understanding how second language (L2) learners engage with and accept new digital tools for informal English learning outside the classroom. It addresses the motivation to explore learners’ attitudes and behaviors toward using advanced language platforms to support their English as a foreign language (EFL) development in informal settings. The study recognizes the importance of examining learners’ perceptions and actual use of these tools to better comprehend their role in language learning practices. The primary objective of the study is to investigate the extent to which Chinese EFL learners accept and utilize large language model platforms for informal digital English learning purposes. It aims to elucidate the relationships between learners’ perceived ease of use, perceived usefulness, intention to use, and actual use of these platforms, as well as to explore learners’ experiences and attitudes toward integrating these tools as part of their language learning activities."
Psychology,TRANSFORMING FINTECH FRAUD DETECTION WITH ADVANCED ARTIFICIAL INTELLIGENCE ALGORITHMS,"The rapid evolution of financial technology (fintech) platforms has exponentially increased the volume and sophistication of financial transactions, concurrently elevating the risk and complexity of fraudulent activities. This necessitates a paradigm shift in fraud detection methodologies towards more agile, accurate, and predictive solutions. This paper presents a comprehensive study on the transformative potential of advanced Artificial Intelligence (AI) algorithms in enhancing fintech fraud detection mechanisms. By leveraging cutting-edge AI techniques including deep learning, machine learning, and natural language processing, this research aims to develop a robust fraud detection framework capable of identifying, analyzing, and preventing fraudulent transactions in real-time.&#x0D; Our methodology encompasses the deployment of several AI algorithms on extensive datasets comprising genuine and fraudulent financial transactions. Through a comparative analysis, we identify the most effective algorithms in terms of accuracy, efficiency, and scalability. Key findings reveal that deep learning models, particularly those employing neural networks, outperform traditional machine learning models in detecting complex and nuanced fraudulent activities. Furthermore, the integration of natural language processing enables the extraction and analysis of unstructured data, significantly enhancing the detection capabilities.&#x0D; Conclusively, this paper underscores the critical role of advanced AI algorithms in revolutionizing fintech fraud detection. It highlights the superior performance of AI-based models over conventional methods, offering fintech platforms a more dynamic and predictive approach to fraud prevention. This research not only contributes to the academic discourse on financial security but also provides practical insights for fintech companies striving to safeguard their operations against fraud.&#x0D; Keywords: Artificial Intelligence, Fintech, Fraud Detection, Ethical Ai, Regulatory Compliance, Data Privacy, Algorithmic Bias, Predictive Analytics, Blockchain Technology, Quantum Computing, Interdisciplinary Collaboration, Innovation, Transparency, Accountability, Continuous Learning, Ethical Principles, Real-Time Processing, Financial Sector.","['deep learning', 'machine learning', 'neural networks']","The study addresses the increasing complexity and risk of fraudulent activities resulting from the rapid growth and sophistication of financial technology platforms. This escalation in fraudulent behavior creates a pressing need for more effective and agile approaches to detect and prevent fraud within financial transactions. The primary aim of the research is to explore and enhance fraud detection mechanisms in fintech by developing a robust framework capable of identifying, analyzing, and preventing fraudulent transactions in real-time. The study seeks to improve the accuracy and efficiency of fraud detection to better safeguard financial operations against increasingly complex fraudulent activities."
Psychology,Mental-LLM,"Advances in large language models (LLMs) have empowered a variety of applications. However, there is still a significant gap in research when it comes to understanding and enhancing the capabilities of LLMs in the field of mental health. In this work, we present a comprehensive evaluation of multiple LLMs on various mental health prediction tasks via online text data, including Alpaca, Alpaca-LoRA, FLAN-T5, GPT-3.5, and GPT-4. We conduct a broad range of experiments, covering zero-shot prompting, few-shot prompting, and instruction fine-tuning. The results indicate a promising yet limited performance of LLMs with zero-shot and few-shot prompt designs for mental health tasks. More importantly, our experiments show that instruction finetuning can significantly boost the performance of LLMs for all tasks simultaneously. Our best-finetuned models, Mental-Alpaca and Mental-FLAN-T5, outperform the best prompt design of GPT-3.5 (25 and 15 times bigger) by 10.9% on balanced accuracy and the best of GPT-4 (250 and 150 times bigger) by 4.8%. They further perform on par with the state-of-the-art task-specific language model. We also conduct an exploratory case study on LLMs' capability on mental health reasoning tasks, illustrating the promising capability of certain models such as GPT-4. We summarize our findings into a set of action guidelines for potential methods to enhance LLMs' capability for mental health tasks. Meanwhile, we also emphasize the important limitations before achieving deployability in real-world mental health settings, such as known racial and gender bias. We highlight the important ethical risks accompanying this line of research.","['zero-shot prompting', 'few-shot prompting', 'instruction fine-tuning']","The research idea centers on addressing the significant gap in understanding and improving the capabilities related to mental health within current approaches. Despite advances in related technologies, there remains a need to evaluate and enhance performance specifically for mental health prediction and reasoning tasks. The study is motivated by the potential to better support mental health applications while acknowledging existing limitations and ethical concerns such as bias. The primary objective of the study is to comprehensively evaluate various approaches on multiple mental health prediction tasks using online text data, aiming to identify methods that can significantly improve performance across these tasks. Additionally, the study seeks to explore the reasoning capabilities related to mental health and to provide guidelines for enhancing effectiveness while highlighting important ethical considerations before real-world deployment."
Psychology,Human-AI collaboration patterns in AI-assisted academic writing,"Artificial Intelligence (AI) has increasingly influenced higher education, notably in academic writing where AI-powered assisting tools offer both opportunities and challenges. Recently, the rapid growth of generative AI (GAI) has brought its impacts into sharper focus, yet the dynamics of its utilisation in academic writing remain largely unexplored. This paper focuses on examining the nature of human-AI interactions in academic writing, specifically investigating the strategies doctoral students employ when collaborating with a GAI-powered assisting tool. This study involves 626 recorded activities on how ten doctoral students interact with GAI-powered assisting tool during academic writing. AI-driven learning analytics approach was adopted for three layered analyses: (1) data pre-processing and analysis with quantitative content analysis, (2) sequence analysis with Hidden Markov Model (HMM) and hierarchical sequence clustering, and (3) pattern analysis with process mining. Findings indicate that doctoral students engaging in iterative, highly interactive processes with the GAI-powered assisting tool generally achieve better performance in the writing task. In contrast, those who use GAI merely as a supplementary information source, maintaining a linear writing approach, tend to get lower writing performance. This study points to the need for further investigations into human-AI collaboration in learning in higher education, with implications for tailored educational strategies and solutions.",['Hidden Markov Model (HMM)'],"The study addresses the growing influence of generative AI on academic writing in higher education, highlighting both the opportunities and challenges it presents. Despite the increasing use of AI-assisted tools, the dynamics of how doctoral students engage with these tools during academic writing remain largely unexplored. The primary aim of the study is to examine the nature of interactions between doctoral students and AI-assisted tools in academic writing, specifically investigating the strategies these students employ when collaborating with such tools. The research seeks to understand how different interaction patterns relate to writing performance, with the goal of informing tailored educational strategies in higher education."
Psychology,Recent advancements and challenges of NLP-based sentiment analysis: A state-of-the-art review,"Sentiment analysis is a method within natural language processing that evaluates and identifies the emotional tone or mood conveyed in textual data. Scrutinizing words and phrases categorizes them into positive, negative, or neutral sentiments. The significance of sentiment analysis lies in its capacity to derive valuable insights from extensive textual data, empowering businesses to grasp customer sentiments, make informed choices, and enhance their offerings. For the further advancement of sentiment analysis, gaining a deep understanding of its algorithms, applications, current performance, and challenges is imperative. Therefore, in this extensive survey, we began exploring the vast array of application domains for sentiment analysis, scrutinizing them within the context of existing research. We then delved into prevalent pre-processing techniques, datasets, and evaluation metrics to enhance comprehension. We also explored Machine Learning, Deep Learning, Large Language Models and Pre-trained models in sentiment analysis, providing insights into their advantages and drawbacks. Subsequently, we precisely reviewed the experimental results and limitations of recent state-of-the-art articles. Finally, we discussed the diverse challenges encountered in sentiment analysis and proposed future research directions to mitigate these concerns. This extensive review provides a complete understanding of sentiment analysis, covering its models, application domains, results analysis, challenges, and research directions.","['Machine Learning', 'Deep Learning']","The research idea centers on the importance of understanding the emotional tone or mood conveyed in textual data to gain valuable insights into human sentiments. This understanding is crucial for interpreting positive, negative, or neutral feelings expressed in language, which can inform decision-making and improve various applications that rely on sentiment interpretation. The study recognizes the need to thoroughly examine the current state, challenges, and applications of sentiment evaluation to advance knowledge in this area. The primary objective of the study is to provide a comprehensive review of the existing research on sentiment evaluation, including its application domains, current performance, and challenges. It aims to enhance understanding by scrutinizing relevant techniques, datasets, and evaluation criteria, as well as discussing limitations and proposing future directions to address ongoing issues in the field."
Psychology,Artificial intelligence (AI) learning tools in K-12 education: A scoping review,"Abstract Artificial intelligence (AI) literacy is a global strategic objective in education. However, little is known about how AI should be taught. In this paper, 46 studies in academic conferences and journals are reviewed to investigate pedagogical strategies, learning tools, assessment methods in AI literacy education in K-12 contexts, and students’ learning outcomes. The investigation reveals that the promotion of AI literacy education has seen significant progress in the past two decades. This highlights that intelligent agents, including Google’s Teachable Machine, Learning ML, and Machine Learning for Kids, are age-appropriate tools for AI literacy education in K-12 contexts. Kindergarten students can benefit from learning tools such as PopBots, while software devices, such as Scratch and Python, which help to develop the computational thinking of AI algorithms, can be introduced to both primary and secondary schools. The research shows that project-based, human–computer collaborative learning and play- and game-based approaches, with constructivist methodologies, have been applied frequently in AI literacy education. Cognitive, affective, and behavioral learning outcomes, course satisfaction and soft skills acquisition have been reported. The paper informs educators of appropriate learning tools, pedagogical strategies, assessment methodologies in AI literacy education, and students’ learning outcomes. Research implications and future research directions within the K-12 context are also discussed.",['Teachable Machine'],"The research idea centers on the growing importance of literacy in a specific emerging field as a global strategic objective in education, while highlighting the current lack of understanding regarding effective teaching methods for this subject in K-12 contexts. The study addresses the need to explore how educational strategies, learning tools, and assessment methods contribute to students’ learning outcomes in this area. The primary objective of the study is to investigate and review existing pedagogical strategies, learning tools, and assessment methods used in K-12 education to promote literacy in this field, as well as to examine the cognitive, affective, and behavioral learning outcomes, course satisfaction, and soft skills acquisition reported in the literature. The study aims to provide educators with informed guidance on appropriate educational approaches and to discuss implications and future directions for literacy education within the K-12 context."
Psychology,A Comprehensive Survey on Source-Free Domain Adaptation,"Over the past decade, domain adaptation has become a widely studied branch of transfer learning which aims to improve performance on target domains by leveraging knowledge from the source domain. Conventional domain adaptation methods often assume access to both source and target domain data simultaneously, which may not be feasible in real-world scenarios due to privacy and confidentiality concerns. As a result, the research of Source-Free Domain Adaptation (SFDA) has drawn growing attention in recent years, which only utilizes the source-trained model and unlabeled target data to adapt to the target domain. Despite the rapid explosion of SFDA work, there has been no timely and comprehensive survey in the field. To fill this gap, we provide a comprehensive survey of recent advances in SFDA and organize them into a unified categorization scheme based on the framework of transfer learning. Instead of presenting each approach independently, we modularize several components of each method to more clearly illustrate their relationships and mechanisms in light of the composite properties of each method. Furthermore, we compare the results of more than 30 representative SFDA methods on three popular classification benchmarks, namely Office-31, Office-home, and VisDA, to explore the effectiveness of various technical routes and the combination effects among them. Additionally, we briefly introduce the applications of SFDA and related fields. Drawing on our analysis of the challenges confronting SFDA, we offer some insights into future research directions and potential settings.","['domain adaptation', 'transfer learning', 'Source-Free Domain Adaptation (SFDA)']","The research idea centers on addressing the challenge of adapting psychological models or knowledge from one domain to another when direct access to original source data is restricted due to privacy and confidentiality concerns. This issue is significant because traditional approaches often require simultaneous access to both source and target domain information, which is not always practical in real-world psychological research or applications. The study aims to explore how adaptation can occur effectively using only previously developed knowledge and new, unlabeled data from the target domain. The primary objective of the study is to provide a comprehensive overview and categorization of recent advances in this area of adaptation, clarifying the relationships and mechanisms among different approaches. Additionally, the study seeks to evaluate the effectiveness of various strategies across multiple established benchmarks and to offer insights into future directions and potential applications within psychological contexts."
Psychology,AI-Driven Clinical Decision Support Systems: An Ongoing Pursuit of Potential,"Clinical Decision Support Systems (CDSS) are essential tools in contemporary healthcare, enhancing clinicians' decisions and patient outcomes. The integration of artificial intelligence (AI) is now revolutionizing CDSS even further. This review delves into AI technologies transforming CDSS, their applications in healthcare decision-making, associated challenges, and the potential trajectory toward fully realizing AI-CDSS's potential. The review begins by laying the groundwork with a definition of CDSS and its function within the healthcare field. It then highlights the increasingly significant role that AI is playing in enhancing CDSS effectiveness and efficiency, underlining its evolving prominence in shaping healthcare practices. It examines the integration of AI technologies into CDSS, including machine learning algorithms like neural networks and decision trees, natural language processing, and deep learning. It also addresses the challenges associated with AI integration, such as interpretability and bias. We then shift to AI applications within CDSS, with real-life examples of AI-driven diagnostics, personalized treatment recommendations, risk prediction, early intervention, and AI-assisted clinical documentation. The review emphasizes user-centered design in AI-CDSS integration, addressing usability, trust, workflow, and ethical and legal considerations. It acknowledges prevailing obstacles and suggests strategies for successful AI-CDSS adoption, highlighting the need for workflow alignment and interdisciplinary collaboration. The review concludes by summarizing key findings, underscoring AI's transformative potential in CDSS, and advocating for continued research and innovation. It emphasizes the need for collaborative efforts to realize a future where AI-powered CDSS optimizes healthcare delivery and improves patient outcomes.","['neural networks', 'decision trees', 'deep learning']","The study addresses the critical role of clinical decision support systems (CDSS) in improving healthcare delivery by enhancing clinicians' decisions and patient outcomes. It highlights the evolving challenges and opportunities in integrating advanced technologies into healthcare decision-making processes, emphasizing the importance of usability, trust, workflow alignment, and ethical considerations. The primary objective of the study is to review the current state and applications of these technologies within CDSS, identify associated challenges such as interpretability and bias, and propose strategies for successful adoption. The study aims to underscore the transformative potential of these systems in optimizing healthcare practices and improving patient outcomes through continued research and interdisciplinary collaboration."
Psychology,Integration of Generative AI Techniques and Applications in Student Behavior and Cognitive Achievement in Arab Higher Education,"The integration of Artificial Intelligence (AI) in higher education has the power to revolutionize the learning experience by fostering engagement, personalization, efficiency, and innovation. AI offers a wide range of exciting possibilities where AI-powered tools enable students to receive tailored feedback and guidance, enabling them to learn at their own pace and excel academically. This research aims to investigate the effects of generative AI techniques and applications on students' cognitive achievement through student behavior. Data was collected through surveys in three Arab countries including Oman, Jordan and Yemen. 768 students from these Arab country's universities were participated in completing surveys randomly. Structure Equation Modeling SEM-PLS was adopted to analysis data. Results reveal that generative AI techniques and applications have positive and significant effects on students' cognitive achievement in Arab higher education institutions. Results also reveal that student behavior enhances the relationship among AI techniques, applications and cognitive achievement. These results highlight the crucial role of AI applications among students in higher education while the integration of this emerging technology is still at the first stage, students' interaction with and utility of these applications show high satisfactory level of their impact on students' behavior and cognitive achievement. This research contributes to literature of generative AI applications giving evidence from Arab region and filling the gap regarding usage of these applications in higher education.",['generative AI techniques'],"The study addresses the potential impact of emerging technologies on higher education, focusing on how these tools can enhance student engagement, personalization, and academic success. It highlights the importance of understanding the relationship between student behavior and cognitive achievement within the context of higher education in Arab countries. The primary aim of the research is to investigate the effects of these technologies on students' cognitive achievement through the lens of student behavior. The study seeks to provide evidence from the Arab region regarding the influence of these applications on learning outcomes and student interaction in higher education institutions."
Psychology,Hallucination Rates and Reference Accuracy of ChatGPT and Bard for Systematic Reviews: Comparative Analysis,"Background Large language models (LLMs) have raised both interest and concern in the academic community. They offer the potential for automating literature search and synthesis for systematic reviews but raise concerns regarding their reliability, as the tendency to generate unsupported (hallucinated) content persist. Objective The aim of the study is to assess the performance of LLMs such as ChatGPT and Bard (subsequently rebranded Gemini) to produce references in the context of scientific writing. Methods The performance of ChatGPT and Bard in replicating the results of human-conducted systematic reviews was assessed. Using systematic reviews pertaining to shoulder rotator cuff pathology, these LLMs were tested by providing the same inclusion criteria and comparing the results with original systematic review references, serving as gold standards. The study used 3 key performance metrics: recall, precision, and F1-score, alongside the hallucination rate. Papers were considered “hallucinated” if any 2 of the following information were wrong: title, first author, or year of publication. Results In total, 11 systematic reviews across 4 fields yielded 33 prompts to LLMs (3 LLMs×11 reviews), with 471 references analyzed. Precision rates for GPT-3.5, GPT-4, and Bard were 9.4% (13/139), 13.4% (16/119), and 0% (0/104) respectively (P&lt;.001). Recall rates were 11.9% (13/109) for GPT-3.5 and 13.7% (15/109) for GPT-4, with Bard failing to retrieve any relevant papers (P&lt;.001). Hallucination rates stood at 39.6% (55/139) for GPT-3.5, 28.6% (34/119) for GPT-4, and 91.4% (95/104) for Bard (P&lt;.001). Further analysis of nonhallucinated papers retrieved by GPT models revealed significant differences in identifying various criteria, such as randomized studies, participant criteria, and intervention criteria. The study also noted the geographical and open-access biases in the papers retrieved by the LLMs. Conclusions Given their current performance, it is not recommended for LLMs to be deployed as the primary or exclusive tool for conducting systematic reviews. Any references generated by such models warrant thorough validation by researchers. The high occurrence of hallucinations in LLMs highlights the necessity for refining their training and functionality before confidently using them for rigorous academic purposes.","['GPT-3.5', 'GPT-4']","The research idea centers on the growing interest and concern within the academic community regarding the reliability of automated tools in supporting scientific literature synthesis, particularly for systematic reviews. There is a motivation to explore whether these tools can effectively replicate human-conducted systematic reviews without generating unsupported or inaccurate content. The study’s primary objective is to evaluate the ability of these tools to produce accurate and reliable references in the context of scientific writing, specifically assessing their performance in replicating the results of systematic reviews related to shoulder rotator cuff pathology. The aim is to determine the extent to which these tools can retrieve relevant papers accurately and to identify the prevalence of errors or hallucinated content in their outputs."
Psychology,Object detection and tracking in Precision Farming: a systematic review,"Object Detection and Tracking have gained importance in recent years because of the great advances in image and video analysis techniques and the accurate results these technologies are producing. Moreover, they have successfully been applied to multiple fields, including the agricultural domain since they offer real-time monitoring of the status of the crops and animals while counting how many are present within a field/barn. This review aims to review the current literature on Object Detection and Tracking within the field of Precision Farming. For that, over 300 research articles were explored, from which 150 articles from the last five years were systematically reviewed and analysed regarding the algorithms they implemented, the domain they belong to, the difficulties they faced, and which limitations should be tackled in the future. Lastly, it examines potential issues that this approach might have, for instance, the lack of open-source datasets with labelled data. The findings of this study indicate that Object Detection and Tracking are critical techniques to enhance Precision Farming and pave the way for robotization for the agricultural sector since they provide accurate results and insights on crop and animal management, and optimize resource allocation. Future work should focus on the optimal acquisition of the datasets prior to Object Detection and Tracking, along with the consideration of the biophysical environment of the farming scenarios.",['Object Detection'],"The research idea addresses the growing importance of accurately monitoring crops and animals in agricultural settings to improve management and resource allocation. It highlights the need for effective techniques that can provide real-time insights into the status and quantity of agricultural elements within fields or barns. The study is motivated by the challenges and limitations faced in this area, including the scarcity of comprehensive labeled datasets and the complexities of the biophysical farming environment. The primary objective of the study is to systematically review recent literature on methods used for detecting and tracking objects in precision farming, identifying the difficulties encountered and limitations that need to be addressed in future research. It aims to provide a comprehensive understanding of how these approaches contribute to enhancing agricultural practices and to suggest directions for improving data acquisition and environmental considerations in this context."
Psychology,Applying large language models and chain-of-thought for automatic scoring,"This study investigates the application of large language models (LLMs), specifically GPT-3.5 and GPT-4, with Chain-of-Though (CoT) in the automatic scoring of student-written responses to science assessments. We focused on overcoming the challenges of accessibility, technical complexity, and lack of explainability that have previously limited the use of artificial intelligence-based automatic scoring tools among researchers and educators. With a testing dataset comprising six assessment tasks (three binomial and three trinomial) with 1650 student responses, we employed six prompt engineering strategies to automatically score student responses. The six strategies combined zero-shot or few-shot learning with CoT, either alone or alongside item stem and scoring rubrics, developed based on a novel approach, WRVRT (prompt writing, reviewing, validating, revising, and testing). Results indicated that few-shot (acc = 0.67) outperformed zero-shot learning (acc = 0.60), with 12.6% increase. CoT, when used without item stem and scoring rubrics, did not significantly affect scoring accuracy (acc = 0.60). However, CoT prompting paired with contextual item stems and rubrics proved to be a significant contributor to scoring accuracy (13.44% increase for zero-shot; 3.7% increase for few-shot). We found a more balanced accuracy across different proficiency categories when CoT was used with a scoring rubric, highlighting the importance of domain-specific reasoning in enhancing the effectiveness of LLMs in scoring tasks. We also found that GPT-4 demonstrated superior performance over GPT -3.5 in various scoring tasks when combined with the single-call greedy sampling or ensemble voting nucleus sampling strategy, showing 8.64% difference. Particularly, the single-call greedy sampling strategy with GPT-4 outperformed other approaches. This study also demonstrates the potential of LLMs in facilitating explainable and interpretable automatic scoring, emphasizing that CoT enhances accuracy and transparency, particularly when used with item stem and scoring rubrics.","['GPT-3.5', 'GPT-4', 'Chain-of-Thought (CoT)', 'zero-shot learning', 'few-shot learning']","The research idea centers on addressing the challenges of accessibility, technical complexity, and lack of explainability that have limited the use of automatic scoring tools for student-written responses in science assessments. The study is motivated by the need to improve the accuracy and transparency of scoring methods to better support researchers and educators in evaluating student performance. The primary objective of the study is to investigate how different prompting strategies, particularly those incorporating domain-specific reasoning through item stems and scoring rubrics, can enhance the accuracy and interpretability of automatic scoring of student responses. The study aims to evaluate the effectiveness of these strategies in producing more balanced and explainable scoring outcomes across various proficiency levels."
Psychology,Transformative Breast Cancer Diagnosis using CNNs with Optimized ReduceLROnPlateau and Early Stopping Enhancements,"Abstract Breast cancer stands as a paramount public health concern worldwide, underscoring an imperative necessity within the research sphere for precision-driven and efficacious methodologies facilitating accurate detection. The existing diagnostic approaches in breast cancer often suffer from limitations in accuracy and efficiency, leading to delayed detection and subsequent challenges in personalized treatment planning. The primary focus of this research is to overcome these shortcomings by harnessing the power of advanced deep learning techniques, thereby revolutionizing the precision and reliability of breast cancer classification. This research addresses the critical need for improved breast cancer diagnostics by introducing a novel Convolutional Neural Network (CNN) model integrated with an Early Stopping callback and ReduceLROnPlateau callback. By enhancing the precision and reliability of breast cancer classification, the study aims to overcome the limitations of existing diagnostic methods, ultimately leading to better patient outcomes and reduced mortality rates. The comprehensive methodology includes diverse datasets, meticulous image preprocessing, robust model training, and validation strategies, emphasizing the model's adaptability and reliability in varied clinical contexts. The findings showcase the CNN model's exceptional performance, achieving a 95.2% accuracy rate in distinguishing cancerous and non-cancerous breast tissue in the integrated dataset, thereby demonstrating its potential for enhancing clinical decision-making and fostering the development of AI-driven diagnostic solutions.","['Convolutional Neural Network (CNN)', 'Early Stopping callback']","The research idea centers on the significant public health challenge posed by breast cancer and the urgent need for more accurate and efficient diagnostic approaches. Current methods often lack precision, leading to delayed detection and difficulties in personalized treatment planning. This study is motivated by the necessity to improve the accuracy and reliability of breast cancer classification to enhance patient outcomes and reduce mortality rates. The primary objective of the research is to address the limitations of existing diagnostic techniques by developing a more precise and dependable method for distinguishing cancerous from non-cancerous breast tissue. By improving diagnostic accuracy, the study aims to facilitate better clinical decision-making and ultimately contribute to more effective breast cancer management."
Psychology,Detecting and Preventing Hallucinations in Large Vision Language Models,"Instruction tuned Large Vision Language Models (LVLMs) have significantly advanced in generalizing across a diverse set of multi-modal tasks, especially for Visual Question Answering (VQA). However, generating detailed responses that are visually grounded is still a challenging task for these models. We find that even the current state-of-the-art LVLMs (InstructBLIP) still contain a staggering 30 percent of the hallucinatory text in the form of non-existent objects, unfaithful descriptions, and inaccurate relationships. To address this, we introduce M-HalDetect, a Multimodal Hallucination Detection Dataset that can be used to train and benchmark models for hallucination detection and prevention. M-HalDetect consists of 16k fine-grained annotations on VQA examples, making it the first comprehensive multi-modal hallucination detection dataset for detailed image descriptions. Unlike previous work that only consider object hallucination, we additionally annotate both entity descriptions and relationships that are unfaithful. To demonstrate the potential of this dataset for hallucination prevention, we optimize InstructBLIP through our novel Fine-grained Direct Preference Optimization (FDPO). We also train fine-grained multi-modal reward models from InstructBLIP and evaluate their effectiveness with best-of-n rejection sampling (RS). We perform human evaluation on both FDPO and rejection sampling, and find that they reduce hallucination rates in InstructBLIP by 41% and 55% respectively. We also find that our reward model generalizes to other multi-modal models, reducing hallucinations in LLaVA and mPLUG-OWL by 15% and 57% respectively, and has strong correlation with human evaluated accuracy scores. The dataset is available at https://github.com/hendryx-scale/mhal-detect.",['Instruction tuned Large Vision Language Models (LVLMs)'],"The research idea centers on the challenge of generating detailed and visually accurate responses in visual question answering tasks, highlighting that even advanced models frequently produce hallucinated content such as non-existent objects, unfaithful descriptions, and inaccurate relationships. This issue of hallucination undermines the reliability and fidelity of image-based descriptions, indicating a significant problem in ensuring that responses are truly grounded in the visual input. The primary objective of the study is to create a comprehensive dataset with fine-grained annotations that identify hallucinations in visual question answering, including both entity descriptions and relationships, to facilitate the detection and reduction of these inaccuracies. The study aims to use this dataset to improve the accuracy and faithfulness of detailed image descriptions by reducing hallucination rates, thereby enhancing the quality of responses in visual question answering tasks."
Psychology,Sentiment Analysis in the Age of Generative AI,"Abstract In the rapidly advancing age of Generative AI, Large Language Models (LLMs) such as ChatGPT stand at the forefront of disrupting marketing practice and research. This paper presents a comprehensive exploration of LLMs’ proficiency in sentiment analysis, a core task in marketing research for understanding consumer emotions, opinions, and perceptions. We benchmark the performance of three state-of-the-art LLMs, i.e., GPT-3.5, GPT-4, and Llama 2, against established, high-performing transfer learning models. Despite their zero-shot nature, our research reveals that LLMs can not only compete with but in some cases also surpass traditional transfer learning methods in terms of sentiment classification accuracy. We investigate the influence of textual data characteristics and analytical procedures on classification accuracy, shedding light on how data origin, text complexity, and prompting techniques impact LLM performance. We find that linguistic features such as the presence of lengthy, content-laden words improve classification performance, while other features such as single-sentence reviews and less structured social media text documents reduce performance. Further, we explore the explainability of sentiment classifications generated by LLMs. The findings indicate that LLMs, especially Llama 2, offer remarkable classification explanations, highlighting their advanced human-like reasoning capabilities. Collectively, this paper enriches the current understanding of sentiment analysis, providing valuable insights and guidance for the selection of suitable methods by marketing researchers and practitioners in the age of Generative AI.","['GPT-3.5', 'GPT-4', 'Llama 2', 'transfer learning models']","The research idea centers on understanding how advancements in language processing technologies impact the ability to analyze consumer emotions, opinions, and perceptions through sentiment analysis, which is a fundamental task in marketing research. The study addresses the challenge of accurately interpreting diverse textual data from various sources, considering factors such as text complexity and linguistic features that influence classification performance. The primary objective of the study is to evaluate the effectiveness of different approaches in sentiment classification accuracy and to examine how characteristics of textual data affect this accuracy. Additionally, the study aims to explore the clarity and quality of explanations provided for sentiment classifications, thereby enhancing the understanding of how these methods can support marketing researchers and practitioners in selecting appropriate tools for sentiment analysis."
Psychology,NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models,"Trained with an unprecedented scale of data, large language models (LLMs) like ChatGPT and GPT-4 exhibit the emergence of significant reasoning abilities from model scaling. Such a trend underscored the potential of training LLMs with unlimited language data, advancing the development of a universal embodied agent. In this work, we introduce the NavGPT, a purely LLM-based instruction-following navigation agent, to reveal the reasoning capability of GPT models in complex embodied scenes by performing zero-shot sequential action prediction for vision-and-language navigation (VLN). At each step, NavGPT takes the textual descriptions of visual observations, navigation history, and future explorable directions as inputs to reason the agent's current status, and makes the decision to approach the target. Through comprehensive experiments, we demonstrate NavGPT can explicitly perform high-level planning for navigation, including decomposing instruction into sub-goals, integrating commonsense knowledge relevant to navigation task resolution, identifying landmarks from observed scenes, tracking navigation progress, and adapting to exceptions with plan adjustment. Furthermore, we show that LLMs is capable of generating high-quality navigational instructions from observations and actions along a path, as well as drawing accurate top-down metric trajectory given the agent's navigation history. Despite the performance of using NavGPT to zero-shot R2R tasks still falling short of trained models, we suggest adapting multi-modality inputs for LLMs to use as visual navigation agents and applying the explicit reasoning of LLMs to benefit learning-based models. Code is available at: https://github.com/GengzeZhou/NavGPT.","['GPT-4', 'zero-shot sequential action prediction']","The research idea centers on exploring the reasoning capabilities involved in navigating complex environments, particularly how an agent can interpret and act upon sequential instructions and visual information to reach a target. This study addresses the challenge of understanding how high-level planning, commonsense knowledge, landmark identification, progress tracking, and adaptive decision-making contribute to effective navigation in dynamic settings. The primary objective of the study is to investigate the ability to perform sequential action prediction in navigation tasks by reasoning through textual descriptions of visual observations, navigation history, and possible future directions. The study aims to demonstrate how explicit reasoning can support decomposing instructions into sub-goals, integrating relevant knowledge, and adjusting plans to successfully guide navigation toward a target."
Psychology,Investigating Spatial Effects through Machine Learning and Leveraging Explainable AI for Child Malnutrition in Pakistan,"While socioeconomic gradients in regional health inequalities are firmly established, the synergistic interactions between socioeconomic deprivation and climate vulnerability within convenient proximity and neighbourhood locations with health disparities remain poorly explored and thus require deep understanding within a regional context. Furthermore, disregarding the importance of spatial spillover effects and nonlinear effects of covariates on childhood stunting are inevitable in dealing with an enduring issue of regional health inequalities. The present study aims to investigate the spatial inequalities in childhood stunting at the district level in Pakistan and validate the importance of spatial lag in predicting childhood stunting. Furthermore, it examines the presence of any nonlinear relationships among the selected independent features with childhood stunting. The study utilized data related to socioeconomic features from MICS 2017–2018 and climatic data from Integrated Contextual Analysis. A multi-model approach was employed to address the research questions, which included Ordinary Least Squares Regression (OLS), various Spatial Models, Machine Learning Algorithms and Explainable Artificial Intelligence methods. Firstly, OLS was used to analyse and test the linear relationships among selected variables. Secondly, Spatial Durbin Error Model (SDEM) was used to detect and capture the impact of spatial spillover on childhood stunting. Third, XGBoost and Random Forest machine learning algorithms were employed to examine and validate the importance of the spatial lag component. Finally, EXAI methods such as SHapley were utilized to identify potential nonlinear relationships. The study found a clear pattern of spatial clustering and geographical disparities in childhood stunting, with multidimensional poverty, high climate vulnerability and early marriage worsening childhood stunting. In contrast, low climate vulnerability, high exposure to mass media and high women’s literacy were found to reduce childhood stunting. The use of machine learning algorithms, specifically XGBoost and Random Forest, highlighted the significant role played by the average value in the neighbourhood in predicting childhood stunting in nearby districts, confirming that the spatial spillover effect is not bounded by geographical boundaries. Furthermore, EXAI methods such as partial dependency plot reveal the existence of a nonlinear relationship between multidimensional poverty and childhood stunting. The study’s findings provide valuable insights into the spatial distribution of childhood stunting in Pakistan, emphasizing the importance of considering spatial effects in predicting childhood stunting. Individual and household-level factors such as exposure to mass media and women’s literacy have shown positive implications for childhood stunting. It further provides a justification for the usage of EXAI methods to draw better insights and propose customised intervention policies accordingly.","['XGBoost', 'Random Forest', 'partial dependency plot']","The research idea centers on addressing the insufficient understanding of how socioeconomic deprivation and climate vulnerability interact within local neighborhoods to influence regional health disparities, specifically childhood stunting. Despite established socioeconomic gradients in health inequalities, the combined effects of these factors and the role of spatial spillover and nonlinear relationships remain underexplored in a regional context. The study aims to investigate spatial inequalities in childhood stunting at the district level in Pakistan, emphasizing the importance of spatial influences and complex relationships among contributing factors. The primary objective of the study is to examine the spatial distribution and clustering of childhood stunting, validate the significance of spatial spillover effects, and explore nonlinear associations between socioeconomic and climatic variables with childhood stunting. It seeks to provide insights into how multidimensional poverty, climate vulnerability, early marriage, exposure to mass media, and women’s literacy relate to childhood stunting, thereby informing targeted intervention policies."
Psychology,Cognition-Driven Structural Prior for Instance-Dependent Label Transition Matrix Estimation,"The label transition matrix has emerged as a widely accepted method for mitigating label noise in machine learning. In recent years, numerous studies have centered on leveraging deep neural networks to estimate the label transition matrix for individual instances within the context of instance-dependent noise. However, these methods suffer from low search efficiency due to the large space of feasible solutions. Behind this drawback, we have explored that the real murderer lies in the invalid class transitions, that is, the actual transition probability between certain classes is zero but is estimated to have a certain value. To mask the <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">invalid class transitions</i> , we introduced a human-cognition-assisted method with structural information from human cognition. Specifically, we introduce a structured transition matrix network ( <bold xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">STMN</b> ) designed with an adversarial learning process to balance instance features and prior information from human cognition. The proposed method offers two advantages: 1) better estimation effectiveness is obtained by sparing the transition matrix and 2) better estimation accuracy is obtained with the assistance of human cognition. By exploiting these two advantages, our method parametrically estimates a sparse label transition matrix, effectively converting noisy labels into true labels. The efficiency and superiority of our proposed method are substantiated through comprehensive comparisons with state-of-the-art methods on three synthetic datasets and a real-world dataset. Our code will be available at https://github.com/WheatCao/STMN-Pytorch.","['deep neural networks', 'adversarial learning process']","The research idea centers on addressing the challenge of inaccurate estimation of class transitions in the presence of label noise, particularly when certain class transitions are invalid but are mistakenly assigned nonzero probabilities. This issue undermines the effectiveness of existing approaches that attempt to correct noisy labels, highlighting the need for a method that can better reflect true class relationships. The study aims to improve the accuracy of identifying true labels by incorporating insights from human cognition to mask invalid class transitions. The primary objective of the study is to develop a method that leverages structural information derived from human cognition to enhance the estimation of label transitions, thereby improving the correction of noisy labels. The study seeks to achieve more accurate and effective label correction by balancing instance-specific features with prior cognitive knowledge, ultimately converting noisy labels into true labels with greater precision."
Psychology,Artificial intelligence (AI)—it’s the end of the tox as we know it (and I feel fine)*,"The rapid progress of AI impacts diverse scientific disciplines, including toxicology, and has the potential to transform chemical safety evaluation. Toxicology has evolved from an empirical science focused on observing apical outcomes of chemical exposure, to a data-rich field ripe for AI integration. The volume, variety and velocity of toxicological data from legacy studies, literature, high-throughput assays, sensor technologies and omics approaches create opportunities but also complexities that AI can help address. In particular, machine learning is well suited to handle and integrate large, heterogeneous datasets that are both structured and unstructured-a key challenge in modern toxicology. AI methods like deep neural networks, large language models, and natural language processing have successfully predicted toxicity endpoints, analyzed high-throughput data, extracted facts from literature, and generated synthetic data. Beyond automating data capture, analysis, and prediction, AI techniques show promise for accelerating quantitative risk assessment by providing probabilistic outputs to capture uncertainties. AI also enables explanation methods to unravel mechanisms and increase trust in modeled predictions. However, issues like model interpretability, data biases, and transparency currently limit regulatory endorsement of AI. Multidisciplinary collaboration is needed to ensure development of interpretable, robust, and human-centered AI systems. Rather than just automating human tasks at scale, transformative AI can catalyze innovation in how evidence is gathered, data are generated, hypotheses are formed and tested, and tasks are performed to usher new paradigms in chemical safety assessment. Used judiciously, AI has immense potential to advance toxicology into a more predictive, mechanism-based, and evidence-integrated scientific discipline to better safeguard human and environmental wellbeing across diverse populations.","['machine learning', 'deep neural networks']","The research idea centers on the evolving nature of toxicology from an empirical science focused on observing outcomes of chemical exposure to a more complex, data-rich discipline that faces challenges in integrating diverse and extensive toxicological information. This complexity creates a need for innovative approaches to improve chemical safety evaluation and risk assessment, ultimately aiming to better protect human and environmental health. The primary objective of the study is to explore how advancements can transform toxicology into a more predictive, mechanism-based, and evidence-integrated scientific field. The study aims to enhance the processes of gathering evidence, generating data, forming and testing hypotheses, and performing tasks to improve chemical safety assessment and safeguard wellbeing across diverse populations."
Psychology,Multiple Classification of Brain MRI Autism Spectrum Disorder by Age and Gender Using Deep Learning,"Abstract The fact that the rapid and definitive diagnosis of autism cannot be made today and that autism cannot be treated provides an impetus to look into novel technological solutions. To contribute to the resolution of this problem through multiple classifications by considering age and gender factors, in this study, two quadruple and one octal classifications were performed using a deep learning (DL) approach. Gender in one of the four classifications and age groups in the other were considered. In the octal classification, classes were created considering gender and age groups. In addition to the diagnosis of ASD (Autism Spectrum Disorders), another goal of this study is to find out the contribution of gender and age factors to the diagnosis of ASD by making multiple classifications based on age and gender for the first time. Brain structural MRI (sMRI) scans of participators with ASD and TD (Typical Development) were pre-processed in the system originally designed for this purpose. Using the Canny Edge Detection (CED) algorithm, the sMRI image data was cropped in the data pre-processing stage, and the data set was enlarged five times with the data augmentation (DA) techniques. The most optimal convolutional neural network (CNN) models were developed using the grid search optimization (GSO) algorism. The proposed DL prediction system was tested with the five-fold cross-validation technique. Three CNN models were designed to be used in the system. The first of these models is the quadruple classification model created by taking gender into account (model 1), the second is the quadruple classification model created by taking into account age (model 2), and the third is the eightfold classification model created by taking into account both gender and age (model 3). ). The accuracy rates obtained for all three designed models are 80.94, 85.42 and 67.94, respectively. These obtained accuracy rates were compared with pre-trained models by using the transfer learning approach. As a result, it was revealed that age and gender factors were effective in the diagnosis of ASD with the system developed for ASD multiple classifications, and higher accuracy rates were achieved compared to pre-trained models.","['convolutional neural network (CNN) models', 'transfer learning approach']","The research idea centers on the challenge that autism cannot currently be diagnosed rapidly and definitively, nor can it be treated effectively, which motivates the exploration of new approaches to improve diagnosis. The study addresses the need to understand how age and gender factors contribute to the diagnosis of Autism Spectrum Disorders (ASD), recognizing that these factors may influence diagnostic accuracy. The primary objective of the study is to investigate the contribution of gender and age to the diagnosis of ASD by performing multiple classifications based on these factors for the first time. Additionally, the study aims to enhance the accuracy of ASD diagnosis by considering age and gender differences in the classification process."
Psychology,Counterfactual Explanations and Algorithmic Recourses for Machine Learning: A Review,"Machine learning plays a role in many deployed decision systems, often in ways that are difficult or impossible to understand by human stakeholders. Explaining, in a human-understandable way, the relationship between the input and output of machine learning models is essential to the development of trustworthy machine learning based systems. A burgeoning body of research seeks to define the goals and methods of explainability in machine learning. In this article, we seek to review and categorize research on counterfactual explanations , a specific class of explanation that provides a link between what could have happened had input to a model been changed in a particular way. Modern approaches to counterfactual explainability in machine learning draw connections to the established legal doctrine in many countries, making them appealing to fielded systems in high-impact areas such as finance and healthcare. Thus, we design a rubric with desirable properties of counterfactual explanation algorithms and comprehensively evaluate all currently proposed algorithms against that rubric. Our rubric provides easy comparison and comprehension of the advantages and disadvantages of different approaches and serves as an introduction to major research themes in this field. We also identify gaps and discuss promising research directions in the space of counterfactual explainability.","['counterfactual explanations', 'counterfactual explanation algorithms']","The research idea centers on the importance of providing explanations that are understandable to humans regarding the relationship between inputs and outputs in decision-making processes. This need arises from the challenge that many decision systems operate in ways that are difficult or impossible for human stakeholders to comprehend, which impacts trustworthiness. The study addresses the broader motivation to clarify how explanations, particularly counterfactual explanations, can enhance understanding and trust in these systems. The primary objective of the study is to review and categorize existing research on counterfactual explanations, evaluating them against a set of desirable properties to facilitate comparison and comprehension. Additionally, the study aims to identify gaps in the current research and discuss promising directions for future investigation in the area of explainability."
Psychology,The Crowdless Future? Generative AI and Creative Problem-Solving,"The rapid advances in generative artificial intelligence (AI) open up attractive opportunities for creative problem-solving through human-guided AI partnerships. To explore this potential, we initiated a crowdsourcing challenge focused on sustainable, circular economy business ideas generated by the human crowd (HC) and collaborative human-AI efforts using two alternative forms of solution search. The challenge attracted 125 global solvers from various industries, and we used strategic prompt engineering to generate the human-AI solutions. We recruited 300 external human evaluators to judge a randomized selection of 13 out of 234 solutions, totaling 3,900 evaluator-solution pairs. Our results indicate that while human crowd solutions exhibited higher novelty—both on average and for highly novel outcomes—human-AI solutions demonstrated superior strategic viability, financial and environmental value, and overall quality. Notably, human-AI solutions cocreated through differentiated search, where human-guided prompts instructed the large language model to sequentially generate outputs distinct from previous iterations, outperformed solutions generated through independent search. By incorporating “AI in the loop” into human-centered creative problem-solving, our study demonstrates a scalable, cost-effective approach to augment the early innovation phases and lays the groundwork for investigating how integrating human-AI solution search processes can drive more impactful innovations. Funding: This work was supported by Harvard Business School (Division of Research and Faculty Development) and the Laboratory for Innovation Science at Harvard (LISH) at the Digital Data and Design (D 3 ) Institute at Harvard. Supplemental Material: The online appendix is available at https://doi.org/10.1287/orsc.2023.18430 .",['large language model'],"The research idea centers on exploring how collaborative efforts between humans and external agents can enhance creative problem-solving, particularly in generating innovative business ideas that support sustainable and circular economy practices. The study addresses the motivation to understand the comparative strengths of human-only versus collaborative human-partnered solutions in terms of novelty, strategic viability, and overall quality. The primary objective of the study is to investigate the effectiveness of human-guided collaborative solution search processes in producing impactful and high-quality innovations. Specifically, the study aims to evaluate how integrating guided collaborative efforts influences the novelty, strategic value, and environmental and financial viability of creative solutions in early innovation phases."
Psychology,Assessing ChatGPT’s Mastery of Bloom’s Taxonomy Using Psychosomatic Medicine Exam Questions: Mixed-Methods Study,"Background Large language models such as GPT-4 (Generative Pre-trained Transformer 4) are being increasingly used in medicine and medical education. However, these models are prone to “hallucinations” (ie, outputs that seem convincing while being factually incorrect). It is currently unknown how these errors by large language models relate to the different cognitive levels defined in Bloom’s taxonomy. Objective This study aims to explore how GPT-4 performs in terms of Bloom’s taxonomy using psychosomatic medicine exam questions. Methods We used a large data set of psychosomatic medicine multiple-choice questions (N=307) with real-world results derived from medical school exams. GPT-4 answered the multiple-choice questions using 2 distinct prompt versions: detailed and short. The answers were analyzed using a quantitative approach and a qualitative approach. Focusing on incorrectly answered questions, we categorized reasoning errors according to the hierarchical framework of Bloom’s taxonomy. Results GPT-4’s performance in answering exam questions yielded a high success rate: 93% (284/307) for the detailed prompt and 91% (278/307) for the short prompt. Questions answered correctly by GPT-4 had a statistically significant higher difficulty than questions answered incorrectly (P=.002 for the detailed prompt and P&lt;.001 for the short prompt). Independent of the prompt, GPT-4’s lowest exam performance was 78.9% (15/19), thereby always surpassing the “pass” threshold. Our qualitative analysis of incorrect answers, based on Bloom’s taxonomy, showed that errors were primarily in the “remember” (29/68) and “understand” (23/68) cognitive levels; specific issues arose in recalling details, understanding conceptual relationships, and adhering to standardized guidelines. Conclusions GPT-4 demonstrated a remarkable success rate when confronted with psychosomatic medicine multiple-choice exam questions, aligning with previous findings. When evaluated through Bloom’s taxonomy, our data revealed that GPT-4 occasionally ignored specific facts (remember), provided illogical reasoning (understand), or failed to apply concepts to a new situation (apply). These errors, which were confidently presented, could be attributed to inherent model biases and the tendency to generate outputs that maximize likelihood.",['GPT-4 (Generative Pre-trained Transformer 4)'],"The research idea centers on understanding the nature of errors made by a language-based system when responding to psychosomatic medicine exam questions, particularly how these errors correspond to different cognitive levels defined in Bloom’s taxonomy. There is a need to investigate the relationship between the accuracy of responses and the cognitive demands of exam questions, as well as to identify specific types of reasoning mistakes in the context of medical education. The primary objective of the study is to explore the performance of the system in answering psychosomatic medicine multiple-choice questions according to Bloom’s taxonomy, with a focus on categorizing the reasoning errors associated with incorrectly answered questions. This aims to shed light on how cognitive processes such as remembering, understanding, and applying knowledge are reflected in the errors made during exam question responses."
Psychology,An Explainable AI Paradigm for Alzheimer’s Diagnosis Using Deep Transfer Learning,"Alzheimer’s disease (AD) is a progressive neurodegenerative disorder that affects millions of individuals worldwide, causing severe cognitive decline and memory impairment. The early and accurate diagnosis of AD is crucial for effective intervention and disease management. In recent years, deep learning techniques have shown promising results in medical image analysis, including AD diagnosis from neuroimaging data. However, the lack of interpretability in deep learning models hinders their adoption in clinical settings, where explainability is essential for gaining trust and acceptance from healthcare professionals. In this study, we propose an explainable AI (XAI)-based approach for the diagnosis of Alzheimer’s disease, leveraging the power of deep transfer learning and ensemble modeling. The proposed framework aims to enhance the interpretability of deep learning models by incorporating XAI techniques, allowing clinicians to understand the decision-making process and providing valuable insights into disease diagnosis. By leveraging popular pre-trained convolutional neural networks (CNNs) such as VGG16, VGG19, DenseNet169, and DenseNet201, we conducted extensive experiments to evaluate their individual performances on a comprehensive dataset. The proposed ensembles, Ensemble-1 (VGG16 and VGG19) and Ensemble-2 (DenseNet169 and DenseNet201), demonstrated superior accuracy, precision, recall, and F1 scores compared to individual models, reaching up to 95%. In order to enhance interpretability and transparency in Alzheimer’s diagnosis, we introduced a novel model achieving an impressive accuracy of 96%. This model incorporates explainable AI techniques, including saliency maps and grad-CAM (gradient-weighted class activation mapping). The integration of these techniques not only contributes to the model’s exceptional accuracy but also provides clinicians and researchers with visual insights into the neural regions influencing the diagnosis. Our findings showcase the potential of combining deep transfer learning with explainable AI in the realm of Alzheimer’s disease diagnosis, paving the way for more interpretable and clinically relevant AI models in healthcare.","['deep learning', 'explainable AI (XAI)', 'deep transfer learning', 'ensemble modeling', 'pre-trained convolutional neural networks (CNNs)', 'VGG16', 'VGG19', 'DenseNet169', 'DenseNet201', 'saliency maps', 'grad-CAM (gradient-weighted class activation mapping)']","The research idea centers on addressing the challenge of early and accurate diagnosis of Alzheimer’s disease, a progressive neurodegenerative disorder that leads to severe cognitive decline and memory impairment. Despite advances in diagnostic approaches, there remains a critical need for methods that are not only accurate but also interpretable and transparent to gain trust and acceptance from healthcare professionals. The study highlights the importance of enhancing the explainability of diagnostic tools to support effective intervention and disease management in clinical settings. The primary objective of the study is to develop an approach that improves the interpretability of Alzheimer’s disease diagnosis, enabling clinicians to understand the decision-making process behind diagnostic outcomes. This objective aims to provide valuable insights into the neural regions influencing the diagnosis, thereby facilitating more transparent and clinically relevant assessments of the disease."
Psychology,REVIEWING THE TRANSFORMATIONAL IMPACT OF EDGE COMPUTING ON REAL-TIME DATA PROCESSING AND ANALYTICS,"Edge computing has emerged as a pivotal paradigm shift in the realm of data processing and analytics, revolutionizing the way organizations handle real-time data. This review presents a comprehensive review of the transformational impact of edge computing on real-time data processing and analytics. Firstly, the review delves into the fundamental concepts of edge computing, elucidating its architectural framework and highlighting its distinct advantages over traditional cloud-centric approaches. By distributing computational resources closer to data sources, edge computing mitigates latency issues and enhances responsiveness, thereby enabling real-time data processing at the edge. Furthermore, this review explores how edge computing facilitates the seamless integration of analytics capabilities into edge devices, empowering organizations to derive actionable insights at the source of data generation. Leveraging advanced analytics algorithms, such as machine learning and artificial intelligence, edge computing enables autonomous decision-making and predictive analytics in real time, fostering innovation across diverse industry verticals. Moreover, the review examines the transformative implications of edge computing on various sectors, including healthcare, manufacturing, transportation, and smart cities. By enabling localized data processing and analytics, edge computing enhances operational efficiency, ensures data privacy and security, and unlocks new opportunities for business optimization and value creation. This review underscores the profound impact of edge computing on real-time data processing and analytics, revolutionizing the way organizations harness data to drive informed decision-making and gain competitive advantage in today's dynamic business landscape. As edge computing continues to evolve, its transformative potential is poised to redefine the future of data-driven innovation and digital transformation.&#x0D; Keywords: Edge, Computing, Analytics, Data, Impact, Review.",['machine learning'],"The research idea centers on understanding the significant changes brought about by a new approach to processing information closer to the source of data generation, which addresses challenges related to delays and responsiveness in real-time data handling. This shift has important implications for various fields, including healthcare, manufacturing, transportation, and urban development, by improving efficiency, privacy, and opportunities for optimization. The primary objective of the study is to comprehensively review the impact of this approach on real-time information processing and its ability to integrate analytical capabilities directly into the environment where data is produced. The study aims to highlight how these advancements enable more immediate and informed decision-making, thereby transforming operational practices across multiple sectors."
Psychology,"Human-in-the-Loop Reinforcement Learning: A Survey and Position on Requirements, Challenges, and Opportunities","Artificial intelligence (AI) and especially reinforcement learning (RL) have the potential to enable agents to learn and perform tasks autonomously with superhuman performance. However, we consider RL as fundamentally a Human-in-the-Loop (HITL) paradigm, even when an agent eventually performs its task autonomously. In cases where the reward function is challenging or impossible to define, HITL approaches are considered particularly advantageous. The application of Reinforcement Learning from Human Feedback (RLHF) in systems such as ChatGPT demonstrates the effectiveness of optimizing for user experience and integrating their feedback into the training loop. In HITL RL, human input is integrated during the agent’s learning process, allowing iterative updates and fine-tuning based on human feedback, thus enhancing the agent’s performance. Since the human is an essential part of this process, we argue that human-centric approaches are the key to successful RL, a fact that has not been adequately considered in the existing literature. This paper aims to inform readers about current explainability methods in HITL RL. It also shows how the application of explainable AI (xAI) and specific improvements to existing explainability approaches can enable a better human-agent interaction in HITL RL for all types of users, whether for lay people, domain experts, or machine learning specialists. Accounting for the workflow in HITL RL and based on software and machine learning methodologies, this article identifies four phases for human involvement for creating HITL RL systems: (1) Agent Development, (2) Agent Learning, (3) Agent Evaluation, and (4) Agent Deployment. We highlight human involvement, explanation requirements, new challenges, and goals for each phase. We furthermore identify low-risk, high-return opportunities for explainability research in HITL RL and present long-term research goals to advance the field. Finally, we propose a vision of human-robot collaboration that allows both parties to reach their full potential and cooperate effectively.","['reinforcement learning (RL)', 'Reinforcement Learning from Human Feedback (RLHF)', 'explainable AI (xAI)']","The research idea centers on the importance of human involvement in learning processes where autonomous agents perform tasks, emphasizing that human-centric approaches are crucial for success but have been insufficiently addressed in existing studies. It highlights the challenge of defining reward functions and the advantage of integrating human feedback to improve task performance, underscoring the need for better understanding and support of human-agent interaction. The primary objective of the study is to inform readers about current methods that enhance explainability in human-involved learning paradigms and to demonstrate how improvements in these approaches can facilitate more effective interaction between humans and agents across different user groups. Additionally, the study aims to identify key phases of human involvement, outline explanation requirements and challenges, and propose long-term goals to advance collaboration between humans and autonomous systems."
Psychology,AlphaFold predictions of fold-switched conformations are driven by structure memorization,"Abstract Recent work suggests that AlphaFold (AF)–a deep learning-based model that can accurately infer protein structure from sequence–may discern important features of folded protein energy landscapes, defined by the diversity and frequency of different conformations in the folded state. Here, we test the limits of its predictive power on fold-switching proteins, which assume two structures with regions of distinct secondary and/or tertiary structure. We find that (1) AF is a weak predictor of fold switching and (2) some of its successes result from memorization of training-set structures rather than learned protein energetics. Combining &gt;280,000 models from several implementations of AF2 and AF3, a 35% success rate was achieved for fold switchers likely in AF’s training sets. AF2’s confidence metrics selected against models consistent with experimentally determined fold-switching structures and failed to discriminate between low and high energy conformations. Further, AF captured only one out of seven experimentally confirmed fold switchers outside of its training sets despite extensive sampling of an additional ~280,000 models. Several observations indicate that AF2 has memorized structural information during training, and AF3 misassigns coevolutionary restraints. These limitations constrain the scope of successful predictions, highlighting the need for physically based methods that readily predict multiple protein conformations.","['AlphaFold (AF)', 'AF2']","The research idea centers on understanding the challenges in accurately predicting the structural behavior of fold-switching proteins, which can adopt multiple distinct conformations. This study addresses the problem of discerning important features of protein energy landscapes, particularly the diversity and frequency of different folded states, and the limitations in current predictive approaches for these complex proteins. The research objective is to evaluate the effectiveness of existing predictive methods in identifying fold-switching proteins and to assess their ability to distinguish between different conformations based on experimentally determined structures. The study aims to highlight the constraints of current approaches and emphasize the need for methods that can reliably predict multiple protein conformations."
Psychology,Larger and more instructable language models become less reliable,"Abstract The prevailing methods to make large language models more powerful and amenable have been based on continuous scaling up (that is, increasing their size, data volume and computational resources 1 ) and bespoke shaping up (including post-filtering 2,3 , fine tuning or use of human feedback 4,5 ). However, larger and more instructable large language models may have become less reliable. By studying the relationship between difficulty concordance, task avoidance and prompting stability of several language model families, here we show that easy instances for human participants are also easy for the models, but scaled-up, shaped-up models do not secure areas of low difficulty in which either the model does not err or human supervision can spot the errors. We also find that early models often avoid user questions but scaled-up, shaped-up models tend to give an apparently sensible yet wrong answer much more often, including errors on difficult questions that human supervisors frequently overlook. Moreover, we observe that stability to different natural phrasings of the same question is improved by scaling-up and shaping-up interventions, but pockets of variability persist across difficulty levels. These findings highlight the need for a fundamental shift in the design and development of general-purpose artificial intelligence, particularly in high-stakes areas for which a predictable distribution of errors is paramount.","['post-filtering', 'fine tuning', 'use of human feedback']","The research idea centers on the challenge that increasing the size and refinement of language models, while intended to enhance their performance, may actually reduce their reliability, especially in areas where errors are difficult to detect by human supervisors. The study addresses the problem that although easier tasks for humans are also easier for these models, more advanced models tend to produce plausible but incorrect answers more frequently, including on difficult questions, which raises concerns about error predictability and oversight. The primary objective of the study is to investigate the relationship between task difficulty, task avoidance, and response consistency across different language model versions, with a focus on understanding how scaling and refinement impact the models’ error patterns and stability in responding to varied question phrasings. The aim is to highlight the limitations of current approaches and emphasize the need for a fundamental change in the development of reliable and predictable systems, particularly in contexts where error management is critical."
Psychology,Semantic and Instance Segmentation in Coastal Urban Spatial Perception: A Multi-Task Learning Framework with an Attention Mechanism,"With the continuous acceleration of urbanization, urban planning and design require more in-depth research and development. Street view images can express rich urban features and guide residents’ emotions toward a city, thereby providing the most intuitive reflection of their perception of the city’s spatial quality. However, current researchers mainly conduct research on urban spatial quality through subjective experiential judgment, which includes problems such as a high cost and a low judgment accuracy. In response to these problems, this study proposes a multi-task learning urban spatial attribute perception model that integrates an attention mechanism. Via this model, the existing attributes of urban street scenes are analyzed. Then, the model is improved by introducing semantic segmentation and instance segmentation to identify and match the qualities of the urban space. The experimental results show that the multi-task learning urban spatial attribute perception model with an integrated attention mechanism has prediction accuracies of 79.54%, 78.62%, 79.68%, 77.42%, 78.45%, and 76.98% for the urban spatial attributes of beauty, boredom, depression, liveliness, safety, and richness, respectively. The accuracy of the multi-task learning urban spatial scene feature image segmentation model with an integrated attention mechanism is 95.4, 94.8, 96.2, 92.1, and 96.7 for roads, walls, sky, vehicles, and buildings, respectively. The multi-task learning urban spatial scene feature image segmentation model with an integrated attention mechanism has a higher recognition accuracy for urban spatial buildings than other models. These research results indicate the model’s effectiveness in matching urban spatial quality with public perception.","['multi-task learning', 'attention mechanism', 'semantic segmentation', 'instance segmentation']","The research idea centers on the need for more accurate and cost-effective methods to assess urban spatial quality, as current approaches relying on subjective experiential judgment face challenges such as high costs and low accuracy. Urban street scenes convey rich features that influence residents' emotional responses and perceptions of a city's spatial quality, highlighting the importance of understanding these perceptions in urban planning and design. The primary objective of the study is to analyze and improve the identification and matching of urban spatial attributes related to residents' perceptions, such as beauty, boredom, depression, liveliness, safety, and richness, by enhancing the recognition of urban street scene qualities. This aims to provide a more effective way to reflect public perception of urban spatial quality to support urban planning efforts."
Psychology,Evaluating the ChatGPT family of models for biomedical reasoning and classification,"Abstract Objective Large language models (LLMs) have shown impressive ability in biomedical question-answering, but have not been adequately investigated for more specific biomedical applications. This study investigates ChatGPT family of models (GPT-3.5, GPT-4) in biomedical tasks beyond question-answering. Materials and Methods We evaluated model performance with 11 122 samples for two fundamental tasks in the biomedical domain—classification (n = 8676) and reasoning (n = 2446). The first task involves classifying health advice in scientific literature, while the second task is detecting causal relations in biomedical literature. We used 20% of the dataset for prompt development, including zero- and few-shot settings with and without chain-of-thought (CoT). We then evaluated the best prompts from each setting on the remaining dataset, comparing them to models using simple features (BoW with logistic regression) and fine-tuned BioBERT models. Results Fine-tuning BioBERT produced the best classification (F1: 0.800-0.902) and reasoning (F1: 0.851) results. Among LLM approaches, few-shot CoT achieved the best classification (F1: 0.671-0.770) and reasoning (F1: 0.682) results, comparable to the BoW model (F1: 0.602-0.753 and 0.675 for classification and reasoning, respectively). It took 78 h to obtain the best LLM results, compared to 0.078 and 0.008 h for the top-performing BioBERT and BoW models, respectively. Discussion The simple BoW model performed similarly to the most complex LLM prompting. Prompt engineering required significant investment. Conclusion Despite the excitement around viral ChatGPT, fine-tuning for two fundamental biomedical natural language processing tasks remained the best strategy.","['ChatGPT family of models (GPT-3.5, GPT-4)', 'zero-shot prompting', 'few-shot prompting', 'chain-of-thought (CoT) prompting', 'Bag of Words (BoW) with logistic regression', 'fine-tuned BioBERT']","The research idea centers on addressing the need to evaluate the effectiveness of advanced language models in specific biomedical tasks beyond general question-answering, particularly focusing on classification of health advice and detection of causal relations in biomedical literature. This study is motivated by the gap in understanding how these models perform in fundamental biomedical applications that require nuanced interpretation and reasoning. The primary objective of the study is to investigate the performance of different approaches in classifying health advice and detecting causal relationships within biomedical texts, aiming to determine which strategies yield the most accurate and efficient results for these critical tasks. The study seeks to compare various methods to identify the best approach for improving biomedical text understanding and reasoning."
Psychology,Optimum tuned mass damper inerter under near-fault pulse-like ground motions of buildings including soil-structure interaction,"This study investigates the effectiveness of the tuned mass damper inerter (TMDI) in mitigating building response, considering the soil structure interaction (SSI). Three types of models are examined: single degree of freedom (SDOF), low-rise multi-degree of freedom (MDOF), and high-rise MDOF. Additionally, the natural period of the SDOF model is varied to explore the TMDI's efficacy across different ranges. Frequency and time domain analysis are conducted under pulse-like ground motions. The H2 and genetic algorithm (GA) are used to optimize the parameters of the TMDI. In this optimization method the transfer function for displacement response is minimized. In time domain analysis we used Newmark's integration method to solve the equation of motion for all the cases considered. It is found that the optimized TMDI proves highly effective in mitigating the displacement response of the buildings, accounting for SSI. Notably, its efficiency is more pronounced when pulse period aligns closely with the buildings' natural period. In addition, a notable pattern emerges, wherein the TMDI excels in mitigating response for buildings experiencing large motion, thereby enhancing safety under severe conditions. These findings offer valuable insights into the application and optimization of the TMDI to enhance seismic performance in various buildings, while considering complex interaction with the soil.",['genetic algorithm (GA)'],"The study addresses the challenge of reducing the impact of seismic activity on buildings by focusing on how building responses can be mitigated, especially when considering the interaction between the soil and the structure. It highlights the importance of understanding how different building types and their natural periods influence the effectiveness of mitigation strategies during ground motions. The primary objective of the study is to evaluate the effectiveness of a specific mitigation approach in reducing building displacement responses under seismic conditions, taking into account soil-structure interaction. The study aims to determine how this approach performs across various building models and motion characteristics to enhance building safety during severe seismic events."
Psychology,Machine Learning and Digital Biomarkers Can Detect Early Stages of Neurodegenerative Diseases,"Neurodegenerative diseases (NDs) such as Alzheimer’s Disease (AD) and Parkinson’s Disease (PD) are devastating conditions that can develop without noticeable symptoms, causing irreversible damage to neurons before any signs become clinically evident. NDs are a major cause of disability and mortality worldwide. Currently, there are no cures or treatments to halt their progression. Therefore, the development of early detection methods is urgently needed to delay neuronal loss as soon as possible. Despite advancements in Medtech, the early diagnosis of NDs remains a challenge at the intersection of medical, IT, and regulatory fields. Thus, this review explores “digital biomarkers” (tools designed for remote neurocognitive data collection and AI analysis) as a potential solution. The review summarizes that recent studies combining AI with digital biomarkers suggest the possibility of identifying pre-symptomatic indicators of NDs. For instance, research utilizing convolutional neural networks for eye tracking has achieved significant diagnostic accuracies. ROC-AUC scores reached up to 0.88, indicating high model performance in differentiating between PD patients and healthy controls. Similarly, advancements in facial expression analysis through tools have demonstrated significant potential in detecting emotional changes in ND patients, with some models reaching an accuracy of 0.89 and a precision of 0.85. This review follows a structured approach to article selection, starting with a comprehensive database search and culminating in a rigorous quality assessment and meaning for NDs of the different methods. The process is visualized in 10 tables with 54 parameters describing different approaches and their consequences for understanding various mechanisms in ND changes. However, these methods also face challenges related to data accuracy and privacy concerns. To address these issues, this review proposes strategies that emphasize the need for rigorous validation and rapid integration into clinical practice. Such integration could transform ND diagnostics, making early detection tools more cost-effective and globally accessible. In conclusion, this review underscores the urgent need to incorporate validated digital health tools into mainstream medical practice. This integration could indicate a new era in the early diagnosis of neurodegenerative diseases, potentially altering the trajectory of these conditions for millions worldwide. Thus, by highlighting specific and statistically significant findings, this review demonstrates the current progress in this field and the potential impact of these advancements on the global management of NDs.",['convolutional neural networks'],"The research idea centers on the urgent need for early detection methods for neurodegenerative diseases such as Alzheimer’s Disease and Parkinson’s Disease, which often develop without noticeable symptoms and cause irreversible neuronal damage before clinical signs appear. These diseases are a major cause of disability and mortality worldwide, and currently, no cures or treatments exist to halt their progression. Early diagnosis is critical to delay neuronal loss and improve patient outcomes, yet it remains a significant challenge in the medical field. The study addresses the potential of emerging approaches to identify pre-symptomatic indicators that could transform the management of these conditions.

The primary objective of the study is to explore and evaluate the potential of novel tools designed for remote neurocognitive data collection as early detection methods for neurodegenerative diseases. The review aims to summarize recent findings that suggest these tools can identify early, pre-symptomatic changes in patients, thereby facilitating earlier diagnosis. Additionally, the study seeks to highlight the challenges and propose strategies for the validation and integration of these tools into clinical practice to make early detection more accessible and effective worldwide."
Psychology,The Impact of Artificial Intelligence on Students' Learning Experience,"The integration of artificial intelligence (AI) in education has the potential to revolutionize the learning experience for students. This abstract provides an overview of the impact of AI on students' learning experience, highlighting its benefits and potential challenges.AI technologies such as machine learning, natural language processing, and data analytics have been increasingly adopted in educational settings. These technologies enable personalized and adaptive learning experiences, providing students with tailored content and feedback based on their individual needs and learning styles. AI-powered educational platforms can analyze vast amounts of data to identify patterns and offer personalized recommendations, thereby enhancing students' engagement and motivation.One of the significant benefits of AI in education is its ability to provide immediate and constructive feedback to students. Automated grading systems powered by AI algorithms can assess and provide feedback on assignments, quizzes, and exams promptly, allowing students to understand their strengths and weaknesses in real-time. This timely feedback facilitates self-reflection and enables students to make necessary improvements, leading to enhanced learning outcomes.Furthermore, AI can support collaborative learning environments. Intelligent tutoring systems and virtual learning assistants can facilitate group discussions, provide guidance, and foster collaboration among students. These AI-powered tools can promote active participation, critical thinking, and problem-solving skills, creating a dynamic learning environment that mirrors real-world scenarios.However, the integration of AI in education also poses challenges that need to be addressed. Privacy and ethical concerns arise when dealing with student data, as AI relies on collecting and analyzing personal information to provide personalized experiences. Safeguarding student data privacy and ensuring ethical use of AI technologies are essential considerations for educators and policymakers.Additionally, there is a potential risk of over-reliance on AI technologies, leading to a passive learning experience for students. Balancing the use of AI with human instruction and guidance is crucial to maintain meaningful interactions and promote deeper understanding.",['machine learning'],"The research idea centers on the transformative potential of emerging technologies in education to enhance students' learning experiences by offering personalized, adaptive content and immediate feedback, while also acknowledging the challenges related to privacy, ethics, and the risk of diminishing active learning. The study highlights the importance of balancing technological integration with human instruction to foster meaningful interactions and deeper understanding. The primary objective of the study is to examine the impact of these educational technologies on students' engagement, motivation, and learning outcomes, as well as to explore the associated ethical and privacy concerns. Additionally, the study aims to investigate how these tools can support collaborative learning environments and promote critical thinking and problem-solving skills among students."
Psychology,Integrating artificial intelligence to assess emotions in learning environments: a systematic literature review,"Introduction Artificial Intelligence (AI) is transforming multiple sectors within our society, including education. In this context, emotions play a fundamental role in the teaching-learning process given that they influence academic performance, motivation, information retention, and student well-being. Thus, the integration of AI in emotional assessment within educational environments offers several advantages that can transform how we understand and address the socio-emotional development of students. However, there remains a lack of comprehensive approach that systematizes advancements, challenges, and opportunities in this field. Aim This systematic literature review aims to explore how artificial intelligence (AI) is used to evaluate emotions within educational settings. We provide a comprehensive overview of the current state of research, focusing on advancements, challenges, and opportunities in the domain of AI-driven emotional assessment within educational settings. Method The review involved a search across the following academic databases: Pubmed, Web of Science, PsycINFO and Scopus. Forty-one articles were selected that meet the established inclusion criteria. These articles were analyzed to extract key insights related to the integration of AI and emotional assessment within educational environments. Results The findings reveal a variety of AI-driven approaches that were developed to capture and analyze students’ emotional states during learning activities. The findings are summarized in four fundamental topics: (1) emotion recognition in education, (2) technology integration and learning outcomes, (3) special education and assistive technology, (4) affective computing. Among the key AI techniques employed are machine learning and facial recognition, which are used to assess emotions. These approaches demonstrate promising potential in enhancing pedagogical strategies and creating adaptive learning environments that cater to individual emotional needs. The review identified emerging factors that, while important, require further investigation to understand their relationships and implications fully. These elements could significantly enhance the use of AI in assessing emotions within educational settings. Specifically, we are referring to: (1) federated learning, (2) convolutional neural network (CNN), (3) recurrent neural network (RNN), (4) facial expression databases, and (5) ethics in the development of intelligent systems. Conclusion This systematic literature review showcases the significance of AI in revolutionizing educational practices through emotion assessment. While advancements are evident, challenges related to accuracy, privacy, and cross-cultural validity were also identified. The synthesis of existing research highlights the need for further research into refining AI models for emotion recognition and emphasizes the importance of ethical considerations in implementing AI technologies within educational contexts.","['machine learning', 'federated learning', 'convolutional neural network (CNN)', 'recurrent neural network (RNN)']","The study addresses the fundamental role of emotions in the teaching-learning process, emphasizing their influence on academic performance, motivation, information retention, and student well-being. It highlights the need to better understand and systematize the advancements, challenges, and opportunities related to emotional assessment within educational environments. The primary aim of the study is to explore how emotions are evaluated within educational settings, providing a comprehensive overview of the current state of research focused on emotional assessment. The study seeks to identify key factors that influence the assessment of emotions in education and to highlight areas requiring further investigation to enhance socio-emotional development in students."
Psychology,Evaluating LLM-generated Worked Examples in an Introductory Programming Course,"Worked examples, which illustrate the process for solving a problem step-by-step, are a well-established pedagogical technique that has been widely studied in computing classrooms. However, creating high-quality worked examples is very time-intensive for educators, and thus learners tend not to have access to a broad range of such examples. The recent emergence of powerful large language models (LLMs), which appear capable of generating high-quality human-like content, may offer a solution. Separate strands of recent work have shown that LLMs can accurately generate code suitable for a novice audience, and that they can generate high-quality explanations of code. Therefore, LLMs may be well suited to creating a broad range of worked examples, overcoming the bottleneck of manual effort that is currently required. In this work, we present a novel tool, 'WorkedGen', which uses an LLM to generate interactive worked examples. We evaluate this tool with both an expert assessment of the content, and a user study involving students in a first-year Python programming course (n = ~400). We find that prompt chaining and one-shot learning are useful strategies for optimising the output of an LLM when producing worked examples. Our expert analysis suggests that LLMs generate clear explanations, and our classroom deployment revealed that students find the LLM-generated worked examples useful for their learning. We propose several avenues for future work, including investigating WorkedGen's value in a range of programming languages, and with more complex questions suitable for more advanced courses.","['prompt chaining', 'one-shot learning']","The research idea addresses the challenge that creating high-quality worked examples, which are important for illustrating problem-solving processes step-by-step, is very time-intensive for educators, limiting learners' access to a broad range of such examples. This bottleneck in manual effort restricts the availability of effective instructional materials that support student learning. The study’s primary objective is to explore the potential of a novel approach to generate interactive worked examples that can provide clear explanations and support novice learners effectively. It aims to evaluate the quality and usefulness of these generated worked examples through expert assessment and student feedback in an educational setting."
Psychology,Evaluating the subjective perceptions of streetscapes using street-view images,"Developing a model to evaluate urban streetscapes based on subjective perceptions is important for quantitative understanding. However, previous studies have only considered limited types of subjective perceptions, neglecting the relationships between them. Further, accurately measuring subjective perception with low computational costs for large-scale urban regions at high spatial resolutions has been difficult. We present a deep-learning-based multilabel classification model that can measure 22 subjective perceptions scores from street-view images. This model uses the results of a web questionnaire survey encompassing 22 subjective perceptions, with 8.8 million responses. Our model demonstrates high accuracy (0.80–0.91) in measuring subjective perception scores from street-view images and achieves low computational cost by training on 22 subjective perception relationships. The 22 subjective perceptions were analyzed using PCA and k-means analysis. By categorizing the 22 subjective perceptions into a two-dimensional space visualized and grouped into distinct groups—positive, negative, calm, and lively—we unearthed vital insights into the intricate nuances of human perception. In addition, the study used semantic segmentation to extract landscape elements from street-view images and applied ℓ1-regularized sparse modeling to identify the landscape elements structurally correlating with each subjective perception class. The analysis revealed that only seven out of nineteen landscape elements significantly correlated with subjective impressions, and these effects varied by class. Notably, sky coverage positively influences positive subjective perceptions, such as attractiveness and calmness, but negatively affects lively impressions. The proposed model can be used to map the overall image of a city and identify landscape design issues in community development design.","['PCA', 'k-means analysis', 'semantic segmentation', 'ℓ1-regularized sparse modeling']","The research idea centers on the importance of evaluating urban streetscapes based on subjective human perceptions to achieve a quantitative understanding of how people experience urban environments. Previous studies have been limited by focusing on only a few types of subjective perceptions and have overlooked the relationships among these perceptions, making it challenging to measure them accurately across large urban areas. The study aims to address these gaps by exploring a comprehensive range of subjective perceptions and their interrelations in the context of urban streetscapes. The primary objective of the study is to measure and analyze a broad spectrum of 22 subjective perception scores related to urban streetscapes, categorize these perceptions into meaningful groups, and identify specific landscape elements that significantly influence different types of subjective impressions. This objective seeks to provide insights into how various environmental features affect human perception and to inform community development and landscape design by highlighting key factors that shape subjective experiences of urban spaces."
Psychology,Firefighter Skill Advancement through IoT-Enabled Virtual Reality and CNN-Based Training,"To maintain the safety and efficacy of firefighters in various circumstances, modern firefighting necessitates constantly improving skills and training techniques. Utilizing the Internet of Things (IoT), virtual reality (VR), and convolutional neural networks (CNN), this paper details a novel method for training firefighters. The proposed system collects real-time data on ambient variables, equipment state, and firefighter biometrics via integrating IoT sensors into firefighting equipment and training settings. Using this information, it can develop lifelike VR training simulations of difficult and potentially dangerous scenarios. To make the training settings more realistic and malleable, CNN-based algorithms are used to assess the data. The capacity to simulate a wide variety of firefighting situations, customize training difficulty depending on individual and team performance, and provide instant feedback and performance metrics to trainees are all major benefits of this method. The method also allows teachers to check in and evaluate their learners remotely, improving instruction quality. An IoT-enabled VR and CNN-based training technique has shown promising preliminary results in pilot trials, suggesting it might greatly enhance firefighter competence, situational awareness, and decision-making ability. Because of this, it has the potential to completely alter the way firefighters are informed and prepared for the ever-changing dangers users may encounter on the job.",['convolutional neural networks (CNN)'],"The research idea centers on the need to enhance the safety and effectiveness of firefighters by continuously improving their skills and training methods to better prepare them for various challenging and hazardous situations. The study addresses the importance of creating realistic and adaptable training environments that can simulate diverse firefighting scenarios to improve situational awareness and decision-making abilities. The primary objective of the study is to develop and evaluate a novel approach to firefighter training that can simulate difficult and dangerous situations, customize training difficulty based on individual and team performance, and provide immediate feedback to improve competence and instructional quality. This approach aims to significantly enhance firefighters' preparedness for the dynamic risks they face in their work environment."
Psychology,Bias in medical AI: Implications for clinical decision-making,"Biases in medical artificial intelligence (AI) arise and compound throughout the AI lifecycle. These biases can have significant clinical consequences, especially in applications that involve clinical decision-making. Left unaddressed, biased medical AI can lead to substandard clinical decisions and the perpetuation and exacerbation of longstanding healthcare disparities. We discuss potential biases that can arise at different stages in the AI development pipeline and how they can affect AI algorithms and clinical decision-making. Bias can occur in data features and labels, model development and evaluation, deployment, and publication. Insufficient sample sizes for certain patient groups can result in suboptimal performance, algorithm underestimation, and clinically unmeaningful predictions. Missing patient findings can also produce biased model behavior, including capturable but nonrandomly missing data, such as diagnosis codes, and data that is not usually or not easily captured, such as social determinants of health. Expertly annotated labels used to train supervised learning models may reflect implicit cognitive biases or substandard care practices. Overreliance on performance metrics during model development may obscure bias and diminish a model's clinical utility. When applied to data outside the training cohort, model performance can deteriorate from previous validation and can do so differentially across subgroups. How end users interact with deployed solutions can introduce bias. Finally, where models are developed and published, and by whom, impacts the trajectories and priorities of future medical AI development. Solutions to mitigate bias must be implemented with care, which include the collection of large and diverse data sets, statistical debiasing methods, thorough model evaluation, emphasis on model interpretability, and standardized bias reporting and transparency requirements. Prior to real-world implementation in clinical settings, rigorous validation through clinical trials is critical to demonstrate unbiased application. Addressing biases across model development stages is crucial for ensuring all patients benefit equitably from the future of medical AI.","['supervised learning', 'statistical debiasing methods']","The research idea centers on the presence and compounding nature of biases in medical decision-making tools, which can lead to significant clinical consequences and exacerbate existing healthcare disparities. These biases arise at various stages of development and deployment, affecting the quality and equity of clinical decisions. The study highlights the importance of recognizing how insufficient representation of certain patient groups and missing patient information contribute to biased outcomes, ultimately impacting the fairness and effectiveness of clinical care. The research objective is to examine the different sources and impacts of bias throughout the development and application process of medical decision-making tools, emphasizing the need for careful mitigation strategies. The study aims to ensure that these tools provide equitable benefits to all patients by addressing bias at every stage and advocating for rigorous validation before clinical implementation."
Psychology,Flood Detection with SAR: A Review of Techniques and Datasets,"Floods are among the most severe and impacting natural disasters. Their occurrence rate and intensity have been significantly increasing worldwide in the last years due to climate change and urbanization, bringing unprecedented effects on human lives and activities. Hence, providing a prompt response to flooding events is of crucial relevance for humanitarian, social and economic reasons. Satellite remote sensing using synthetic aperture radar (SAR) offers a great deal of support in facing flood events and mitigating their effects on a global scale. As opposed to multi-spectral sensors, SAR offers important advantages, as it enables Earth’s surface imaging regardless of weather and sunlight illumination conditions. In the last decade, the increasing availability of SAR data, even at no cost, thanks to the efforts of international and national space agencies, has been deeply stimulating research activities in every Earth observation field, including flood mapping and monitoring, where advanced processing paradigms, e.g., fuzzy logic, machine learning, data fusion, have been applied, demonstrating their superiority with respect to traditional classification strategies. However, a fair assessment of the performance and reliability of flood mapping techniques is of key importance for an efficient disasters response and, hence, should be addressed carefully and on a quantitative basis trough synthetic quality metrics and high-quality reference data. To this end, the recent development of open SAR datasets specifically covering flood events with related ground-truth reference data can support thorough and objective validation as well as reproducibility of results. Notwithstanding, SAR-based flood monitoring still suffers from severe limitations, especially in vegetated and urban areas, where complex scattering mechanisms can impair an accurate extraction of water regions. All such aspects, including classification methodologies, SAR datasets, validation strategies, challenges and future perspectives for SAR-based flood mapping are described and discussed.",['machine learning'],"The research idea centers on the increasing severity and frequency of floods due to climate change and urbanization, which have profound impacts on human lives and activities, making prompt and effective responses to flooding events critically important for humanitarian, social, and economic reasons. The study highlights the challenges in accurately monitoring floods, especially in vegetated and urban areas, where complex environmental factors complicate the identification of water-affected regions. The primary objective of the study is to evaluate and improve the reliability and performance of flood mapping techniques to support efficient disaster response. It aims to address the limitations in current flood monitoring approaches by discussing classification methods, datasets, validation strategies, and the challenges involved in achieving accurate flood detection and mapping."
Psychology,Investigating the impact of motion in the scanner on brain age predictions,"Abstract Brain Age Gap (BAG) is defined as the difference between the brain’s predicted age and the chronological age of an individual. Magnetic resonance imaging (MRI)-based BAG can quantify acceleration of brain aging, and is used to infer brain health as aging and disease interact. Motion in the scanner is a common occurrence that can affect the acquired MRI data and act as a major confound in the derived models. As such, age-related changes in head motion may impact the observed age-related differences. However, the relationship between head motion and BAG as estimated by structural MRI has not been systematically examined. The aim of this study is to assess the impact of motion on voxel-based morphometry (VBM) based BAG. Data were obtained from two sources: i) T1-weighted (T1w) MRIs from the Cambridge Centre for Ageing and Neuroscience (CamCAN) were used to train the brain age prediction model, and ii) T1w MRIs from the Movement-related artifacts (MR-ART) dataset were used to assess the impact of motion on BAG. MR-ART includes one motion-free and two motion-affected (one low and one high) 3D T1w MRIs. We also visually rated the motion levels of the MR-ART MRIs from 0 to 5, with 0 meaning no motion and 5 high motion levels. All images were pre-processed through a standard VBM pipeline. GM density across cortical and subcortical regions were then used to train the brain age prediction model and assess the relationship between BAG and MRI motion. Principal component analysis was used to perform dimension reduction and extract the VBM-based features. BAG was estimated by regressing out the portion of delta age explained by chronological age. Linear mixed-effects models were used to investigate the relationship between BAG and motion session as well as motion severity, including participant IDs as random effects. We repeated the same analysis using cortical thickness based on FreeSurfer 7.4.1 and to compare the results for volumetric versus surface-based measures of brain morphometry. In contrast with the session with no induced motion, predicted delta age was significantly higher for high motion sessions 2.35 years (t = 5.17, p &amp;lt; 0.0001), with marginal effect for low motion sessions 0.95 years (t = 2.11, p = 0.035) for VBM analysis as well as 3.46 years (t = 11.45, p &amp;lt; 0.0001) for high motion and 2.28 years (t = 7.54, p &amp;lt; 0.0001) for low motion based on cortical thickness. In addition, delta age was significantly associated with motion severity as evaluated by visual rating 0.45 years per rating level (t = 4.59, p &amp;lt; 0.0001) for VBM analysis and 0.83 years per motion level (t = 12.89, p &amp;lt; 0.0001) for cortical thickness analysis. Motion in the scanner can significantly impact brain age estimates, and needs to be accounted for as a confound, particularly when studying populations that are known to have higher levels of motion in the scanner. These results have significant implications for brain age studies in aging and neurodegeneration. Based on these findings, we recommend assessment and inclusion of visual motion ratings in such studies. In cases that the visual rating proves prohibitive, we recommend the inclusion of normalized Euler number from FreeSurfer as defined in the manuscript as a covariate in the models.","['principal component analysis', 'regression']","The research idea centers on understanding how motion during brain imaging scans may influence the measurement of brain aging, specifically the difference between predicted brain age and chronological age, known as the Brain Age Gap (BAG). Since motion is common during scanning and can affect the quality of imaging data, it may confound assessments of brain health and aging, yet the relationship between head motion and BAG has not been thoroughly investigated. The study addresses the potential impact of age-related changes in head motion on observed differences in brain aging measures. The primary objective of the study is to assess the impact of motion on brain age estimates derived from structural brain imaging, examining how different levels of motion affect the accuracy of brain age predictions. The study aims to determine the extent to which motion influences brain age measurements and to provide recommendations for accounting for motion as a confounding factor in brain aging research, particularly in populations prone to increased motion during scanning."
Psychology,Reliability of ChatGPT for performing triage task in the emergency department using the Korean Triage and Acuity Scale,"Background Artificial intelligence (AI) technology can enable more efficient decision-making in healthcare settings. There is a growing interest in improving the speed and accuracy of AI systems in providing responses for given tasks in healthcare settings. Objective This study aimed to assess the reliability of ChatGPT in determining emergency department (ED) triage accuracy using the Korean Triage and Acuity Scale (KTAS). Methods Two hundred and two virtual patient cases were built. The gold standard triage classification for each case was established by an experienced ED physician. Three other human raters (ED paramedics) were involved and rated the virtual cases individually. The virtual cases were also rated by two different versions of the chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0). Inter-rater reliability was examined using Fleiss’ kappa and intra-class correlation coefficient (ICC). Results The kappa values for the agreement between the four human raters and ChatGPTs were .523 (version 4.0) and .320 (version 3.5). Of the five levels, the performance was poor when rating patients at levels 1 and 5, as well as case scenarios with additional text descriptions. There were differences in the accuracy of the different versions of GPTs. The ICC between version 3.5 and the gold standard was .520, and that between version 4.0 and the gold standard was .802. Conclusions A substantial level of inter-rater reliability was revealed when GPTs were used as KTAS raters. The current study showed the potential of using GPT in emergency healthcare settings. Considering the shortage of experienced manpower, this AI method may help improve triaging accuracy.","['chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0)']","The research idea centers on addressing the challenge of accurately and efficiently determining patient triage levels in emergency department settings, which is critical for prioritizing care and managing limited healthcare resources. There is a recognized need to improve the speed and reliability of triage decisions to enhance patient outcomes and optimize emergency healthcare delivery. The study’s primary objective is to assess the reliability of a novel approach in determining emergency department triage accuracy using the Korean Triage and Acuity Scale (KTAS). Specifically, the study aims to evaluate how well this approach agrees with established triage classifications made by experienced emergency department physicians and paramedics."
Psychology,Deep Reinforcement Learning Unleashing the Power of AI in Decision-Making,"Deep Reinforcement Learning (DRL) has emerged as a transformative paradigm in the field of artificial intelligence (AI), offering unprecedented capabilities in decision-making across diverse domains. This article explores the profound impact of DRL on enhancing the decision-making capabilities of AI systems, elucidating its underlying principles, applications, and implications.DRL represents a fusion of deep learning and reinforcement learning, enabling machines to learn complex behaviors and make decisions by interacting with their environment. The utilization of neural networks allows DRL algorithms to handle high-dimensional input spaces, making it well-suited for tasks that involve intricate decision-making processes.One of the key strengths of DRL lies in its ability to address problems with sparse and delayed rewards, common challenges in traditional reinforcement learning. Through a process of trial and error, DRL algorithms can learn optimal decision strategies by navigating through a vast decision space, adapting to dynamic environments, and maximizing cumulative rewards over time.The applications of DRL span various domains, including robotics, finance, healthcare, gaming, and autonomous systems. In robotics, DRL facilitates the development of intelligent agents capable of autonomously navigating complex environments, performing intricate tasks, and adapting to unforeseen circumstances. In finance, DRL is leveraged for portfolio optimization, algorithmic trading, and risk management, demonstrating its potential to revolutionize traditional financial strategies.","['Deep Reinforcement Learning (DRL)', 'deep learning', 'reinforcement learning']","The research idea centers on the challenge of enhancing decision-making capabilities in complex and dynamic environments, particularly where outcomes are influenced by sparse and delayed feedback. The study addresses the need to understand how agents can learn optimal strategies through interaction and adaptation over time, which is a significant problem in fields requiring intricate decision processes. The primary objective of the study is to explore the mechanisms that enable effective decision-making by agents navigating complex tasks and environments, with a focus on how these agents can improve their performance by learning from experience and adapting to changing conditions. The study aims to elucidate the principles and implications of such learning processes to advance understanding of adaptive behavior in challenging contexts."
Psychology,3WC-GBNRS++: A novel three-way classifier with granular-ball neighborhood rough sets based on uncertainty,"Three-way decision with neighborhood rough sets (3WDNRS) is adept at addressing uncertain problems involving continuous data by configuring the neighborhood radius. However, on one hand, the inputs of 3WDNRS are individual neighborhood granules, which reduce the decision efficiency and generality; on other hand, the thresholds of 3WDNRS require prior knowledge to be approximately set in advance, making it difficult to apply in cases where such knowledge is unavailable. To address these issues, we introduce granular-ball computing (GBC) into 3WDNRS from the perspective of uncertainty. Firstly, we propose an enhanced granular-ball generation method based on DBSCAN called DBGBC. Subsequently, we present an improved granular-ball neighborhood rough sets model (GBNRS++) by combining DBGBC with a quality index. Furthermore, we construct a three-way classifier with granular-ball neighborhood rough sets (3WC-GBNRS++) based on the principle of minimum fuzziness loss. This approach provides an objective and efficient way to determine the thresholds. To further enhance classification accuracy, we design an adaptive granular-ball neighborhood within the subsequent classification process of 3WC-GBNRS++. Finally, experimental results demonstrate that, 3WC-GBNRS++ almost outperformed other comparison methods in terms of effectiveness and robustness, including 4 state-of-the-art granular-balls-based classifiers and 5 classical machine learning classifiers on 12 public benchmark datasets. Moreover, we discuss the limitations of our work and the outlook for future research.","['three-way decision with neighborhood rough sets (3WDNRS)', 'DBSCAN']","The research idea centers on addressing challenges in decision-making processes involving uncertain and continuous data, particularly the limitations posed by reliance on individual neighborhood granules and the need for prior knowledge to set thresholds. These issues reduce decision efficiency and hinder applicability in situations where such prior knowledge is unavailable. The study aims to overcome these obstacles by introducing a novel approach that enhances the determination of thresholds and improves decision accuracy in uncertain environments. The primary objective of the study is to develop an improved method for configuring neighborhood-based decision frameworks that objectively and efficiently determine thresholds without requiring prior knowledge, thereby enhancing classification accuracy and robustness in handling uncertain data."
Psychology,MentaLLaMA: Interpretable Mental Health Analysis on Social Media with Large Language Models,"As an integral part of people's daily lives, social media is becoming a rich source for automatic mental health analysis.As traditional discriminative methods bear poor generalization ability and low interpretability, the recent large language models (LLMs) have been explored for interpretable mental health analysis on social media, which aims to provide detailed explanations along with predictions in zero-shot or few-shot settings.The results show that LLMs still achieve unsatisfactory classification performance in a zero-shot/few-shot manner, which further significantly affects the quality of the generated explanations.Domain-specific finetuning is an effective solution, but faces two critical challenges: 1) lack of high-quality training data.2) no open-source foundation LLMs.To alleviate these problems, we formally model interpretable mental health analysis as a text generation task, and build the first multi-task and multi-source interpretable mental health instruction (IMHI) dataset with 105K data samples to support LLM instruction tuning and evaluation.The raw social media data are collected from 10 existing sources covering 8 mental health analysis tasks.We prompt ChatGPT with expert-designed few-shot prompts to obtain explanations.To ensure the reliability of the explanations, we perform strict automatic and human evaluations on the correctness, consistency, and quality of generated data.Based on the IMHI dataset and LLaMA2 foundation models, we train MentaLLaMA, the first open-source instruction-following LLM series for interpretable mental health analysis on social media.We evaluate Men-taLLaMA and other advanced methods on the IMHI benchmark, the first holistic evaluation benchmark for interpretable mental health analysis.The results show that MentaLLaMA approaches state-of-the-art discriminative methods in correctness and generates human-level explanations.MentaLLaMA models also show strong generalizability to unseen tasks.The project is available at https://github.com/SteveKGYang/MentaLLaMA.","['zero-shot learning', 'few-shot learning', 'domain-specific finetuning', 'instruction tuning']","The research idea centers on the growing importance of social media as a source for understanding mental health, highlighting challenges in achieving accurate and interpretable mental health assessments from social media content. Traditional methods struggle with generalization and interpretability, which limits their effectiveness in providing meaningful explanations alongside mental health evaluations. The study addresses the need for more reliable and interpretable approaches to analyze mental health indicators in social media data.

The primary objective of the study is to develop a comprehensive and interpretable framework for mental health analysis on social media by creating a large, multi-task, and multi-source dataset that supports detailed explanations in mental health assessments. The study aims to improve the quality and reliability of mental health interpretations by ensuring correctness, consistency, and human-level explanation quality, ultimately enhancing the generalizability of mental health analysis across various tasks."
Psychology,MixFormer: End-to-End Tracking With Iterative Mixed Attention,"Visual object tracking often employs a multi-stage pipeline of feature extraction, target information integration, and bounding box estimation. To simplify this pipeline and unify the process of feature extraction and target information integration, in this paper, we present a compact tracking framework, termed as MixFormer, built upon transformers. Our core design is to utilize the flexibility of attention operations, and we propose a Mixed Attention Module (MAM) for simultaneous feature extraction and target information integration. This synchronous modeling scheme allows us to extract target-specific discriminative features and perform extensive communication between target and search area. Based on MAM, we build our MixFormer trackers simply by stacking multiple MAMs and placing a localization head on top. Specifically, we instantiate two types of MixFormer trackers, a hierarchical tracker MixCvT, and a non-hierarchical simple tracker MixViT. For these two trackers, we investigate a series of pre-training methods and uncover the different behaviors between supervised pre-training and self-supervised pre-training in our MixFormer trackers. We also extend the masked autoencoder pre-training to our MixFormer trackers and design the new competitive TrackMAE pre-training technique. Finally, to handle multiple target templates during online tracking, we devise an asymmetric attention scheme in MAM to reduce computational cost, and propose an effective score prediction module to select high-quality templates. Our MixFormer trackers set a new state-of-the-art performance on seven tracking benchmarks, including LaSOT, TrackingNet, VOT2020, GOT-10 k, OTB100, TOTB and UAV123. In particular, our MixViT-L achieves AUC scores of 73.3% on LaSOT, 86.1% on TrackingNet and 82.8% on TOTB.","['transformers', 'MixFormer trackers', 'supervised pre-training', 'self-supervised pre-training', 'masked autoencoder pre-training']","The research idea centers on improving the process of visual object tracking by addressing the complexity involved in multiple stages such as feature extraction, target information integration, and bounding box estimation. The study is motivated by the need to simplify and unify these processes to enhance the effectiveness of tracking performance. The primary objective of the study is to develop a streamlined framework that integrates feature extraction and target information simultaneously, allowing for more precise identification and communication between the target and its surrounding area. This approach aims to improve tracking accuracy and efficiency across various challenging benchmarks."
Psychology,Role of Artificial Intelligence in Higher Education- An Empirical Investigation,"The importance of artificial intelligence (AI) is growing in all economic sectors and thus also in higher education. In recent years, there have been significant developments in this concept of ""Artificial Intelligence in Education (AIED)"". The purpose of this study was to find out how the concept of artificial intelligence can be applied to teaching and learning in higher education and the implications of the use of artificial intelligence in higher education. The impact of the development of technologies on learning is often studied on the methods and scope of learning and teaching. Artificial intelligence enables higher education services to become easily accessible with extraordinary speed, not only in the classroom but also outside the classroom. This report seeks to explore how AI will become an integral part of universities and seeks to examine its immediate and future impact on various aspects of higher education. The challenges of implementing AI in these institutes were also explored. As artificial intelligence (AI) research in education increases, many researchers in the field believe that the role of teachers, schools and leaders in education will change. In this regard, the aim of this study is to investigate which are the possible scenarios for the arrival of artificial intelligence in education and what impact it can have on the future of schools. In this research, it confirmed that artificial intelligence has been widely adopted and used in various forms in education, especially educational institutions. Artificial intelligence was initially implemented in the form of computers and computer-related technologies, moving to web-based and web-based intelligent educational systems, and finally with the use of embedded computing systems and other technologies such as humanoid robots and web-based chatbots teachers &amp; tasks and assignments independently or with tutors. With these platforms, teachers could perform various administrative tasks such as grading and Work more effectively and efficiently and achieve higher quality in your learning activities. On the other hand, because the systems use machine learning and adaptability, the curriculum and content are adapted which improved uptake and retention, which improved the student experience and the overall quality of education.",['machine learning'],"The research idea centers on understanding the growing influence of emerging technologies in higher education, particularly how these advancements affect teaching and learning processes both inside and outside the classroom. The study addresses the broader implications of integrating such technologies into educational institutions and the potential changes in the roles of teachers, schools, and educational leaders. The research objective is to investigate the possible scenarios for the introduction of these technologies in education and to examine their immediate and future impact on various aspects of higher education. Additionally, the study aims to explore the challenges associated with implementing these innovations in educational settings and how they may transform educational practices and experiences."
Psychology,Automated Classification of Cognitive Visual Objects Using Multivariate Swarm Sparse Decomposition From Multichannel EEG-MEG Signals,"In visual object decoding, magnetoencephalogram (MEG) and electroencephalogram (EEG) activation patterns demonstrate the utmost discriminative cognitive analysis due to their multivariate oscillatory nature. However, high noise in the recorded EEG-MEG signals and subject-specific variability make it extremely difficult to classify subject's cognitive responses to different visual stimuli. The proposed method is a multivariate extension of the swarm sparse decomposition method (MSSDM) for multivariate pattern analysis of EEG-MEG-based visual activation signals. In comparison, it is an advanced technique for decomposing nonstationary multicomponent signals into a finite number of channel-aligned oscillatory components that significantly enhance visual activation-related sub-bands. The MSSDM method adopts multivariate swarm filtering and sparse spectrum to automatically deliver optimal frequency bands in channel-specific sparse spectrums, resulting in improved filter banks. By combining the advantages of the multivariate SSDM and Riemann's correlation-assisted fusion feature (RCFF), the MSSDM-RCFF algorithm is investigated to improve the visual object recognition ability of EEG-MEG signals. We have also proposed time–frequency representation based on MSSDM to analyze discriminative cognitive patterns of different visual object classes from multichannel EEG-MEG signals. A proposed MSSDM is evaluated on multivariate synthetic signals and multivariate EEG-MEG signals using five classifiers. The proposed fusion feature and linear discriminant analysis classifier-based framework outperformed all existing state-of-the-art methods used for visual object detection and achieved the highest accuracy of 86.42% using tenfold cross-validation on EEG-MEG multichannel signals.","['sparse spectrum', 'linear discriminant analysis classifier']","The research idea centers on the challenge of accurately classifying cognitive responses to different visual stimuli using brain activation patterns recorded through EEG and MEG, which are often hindered by high noise levels and individual variability. This difficulty limits the understanding of how the brain discriminates between various visual objects based on neural signals. The study’s primary objective is to enhance the ability to decode and recognize visual object-related cognitive patterns from EEG-MEG signals by improving the identification of relevant frequency bands and oscillatory components associated with visual activation. Ultimately, the research aims to achieve more precise discrimination of cognitive responses to different visual stimuli, thereby advancing knowledge of visual object recognition processes in the brain."
Psychology,Enhancing black-box models: Advances in explainable artificial intelligence for ethical decision-making,"Transparency, trust, and accountability are among the issues raised by artificial intelligence's (AI) growing reliance on black-box models, especially in high-stakes industries like healthcare, finance, and criminal justice. These models, which are frequently distinguished by their intricacy and opacity, are capable of producing extremely accurate forecasts, but users and decision-makers are still unable to fully understand how they operate. In response to this challenge, the field of Explainable AI (XAI) has emerged with the goal of demystifying these models by offering insights into their decision-making processes. Our ability to interpret model behavior has greatly improved with recent developments in XAI techniques, such as SHAP (Shapley Additive Explanations), LIME (Local Interpretable Model-agnostic Explanations), and counterfactual explanations. These instruments make it easier to recognize bias, promote trust, and guarantee adherence to moral principles and laws like the GDPR and the AI Act. Modern XAI techniques are reviewed in this research along with how they are used in moral decision-making. It looks at how explainability can improve fairness, reduce the risks of AI bias and discrimination, and assist well-informed decision-making in a variety of industries. It also examines the trade-offs between performance and interpretability of models, as well as the growing trends toward user-centric explainability techniques. In order to ensure responsible AI development and deployment, XAI's role in fostering accountability and transparency will become increasingly important as AI becomes more integrated into critical systems.","['SHAP (Shapley Additive Explanations)', 'LIME (Local Interpretable Model-agnostic Explanations)', 'counterfactual explanations']","The research addresses the critical issues of transparency, trust, and accountability in decision-making processes within high-stakes industries such as healthcare, finance, and criminal justice. It highlights the challenge that users and decision-makers face in understanding complex and opaque systems that, despite their accuracy, lack clear interpretability. The study is motivated by the need to improve fairness, reduce bias and discrimination, and support well-informed decisions through enhanced explainability. The primary objective of the study is to review contemporary approaches to explainability and their application in ethical decision-making, focusing on how increased transparency can promote fairness, accountability, and adherence to moral and legal standards. It also aims to explore the balance between performance and interpretability and the shift toward user-centered approaches to foster responsible development and deployment in critical contexts."
Psychology,Active inference as a theory of sentient behavior,"This review paper offers an overview of the history and future of active inference—a unifying perspective on action and perception. Active inference is based upon the idea that sentient behavior depends upon our brains' implicit use of internal models to predict, infer, and direct action. Our focus is upon the conceptual roots and development of this theory of (basic) sentience and does not follow a rigid chronological narrative. We trace the evolution from Helmholtzian ideas on unconscious inference, through to a contemporary understanding of action and perception. In doing so, we touch upon related perspectives, the neural underpinnings of active inference, and the opportunities for future development. Key steps in this development include the formulation of predictive coding models and related theories of neuronal message passing, the use of sequential models for planning and policy optimization, and the importance of hierarchical (temporally) deep internal (i.e., generative or world) models. Active inference has been used to account for aspects of anatomy and neurophysiology, to offer theories of psychopathology in terms of aberrant precision control, and to unify extant psychological theories. We anticipate further development in all these areas and note the exciting early work applying active inference beyond neuroscience. This suggests a future not just in biology, but in robotics, machine learning, and artificial intelligence.","['active inference', 'predictive coding models', 'sequential models for planning and policy optimization']","The research idea centers on understanding sentient behavior through the brain's implicit use of internal models to predict, infer, and direct action, highlighting a unifying perspective on action and perception. The study addresses the conceptual roots and development of a theory of basic sentience, tracing its evolution from early ideas on unconscious inference to contemporary understandings of how action and perception are integrated. The research objective is to provide an overview of the history and future directions of this theory, focusing on its conceptual foundations and development rather than a strict chronological account. The study aims to explore key theoretical advancements and their implications for understanding anatomy, neurophysiology, and psychopathology, as well as to anticipate future developments within psychological science."
Psychology,CLARUS: An interactive explainable AI platform for manual counterfactuals in graph neural networks,"Lack of trust in artificial intelligence (AI) models in medicine is still the key blockage for the use of AI in clinical decision support systems (CDSS). Although AI models are already performing excellently in systems medicine, their black-box nature entails that patient-specific decisions are incomprehensible for the physician. Explainable AI (XAI) algorithms aim to ""explain"" to a human domain expert, which input features influenced a specific recommendation. However, in the clinical domain, these explanations must lead to some degree of causal understanding by a clinician. We developed the CLARUS platform, aiming to promote human understanding of graph neural network (GNN) predictions. CLARUS enables the visualisation of patient-specific networks, as well as, relevance values for genes and interactions, computed by XAI methods, such as GNNExplainer. This enables domain experts to gain deeper insights into the network and more importantly, the expert can interactively alter the patient-specific network based on the acquired understanding and initiate re-prediction or retraining. This interactivity allows us to ask manual counterfactual questions and analyse the effects on the GNN prediction. We present the first interactive XAI platform prototype, CLARUS, that allows not only the evaluation of specific human counterfactual questions based on user-defined alterations of patient networks and a re-prediction of the clinical outcome but also a retraining of the entire GNN after changing the underlying graph structures. The platform is currently hosted by the GWDG on https://rshiny.gwdg.de/apps/clarus/.","['graph neural network (GNN)', 'GNNExplainer']","The research idea addresses the challenge of lack of trust in clinical decision support systems due to the incomprehensibility of patient-specific decisions made by complex models in medicine. Although these models perform well, their opaque nature prevents physicians from understanding the rationale behind recommendations, which is crucial for clinical acceptance. The study emphasizes the need for explanations that lead to a causal understanding by clinicians to improve trust and usability in medical decision-making. The research objective is to develop a platform that promotes human understanding of patient-specific predictions by enabling visualization and interactive exploration of relevant features influencing clinical outcomes. This platform aims to allow domain experts to gain deeper insights, modify patient-specific information based on their understanding, and observe the effects of these changes on clinical predictions, thereby facilitating a more transparent and interpretable decision-making process in medicine."
Psychology,Visual Adversarial Examples Jailbreak Aligned Large Language Models,"Warning: this paper contains data, prompts, and model outputs that are offensive in nature. Recently, there has been a surge of interest in integrating vision into Large Language Models (LLMs), exemplified by Visual Language Models (VLMs) such as Flamingo and GPT-4. This paper sheds light on the security and safety implications of this trend. First, we underscore that the continuous and high-dimensional nature of the visual input makes it a weak link against adversarial attacks, representing an expanded attack surface of vision-integrated LLMs. Second, we highlight that the versatility of LLMs also presents visual attackers with a wider array of achievable adversarial objectives, extending the implications of security failures beyond mere misclassification. As an illustration, we present a case study in which we exploit visual adversarial examples to circumvent the safety guardrail of aligned LLMs with integrated vision. Intriguingly, we discover that a single visual adversarial example can universally jailbreak an aligned LLM, compelling it to heed a wide range of harmful instructions (that it otherwise would not) and generate harmful content that transcends the narrow scope of a `few-shot' derogatory corpus initially employed to optimize the adversarial example. Our study underscores the escalating adversarial risks associated with the pursuit of multimodality. Our findings also connect the long-studied adversarial vulnerabilities of neural networks to the nascent field of AI alignment. The presented attack suggests a fundamental adversarial challenge for AI alignment, especially in light of the emerging trend toward multimodality in frontier foundation models.","['Visual Language Models (VLMs)', 'Flamingo', 'GPT-4']","The research idea centers on the increasing integration of visual information into language-based models and the resulting security and safety concerns that arise from this development. Specifically, the study addresses how the complex nature of visual input creates vulnerabilities that can be exploited to bypass safety measures, leading to harmful outcomes. This highlights broader psychological and ethical implications related to the control and alignment of advanced cognitive systems when exposed to diverse and potentially malicious stimuli. The primary objective of the study is to investigate the risks associated with adversarial visual inputs that can undermine safety protocols, demonstrating how a single visual stimulus can provoke harmful responses that extend beyond initially targeted content. The research aims to illuminate the challenges in maintaining aligned and safe behavior in systems that process multimodal information, emphasizing the psychological significance of these vulnerabilities in the context of emerging technologies."
Psychology,Multimodal data integration for oncology in the era of deep neural networks: a review,"Cancer research encompasses data across various scales, modalities, and resolutions, from screening and diagnostic imaging to digitized histopathology slides to various types of molecular data and clinical records. The integration of these diverse data types for personalized cancer care and predictive modeling holds the promise of enhancing the accuracy and reliability of cancer screening, diagnosis, and treatment. Traditional analytical methods, which often focus on isolated or unimodal information, fall short of capturing the complex and heterogeneous nature of cancer data. The advent of deep neural networks has spurred the development of sophisticated multimodal data fusion techniques capable of extracting and synthesizing information from disparate sources. Among these, Graph Neural Networks (GNNs) and Transformers have emerged as powerful tools for multimodal learning, demonstrating significant success. This review presents the foundational principles of multimodal learning including oncology data modalities, taxonomy of multimodal learning, and fusion strategies. We delve into the recent advancements in GNNs and Transformers for the fusion of multimodal data in oncology, spotlighting key studies and their pivotal findings. We discuss the unique challenges of multimodal learning, such as data heterogeneity and integration complexities, alongside the opportunities it presents for a more nuanced and comprehensive understanding of cancer. Finally, we present some of the latest comprehensive multimodal pan-cancer data sources. By surveying the landscape of multimodal data integration in oncology, our goal is to underline the transformative potential of multimodal GNNs and Transformers. Through technological advancements and the methodological innovations presented in this review, we aim to chart a course for future research in this promising field. This review may be the first that highlights the current state of multimodal modeling applications in cancer using GNNs and transformers, presents comprehensive multimodal oncology data sources, and sets the stage for multimodal evolution, encouraging further exploration and development in personalized cancer care.","['deep neural networks', 'Graph Neural Networks (GNNs)', 'Transformers']","The research idea centers on addressing the complexity and heterogeneity of cancer by integrating diverse types of data, such as screening, diagnostic imaging, histopathology, molecular data, and clinical records, to improve personalized cancer care. Traditional approaches that focus on isolated data types are insufficient for capturing the multifaceted nature of cancer, highlighting the need for more comprehensive methods to enhance the accuracy and reliability of cancer screening, diagnosis, and treatment. The research objective is to review and synthesize the current advancements in multimodal data integration within oncology, emphasizing the potential for combining various cancer-related data sources to achieve a more nuanced and comprehensive understanding of the disease. This study aims to outline the foundational principles, challenges, and opportunities in multimodal learning for cancer research, ultimately guiding future investigations toward improving personalized cancer care."
Psychology,Role of machine learning and deep learning techniques in EEG-based BCI emotion recognition system: a review,"Abstract Emotion is a subjective psychophysiological reaction coming from external stimuli which impacts every aspect of our daily lives. Due to the continuing development of non-invasive and portable sensor technologies, such as brain-computer interfaces (BCI), intellectuals from several fields have been interested in emotion recognition techniques. Human emotions can be recognised using a variety of behavioural cues, including gestures and body language, voice, and physiological markers. The first three, however, might be ineffective because people sometimes conceal their genuine emotions either intentionally or unknowingly. More precise and objective emotion recognition can be accomplished using physiological signals. Among other physiological signals, Electroencephalogram (EEG) is more responsive and sensitive to variation in affective states. Various EEG-based emotion recognition methods have recently been introduced. This study reviews EEG-based BCIs for emotion identification and gives an outline of the progress made in this field. A summary of the datasets and techniques utilised to evoke human emotions and various emotion models is also given. We discuss several EEG feature extractions, feature selection/reduction, machine learning, and deep learning algorithms in accordance with standard emotional identification process. We provide an overview of the human brain's EEG rhythms, which are closely related to emotional states. We also go over a number of EEG-based emotion identification research and compare numerous machine learning and deep learning techniques. In conclusion, this study highlights the applications, challenges and potential areas for future research in identification and classification of human emotional states.",['feature selection/reduction'],"The research idea centers on the importance of accurately recognizing human emotions, which are subjective psychophysiological reactions influenced by external stimuli and affect many aspects of daily life. Traditional behavioral cues such as gestures, body language, and voice may be unreliable because individuals can consciously or unconsciously conceal their true emotions. Therefore, there is a need for more precise and objective methods of emotion recognition using physiological signals, with a particular focus on brain activity that is sensitive to changes in affective states. The study addresses the ongoing development and progress in understanding how these physiological markers can improve emotion identification.

The primary objective of the study is to review the current state of research on emotion identification using physiological signals, specifically focusing on brain activity related to emotional states. It aims to summarize the various approaches used to evoke and model human emotions, outline the progress made in this area, and highlight the applications, challenges, and potential directions for future research in the identification and classification of human emotional states."
Psychology,A self-attention-based CNN-Bi-LSTM model for accurate state-of-charge estimation of lithium-ion batteries,"In the quest for clean and efficient energy solutions, lithium-ion batteries have emerged at the forefront of technological innovation. Accurate state-of-charge (SOC) estimation across a broad temperature range is essential for extending battery longevity, and enduring effective management of overcharge and over-discharge conditions. However, prevailing challenges persist in achieving precise SOC estimates and generalizing across a wide temperature range, particularly at lower temperatures. Our comparative analysis reveals that, while a single-layer bidirectional LSTM model with a self-attention mechanism achieves remarkable SOC estimation accuracy at room temperature, the intricacies of SOC estimation at lower temperatures necessitate the incorporation of more hidden layers and more complex network architecture to capture intricate features influencing battery dynamics. Hence, we propose a deep learning model, based on convolutional neural networks integrating bidirectional long short-term memory and self-attention mechanism (CNN-Bi-LSTM-AM), specifically designed to tackle the challenges of achieving accurate SOC estimations across a wide temperature range. The proposed model demonstrates proficiency in capturing both spatial and temporal dependencies critical for lithium-ion battery SOC estimation. Furthermore, the integration of a self-attention mechanism enhances the model's adeptness to discern pertinent features and patterns within the dataset, thereby improving its overall performance and robustness, even in sub-room temperature environments.","['single-layer bidirectional LSTM model with a self-attention mechanism', 'deep learning model based on convolutional neural networks integrating bidirectional long short-term memory and self-attention mechanism (CNN-Bi-LSTM-AM)']","The research idea centers on the challenge of accurately estimating the state-of-charge (SOC) of lithium-ion batteries across a wide temperature range, which is crucial for extending battery longevity and effectively managing overcharge and over-discharge conditions. Existing methods struggle particularly with precise SOC estimation at lower temperatures, highlighting the need for improved approaches to address these limitations. The primary objective of the study is to develop a solution that enhances the accuracy of SOC estimation across varying temperatures, with a focus on overcoming difficulties encountered in sub-room temperature environments. This aims to ensure more reliable battery management and performance under diverse thermal conditions."
Psychology,Artificial Intelligence in Point-of-Care Biosensing: Challenges and Opportunities,"The integration of artificial intelligence (AI) into point-of-care (POC) biosensing has the potential to revolutionize diagnostic methodologies by offering rapid, accurate, and accessible health assessment directly at the patient level. This review paper explores the transformative impact of AI technologies on POC biosensing, emphasizing recent computational advancements, ongoing challenges, and future prospects in the field. We provide an overview of core biosensing technologies and their use at the POC, highlighting ongoing issues and challenges that may be solved with AI. We follow with an overview of AI methodologies that can be applied to biosensing, including machine learning algorithms, neural networks, and data processing frameworks that facilitate real-time analytical decision-making. We explore the applications of AI at each stage of the biosensor development process, highlighting the diverse opportunities beyond simple data analysis procedures. We include a thorough analysis of outstanding challenges in the field of AI-assisted biosensing, focusing on the technical and ethical challenges regarding the widespread adoption of these technologies, such as data security, algorithmic bias, and regulatory compliance. Through this review, we aim to emphasize the role of AI in advancing POC biosensing and inform researchers, clinicians, and policymakers about the potential of these technologies in reshaping global healthcare landscapes.",['neural networks'],"The research idea centers on the potential to transform diagnostic methodologies by enabling rapid, accurate, and accessible health assessments directly at the patient level through advancements in point-of-care biosensing. The study addresses ongoing issues and challenges in current biosensing technologies that impact their effectiveness and accessibility in healthcare settings. The primary objective of the study is to explore the transformative impact of recent advancements on point-of-care biosensing, highlighting the challenges and future prospects in the field. It aims to inform researchers, clinicians, and policymakers about the opportunities and obstacles involved in advancing these diagnostic approaches to improve global healthcare outcomes."
Psychology,Evaluating the persuasive influence of political microtargeting with large language models,"Recent advancements in large language models (LLMs) have raised the prospect of scalable, automated, and fine-grained political microtargeting on a scale previously unseen; however, the persuasive influence of microtargeting with LLMs remains unclear. Here, we build a custom web application capable of integrating self-reported demographic and political data into GPT-4 prompts in real-time, facilitating the live creation of unique messages tailored to persuade individual users on four political issues. We then deploy this application in a preregistered randomized control experiment ( n = 8,587) to investigate the extent to which access to individual-level data increases the persuasive influence of GPT-4. Our approach yields two key findings. First, messages generated by GPT-4 were broadly persuasive, in some cases increasing support for an issue stance by up to 12 percentage points. Second, in aggregate, the persuasive impact of microtargeted messages was not statistically different from that of non-microtargeted messages (4.83 vs. 6.20 percentage points, respectively, P = 0.226). These trends hold even when manipulating the type and number of attributes used to tailor the message. These findings suggest—contrary to widespread speculation—that the influence of current LLMs may reside not in their ability to tailor messages to individuals but rather in the persuasiveness of their generic, nontargeted messages. We release our experimental dataset, GPTarget2024 , as an empirical baseline for future research.",['GPT-4'],"The research idea centers on understanding the persuasive influence of personalized political messaging, specifically examining whether tailoring messages to individuals based on their demographic and political characteristics enhances persuasion. Despite the growing interest in microtargeting as a strategy to influence political opinions, it remains unclear if such individualized approaches are more effective than generic messaging. The study aims to clarify the extent to which access to individual-level data increases the persuasive impact of political messages. The primary objective of the study is to investigate whether microtargeted political messages, customized using personal demographic and political information, have a greater persuasive effect on individuals compared to non-microtargeted, generic messages across multiple political issues."
Medicine,Discovering biomarkers associated and predicting cardiovascular disease with high accuracy using a novel nexus of machine learning techniques for precision medicine,"Abstract Personalized interventions are deemed vital given the intricate characteristics, advancement, inherent genetic composition, and diversity of cardiovascular diseases (CVDs). The appropriate utilization of artificial intelligence (AI) and machine learning (ML) methodologies can yield novel understandings of CVDs, enabling improved personalized treatments through predictive analysis and deep phenotyping. In this study, we proposed and employed a novel approach combining traditional statistics and a nexus of cutting-edge AI/ML techniques to identify significant biomarkers for our predictive engine by analyzing the complete transcriptome of CVD patients. After robust gene expression data pre-processing, we utilized three statistical tests (Pearson correlation, Chi-square test, and ANOVA) to assess the differences in transcriptomic expression and clinical characteristics between healthy individuals and CVD patients. Next, the recursive feature elimination classifier assigned rankings to transcriptomic features based on their relation to the case–control variable. The top ten percent of commonly observed significant biomarkers were evaluated using four unique ML classifiers (Random Forest, Support Vector Machine, Xtreme Gradient Boosting Decision Trees, and k-Nearest Neighbors). After optimizing hyperparameters, the ensembled models, which were implemented using a soft voting classifier, accurately differentiated between patients and healthy individuals. We have uncovered 18 transcriptomic biomarkers that are highly significant in the CVD population that were used to predict disease with up to 96% accuracy. Additionally, we cross-validated our results with clinical records collected from patients in our cohort. The identified biomarkers served as potential indicators for early detection of CVDs. With its successful implementation, our newly developed predictive engine provides a valuable framework for identifying patients with CVDs based on their biomarker profiles.","['Random Forest', 'Support Vector Machine', 'Xtreme Gradient Boosting Decision Trees', 'k-Nearest Neighbors', 'soft voting classifier']","The research idea centers on the need for personalized interventions in cardiovascular diseases (CVDs) due to their complex characteristics, progression, genetic makeup, and diversity. Understanding these intricacies is crucial for improving treatment outcomes and early detection. The study aims to identify significant biomarkers that can serve as potential indicators for early detection and better management of CVDs. The primary objective of the study is to identify and validate transcriptomic biomarkers that distinguish between healthy individuals and CVD patients, thereby enabling accurate prediction and early diagnosis of cardiovascular diseases. This objective is pursued through the analysis of gene expression data and clinical characteristics to uncover biomarkers highly significant in the CVD population."
Medicine,Improving large language models for clinical named entity recognition via prompt engineering,"Abstract Importance The study highlights the potential of large language models, specifically GPT-3.5 and GPT-4, in processing complex clinical data and extracting meaningful information with minimal training data. By developing and refining prompt-based strategies, we can significantly enhance the models’ performance, making them viable tools for clinical NER tasks and possibly reducing the reliance on extensive annotated datasets. Objectives This study quantifies the capabilities of GPT-3.5 and GPT-4 for clinical named entity recognition (NER) tasks and proposes task-specific prompts to improve their performance. Materials and Methods We evaluated these models on 2 clinical NER tasks: (1) to extract medical problems, treatments, and tests from clinical notes in the MTSamples corpus, following the 2010 i2b2 concept extraction shared task, and (2) to identify nervous system disorder-related adverse events from safety reports in the vaccine adverse event reporting system (VAERS). To improve the GPT models' performance, we developed a clinical task-specific prompt framework that includes (1) baseline prompts with task description and format specification, (2) annotation guideline-based prompts, (3) error analysis-based instructions, and (4) annotated samples for few-shot learning. We assessed each prompt's effectiveness and compared the models to BioClinicalBERT. Results Using baseline prompts, GPT-3.5 and GPT-4 achieved relaxed F1 scores of 0.634, 0.804 for MTSamples and 0.301, 0.593 for VAERS. Additional prompt components consistently improved model performance. When all 4 components were used, GPT-3.5 and GPT-4 achieved relaxed F1 socres of 0.794, 0.861 for MTSamples and 0.676, 0.736 for VAERS, demonstrating the effectiveness of our prompt framework. Although these results trail BioClinicalBERT (F1 of 0.901 for the MTSamples dataset and 0.802 for the VAERS), it is very promising considering few training samples are needed. Discussion The study’s findings suggest a promising direction in leveraging LLMs for clinical NER tasks. However, while the performance of GPT models improved with task-specific prompts, there's a need for further development and refinement. LLMs like GPT-4 show potential in achieving close performance to state-of-the-art models like BioClinicalBERT, but they still require careful prompt engineering and understanding of task-specific knowledge. The study also underscores the importance of evaluation schemas that accurately reflect the capabilities and performance of LLMs in clinical settings. Conclusion While direct application of GPT models to clinical NER tasks falls short of optimal performance, our task-specific prompt framework, incorporating medical knowledge and training samples, significantly enhances GPT models' feasibility for potential clinical applications.","['large language models (GPT-3.5)', 'large language models (GPT-4)', 'prompt-based strategies', 'few-shot learning', 'BioClinicalBERT']","The study addresses the challenge of accurately extracting meaningful clinical information, such as medical problems, treatments, and adverse events, from complex clinical texts with limited annotated data. It highlights the need for effective strategies to improve the performance of tools used for clinical named entity recognition (NER) tasks, which are essential for processing clinical notes and safety reports. The primary aim of the study is to quantify the capabilities of specific language models in performing clinical NER tasks and to propose task-specific strategies that enhance their performance in extracting relevant clinical concepts. This objective focuses on improving the feasibility of these tools for clinical applications by incorporating medical knowledge and limited training samples."
Medicine,"Revolutionizing agriculture with artificial intelligence: plant disease detection methods, applications, and their limitations","Accurate and rapid plant disease detection is critical for enhancing long-term agricultural yield. Disease infection poses the most significant challenge in crop production, potentially leading to economic losses. Viruses, fungi, bacteria, and other infectious organisms can affect numerous plant parts, including roots, stems, and leaves. Traditional techniques for plant disease detection are time-consuming, require expertise, and are resource-intensive. Therefore, automated leaf disease diagnosis using artificial intelligence (AI) with Internet of Things (IoT) sensors methodologies are considered for the analysis and detection. This research examines four crop diseases: tomato, chilli, potato, and cucumber. It also highlights the most prevalent diseases and infections in these four types of vegetables, along with their symptoms. This review provides detailed predetermined steps to predict plant diseases using AI. Predetermined steps include image acquisition, preprocessing, segmentation, feature selection, and classification. Machine learning (ML) and deep understanding (DL) detection models are discussed. A comprehensive examination of various existing ML and DL-based studies to detect the disease of the following four crops is discussed, including the datasets used to evaluate these studies. We also provided the list of plant disease detection datasets. Finally, different ML and DL application problems are identified and discussed, along with future research prospects, by combining AI with IoT platforms like smart drones for field-based disease detection and monitoring. This work will help other practitioners in surveying different plant disease detection strategies and the limits of present systems.","['machine learning (ML)', 'deep learning (DL)']","The research addresses the critical need for accurate and rapid detection of plant diseases to enhance long-term agricultural yield, as disease infections pose significant challenges in crop production and can lead to substantial economic losses. Various infectious organisms such as viruses, fungi, and bacteria affect multiple parts of plants, including roots, stems, and leaves, making timely and effective diagnosis essential. The primary objective of the study is to examine and highlight the most prevalent diseases and infections in four major crops—tomato, chilli, potato, and cucumber—along with their symptoms. Additionally, the study aims to provide a comprehensive review of existing approaches for plant disease detection, discuss the limitations of current methods, and outline future research prospects to improve disease diagnosis and monitoring in these crops."
Medicine,Can large language models replace humans in systematic reviews? Evaluating <scp>GPT</scp>‐4's efficacy in screening and extracting data from peer‐reviewed and grey literature in multiple languages,"Systematic reviews are vital for guiding practice, research and policy, although they are often slow and labour-intensive. Large language models (LLMs) could speed up and automate systematic reviews, but their performance in such tasks has yet to be comprehensively evaluated against humans, and no study has tested Generative Pre-Trained Transformer (GPT)-4, the biggest LLM so far. This pre-registered study uses a ""human-out-of-the-loop"" approach to evaluate GPT-4's capability in title/abstract screening, full-text review and data extraction across various literature types and languages. Although GPT-4 had accuracy on par with human performance in some tasks, results were skewed by chance agreement and dataset imbalance. Adjusting for these caused performance scores to drop across all stages: for data extraction, performance was moderate, and for screening, it ranged from none in highly balanced literature datasets (~1:1) to moderate in those datasets where the ratio of inclusion to exclusion in studies was imbalanced (~1:3). When screening full-text literature using highly reliable prompts, GPT-4's performance was more robust, reaching ""human-like"" levels. Although our findings indicate that, currently, substantial caution should be exercised if LLMs are being used to conduct systematic reviews, they also offer preliminary evidence that, for certain review tasks delivered under specific conditions, LLMs can rival human performance.",['Generative Pre-Trained Transformer (GPT)-4'],"The research idea centers on the importance of systematic reviews for guiding clinical practice, research, and policy, while highlighting the challenges posed by their slow and labor-intensive nature. There is a need to explore ways to improve the efficiency of conducting systematic reviews without compromising accuracy. The study’s primary objective is to evaluate the capability of a large language model, specifically GPT-4, in performing key tasks involved in systematic reviews such as title and abstract screening, full-text review, and data extraction across diverse types of literature and languages. The aim is to determine how well GPT-4 performs these tasks compared to human reviewers and to assess its potential role in supporting or automating systematic review processes."
Medicine,Optimization of hepatological clinical guidelines interpretation by large language models: a retrieval augmented generation-based framework,"Abstract Large language models (LLMs) can potentially transform healthcare, particularly in providing the right information to the right provider at the right time in the hospital workflow. This study investigates the integration of LLMs into healthcare, specifically focusing on improving clinical decision support systems (CDSSs) through accurate interpretation of medical guidelines for chronic Hepatitis C Virus infection management. Utilizing OpenAI’s GPT-4 Turbo model, we developed a customized LLM framework that incorporates retrieval augmented generation (RAG) and prompt engineering. Our framework involved guideline conversion into the best-structured format that can be efficiently processed by LLMs to provide the most accurate output. An ablation study was conducted to evaluate the impact of different formatting and learning strategies on the LLM’s answer generation accuracy. The baseline GPT-4 Turbo model’s performance was compared against five experimental setups with increasing levels of complexity: inclusion of in-context guidelines, guideline reformatting, and implementation of few-shot learning. Our primary outcome was the qualitative assessment of accuracy based on expert review, while secondary outcomes included the quantitative measurement of similarity of LLM-generated responses to expert-provided answers using text-similarity scores. The results showed a significant improvement in accuracy from 43 to 99% ( p &lt; 0.001), when guidelines were provided as context in a coherent corpus of text and non-text sources were converted into text. In addition, few-shot learning did not seem to improve overall accuracy. The study highlights that structured guideline reformatting and advanced prompt engineering (data quality vs. data quantity) can enhance the efficacy of LLM integrations to CDSSs for guideline delivery.","['OpenAI’s GPT-4 Turbo model', 'retrieval augmented generation (RAG)', 'few-shot learning']","The research idea addresses the challenge of improving clinical decision support systems (CDSSs) in healthcare by enhancing the accurate interpretation and delivery of medical guidelines for managing chronic Hepatitis C Virus infection. There is a need to provide the right information to healthcare providers at the right time within the hospital workflow to support better clinical decisions. The study focuses on overcoming limitations in guideline presentation to improve the accuracy of guideline-based recommendations in clinical practice. The primary objective of the study is to investigate how the integration of structured and well-formatted medical guidelines can improve the accuracy of clinical decision support for chronic Hepatitis C Virus infection management. The study aims to assess the impact of different guideline formatting strategies on the accuracy of guideline interpretation and delivery, with the goal of enhancing the effectiveness of clinical decision support systems in healthcare settings."
Medicine,Employing deep learning and transfer learning for accurate brain tumor detection,"Abstract Artificial intelligence-powered deep learning methods are being used to diagnose brain tumors with high accuracy, owing to their ability to process large amounts of data. Magnetic resonance imaging stands as the gold standard for brain tumor diagnosis using machine vision, surpassing computed tomography, ultrasound, and X-ray imaging in its effectiveness. Despite this, brain tumor diagnosis remains a challenging endeavour due to the intricate structure of the brain. This study delves into the potential of deep transfer learning architectures to elevate the accuracy of brain tumor diagnosis. Transfer learning is a machine learning technique that allows us to repurpose pre-trained models on new tasks. This can be particularly useful for medical imaging tasks, where labelled data is often scarce. Four distinct transfer learning architectures were assessed in this study: ResNet152, VGG19, DenseNet169, and MobileNetv3. The models were trained and validated on a dataset from benchmark database: Kaggle. Five-fold cross validation was adopted for training and testing. To enhance the balance of the dataset and improve the performance of the models, image enhancement techniques were applied to the data for the four categories: pituitary, normal, meningioma, and glioma. MobileNetv3 achieved the highest accuracy of 99.75%, significantly outperforming other existing methods. This demonstrates the potential of deep transfer learning architectures to revolutionize the field of brain tumor diagnosis.","['deep learning', 'deep transfer learning', 'transfer learning', 'ResNet152', 'VGG19', 'DenseNet169', 'MobileNetv3']","The study addresses the challenge of accurately diagnosing brain tumors, which remains difficult due to the complex structure of the brain. Magnetic resonance imaging is recognized as the gold standard for brain tumor diagnosis, yet improving diagnostic accuracy continues to be a critical need in medical practice. The research focuses on enhancing the precision of brain tumor identification to support better clinical outcomes. The primary aim of the study is to evaluate different approaches to improve the accuracy of brain tumor diagnosis using magnetic resonance imaging data. The objective is to assess and compare various methods to determine which can most effectively distinguish between different types of brain tumors, including pituitary, meningioma, glioma, and normal brain tissue, thereby advancing diagnostic capabilities in this field."
Medicine,Transformative Breast Cancer Diagnosis using CNNs with Optimized ReduceLROnPlateau and Early Stopping Enhancements,"Abstract Breast cancer stands as a paramount public health concern worldwide, underscoring an imperative necessity within the research sphere for precision-driven and efficacious methodologies facilitating accurate detection. The existing diagnostic approaches in breast cancer often suffer from limitations in accuracy and efficiency, leading to delayed detection and subsequent challenges in personalized treatment planning. The primary focus of this research is to overcome these shortcomings by harnessing the power of advanced deep learning techniques, thereby revolutionizing the precision and reliability of breast cancer classification. This research addresses the critical need for improved breast cancer diagnostics by introducing a novel Convolutional Neural Network (CNN) model integrated with an Early Stopping callback and ReduceLROnPlateau callback. By enhancing the precision and reliability of breast cancer classification, the study aims to overcome the limitations of existing diagnostic methods, ultimately leading to better patient outcomes and reduced mortality rates. The comprehensive methodology includes diverse datasets, meticulous image preprocessing, robust model training, and validation strategies, emphasizing the model's adaptability and reliability in varied clinical contexts. The findings showcase the CNN model's exceptional performance, achieving a 95.2% accuracy rate in distinguishing cancerous and non-cancerous breast tissue in the integrated dataset, thereby demonstrating its potential for enhancing clinical decision-making and fostering the development of AI-driven diagnostic solutions.","['Convolutional Neural Network (CNN)', 'Early Stopping callback']","Breast cancer remains a significant public health challenge globally, highlighting the urgent need for more accurate and efficient diagnostic methods. Current approaches often face limitations that result in delayed detection and complicate personalized treatment planning. The study is motivated by the necessity to improve the precision and reliability of breast cancer classification to address these diagnostic shortcomings. The primary objective of this research is to enhance breast cancer diagnostics by developing a method that improves the accuracy and reliability of distinguishing cancerous from non-cancerous breast tissue, ultimately aiming to facilitate better patient outcomes and reduce mortality rates."
Medicine,Investigating Spatial Effects through Machine Learning and Leveraging Explainable AI for Child Malnutrition in Pakistan,"While socioeconomic gradients in regional health inequalities are firmly established, the synergistic interactions between socioeconomic deprivation and climate vulnerability within convenient proximity and neighbourhood locations with health disparities remain poorly explored and thus require deep understanding within a regional context. Furthermore, disregarding the importance of spatial spillover effects and nonlinear effects of covariates on childhood stunting are inevitable in dealing with an enduring issue of regional health inequalities. The present study aims to investigate the spatial inequalities in childhood stunting at the district level in Pakistan and validate the importance of spatial lag in predicting childhood stunting. Furthermore, it examines the presence of any nonlinear relationships among the selected independent features with childhood stunting. The study utilized data related to socioeconomic features from MICS 2017–2018 and climatic data from Integrated Contextual Analysis. A multi-model approach was employed to address the research questions, which included Ordinary Least Squares Regression (OLS), various Spatial Models, Machine Learning Algorithms and Explainable Artificial Intelligence methods. Firstly, OLS was used to analyse and test the linear relationships among selected variables. Secondly, Spatial Durbin Error Model (SDEM) was used to detect and capture the impact of spatial spillover on childhood stunting. Third, XGBoost and Random Forest machine learning algorithms were employed to examine and validate the importance of the spatial lag component. Finally, EXAI methods such as SHapley were utilized to identify potential nonlinear relationships. The study found a clear pattern of spatial clustering and geographical disparities in childhood stunting, with multidimensional poverty, high climate vulnerability and early marriage worsening childhood stunting. In contrast, low climate vulnerability, high exposure to mass media and high women’s literacy were found to reduce childhood stunting. The use of machine learning algorithms, specifically XGBoost and Random Forest, highlighted the significant role played by the average value in the neighbourhood in predicting childhood stunting in nearby districts, confirming that the spatial spillover effect is not bounded by geographical boundaries. Furthermore, EXAI methods such as partial dependency plot reveal the existence of a nonlinear relationship between multidimensional poverty and childhood stunting. The study’s findings provide valuable insights into the spatial distribution of childhood stunting in Pakistan, emphasizing the importance of considering spatial effects in predicting childhood stunting. Individual and household-level factors such as exposure to mass media and women’s literacy have shown positive implications for childhood stunting. It further provides a justification for the usage of EXAI methods to draw better insights and propose customised intervention policies accordingly.","['XGBoost', 'Random Forest', 'partial dependency plot']","The research idea addresses the complex interplay between socioeconomic deprivation and climate vulnerability in contributing to regional health inequalities, specifically focusing on childhood stunting. Despite established knowledge of socioeconomic gradients in health disparities, the combined effects of these factors within local neighborhoods and their spatial interactions remain insufficiently understood, particularly in the context of Pakistan. This gap highlights the need to explore how spatial spillover effects and nonlinear relationships among various determinants influence childhood stunting across different districts. The study aims to investigate spatial inequalities in childhood stunting at the district level in Pakistan, emphasizing the importance of spatial factors in understanding health disparities. It seeks to validate the role of spatial proximity in predicting childhood stunting and to examine potential nonlinear relationships between selected socioeconomic and climatic variables and childhood stunting, thereby providing insights for targeted public health interventions."
Medicine,Unmasking bias in artificial intelligence: a systematic review of bias detection and mitigation strategies in electronic health record-based models,"Abstract Objectives Leveraging artificial intelligence (AI) in conjunction with electronic health records (EHRs) holds transformative potential to improve healthcare. However, addressing bias in AI, which risks worsening healthcare disparities, cannot be overlooked. This study reviews methods to handle various biases in AI models developed using EHR data. Materials and Methods We conducted a systematic review following the Preferred Reporting Items for Systematic Reviews and Meta-analyses guidelines, analyzing articles from PubMed, Web of Science, and IEEE published between January 01, 2010 and December 17, 2023. The review identified key biases, outlined strategies for detecting and mitigating bias throughout the AI model development, and analyzed metrics for bias assessment. Results Of the 450 articles retrieved, 20 met our criteria, revealing 6 major bias types: algorithmic, confounding, implicit, measurement, selection, and temporal. The AI models were primarily developed for predictive tasks, yet none have been deployed in real-world healthcare settings. Five studies concentrated on the detection of implicit and algorithmic biases employing fairness metrics like statistical parity, equal opportunity, and predictive equity. Fifteen studies proposed strategies for mitigating biases, especially targeting implicit and selection biases. These strategies, evaluated through both performance and fairness metrics, predominantly involved data collection and preprocessing techniques like resampling and reweighting. Discussion This review highlights evolving strategies to mitigate bias in EHR-based AI models, emphasizing the urgent need for both standardized and detailed reporting of the methodologies and systematic real-world testing and evaluation. Such measures are essential for gauging models’ practical impact and fostering ethical AI that ensures fairness and equity in healthcare.","['resampling', 'reweighting']","The research idea centers on the critical issue of bias in healthcare applications developed using electronic health records, which poses a risk of exacerbating healthcare disparities. Addressing these biases is essential to ensure fairness and equity in healthcare delivery. The study recognizes the transformative potential of improving healthcare outcomes but emphasizes that bias cannot be overlooked in this context. The primary objective of the study is to review existing methods for identifying and mitigating various types of bias in healthcare models developed from electronic health record data. It aims to outline strategies for detecting and reducing bias and to analyze metrics used for bias assessment, with the goal of promoting ethical practices and ensuring equitable healthcare outcomes."
Medicine,Real-Time Plant Disease Dataset Development and Detection of Plant Disease Using Deep Learning,"Agriculture plays a significant role in meeting food needs and providing food security for the increasingly growing global population, which has increased by 0.88% since 2022. Plant diseases can reduce food production and affect food security. Worldwide crop loss due to plant disease is estimated to be around 14.1%. The lack of proper identification of plant disease at the early stages of infection can result in inappropriate disease control measures. Therefore, the automatic identification and diagnosis of plant diseases are highly recommended. Lack of availability of large amounts of data that are not processed to a large extent is one of the main challenges in plant disease diagnosis. In the current manuscript, we developed datasets for food grains specifically for rice, wheat, and maize to address the identified challenges. The developed datasets consider the common diseases (two bacterial diseases and two fungal diseases of rice, four fungal diseases of maize, and four fungal diseases of wheat) that affect crop yields and cause damage to the whole plant. The datasets developed were applied to eight fine-tuned deep learning models with the same training hyperparameters. The experimental results based on eight fine-tuned deep learning models show that, while recognizing maize leaf diseases, the models Xception and MobileNet performed best with a testing accuracy of 0.9580 and 0.9464 respectively. Similarly, while recognizing the wheat leaf diseases, the models MobileNetV2 and MobileNet performed best with a testing accuracy of 0.9632 and 0.9628 respectively. The Xception and Inception V3 models performed best, with a testing accuracy of 0.9728 and 0.9620, respectively, for recognizing rice leaf diseases. The research also proposes a new convolutional neural network (CNN) model trained from scratch on all three food grain datasets developed. The proposed model performs well and shows a testing accuracy of 0.9704, 0.9706, and 0.9808 respectively on the maize, rice, and wheat datasets.","['fine-tuned deep learning models', 'Xception', 'MobileNet', 'MobileNetV2', 'Inception V3', 'convolutional neural network (CNN) model trained from scratch']","The research addresses the significant impact of plant diseases on food production and food security, emphasizing that worldwide crop loss due to plant disease is estimated to be around 14.1%. Early and accurate identification of plant diseases is crucial to prevent inappropriate disease control measures that can further harm crop yields. The study highlights the challenge posed by the lack of properly processed and comprehensive data for diagnosing plant diseases, particularly in important food grains such as rice, wheat, and maize. The primary objective of the study is to develop datasets for common bacterial and fungal diseases affecting these food grains to improve the identification and diagnosis of plant diseases, thereby supporting efforts to reduce crop damage and enhance food security."
Medicine,Vision–language foundation model for echocardiogram interpretation,"Abstract The development of robust artificial intelligence models for echocardiography has been limited by the availability of annotated clinical data. Here, to address this challenge and improve the performance of cardiac imaging models, we developed EchoCLIP, a vision–language foundation model for echocardiography, that learns the relationship between cardiac ultrasound images and the interpretations of expert cardiologists across a wide range of patients and indications for imaging. After training on 1,032,975 cardiac ultrasound videos and corresponding expert text, EchoCLIP performs well on a diverse range of benchmarks for cardiac image interpretation, despite not having been explicitly trained for individual interpretation tasks. EchoCLIP can assess cardiac function (mean absolute error of 7.1% when predicting left ventricular ejection fraction in an external validation dataset) and identify implanted intracardiac devices (area under the curve (AUC) of 0.84, 0.92 and 0.97 for pacemakers, percutaneous mitral valve repair and artificial aortic valves, respectively). We also developed a long-context variant (EchoCLIP-R) using a custom tokenizer based on common echocardiography concepts. EchoCLIP-R accurately identified unique patients across multiple videos (AUC of 0.86), identified clinical transitions such as heart transplants (AUC of 0.79) and cardiac surgery (AUC 0.77) and enabled robust image-to-text search (mean cross-modal retrieval rank in the top 1% of candidate text reports). These capabilities represent a substantial step toward understanding and applying foundation models in cardiovascular imaging for preliminary interpretation of echocardiographic findings.",['vision–language foundation model'],"The research addresses the challenge of limited availability of annotated clinical data for echocardiography, which has hindered the development of robust methods for cardiac imaging interpretation. Improving the understanding and performance of cardiac ultrasound image analysis is essential for better assessment of cardiac function and identification of intracardiac devices across diverse patient populations and clinical indications. The primary aim of the study is to develop a comprehensive approach that learns the relationship between cardiac ultrasound images and expert cardiologists’ interpretations to enhance the accuracy and applicability of echocardiographic evaluation. This includes assessing cardiac function, identifying implanted devices, recognizing clinical transitions such as heart transplants and cardiac surgery, and enabling effective retrieval of relevant clinical information from imaging data."
Medicine,Oral squamous cell carcinoma detection using EfficientNet on histopathological images,"Introduction Oral Squamous Cell Carcinoma (OSCC) poses a significant challenge in oncology due to the absence of precise diagnostic tools, leading to delays in identifying the condition. Current diagnostic methods for OSCC have limitations in accuracy and efficiency, highlighting the need for more reliable approaches. This study aims to explore the discriminative potential of histopathological images of oral epithelium and OSCC. By utilizing a database containing 1224 images from 230 patients, captured at varying magnifications and publicly available, a customized deep learning model based on EfficientNetB3 was developed. The model’s objective was to differentiate between normal epithelium and OSCC tissues by employing advanced techniques such as data augmentation, regularization, and optimization. Methods The research utilized a histopathological imaging database for Oral Cancer analysis, incorporating 1224 images from 230 patients. These images, taken at various magnifications, formed the basis for training a specialized deep learning model built upon the EfficientNetB3 architecture. The model underwent training to distinguish between normal epithelium and OSCC tissues, employing sophisticated methodologies including data augmentation, regularization techniques, and optimization strategies. Results The customized deep learning model achieved significant success, showcasing a remarkable 99% accuracy when tested on the dataset. This high accuracy underscores the model’s efficacy in effectively discerning between normal epithelium and OSCC tissues. Furthermore, the model exhibited impressive precision, recall, and F1-score metrics, reinforcing its potential as a robust diagnostic tool for OSCC. Discussion This research demonstrates the promising potential of employing deep learning models to address the diagnostic challenges associated with OSCC. The model’s ability to achieve a 99% accuracy rate on the test dataset signifies a considerable leap forward in earlier and more accurate detection of OSCC. Leveraging advanced techniques in machine learning, such as data augmentation and optimization, has shown promising results in improving patient outcomes through timely and precise identification of OSCC.",['deep learning model based on EfficientNetB3'],"Oral Squamous Cell Carcinoma (OSCC) presents a significant challenge in oncology due to the lack of precise diagnostic tools, which often results in delays in identifying the condition. Current diagnostic methods for OSCC are limited in both accuracy and efficiency, underscoring the need for more reliable approaches to improve early detection. The primary aim of this study is to explore the discriminative potential of histopathological images of oral epithelium and OSCC. Specifically, the study seeks to differentiate between normal epithelium and OSCC tissues using a comprehensive database of histopathological images, with the goal of enhancing the accuracy and reliability of OSCC diagnosis."
Medicine,Damage identification of steel bridge based on data augmentation and adaptive optimization neural network,"With the advancement of deep learning, data-driven structural damage identification (SDI) has shown considerable development. However, collecting vibration signals related to structural damage poses certain challenges, which can undermine the accuracy of the identification results produced by data-driven SDI methods in scenarios where data is scarce. This paper introduces an innovative approach to bridge SDI in a few-shot context by integrating an adaptive simulated annealing particle swarm optimization-convolutional neural network (ASAPSO-CNN) as the foundational framework, augmented by data enhancement techniques. Firstly, three specific types of noise are introduced to augment the source signals used for training. Subsequently, the source signals and augmented signals are recombined to construct a four-dimensional matrix as the input to the CNN, while defining the damage feature vector as the output. Secondly, a CNN is constructed to establish the mapping relationship between the input and output. Then, an adaptive fitness function is proposed that simultaneously considers the accuracy of SDI, model complexity, and training efficiency. The ASAPSO is employed to adaptively optimize the hyperparameters of the CNN. The proposed method is validated on an experimental model of a three-span continuous beam. It is compared with four other data-driven methods, demonstrating good effectiveness and robustness of SDI under cases of scarce data. Finally, the effectiveness of this SDI method is validated in a real-world case of a steel truss bridge.",['convolutional neural network (CNN)'],"The research idea addresses the challenge of accurately identifying structural damage when vibration signal data related to such damage is scarce, which can compromise the reliability of existing identification methods. The study is motivated by the need to improve structural damage identification in scenarios where collecting sufficient vibration signals is difficult, thereby enhancing the detection accuracy and robustness under limited data conditions. The primary objective of the study is to develop and validate a novel approach that improves the identification of structural damage using limited vibration signal data. This approach aims to enhance the effectiveness and robustness of damage detection in both experimental models and real-world structures, such as steel truss bridges, particularly in cases where data availability is constrained."
Medicine,Enhancing heart disease prediction using a self-attention-based transformer model,"Abstract Cardiovascular diseases (CVDs) continue to be the leading cause of more than 17 million mortalities worldwide. The early detection of heart failure with high accuracy is crucial for clinical trials and therapy. Patients will be categorized into various types of heart disease based on characteristics like blood pressure, cholesterol levels, heart rate, and other characteristics. With the use of an automatic system, we can provide early diagnoses for those who are prone to heart failure by analyzing their characteristics. In this work, we deploy a novel self-attention-based transformer model, that combines self-attention mechanisms and transformer networks to predict CVD risk. The self-attention layers capture contextual information and generate representations that effectively model complex patterns in the data. Self-attention mechanisms provide interpretability by giving each component of the input sequence a certain amount of attention weight. This includes adjusting the input and output layers, incorporating more layers, and modifying the attention processes to collect relevant information. This also makes it possible for physicians to comprehend which features of the data contributed to the model's predictions. The proposed model is tested on the Cleveland dataset, a benchmark dataset of the University of California Irvine (UCI) machine learning (ML) repository. Comparing the proposed model to several baseline approaches, we achieved the highest accuracy of 96.51%. Furthermore, the outcomes of our experiments demonstrate that the prediction rate of our model is higher than that of other cutting-edge approaches used for heart disease prediction.","['self-attention-based transformer model', 'self-attention mechanisms', 'transformer networks']","Cardiovascular diseases (CVDs) remain the leading cause of over 17 million deaths globally, highlighting the critical need for early and accurate detection of heart failure to improve clinical outcomes and guide therapy. Identifying patients at risk by categorizing them based on clinical characteristics such as blood pressure, cholesterol levels, and heart rate is essential for timely intervention. The primary aim of this study is to enhance the early diagnosis of heart failure by effectively utilizing patient characteristics to predict the risk of cardiovascular disease. This approach seeks to support physicians in understanding which clinical features contribute most significantly to the risk, thereby facilitating better-informed medical decisions."
Medicine,The diagnostic and triage accuracy of the GPT-3 artificial intelligence model: an observational study,"BackgroundArtificial intelligence (AI) applications in health care have been effective in many areas of medicine, but they are often trained for a single task using labelled data, making deployment and generalisability challenging. How well a general-purpose AI language model performs diagnosis and triage relative to physicians and laypeople is not well understood.MethodsWe compared the predictive accuracy of Generative Pre-trained Transformer 3 (GPT-3)'s diagnostic and triage ability for 48 validated synthetic case vignettes (<50 words; sixth-grade reading level or below) of both common (eg, viral illness) and severe (eg, heart attack) conditions to a nationally representative sample of 5000 lay people from the USA who could use the internet to find the correct options and 21 practising physicians at Harvard Medical School. There were 12 vignettes for each of four triage categories: emergent, within one day, within 1 week, and self-care. The correct diagnosis and triage category (ie, ground truth) for each vignette was determined by two general internists at Harvard Medical School. For each vignette, human respondents and GPT-3 were prompted to list diagnoses in order of likelihood, and the vignette was marked as correct if the ground-truth diagnosis was in the top three of the listed diagnoses. For triage accuracy, we examined whether the human respondents' and GPT-3's selected triage was exactly correct according to the four triage categories, or matched a dichotomised triage variable (emergent or within 1 day vs within 1 week or self-care). We estimated GPT-3's diagnostic and triage confidence on a given vignette using a modified bootstrap resampling procedure, and examined how well calibrated GPT-3's confidence was by computing calibration curves and Brier scores. We also performed subgroup analysis by case acuity, and an error analysis for triage advice to characterise how its advice might affect patients using this tool to decide if they should seek medical care immediately.FindingsAmong all cases, GPT-3 replied with the correct diagnosis in its top three for 88% (42/48, 95% CI 75–94) of cases, compared with 54% (2700/5000, 53–55) for lay individuals (p<0.0001) and 96% (637/666, 94–97) for physicians (p=0·012). GPT-3 triaged 70% correct (34/48, 57–82) versus 74% (3706/5000, 73–75; p=0.60) for lay individuals and 91% (608/666, 89–93%; p<0.0001) for physicians. As measured by the Brier score, GPT-3 confidence in its top prediction was reasonably well calibrated for diagnosis (Brier score=0·18) and triage (Brier score=0·22). We observed an inverse relationship between case acuity and GPT-3 accuracy (p<0·0001) with a fitted trend line of –8·33% decrease in accuracy for every level of increase in case acuity. For triage error analysis, GPT-3 deprioritised truly emergent cases in seven instances.InterpretationA general-purpose AI language model without any content-specific training could perform diagnosis at levels close to, but below, physicians and better than lay individuals. We found that GPT-3's performance was inferior to physicians for triage, sometimes by a large margin, and its performance was closer to that of lay individuals. Although the diagnostic performance of GPT-3 was comparable to physicians, it was significantly better than a typical person using a search engine.FundingThe National Heart, Lung, and Blood Institute.",['Generative Pre-trained Transformer 3 (GPT-3)'],"The study addresses the challenge of understanding how well a general-purpose diagnostic and triage tool performs compared to physicians and laypeople, particularly given the difficulty in deploying tools that are typically trained for single tasks. There is limited knowledge about the accuracy and reliability of such a tool in diagnosing and triaging a range of medical conditions, from common illnesses to severe emergencies. The primary aim of the study is to evaluate the diagnostic and triage accuracy of a general-purpose language-based tool relative to practicing physicians and lay individuals using validated clinical case vignettes. The study seeks to determine how closely the tool’s performance approaches that of physicians and whether it surpasses the abilities of laypeople in providing correct diagnoses and appropriate triage recommendations."
Medicine,Machine Learning and Digital Biomarkers Can Detect Early Stages of Neurodegenerative Diseases,"Neurodegenerative diseases (NDs) such as Alzheimer’s Disease (AD) and Parkinson’s Disease (PD) are devastating conditions that can develop without noticeable symptoms, causing irreversible damage to neurons before any signs become clinically evident. NDs are a major cause of disability and mortality worldwide. Currently, there are no cures or treatments to halt their progression. Therefore, the development of early detection methods is urgently needed to delay neuronal loss as soon as possible. Despite advancements in Medtech, the early diagnosis of NDs remains a challenge at the intersection of medical, IT, and regulatory fields. Thus, this review explores “digital biomarkers” (tools designed for remote neurocognitive data collection and AI analysis) as a potential solution. The review summarizes that recent studies combining AI with digital biomarkers suggest the possibility of identifying pre-symptomatic indicators of NDs. For instance, research utilizing convolutional neural networks for eye tracking has achieved significant diagnostic accuracies. ROC-AUC scores reached up to 0.88, indicating high model performance in differentiating between PD patients and healthy controls. Similarly, advancements in facial expression analysis through tools have demonstrated significant potential in detecting emotional changes in ND patients, with some models reaching an accuracy of 0.89 and a precision of 0.85. This review follows a structured approach to article selection, starting with a comprehensive database search and culminating in a rigorous quality assessment and meaning for NDs of the different methods. The process is visualized in 10 tables with 54 parameters describing different approaches and their consequences for understanding various mechanisms in ND changes. However, these methods also face challenges related to data accuracy and privacy concerns. To address these issues, this review proposes strategies that emphasize the need for rigorous validation and rapid integration into clinical practice. Such integration could transform ND diagnostics, making early detection tools more cost-effective and globally accessible. In conclusion, this review underscores the urgent need to incorporate validated digital health tools into mainstream medical practice. This integration could indicate a new era in the early diagnosis of neurodegenerative diseases, potentially altering the trajectory of these conditions for millions worldwide. Thus, by highlighting specific and statistically significant findings, this review demonstrates the current progress in this field and the potential impact of these advancements on the global management of NDs.",['convolutional neural networks'],"Neurodegenerative diseases such as Alzheimer’s Disease and Parkinson’s Disease are devastating conditions that often develop without noticeable symptoms, leading to irreversible neuronal damage before clinical signs appear. These diseases are a major cause of disability and mortality worldwide, and currently, there are no cures or treatments to halt their progression. Therefore, there is an urgent need for early detection methods to delay neuronal loss and improve patient outcomes. The study aims to explore and summarize recent advancements in early diagnostic approaches for neurodegenerative diseases, focusing on the potential of novel tools to identify pre-symptomatic indicators. It seeks to evaluate the effectiveness and challenges of these approaches, propose strategies for their validation, and emphasize the importance of integrating validated early detection tools into clinical practice to transform diagnostics and improve global management of neurodegenerative diseases."
Medicine,RanMerFormer: Randomized vision transformer with token merging for brain tumor classification,"Brains are the control center of the nervous system in human bodies, and brain tumor is one of the most deadly diseases. Currently, magnetic resonance imaging (MRI) is the most effective way to brain tumors early detection in clinical diagnoses due to its superior imaging quality for soft tissues. Manual analysis of brain MRI is error-prone which depends on empirical experience and the fatigue state of the radiologists to a large extent. Computer-aided diagnosis (CAD) systems are becoming more and more impactful because they can provide accurate prediction results based on medical images with advanced techniques from computer vision. Therefore, a novel CAD method for brain tumor classification named RanMerFormer is presented in this paper. A pre-trained vision transformer is used as the backbone model. Then, a merging mechanism is proposed to remove the redundant tokens in the vision transformer, which improves computing efficiency substantially. Finally, a randomized vector functional-link serves as the head in the proposed RanMerFormer, which can be trained swiftly. All the simulation results are obtained from two public benchmark datasets, which reveal that the proposed RanMerFormer can achieve state-of-the-art performance for brain tumor classification. The trained RanMerFormer can be applied in real-world scenarios to assist in brain tumor diagnosis.","['vision transformer', 'randomized vector functional-link']","The study addresses the critical challenge of early and accurate detection of brain tumors, which are among the most deadly diseases affecting the nervous system. Magnetic resonance imaging (MRI) is currently the most effective clinical tool for detecting brain tumors due to its superior imaging quality for soft tissues. However, manual analysis of brain MRI scans is prone to errors and heavily reliant on the radiologists' experience and fatigue levels, which can impact diagnostic accuracy. The primary objective of this study is to develop a method that improves the classification of brain tumors using MRI images to assist in more accurate and efficient diagnosis. This method aims to enhance diagnostic performance and can be applied in real-world clinical scenarios to support radiologists in brain tumor diagnosis."
Medicine,A hybrid deep CNN model for brain tumor image multi-classification,"Abstract The current approach to diagnosing and classifying brain tumors relies on the histological evaluation of biopsy samples, which is invasive, time-consuming, and susceptible to manual errors. These limitations underscore the pressing need for a fully automated, deep-learning-based multi-classification system for brain malignancies. This article aims to leverage a deep convolutional neural network (CNN) to enhance early detection and presents three distinct CNN models designed for different types of classification tasks. The first CNN model achieves an impressive detection accuracy of 99.53% for brain tumors. The second CNN model, with an accuracy of 93.81%, proficiently categorizes brain tumors into five distinct types: normal, glioma, meningioma, pituitary, and metastatic. Furthermore, the third CNN model demonstrates an accuracy of 98.56% in accurately classifying brain tumors into their different grades. To ensure optimal performance, a grid search optimization approach is employed to automatically fine-tune all the relevant hyperparameters of the CNN models. The utilization of large, publicly accessible clinical datasets results in robust and reliable classification outcomes. This article conducts a comprehensive comparison of the proposed models against classical models, such as AlexNet, DenseNet121, ResNet-101, VGG-19, and GoogleNet, reaffirming the superiority of the deep CNN-based approach in advancing the field of brain tumor classification and early detection.","['deep convolutional neural network (CNN)', 'AlexNet', 'DenseNet121', 'ResNet-101', 'VGG-19', 'GoogleNet']","The current approach to diagnosing and classifying brain tumors relies on the histological evaluation of biopsy samples, which is invasive, time-consuming, and susceptible to manual errors. These limitations highlight the need for improved methods that can facilitate early detection and accurate classification of brain malignancies. The primary aim of this study is to enhance early detection of brain tumors and to accurately classify them into different types and grades. This is achieved by developing and evaluating models designed for multi-classification tasks to improve the diagnosis and categorization of brain tumors."
Medicine,Present and Future Innovations in AI and Cardiac MRI,"Cardiac MRI is used to diagnose and treat patients with a multitude of cardiovascular diseases. Despite the growth of clinical cardiac MRI, complicated image prescriptions and long acquisition protocols limit the specialty and restrain its impact on the practice of medicine. Artificial intelligence (AI)-the ability to mimic human intelligence in learning and performing tasks-will impact nearly all aspects of MRI. Deep learning (DL) primarily uses an artificial neural network to learn a specific task from example data sets. Self-driving scanners are increasingly available, where AI automatically controls cardiac image prescriptions. These scanners offer faster image collection with higher spatial and temporal resolution, eliminating the need for cardiac triggering or breath holding. In the future, fully automated inline image analysis will most likely provide all contour drawings and initial measurements to the reader. Advanced analysis using radiomic or DL features may provide new insights and information not typically extracted in the current analysis workflow. AI may further help integrate these features with clinical, genetic, wearable-device, and ""omics"" data to improve patient outcomes. This article presents an overview of AI and its application in cardiac MRI, including in image acquisition, reconstruction, and processing, and opportunities for more personalized cardiovascular care through extraction of novel imaging markers.","['Deep learning (DL)', 'artificial neural network']","The research idea addresses the challenges in cardiac MRI, including complicated image prescriptions and lengthy acquisition protocols, which limit its broader use and impact in cardiovascular medicine. Despite the clinical growth of cardiac MRI, these limitations hinder its effectiveness in diagnosing and treating various cardiovascular diseases. The study aims to explore advancements that could streamline cardiac MRI procedures and enhance its clinical utility. The primary objective of the study is to present an overview of recent developments in cardiac MRI that improve image acquisition, reconstruction, and processing, with the goal of enabling more personalized cardiovascular care through the extraction of novel imaging markers."
Medicine,Artificial intelligence-driven virtual rehabilitation for people living in the community: A scoping review,"Abstract Virtual Rehabilitation (VRehab) is a promising approach to improving the physical and mental functioning of patients living in the community. The use of VRehab technology results in the generation of multi-modal datasets collected through various devices. This presents opportunities for the development of Artificial Intelligence (AI) techniques in VRehab, namely the measurement, detection, and prediction of various patients’ health outcomes. The objective of this scoping review was to explore the applications and effectiveness of incorporating AI into home-based VRehab programs. PubMed/MEDLINE, Embase, IEEE Xplore, Web of Science databases, and Google Scholar were searched from inception until June 2023 for studies that applied AI for the delivery of VRehab programs to the homes of adult patients. After screening 2172 unique titles and abstracts and 51 full-text studies, 13 studies were included in the review. A variety of AI algorithms were applied to analyze data collected from various sensors and make inferences about patients’ health outcomes, most involving evaluating patients’ exercise quality and providing feedback to patients. The AI algorithms used in the studies were mostly fuzzy rule-based methods, template matching, and deep neural networks. Despite the growing body of literature on the use of AI in VRehab, very few studies have examined its use in patients’ homes. Current research suggests that integrating AI with home-based VRehab can lead to improved rehabilitation outcomes for patients. However, further research is required to fully assess the effectiveness of various forms of AI-driven home-based VRehab, taking into account its unique challenges and using standardized metrics.","['fuzzy rule-based methods', 'deep neural networks']","The research idea centers on the potential of virtual rehabilitation (VRehab) to enhance the physical and mental functioning of patients living in the community, particularly through home-based programs. While VRehab generates diverse health-related data, there is limited exploration of its application directly in patients’ homes, despite its promise for improving rehabilitation outcomes. The study aims to address the gap in understanding the effectiveness of home-based VRehab interventions and their impact on patient health outcomes. The primary objective of this scoping review was to explore the applications and effectiveness of incorporating advanced techniques into home-based VRehab programs for adult patients. It sought to evaluate existing studies that delivered VRehab in home settings and to assess how these interventions influence patients’ exercise quality and overall rehabilitation progress."
Medicine,Assessing ChatGPT 4.0’s test performance and clinical diagnostic accuracy on USMLE STEP 2 CK and clinical case reports,"Abstract While there is data assessing the test performance of artificial intelligence (AI) chatbots, including the Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0), there is scarce data on its diagnostic accuracy of clinical cases. We assessed the large language model (LLM), ChatGPT 4.0, on its ability to answer questions from the United States Medical Licensing Exam (USMLE) Step 2, as well as its ability to generate a differential diagnosis based on corresponding clinical vignettes from published case reports. A total of 109 Step 2 Clinical Knowledge (CK) practice questions were inputted into both ChatGPT 3.5 and ChatGPT 4.0, asking ChatGPT to pick the correct answer. Compared to its previous version, ChatGPT 3.5, we found improved accuracy of ChatGPT 4.0 when answering these questions, from 47.7 to 87.2% ( p = 0.035) respectively. Utilizing the topics tested on Step 2 CK questions, we additionally found 63 corresponding published case report vignettes and asked ChatGPT 4.0 to come up with its top three differential diagnosis. ChatGPT 4.0 accurately created a shortlist of differential diagnoses in 74.6% of the 63 case reports (74.6%). We analyzed ChatGPT 4.0’s confidence in its diagnosis by asking it to rank its top three differentials from most to least likely. Out of the 47 correct diagnoses, 33 were the first (70.2%) on the differential diagnosis list, 11 were second (23.4%), and three were third (6.4%). Our study shows the continued iterative improvement in ChatGPT’s ability to answer standardized USMLE questions accurately and provides insights into ChatGPT’s clinical diagnostic accuracy.","['Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0)', 'large language model (LLM)']","The research idea centers on the limited information available regarding the diagnostic accuracy of clinical cases when assessed by advanced language-based tools, despite existing data on their test performance in medical examinations. This study addresses the need to evaluate how well such tools can generate accurate differential diagnoses based on clinical vignettes and answer medical licensing exam questions. The primary objective of the study is to assess the ability of the latest version of a language-based tool to correctly answer questions from the United States Medical Licensing Exam Step 2 Clinical Knowledge and to generate accurate differential diagnoses from published clinical case vignettes. The study aims to compare the diagnostic accuracy and performance improvements of this tool relative to its previous version in the context of clinical reasoning and medical knowledge application."
Medicine,Advanced Ensemble Machine Learning Techniques for Optimizing Diabetes Mellitus Prognostication: A Detailed Examination of Hospital Data,"Diabetes is a chronic disease that affects millions of people worldwide. Early diagnosis and effective management are crucial for reducing its complications. Diabetes is the fourth-highest cause of mortality due to its association with various comorbidities, including heart disease, nerve damage, blood vessel damage, and blindness. The potential of machine learning algorithms in predicting Diabetes and related conditions is significant, and mining diabetes data is an efficient method for extracting new insights.The primary objective of this study is to develop an enhanced ensemble model to predict Diabetes with improved accuracy by leveraging various machine learning algorithms.This study tested several popular machine learning algorithms commonly used in diabetes prediction, including Naive Bayes (NB), Generalized Linear Model (GLM), Logistic Regression (LR), Fast Large Margin (FLM), Deep Learning (DL), Decision Tree (DT), Random Forest (RF), Gradient Boosted Trees (GBT), and Support Vector Machine (SVM). The performance of these algorithms was compared, and two different ensemble techniques—stacking and voting—were used to build a more accurate predictive model.The top three algorithms based on accuracy were Deep Learning, Naive Bayes, and Gradient Boosted Trees. The machine learning algorithms revealed that individuals with Diabetes are significantly affected by the number of chronic conditions they have, as well as their gender and age. The ensemble models, particularly the stacking method, provided higher accuracy than individual algorithms. The stacking ensemble model achieved a slightly better accuracy of 99.94% compared to 99.34% for the voting method.Building an ensemble model significantly increased the accuracy of predicting Diabetes and related conditions. The stacking ensemble model, in particular, demonstrated superior performance, highlighting the importance of combining multiple machine learning approaches to enhance predictive accuracy","['Naive Bayes (NB)', 'Logistic Regression (LR)', 'Deep Learning (DL)', 'Decision Tree (DT)', 'Random Forest (RF)', 'Gradient Boosted Trees (GBT)', 'Support Vector Machine (SVM)', 'stacking ensemble', 'voting ensemble']","Diabetes is a chronic disease affecting millions worldwide and is a leading cause of mortality due to its association with various comorbidities such as heart disease, nerve damage, blood vessel damage, and blindness. Early diagnosis and effective management are essential to reduce the complications arising from diabetes. The primary objective of this study is to improve the accuracy of diabetes prediction by developing an enhanced approach that combines multiple methods. This study aims to identify the most effective strategy for predicting diabetes and related conditions to support better clinical outcomes."
Medicine,Reliability of ChatGPT for performing triage task in the emergency department using the Korean Triage and Acuity Scale,"Background Artificial intelligence (AI) technology can enable more efficient decision-making in healthcare settings. There is a growing interest in improving the speed and accuracy of AI systems in providing responses for given tasks in healthcare settings. Objective This study aimed to assess the reliability of ChatGPT in determining emergency department (ED) triage accuracy using the Korean Triage and Acuity Scale (KTAS). Methods Two hundred and two virtual patient cases were built. The gold standard triage classification for each case was established by an experienced ED physician. Three other human raters (ED paramedics) were involved and rated the virtual cases individually. The virtual cases were also rated by two different versions of the chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0). Inter-rater reliability was examined using Fleiss’ kappa and intra-class correlation coefficient (ICC). Results The kappa values for the agreement between the four human raters and ChatGPTs were .523 (version 4.0) and .320 (version 3.5). Of the five levels, the performance was poor when rating patients at levels 1 and 5, as well as case scenarios with additional text descriptions. There were differences in the accuracy of the different versions of GPTs. The ICC between version 3.5 and the gold standard was .520, and that between version 4.0 and the gold standard was .802. Conclusions A substantial level of inter-rater reliability was revealed when GPTs were used as KTAS raters. The current study showed the potential of using GPT in emergency healthcare settings. Considering the shortage of experienced manpower, this AI method may help improve triaging accuracy.","['chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0)']","The research addresses the challenge of accurately and efficiently determining triage levels in emergency departments, which is critical for prioritizing patient care and managing limited healthcare resources. There is a need to improve the speed and reliability of triage decisions to enhance patient outcomes and support healthcare providers, especially given the shortage of experienced personnel. The primary aim of the study was to assess the reliability of ChatGPT in determining emergency department triage accuracy using the Korean Triage and Acuity Scale (KTAS). Specifically, the study sought to compare the triage classifications made by ChatGPT with those made by experienced emergency department physicians and paramedics to evaluate its potential role in emergency healthcare settings."
Medicine,Assessing generalisability of deep learning-based polyp detection and segmentation methods through a computer vision challenge,"Abstract Polyps are well-known cancer precursors identified by colonoscopy. However, variability in their size, appearance, and location makes the detection of polyps challenging. Moreover, colonoscopy surveillance and removal of polyps are highly operator-dependent procedures and occur in a highly complex organ topology. There exists a high missed detection rate and incomplete removal of colonic polyps. To assist in clinical procedures and reduce missed rates, automated methods for detecting and segmenting polyps using machine learning have been achieved in past years. However, the major drawback in most of these methods is their ability to generalise to out-of-sample unseen datasets from different centres, populations, modalities, and acquisition systems. To test this hypothesis rigorously, we, together with expert gastroenterologists, curated a multi-centre and multi-population dataset acquired from six different colonoscopy systems and challenged the computational expert teams to develop robust automated detection and segmentation methods in a crowd-sourcing Endoscopic computer vision challenge. This work put forward rigorous generalisability tests and assesses the usability of devised deep learning methods in dynamic and actual clinical colonoscopy procedures. We analyse the results of four top performing teams for the detection task and five top performing teams for the segmentation task. Our analyses demonstrate that the top-ranking teams concentrated mainly on accuracy over the real-time performance required for clinical applicability. We further dissect the devised methods and provide an experiment-based hypothesis that reveals the need for improved generalisability to tackle diversity present in multi-centre datasets and routine clinical procedures.","['machine learning', 'deep learning']","The research idea addresses the challenge of detecting colonic polyps during colonoscopy, which is complicated by variability in polyp size, appearance, and location, as well as the highly operator-dependent nature of colonoscopy procedures within a complex organ topology. There is a significant issue with high missed detection rates and incomplete removal of polyps, which are precursors to cancer, highlighting the need for improved detection methods that can perform reliably across diverse clinical settings. The primary objective of the study is to rigorously evaluate the generalisability and clinical applicability of automated polyp detection and segmentation methods across multi-centre and multi-population datasets obtained from different colonoscopy systems. This evaluation aims to identify the limitations of current approaches in real-time clinical procedures and to provide insights for enhancing the robustness of polyp detection techniques in routine colonoscopy practice."
Medicine,Effective lung nodule detection using deep CNN with dual attention mechanisms,"Abstract Novel methods are required to enhance lung cancer detection, which has overtaken other cancer-related causes of death as the major cause of cancer-related mortality. Radiologists have long-standing methods for locating lung nodules in patients with lung cancer, such as computed tomography (CT) scans. Radiologists must manually review a significant amount of CT scan pictures, which makes the process time-consuming and prone to human error. Computer-aided diagnosis (CAD) systems have been created to help radiologists with their evaluations in order to overcome these difficulties. These systems make use of cutting-edge deep learning architectures. These CAD systems are designed to improve lung nodule diagnosis efficiency and accuracy. In this study, a bespoke convolutional neural network (CNN) with a dual attention mechanism was created, which was especially crafted to concentrate on the most important elements in images of lung nodules. The CNN model extracts informative features from the images, while the attention module incorporates both channel attention and spatial attention mechanisms to selectively highlight significant features. After the attention module, global average pooling is applied to summarize the spatial information. To evaluate the performance of the proposed model, extensive experiments were conducted using benchmark dataset of lung nodules. The results of these experiments demonstrated that our model surpasses recent models and achieves state-of-the-art accuracy in lung nodule detection and classification tasks.","['convolutional neural network (CNN)', 'dual attention mechanism', 'channel attention', 'spatial attention', 'global average pooling']","The study addresses the critical need for improved methods to enhance lung cancer detection, as lung cancer has become the leading cause of cancer-related mortality. Traditional approaches, such as manual review of computed tomography (CT) scans by radiologists, are time-consuming and susceptible to human error, highlighting the necessity for more efficient and accurate diagnostic techniques. The primary aim of the study is to develop a specialized approach that focuses on the most important features in lung nodule images to improve the efficiency and accuracy of lung nodule diagnosis. This approach seeks to assist radiologists in better identifying and classifying lung nodules, ultimately contributing to more effective lung cancer detection."
Medicine,A precise model for skin cancer diagnosis using hybrid U-Net and improved MobileNet-V3 with hyperparameters optimization,"Abstract Skin cancer is a frequently occurring and possibly deadly disease that necessitates prompt and precise diagnosis in order to ensure efficacious treatment. This paper introduces an innovative approach for accurately identifying skin cancer by utilizing Convolution Neural Network architecture and optimizing hyperparameters. The proposed approach aims to increase the precision and efficacy of skin cancer recognition and consequently enhance patients' experiences. This investigation aims to tackle various significant challenges in skin cancer recognition, encompassing feature extraction, model architecture design, and optimizing hyperparameters. The proposed model utilizes advanced deep-learning methodologies to extract complex features and patterns from skin cancer images. We enhance the learning procedure of deep learning by integrating Standard U-Net and Improved MobileNet-V3 with optimization techniques, allowing the model to differentiate malignant and benign skin cancers. Also substituted the crossed-entropy loss function of the Mobilenet-v3 mathematical framework with a bias loss function to enhance the accuracy. The model's squeeze and excitation component was replaced with the practical channel attention component to achieve parameter reduction. Integrating cross-layer connections among Mobile modules has been proposed to leverage synthetic features effectively. The dilated convolutions were incorporated into the model to enhance the receptive field. The optimization of hyperparameters is of utmost importance in improving the efficiency of deep learning models. To fine-tune the model's hyperparameter, we employ sophisticated optimization methods such as the Bayesian optimization method using pre-trained CNN architecture MobileNet-V3. The proposed model is compared with existing models, i.e., MobileNet, VGG-16, MobileNet-V2, Resnet-152v2 and VGG-19 on the “HAM-10000 Melanoma Skin Cancer dataset"". The empirical findings illustrate that the proposed optimized hybrid MobileNet-V3 model outperforms existing skin cancer detection and segmentation techniques based on high precision of 97.84%, sensitivity of 96.35%, accuracy of 98.86% and specificity of 97.32%. The enhanced performance of this research resulted in timelier and more precise diagnoses, potentially contributing to life-saving outcomes and mitigating healthcare expenditures.","['Standard U-Net', 'Improved MobileNet-V3', 'dilated convolutions', 'Bayesian optimization method', 'pre-trained CNN architecture MobileNet-V3']","The research addresses the critical need for prompt and precise diagnosis of skin cancer, a common and potentially fatal disease, to ensure effective treatment and improve patient outcomes. It focuses on overcoming significant challenges in accurately recognizing skin cancer, including the differentiation between malignant and benign cases. The primary aim of the study is to develop a highly accurate method for identifying skin cancer that enhances the precision and efficacy of diagnosis. This objective seeks to improve diagnostic performance, leading to timelier and more reliable detection that can contribute to life-saving outcomes and reduce healthcare costs."
Medicine,A comparative study of explainable ensemble learning and logistic regression for predicting in-hospital mortality in the emergency department,"Abstract This study addresses the challenges associated with emergency department (ED) overcrowding and emphasizes the need for efficient risk stratification tools to identify high-risk patients for early intervention. While several scoring systems, often based on logistic regression (LR) models, have been proposed to indicate patient illness severity, this study aims to compare the predictive performance of ensemble learning (EL) models with LR for in-hospital mortality in the ED. A cross-sectional single-center study was conducted at the ED of Imam Reza Hospital in northeast Iran from March 2016 to March 2017. The study included adult patients with one to three levels of emergency severity index. EL models using Bagging, AdaBoost, random forests (RF), Stacking and extreme gradient boosting (XGB) algorithms, along with an LR model, were constructed. The training and validation visits from the ED were randomly divided into 80% and 20%, respectively. After training the proposed models using tenfold cross-validation, their predictive performance was evaluated. Model performance was compared using the Brier score (BS), The area under the receiver operating characteristics curve (AUROC), The area and precision–recall curve (AUCPR), Hosmer–Lemeshow (H–L) goodness-of-fit test, precision, sensitivity, accuracy, F1-score, and Matthews correlation coefficient (MCC). The study included 2025 unique patients admitted to the hospital’s ED, with a total percentage of hospital deaths at approximately 19%. In the training group and the validation group, 274 of 1476 (18.6%) and 152 of 728 (20.8%) patients died during hospitalization, respectively. According to the evaluation of the presented framework, EL models, particularly Bagging, predicted in-hospital mortality with the highest AUROC (0.839, CI (0.802–0.875)) and AUCPR = 0.64 comparable in terms of discrimination power with LR (AUROC (0.826, CI (0.787–0.864)) and AUCPR = 0.61). XGB achieved the highest precision (0.83), sensitivity (0.831), accuracy (0.842), F1-score (0.833), and the highest MCC (0.48). Additionally, the most accurate models in the unbalanced dataset belonged to RF with the lowest BS (0.128). Although all studied models overestimate mortality risk and have insufficient calibration ( P &gt; 0.05), stacking demonstrated relatively good agreement between predicted and actual mortality. EL models are not superior to LR in predicting in-hospital mortality in the ED. Both EL and LR models can be considered as screening tools to identify patients at risk of mortality.","['logistic regression (LR)', 'ensemble learning (EL)', 'Bagging', 'AdaBoost', 'random forests (RF)', 'Stacking', 'extreme gradient boosting (XGB)']","The study addresses the challenges of overcrowding in emergency departments and highlights the necessity for effective tools to stratify risk and identify high-risk patients for timely intervention. Existing scoring systems based on logistic regression have been used to indicate patient illness severity, but there is a need to evaluate alternative approaches for predicting in-hospital mortality in the emergency department. The primary objective of the study is to compare the predictive performance of different models for in-hospital mortality among adult patients admitted to the emergency department. The study aims to determine whether alternative approaches offer superior accuracy compared to logistic regression in identifying patients at risk of mortality during hospitalization."
Medicine,Multimodal data integration for oncology in the era of deep neural networks: a review,"Cancer research encompasses data across various scales, modalities, and resolutions, from screening and diagnostic imaging to digitized histopathology slides to various types of molecular data and clinical records. The integration of these diverse data types for personalized cancer care and predictive modeling holds the promise of enhancing the accuracy and reliability of cancer screening, diagnosis, and treatment. Traditional analytical methods, which often focus on isolated or unimodal information, fall short of capturing the complex and heterogeneous nature of cancer data. The advent of deep neural networks has spurred the development of sophisticated multimodal data fusion techniques capable of extracting and synthesizing information from disparate sources. Among these, Graph Neural Networks (GNNs) and Transformers have emerged as powerful tools for multimodal learning, demonstrating significant success. This review presents the foundational principles of multimodal learning including oncology data modalities, taxonomy of multimodal learning, and fusion strategies. We delve into the recent advancements in GNNs and Transformers for the fusion of multimodal data in oncology, spotlighting key studies and their pivotal findings. We discuss the unique challenges of multimodal learning, such as data heterogeneity and integration complexities, alongside the opportunities it presents for a more nuanced and comprehensive understanding of cancer. Finally, we present some of the latest comprehensive multimodal pan-cancer data sources. By surveying the landscape of multimodal data integration in oncology, our goal is to underline the transformative potential of multimodal GNNs and Transformers. Through technological advancements and the methodological innovations presented in this review, we aim to chart a course for future research in this promising field. This review may be the first that highlights the current state of multimodal modeling applications in cancer using GNNs and transformers, presents comprehensive multimodal oncology data sources, and sets the stage for multimodal evolution, encouraging further exploration and development in personalized cancer care.","['deep neural networks', 'Graph Neural Networks (GNNs)', 'Transformers']","The research idea centers on the challenge of integrating diverse types of cancer-related data, including screening and diagnostic imaging, histopathology slides, molecular data, and clinical records, to improve personalized cancer care. Traditional methods that analyze isolated data types are insufficient to capture the complex and heterogeneous nature of cancer, highlighting the need for more comprehensive approaches to enhance the accuracy and reliability of cancer screening, diagnosis, and treatment. The research objective is to review and present the foundational principles and recent advancements in the integration of multimodal oncology data, emphasizing the potential to achieve a more nuanced and comprehensive understanding of cancer. This study aims to highlight key developments, discuss challenges and opportunities in multimodal data fusion, and provide a roadmap for future research to advance personalized cancer care through improved data integration strategies."
Medicine,Accuracy of GPT-4 in histopathological image detection and classification of colorectal adenomas,"Aims To evaluate the accuracy of Chat Generative Pre-trained Transformer (ChatGPT) powered by GPT-4 in histopathological image detection and classification of colorectal adenomas using the diagnostic consensus provided by pathologists as a reference standard. Methods A study was conducted with 100 colorectal polyp photomicrographs, comprising an equal number of adenomas and non-adenomas, classified by two pathologists. These images were analysed by classic GPT-4 for 1 time in October 2023 and custom GPT-4 for 20 times in December 2023. GPT-4’s responses were compared against the reference standard through statistical measures to evaluate its proficiency in histopathological diagnosis, with the pathologists further assessing the model’s descriptive accuracy. Results GPT-4 demonstrated a median sensitivity of 74% and specificity of 36% for adenoma detection. The median accuracy of polyp classification varied, ranging from 16% for non-specific changes to 36% for tubular adenomas. Its diagnostic consistency, indicated by low kappa values ranging from 0.06 to 0.11, suggested only poor to slight agreement. All of the microscopic descriptions corresponded with their diagnoses. GPT-4 also commented about the limitations in its diagnoses (eg, slide diagnosis best done by pathologists, the inadequacy of single-image diagnostic conclusions, the need for clinical data and a higher magnification view). Conclusions GPT-4 showed high sensitivity but low specificity in detecting adenomas and varied accuracy for polyp classification. However, its diagnostic consistency was low. This artificial intelligence tool acknowledged its diagnostic limitations, emphasising the need for a pathologist’s expertise and additional clinical context.",['Chat Generative Pre-trained Transformer (ChatGPT) powered by GPT-4'],"The study addresses the challenge of accurately detecting and classifying colorectal adenomas through histopathological image evaluation, highlighting the importance of reliable diagnostic methods in colorectal pathology. Given the critical role of pathologists in providing definitive diagnoses, there is a need to assess alternative approaches that could support or enhance diagnostic accuracy. The primary aim of the study is to evaluate the accuracy of a diagnostic tool in identifying and classifying colorectal adenomas using histopathological images, with the diagnostic consensus of pathologists serving as the reference standard. The study seeks to determine the sensitivity, specificity, and overall consistency of this tool in comparison to expert pathological assessment."
Medicine,A domain adaptation approach to damage classification with an application to bridge monitoring,"Data-driven machine-learning algorithms generally suffer from a lack of labelled health-state data, mainly those referring to damage conditions. To address such an issue, population-based structural health monitoring seeks to enrich the original dataset by transferring knowledge from a population of monitored structures. Within this context, this paper presents a transfer learning approach, based on domain adaptation, to leverage information from completely-labelled bridge structure data to accurately predict new instances of an unknown target domain. Since intrinsic structural differences may cause distribution shifts, domain adaptation attempts to minimise the distance between the domains and to learn a mapping within a shared feature space. Specifically, the methodology involves the long-term acquisition of natural frequencies from several structural scenarios. Such damage-sensitive features are then aligned via domain adaptation so that a machine-learning algorithm can effectively utilise the labelled source domain data and generalise well to the unlabelled target-domain data. The described procedure is applied to two case studies, including the Z24 and the S101 benchmark bridges and their finite element models, respectively. The results demonstrate the successful exchange of health-state labels to identify the damage class within a population of bridges equipped with SHM systems, showing potential to reduce computational efforts and to deal with scarce or poor data sets in application to bridge network monitoring.","['transfer learning', 'domain adaptation']","The research idea addresses the challenge of limited labeled health-state data related to damage conditions in structural health monitoring of bridges. This scarcity hinders accurate identification and assessment of structural damage across different bridge structures. The study is motivated by the need to improve damage detection by utilizing information from a population of monitored bridges to enhance the understanding of new, unlabelled structures. The primary objective of the study is to develop an approach that enables the effective transfer of health-state information from fully labeled bridge data to new instances with unknown conditions, thereby improving the identification of damage classes within a population of bridges. This aims to facilitate more accurate damage assessment despite differences in structural characteristics and limited availability of labeled data."
Medicine,Revolutionizing core muscle analysis in female sexual dysfunction based on machine learning,"Abstract The purpose of this study is to investigate the role of core muscles in female sexual dysfunction (FSD) and develop comprehensive rehabilitation programs to address this issue. We aim to answer the following research questions: what are the roles of core muscles in FSD, and how can machine and deep learning models accurately predict changes in core muscles during FSD? FSD is a common condition that affects women of all ages, characterized by symptoms such as decreased libido, difficulty achieving orgasm, and pain during intercourse. We conducted a comprehensive analysis of changes in core muscles during FSD using machine and deep learning. We evaluated the performance of multiple models, including multi-layer perceptron (MLP), long short-term memory (LSTM), convolutional neural network (CNN), recurrent neural network (RNN), ElasticNetCV, random forest regressor, SVR, and Bagging regressor. The models were evaluated based on mean squared error (MSE), mean absolute error (MAE), and R-squared (R 2 ) score. Our results show that CNN and random forest regressor are the most accurate models for predicting changes in core muscles during FSD. CNN achieved the lowest MSE (0.002) and the highest R 2 score (0.988), while random forest regressor also performed well with an MSE of 0.0021 and an R 2 score of 0.9905. Our study demonstrates that machine and deep learning models can accurately predict changes in core muscles during FSD. The neglected core muscles play a significant role in FSD, highlighting the need for comprehensive rehabilitation programs that address these muscles. By developing these programs, we can improve the quality of life for women with FSD and help them achieve optimal sexual health.","['multi-layer perceptron (MLP)', 'long short-term memory (LSTM)', 'convolutional neural network (CNN)', 'recurrent neural network (RNN)', 'ElasticNetCV', 'random forest regressor', 'SVR', 'Bagging regressor']","The study addresses the common condition of female sexual dysfunction (FSD), which affects women of all ages and is characterized by symptoms such as decreased libido, difficulty achieving orgasm, and pain during intercourse. It highlights the often neglected role of core muscles in FSD and the importance of understanding their involvement in this condition. The primary aim of the study is to investigate the role of core muscles in female sexual dysfunction and to develop comprehensive rehabilitation programs that specifically target these muscles. By doing so, the research seeks to improve the quality of life for women with FSD and help them achieve optimal sexual health."
Medicine,The SAFE procedure: a practical stopping heuristic for active learning-based screening in systematic reviews and meta-analyses,"Abstract Active learning has become an increasingly popular method for screening large amounts of data in systematic reviews and meta-analyses. The active learning process continually improves its predictions on the remaining unlabeled records, with the goal of identifying all relevant records as early as possible. However, determining the optimal point at which to stop the active learning process is a challenge. The cost of additional labeling of records by the reviewer must be balanced against the cost of erroneous exclusions. This paper introduces the SAFE procedure, a practical and conservative set of stopping heuristics that offers a clear guideline for determining when to end the active learning process in screening software like ASReview. The eclectic mix of stopping heuristics helps to minimize the risk of missing relevant papers in the screening process. The proposed stopping heuristic balances the costs of continued screening with the risk of missing relevant records, providing a practical solution for reviewers to make informed decisions on when to stop screening. Although active learning can significantly enhance the quality and efficiency of screening, this method may be more applicable to certain types of datasets and problems. Ultimately, the decision to stop the active learning process depends on careful consideration of the trade-off between the costs of additional record labeling against the potential errors of the current model for the specific dataset and context.",['active learning'],"The research idea addresses the challenge of efficiently screening large volumes of records in systematic reviews and meta-analyses while minimizing the risk of missing relevant studies. There is a need to balance the cost of additional manual review of records against the potential errors caused by prematurely stopping the screening process. The study focuses on providing a practical approach to determine the optimal point to end the screening process to ensure thorough identification of relevant literature. The primary objective of the study is to introduce a set of stopping guidelines that help reviewers decide when to stop screening records in order to reduce the risk of excluding important studies while managing the workload involved in reviewing. This approach aims to offer clear recommendations that balance the costs of continued screening with the risk of missing relevant records, thereby supporting informed decision-making during systematic review screening."
Medicine,Evaluating AI and Machine Learning Models in Breast Cancer Detection: A Review of Convolutional Neural Networks (CNN) and Global Research Trends,"Numerous studies have highlighted the significance of artificial intelligence (AI) in breast cancer diagnosis. However, systematic reviews of AI applications in this field often lack cohesion, with each study adopting a unique approach. The aim of this study is to provide a detailed examination of AI's role in breast cancer diagnosis through citation analysis, helping to categorize the key areas that attract academic attention. It also includes a thematic analysis to identify the specific research topics within each category. A total of 30,200 studies related to breast cancer and AI, published between 2015 and 2024, were sourced from databases such as IEEE, Scopus, PubMed, Springer, and Google Scholar. After applying inclusion and exclusion criteria, 32 relevant studies were identified. Most of these studies utilized classification models for breast cancer prediction, with high accuracy being the most commonly reported performance metric. Convolutional Neural Networks (CNN) emerged as the preferred model in many studies. The findings indicate that both the quantity and quality of AI-based algorithms in breast cancer diagnosis are increases in the given years. AI is increasingly seen as a complement to healthcare sector and clinical expertise, with the target of enhancing the accessibility and affordability of quality healthcare worldwide.",['Convolutional Neural Networks (CNN)'],"The research idea centers on the importance of improving breast cancer diagnosis, recognizing that existing studies in this area often lack cohesion and adopt varied approaches. There is a need to better understand and categorize the key areas of academic focus within breast cancer diagnosis to enhance clarity and direction in this field. The primary objective of the study is to provide a detailed examination of the role of diagnostic approaches in breast cancer by categorizing key research areas and identifying specific topics within each category. This aims to offer a clearer understanding of the current landscape and trends in breast cancer diagnosis research."
Medicine,Unlocking the Potential of XAI for Improved Alzheimer’s Disease Detection and Classification Using a ViT-GRU Model,"Alzheimer's Disease (AD) is a significant cause of dementia worldwide, and its progression from mild to severe affects an individual's ability to perform daily activities independently. The accurate and early diagnosis of AD is crucial for effective clinical intervention. However, interpreting AD from medical images can be challenging, even for experienced radiologists. Therefore, there is a need for an automatic diagnosis of AD, and researchers have investigated the potential of utilizing Artificial Intelligence (AI) techniques, particularly deep learning models, to address this challenge. This study proposes a framework that combines a Vision Transformer (ViT) and a Gated Recurrent Unit (GRU) to detect AD characteristics from Magnetic Resonance Imaging (MRI) images accurately and reliably. The ViT identifies crucial features from the input image, and the GRU establishes clear correlations between these features. The proposed model overcomes the class imbalance issue in the MRI image dataset and achieves superior accuracy and performance compared to existing methods. The model was trained on the Alzheimer's MRI Preprocessed Dataset obtained from Kaggle, achieving notable accuracies of 99.53% for 4-class and 99.69% for binary classification. It also demonstrated a high accuracy of 99.26% for 3-class on the AD Neuroimaging Initiative (ADNI) Baseline Database. These results were validated through a thorough 10-fold cross-validation process. Furthermore, Explainable AI (XAI) techniques were incorporated to make the model interpretable and explainable. This allows clinicians to understand the model's decision-making process and gain insights into the underlying factors driving the AD diagnosis.","['Vision Transformer (ViT)', 'Gated Recurrent Unit (GRU)']","Alzheimer's Disease (AD) is a significant cause of dementia worldwide, and its progression from mild to severe impairs an individual's ability to perform daily activities independently. Early and accurate diagnosis of AD is crucial for effective clinical intervention, yet interpreting AD from medical images remains challenging even for experienced radiologists. The primary aim of this study is to develop a reliable approach for detecting AD characteristics from Magnetic Resonance Imaging (MRI) images to improve diagnostic accuracy. This study seeks to address the difficulties in diagnosing AD by proposing a method that can accurately identify and classify the stages of the disease, thereby supporting clinicians in making informed decisions."
Medicine,"Prediction of atmospheric PM2.5 level by machine learning techniques in Isfahan, Iran","Abstract With increasing levels of air pollution, air quality prediction has attracted more attention. Mathematical models are being developed by researchers to achieve precise predictions. Monitoring and prediction of atmospheric PM 2.5 levels, as a predominant pollutant, is essential in emission mitigation programs. In this study, meteorological datasets from 9 years in Isfahan city, a large metropolis of Iran, were applied to predict the PM 2.5 levels, using four machine learning algorithms including Artificial Neural |Networks (ANNs), K-Nearest-Neighbors (KNN), Support Vector |Machines (SVMs) and ensembles of classification trees Random Forest (RF). The data from 7 air quality monitoring stations located in Isfahan City were taken into consideration. The Confusion Matrix and Cross-Entropy Loss were used to analyze the performance of classification models. Several parameters, including sensitivity, specificity, accuracy, F1 score, precision, and the area under the curve (AUC), are computed to assess model performance. Finally, by introducing the predicted data for 2020 into ArcGIS software and using the IDW (Inverse Distance Weighting) method, interpolation was conducted for the area of Isfahan city and the pollution map was illustrated for each month of the year. The results showed that, based on the accuracy percentage, the ANN model has a better performance (90.1%) in predicting PM 2.5 grades compared to the other models for the applied meteorological dataset, followed by RF (86.1%), SVM (84.6%) and KNN (82.2%) models, respectively. Therefore, ANN modelling provides a feasible procedure for the managerial planning of air pollution control.","['Artificial Neural Networks (ANNs)', 'K-Nearest-Neighbors (KNN)', 'Support Vector Machines (SVMs)', 'Random Forest (RF)']","The study addresses the growing concern of air pollution and the critical need for accurate prediction of atmospheric PM 2.5 levels, which are a predominant pollutant affecting public health and environmental quality. Monitoring and predicting these pollutant levels are essential components of emission mitigation programs, especially in large urban areas like Isfahan city, Iran. The primary aim of the study is to predict PM 2.5 levels in Isfahan city using meteorological data collected over nine years from multiple air quality monitoring stations. This prediction is intended to support effective managerial planning and control of air pollution in the region."
Medicine,Machine Learning–Based Prediction of Suicidality in Adolescents With Allergic Rhinitis: Derivation and Validation in 2 Independent Nationwide Cohorts,"Background Given the additional risk of suicide-related behaviors in adolescents with allergic rhinitis (AR), it is important to use the growing field of machine learning (ML) to evaluate this risk. Objective This study aims to evaluate the validity and usefulness of an ML model for predicting suicide risk in patients with AR. Methods We used data from 2 independent survey studies, Korea Youth Risk Behavior Web-based Survey (KYRBS; n=299,468) for the original data set and Korea National Health and Nutrition Examination Survey (KNHANES; n=833) for the external validation data set, to predict suicide risks of AR in adolescents aged 13 to 18 years, with 3.45% (10,341/299,468) and 1.4% (12/833) of the patients attempting suicide in the KYRBS and KNHANES studies, respectively. The outcome of interest was the suicide attempt risks. We selected various ML-based models with hyperparameter tuning in the discovery and performed an area under the receiver operating characteristic curve (AUROC) analysis in the train, test, and external validation data. Results The study data set included 299,468 (KYRBS; original data set) and 833 (KNHANES; external validation data set) patients with AR recruited between 2005 and 2022. The best-performing ML model was the random forest model with a mean AUROC of 84.12% (95% CI 83.98%-84.27%) in the original data set. Applying this result to the external validation data set revealed the best performance among the models, with an AUROC of 89.87% (sensitivity 83.33%, specificity 82.58%, accuracy 82.59%, and balanced accuracy 82.96%). While looking at feature importance, the 5 most important features in predicting suicide attempts in adolescent patients with AR are depression, stress status, academic achievement, age, and alcohol consumption. Conclusions This study emphasizes the potential of ML models in predicting suicide risks in patients with AR, encouraging further application of these models in other conditions to enhance adolescent health and decrease suicide rates.",['random forest'],"The research idea addresses the increased risk of suicide-related behaviors in adolescents with allergic rhinitis (AR), highlighting the importance of evaluating this risk to improve adolescent health outcomes. Given the significant impact of suicide attempts among this population, there is a critical need to identify factors that contribute to suicide risk in patients with AR. The study’s primary objective is to evaluate the validity and usefulness of a predictive approach for assessing suicide risk in adolescents aged 13 to 18 years with AR. Specifically, the study aims to determine how well this approach can identify individuals at risk of suicide attempts, thereby supporting efforts to reduce suicide rates in this vulnerable group."
Medicine,Geographically weighted machine learning for modeling spatial heterogeneity in traffic crash frequency and determinants in US,"Spatial analyses of traffic crashes have drawn much interest due to the nature of the spatial dependence and spatial heterogeneity in the crash data. This study makes the best of Geographically Weighted Random Forest (GW-RF) model to explore the local associations between crash frequency and various influencing factors in the US, including road network attributes, socio-economic characteristics, and land use factors collected from multiple data sources. Special emphasis is put on modeling the spatial heterogeneity in the effects of a factor on crash frequency in different geographical areas in a data-driven way. The GW-RF model outperforms global models (e.g. Random Forest) and conventional geographically weighted regression, demonstrating superior predictive accuracy and elucidating spatial variations. The GW-RF model reveals spatial distinctions in the effects of certain factors on crash frequency. For example, the importance of intersection density varies significantly across regions, with high significance in the southern and northeastern areas. Low-grade road density emerges as influential in specific cities. The findings highlight the significance of different factors in influencing crash frequency across zones. Road network factors, particularly intersection density, exhibit high importance universally, while socioeconomic variables demonstrate moderate effects. Interestingly, land use variables show relatively lower importance. The outcomes could help to allocate resources and implement tailored interventions to reduce the likelihood of crashes.","['Geographically Weighted Random Forest (GW-RF)', 'Random Forest']","The research idea centers on understanding the spatial dependence and heterogeneity in traffic crash data, recognizing that the frequency of crashes is influenced by various factors that differ across geographical areas. There is a need to explore how road network attributes, socio-economic characteristics, and land use factors locally affect crash frequency in order to better comprehend regional variations in crash risk. The primary objective of the study is to investigate the local associations between crash frequency and multiple influencing factors across different regions in the US, with a focus on identifying spatial variations in the effects of these factors. This aims to provide insights that can guide the allocation of resources and the implementation of targeted interventions to reduce the likelihood of traffic crashes."
Medicine,"Developing Deep LSTMs With Later Temporal Attention for Predicting COVID-19 Severity, Clinical Outcome, and Antibody Level by Screening Serological Indicators Over Time","Objective: The clinical course of COVID-19, as well as the immunological reaction, is notable for its extreme variability. Identifying the main associated factors might help understand the disease progression and physiological status of COVID-19 patients. The dynamic changes of the antibody against Spike protein are crucial for understanding the immune response. This work explores a temporal attention (TA) mechanism of deep learning to predict COVID-19 disease severity, clinical outcomes, and Spike antibody levels by screening serological indicators over time. Methods: We use feature selection techniques to filter feature subsets that are highly correlated with the target. The specific deep Long Short-Term Memory (LSTM) models are employed to capture the dynamic changes of disease severity, clinical outcome, and Spike antibody level. We also propose deep LSTMs with a TA mechanism to emphasize the later blood test records because later records often attract more attention from doctors. Results: Risk factors highly correlated with COVID-19 are revealed. LSTM achieves the highest classification accuracy for disease severity prediction. Temporal Attention Long Short-Term Memory (TA-LSTM) achieves the best performance for clinical outcome prediction. For Spike antibody level prediction, LSTM achieves the best permanence. Conclusion: The experimental results demonstrate the effectiveness of the proposed models. The proposed models can provide a computer-aided medical diagnostics system by simply using time series of serological indicators.","['deep Long Short-Term Memory (LSTM) models', 'deep LSTMs with a temporal attention (TA) mechanism', 'Temporal Attention Long Short-Term Memory (TA-LSTM)']","The clinical course of COVID-19 and the immunological response exhibit significant variability among patients, making it challenging to understand disease progression and physiological status. Identifying the main factors associated with COVID-19 severity and immune response is essential for improving knowledge of the disease. The dynamic changes in antibodies against the Spike protein are particularly important for understanding the immune response in COVID-19 patients. This study aims to predict COVID-19 disease severity, clinical outcomes, and Spike antibody levels by examining temporal changes in serological indicators, with the goal of better understanding the progression and immune status of affected individuals."
Medicine,A New Brain Network Construction Paradigm for Brain Disorder via Diffusion-Based Graph Contrastive Learning,"Brain network analysis plays an increasingly important role in studying brain function and the exploring of disease mechanisms. However, existing brain network construction tools have some limitations, including dependency on empirical users, weak consistency in repeated experiments and time-consuming processes. In this work, a diffusion-based brain network pipeline, DGCL is designed for end-to-end construction of brain networks. Initially, the brain region-aware module (BRAM) precisely determines the spatial locations of brain regions by the diffusion process, avoiding subjective parameter selection. Subsequently, DGCL employs graph contrastive learning to optimize brain connections by eliminating individual differences in redundant connections unrelated to diseases, thereby enhancing the consistency of brain networks within the same group. Finally, the node-graph contrastive loss and classification loss jointly constrain the learning process of the model to obtain the reconstructed brain network, which is then used to analyze important brain connections. Validation on two datasets, ADNI and ABIDE, demonstrates that DGCL surpasses traditional methods and other deep learning models in predicting disease development stages. Significantly, the proposed model improves the efficiency and generalization of brain network construction. In summary, the proposed DGCL can be served as a universal brain network construction scheme, which can effectively identify important brain connections through generative paradigms and has the potential to provide disease interpretability support for neuroscience research.","['diffusion process', 'graph contrastive learning']","The study addresses the challenges in brain network construction, which is crucial for understanding brain function and exploring disease mechanisms. Existing tools for constructing brain networks face limitations such as reliance on subjective user input, inconsistency in repeated experiments, and time-consuming procedures. The primary aim of the study is to develop a more efficient and consistent approach for constructing brain networks that can accurately identify important brain connections. This approach seeks to improve the reliability of brain network analysis and provide meaningful insights into disease development stages, thereby supporting neuroscience research and disease interpretability."
Medicine,Development and Validation of a Machine Learning Model to Predict Weekly Risk of Hypoglycemia in Patients with Type 1 Diabetes Based on Continuous Glucose Monitoring,"Aim: The aim of this study was to develop and validate a prediction model based on CGM data to identify a week-to-week risk profile of excessive hypoglycemia. Methods: We analyzed, trained, and internally tested two prediction models using CGM data from 205 type 1 diabetes patients with long-term CGM monitoring. A binary classification approach (XGBoost) combined with feature engineering deployed on the CGM signals was utilized to predict excessive hypoglycemia risk defined by two targets (TBR > 4% and the upper TBR 90th percentile limit) of time below range (TBR) the following week. The models were validated in two independent cohorts with a total of 253 additional patients. Results: A total of 61,470 weeks of CGM data were included in the analysis. The XGBoost models had a ROC-AUC of 0.83-0.87 (95% confidence interval [CI]; 0.83-0.88) in the test dataset. The external validation showed ROC-AUCs of 0.81-0.90. The most discriminative features included the low blood glucose index (LBGI), the glycemic risk assessment diabetes equation (GRADE), hypoglycemia, the TBR, waveform length, the CV and mean glucose during the previous week. This highlights that the pattern of hypoglycemia combined with glucose variability during the past week contains information on the risk of future hypoglycemia. Conclusion: Prediction models based on real-world CGM data can be used to predict the risk of hypoglycemia in the forthcoming week. The models showed good performance in both the internal and external validation cohorts.",['XGBoost'],"The research idea addresses the challenge of identifying patients with type 1 diabetes who are at risk of experiencing excessive hypoglycemia in the upcoming week. Hypoglycemia poses significant health risks, and understanding the week-to-week risk profile is crucial for improving patient safety and management. The study focuses on utilizing continuous glucose monitoring data to capture patterns that may indicate future hypoglycemia events. The primary objective of the study was to develop and validate a method to predict the risk of excessive hypoglycemia in the following week among type 1 diabetes patients. This involved assessing specific targets related to time spent below the glucose range and evaluating the predictive performance in both internal and external patient cohorts to ensure reliability and applicability."
Medicine,A methodical exploration of imaging modalities from dataset to detection through machine learning paradigms in prominent lung disease diagnosis: a review,"Abstract Background Lung diseases, both infectious and non-infectious, are the most prevalent cause of mortality overall in the world. Medical research has identified pneumonia, lung cancer, and Corona Virus Disease 2019 (COVID-19) as prominent lung diseases prioritized over others. Imaging modalities, including X-rays, computer tomography (CT) scans, magnetic resonance imaging (MRIs), positron emission tomography (PET) scans, and others, are primarily employed in medical assessments because they provide computed data that can be utilized as input datasets for computer-assisted diagnostic systems. Imaging datasets are used to develop and evaluate machine learning (ML) methods to analyze and predict prominent lung diseases. Objective This review analyzes ML paradigms, imaging modalities' utilization, and recent developments for prominent lung diseases. Furthermore, the research also explores various datasets available publically that are being used for prominent lung diseases. Methods The well-known databases of academic studies that have been subjected to peer review, namely ScienceDirect, arXiv, IEEE Xplore, MDPI, and many more, were used for the search of relevant articles. Applied keywords and combinations used to search procedures with primary considerations for review, such as pneumonia, lung cancer, COVID-19, various imaging modalities, ML, convolutional neural networks (CNNs), transfer learning, and ensemble learning. Results This research finding indicates that X-ray datasets are preferred for detecting pneumonia, while CT scan datasets are predominantly favored for detecting lung cancer. Furthermore, in COVID-19 detection, X-ray datasets are prioritized over CT scan datasets. The analysis reveals that X-rays and CT scans have surpassed all other imaging techniques. It has been observed that using CNNs yields a high degree of accuracy and practicability in identifying prominent lung diseases. Transfer learning and ensemble learning are complementary techniques to CNNs to facilitate analysis. Furthermore, accuracy is the most favored metric for assessment.","['machine learning (ML)', 'convolutional neural networks (CNNs)', 'transfer learning', 'ensemble learning']","The research idea addresses the high prevalence and mortality caused by lung diseases worldwide, with a focus on prominent conditions such as pneumonia, lung cancer, and COVID-19. These diseases represent significant health challenges that require effective diagnostic approaches to improve patient outcomes. The study recognizes the importance of various imaging modalities, including X-rays and CT scans, in medical assessments for detecting these lung diseases. The research objective is to review and analyze the utilization of different imaging techniques and the recent developments related to the diagnosis of prominent lung diseases. Additionally, the study aims to explore the availability and use of publicly accessible imaging datasets that support the detection and evaluation of pneumonia, lung cancer, and COVID-19."
Medicine,A novel fusion framework of deep bottleneck residual convolutional neural network for breast cancer classification from mammogram images,"With over 2.1 million new cases of breast cancer diagnosed annually, the incidence and mortality rate of this disease pose severe global health issues for women. Identifying the disease’s influence is the only practical way to lessen it immediately. Numerous research works have developed automated methods using different medical imaging to identify BC. Still, the precision of each strategy differs based on the available resources, the issue’s nature, and the dataset being used. We proposed a novel deep bottleneck convolutional neural network with a quantum optimization algorithm for breast cancer classification and diagnosis from mammogram images. Two novel deep architectures named three-residual blocks bottleneck and four-residual blocks bottle have been proposed with parallel and single paths. Bayesian Optimization (BO) has been employed to initialize hyperparameter values and train the architectures on the selected dataset. Deep features are extracted from the global average pool layer of both models. After that, a kernel-based canonical correlation analysis and entropy technique is proposed for the extracted deep features fusion. The fused feature set is further refined using an optimization technique named quantum generalized normal distribution optimization. The selected features are finally classified using several neural network classifiers, such as bi-layered and wide-neural networks. The experimental process was conducted on a publicly available mammogram imaging dataset named INbreast, and a maximum accuracy of 96.5% was obtained. Moreover, for the proposed method, the sensitivity rate is 96.45, the precision rate is 96.5, the F1 score value is 96.64, the MCC value is 92.97%, and the Kappa value is 92.97%, respectively. The proposed architectures are further utilized for the diagnosis process of infected regions. In addition, a detailed comparison has been conducted with a few recent techniques showing the proposed framework’s higher accuracy and precision rate.","['deep bottleneck convolutional neural network', 'three-residual blocks bottleneck architecture', 'Bayesian Optimization (BO)', 'kernel-based canonical correlation analysis', 'bi-layered neural network classifier', 'wide-neural network classifier']","The research addresses the significant global health challenge posed by breast cancer, which affects over 2.1 million women annually with high incidence and mortality rates. Early and accurate identification of breast cancer is crucial to reducing its impact and improving patient outcomes. The study focuses on improving the precision of breast cancer classification and diagnosis from mammogram images, acknowledging that existing methods vary in effectiveness depending on resources and data quality. The primary aim of the study is to develop and evaluate novel approaches for classifying and diagnosing breast cancer using mammogram images, with the goal of achieving higher accuracy and reliability in detecting the disease and identifying infected regions."
Medicine,Artificial intelligence for radiographic imaging detection of caries lesions: a systematic review,"Abstract Background The aim of this systematic review is to evaluate the diagnostic performance of Artificial Intelligence (AI) models designed for the detection of caries lesion (CL). Materials and methods An electronic literature search was conducted on PubMed, Web of Science, SCOPUS, LILACS and Embase databases for retrospective, prospective and cross-sectional studies published until January 2023, using the following keywords: artificial intelligence (AI), machine learning (ML), deep learning (DL), artificial neural networks (ANN), convolutional neural networks (CNN), deep convolutional neural networks (DCNN), radiology, detection, diagnosis and dental caries (DC). The quality assessment was performed using the guidelines of QUADAS-2. Results Twenty articles that met the selection criteria were evaluated. Five studies were performed on periapical radiographs, nine on bitewings, and six on orthopantomography. The number of imaging examinations included ranged from 15 to 2900. Four studies investigated ANN models, fifteen CNN models, and two DCNN models. Twelve were retrospective studies, six cross-sectional and two prospective. The following diagnostic performance was achieved in detecting CL: sensitivity from 0.44 to 0.86, specificity from 0.85 to 0.98, precision from 0.50 to 0.94, PPV (Positive Predictive Value) 0.86, NPV (Negative Predictive Value) 0.95, accuracy from 0.73 to 0.98, area under the curve (AUC) from 0.84 to 0.98, intersection over union of 0.3–0.4 and 0.78, Dice coefficient 0.66 and 0.88, F1-score from 0.64 to 0.92. According to the QUADAS-2 evaluation, most studies exhibited a low risk of bias. Conclusion AI-based models have demonstrated good diagnostic performance, potentially being an important aid in CL detection. Some limitations of these studies are related to the size and heterogeneity of the datasets. Future studies need to rely on comparable, large, and clinically meaningful datasets. Protocol PROSPERO identifier: CRD42023470708","['Artificial Neural Networks (ANN)', 'Convolutional Neural Networks (CNN)', 'Deep Convolutional Neural Networks (DCNN)']","The research idea addresses the need to evaluate the effectiveness of current diagnostic approaches for detecting caries lesions, which is crucial for improving dental health outcomes. Accurate detection of caries lesions is essential for timely intervention and treatment, yet there are challenges related to the variability and quality of diagnostic methods. This study focuses on assessing the diagnostic performance of existing approaches to better understand their reliability and potential clinical utility. The research objective is to systematically review and evaluate the diagnostic performance of methods designed for the detection of caries lesions by analyzing studies that report sensitivity, specificity, and other relevant diagnostic metrics. The aim is to determine how well these approaches perform in identifying caries lesions and to identify limitations related to study design and dataset characteristics, ultimately guiding future research toward more robust and clinically meaningful evaluations."
Medicine,Generative Large Language Models for Detection of Speech Recognition Errors in Radiology Reports,"This study evaluated the ability of generative large language models (LLMs) to detect speech recognition errors in radiology reports. A dataset of 3233 CT and MRI reports was assessed by radiologists for speech recognition errors. Errors were categorized as clinically significant or not clinically significant. Performances of five generative LLMs—GPT-3.5-turbo, GPT-4, text-davinci-003, Llama-v2–70B-chat, and Bard—were compared in detecting these errors, using manual error detection as the reference standard. Prompt engineering was used to optimize model performance. GPT-4 demonstrated high accuracy in detecting clinically significant errors (precision, 76.9%; recall, 100%; F1 score, 86.9%) and not clinically significant errors (precision, 93.9%; recall, 94.7%; F1 score, 94.3%). Text-davinci-003 achieved F1 scores of 72% and 46.6% for clinically significant and not clinically significant errors, respectively. GPT-3.5-turbo obtained 59.1% and 32.2% F1 scores, while Llama-v2–70B-chat scored 72.8% and 47.7%. Bard showed the lowest accuracy, with F1 scores of 47.5% and 20.9%. GPT-4 effectively identified challenging errors of nonsense phrases and internally inconsistent statements. Longer reports, resident dictation, and overnight shifts were associated with higher error rates. In conclusion, advanced generative LLMs show potential for automatic detection of speech recognition errors in radiology reports. Keywords: CT, Large Language Model, Machine Learning, MRI, Natural Language Processing, Radiology Reports, Speech, Unsupervised Learning Supplemental material is available for this article. © RSNA, 2024","['generative large language models (LLMs)', 'GPT-3.5-turbo', 'GPT-4', 'text-davinci-003', 'Llama-v2–70B-chat', 'unsupervised learning']","The study addresses the problem of speech recognition errors in radiology reports, which can impact the accuracy and reliability of clinical documentation. These errors, particularly those that are clinically significant, pose challenges for patient care and diagnostic processes. Identifying and correcting such errors is crucial to ensure the quality and safety of radiological interpretations.

The primary aim of the study was to evaluate the ability to detect speech recognition errors in CT and MRI radiology reports, distinguishing between clinically significant and not clinically significant errors. The study sought to assess the accuracy of different approaches in identifying these errors, using manual error detection by radiologists as the reference standard."
Medicine,Performance of convolutional neural networks for the classification of brain tumors using magnetic resonance imaging,"Brain tumors are a diverse group of neoplasms that are challenging to detect and classify due to their varying characteristics. Deep learning techniques have proven to be effective in tumor classification. However, there is a lack of studies that compare these techniques using a common methodology. This work aims to analyze the performance of convolutional neural networks in the classification of brain tumors. We propose a network consisting of a few convolutional layers, batch normalization, and max-pooling. Then, we explore recent deep architectures, such as VGG, ResNet, EfficientNet, or ConvNeXt. The study relies on two magnetic resonance imaging datasets with over 3000 images of three types of tumors –gliomas, meningiomas, and pituitary tumors–, as well as images without tumors. We determine the optimal hyperparameters of the networks using the training and validation sets. The training and test sets are used to assess the performance of the models from different perspectives, including training from scratch, data augmentation, transfer learning, and fine-tuning. The experiments are performed using the TensorFlow and Keras libraries in Python. We compare the accuracy of the models and analyze their complexity based on the capacity of the networks, their training times, and image throughput. Several networks achieve high accuracy rates on both datasets, with the best model achieving 98.7% accuracy, which is on par with state-of-the-art methods. The average precision for each type of tumor is 94.3% for gliomas, 93.8% for meningiomas, 97.9% for pituitary tumors, and 95.3% for images without tumors. VGG is the largest model with over 171 million parameters, whereas MobileNet and EfficientNetB0 are the smallest ones with 3.2 and 5.9 million parameters, respectively. These two neural networks are also the fastest to train with 23.7 and 25.4 seconds per epoch, respectively. On the other hand, ConvNext is the slowest model with 58.2 seconds per epoch. Our custom model obtained the highest image throughput with 234.37 images per second, followed by MobileNet with 226 images per second. ConvNext obtained the smallest throughput with 97.35 images per second. ResNet, MobileNet, and EfficientNet are the most accurate networks, with MobileNet and EfficientNet demonstrating superior performance in terms of complexity. Most models achieve the best accuracy using transfer learning followed by a fine-tuning step. However, data augmentation does not contribute to increasing the accuracy of the models in general.","['convolutional neural networks', 'batch normalization', 'max-pooling', 'VGG', 'ResNet', 'EfficientNet', 'ConvNeXt', 'transfer learning', 'fine-tuning']","The study addresses the challenge of detecting and classifying brain tumors, which are a diverse group of neoplasms with varying characteristics that complicate accurate diagnosis. There is a need for a comprehensive comparison of different approaches to brain tumor classification using a consistent methodology. The primary aim of the study is to evaluate and compare the performance of various classification methods on magnetic resonance imaging datasets containing images of gliomas, meningiomas, pituitary tumors, and non-tumor cases. The objective is to determine the effectiveness and accuracy of these methods in correctly identifying and classifying different types of brain tumors."
Medicine,Predictors for estimating subcortical EEG responses to continuous speech,"Perception of sounds and speech involves structures in the auditory brainstem that rapidly process ongoing auditory stimuli. The role of these structures in speech processing can be investigated by measuring their electrical activity using scalp-mounted electrodes. However, typical analysis methods involve averaging neural responses to many short repetitive stimuli that bear little relevance to daily listening environments. Recently, subcortical responses to more ecologically relevant continuous speech were detected using linear encoding models. These methods estimate the temporal response function (TRF), which is a regression model that minimises the error between the measured neural signal and a predictor derived from the stimulus. Using predictors that model the highly non-linear peripheral auditory system may improve linear TRF estimation accuracy and peak detection. Here, we compare predictors from both simple and complex peripheral auditory models for estimating brainstem TRFs on electroencephalography (EEG) data from 24 participants listening to continuous speech. We also investigate the data length required for estimating subcortical TRFs, and find that around 12 minutes of data is sufficient for clear wave V peaks (&gt;3 dB SNR) to be seen in nearly all participants. Interestingly, predictors derived from simple filterbank-based models of the peripheral auditory system yield TRF wave V peak SNRs that are not significantly different from those estimated using a complex model of the auditory nerve, provided that the nonlinear effects of adaptation in the auditory system are appropriately modelled. Crucially, computing predictors from these simpler models is more than 50 times faster compared to the complex model. This work paves the way for efficient modelling and detection of subcortical processing of continuous speech, which may lead to improved diagnosis metrics for hearing impairment and assistive hearing technology.","['linear encoding models', 'temporal response function (TRF)', 'regression model']","The perception of sounds and speech relies on structures in the auditory brainstem that rapidly process ongoing auditory stimuli, yet typical methods to study these responses use repetitive stimuli that do not reflect everyday listening environments. Understanding how these brainstem structures respond to continuous, ecologically relevant speech is important for advancing knowledge of auditory processing. The primary aim of this study is to compare different models of the peripheral auditory system in estimating brainstem responses to continuous speech, and to determine the amount of data needed to reliably detect key neural response peaks. This research seeks to improve the accuracy and efficiency of measuring subcortical processing of speech, which could enhance diagnostic approaches for hearing impairment and the development of assistive hearing technologies."
Medicine,"Comparative performance analysis of Boruta, SHAP, and Borutashap for disease diagnosis: A study with multiple machine learning algorithms","Interpretable machine learning models are instrumental in disease diagnosis and clinical decision-making, shedding light on relevant features. Notably, Boruta, SHAP (SHapley Additive exPlanations), and BorutaShap were employed for feature selection, each contributing to the identification of crucial features. These selected features were then utilized to train six machine learning algorithms, including LR, SVM, ETC, AdaBoost, RF, and LR, using diverse medical datasets obtained from public sources after rigorous preprocessing. The performance of each feature selection technique was evaluated across multiple ML models, assessing accuracy, precision, recall, and F1-score metrics. Among these, SHAP showcased superior performance, achieving average accuracies of 80.17%, 85.13%, 90.00%, and 99.55% across diabetes, cardiovascular, statlog, and thyroid disease datasets, respectively. Notably, the LGBM emerged as the most effective algorithm, boasting an average accuracy of 91.00% for most disease states. Moreover, SHAP enhanced the interpretability of the models, providing valuable insights into the underlying mechanisms driving disease diagnosis. This comprehensive study contributes significant insights into feature selection techniques and machine learning algorithms for disease diagnosis, benefiting researchers and practitioners in the medical field. Further exploration of feature selection methods and algorithms holds promise for advancing disease diagnosis methodologies, paving the way for more accurate and interpretable diagnostic models.","['Boruta', 'SHAP (SHapley Additive exPlanations)', 'LR', 'SVM', 'AdaBoost', 'RF', 'LGBM']","The research idea centers on improving disease diagnosis and clinical decision-making by identifying the most relevant features that contribute to accurate diagnosis across various medical conditions. The study addresses the need for enhanced interpretability and effectiveness in selecting crucial features from medical datasets to better understand the underlying mechanisms of diseases such as diabetes, cardiovascular disease, statlog, and thyroid disorders. The primary objective of the study is to evaluate and compare different feature selection techniques in their ability to identify important features that improve diagnostic accuracy across multiple disease datasets. Additionally, the study aims to determine which approach provides the most reliable and interpretable insights to support more accurate disease diagnosis and benefit medical researchers and practitioners."
Medicine,Distilling large language models for matching patients to clinical trials,"Abstract Objective The objective of this study is to systematically examine the efficacy of both proprietary (GPT-3.5, GPT-4) and open-source large language models (LLMs) (LLAMA 7B, 13B, 70B) in the context of matching patients to clinical trials in healthcare. Materials and methods The study employs a multifaceted evaluation framework, incorporating extensive automated and human-centric assessments along with a detailed error analysis for each model, and assesses LLMs’ capabilities in analyzing patient eligibility against clinical trial’s inclusion and exclusion criteria. To improve the adaptability of open-source LLMs, a specialized synthetic dataset was created using GPT-4, facilitating effective fine-tuning under constrained data conditions. Results The findings indicate that open-source LLMs, when fine-tuned on this limited and synthetic dataset, achieve performance parity with their proprietary counterparts, such as GPT-3.5. Discussion This study highlights the recent success of LLMs in the high-stakes domain of healthcare, specifically in patient-trial matching. The research demonstrates the potential of open-source models to match the performance of proprietary models when fine-tuned appropriately, addressing challenges like cost, privacy, and reproducibility concerns associated with closed-source proprietary LLMs. Conclusion The study underscores the opportunity for open-source LLMs in patient-trial matching. To encourage further research and applications in this field, the annotated evaluation dataset and the fine-tuned LLM, Trial-LLAMA, are released for public use.","['GPT-3.5', 'GPT-4', 'LLAMA 7B', 'LLAMA 13B', 'LLAMA 70B', 'fine-tuning']","The research idea centers on addressing the challenge of effectively matching patients to appropriate clinical trials, which is a critical step in advancing personalized healthcare and improving patient outcomes. This process requires accurate assessment of patient eligibility based on clinical trial inclusion and exclusion criteria, a task that is complex and resource-intensive. The study is motivated by the need to explore solutions that can enhance the efficiency and accuracy of patient-trial matching while considering issues such as cost, privacy, and reproducibility in healthcare settings. The primary objective of the study is to systematically examine the efficacy of various language models in matching patients to clinical trials by evaluating their ability to analyze patient eligibility criteria. The study aims to determine whether open-source models can achieve comparable performance to proprietary models in this context, thereby offering viable alternatives for patient-trial matching in healthcare."
Medicine,Impact of random oversampling and random undersampling on the performance of prediction models developed using observational health data,"Abstract Background There is currently no consensus on the impact of class imbalance methods on the performance of clinical prediction models. We aimed to empirically investigate the impact of random oversampling and random undersampling, two commonly used class imbalance methods, on the internal and external validation performance of prediction models developed using observational health data. Methods We developed and externally validated prediction models for various outcomes of interest within a target population of people with pharmaceutically treated depression across four large observational health databases. We used three different classifiers (lasso logistic regression, random forest, XGBoost) and varied the target imbalance ratio. We evaluated the impact on model performance in terms of discrimination and calibration. Discrimination was assessed using the area under the receiver operating characteristic curve (AUROC) and calibration was assessed using calibration plots. Results We developed and externally validated a total of 1,566 prediction models. On internal and external validation, random oversampling and random undersampling generally did not result in higher AUROCs. Moreover, we found overestimated risks, although this miscalibration could largely be corrected by recalibrating the models towards the imbalance ratios in the original dataset. Conclusions Overall, we found that random oversampling or random undersampling generally does not improve the internal and external validation performance of prediction models developed in large observational health databases. Based on our findings, we do not recommend applying random oversampling or random undersampling when developing prediction models in large observational health databases.","['random undersampling', 'lasso logistic regression', 'random forest', 'XGBoost']","The research idea addresses the lack of consensus on how class imbalance methods affect the performance of clinical prediction models, particularly in the context of observational health data. This issue is important because class imbalance can influence the accuracy and reliability of models used to predict clinical outcomes, yet the impact of commonly used methods such as random oversampling and random undersampling remains unclear. The study aims to empirically investigate the effects of these two class imbalance methods on the internal and external validation performance of prediction models developed for patients with pharmaceutically treated depression across multiple large health databases. The primary objective of the study is to evaluate whether random oversampling and random undersampling improve the discrimination and calibration of clinical prediction models, as measured by standard performance metrics, and to determine if these methods enhance model validity when applied to large observational health datasets."
Medicine,Auto-detection of the coronavirus disease by using deep convolutional neural networks and X-ray photographs,"Abstract The most widely used method for detecting Coronavirus Disease 2019 (COVID-19) is real-time polymerase chain reaction. However, this method has several drawbacks, including high cost, lengthy turnaround time for results, and the potential for false-negative results due to limited sensitivity. To address these issues, additional technologies such as computed tomography (CT) or X-rays have been employed for diagnosing the disease. Chest X-rays are more commonly used than CT scans due to the widespread availability of X-ray machines, lower ionizing radiation, and lower cost of equipment. COVID-19 presents certain radiological biomarkers that can be observed through chest X-rays, making it necessary for radiologists to manually search for these biomarkers. However, this process is time-consuming and prone to errors. Therefore, there is a critical need to develop an automated system for evaluating chest X-rays. Deep learning techniques can be employed to expedite this process. In this study, a deep learning-based method called Custom Convolutional Neural Network (Custom-CNN) is proposed for identifying COVID-19 infection in chest X-rays. The Custom-CNN model consists of eight weighted layers and utilizes strategies like dropout and batch normalization to enhance performance and reduce overfitting. The proposed approach achieved a classification accuracy of 98.19% and aims to accurately classify COVID-19, normal, and pneumonia samples.","['Deep learning', 'dropout', 'batch normalization']","The research addresses the limitations of the current standard method for detecting COVID-19, real-time polymerase chain reaction, which includes high cost, long turnaround times, and the possibility of false-negative results due to limited sensitivity. To overcome these challenges, chest X-rays have been utilized as a diagnostic tool because they are more accessible, involve lower radiation exposure, and are less expensive compared to CT scans. However, identifying COVID-19-related radiological biomarkers on chest X-rays requires manual examination by radiologists, which is time-consuming and susceptible to errors. The study’s primary objective is to develop an approach that can accurately classify COVID-19, normal, and pneumonia cases using chest X-rays, thereby improving the efficiency and reliability of diagnosis."
Medicine,GAN-based generation of realistic 3D volumetric data: A systematic review and taxonomy,"With the massive proliferation of data-driven algorithms, such as deep learning-based approaches, the availability of high-quality data is of great interest. Volumetric data is very important in medicine, as it ranges from disease diagnoses to therapy monitoring. When the dataset is sufficient, models can be trained to help doctors with these tasks. Unfortunately, there are scenarios where large amounts of data is unavailable. For example, rare diseases and privacy issues can lead to restricted data availability. In non-medical fields, the high cost of obtaining enough high-quality data can also be a concern. A solution to these problems can be the generation of realistic synthetic data using Generative Adversarial Networks (GANs). The existence of these mechanisms is a good asset, especially in healthcare, as the data must be of good quality, realistic, and without privacy issues. Therefore, most of the publications on volumetric GANs are within the medical domain. In this review, we provide a summary of works that generate realistic volumetric synthetic data using GANs. We therefore outline GAN-based methods in these areas with common architectures, loss functions and evaluation metrics, including their advantages and disadvantages. We present a novel taxonomy, evaluations, challenges, and research opportunities to provide a holistic overview of the current state of volumetric GANs.","['Generative Adversarial Networks (GANs)', 'GAN-based methods']","The research idea centers on the critical importance of high-quality volumetric data in medicine, which is essential for tasks ranging from disease diagnosis to therapy monitoring. However, the availability of sufficient medical data is often limited due to factors such as the rarity of certain diseases and privacy concerns. This scarcity poses significant challenges for medical research and clinical applications that rely on comprehensive datasets. The study aims to address these challenges by exploring approaches to generate realistic synthetic volumetric data that can supplement limited real-world data while maintaining quality and privacy standards."
Medicine,Molecular structural modeling and physical characteristics of anti-breast cancer drugs via some novel topological descriptors and regression models,"Research is continuously being pursued to treat cancer patients and prevent the disease by developing new medicines. However, experimental drug design and development is a costly, time-consuming, and challenging process. Alternatively, computational and mathematical techniques play an important role in optimally achieving this goal. Among these mathematical techniques, topological indices (TIs) have many applications in the drugs used for the treatment of breast cancer. TIs can be utilized to forecast the effectiveness of drugs by providing molecular structure information and related properties of the drugs. In addition, these can assist in the design and discovery of new drugs by providing insights into the structure-property/structure-activity relationships. In this article, a Quantitative Structure Property Relationship (QSPR) analysis is carried out using some novel degree-based molecular descriptors and regression models to predict various properties (such as boiling point, melting point, enthalpy, flashpoint, molar refraction, molar volume, and polarizability) of 14 drugs used for the breast cancer treatment. The molecular structures of these drugs are topologically modeled through vertex and edge partitioning techniques of graph theory, and then linear regression models are developed to correlate the computed values with the experimental properties of the drugs to investigate the performance of TIs in predicting these properties. The results confirmed the potential of the considered topological indices as a tool for drug discovery and design in the field of breast cancer treatment.","['regression models', 'linear regression models']","The research addresses the challenge of developing effective treatments for breast cancer, highlighting the complexity, cost, and time involved in experimental drug design and development. It emphasizes the importance of understanding molecular structure information and related properties of drugs to improve their effectiveness and aid in the discovery of new therapeutic agents. The primary aim of the study is to evaluate the potential of certain molecular descriptors, specifically topological indices, in predicting various physical and chemical properties of drugs used for breast cancer treatment. This evaluation seeks to confirm the usefulness of these descriptors as tools to support drug discovery and design in the context of breast cancer therapy."
Medicine,Exploring the role of skin temperature in thermal sensation and thermal comfort: A comprehensive review,"The role of skin temperature as a determinant of human thermal sensation and comfort has gained increasing recognition, prompting a need for a systematic review. This review examines the relationship between skin temperature and thermal sensation, synthesizing insights from 172 studies published since 2000. It uniquely focuses on the indispensable roles of local and mean skin temperatures, a perspective not comprehensively explored in previous literature. The review reveals that the most common measurement points for skin temperature are the face and hands, attributed to their higher thermal sensitivity and the practical ease of measurement. It establishes a clear linear relationship between mean skin temperature and user thermal sensation, though affected by the choice of measurement locations and number of points. A notable finding is the varying impact of local skin temperature on overall thermal sensation in changing environments, with local heating less influential than cooling. The review also uncovers significant demographic variations in thermal sensation, strongly influenced by differing skin temperatures across age groups, genders, and climatic regions. For example, elderly populations exhibit a decreased temperature sensitivity, especially towards warmth. Gender differences are also significant, with females experiencing higher skin temperatures in warmer environments and lower in colder ones. Machine learning (ML)-based methods, especially classification tree-based and support vector machine (SVM) techniques, dominate in predicting thermal sensation and comfort, leveraging skin temperature data. While ML methods are prevalent, statistical regression-based approaches offer valuable empirical insights. Thermo-physiological model-based methods provide reliable results by incorporating detailed skin temperature dynamics. The review identifies a gap in understanding how gender, age, and regional differences influence thermal comfort in diverse environments. The study recommends conducting more nuanced experiments to dissect the impact of these factors and proposes the integration of individual demographic variables into ML models to personalize thermal comfort predictions.","['support vector machine (SVM)', 'statistical regression-based approaches']","The research idea centers on the increasing recognition of skin temperature as a key determinant of human thermal sensation and comfort, highlighting the need for a comprehensive synthesis of existing knowledge on this relationship. Despite numerous studies, there remains a gap in understanding how local and mean skin temperatures, as well as demographic factors such as age, gender, and climatic region, influence thermal sensation in varying environments. The study aims to systematically review and clarify these aspects, which have not been comprehensively explored in previous literature. The primary objective of the study is to examine the relationship between skin temperature and thermal sensation by synthesizing findings from 172 studies published since 2000, with a particular focus on the roles of local and mean skin temperatures. Additionally, the study seeks to identify demographic variations in thermal sensation and to highlight gaps in knowledge regarding how these factors affect thermal comfort across different populations and environments."
Medicine,"Artificial intelligence in lung cancer screening: Detection, classification, prediction, and prognosis","Abstract Background The exceptional capabilities of artificial intelligence (AI) in extracting image information and processing complex models have led to its recognition across various medical fields. With the continuous evolution of AI technologies based on deep learning, particularly the advent of convolutional neural networks (CNNs), AI presents an expanded horizon of applications in lung cancer screening, including lung segmentation, nodule detection, false‐positive reduction, nodule classification, and prognosis. Methodology This review initially analyzes the current status of AI technologies. It then explores the applications of AI in lung cancer screening, including lung segmentation, nodule detection, and classification, and assesses the potential of AI in enhancing the sensitivity of nodule detection and reducing false‐positive rates. Finally, it addresses the challenges and future directions of AI in lung cancer screening. Results AI holds substantial prospects in lung cancer screening. It demonstrates significant potential in improving nodule detection sensitivity, reducing false‐positive rates, and classifying nodules, while also showing value in predicting nodule growth and pathological/genetic typing. Conclusions AI offers a promising supportive approach to lung cancer screening, presenting considerable potential in enhancing nodule detection sensitivity, reducing false‐positive rates, and classifying nodules. However, the universality and interpretability of AI results need further enhancement. Future research should focus on the large‐scale validation of new deep learning‐based algorithms and multi‐center studies to improve the efficacy of AI in lung cancer screening.","['deep learning', 'convolutional neural networks (CNNs)']","The research idea centers on the need to improve lung cancer screening by enhancing the detection and classification of lung nodules, as well as reducing false-positive rates, which are critical challenges in early diagnosis and prognosis. Lung cancer screening currently faces limitations in sensitivity and accuracy, and there is a growing interest in methods that can better identify and characterize nodules to support clinical decision-making. The study’s primary objective is to evaluate the current advancements in lung cancer screening techniques aimed at improving nodule detection sensitivity, reducing false-positive findings, and accurately classifying nodules. Additionally, the study seeks to explore the potential for predicting nodule growth and pathological or genetic characteristics to enhance screening outcomes and guide future research directions."
Medicine,Enhancing EfficientNetv2 with global and efficient channel attention mechanisms for accurate MRI-Based brain tumor classification,"Abstract The early and accurate diagnosis of brain tumors is critical for effective treatment planning, with Magnetic Resonance Imaging (MRI) serving as a key tool in the non-invasive examination of such conditions. Despite the advancements in Computer-Aided Diagnosis (CADx) systems powered by deep learning, the challenge of accurately classifying brain tumors from MRI scans persists due to the high variability of tumor appearances and the subtlety of early-stage manifestations. This work introduces a novel adaptation of the EfficientNetv2 architecture, enhanced with Global Attention Mechanism (GAM) and Efficient Channel Attention (ECA), aimed at overcoming these hurdles. This enhancement not only amplifies the model’s ability to focus on salient features within complex MRI images but also significantly improves the classification accuracy of brain tumors. Our approach distinguishes itself by meticulously integrating attention mechanisms that systematically enhance feature extraction, thereby achieving superior performance in detecting a broad spectrum of brain tumors. Demonstrated through extensive experiments on a large public dataset, our model achieves an exceptional high-test accuracy of 99.76%, setting a new benchmark in MRI-based brain tumor classification. Moreover, the incorporation of Grad-CAM visualization techniques sheds light on the model’s decision-making process, offering transparent and interpretable insights that are invaluable for clinical assessment. By addressing the limitations inherent in previous models, this study not only advances the field of medical imaging analysis but also highlights the pivotal role of attention mechanisms in enhancing the interpretability and accuracy of deep learning models for brain tumor diagnosis. This research sets the stage for advanced CADx systems, enhancing patient care and treatment outcomes.","['EfficientNetv2 architecture', 'Global Attention Mechanism (GAM)', 'Efficient Channel Attention (ECA)']","The early and accurate diagnosis of brain tumors is critical for effective treatment planning, with Magnetic Resonance Imaging (MRI) serving as a key tool in the non-invasive examination of such conditions. However, accurately classifying brain tumors from MRI scans remains challenging due to the high variability of tumor appearances and the subtlety of early-stage manifestations. The primary aim of this study is to improve the classification accuracy of brain tumors using MRI images by enhancing the ability to focus on salient features within complex scans. This work seeks to overcome existing limitations in brain tumor diagnosis to ultimately support better clinical assessment and treatment outcomes."
Medicine,Automated model discovery for human cardiac tissue: Discovering the best model and parameters,"For more than half a century, scientists have developed mathematical models to understand the behavior of the human heart. Today, we have dozens of heart tissue models to choose from, but selecting the best model is limited to expert professionals, prone to user bias, and vulnerable to human error. Here we take the human out of the loop and automate the process of model discovery. Towards this goal, we establish a novel incompressible orthotropic constitutive neural network to simultaneously discover both, model and parameters, that best explain human cardiac tissue. Notably, our network features 32 individual terms, 8 isotropic and 24 anisotropic, and fully autonomously selects the best model, out of more than 4 billion possible combinations of terms. We demonstrate that we can successfully train the network with triaxial shear and biaxial extension tests and systematically sparsify the parameter vector with L1-regularization. Strikingly, we robustly discover a four-term model that features a quadratic term in the second invariant I2, and exponential quadratic terms in the fourth and eighth invariants I4f, I4n, and I8fs. Importantly, our discovered model is interpretable by design and has parameters with well-defined physical units. We show that it outperforms popular existing myocardium models and generalizes well, from homogeneous laboratory tests to heterogeneous whole heart simulations. This is made possible by a new universal material subroutine that directly takes the discovered network weights as input. Automating the process of model discovery has the potential to democratize cardiac modeling, broaden participation in scientific discovery, and accelerate the development of innovative treatments for cardiovascular disease. Our source code, data, and examples are available at https://github.com/LivingMatterLab/CANN.",['L1-regularization'],"The study addresses the challenge of selecting the most appropriate mathematical model to understand the behavior of human cardiac tissue, a process currently limited to expert professionals and susceptible to user bias and human error. Despite the availability of numerous heart tissue models, there is a need for a more objective and reliable approach to identify the best model that accurately represents human myocardium. The primary aim of the study is to develop a method that can autonomously discover both the optimal model and its parameters to best explain human cardiac tissue behavior. This approach seeks to improve the interpretability and physical relevance of the model while enhancing its performance and generalizability across different cardiac testing conditions."
Medicine,Improving diabetes disease patients classification using stacking ensemble method with PIMA and local healthcare data,"Diabetes mellitus, a chronic metabolic disorder, continues to be a major public health issue around the world. It is estimated that one in every two diabetics is undiagnosed. Early diagnosis and management of diabetes can also prevent or delay the onset of complications. With the help of a variety of machine learning and deep learning models, stacking algorithms, and other techniques, our study's goal is to detect diseases early. In this study, we propose two stacking-based models for diabetes disease classification using a combination of the PIMA Indian diabetes dataset, simulated data, and additional data collected from a local healthcare facility. We use both the classical and deep neural network stacking ensemble methods to combine the predictions of multiple classification models and improve classification accuracy and robustness. In the evaluation protocol, we used both the train-test and cross-validation (CV) techniques to validate our proposed model. The highest accuracy is obtained by stacking ensemble with three NN architectures, resulting in an accuracy of 95.50 %, precision of 94 %, recall of 97 %, and f1-score of 96 % using 5-fold CV on simulation study. The stacked accuracy obtained from ML algorithms for the Pima Indian Diabetes dataset is 75.03 % using the train-test split protocol, while the accuracy obtained from the CV protocol is 77.10 % on the stacked model. The range of performance scores that outperformed the CV protocol 2.23 %–12 %. Our proposed method achieves a high accuracy range from 92 % to 95 %, precision, recall, and F1-score ranges from 88 % to 96 % using classical and deep neural network (NN)-based stacking method on the primary dataset. The proposed dataset and ensemble method could be useful in the early detection and treatment of diabetes, as well as in the advancement of machine learning and data analysis techniques in the healthcare industry.","['stacking algorithms', 'stacking-based models', 'classical stacking ensemble methods', 'deep neural network stacking ensemble methods']","Diabetes mellitus, a chronic metabolic disorder, remains a significant public health concern worldwide, with an estimated one in every two diabetics remaining undiagnosed. Early diagnosis and management of diabetes are crucial to prevent or delay the onset of complications associated with the disease. The primary aim of this study is to improve the early detection of diabetes by developing effective classification approaches using a combination of existing datasets and locally collected healthcare data. This study seeks to enhance the accuracy and robustness of diabetes diagnosis to support timely treatment and better health outcomes."
Medicine,Federated Learning for Decentralized Artificial Intelligence in Melanoma Diagnostics,"Importance The development of artificial intelligence (AI)–based melanoma classifiers typically calls for large, centralized datasets, requiring hospitals to give away their patient data, which raises serious privacy concerns. To address this concern, decentralized federated learning has been proposed, where classifier development is distributed across hospitals. Objective To investigate whether a more privacy-preserving federated learning approach can achieve comparable diagnostic performance to a classical centralized (ie, single-model) and ensemble learning approach for AI-based melanoma diagnostics. Design, Setting, and Participants This multicentric, single-arm diagnostic study developed a federated model for melanoma-nevus classification using histopathological whole-slide images prospectively acquired at 6 German university hospitals between April 2021 and February 2023 and benchmarked it using both a holdout and an external test dataset. Data analysis was performed from February to April 2023. Exposures All whole-slide images were retrospectively analyzed by an AI-based classifier without influencing routine clinical care. Main Outcomes and Measures The area under the receiver operating characteristic curve (AUROC) served as the primary end point for evaluating the diagnostic performance. Secondary end points included balanced accuracy, sensitivity, and specificity. Results The study included 1025 whole-slide images of clinically melanoma-suspicious skin lesions from 923 patients, consisting of 388 histopathologically confirmed invasive melanomas and 637 nevi. The median (range) age at diagnosis was 58 (18-95) years for the training set, 57 (18-93) years for the holdout test dataset, and 61 (18-95) years for the external test dataset; the median (range) Breslow thickness was 0.70 (0.10-34.00) mm, 0.70 (0.20-14.40) mm, and 0.80 (0.30-20.00) mm, respectively. The federated approach (0.8579; 95% CI, 0.7693-0.9299) performed significantly worse than the classical centralized approach (0.9024; 95% CI, 0.8379-0.9565) in terms of AUROC on a holdout test dataset (pairwise Wilcoxon signed-rank, P &amp;amp;lt; .001) but performed significantly better (0.9126; 95% CI, 0.8810-0.9412) than the classical centralized approach (0.9045; 95% CI, 0.8701-0.9331) on an external test dataset (pairwise Wilcoxon signed-rank, P &amp;amp;lt; .001). Notably, the federated approach performed significantly worse than the ensemble approach on both the holdout (0.8867; 95% CI, 0.8103-0.9481) and external test dataset (0.9227; 95% CI, 0.8941-0.9479). Conclusions and Relevance The findings of this diagnostic study suggest that federated learning is a viable approach for the binary classification of invasive melanomas and nevi on a clinically representative distributed dataset. Federated learning can improve privacy protection in AI-based melanoma diagnostics while simultaneously promoting collaboration across institutions and countries. Moreover, it may have the potential to be extended to other image classification tasks in digital cancer histopathology and beyond.","['federated learning', 'ensemble learning approach']","The study addresses the challenge of developing effective melanoma diagnostic tools while preserving patient privacy, as traditional approaches require centralized collection of sensitive patient data from multiple hospitals. This raises significant privacy concerns and limits collaboration across institutions. The research explores whether a more privacy-preserving approach to melanoma classification can maintain diagnostic accuracy comparable to conventional centralized methods.

The primary aim of the study is to investigate whether a privacy-preserving federated approach can achieve diagnostic performance comparable to classical centralized and ensemble learning approaches for melanoma diagnostics. The study focuses on evaluating the effectiveness of this approach in classifying invasive melanomas and nevi using histopathological whole-slide images collected from multiple university hospitals."
Medicine,Exploration of Interpretability Techniques for Deep COVID-19 Classification Using Chest X-ray Images,"The outbreak of COVID-19 has shocked the entire world with its fairly rapid spread, and has challenged different sectors. One of the most effective ways to limit its spread is the early and accurate diagnosing of infected patients. Medical imaging, such as X-ray and computed tomography (CT), combined with the potential of artificial intelligence (AI), plays an essential role in supporting medical personnel in the diagnosis process. Thus, in this article, five different deep learning models (ResNet18, ResNet34, InceptionV3, InceptionResNetV2, and DenseNet161) and their ensemble, using majority voting, have been used to classify COVID-19, pneumoniæ and healthy subjects using chest X-ray images. Multilabel classification was performed to predict multiple pathologies for each patient, if present. Firstly, the interpretability of each of the networks was thoroughly studied using local interpretability methods—occlusion, saliency, input X gradient, guided backpropagation, integrated gradients, and DeepLIFT—and using a global technique—neuron activation profiles. The mean micro F1 score of the models for COVID-19 classifications ranged from 0.66 to 0.875, and was 0.89 for the ensemble of the network models. The qualitative results showed that the ResNets were the most interpretable models. This research demonstrates the importance of using interpretability methods to compare different models before making a decision regarding the best performing model.","['ResNet18', 'ResNet34', 'InceptionV3', 'InceptionResNetV2', 'DenseNet161', 'ensemble using majority voting', 'saliency', 'input X gradient', 'guided backpropagation', 'integrated gradients', 'DeepLIFT']","The outbreak of COVID-19 has posed a significant global health challenge due to its rapid spread, highlighting the critical need for early and accurate diagnosis of infected patients to limit transmission. Medical imaging techniques, such as chest X-rays, are essential tools in supporting healthcare professionals in identifying COVID-19 and differentiating it from other conditions like pneumonia and healthy states. The primary aim of this study is to classify COVID-19, pneumonia, and healthy subjects using chest X-ray images and to predict multiple pathologies for each patient when present. Additionally, the study seeks to evaluate and compare the interpretability of different diagnostic approaches to determine the most effective method for accurate COVID-19 classification."
Medicine,Diabetic foot ulcers segmentation challenge report: Benchmark and analysis,"Monitoring the healing progress of diabetic foot ulcers is a challenging process. Accurate segmentation of foot ulcers can help podiatrists to quantitatively measure the size of wound regions to assist prediction of healing status. The main challenge in this field is the lack of publicly available manual delineation, which can be time consuming and laborious. Recently, methods based on deep learning have shown excellent results in automatic segmentation of medical images, however, they require large-scale datasets for training, and there is limited consensus on which methods perform the best. The 2022 Diabetic Foot Ulcers segmentation challenge was held in conjunction with the 2022 International Conference on Medical Image Computing and Computer Assisted Intervention, which sought to address these issues and stimulate progress in this research domain. A training set of 2000 images exhibiting diabetic foot ulcers was released with corresponding segmentation ground truth masks. Of the 72 (approved) requests from 47 countries, 26 teams used this data to develop fully automated systems to predict the true segmentation masks on a test set of 2000 images, with the corresponding ground truth segmentation masks kept private. Predictions from participating teams were scored and ranked according to their average Dice similarity coefficient of the ground truth masks and prediction masks. The winning team achieved a Dice of 0.7287 for diabetic foot ulcer segmentation. This challenge has now entered a live leaderboard stage where it serves as a challenging benchmark for diabetic foot ulcer segmentation.",['deep learning'],"The study addresses the challenge of monitoring the healing progress of diabetic foot ulcers, which requires accurate measurement of wound size to assist in predicting healing status. A significant problem in this field is the lack of publicly available manual delineations of foot ulcers, making the process time-consuming and laborious for clinicians. The primary aim of the study was to facilitate progress in the segmentation of diabetic foot ulcers by providing a large dataset of images with corresponding manual segmentation masks and organizing a challenge to evaluate and compare different approaches for accurately delineating ulcer regions. This effort sought to establish a benchmark for diabetic foot ulcer segmentation to improve quantitative assessment and support clinical decision-making."
Medicine,Predictive Modelling of Critical Vital Signs in ICU Patients by Machine Learning: An Early Warning System for Improved Patient Outcomes,"Accurate monitoring of vital signs in an ICU is integral to understanding overall physical well-being for patients. Our research endeavor employed machine learning techniques to construct a predictive classification model utilizing continuous ICU vital sign measurements. The primary aim was to develop an early warning system capable of forecasting whether vital indicators would reach critical values within one hour; our ultimate aim was to enable healthcare professionals, including nurses and doctors, to intervene proactively, preventing emergency situations which could result in organ dysfunction or mortality. Our comprehensive dataset comprises vital sign measurements, lab test results, procedures, and medications from over 50,000 patients collected via rigorous preprocessing procedures like data cleansing, bias correction, feature extraction and selection to produce an insightful dataset with distinguishing attributes. After selecting an algorithmic set that included Decision Trees (DT), Support Vector Machines (SVM), Recurrent Neural Networks (RNN), and Long Short-Term Memory (LSTM), to predict critical vital signs in ICU patients one hour in advance - such as Heart Rate, SpO2, Mean Artery Pressure (MAP), Respiratory Rate (RR), and Systolic Blood Pressure (SBP). Our models included Heart Rate prediction as well as respiratory Rate/RR predictions/SBP estimation models. The results of the study demonstrated the efficacy and accuracy of machine learning methods designed to anticipate imminent changes to vital signs. Utilizing such predictive models, healthcare providers can increase their capacity to address potential complications before they occur, ultimately leading to improved patient outcomes in challenging settings.","['Decision Trees (DT)', 'Support Vector Machines (SVM)', 'Recurrent Neural Networks (RNN)', 'Long Short-Term Memory (LSTM)']","The research idea centers on the critical importance of accurately monitoring vital signs in an intensive care unit (ICU) to understand and maintain the overall physical well-being of patients. Early detection of changes in vital indicators is essential to prevent emergency situations that could lead to organ dysfunction or mortality. The study addresses the need for timely identification of critical vital sign changes to enable proactive intervention by healthcare professionals. The primary objective of the study was to develop a method capable of forecasting whether vital signs such as Heart Rate, SpO2, Mean Artery Pressure, Respiratory Rate, and Systolic Blood Pressure would reach critical values within one hour. This early warning capability aims to support nurses and doctors in intervening promptly to prevent complications and improve patient outcomes in the ICU setting."
Medicine,Enhancing cervical cancer detection and robust classification through a fusion of deep learning models,"Abstract Cervical cancer, the second most prevalent cancer affecting women, arises from abnormal cell growth in the cervix, a crucial anatomical structure within the uterus. The significance of early detection cannot be overstated, prompting the use of various screening methods such as Pap smears, colposcopy, and Human Papillomavirus (HPV) testing to identify potential risks and initiate timely intervention. These screening procedures encompass visual inspections, Pap smears, colposcopies, biopsies, and HPV-DNA testing, each demanding the specialized knowledge and skills of experienced physicians and pathologists due to the inherently subjective nature of cancer diagnosis. In response to the imperative for efficient and intelligent screening, this article introduces a groundbreaking methodology that leverages pre-trained deep neural network models, including Alexnet, Resnet-101, Resnet-152, and InceptionV3, for feature extraction. The fine-tuning of these models is accompanied by the integration of diverse machine learning algorithms, with ResNet152 showcasing exceptional performance, achieving an impressive accuracy rate of 98.08%. It is noteworthy that the SIPaKMeD dataset, publicly accessible and utilized in this study, contributes to the transparency and reproducibility of our findings. The proposed hybrid methodology combines aspects of DL and ML for cervical cancer classification. Most intricate and complicated features from images can be extracted through DL. Further various ML algorithms can be implemented on extracted features. This innovative approach not only holds promise for significantly improving cervical cancer detection but also underscores the transformative potential of intelligent automation within the realm of medical diagnostics, paving the way for more accurate and timely interventions.","['Alexnet', 'Resnet-101', 'Resnet-152', 'InceptionV3', 'deep neural network models', 'fine-tuning']","The research idea centers on the critical importance of early detection of cervical cancer, which is the second most prevalent cancer affecting women and arises from abnormal cell growth in the cervix. Current screening methods such as Pap smears, colposcopy, and HPV testing require specialized knowledge due to the subjective nature of cancer diagnosis, highlighting the need for more efficient and accurate screening approaches. The study addresses the challenge of improving cervical cancer detection to enable timely intervention and better patient outcomes. The primary objective of the study is to develop and evaluate a novel approach for cervical cancer classification that enhances the accuracy of detection by utilizing advanced techniques for feature extraction and classification. This approach aims to improve the reliability and effectiveness of screening procedures, ultimately facilitating earlier diagnosis and treatment of cervical cancer."
Medicine,A review of uncertainty quantification in medical image analysis: Probabilistic and non-probabilistic methods,"The comprehensive integration of machine learning healthcare models within clinical practice remains suboptimal, notwithstanding the proliferation of high-performing solutions reported in the literature. A predominant factor hindering widespread adoption pertains to an insufficiency of evidence affirming the reliability of the aforementioned models. Recently, uncertainty quantification methods have been proposed as a potential solution to quantify the reliability of machine learning models and thus increase the interpretability and acceptability of the results. In this review, we offer a comprehensive overview of the prevailing methods proposed to quantify the uncertainty inherent in machine learning models developed for various medical image tasks. Contrary to earlier reviews that exclusively focused on probabilistic methods, this review also explores non-probabilistic approaches, thereby furnishing a more holistic survey of research pertaining to uncertainty quantification for machine learning models. Analysis of medical images with the summary and discussion on medical applications and the corresponding uncertainty evaluation protocols are presented, which focus on the specific challenges of uncertainty in medical image analysis. We also highlight some potential future research work at the end. Generally, this review aims to allow researchers from both clinical and technical backgrounds to gain a quick and yet in-depth understanding of the research in uncertainty quantification for medical image analysis machine learning models.","['probabilistic methods', 'non-probabilistic approaches']","The research idea addresses the challenge of suboptimal integration of advanced healthcare solutions into clinical practice due to insufficient evidence supporting their reliability. This lack of reliable evidence limits the widespread adoption of these solutions in medical settings, particularly in the context of medical image analysis. The study recognizes the importance of quantifying uncertainty to enhance the trustworthiness and acceptability of results in medical applications. The primary objective of the study is to provide a comprehensive overview of existing methods used to quantify uncertainty in medical image analysis, highlighting both probabilistic and non-probabilistic approaches. It aims to summarize and discuss the specific challenges related to uncertainty in medical image tasks and to present relevant evaluation protocols, thereby facilitating a deeper understanding for researchers from clinical backgrounds."
Medicine,Integrative analysis of AI-driven optimization in HIV treatment regimens,"The integration of artificial intelligence (AI) into HIV treatment regimens has revolutionized the approach to personalized care and optimization strategies. This study presents an in-depth analysis of the role of AI in transforming HIV treatment, focusing on its ability to tailor therapy to individual patient needs and enhance treatment outcomes. AI-driven optimization in HIV treatment involves the utilization of advanced algorithms and computational techniques to analyze vast amounts of patient data, including genetic information, viral load measurements, and treatment history. By harnessing the power of machine learning and predictive analytics, AI algorithms can identify patterns and trends in patient data that may not be readily apparent to human clinicians. One of the key benefits of AI-driven optimization is its ability to personalize treatment regimens based on individual patient characteristics and disease progression. By considering factors such as drug resistance profiles, comorbidities, and lifestyle factors, AI algorithms can recommend the most effective and well-tolerated treatment options for each patient, leading to improved adherence and clinical outcomes. Furthermore, AI enables continuous monitoring and adjustment of treatment regimens in real time, allowing healthcare providers to respond rapidly to changes in patient status and evolving viral dynamics. This proactive approach to HIV management can help prevent treatment failure and the development of drug resistance, ultimately leading to better long-term outcomes for patients. Despite its transformative potential, AI-driven optimization in HIV treatment is not without challenges. Ethical considerations, data privacy concerns, and the need for robust validation and regulatory oversight are all important factors that must be addressed to ensure the safe and effective implementation of AI algorithms in clinical practice. In conclusion, the integrative analysis presented in this study underscores the significant impact of AI-driven optimization on the personalization and optimization of HIV treatment regimens. By leveraging AI technologies, healthcare providers can tailor treatment approaches to individual patient needs, leading to improved outcomes and quality of life for people living with HIV. Keywords: Integrative Analysis, AI- Driven, Optimization, HIV Treatment, Regimens.",['machine learning'],"The study addresses the challenge of optimizing HIV treatment regimens to better personalize care for individual patients, aiming to improve treatment outcomes by considering factors such as drug resistance, comorbidities, and lifestyle. It highlights the need for approaches that can tailor therapy based on patient-specific characteristics and disease progression, thereby enhancing adherence and clinical effectiveness. The primary objective of the study is to explore how personalized treatment strategies can be developed to improve the management of HIV, focusing on tailoring therapy to individual patient needs and continuously adjusting treatment to respond to changes in patient status and viral dynamics. The study aims to demonstrate the benefits of individualized treatment regimens in preventing treatment failure and drug resistance, ultimately improving long-term outcomes and quality of life for people living with HIV."
Medicine,Artificial intelligence for oral squamous cell carcinoma detection based on oral photographs: A comprehensive literature review,"Abstract Introduction Oral squamous cell carcinoma (OSCC) presents a significant global health challenge. The integration of artificial intelligence (AI) and computer vision holds promise for the early detection of OSCC through the analysis of digitized oral photographs. This literature review explores the landscape of AI‐driven OSCC automatic detection, assessing both the performance and limitations of the current state of the art. Materials and Methods An electronic search using several data base was conducted, and a systematic review performed in accordance with PRISMA guidelines (CRD42023441416). Results Several studies have demonstrated remarkable results for this task, consistently achieving sensitivity rates exceeding 85% and accuracy rates surpassing 90%, often encompassing around 1000 images. The review scrutinizes these studies, shedding light on their methodologies, including the use of recent machine learning and pattern recognition approaches coupled with different supervision strategies. However, comparing the results from different papers is challenging due to variations in the datasets used. Discussion Considering these findings, this review underscores the urgent need for more robust and reliable datasets in the field of OSCC detection. Furthermore, it highlights the potential of advanced techniques such as multi‐task learning, attention mechanisms, and ensemble learning as crucial tools in enhancing the accuracy and sensitivity of OSCC detection through oral photographs. Conclusion These insights collectively emphasize the transformative impact of AI‐driven approaches on early OSCC diagnosis, with the potential to significantly improve patient outcomes and healthcare practices.","['machine learning', 'multi-task learning', 'attention mechanisms', 'ensemble learning']","Oral squamous cell carcinoma (OSCC) presents a significant global health challenge due to its prevalence and the critical importance of early detection for improving patient outcomes. Early diagnosis of OSCC through the analysis of oral photographs could greatly enhance treatment effectiveness and reduce mortality rates. The study addresses the need to evaluate current approaches for detecting OSCC to understand their performance and limitations. The primary aim of this study is to systematically review the existing literature on automatic detection of OSCC using digitized oral photographs, assessing the sensitivity and accuracy reported in various studies. Additionally, the study seeks to highlight the challenges posed by variability in datasets and emphasize the necessity for more robust and reliable data to improve early OSCC diagnosis."
Medicine,Diagnostic Performance Comparison between Generative AI and Physicians: A Systematic Review and Meta-Analysis,"Abstract Background The rapid advancement of generative artificial intelligence (AI) has led to the wide dissemination of models with exceptional understanding and generation of human language. Their integration into healthcare has shown potential for improving medical diagnostics, yet a comprehensive diagnostic performance evaluation of generative AI models and the comparison of their diagnostic performance with that of physicians has not been extensively explored. Methods In this systematic review and meta-analysis, a comprehensive search of Medline, Scopus, Web of Science, Cochrane Central, and MedRxiv was conducted for studies published from June 2018 through December 2023, focusing on those that validate generative AI models for diagnostic tasks. The risk of bias was assessed using the Prediction Model Study Risk of Bias Assessment Tool. Meta-regression was performed to summarize the performance of the models and to compare the accuracy of the models with that of physicians. Results The search resulted in 54 studies being included in the meta-analysis. Nine generative AI models were evaluated across 17 medical specialties. The quality assessment indicated a high risk of bias in the majority of studies, primarily due to small sample sizes. The overall accuracy for generative AI models across 54 studies was 56.9% (95% confidence interval [CI]: 51.0–62.7%). The meta-analysis demonstrated that, on average, physicians exceeded the accuracy of the models (difference in accuracy: 14.4% [95% CI: 4.9–23.8%], p-value =0.004). However, both Prometheus (Bing) and GPT-4 showed slightly better performance compared to non-experts (-2.3% [95% CI: -27.0–22.4%], p-value = 0.848 and -0.32% [95% CI: -14.4–13.7%], p-value = 0.962), but slightly underperformed when compared to experts (10.9% [95% CI: -13.1–35.0%], p-value = 0.356 and 12.9% [95% CI: 0.15–25.7%], p-value = 0.048). The sub-analysis revealed significantly improved accuracy in the fields of Gynecology, Pediatrics, Orthopedic surgery, Plastic surgery, and Otolaryngology, while showing reduced accuracy for Neurology, Psychiatry, Rheumatology, and Endocrinology compared to that of General Medicine. No significant heterogeneity was observed based on the risk of bias. Conclusions Generative AI exhibits promising diagnostic capabilities, with accuracy varying significantly by model and medical specialty. Although they have not reached the reliability of expert physicians, the findings suggest that generative AI models have the potential to enhance healthcare delivery and medical education, provided they are integrated with caution and their limitations are well-understood. Key Points Question: What is the diagnostic accuracy of generative AI models and how does this accuracy compare to that of physicians? Findings: This meta-analysis found that generative AI models have a pooled accuracy of 56.9% (95% confidence interval: 51.0–62.7%). The accuracy of expert physicians exceeds that of AI in all specialties, however, some generative AI models are comparable to non-expert physicians. Meaning: The diagnostic performance of generative AI models suggests that they do not match the level of experienced physicians but that they may have potential applications in healthcare delivery and medical education.",['generative AI models'],"The study addresses the growing interest in improving medical diagnostics through advanced technologies, highlighting the need to evaluate the diagnostic performance of emerging tools compared to physicians. Despite the potential benefits for healthcare delivery, there has been limited comprehensive assessment of how these diagnostic approaches perform across various medical specialties and in comparison to expert clinicians. The primary aim of the study is to systematically review and compare the diagnostic accuracy of these emerging diagnostic tools with that of physicians across multiple medical specialties. The objective is to determine their overall diagnostic performance, identify areas of improved or reduced accuracy, and assess their potential role in enhancing healthcare delivery and medical education while acknowledging current limitations."
Medicine,A systematic review of artificial intelligence techniques for oral cancer detection,"Oral cancer is a form of cancer that develops in the tissue of an oral cavity. Detection at an early stage is necessary to prevent the mortality rate in cancer patients. Artificial intelligence (AI) techniques play a significant role in assisting with diagnosing oral cancer. The AI techniques provide better detection accuracy and help automate oral cancer detection. The study shows that AI has a wide range of algorithms and provides outcomes in the most precise manner possible. We provide an overview of different input types and apply an appropriate algorithm to detect oral cancer. We aim to provide an overview of various AI techniques that can be used to automate oral cancer detection and to analyze these techniques to improve the efficiency and accuracy of oral cancer screening. We provide a summary of various methods available for oral cancer detection. We cover different input image formats, their processing, and the need for segmentation and feature extraction. We further include a list of other conventional strategies. We focus on various AI techniques for detecting oral cancer, including deep learning, machine learning, fuzzy computing, data mining, and genetic algorithms, and evaluates their benefits and drawbacks. The larger part of the articles focused on deep learning (37%) methods, followed by machine learning (32%), genetic algorithms (12%), data mining techniques (10%), and fuzzy computing (9%) for oral cancer detection.","['deep learning', 'machine learning', 'genetic algorithms']","The research idea centers on the critical need for early detection of oral cancer to reduce mortality rates among patients, highlighting the challenges in accurately diagnosing this disease at an initial stage. The study addresses the importance of improving the efficiency and accuracy of oral cancer screening by exploring various approaches to assist in diagnosis. The primary objective of the study is to provide an overview of different methods available for oral cancer detection, including various input types and conventional strategies, and to analyze these approaches to enhance the effectiveness of oral cancer screening. The study aims to summarize and evaluate the benefits and drawbacks of multiple techniques used in detecting oral cancer to support better diagnostic outcomes."
Medicine,Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models,"Suicidal ideation detection is a vital research area that holds great potential for improving mental health support systems. However, the sensitivity surrounding suicide-related data poses challenges in accessing large-scale, annotated datasets necessary for training effective machine learning models. To address this limitation, we introduce an innovative strategy that leverages the capabilities of generative AI models, such as ChatGPT, Flan-T5, and Llama, to create synthetic data for suicidal ideation detection. Our data generation approach is grounded in social factors extracted from psychology literature and aims to ensure coverage of essential information related to suicidal ideation. In our study, we benchmarked against state-of-the-art NLP classification models, specifically, those centered around the BERT family structures. When trained on the real-world dataset, UMD, these conventional models tend to yield F1-scores ranging from 0.75 to 0.87. Our synthetic data-driven method, informed by social factors, offers consistent F1-scores of 0.82 for both models, suggesting that the richness of topics in synthetic data can bridge the performance gap across different model complexities. Most impressively, when we combined a mere 30% of the UMD dataset with our synthetic data, we witnessed a substantial increase in performance, achieving an F1-score of 0.88 on the UMD test set. Such results underscore the cost-effectiveness and potential of our approach in confronting major challenges in the field, such as data scarcity and the quest for diversity in data representation.","['generative AI models', 'Flan-T5', 'Llama']","The research idea centers on the critical need to improve the detection of suicidal ideation to enhance mental health support systems, while recognizing the challenges posed by the sensitivity of suicide-related data that limit access to large-scale, annotated datasets. This scarcity of comprehensive data hampers efforts to effectively identify individuals at risk and provide timely interventions. The primary objective of the study is to develop a strategy that addresses the limitation of data availability by generating synthetic data informed by social factors relevant to suicidal ideation, with the aim of improving the performance and diversity of datasets used for suicidal ideation detection. The study seeks to demonstrate that incorporating this synthetic data can enhance detection accuracy and offer a cost-effective solution to overcome challenges related to data scarcity and representation in this important area of mental health research."
Medicine,Artificial intelligence framework for heart disease classification from audio signals,"Abstract As cardiovascular disorders are prevalent, there is a growing demand for reliable and precise diagnostic methods within this domain. Audio signal-based heart disease detection is a promising area of research that leverages sound signals generated by the heart to identify and diagnose cardiovascular disorders. Machine learning (ML) and deep learning (DL) techniques are pivotal in classifying and identifying heart disease from audio signals. This study investigates ML and DL techniques to detect heart disease by analyzing noisy sound signals. This study employed two subsets of datasets from the PASCAL CHALLENGE having real heart audios. The research process and visually depict signals using spectrograms and Mel-Frequency Cepstral Coefficients (MFCCs). We employ data augmentation to improve the model’s performance by introducing synthetic noise to the heart sound signals. In addition, a feature ensembler is developed to integrate various audio feature extraction techniques. Several machine learning and deep learning classifiers are utilized for heart disease detection. Among the numerous models studied and previous study findings, the multilayer perceptron model performed best, with an accuracy rate of 95.65%. This study demonstrates the potential of this methodology in accurately detecting heart disease from sound signals. These findings present promising opportunities for enhancing medical diagnosis and patient care.","['machine learning (ML)', 'deep learning (DL)', 'multilayer perceptron model']","The study addresses the growing need for reliable and precise diagnostic methods for cardiovascular disorders, which are highly prevalent. It focuses on the potential of using heart-generated sound signals to identify and diagnose heart disease, highlighting the importance of accurate detection in improving patient outcomes. The primary aim of the study is to investigate the effectiveness of analyzing heart sound signals, including those with noise, to detect heart disease accurately. This research seeks to demonstrate the potential of this approach in enhancing medical diagnosis and patient care for cardiovascular conditions."
Medicine,Investigation on explainable machine learning models to predict chronic kidney diseases,"Chronic kidney disease (CKD) is a major worldwide health problem, affecting a large proportion of the world's population and leading to higher morbidity and death rates. The early stages of CKD sometimes present without visible symptoms, causing patients to be unaware. Early detection and treatments are critical in reducing complications and improving the overall quality of life for people afflicted. In this work, we investigate the use of an explainable artificial intelligence (XAI)-based strategy, leveraging clinical characteristics, to predict CKD. This study collected clinical data from 491 patients, comprising 56 with CKD and 435 without CKD, encompassing clinical, laboratory, and demographic variables. To develop the predictive model, five machine learning (ML) methods, namely logistic regression (LR), random forest (RF), decision tree (DT), Naïve Bayes (NB), and extreme gradient boosting (XGBoost), were employed. The optimal model was selected based on accuracy and area under the curve (AUC). Additionally, the SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable Model-agnostic Explanations) algorithms were utilized to demonstrate the influence of the features on the optimal model. Among the five models developed, the XGBoost model achieved the best performance with an AUC of 0.9689 and an accuracy of 93.29%. The analysis of feature importance revealed that creatinine, glycosylated hemoglobin type A1C (HgbA1C), and age were the three most influential features in the XGBoost model. The SHAP force analysis further illustrated the model's visualization of individualized CKD predictions. For further insights into individual predictions, we also utilized the LIME algorithm. This study presents an interpretable ML-based approach for the early prediction of CKD. The SHAP and LIME methods enhance the interpretability of ML models and help clinicians better understand the rationale behind the predicted outcomes more effectively.","['logistic regression (LR)', 'random forest (RF)', 'decision tree (DT)', 'Naïve Bayes (NB)', 'extreme gradient boosting (XGBoost)', 'SHAP (SHapley Additive exPlanations)', 'LIME (Local Interpretable Model-agnostic Explanations)']","Chronic kidney disease (CKD) is a major worldwide health problem that affects a large proportion of the global population and leads to increased morbidity and mortality. Early stages of CKD often present without visible symptoms, causing many patients to remain unaware of their condition. Early detection and treatment are essential to reduce complications and improve the quality of life for those affected. The primary aim of this study is to investigate clinical characteristics to enable early prediction of CKD, thereby facilitating timely intervention and better patient outcomes."
Medicine,Prostate cancer grading framework based on deep transfer learning and Aquila optimizer,"Abstract Prostate cancer is the one of the most dominant cancer among males. It represents one of the leading cancer death causes worldwide. Due to the current evolution of artificial intelligence in medical imaging, deep learning has been successfully applied in diseases diagnosis. However, most of the recent studies in prostate cancer classification suffers from either low accuracy or lack of data. Therefore, the present work introduces a hybrid framework for early and accurate classification and segmentation of prostate cancer using deep learning. The proposed framework consists of two stages, namely classification stage and segmentation stage. In the classification stage, 8 pretrained convolutional neural networks were fine-tuned using Aquila optimizer and used to classify patients of prostate cancer from normal ones. If the patient is diagnosed with prostate cancer, segmenting the cancerous spot from the overall image using U-Net can help in accurate diagnosis, and here comes the importance of the segmentation stage. The proposed framework is trained on 3 different datasets in order to generalize the framework. The best reported classification accuracies of the proposed framework are 88.91% using MobileNet for the “ISUP Grade-wise Prostate Cancer” dataset and 100% using MobileNet and ResNet152 for the “Transverse Plane Prostate Dataset” dataset with precisions 89.22% and 100%, respectively. U-Net model gives an average segmentation accuracy and AUC of 98.46% and 0.9778, respectively, using the “PANDA: Resized Train Data (512 × 512)” dataset. The results give an indicator of the acceptable performance of the proposed framework.","['pretrained convolutional neural networks', 'MobileNet', 'ResNet152', 'U-Net']","Prostate cancer is one of the most prevalent cancers among males and is a leading cause of cancer-related deaths worldwide. Accurate and early diagnosis of prostate cancer is crucial for effective treatment and improved patient outcomes. The study aims to develop a reliable approach for the early and precise classification and segmentation of prostate cancer to enhance diagnostic accuracy. Specifically, the primary objective is to classify patients with prostate cancer from normal individuals and to accurately identify and segment cancerous regions within medical images to support better diagnosis."
Medicine,Methodological insights into ChatGPT’s screening performance in systematic reviews,"Abstract Background The screening process for systematic reviews and meta-analyses in medical research is a labor-intensive and time-consuming task. While machine learning and deep learning have been applied to facilitate this process, these methods often require training data and user annotation. This study aims to assess the efficacy of ChatGPT, a large language model based on the Generative Pretrained Transformers (GPT) architecture, in automating the screening process for systematic reviews in radiology without the need for training data. Methods A prospective simulation study was conducted between May 2nd and 24th, 2023, comparing ChatGPT’s performance in screening abstracts against that of general physicians (GPs). A total of 1198 abstracts across three subfields of radiology were evaluated. Metrics such as sensitivity, specificity, positive and negative predictive values (PPV and NPV), workload saving, and others were employed. Statistical analyses included the Kappa coefficient for inter-rater agreement, ROC curve plotting, AUC calculation, and bootstrapping for p-values and confidence intervals. Results ChatGPT completed the screening process within an hour, while GPs took an average of 7–10 days. The AI model achieved a sensitivity of 95% and an NPV of 99%, slightly outperforming the GPs’ sensitive consensus (i.e., including records if at least one person includes them). It also exhibited remarkably low false negative counts and high workload savings, ranging from 40 to 83%. However, ChatGPT had lower specificity and PPV compared to human raters. The average Kappa agreement between ChatGPT and other raters was 0.27. Conclusions ChatGPT shows promise in automating the article screening phase of systematic reviews, achieving high sensitivity and workload savings. While not entirely replacing human expertise, it could serve as an efficient first-line screening tool, particularly in reducing the burden on human resources. Further studies are needed to fine-tune its capabilities and validate its utility across different medical subfields.","['machine learning', 'deep learning', 'Generative Pretrained Transformers (GPT) architecture']","The research idea addresses the challenge that the screening process for systematic reviews and meta-analyses in medical research is labor-intensive and time-consuming, particularly in the field of radiology. This process requires significant human effort to evaluate large volumes of abstracts, which can delay the synthesis of medical evidence. The study is motivated by the need to find more efficient ways to conduct this screening without compromising accuracy. The research objective is to assess the efficacy of an automated approach in performing the screening of abstracts for systematic reviews in radiology, specifically evaluating its sensitivity, specificity, predictive values, and potential to reduce workload compared to general physicians. The study aims to determine whether this approach can serve as an efficient first-line screening tool that maintains high sensitivity while significantly saving human resources during the article screening phase."
Medicine,Advancing Ligand Docking through Deep Learning: Challenges and Prospects in Virtual Screening,"ConspectusMolecular docking, also termed ligand docking (LD), is a pivotal element of structure-based virtual screening (SBVS) used to predict the binding conformations and affinities of protein–ligand complexes. Traditional LD methodologies rely on a search and scoring framework, utilizing heuristic algorithms to explore binding conformations and scoring functions to evaluate binding strengths. However, to meet the efficiency demands of SBVS, these algorithms and functions are often simplified, prioritizing speed over accuracy.The emergence of deep learning (DL) has exerted a profound impact on diverse fields, ranging from natural language processing to computer vision and drug discovery. DeepMind's AlphaFold2 has impressively exhibited its ability to accurately predict protein structures solely from amino acid sequences, highlighting the remarkable potential of DL in conformation prediction. This groundbreaking advancement circumvents the traditional search-scoring frameworks in LD, enhancing both accuracy and processing speed and thereby catalyzing a broader adoption of DL algorithms in binding pose prediction. Nevertheless, a consensus on certain aspects remains elusive.In this Account, we delineate the current status of employing DL to augment LD within the VS paradigm, highlighting our contributions to this domain. Furthermore, we discuss the challenges and future prospects, drawing insights from our scholarly investigations. Initially, we present an overview of VS and LD, followed by an introduction to DL paradigms, which deviate significantly from traditional search-scoring frameworks. Subsequently, we delve into the challenges associated with the development of DL-based LD (DLLD), encompassing evaluation metrics, application scenarios, and physical plausibility of the predicted conformations. In the evaluation of LD algorithms, it is essential to recognize the multifaceted nature of the metrics. While the accuracy of binding pose prediction, often measured by the success rate, is a pivotal aspect, the scoring/screening power and computational speed of these algorithms are equally important given the pivotal role of LD tools in VS. Regarding application scenarios, early methods focused on blind docking, where the binding site is unknown. However, recent studies suggest a shift toward identifying binding sites rather than solely predicting binding poses within these models. In contrast, LD with a known pocket in VS has been shown to be more practical. Physical plausibility poses another significant challenge. Although DLLD models often achieve higher success rates compared to traditional methods, they may generate poses with implausible local structures, such as incorrect bond angles or lengths, which are disadvantageous for postprocessing tasks like visualization. Finally, we discuss the future perspectives for DLLD, emphasizing the need to improve generalization ability, strike a balance between speed and accuracy, account for protein conformation flexibility, and enhance physical plausibility. Additionally, we delve into the comparison between generative and regression algorithms in this context, exploring their respective strengths and potential.","['deep learning (DL)', ""DeepMind's AlphaFold2"", 'regression algorithms']","The research idea centers on the critical role of molecular docking in structure-based virtual screening for predicting protein–ligand binding conformations and affinities, highlighting the limitations of traditional methods that prioritize speed over accuracy. There is a growing need to improve the accuracy and efficiency of binding pose prediction while addressing challenges such as physical plausibility and the practical application of docking when binding sites are known or unknown. The study’s primary objective is to evaluate and enhance the current approaches to molecular docking within virtual screening, focusing on improving prediction accuracy, balancing computational speed, and ensuring the physical plausibility of predicted conformations. Additionally, the research aims to explore future directions to better account for protein flexibility and improve the generalization of docking predictions in practical scenarios."
Medicine,The Sociodemographic Biases in Machine Learning Algorithms: A Biomedical Informatics Perspective,"Artificial intelligence models represented in machine learning algorithms are promising tools for risk assessment used to guide clinical and other health care decisions. Machine learning algorithms, however, may house biases that propagate stereotypes, inequities, and discrimination that contribute to socioeconomic health care disparities. The biases include those related to some sociodemographic characteristics such as race, ethnicity, gender, age, insurance, and socioeconomic status from the use of erroneous electronic health record data. Additionally, there is concern that training data and algorithmic biases in large language models pose potential drawbacks. These biases affect the lives and livelihoods of a significant percentage of the population in the United States and globally. The social and economic consequences of the associated backlash cannot be underestimated. Here, we outline some of the sociodemographic, training data, and algorithmic biases that undermine sound health care risk assessment and medical decision-making that should be addressed in the health care system. We present a perspective and overview of these biases by gender, race, ethnicity, age, historically marginalized communities, algorithmic bias, biased evaluations, implicit bias, selection/sampling bias, socioeconomic status biases, biased data distributions, cultural biases and insurance status bias, conformation bias, information bias and anchoring biases and make recommendations to improve large language model training data, including de-biasing techniques such as counterfactual role-reversed sentences during knowledge distillation, fine-tuning, prefix attachment at training time, the use of toxicity classifiers, retrieval augmented generation and algorithmic modification to mitigate the biases moving forward.","['knowledge distillation', 'fine-tuning', 'retrieval augmented generation']","The research idea centers on the concern that biases related to sociodemographic characteristics such as race, ethnicity, gender, age, insurance, and socioeconomic status, stemming from erroneous electronic health record data, undermine the accuracy and fairness of health care risk assessment and medical decision-making. These biases contribute to stereotypes, inequities, and discrimination that exacerbate socioeconomic health care disparities, affecting a significant portion of the population both in the United States and globally. The study highlights the social and economic consequences of these biases and the need to address them within the health care system. The primary objective of the study is to outline and provide an overview of various sociodemographic and systemic biases that compromise sound health care risk assessment and medical decision-making. It aims to raise awareness of these biases, including those related to gender, race, ethnicity, age, marginalized communities, and socioeconomic status, and to offer recommendations for mitigating their impact to improve equity in health care outcomes."
Medicine,AI-POWERED FRAUD DETECTION IN BANKING: SAFEGUARDING FINANCIAL TRANSACTIONS,"The banking industry's metamorphosis through digitalization has unquestionably revolutionized accessibility and convenience for customers worldwide. However, this paradigm shift has ushered in a new era of challenges, most notably in the realm of cybersecurity. Conventional rule-based fraud detection strategies have struggled to keep pace with the rapid evolution of cyber threats, prompting a surge of interest in more adaptive approaches like unsupervised learning. Furthermore, the COVID-19 pandemic has exacerbated the issue of bank fraud due to the widespread transition to online platforms and the proliferation of charitable funds, which present ripe opportunities for exploitation by cybercriminals. In response to these pressing concerns, this study delves into the realm of machine learning algorithms for the analysis and identification of fraudulent banking transactions. Notably, it contributes scientific novelty by developing models specifically tailored to this purpose and implementing innovative preprocessing techniques to enhance detection accuracy. Utilizing a diverse array of algorithms, including Random Forest, K-Nearest Neighbor (KNN), Naïve Bayes, Decision Trees, and Logistic Regression, the study showcases promising results. In particular, logistic regression and decision tree models exhibit impressive accuracy and Area Under the Curve (AUC) values of approximately 0.98, 0.97 and 0.95, 0.94, respectively. Given the pervasive nature of banking fraud in our digital society, the utilization of artificial intelligence algorithms for fraud detection stands as a critical and timely endeavor, promising enhanced security and trust in the financial ecosystem.","['unsupervised learning', 'Random Forest', 'K-Nearest Neighbor (KNN)', 'Naïve Bayes', 'Decision Trees', 'Logistic Regression']","The research idea addresses the increasing challenges posed by the rapid evolution of cyber threats in the banking industry, especially as digitalization has expanded accessibility and convenience for customers worldwide. The COVID-19 pandemic has further intensified the problem of bank fraud due to the widespread shift to online platforms and the increased flow of charitable funds, which have become targets for exploitation by criminals. The study is motivated by the need to improve the detection of fraudulent banking transactions in this changing landscape. The primary objective of the study is to develop and evaluate approaches specifically designed to identify fraudulent banking transactions with enhanced accuracy, aiming to contribute to improved security and trust within the financial ecosystem."
Medicine,"A comparative analysis of machine learning techniques for aboveground biomass estimation: A case study of the Western Ghats, India","Accurate assessment of aboveground biomass (AGB) in tropical forests, particularly within a biodiversity hotspot, is vital for sustainable resource management and the preservation of ecosystems. However, estimating AGB in tropical forests is complex due to the diverse and intricate nature of vegetation, necessitating the integration of data from multiple sources. To tackle this challenge, our study utilized seven machine learning algorithms to analyze various combination of multisource datasets. We developed seven models/scenarios that incorporated Sentinel-1, Sentinel-2 as well as environmental factors such as topography, soil and climate to identify key variables for accurate estimation of AGB. For optimal performance, hyperparameters of the algorithms were fine-tuned through 10-fold cross-validation and their accuracy were assessed using the testing dataset. We found that the integrated model of satellite datasets, topography, climate, and soil variables exhibited the highest accuracy, where ensemble stacking, that combined multiple MLAs, proved to be reliable and best suited for predicting AGB (mean absolute error-3.97 Mg 0.1 ha−1, root mean square error-5.67 Mg 0.1 ha−1, and coefficient of determination - 0.82). Notably, the top predictor variables included Sentinel-2 bands (near infrared and green), soil properties (pH and soil organic carbon), and topography (elevation). The study emphasizes the significance of incorporating environmental variables (specifically topography and soil properties) along with Sentinel datasets to improve the accuracy of AGB estimation. This approach has the potential for broader applications, specifically in regions where vegetation productivity is governed by diverse environmental conditions.",['ensemble stacking'],"The study addresses the challenge of accurately assessing aboveground biomass (AGB) in tropical forests, particularly within biodiversity hotspots, which is crucial for sustainable resource management and ecosystem preservation. Estimating AGB in these forests is complex due to the diverse and intricate nature of vegetation, requiring the integration of multiple environmental factors. The primary aim of the study is to improve the accuracy of AGB estimation by identifying key variables from satellite datasets combined with environmental factors such as topography, soil, and climate. The research seeks to determine the most effective combination of these variables to enhance the precision of biomass assessment in tropical forest ecosystems."
Medicine,Identifying top ten predictors of type 2 diabetes through machine learning analysis of UK Biobank data,"Abstract The study aimed to identify the most predictive factors for the development of type 2 diabetes. Using an XGboost classification model, we projected type 2 diabetes incidence over a 10-year horizon. We deliberately minimized the selection of baseline factors to fully exploit the rich dataset from the UK Biobank. The predictive value of features was assessed using shap values, with model performance evaluated via Receiver Operating Characteristic Area Under the Curve, sensitivity, and specificity. Data from the UK Biobank, encompassing a vast population with comprehensive demographic and health data, was employed. The study enrolled 450,000 participants aged 40–69, excluding those with pre-existing diabetes. Among 448,277 participants, 12,148 developed type 2 diabetes within a decade. HbA1c emerged as the foremost predictor, followed by BMI, waist circumference, blood glucose, family history of diabetes, gamma-glutamyl transferase, waist-hip ratio, HDL cholesterol, age, and urate. Our XGboost model achieved a Receiver Operating Characteristic Area Under the Curve of 0.9 for 10-year type 2 diabetes prediction, with a reduced 10-feature model achieving 0.88. Easily measurable biological factors surpassed traditional risk factors like diet, physical activity, and socioeconomic status in predicting type 2 diabetes. Furthermore, high prediction accuracy could be maintained using just the top 10 biological factors, with additional ones offering marginal improvements. These findings underscore the significance of biological markers in type 2 diabetes prediction.","['XGboost classification model', 'shap values']","The study addresses the need to identify the most predictive factors for the development of type 2 diabetes over a long-term period. It highlights the importance of understanding which baseline biological and health-related factors can effectively forecast the incidence of type 2 diabetes in a large population. The research aims to determine the primary predictors among various demographic and biological markers to improve the identification of individuals at risk. The primary objective of the study is to identify and evaluate the key factors that predict the development of type 2 diabetes within a 10-year horizon, focusing on easily measurable biological markers and their relative importance compared to traditional risk factors."
Medicine,Protocol for metadata and image collection at diabetic foot ulcer clinics: enabling research in wound analytics and deep learning,"Abstract Background The escalating impact of diabetes and its complications, including diabetic foot ulcers (DFUs), presents global challenges in quality of life, economics, and resources, affecting around half a billion people. DFU healing is hindered by hyperglycemia-related issues and diverse diabetes-related physiological changes, necessitating ongoing personalized care. Artificial intelligence and clinical research strive to address these challenges by facilitating early detection and efficient treatments despite resource constraints. This study establishes a standardized framework for DFU data collection, introducing a dedicated case report form, a comprehensive dataset named Zivot with patient population clinical feature breakdowns and a baseline for DFU detection using this dataset and a UNet architecture. Results Following this protocol, we created the Zivot dataset consisting of 269 patients with active DFUs, and about 3700 RGB images and corresponding thermal and depth maps for the DFUs. The effectiveness of collecting a consistent and clean dataset was demonstrated using a bounding box prediction deep learning network that was constructed with EfficientNet as the feature extractor and UNet architecture. The network was trained on the Zivot dataset, and the evaluation metrics showed promising values of 0.79 and 0.86 for F1-score and mAP segmentation metrics. Conclusions This work and the Zivot database offer a foundation for further exploration of holistic and multimodal approaches to DFU research.","['UNet architecture', 'EfficientNet']","The escalating impact of diabetes and its complications, including diabetic foot ulcers (DFUs), presents significant global challenges affecting quality of life, economic burden, and healthcare resources, with around half a billion people affected. Healing of DFUs is complicated by hyperglycemia-related issues and various diabetes-related physiological changes, which require ongoing personalized care to improve outcomes. The primary aim of this study is to establish a standardized framework for DFU data collection by introducing a dedicated case report form and creating a comprehensive dataset named Zivot, which includes clinical feature breakdowns of the patient population. This effort seeks to provide a foundational resource to support further research and improve understanding of DFU detection and management."
Medicine,BINDTI: A bi-directional Intention network for drug-target interaction identification based on attention mechanisms,"The identification of drug-target interactions (DTIs) is an essential step in drug discovery. In vitro experimental methods are expensive, laborious, and time-consuming. Deep learning has witnessed promising progress in DTI prediction. However, how to precisely represent drug and protein features is a major challenge for DTI prediction. Here, we developed an end-to-end DTI identification framework called BINDTI based on bi-directional Intention network. First, drug features are encoded with graph convolutional networks based on its 2D molecular graph obtained by its SMILES string. Next, protein features are encoded based on its amino acid sequence through a mixed model called ACmix, which integrates self-attention mechanism and convolution. Third, drug and target features are fused through bi-directional Intention network, which combines Intention and multi-head attention. Finally, unknown drug-target (DT) pairs are classified through multilayer perceptron based on the fused DT features. The results demonstrate that BINDTI greatly outperformed four baseline methods (i.e., CPI-GNN, TransfomerCPI, MolTrans, and IIFDTI) on the BindingDB, BioSNAP, DrugBank, and Human datasets. More importantly, it was more appropriate to predict new DTIs than the four baseline methods on imbalanced datasets. Ablation experimental results elucidated that both bi-directional Intention and ACmix could greatly advance DTI prediction. The fused feature visualization and case studies manifested that the predicted results by BINDTI were basically consistent with the true ones. We anticipate that the proposed BINDTI framework can find new low-cost drug candidates, improve drugs' virtual screening, and further facilitate drug repositioning as well as drug discovery. BINDTI is publicly available at <uri xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">https://github.com/plhhnu/BINDTI</uri> .","['graph convolutional networks', 'self-attention mechanism', 'convolution', 'multi-head attention', 'multilayer perceptron']","The identification of drug-target interactions (DTIs) is a crucial step in drug discovery, yet current experimental methods are expensive, laborious, and time-consuming. Accurately representing the features of drugs and proteins remains a significant challenge in improving the prediction of these interactions. The primary aim of this study is to develop a framework that can more precisely identify drug-target interactions to facilitate the discovery of new drug candidates. This framework seeks to improve virtual screening processes and support drug repositioning and overall drug discovery efforts by providing more accurate predictions of drug-target pairs."
Medicine,Prediction of Alzheimer's disease progression within 6 years using speech: A novel approach leveraging language models,"Abstract INTRODUCTION Identification of individuals with mild cognitive impairment (MCI) who are at risk of developing Alzheimer's disease (AD) is crucial for early intervention and selection of clinical trials. METHODS We applied natural language processing techniques along with machine learning methods to develop a method for automated prediction of progression to AD within 6 years using speech. The study design was evaluated on the neuropsychological test interviews of n = 166 participants from the Framingham Heart Study, comprising 90 progressive MCI and 76 stable MCI cases. RESULTS Our best models, which used features generated from speech data, as well as age, sex, and education level, achieved an accuracy of 78.5% and a sensitivity of 81.1% to predict MCI‐to‐AD progression within 6 years. DISCUSSION The proposed method offers a fully automated procedure, providing an opportunity to develop an inexpensive, broadly accessible, and easy‐to‐administer screening tool for MCI‐to‐AD progression prediction, facilitating development of remote assessment. Highlights Voice recordings from neuropsychological exams coupled with basic demographics can lead to strong predictive models of progression to dementia from mild cognitive impairment. The study leveraged AI methods for speech recognition and processed the resulting text using language models. The developed AI‐powered pipeline can lead to fully automated assessment that could enable remote and cost‐effective screening and prognosis for Alzehimer's disease.",['machine learning'],"The research idea centers on the importance of identifying individuals with mild cognitive impairment (MCI) who are at risk of progressing to Alzheimer's disease (AD), as early detection is crucial for timely intervention and appropriate selection for clinical trials. There is a need for accessible and cost-effective screening tools that can predict the progression from MCI to AD to improve patient outcomes and facilitate remote assessment. The primary objective of the study is to develop a method for predicting the progression to Alzheimer's disease within six years among individuals with mild cognitive impairment, using information derived from speech and basic demographic factors. This approach aims to provide an easy-to-administer and broadly accessible screening tool to support early diagnosis and monitoring of disease progression."
Medicine,Detecting COVID-19 in chest CT images based on several pre-trained models,"Abstract This paper explores the use of chest CT scans for early detection of COVID-19 and improved patient outcomes. The proposed method employs advanced techniques, including binary cross-entropy, transfer learning, and deep convolutional neural networks, to achieve accurate results. The COVIDx dataset, which contains 104,009 chest CT images from 1,489 patients, is used for a comprehensive analysis of the virus. A sample of 13,413 images from this dataset is categorised into two groups: 7,395 CT scans of individuals with confirmed COVID-19 and 6,018 images of normal cases. The study presents pre-trained transfer learning models such as ResNet (50), VGG (19), VGG (16), and Inception V3 to enhance the DCNN for classifying the input CT images. The binary cross-entropy metric is used to compare COVID-19 cases with normal cases based on predicted probabilities for each class. Stochastic Gradient Descent and Adam optimizers are employed to address overfitting issues. The study shows that the proposed pre-trained transfer learning models achieve accuracies of 99.07%, 98.70%, 98.55%, and 96.23%, respectively, in the validation set using the Adam optimizer. Therefore, the proposed work demonstrates the effectiveness of pre-trained transfer learning models in enhancing the accuracy of DCNNs for image classification. Furthermore, this paper provides valuable insights for the development of more accurate and efficient diagnostic tools for COVID-19.","['transfer learning', 'deep convolutional neural networks', 'pre-trained transfer learning models', 'ResNet (50)', 'VGG (19)', 'VGG (16)', 'Inception V3', 'Stochastic Gradient Descent optimizer', 'Adam optimizer']",The research idea centers on the importance of early detection of COVID-19 through chest CT scans to improve patient outcomes. Accurate identification of COVID-19 cases is critical for timely treatment and controlling the spread of the virus. The study addresses the challenge of distinguishing COVID-19 infections from normal cases using imaging techniques. The primary objective of the study is to enhance the accuracy of classifying chest CT images into COVID-19 positive and normal cases. This aims to provide more reliable diagnostic tools that can support healthcare professionals in the early and precise detection of COVID-19.
Medicine,A Novel Early Detection and Prevention of Coronary Heart Disease Framework Using Hybrid Deep Learning Model and Neural Fuzzy Inference System,"Diabetes is the ""mother of all diseases"" as it affects multiple organs of body of an individual in some way. Its timely detection and management are critically important. Otherwise, the long run, it can cause several complications in a diabetic. Heart disease is one of the major complications of diabetes.This work proposed an Optimal Scrutiny Boosted Graph Convolutional LSTM (O-SBGC-LSTM), SBGC-LSTM enhanced by Eurygaster Optimization Algorithm (EOA) to tune hyperparameters for early prevention and detection of diabetes disease. This work proposed an Optimal Scrutiny Boosted Graph Convolutional LSTM (O-SBGC-LSTM), SBGC-LSTM enhanced by Eurygaster Optimization Algorithm (EOA) to tune hyperparameters for early prevention and detection of diabetes disease. This method not only captures discriminative features in spatial configuration and temporal dynamics but also explore the co-occurrence relationship between spatial and temporal domains. This method also presents a temporal hierarchical architecture to increase temporal receptive fields of top SBGC-LSTM layer, which boosts the ability to learn high-level semantic representation and significantly reduces computation cost. The performance of O-SBGC-LSTM was found overall to be satisfactory, reaching >98% accuracy in most studies. In comparison with classic machine learning approaches, proposed hybrid DL was found to achieve better performance in almost all studies that reported such comparison outcomes. Furthermore, prevention is better than cure. Additionally, employed fuzzy based inference techniques to enhance the prevention procedure using suggestion table.",['fuzzy based inference techniques'],"The research idea centers on the critical importance of timely detection and management of diabetes, a disease that affects multiple organs and can lead to serious complications, including heart disease. Early prevention and detection are essential to reduce the long-term adverse effects associated with diabetes. The study’s primary objective is to develop an approach for the early prevention and detection of diabetes disease, aiming to improve the identification of discriminative features related to the condition and enhance the ability to learn meaningful representations that support better disease management. Additionally, the study seeks to improve prevention procedures by incorporating techniques that provide suggestions to aid in managing diabetes effectively."
Medicine,<scp>CerviFormer</scp>: A pap smear‐based cervical cancer classification method using cross‐attention and latent transformer,"Abstract Cervical cancer is one of the primary causes of death in women. It should be diagnosed early and treated according to the best medical advice, similar to other diseases, to ensure that its effects are as minimal as possible. Pap smear images are one of the most constructive ways for identifying this type of cancer. This study proposes a cross‐attention‐based Transfomer approach for the reliable classification of cervical cancer in pap smear images. In this study, we propose the CerviFormer‐a model that depends on the Transformers and thereby requires minimal architectural assumptions about the size of the input data. The model uses a cross‐attention technique to repeatedly consolidate the input data into a compact latent Transformer module, which enables it to manage very large‐scale inputs. We evaluated our model on two publicly available pap smear datasets. For 3‐state classification on the Sipakmed data, the model achieved an accuracy of 96.67%. For 2‐state classification on the Herlev data, the model achieved an accuracy of 94.57%. Experimental results on two publicly accessible datasets demonstrate that the proposed method achieves competitive results when compared to contemporary approaches. The proposed method brings forth a comprehensive classification model to detect cervical cancer in pap smear images. This may aid medical professionals in providing better cervical cancer treatment, consequently, enhancing the overall effectiveness of the entire testing process.","['cross-attention-based Transformer', 'Transformers']","Cervical cancer is a leading cause of death among women and requires early diagnosis and appropriate treatment to minimize its impact. Pap smear images serve as a crucial tool for identifying cervical cancer, highlighting the need for reliable and accurate classification methods to support medical decision-making. The primary aim of this study is to develop a comprehensive classification approach for detecting cervical cancer in pap smear images. This approach seeks to improve the accuracy and reliability of cervical cancer diagnosis, thereby assisting healthcare professionals in delivering better treatment and enhancing the overall effectiveness of the screening process."
Medicine,Unified deep learning models for enhanced lung cancer prediction with ResNet-50–101 and EfficientNet-B3 using DICOM images,"Abstract Significant advancements in machine learning algorithms have the potential to aid in the early detection and prevention of cancer, a devastating disease. However, traditional research methods face obstacles, and the amount of cancer-related information is rapidly expanding. The authors have developed a helpful support system using three distinct deep-learning models, ResNet-50, EfficientNet-B3, and ResNet-101, along with transfer learning, to predict lung cancer, thereby contributing to health and reducing the mortality rate associated with this condition. This offer aims to address the issue effectively. Using a dataset of 1,000 DICOM lung cancer images from the LIDC-IDRI repository, each image is classified into four different categories. Although deep learning is still making progress in its ability to analyze and understand cancer data, this research marks a significant step forward in the fight against cancer, promoting better health outcomes and potentially lowering the mortality rate. The Fusion Model, like all other models, achieved 100% precision in classifying Squamous Cells. The Fusion Model and ResNet-50 achieved a precision of 90%, closely followed by EfficientNet-B3 and ResNet-101 with slightly lower precision. To prevent overfitting and improve data collection and planning, the authors implemented a data extension strategy. The relationship between acquiring knowledge and reaching specific scores was also connected to advancing and addressing the issue of imprecise accuracy, ultimately contributing to advancements in health and a reduction in the mortality rate associated with lung cancer.","['ResNet-50', 'EfficientNet-B3', 'ResNet-101', 'transfer learning']","The research idea centers on the urgent need for improved early detection and prevention of lung cancer, a disease with a high mortality rate, amid the challenges posed by rapidly expanding cancer-related information and limitations of traditional research methods. The study addresses the critical problem of accurately classifying lung cancer types to contribute to better health outcomes and reduce mortality associated with this condition. The primary objective of the study is to develop an effective approach for predicting lung cancer by classifying lung cancer images into distinct categories, thereby enhancing diagnostic precision. This aims to promote advancements in health and contribute to lowering the mortality rate linked to lung cancer."
Medicine,More Robots are Coming: Large Multimodal Models (ChatGPT) can Solve Visually Diverse Images of Parsons Problems,"Large language models are reshaping computing education. Based on recent research, these models explain code better than students, answer multiple choice questions at or above the class average, and generate code that can pass automated tests in introductory courses. In response to these capabilities, instructors have quickly adjusted their courses and assessment methods to align with shifting learning goals and the increased risk of academic integrity issues. While some scholars have advocated for the integration of visual problems as a safeguard against the capabilities of language models, new multimodal models now have vision and language capabilities that may allow them to analyze and solve visual problems. In this paper, we compare the large multimodal model (LMMs) GPT-4V with Bard, an LLM that uses Google Lens for text recognition. We find that LMMs, which have learned both pixel features (from images) and text features (from prompts) in the same embedding space, performed substantially better than Bard which uses a piecemeal approach. With a specific focus on Parsons problems presented across diverse visual representations, our results show that GPT-4V solved 96.7% these visual problems, struggling minimally with a single Parsons problem. Conversely, Bard performed poorly by only solving 69.2% of problems, struggling with common issues like hallucinations and refusals. These findings suggest that merely transitioning to visual programming problems might not be a panacea to issues of academic integrity in the generative AI era.",['large multimodal models (LMMs)'],"The study addresses the challenge of maintaining academic integrity in computing education amid the emergence of advanced language models capable of understanding and solving visual programming problems. As instructors adapt their courses and assessments to counteract the increased risk of academic dishonesty, there is a concern that traditional safeguards, such as using visual problems, may no longer be effective. The research aims to evaluate the effectiveness of large multimodal models in solving visual programming problems, specifically Parsons problems, to determine whether transitioning to visual problem formats can mitigate academic integrity issues. The primary objective is to compare the performance of different multimodal models on these visual problems to assess their capability and the implications for educational assessment strategies."
Medicine,The Utility of AI in Writing a Scientific Review Article on the Impacts of COVID-19 on Musculoskeletal Health,"Abstract Purpose of Review There were two primary purposes to our reviews. First, to provide an update to the scientific community about the impacts of COVID-19 on musculoskeletal health. Second, was to determine the value of using a large language model, ChatGPT 4.0, in the process of writing a scientific review article. To accomplish these objectives, we originally set out to write three review articles on the topic using different methods to produce the initial drafts of the review articles. The first review article was written in the traditional manner by humans, the second was to be written exclusively using ChatGPT (AI-only or AIO), and the third approach was to input the outline and references selected by humans from approach 1 into ChatGPT, using the AI to assist in completing the writing (AI-assisted or AIA). All review articles were extensively fact-checked and edited by all co-authors leading to the final drafts of the manuscripts, which were significantly different from the initial drafts. Recent Findings Unfortunately, during this process, it became clear that approach 2 was not feasible for a very recent topic like COVID-19 as at the time, ChatGPT 4.0 had a cutoff date of September 2021 and all articles published after this date had to be provided to ChatGPT, making approaches 2 and 3 virtually identical. Therefore, only two approaches and two review articles were written (human and AI-assisted). Here we found that the human-only approach took less time to complete than the AI-assisted approach. This was largely due to the number of hours required to fact-check and edit the AI-assisted manuscript. Of note, the AI-assisted approach resulted in inaccurate attributions of references (about 20%) and had a higher similarity index suggesting an increased risk of plagiarism. Summary The main aim of this project was to determine whether the use of AI could improve the process of writing a scientific review article. Based on our experience, with the current state of technology, it would not be advised to solely use AI to write a scientific review article, especially on a recent topic.","['large language model, ChatGPT 4.0']","The research idea centers on addressing the impacts of COVID-19 on musculoskeletal health and exploring the effectiveness of different approaches to writing scientific review articles on this recent and evolving topic. The study highlights challenges in producing accurate and reliable scientific reviews, especially given the rapidly changing nature of COVID-19-related research. The primary objective of the study was to evaluate whether the use of an AI-assisted approach could improve the process of writing a scientific review article compared to the traditional human-only method. The study aimed to assess the feasibility, accuracy, and efficiency of these approaches in producing high-quality scientific reviews on the musculoskeletal effects of COVID-19."
Medicine,Machine learning model (RG-DMML) and ensemble algorithm for prediction of students’ retention and graduation in education,"Automated prediction of students' retention and graduation in education using advanced analytical methods such as artificial intelligence (AI), has recently attracted the attention of educators, both in theory and in practice. Whereas invaluable insights and theories for measuring and testing the topic have been proposed, most of the existing methods do not technically highlight the non-trivial factors behind the renowned challenges and attrition. To this effect, by making use of two categories of data collected in a higher education setting about students (i) retention (n = 52262) and (ii) graduation (n = 53639); this study proposes a machine learning model - RG-DMML (retention and graduation data mining and machine learning) and ensemble algorithm for prediction of students' retention and graduation status in education. This was done by training and testing key features that are technically deemed suitable for measuring the constructs (retention and graduation), such as (i) the Average grade of the previous high school, and (ii) the Entry/admission score. The proposed model (RG-DMML) is designed based on the cross industry standard process for data mining (CRISP-DM) methodology, implemented using supervised machine learning technique such as K-Nearest Neighbor (KNN), and validated using the k-fold cross-validation method. The results show that the executed model and algorithm based on the Bagging method and 10-fold cross-validation are efficient and effective for predicting the student's retention and graduation status, with Precision (retention = 0.909, graduation = 0.822), Recall (retention = 1.000, graduation = 0.957), Accuracy (retention = 0.909, graduation = 0.817), F1-Score (retention = 0.952, graduation = 0.885) showing significant high accuracy levels or performance rate, and low Error-rate (retention = 0.090, graduation = 0.182), respectively. In addition, by considering the individual features selected through the Wrapper method in predicting the outputs, the proposed model proved more effective for predicting the students' retention status in comparison to the graduation data. The implications of the models' output and factors that impact the effective prediction or identification of at-risk students, e.g., for timely intervention, counselling, decision-making, and sustainable educational practice are empirically discussed in the study.","['ensemble algorithm', 'supervised machine learning technique', 'K-Nearest Neighbor (KNN)', 'Wrapper method']","The research idea addresses the challenge of understanding and predicting student retention and graduation in higher education, highlighting that existing approaches often fail to reveal the complex factors contributing to these issues. There is a need to identify key features that influence students' likelihood to continue their studies or successfully graduate, which is critical for timely intervention and support. The study aims to improve insights into the factors behind student attrition and graduation outcomes to enhance educational practices and decision-making. The primary objective of the study is to predict students' retention and graduation status by utilizing key academic indicators such as average high school grades and admission scores. The study seeks to evaluate the effectiveness of these indicators in identifying students at risk of dropping out or not graduating, thereby supporting timely counseling and sustainable educational strategies."
Medicine,Deep learning algorithm-based multimodal MRI radiomics and pathomics data improve prediction of bone metastases in primary prostate cancer,"Abstract Purpose Bone metastasis is a significant contributor to morbidity and mortality in advanced prostate cancer, and early diagnosis is challenging due to its insidious onset. The use of machine learning to obtain prognostic information from pathological images has been highlighted. However, there is a limited understanding of the potential of early prediction of bone metastasis through the feature combination method from various sources. This study presents a method of integrating multimodal data to enhance the feasibility of early diagnosis of bone metastasis in prostate cancer. Methods and materials Overall, 211 patients diagnosed with prostate cancer (PCa) at Gansu Provincial Hospital between January 2017 and February 2023 were included in this study. The patients were randomized (8:2) into a training group ( n = 169) and a validation group ( n = 42). The region of interest (ROI) were segmented from the three magnetic resonance imaging (MRI) sequences (T2WI, DWI, and ADC), and pathological features were extracted from tissue sections (hematoxylin and eosin [H&amp;E] staining, 10 × 20). A deep learning (DL) model using ResNet 50 was employed to extract deep transfer learning (DTL) features. The least absolute shrinkage and selection operator (LASSO) regression method was utilized for feature selection, feature construction, and reducing feature dimensions. Different machine learning classifiers were used to build predictive models. The performance of the models was evaluated using receiver operating characteristic curves. The net clinical benefit was assessed using decision curve analysis (DCA). The goodness of fit was evaluated using calibration curves. A joint model nomogram was eventually developed by combining clinically independent risk factors. Results The best prediction models based on DTL and pathomics features showed area under the curve (AUC) values of 0.89 (95% confidence interval [CI], 0.799–0.989) and 0.85 (95% CI, 0.714–0.989), respectively. The AUC for the best prediction model based on radiomics features and combining radiomics features, DTL features, and pathomics features were 0.86 (95% CI, 0.735–0.979) and 0.93 (95% CI, 0.854–1.000), respectively. Based on DCA and calibration curves, the model demonstrated good net clinical benefit and fit. Conclusion Multimodal radiomics and pathomics serve as valuable predictors of the risk of bone metastases in patients with primary PCa.","['deep learning (DL) model using ResNet 50', 'deep transfer learning (DTL) features', 'least absolute shrinkage and selection operator (LASSO) regression method']","The research idea addresses the significant challenge of early diagnosis of bone metastasis in advanced prostate cancer, which contributes greatly to patient morbidity and mortality due to its insidious onset. There is a limited understanding of how combining features from various sources can improve early prediction of bone metastasis. The study is motivated by the need to enhance the feasibility of early diagnosis by integrating multiple types of clinical and pathological information. The primary objective of the study is to develop and evaluate a method that integrates multimodal data to improve the early diagnosis of bone metastasis in patients with prostate cancer. This approach aims to identify valuable predictors of bone metastasis risk by combining different clinical and pathological features to support better prognostic assessment."
Medicine,Explainable hybrid vision transformers and convolutional network for multimodal glioma segmentation in brain MRI,"Abstract Accurate localization of gliomas, the most common malignant primary brain cancer, and its different sub-region from multimodal magnetic resonance imaging (MRI) volumes are highly important for interventional procedures. Recently, deep learning models have been applied widely to assist automatic lesion segmentation tasks for neurosurgical interventions. However, these models are often complex and represented as “black box” models which limit their applicability in clinical practice. This article introduces new hybrid vision Transformers and convolutional neural networks for accurate and robust glioma segmentation in Brain MRI scans. Our proposed method, TransXAI, provides surgeon-understandable heatmaps to make the neural networks transparent. TransXAI employs a post-hoc explanation technique that provides visual interpretation after the brain tumor localization is made without any network architecture modifications or accuracy tradeoffs. Our experimental findings showed that TransXAI achieves competitive performance in extracting both local and global contexts in addition to generating explainable saliency maps to help understand the prediction of the deep network. Further, visualization maps are obtained to realize the flow of information in the internal layers of the encoder-decoder network and understand the contribution of MRI modalities in the final prediction. The explainability process could provide medical professionals with additional information about the tumor segmentation results and therefore aid in understanding how the deep learning model is capable of processing MRI data successfully. Thus, it enables the physicians’ trust in such deep learning systems towards applying them clinically. To facilitate TransXAI model development and results reproducibility, we will share the source code and the pre-trained models after acceptance at https://github.com/razeineldin/TransXAI .","['vision Transformers', 'convolutional neural networks', 'post-hoc explanation technique', 'encoder-decoder network']","The research idea centers on the critical need for accurate localization and segmentation of gliomas, the most common malignant primary brain tumors, and their sub-regions from multimodal MRI scans to support neurosurgical interventions. Precise identification of tumor boundaries is essential for effective interventional procedures, yet current approaches often lack transparency, limiting their clinical applicability. The study addresses the challenge of providing clear and interpretable tumor segmentation results that can be trusted and understood by medical professionals. The primary objective of the study is to develop a method for accurate and robust glioma segmentation in brain MRI scans that also offers surgeon-understandable visual explanations of the tumor localization. This approach aims to enhance the interpretability of segmentation results, thereby aiding physicians in understanding and trusting the tumor delineation process to support clinical decision-making."
Medicine,Prediction of Effectiveness and Toxicities of Immune Checkpoint Inhibitors Using Real-World Patient Data,"PURPOSE Although immune checkpoint inhibitors (ICIs) have improved outcomes in certain patients with cancer, they can also cause life-threatening immunotoxicities. Predicting immunotoxicity risks alongside response could provide a personalized risk-benefit profile, inform therapeutic decision making, and improve clinical trial cohort selection. We aimed to build a machine learning (ML) framework using routine electronic health record (EHR) data to predict hepatitis, colitis, pneumonitis, and 1-year overall survival. METHODS Real-world EHR data of more than 2,200 patients treated with ICI through December 31, 2018, were used to develop predictive models. Using a prediction time point of ICI initiation, a 1-year prediction time window was applied to create binary labels for the four outcomes for each patient. Feature engineering involved aggregating laboratory measurements over appropriate time windows (60-365 days). Patients were randomly partitioned into training (80%) and test (20%) sets. Random forest classifiers were developed using a rigorous model development framework. RESULTS The patient cohort had a median age of 63 years and was 61.8% male. Patients predominantly had melanoma (37.8%), lung cancer (27.3%), or genitourinary cancer (16.4%). They were treated with PD-1 (60.4%), PD-L1 (9.0%), and CTLA-4 (19.7%) ICIs. Our models demonstrate reasonably strong performance, with AUCs of 0.739, 0.729, 0.755, and 0.752 for the pneumonitis, hepatitis, colitis, and 1-year overall survival models, respectively. Each model relies on an outcome-specific feature set, though some features are shared among models. CONCLUSION To our knowledge, this is the first ML solution that assesses individual ICI risk-benefit profiles based predominantly on routine structured EHR data. As such, use of our ML solution will not require additional data collection or documentation in the clinic.",['random forest classifiers'],"The study addresses the challenge that, while immune checkpoint inhibitors (ICIs) have improved outcomes for certain cancer patients, they can also cause severe and potentially life-threatening immunotoxicities. There is a need to predict the risks of these immunotoxicities alongside treatment response to enable personalized risk-benefit assessments, guide therapeutic decision-making, and improve the selection of patients for clinical trials. The primary aim of the study is to develop a method to predict the occurrence of hepatitis, colitis, pneumonitis, and 1-year overall survival in patients treated with ICIs, using routinely collected clinical information. This approach seeks to provide individualized risk-benefit profiles without requiring additional clinical data collection."
Medicine,NSGA-II-DL: Metaheuristic Optimal Feature Selection With Deep Learning Framework for HER2 Classification in Breast Cancer,"Immunohistochemistry (IHC) slides are graded for breast cancer based on visual markers and morphological characteristics of stained membrane regions. The usage of whole slide images (WSIs) from histology in digital pathology algorithms for computer-assisted evaluations has increased recently. Human epidermal growth factor receptor 2 (HER2)-stained microscopic images are challenging, time-consuming, and error-prone to evaluate manually. This is due to different staining, overlapped regions, and huge, non-homogeneous slides. Additionally, the classification of HER2 images by the selection of fundamental features must be used to capture the difficult elements of the images, such as the irregular cell structure and the coloring of the tissue of the cells. To solve the above problems, a transfer learning model-based, trainable metaheuristic method for choosing the best features is suggested in this paper. Moreover, the suggested model is efficient in reducing model complexity and computational costs as well as avoiding overfitting. The four main components of the proposed cascaded design are: (a) converting WSIs to tiled images and enhancing contrast with fast local Laplacian filtering (FlLpF); (b) extracting features with a ResNet50 CNN technique based on transfer learning; (c) selecting the most informative features with the help of a non-dominated sorting genetic algorithm (NSGA-II) optimizer; and (d) using a support vector machine (SVM) to classify HER2 scores. Results from the HER2SC and HER2GAN datasets show that the suggested model is superior to other methods already in use, with 94.4% accuracy, 93.71% precision, 98.07% specificity, 93.83% sensitivity, and a 93.71% F1-score for the HER2SC dataset being achieved.","['transfer learning', 'ResNet50 CNN', 'non-dominated sorting genetic algorithm (NSGA-II)', 'support vector machine (SVM)']","The research addresses the challenge of accurately grading breast cancer using immunohistochemistry slides stained for Human epidermal growth factor receptor 2 (HER2). Manual evaluation of these microscopic images is difficult, time-consuming, and prone to errors due to variations in staining, overlapping regions, and the large, heterogeneous nature of the slides. Additionally, the irregular cell structures and tissue coloring complicate the classification of HER2 images, necessitating effective selection of fundamental features to capture these complexities. The primary objective of the study is to improve the classification of HER2-stained microscopic images by developing a method that enhances feature selection to better capture the difficult elements of the images, thereby facilitating more accurate and reliable HER2 scoring for breast cancer diagnosis."
Medicine,Generalizability of machine learning in predicting antimicrobial resistance in E. coli: a multi-country case study in Africa,"Abstract Background Antimicrobial resistance (AMR) remains a significant global health threat particularly impacting low- and middle-income countries (LMICs). These regions often grapple with limited healthcare resources and access to advanced diagnostic tools. Consequently, there is a pressing need for innovative approaches that can enhance AMR surveillance and management. Machine learning (ML) though underutilized in these settings, presents a promising avenue. This study leverages ML models trained on whole-genome sequencing data from England, where such data is more readily available, to predict AMR in E . coli , targeting key antibiotics such as ciprofloxacin, ampicillin, and cefotaxime. A crucial part of our work involved the validation of these models using an independent dataset from Africa, specifically from Uganda, Nigeria, and Tanzania, to ascertain their applicability and effectiveness in LMICs. Results Model performance varied across antibiotics. The Support Vector Machine excelled in predicting ciprofloxacin resistance (87% accuracy, F1 Score: 0.57), Light Gradient Boosting Machine for cefotaxime (92% accuracy, F1 Score: 0.42), and Gradient Boosting for ampicillin (58% accuracy, F1 Score: 0.66). In validation with data from Africa, Logistic Regression showed high accuracy for ampicillin (94%, F1 Score: 0.97), while Random Forest and Light Gradient Boosting Machine were effective for ciprofloxacin (50% accuracy, F1 Score: 0.56) and cefotaxime (45% accuracy, F1 Score:0.54), respectively. Key mutations associated with AMR were identified for these antibiotics. Conclusion As the threat of AMR continues to rise, the successful application of these models, particularly on genomic datasets from LMICs, signals a promising avenue for improving AMR prediction to support large AMR surveillance programs. This work thus not only expands our current understanding of the genetic underpinnings of AMR but also provides a robust methodological framework that can guide future research and applications in the fight against AMR.","['Support Vector Machine', 'Light Gradient Boosting Machine', 'Gradient Boosting', 'Logistic Regression', 'Random Forest']","The research idea centers on addressing the significant global health threat posed by antimicrobial resistance (AMR), which disproportionately affects low- and middle-income countries (LMICs) that often face limited healthcare resources and lack access to advanced diagnostic tools. There is a pressing need for innovative approaches to enhance AMR surveillance and management in these regions. The study aims to improve the prediction of AMR in Escherichia coli, focusing on key antibiotics such as ciprofloxacin, ampicillin, and cefotaxime, by leveraging genomic data. The primary objective of the study is to evaluate the applicability and effectiveness of predictive approaches trained on genomic data from England when validated with independent datasets from African countries including Uganda, Nigeria, and Tanzania, thereby supporting large AMR surveillance programs and expanding understanding of the genetic factors underlying AMR."
Medicine,Accurate and interpretable drug-drug interaction prediction enabled by knowledge subgraph learning,"Abstract Background Discovering potential drug-drug interactions (DDIs) is a long-standing challenge in clinical treatments and drug developments. Recently, deep learning techniques have been developed for DDI prediction. However, they generally require a huge number of samples, while known DDIs are rare. Methods In this work, we present KnowDDI, a graph neural network-based method that addresses the above challenge. KnowDDI enhances drug representations by adaptively leveraging rich neighborhood information from large biomedical knowledge graphs. Then, it learns a knowledge subgraph for each drug-pair to interpret the predicted DDI, where each of the edges is associated with a connection strength indicating the importance of a known DDI or resembling strength between a drug-pair whose connection is unknown. Thus, the lack of DDIs is implicitly compensated by the enriched drug representations and propagated drug similarities. Results Here we show the evaluation results of KnowDDI on two benchmark DDI datasets. Results show that KnowDDI obtains the state-of-the-art prediction performance with better interpretability. We also find that KnowDDI suffers less than existing works given a sparser knowledge graph. This indicates that the propagated drug similarities play a more important role in compensating for the lack of DDIs when the drug representations are less enriched. Conclusions KnowDDI nicely combines the efficiency of deep learning techniques and the rich prior knowledge in biomedical knowledge graphs. As an original open-source tool, KnowDDI can help detect possible interactions in a broad range of relevant interaction prediction tasks, such as protein-protein interactions, drug-target interactions and disease-gene interactions, eventually promoting the development of biomedicine and healthcare.",['graph neural network-based method'],"The research idea addresses the ongoing challenge in clinical treatments and drug development of discovering potential drug-drug interactions (DDIs), which are rare and difficult to identify. This scarcity of known DDIs limits the ability to effectively predict harmful or beneficial interactions between drugs, posing risks to patient safety and complicating drug development processes. The study aims to overcome these limitations by improving the understanding and identification of DDIs through enhanced drug representation and interpretation of interactions. The primary objective of the study is to develop a method that can accurately predict potential DDIs despite the limited availability of known interaction data, thereby facilitating the detection of possible drug interactions and supporting safer and more effective clinical treatments and drug development."
Medicine,Artificial intelligence–based assessment of built environment from Google Street View and coronary artery disease prevalence,"Abstract Background and Aims Built environment plays an important role in the development of cardiovascular disease. Tools to evaluate the built environment using machine vision and informatic approaches have been limited. This study aimed to investigate the association between machine vision–based built environment and prevalence of cardiometabolic disease in US cities. Methods This cross-sectional study used features extracted from Google Street View (GSV) images to measure the built environment and link them with prevalence of coronary heart disease (CHD). Convolutional neural networks, linear mixed-effects models, and activation maps were utilized to predict health outcomes and identify feature associations with CHD at the census tract level. The study obtained 0.53 million GSV images covering 789 census tracts in seven US cities (Cleveland, OH; Fremont, CA; Kansas City, MO; Detroit, MI; Bellevue, WA; Brownsville, TX; and Denver, CO). Results Built environment features extracted from GSV using deep learning predicted 63% of the census tract variation in CHD prevalence. The addition of GSV features improved a model that only included census tract-level age, sex, race, income, and education or composite indices of social determinant of health. Activation maps from the features revealed a set of neighbourhood features represented by buildings and roads associated with CHD prevalence. Conclusions In this cross-sectional study, the prevalence of CHD was associated with built environment factors derived from GSV through deep learning analysis, independent of census tract demographics. Machine vision–enabled assessment of the built environment could potentially offer a more precise approach to identify at-risk neighbourhoods, thereby providing an efficient avenue to address and reduce cardiovascular health disparities in urban environments.","['convolutional neural networks', 'activation maps']","The research idea centers on the significant role that the built environment plays in the development of cardiovascular disease, particularly coronary heart disease (CHD). Despite its importance, there have been limited tools available to effectively evaluate the built environment in relation to cardiometabolic health outcomes. This study addresses the need to better understand how features of the built environment in urban areas are associated with the prevalence of CHD. The primary objective of the study is to investigate the association between characteristics of the built environment and the prevalence of cardiometabolic disease, specifically CHD, across multiple US cities. The study aims to identify neighborhood features linked to CHD prevalence at the census tract level, independent of demographic factors, to provide insights that could help identify at-risk communities and reduce cardiovascular health disparities in urban settings."
Medicine,Urban morphology clustering analysis to identify heat-prone neighbourhoods in cities,"Exposure to heat is a major health concern to urban populations. Cities aim to reduce outdoor thermal stress by adapting the built environment, but the spatial heterogeneity within cities makes it difficult to establish universal mitigation strategies. We present a methodology that identifies the hottest neighbourhoods in a city and links them to underlying patterns in urban form and function, to derive heat mitigation measures for individual neighbourhoods according to their characteristics, mitigation potential, and average surface temperature. The method applies k-means clustering and is applicable to any city using available datasets on surface cover and building morphology, as well as globally available satellite measurements of surface temperatures. Here, we present a heat-mitigation analysis for the city of Zurich. The clustering differentiates seven neighbourhood types, including two types of residential areas, modern neighbourhoods with high-rise buildings, historical districts, and industrial zones. The hottest temperatures are in neighbourhoods with extensive impervious ground cover such as railway tracks and airport parking. Surface temperatures strongly correlate with impervious surface cover and vegetation cover for all neighbourhoods, with building cover only for non-industrial built neighbourhoods, and with sky-view factor for all neighbourhoods except those with large vegetation cover. Historical, modern, and industrial neighbourhoods are particular heat-prone, and increasing vegetation for evaporative cooling is a suggested mitigation strategy for all. Modern and industrial areas could benefit from shading through increase of tree cover, while historical centres may adapt vertical greening as suitable heat mitigation strategy.",['k-means clustering'],The research idea addresses the significant health concern posed by exposure to heat in urban populations and the challenge cities face in reducing outdoor thermal stress due to spatial heterogeneity within urban environments. It highlights the difficulty in establishing universal heat mitigation strategies because different neighborhoods exhibit varying characteristics that influence their thermal conditions. The study focuses on identifying the hottest neighborhoods and understanding how urban form and function contribute to heat exposure in order to develop targeted mitigation measures. The research objective is to analyze the city of Zurich by categorizing neighborhoods based on their surface cover and building morphology to determine heat-prone areas and propose specific heat mitigation strategies tailored to each neighborhood type. The study aims to link surface temperature patterns with urban characteristics to suggest appropriate interventions such as increasing vegetation and shading to reduce heat stress in different urban settings.
Medicine,Cardiac Arrhythmia Classification Using Advanced Deep Learning Techniques on Digitized ECG Datasets,"ECG classification or heartbeat classification is an extremely valuable tool in cardiology. Deep learning-based techniques for the analysis of ECG signals assist human experts in the timely diagnosis of cardiac diseases and help save precious lives. This research aims at digitizing a dataset of images of ECG records into time series signals and then applying deep learning (DL) techniques on the digitized dataset. State-of-the-art DL techniques are proposed for the classification of the ECG signals into different cardiac classes. Multiple DL models, including a convolutional neural network (CNN), a long short-term memory (LSTM) network, and a self-supervised learning (SSL)-based model using autoencoders are explored and compared in this study. The models are trained on the dataset generated from ECG plots of patients from various healthcare institutes in Pakistan. First, the ECG images are digitized, segmenting the lead II heartbeats, and then the digitized signals are passed to the proposed deep learning models for classification. Among the different DL models used in this study, the proposed CNN model achieves the highest accuracy of ∼92%. The proposed model is highly accurate and provides fast inference for real-time and direct monitoring of ECG signals that are captured from the electrodes (sensors) placed on different parts of the body. Using the digitized form of ECG signals instead of images for the classification of cardiac arrhythmia allows cardiologists to utilize DL models directly on ECG signals from an ECG machine for the real-time and accurate monitoring of ECGs.","['convolutional neural network (CNN)', 'long short-term memory (LSTM) network', 'self-supervised learning (SSL)-based model using autoencoders']","The study addresses the critical need for accurate and timely classification of ECG signals to assist in the diagnosis of cardiac diseases, which is essential for saving lives in cardiology. It focuses on improving the interpretation of ECG records by converting image-based ECG data into a format that can be more effectively utilized for cardiac assessment. The primary aim of the research is to develop and evaluate methods for classifying ECG signals into different cardiac categories using a digitized dataset derived from ECG images of patients from various healthcare institutes. This approach seeks to enable real-time and precise monitoring of heartbeats, facilitating better clinical decision-making for cardiac arrhythmia detection."
Medicine,Deep learning for lungs cancer detection: a review,"Abstract Although lung cancer has been recognized to be the deadliest type of cancer, a good prognosis and efficient treatment depend on early detection. Medical practitioners’ burden is reduced by deep learning techniques, especially Deep Convolutional Neural Networks (DCNN), which are essential in automating the diagnosis and classification of diseases. In this study, we use a variety of medical imaging modalities, including X-rays, WSI, CT scans, and MRI, to thoroughly investigate the use of deep learning techniques in the field of lung cancer diagnosis and classification. This study conducts a comprehensive Systematic Literature Review (SLR) using deep learning techniques for lung cancer research, providing a comprehensive overview of the methodology, cutting-edge developments, quality assessments, and customized deep learning approaches. It presents data from reputable journals and concentrates on the years 2015–2024. Deep learning techniques solve the difficulty of manually identifying and selecting abstract features from lung cancer images. This study includes a wide range of deep learning methods for classifying lung cancer but focuses especially on the most popular method, the Convolutional Neural Network (CNN). CNN can achieve maximum accuracy because of its multi-layer structure, automatic learning of weights, and capacity to communicate local weights. Various algorithms are shown with performance measures like precision, accuracy, specificity, sensitivity, and AUC; CNN consistently shows the greatest accuracy. The findings highlight the important contributions of DCNN in improving lung cancer detection and classification, making them an invaluable resource for researchers looking to gain a greater knowledge of deep learning’s function in medical applications.","['Deep Convolutional Neural Networks (DCNN)', 'Convolutional Neural Network (CNN)']","The research idea centers on the critical challenge of early detection in lung cancer, which is essential for improving prognosis and enabling efficient treatment of this deadliest type of cancer. The study addresses the burden on medical practitioners in diagnosing and classifying lung cancer by exploring advanced approaches to automate these processes using various medical imaging modalities such as X-rays, whole slide imaging, CT scans, and MRI. The research objective is to conduct a comprehensive review of existing methodologies and recent developments in lung cancer diagnosis and classification, focusing on the evaluation and comparison of different approaches to improve accuracy and reliability. This study aims to provide an in-depth overview of the effectiveness of these approaches in enhancing lung cancer detection and classification, thereby supporting further research and clinical application in this field."
Medicine,Population-Specific Glucose Prediction in Diabetes Care With Transformer-Based Deep Learning on the Edge,"Leveraging continuous glucose monitoring (CGM) systems, real-time blood glucose (BG) forecasting is essential for proactive interventions, playing a crucial role in enhancing the management of type 1 diabetes (T1D) and type 2 diabetes (T2D). However, developing a model generalized to a population and subsequently embedding it within a microchip of a wearable device presents significant technical challenges. Furthermore, the domain of BG prediction in T2D remains under-explored in the literature. In light of this, we propose a population-specific BG prediction model, leveraging the capabilities of the temporal fusion Transformer (TFT) to adjust predictions based on personal demographic data. Then the trained model is embedded within a system-on-chip, integral to our low-power and low-cost customized wearable device. This device seamlessly communicates with CGM systems through Bluetooth and provides timely BG predictions using edge computing. When evaluated on two publicly available clinical datasets with a total of 124 participants with T1D or T2D, the embedded TFT model consistently demonstrated superior performance, achieving the lowest prediction errors when compared with a range of machine learning baseline methods. Executing the TFT model on our wearable device requires minimal memory and power consumption, enabling continuous decision support for more than 51 days on a single Li-Poly battery charge. These findings demonstrate the significant potential of the proposed TFT model and wearable device in enhancing the quality of life for people with diabetes and effectively addressing real-world challenges.",['temporal fusion Transformer (TFT)'],"The study addresses the critical need for real-time blood glucose forecasting to enable proactive interventions, which is essential for improving the management of type 1 and type 2 diabetes. Despite the importance of blood glucose prediction, especially in type 2 diabetes, this area remains under-explored, and there are significant challenges in developing a generalized approach suitable for widespread use. The primary aim of the study is to develop a population-specific blood glucose prediction approach that incorporates personal demographic data to enhance accuracy. Additionally, the study seeks to integrate this approach into a wearable device that can provide continuous and timely blood glucose predictions, thereby supporting better diabetes management and improving the quality of life for individuals with diabetes."
Medicine,Machine learning models for predicting preeclampsia: a systematic review,"Abstract Background This systematic review provides an overview of machine learning (ML) approaches for predicting preeclampsia. Method This review adhered to the Preferred Reporting Items for Systematic Reviews and Meta-Analyzes (PRISMA) guidelines. We searched the Cochrane Central Register, PubMed, EMBASE, ProQuest, Scopus, and Google Scholar up to February 2023. Search terms were limited to “preeclampsia” AND “artificial intelligence” OR “machine learning” OR “deep learning.” All studies that used ML-based analysis for predicting preeclampsia in pregnant women were considered. Non-English articles and those that are unrelated to the topic were excluded. The PROBAST was used to assess the risk of bias and applicability of each included study. Results The search strategy yielded 128 citations; after duplicates were removed and title and abstract screening was completed, 18 full-text articles were evaluated for eligibility. Four studies were included in this review. Two studies were at low risk of bias, and two had low to moderate risk. All of the study designs included were retrospective cohort studies. Nine distinct models were chosen as ML models from the four studies. Maternal characteristics, medical history, medication intake, obstetrical history, and laboratory and ultrasound findings obtained during prenatal care visits were candidate predictors to train the ML model. Elastic net, stochastic gradient boosting, extreme gradient boosting, and Random forest were among the best models to predict preeclampsia. All four studies used metrics such as the area under the curve, true positive rate, negative positive rate, accuracy, precision, recall, and F1 score. The AUC of ML models varied from 0.860 to 0.973 in four studies. Conclusion The results of studies yielded high prediction performance of ML models for preeclampsia risk from routine early pregnancy information.","['Elastic net', 'stochastic gradient boosting', 'extreme gradient boosting', 'Random forest']","The research idea addresses the challenge of predicting preeclampsia in pregnant women, a condition that can have serious health implications for both the mother and the fetus. Early identification of women at risk for preeclampsia is crucial for timely intervention and improved pregnancy outcomes. The study aims to provide an overview of existing approaches used to predict the risk of preeclampsia based on routine information collected during early pregnancy. The primary objective of this study is to systematically review and evaluate the effectiveness of different prediction methods for preeclampsia using maternal characteristics, medical history, medication intake, obstetrical history, and prenatal laboratory and ultrasound findings. This review seeks to assess the performance and reliability of these prediction approaches to better understand their potential clinical utility in identifying women at risk for preeclampsia."
Medicine,Association between dietary antioxidant intakes and chronic respiratory diseases in adults,"BackgroundChronic respiratory diseases (CRDs) pose a significant global health burden. Antioxidant-rich diets have been associated with improved lung health, but the specific relationship with CRDs remains unclear.MethodsThis study examined the relationship between dietary antioxidant intakes and CRDs using data from the 2001–2018 National Health and Nutrition Examination Survey (NHANES). Information on dietary antioxidant intakes, including vitamins A, C, and E, zinc, selenium, and carotenoid, were collected from the 2 24-h recall interviews to calculate composite dietary antioxidant index (CDAI). CRDs were determined based on self-reported physician diagnoses. To examine the relationship between CDAI and CRDs, multivariate logistic regression was used. To study potential non-linear correlations within these associations, restricted cubic spline (RCS) regression was performed.ResultsThe study involved 40 557 individuals. The median CDAI was −0.09 (−2.05, 2.25). We discovered those who were in the fourth quartile of CDAI scores had a 19% lower prevalence than those in the first quartile (OR = 0.81 [0.72–0.91], Ptrend < 0.01) after adjusting for all relevant covariates. The fourth quartile of CDAI was linked with a lower prevalence of emphysema (OR = 0.57 [0.40–0.81], Ptrend < 0.01) and chronic bronchitis (OR = 0.74 [0.62–0.88], Ptrend < 0.01). RCS regression showed that CDAI was non-linearly related to the prevalence of CRDs, with inflection points of 3.20 (P for non-linearity <0.01). The stratified analysis did not identify variables that significantly affected the results.ConclusionHigher dietary antioxidant intakes were related with a lower prevalence of CRDs (particularly emphysema and chronic bronchitis) in general adults.",['multivariate logistic regression'],"The study addresses the significant global health burden posed by chronic respiratory diseases (CRDs) and the unclear relationship between antioxidant-rich diets and the prevalence of these diseases. Although antioxidant-rich diets have been associated with improved lung health, the specific impact on CRDs such as emphysema and chronic bronchitis remains insufficiently understood. The primary aim of this study was to examine the relationship between dietary antioxidant intakes, including vitamins A, C, and E, zinc, selenium, and carotenoids, and the prevalence of CRDs in a general adult population. The study sought to determine whether higher dietary antioxidant intakes are associated with a lower prevalence of CRDs, particularly emphysema and chronic bronchitis."
Medicine,"An Extensive Investigation into the Use of Machine Learning Tools and Deep Neural Networks for the Recognition of Skin Cancer: Challenges, Future Directions, and a Comprehensive Review","Skin cancer poses a serious risk to one’s health and can only be effectively treated with early detection. Early identification is critical since skin cancer has a higher fatality rate, and it expands gradually to different areas of the body. The rapid growth of automated diagnosis frameworks has led to the combination of diverse machine learning, deep learning, and computer vision algorithms for detecting clinical samples and atypical skin lesion specimens. Automated methods for recognizing skin cancer that use deep learning techniques are discussed in this article: convolutional neural networks, and, in general, artificial neural networks. The recognition of symmetries is a key point in dealing with the skin cancer image datasets; hence, in developing the appropriate architecture of neural networks, as it can improve the performance and release capacities of the network. The current study emphasizes the need for an automated method to identify skin lesions to reduce the amount of time and effort required for the diagnostic process, as well as the novel aspect of using algorithms based on deep learning for skin lesion detection. The analysis concludes with underlying research directions for the future, which will assist in better addressing the difficulties encountered in human skin cancer recognition. By highlighting the drawbacks and advantages of prior techniques, the authors hope to establish a standard for future analysis in the domain of human skin lesion diagnostics.","['convolutional neural networks', 'artificial neural networks']","The research idea centers on the serious health risk posed by skin cancer and the critical importance of early detection due to its higher fatality rate and gradual spread to different areas of the body. Early identification is essential for effective treatment, yet the diagnostic process can be time-consuming and labor-intensive. The study highlights the need to improve methods for recognizing skin lesions to facilitate quicker and more efficient diagnosis. The primary objective of the study is to emphasize the development of an automated approach for identifying skin lesions that can reduce the time and effort required in the diagnostic process. Additionally, the study aims to review existing techniques for skin lesion detection, discuss their advantages and drawbacks, and provide guidance for future research to better address challenges in human skin cancer recognition."
Medicine,DenRAM: neuromorphic dendritic architecture with RRAM for efficient temporal processing with delays,"An increasing number of studies are highlighting the importance of spatial dendritic branching in pyramidal neurons in the neocortex for supporting non-linear computation through localized synaptic integration. In particular, dendritic branches play a key role in temporal signal processing and feature detection. This is accomplished thanks to coincidence detection (CD) mechanisms enabled by the presence of synaptic delays that align temporally disparate inputs for effective integration. Computational studies on spiking neural networks further highlight the significance of delays for achieving spatio-temporal pattern recognition with pure feed-forward neural networks, without the need of resorting to recurrent architectures. In this work, we present ""DenRAM"", the first realization of a feed-forward spiking neural network with dendritic compartments, implemented using analog electronic circuits integrated into a 130 nm technology node and coupled with Resistive Random Access Memory (RRAM) technology. DenRAM's dendritic circuits use RRAM devices to implement both delays and synaptic weights in the network. By configuring the RRAM devices to reproduce bio-realistic timescales, and by exploiting their heterogeneity we experimentally demonstrate DenRAM's ability to replicate synaptic delay profiles, and to efficiently implement CD for spatio-temporal pattern recognition. To validate the architecture, we conduct comprehensive system-level simulations on two representative temporal benchmarks, demonstrating DenRAM's resilience to analog hardware noise, and its superior accuracy compared to recurrent architectures with an equivalent number of parameters. DenRAM not only brings rich temporal processing capabilities to neuromorphic architectures, but also reduces the memory footprint of edge devices, warrants high accuracy on temporal benchmarks, and represents a significant step-forward in low-power real-time signal processing technologies.",['feed-forward spiking neural network'],"The research idea centers on the critical role of spatial dendritic branching in pyramidal neurons of the neocortex for enabling non-linear computation through localized synaptic integration. Dendritic branches are essential for temporal signal processing and feature detection by facilitating coincidence detection mechanisms that align temporally disparate inputs for effective integration. The study addresses the importance of synaptic delays in supporting spatio-temporal pattern recognition in neural networks. The primary objective of the study is to experimentally demonstrate the ability to replicate synaptic delay profiles and efficiently implement coincidence detection for spatio-temporal pattern recognition using dendritic circuits. Additionally, the study aims to validate the architecture’s resilience to noise and its accuracy on temporal benchmarks, highlighting its potential for enhancing temporal processing capabilities and reducing memory requirements in real-time signal processing applications."
Medicine,Colon and lung cancer classification from multi-modal images using resilient and efficient neural network architectures,"Automatic classification of colon and lung cancer images is crucial for early detection and accurate diagnostics. However, there is room for improvement to enhance accuracy, ensuring better diagnostic precision. This study introduces two novel dense architectures (D1 and D2) and emphasizes their effectiveness in classifying colon and lung cancer from diverse images. It also highlights their resilience, efficiency, and superior performance across multiple datasets. These architectures were tested on various types of datasets, including NCT-CRC-HE-100K (set of 100,000 non-overlapping image patches from hematoxylin and eosin (H&E) stained histological images of human colorectal cancer (CRC) and normal tissue), CRC-VAL-HE-7K (set of 7180 image patches from N=50 patients with colorectal adenocarcinoma, no overlap with patients in NCT-CRC-HE-100K), LC25000 (Lung and Colon Cancer Histopathological Image), and IQ-OTHNCCD (Iraq-Oncology Teaching Hospital/National Center for Cancer Diseases), showcasing their effectiveness in classifying colon and lung cancers from histopathological and Computed Tomography (CT) scan images. This underscores the multi-modal image classification capability of the proposed models. Moreover, the study addresses imbalanced datasets, particularly in CRC-VAL-HE-7K and IQ-OTHNCCD, with a specific focus on model resilience and robustness. To assess overall performance, the study conducted experiments in different scenarios. The D1 model achieved an impressive 99.80% accuracy on the NCT-CRC-HE-100K dataset, with a Jaccard Index (J) of 0.8371, a Matthew's Correlation Coefficient (MCC) of 0.9073, a Cohen's Kappa (Kp) of 0.9057, and a Critical Success Index (CSI) of 0.8213. When subjected to 10-fold cross-validation on LC25000, the D1 model averaged (avg) 99.96% accuracy (avg J, MCC, Kp, and CSI of 0.9993, 0.9987, 0.9853, and 0.9990), surpassing recent reported performances. Furthermore, the ensemble of D1 and D2 reached 93% accuracy (J, MCC, Kp, and CSI of 0.7556, 0.8839, 0.8796, and 0.7140) on the IQ-OTHNCCD dataset, exceeding recent benchmarks and aligning with other reported results. Efficiency evaluations were conducted in various scenarios. For instance, training on only 10% of LC25000 resulted in high accuracy rates of 99.19% (J, MCC, Kp, and CSI of 0.9840, 0.9898, 0.9898, and 0.9837) (D1) and 99.30% (J, MCC, Kp, and CSI of 0.9863, 0.9913, 0.9913, and 0.9861) (D2). In NCT-CRC-HE-100K, D2 achieved an impressive 99.53% accuracy (J, MCC, Kp, and CSI of 0.9906, 0.9946, 0.9946, and 0.9906) with training on only 30% of the dataset and testing on the remaining 70%. When tested on CRC-VAL-HE-7K, D1 and D2 achieved 95% accuracy (J, MCC, Kp, and CSI of 0.8845, 0.9455, 0.9452, and 0.8745) and 96% accuracy (J, MCC, Kp, and CSI of 0.8926, 0.9504, 0.9503, and 0.8798), respectively, outperforming previously reported results and aligning closely with others. Lastly, training D2 on just 10% of NCT-CRC-HE-100K and testing on CRC-VAL-HE-7K resulted in significant outperformance of InceptionV3, Xception, and DenseNet201 benchmarks, achieving an accuracy rate of 82.98% (J, MCC, Kp, and CSI of 0.7227, 0.8095, 0.8081, and 0.6671). Finally, using explainable AI algorithms such as Grad-CAM, Grad-CAM++, Score-CAM, and Faster Score-CAM, along with their emphasized versions, we visualized the features from the last layer of DenseNet201 for histopathological as well as CT-scan image samples. The proposed dense models, with their multi-modality, robustness, and efficiency in cancer image classification, hold the promise of significant advancements in medical diagnostics. They have the potential to revolutionize early cancer detection and improve healthcare accessibility worldwide.","['InceptionV3', 'Xception', 'DenseNet201', 'Grad-CAM', 'Grad-CAM++', 'Score-CAM', 'Faster Score-CAM']","The research idea centers on the critical need for improved classification of colon and lung cancer images to enable early detection and enhance diagnostic accuracy. Despite existing methods, there remains significant room for improvement in achieving higher precision in cancer diagnostics. This study addresses the challenge of accurately classifying diverse histopathological and CT scan images of colon and lung cancers, including handling imbalanced datasets, to support better clinical outcomes.

The primary objective of the study is to evaluate the effectiveness, resilience, and efficiency of two novel dense architectures in classifying colon and lung cancer images across multiple datasets. The study aims to demonstrate superior performance in cancer image classification, including multi-modal imaging, and to assess the models’ robustness in various scenarios, ultimately contributing to advancements in early cancer detection and improved healthcare accessibility."
Medicine,Integration of deep learning and habitat radiomics for predicting the response to immunotherapy in NSCLC patients,"Abstract Background The non-invasive biomarkers for predicting immunotherapy response are urgently needed to prevent both premature cessation of treatment and ineffective extension. This study aimed to construct a non-invasive model for predicting immunotherapy response, based on the integration of deep learning and habitat radiomics in patients with advanced non-small cell lung cancer (NSCLC). Methods Independent patient cohorts from three medical centers were enrolled for training ( n = 164) and test ( n = 82). Habitat imaging radiomics features were derived from sub-regions clustered from individual’s tumor by K-means method. The deep learning features were extracted based on 3D ResNet algorithm. Pearson correlation coefficient, T test and least absolute shrinkage and selection operator regression were used to select features. Support vector machine was applied to implement deep learning and habitat radiomics, respectively. Then, a combination model was developed integrating both sources of data. Results The combination model obtained a strong well-performance, achieving area under receiver operating characteristics curve of 0.865 (95% CI 0.772–0.931). The model significantly discerned high and low-risk patients, and exhibited a significant benefit in the clinical use. Conclusion The integration of deep-leaning and habitat radiomics contributed to predicting response to immunotherapy in patients with NSCLC. The developed integration model may be used as potential tool for individual immunotherapy management.","['K-means', '3D ResNet algorithm', 'least absolute shrinkage and selection operator regression', 'Support vector machine']","The study addresses the urgent need for non-invasive biomarkers to predict immunotherapy response in patients with advanced non-small cell lung cancer (NSCLC). This need arises to prevent both premature cessation of treatment and ineffective extension, which can impact patient outcomes. The research focuses on improving the ability to identify which patients are likely to benefit from immunotherapy, thereby enhancing personalized treatment strategies. The primary aim of the study is to develop a non-invasive approach for predicting immunotherapy response in patients with advanced NSCLC. This approach seeks to integrate different sources of imaging information to accurately distinguish between high and low-risk patients, ultimately supporting better clinical decision-making in immunotherapy management."
Medicine,Comparing machine learning algorithms to predict vegetation fire detections in Pakistan,"Abstract Vegetation fires have major impacts on the ecosystem and present a significant threat to human life. Vegetation fires consists of forest fires, cropland fires, and other vegetation fires in this study. Currently, there is a limited amount of research on the long-term prediction of vegetation fires in Pakistan. The exact effect of every factor on the frequency of vegetation fires remains unclear when using standard analysis. This research utilized the high proficiency of machine learning algorithms to combine data from several sources, including the MODIS Global Fire Atlas dataset, topographic, climatic conditions, and different vegetation types acquired between 2001 and 2022. We tested many algorithms and ultimately chose four models for formal data processing. Their selection was based on their performance metrics, such as accuracy, computational efficiency, and preliminary test results. The model’s logistic regression, a random forest, a support vector machine, and an eXtreme Gradient Boosting were used to identify and select the nine key factors of forest and cropland fires and, in the case of other vegetation, seven key factors that cause a fire in Pakistan. The findings indicated that the vegetation fire prediction models achieved prediction accuracies ranging from 78.7 to 87.5% for forest fires, 70.4 to 84.0% for cropland fires, and 66.6 to 83.1% for other vegetation. Additionally, the area under the curve (AUC) values ranged from 83.6 to 93.4% in forest fires, 72.6 to 90.6% in cropland fires, and 74.2 to 90.7% in other vegetation. The random forest model had the highest accuracy rate of 87.5% in forest fires, 84.0% in cropland fires, and 83.1% in other vegetation and also the highest AUC value of 93.4% in forest fires, 90.6% in cropland fires, and 90.7% in other vegetation, proving to be the most optimal performance model. The models provided predictive insights into specific conditions and regional susceptibilities to fire occurrences, adding significant value beyond the initial MODIS detection data. The maps generated to analyze Pakistan’s vegetation fire risk showed the geographical distribution of areas with high, moderate, and low vegetation fire risks, highlighting predictive risk assessments rather than historical fire detections.","['logistic regression', 'random forest', 'support vector machine', 'eXtreme Gradient Boosting']","The study addresses the significant impact of vegetation fires, including forest fires, cropland fires, and other types, on ecosystems and human life, with a particular focus on Pakistan. There is a limited amount of research on the long-term prediction of vegetation fires in this region, and the exact influence of various factors on fire frequency remains unclear. The primary aim of the study is to identify key factors contributing to different types of vegetation fires in Pakistan and to provide predictive insights into specific conditions and regional susceptibilities to fire occurrences. This objective includes generating risk maps that highlight the geographical distribution of areas with varying levels of vegetation fire risk, thereby enhancing understanding beyond historical fire detections."
Medicine,Enhancing ECG-based heart age: impact of acquisition parameters and generalization strategies for varying signal morphologies and corruptions,"Electrocardiogram (ECG) is a non-invasive approach to capture the overall electrical activity produced by the contraction and relaxation of the cardiac muscles. It has been established in the literature that the difference between ECG-derived age and chronological age represents a general measure of cardiovascular health. Elevated ECG-derived age strongly correlates with cardiovascular conditions (e.g., atherosclerotic cardiovascular disease). However, the neural networks for ECG age estimation are yet to be thoroughly evaluated from the perspective of ECG acquisition parameters. Additionally, deep learning systems for ECG analysis encounter challenges in generalizing across diverse ECG morphologies in various ethnic groups and are susceptible to errors with signals that exhibit random or systematic distortions To address these challenges, we perform a comprehensive empirical study to determine the threshold for the sampling rate and duration of ECG signals while considering their impact on the computational cost of the neural networks. To tackle the concern of ECG waveform variability in different populations, we evaluate the feasibility of utilizing pre-trained and fine-tuned networks to estimate ECG age in different ethnic groups. Additionally, we empirically demonstrate that finetuning is an environmentally sustainable way to train neural networks, and it significantly decreases the ECG instances required (by more than <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML"" id=""IM1""><mml:mn>100</mml:mn><mml:mo>×</mml:mo></mml:math> ) for attaining performance similar to the networks trained from random weight initialization on a complete dataset. Finally, we systematically evaluate augmentation schemes for ECG signals in the context of age estimation and introduce a random cropping scheme that provides best-in-class performance while using shorter-duration ECG signals. The results also show that random cropping enables the networks to perform well with systematic and random ECG signal corruptions.","['neural networks', 'fine-tuned networks', 'finetuning']","The research idea centers on the use of electrocardiogram (ECG) signals as a non-invasive measure of cardiovascular health, specifically through the difference between ECG-derived age and chronological age, which correlates with cardiovascular conditions such as atherosclerotic cardiovascular disease. However, challenges exist in accurately estimating ECG age due to variability in ECG acquisition parameters and differences in ECG waveforms across diverse ethnic groups, as well as the presence of signal distortions. The study aims to address these challenges by investigating the impact of ECG signal characteristics and population diversity on the reliability of ECG age estimation. The primary objective of the study is to determine optimal ECG signal parameters, evaluate the feasibility of estimating ECG age across different ethnic groups, and identify effective approaches to improve the accuracy and robustness of ECG age estimation despite signal variability and distortions."
Medicine,Recent deep learning-based brain tumor segmentation models using multi-modality magnetic resonance imaging: a prospective survey,"Radiologists encounter significant challenges when segmenting and determining brain tumors in patients because this information assists in treatment planning. The utilization of artificial intelligence (AI), especially deep learning (DL), has emerged as a useful tool in healthcare, aiding radiologists in their diagnostic processes. This empowers radiologists to understand the biology of tumors better and provide personalized care to patients with brain tumors. The segmentation of brain tumors using multi-modal magnetic resonance imaging (MRI) images has received considerable attention. In this survey, we first discuss multi-modal and available magnetic resonance imaging modalities and their properties. Subsequently, we discuss the most recent DL-based models for brain tumor segmentation using multi-modal MRI. We divide this section into three parts based on the architecture: the first is for models that use the backbone of convolutional neural networks (CNN), the second is for vision transformer-based models, and the third is for hybrid models that use both convolutional neural networks and transformer in the architecture. In addition, in-depth statistical analysis is performed of the recent publication, frequently used datasets, and evaluation metrics for segmentation tasks. Finally, open research challenges are identified and suggested promising future directions for brain tumor segmentation to improve diagnostic accuracy and treatment outcomes for patients with brain tumors. This aligns with public health goals to use health technologies for better healthcare delivery and population health management.","['deep learning (DL)', 'convolutional neural networks (CNN)', 'vision transformer-based models', 'hybrid models that use both convolutional neural networks and transformer']","The research idea centers on the significant challenges radiologists face in accurately segmenting and determining brain tumors in patients, which is crucial for effective treatment planning. Improving the understanding of tumor biology through advanced imaging techniques can enhance personalized care for patients with brain tumors. The primary objective of the study is to review and discuss the current approaches to brain tumor segmentation using multi-modal magnetic resonance imaging (MRI), highlighting recent advancements and identifying open research challenges. This aims to improve diagnostic accuracy and treatment outcomes for patients with brain tumors, ultimately supporting better healthcare delivery and population health management."
Medicine,A comprehensive investigation of multimodal deep learning fusion strategies for breast cancer classification,"In breast cancer research, diverse data types and formats, such as radiological images, clinical records, histological data, and expression analysis, are employed. Given the intricate nature of natural phenomena, relying on the features of a single modality is seldom sufficient for comprehensive analysis. Therefore, it is possible to guarantee medical relevance and achieve improved clinical outcomes by combining several modalities. The presen study carefully maps and reviews 47 primary articles from six well-known digital libraries that were published between 2018 and 2023 for breast cancer classification based on multimodal deep learning fusion (MDLF) techniques. This systematic literature review encompasses various aspects, including the medical modalities combined, the datasets utilized in these studies, the techniques, models, and architectures used in MDLF and it also discusses the advantages and limitations of each approach. The analysis of selected papers has revealed a compelling trend: the emergence of new modalities and combinations that were previously unexplored in the context of breast cancer classification. This exploration has not only expanded the scope of predictive models but also introduced fresh perspectives for addressing diverse targets, ranging from screening to diagnosis and prognosis. The practical advantages of MDLF are evident in its ability to enhance the predictive capabilities of machine learning models, resulting in improved accuracy across diverse applications. The prevalence of deep learning models underscores their success in autonomously discerning complex patterns, offering a substantial departure from traditional machine learning approaches. Furthermore, the paper explores the challenges and future directions in this field, including the need for larger datasets, the use of ensemble learning methods, and the interpretation of multimodal models.",['ensemble learning methods'],"The research idea centers on the complexity of breast cancer diagnosis and prognosis, highlighting that relying on a single type of medical data is often insufficient for comprehensive understanding. Combining multiple medical modalities, such as radiological images, clinical records, histological data, and expression analysis, can enhance medical relevance and improve clinical outcomes. This approach addresses the need for more effective methods to capture the multifaceted nature of breast cancer. The research objective is to systematically review and map existing studies published between 2018 and 2023 that focus on breast cancer classification using combined medical modalities. The study aims to identify the various medical data types used, examine the advantages and limitations of different approaches, and explore emerging combinations of modalities that offer new perspectives for screening, diagnosis, and prognosis in breast cancer care."
Medicine,Artificial intelligence performance in detecting lymphoma from medical imaging: a systematic review and meta-analysis,"Abstract Background Accurate diagnosis and early treatment are essential in the fight against lymphatic cancer. The application of artificial intelligence (AI) in the field of medical imaging shows great potential, but the diagnostic accuracy of lymphoma is unclear. This study was done to systematically review and meta-analyse researches concerning the diagnostic performance of AI in detecting lymphoma using medical imaging for the first time. Methods Searches were conducted in Medline, Embase, IEEE and Cochrane up to December 2023. Data extraction and assessment of the included study quality were independently conducted by two investigators. Studies that reported the diagnostic performance of an AI model/s for the early detection of lymphoma using medical imaging were included in the systemic review. We extracted the binary diagnostic accuracy data to obtain the outcomes of interest: sensitivity (SE), specificity (SP), and Area Under the Curve (AUC). The study was registered with the PROSPERO, CRD42022383386. Results Thirty studies were included in the systematic review, sixteen of which were meta-analyzed with a pooled sensitivity of 87% (95%CI 83–91%), specificity of 94% (92–96%), and AUC of 97% (95–98%). Satisfactory diagnostic performance was observed in subgroup analyses based on algorithms types (machine learning versus deep learning, and whether transfer learning was applied), sample size (≤ 200 or &gt; 200), clinicians versus AI models and geographical distribution of institutions (Asia versus non-Asia). Conclusions Even if possible overestimation and further studies with a better standards for application of AI algorithms in lymphoma detection are needed, we suggest the AI may be useful in lymphoma diagnosis.","['machine learning', 'deep learning', 'transfer learning']","The research idea centers on the critical need for accurate diagnosis and early treatment in combating lymphatic cancer, highlighting the uncertainty surrounding the diagnostic accuracy of current methods for lymphoma detection. This study addresses the gap in knowledge regarding the effectiveness of diagnostic approaches in identifying lymphoma through medical imaging. The primary objective of the study is to systematically review and meta-analyze existing research on the diagnostic performance of methods used for early detection of lymphoma via medical imaging. The aim is to evaluate sensitivity, specificity, and overall diagnostic accuracy to determine the potential usefulness of these approaches in lymphoma diagnosis."
Medicine,A critical moment in machine learning in medicine: on reproducible and interpretable learning,"Over the past two decades, advances in computational power and data availability combined with increased accessibility to pre-trained models have led to an exponential rise in machine learning (ML) publications. While ML may have the potential to transform healthcare, this sharp increase in ML research output without focus on methodological rigor and standard reporting guidelines has fueled a reproducibility crisis. In addition, the rapidly growing complexity of these models compromises their interpretability, which currently impedes their successful and widespread clinical adoption. In medicine, where failure of such models may have severe implications for patients' health, the high requirements for accuracy, robustness, and interpretability confront ML researchers with a unique set of challenges. In this review, we discuss the semantics of reproducibility and interpretability, as well as related issues and challenges, and outline possible solutions to counteracting the ""black box"". To foster reproducibility, standard reporting guidelines need to be further developed and data or code sharing encouraged. Editors and reviewers may equally play a critical role by establishing high methodological standards and thus preventing the dissemination of low-quality ML publications. To foster interpretable learning, the use of simpler models more suitable for medical data can inform the clinician how results are generated based on input data. Model-agnostic explanation tools, sensitivity analysis, and hidden layer representations constitute further promising approaches to increase interpretability. Balancing model performance and interpretability are important to ensure clinical applicability. We have now reached a critical moment for ML in medicine, where addressing these issues and implementing appropriate solutions will be vital for the future evolution of the field.",['model-agnostic explanation tools'],"The research idea centers on the challenges posed by the rapid increase in complex methodologies applied in medicine, which has led to issues with reproducibility and interpretability. These challenges hinder the successful and widespread clinical adoption of new approaches, especially given the high standards required for accuracy, robustness, and clarity in medical applications where patient health is at stake. The study highlights the critical need to address these problems to ensure that advancements can be reliably and safely integrated into healthcare. The primary objective of the study is to discuss the concepts of reproducibility and interpretability in the medical context, identify related challenges, and propose potential solutions to improve these aspects. It aims to emphasize the importance of developing standard reporting guidelines, encouraging transparency, and balancing performance with interpretability to enhance clinical applicability and support the future evolution of medical research and practice."
Medicine,Risk predictions of surgical wound complications based on a machine learning algorithm: A systematic review,"Abstract Surgical wounds may arise due to harm inflicted upon soft tissue during surgical intervention, and many complications and injuries may accompany them. These complications can lead to prolonged hospitalization and poorer clinical outcomes. Also, Machine learning (ML) is a Section of artificial intelligence (AI) that has emerged in medical care and is increasingly used for diagnosis, complications, prognosis and recurrence prediction. This study aims to investigate surgical wound risk predictions and management using a ML algorithm by R programming language analysis. The systematic review, following PRISMA guidelines, spanned electronic databases using search terms like ‘machine learning’, ‘surgical’ and ‘wound’. Inclusion criteria covered experimental studies from 1990 to the present on ML's application in surgical wound evaluation. Exclusion criteria included studies lacking full text, focusing on ML in all surgeries, neglecting wound assessment and duplications. Two authors rigorously assessed titles, abstracts and full texts, excluding reviews and guidelines. Ultimately, relevant articles were then analysed. The present study identified nine articles employing ML for surgical wound management. The analysis encompassed various surgical procedures, including Cardiothoracic, Caesarean total abdominal colectomy, Burn plastic surgery, facial plastic surgery, laparotomy, minimal invasive surgery, hernia repair and unspecified surgeries. ML was skillful in evaluating surgical site infections (SSI) in seven studies, while two extended its use to burn‐grade diagnosis and wound classification. Support Vector Machine (SVM) and Convolutional Neural Network (CNN) were the most utilized algorithms. ANN achieved a 96% accuracy in facial plastic surgery wound management. CNN demonstrated commendable accuracies in various surgeries, and SVM exhibited high accuracy in multiple surgeries and burn plastic surgery. In sum, these findings underscore ML's potential for significant improvements in postoperative management and the development of enhanced care techniques, particularly in surgical wound management.","['Support Vector Machine (SVM)', 'Convolutional Neural Network (CNN)', 'Artificial Neural Network (ANN)']","The research idea centers on the challenges posed by surgical wounds, which result from soft tissue damage during surgical procedures and can lead to complications, prolonged hospitalization, and poorer clinical outcomes. Addressing these complications is crucial for improving patient recovery and postoperative care. The study’s primary objective is to investigate the prediction and management of surgical wound risks to enhance postoperative outcomes. Specifically, it aims to evaluate approaches for assessing surgical site infections and wound classification across various types of surgeries to improve surgical wound management and care techniques."
Medicine,Prediction models for postoperative delirium in elderly patients with machine-learning algorithms and SHapley Additive exPlanations,"Abstract Postoperative delirium (POD) is a common and severe complication in elderly patients with hip fractures. Identifying high-risk patients with POD can help improve the outcome of patients with hip fractures. We conducted a retrospective study on elderly patients (≥65 years of age) who underwent orthopedic surgery with hip fracture between January 2014 and August 2019. Conventional logistic regression and five machine-learning algorithms were used to construct prediction models of POD. A nomogram for POD prediction was built with the logistic regression method. The area under the receiver operating characteristic curve (AUC-ROC), accuracy, sensitivity, and precision were calculated to evaluate different models. Feature importance of individuals was interpreted using Shapley Additive Explanations (SHAP). About 797 patients were enrolled in the study, with the incidence of POD at 9.28% (74/797). The age, renal insufficiency, chronic obstructive pulmonary disease (COPD), use of antipsychotics, lactate dehydrogenase (LDH), and C-reactive protein are used to build a nomogram for POD with an AUC of 0.71. The AUCs of five machine-learning models are 0.81 (Random Forest), 0.80 (GBM), 0.68 (AdaBoost), 0.77 (XGBoost), and 0.70 (SVM). The sensitivities of the six models range from 68.8% (logistic regression and SVM) to 91.9% (Random Forest). The precisions of the six machine-learning models range from 18.3% (logistic regression) to 67.8% (SVM). Six prediction models of POD in patients with hip fractures were constructed using logistic regression and five machine-learning algorithms. The application of machine-learning algorithms could provide convenient POD risk stratification to benefit elderly hip fracture patients.","['logistic regression', 'Random Forest', 'GBM', 'AdaBoost', 'XGBoost', 'SVM']","The research idea addresses the issue that postoperative delirium (POD) is a common and severe complication in elderly patients with hip fractures, and identifying patients at high risk for POD can help improve their outcomes. Given the significant impact of POD on this vulnerable population, there is a need for effective methods to predict which patients are more likely to develop this complication. The primary objective of the study is to construct and evaluate prediction models for POD in elderly patients undergoing orthopedic surgery for hip fractures. The study aims to develop tools that can stratify the risk of POD to ultimately benefit elderly hip fracture patients by enabling better clinical management and intervention."
Medicine,Predicting mechanical properties of self-healing concrete with Trichoderma Reesei Fungus using machine learning,"Trichoderma Reesei is a mesophilic and filamentous fungus. It is an anamorph of the fungus Hypocrea jecorina, in addition, T. reesei can secrete large amounts of cellulolytic enzymes and form dextrose PDA (potato dextrose agar) and potato injection. After the preparation of fungi, it is added to the cracked samples. The experimental samples were 150 mm3 cubic compression and 70 mm x 30 mm x 15 mm cracks on the surface of each cube. Different fungi water extracts were used with 0, 50.5, 6.37, and 8.42 liters of water per ml. The results show that the addition of 8.42 (ml) of the mushroom extract with one liter of water has the maximum compressive strength with more than 18.99 MPa for 28 days, 16.7 for 14 days, and 14.5 for 7 days. In this study, linear regression, lasso regression, and rigid regression have been used to predict compressive strength, also the cooperation between mushroom juice per milliliter and compressive strength has been predicted. To find the accuracy, Correlation Coefficient (R2), Mean Absolute Errors (MAE), and Root Mean Square Error have been used. The results of machine learning show that the results of linear regression and rigid regression R2 were more than 0.98. In addition, the relationship compressive strength prediction results showed that R2 for fungi broth with one liter of water was 5.05 mL was more than 0.98. Finally, this study shows that the fungus Trichoderma reesei is an effective agent for curing concrete and improving the compressive strength of concrete.","['linear regression', 'lasso regression']","The research idea centers on exploring the potential of the fungus Trichoderma reesei to enhance the compressive strength of concrete by acting as an effective curing agent. This study addresses the problem of improving concrete durability and strength through biological means, focusing on the ability of T. reesei to secrete enzymes that may influence the material properties of concrete. The research objective is to evaluate the effect of different concentrations of fungi water extracts on the compressive strength of concrete samples over various curing periods. Specifically, the study aims to determine the optimal amount of T. reesei extract that maximizes compressive strength at 7, 14, and 28 days of curing."
Medicine,Random forest regression for prediction of Covid-19 daily cases and deaths in Turkey,"During pandemic periods, there is an intense flow of patients to hospitals. Depending on the disease, many patients may require hospitalization. In some cases, these patients must be taken to intensive care units and emergency interventions must be performed. However, finding a sufficient number of hospital beds or intensive care units during pandemic periods poses a big problem. In these periods, fast and effective planning is more important than ever. Another problem experienced during pandemic periods is the burial of the dead in case the number of deaths increases. This is also a situation that requires due planning. We can learn some lessons from Covid 19 pandemic and be prepared for the future ones. In this paper, statistical properties of the daily cases and daily deaths in Turkey, which is one of the most affected countries by the pandemic in the World, are studied. It is found that the characteristics are nonstationary. Then, random forest regression is applied to predict Covid-19 daily cases and deaths. In addition, seven other machine learning models, namely bagging, AdaBoost, gradient boosting, XGBoost, decision tree, LSTM and ARIMA regressors are built for comparison. The performance of the models are measured using accuracy, coefficient of variation, root-mean-square score and relative error metrics. When random forest regressors are employed, test data related to daily cases are predicted with an accuracy of 92.30% and with an r2 score of 0.9893. Besides, daily deaths are predicted with an accuracy of 91.39% and with an r2 score of 0.9834. The closest rival in predictions is the bagging regressor. Nevertheless, the results provided by this algoritm changed in different runs and this fact is shown in the study, as well. Comparisons are based on test data. Comparisons with the earlier works are also provided.","['random forest regression', 'bagging', 'AdaBoost', 'gradient boosting', 'XGBoost', 'decision tree', 'LSTM']","The research idea addresses the critical challenges faced during pandemic periods, such as the overwhelming influx of patients requiring hospitalization and intensive care, as well as the difficulties in managing hospital bed availability and the burial of increased numbers of deceased individuals. Effective and timely planning during such crises is essential to mitigate these problems. The study aims to learn from the Covid-19 pandemic experience in Turkey, one of the most affected countries, by examining the statistical properties of daily cases and deaths to better understand the dynamics of the disease spread and its impact. The primary objective of the study is to predict Covid-19 daily cases and deaths in Turkey to support more informed decision-making and planning during pandemic periods, thereby improving healthcare resource allocation and management."
Medicine,A Comparative Analysis of Machine Learning Algorithms for Breast Cancer Detection and Identification of Key Predictive Features,"Cancer, a disease with numerous subtypes, poses a deadly threat to human life, with the potential for successful clinical treatment heavily reliant on early detection and appropriate treatment planning.The classification of cancer patients into either low or high-risk subgroups is critical.Consequently, various research teams spanning the biomedical and bioinformatics fields have explored the use of Machine Learning (ML) technology in this crucial domain.The impressive capability of ML algorithms to discern significant features in complex datasets underscores their value.In the current study, we propose a framework to detect breast cancer (through benign and malignant categorization) utilizing advanced ML techniques with high accuracy.This framework deploys the Wisconsin Breast Cancer (Diagnostic) dataset.Five supervised ML techniques, namely Decision Tree, Random Forest (RF), Support Vector Machine (SVM), Extreme Gradient Boosting (XGBoost), and Artificial Neural Network (ANN), are trained for classification purposes.Out of 569 samples, 70% are allocated for training while the other 30% for testing.A comprehensive evaluation of ML techniques is performed using an array of metrics: precision, recall, specificity, F1 score, classification accuracy, ROC Curve, training time, and feature utilization.Additionally, feature importance is computed for each classifier.The results reveal that the SVM has the maximum accuracy as 97.66%, with an F1-score of 0.98 for benign and 0.97 for malignant classifications.Conversely, the decision tree registers the minimum performance (94.55%) with an F1-score of 0.95 for benign and 0.91 for malignant classes.Accuracy scores for RF, XGBoost, and ANN stand at 95.32%, 95.91%, and 97.07%, with corresponding F1-scores of 0.96, 0.97, and 0.98 for benign and 0.94, 0.95, and 0.96 for malignant respectively.Interestingly, RF and XGBoost exhibited near-equivalent similarly with respect of accuracy measurements.In the context of the area over the ROC curve, SVM outperformed the other ML classifiers and also reported the shortest training time.Conversely, the ANN reported the longest training time.","['Decision Tree', 'Random Forest (RF)', 'Support Vector Machine (SVM)', 'Extreme Gradient Boosting (XGBoost)', 'Artificial Neural Network (ANN)']","The research idea centers on the critical need for early detection and accurate classification of breast cancer into benign and malignant categories, which is essential for effective clinical treatment and appropriate patient risk stratification. Given the deadly nature of cancer and its numerous subtypes, distinguishing between low and high-risk patients plays a vital role in improving treatment outcomes. The study aims to address this challenge by focusing on enhancing the accuracy of breast cancer detection and classification. The primary objective of the study is to develop and evaluate a framework for detecting breast cancer by categorizing tumors as benign or malignant with high accuracy, using the Wisconsin Breast Cancer (Diagnostic) dataset. The study seeks to identify the most effective approach for classification to support better clinical decision-making in breast cancer diagnosis."
Medicine,An interpretable machine learning system for colorectal cancer diagnosis from pathology slides,"Abstract Considering the profound transformation affecting pathology practice, we aimed to develop a scalable artificial intelligence (AI) system to diagnose colorectal cancer from whole-slide images (WSI). For this, we propose a deep learning (DL) system that learns from weak labels, a sampling strategy that reduces the number of training samples by a factor of six without compromising performance, an approach to leverage a small subset of fully annotated samples, and a prototype with explainable predictions, active learning features and parallelisation. Noting some problems in the literature, this study is conducted with one of the largest WSI colorectal samples dataset with approximately 10,500 WSIs. Of these samples, 900 are testing samples. Furthermore, the robustness of the proposed method is assessed with two additional external datasets (TCGA and PAIP) and a dataset of samples collected directly from the proposed prototype. Our proposed method predicts, for the patch-based tiles, a class based on the severity of the dysplasia and uses that information to classify the whole slide. It is trained with an interpretable mixed-supervision scheme to leverage the domain knowledge introduced by pathologists through spatial annotations. The mixed-supervision scheme allowed for an intelligent sampling strategy effectively evaluated in several different scenarios without compromising the performance. On the internal dataset, the method shows an accuracy of 93.44% and a sensitivity between positive (low-grade and high-grade dysplasia) and non-neoplastic samples of 0.996. On the external test samples varied with TCGA being the most challenging dataset with an overall accuracy of 84.91% and a sensitivity of 0.996.",['deep learning (DL) system that learns from weak labels'],"The research idea addresses the significant changes occurring in pathology practice, specifically focusing on the need for improved diagnostic approaches for colorectal cancer using whole-slide images. The study recognizes challenges in existing literature and emphasizes the importance of utilizing a large dataset to enhance diagnostic accuracy and robustness across different sample collections. The research objective is to develop a scalable and effective method for diagnosing colorectal cancer from whole-slide images, aiming to accurately classify tissue samples based on the severity of dysplasia. The study seeks to evaluate the performance and robustness of this diagnostic approach using a large internal dataset as well as multiple external datasets to ensure reliability and clinical relevance."
Medicine,Predicting sepsis in-hospital mortality with machine learning: a multi-center study using clinical and inflammatory biomarkers,"Abstract Background This study aimed to develop and validate an interpretable machine-learning model that utilizes clinical features and inflammatory biomarkers to predict the risk of in-hospital mortality in critically ill patients suffering from sepsis. Methods We enrolled all patients diagnosed with sepsis in the Medical Information Mart for Intensive Care IV (MIMIC-IV, v.2.0), eICU Collaborative Research Care (eICU-CRD 2.0), and the Amsterdam University Medical Centers databases (AmsterdamUMCdb 1.0.2). LASSO regression was employed for feature selection. Seven machine-learning methods were applied to develop prognostic models. The optimal model was chosen based on its accuracy, F1 score and area under curve (AUC) in the validation cohort. Moreover, we utilized the SHapley Additive exPlanations (SHAP) method to elucidate the effects of the features attributed to the model and analyze how individual features affect the model’s output. Finally, Spearman correlation analysis examined the associations among continuous predictor variables. Restricted cubic splines (RCS) explored potential non-linear relationships between continuous risk factors and in-hospital mortality. Results 3535 patients with sepsis were eligible for participation in this study. The median age of the participants was 66 years (IQR, 55–77 years), and 56% were male. After selection, 12 of the 45 clinical parameters collected on the first day after ICU admission remained associated with prognosis and were used to develop machine-learning models. Among seven constructed models, the eXtreme Gradient Boosting (XGBoost) model achieved the best performance, with an AUC of 0.94 and an F1 score of 0.937 in the validation cohort. Feature importance analysis revealed that Age, AST, invasive ventilation treatment, and serum urea nitrogen (BUN) were the top four features of the XGBoost model with the most significant impact. Inflammatory biomarkers may have prognostic value. Furthermore, SHAP force analysis illustrated how the constructed model visualized the prediction of the model. Conclusions This study demonstrated the potential of machine-learning approaches for early prediction of outcomes in patients with sepsis. The SHAP method could improve the interoperability of machine-learning models and help clinicians better understand the reasoning behind the outcome.","['LASSO regression', 'eXtreme Gradient Boosting (XGBoost)', 'SHapley Additive exPlanations (SHAP)']",The study addresses the critical need to predict the risk of in-hospital mortality among critically ill patients suffering from sepsis by utilizing clinical features and inflammatory biomarkers. Early and accurate identification of patients at high risk of death could improve clinical decision-making and patient outcomes in intensive care settings. The primary aim of the study was to develop and validate a prognostic approach that uses clinical parameters and inflammatory biomarkers collected shortly after ICU admission to predict the likelihood of in-hospital mortality in patients with sepsis. This objective focuses on identifying key factors associated with prognosis to enhance early risk stratification and support timely interventions.
Medicine,Structural health monitoring on offshore jacket platforms using a novel ensemble deep learning model,"Monitoring health condition of offshore jacket platforms is crucial to prevent unexpected structural damages, where a prevailing challenge involves translating available feature information into structural damage patterns. Although the artificial neural network (ANN) models are popular in addressing this challenge, they often fail to capture the temporal correlations between the feature information and the damage patterns, which reduce their capability for discovering the laws governing the structural damage detection. To bridge this research gap, this study proposes a novel ensemble deep learning model to enhance the temporal feature extraction to improve the damage pattern identification. In this approach, a one-dimensional Convolutional Neural Network (CNN) extracts the spatiotemporal features from the structural vibration measurements. Simultaneously, a SENet attention mechanism is introduced to select the most informatic features. Subsequently, a bidirectional long short-term memory network (BiLSTM) is employed to learn the mapping between the extracted features and the structural damage patterns. Furthermore, the particle swarm optimization (PSO) algorithm is used to optimize the BiLSTM hyperparameters to enhance its stability and reliability. Both simulations and experiments are carried out to collect the vibration responses of the offshore jacket structure in different damage scenarios. The analysis results demonstrate that the proposed method produces remarkable improvement with respect to the accuracy and robustness in identifying the structural damages when compared with the ANNs. The overall detection accuracy of the proposed CNN-BiLSTM-Attention ensemble model is beyond 95%, which provides strong applicability to practical structural health monitoring of offshore platforms.","['artificial neural network (ANN)', 'ensemble deep learning model', 'one-dimensional Convolutional Neural Network (CNN)', 'SENet attention mechanism', 'bidirectional long short-term memory network (BiLSTM)', 'particle swarm optimization (PSO) algorithm']","The research idea centers on the critical need to monitor the health condition of offshore jacket platforms to prevent unexpected structural damages. A significant challenge in this area is effectively translating available feature information into accurate identification of structural damage patterns. Existing approaches often struggle to capture the temporal relationships between feature information and damage patterns, limiting their ability to uncover the underlying mechanisms of structural damage detection. The study aims to address this gap to improve the reliability of damage identification in offshore structures. The primary objective of the study is to enhance the identification of structural damage patterns by improving the extraction of temporal features from vibration measurements of offshore jacket platforms. The study seeks to develop a method that achieves higher accuracy and robustness in detecting structural damages across different damage scenarios, thereby providing a more reliable approach for practical structural health monitoring of offshore platforms."
Medicine,A study on smart home use intention of elderly consumers based on technology acceptance models,"Purpose Smart home devices have great potential to improve the quality of life and independence of older people, positively impacting their health, safety, and comfort. However, Chinese research in this field is still in its early stages. Therefore, more comprehensive and in-depth studies are needed to comprehend the various aspects influencing the acceptance and use of smart homes by older users. Patients and methods This study adopted the Technology Acceptance Model (TAM) and included perceived usefulness, perceived ease of use, usage intention, intergenerational technology support, perceived value, and perceived risk as extension variables to delve deeper into the behavioral intentions of older users in smart home services. The study used a convenience sampling method to randomly distribute 236 questionnaires among older adults over the age of 60 in the school’s community and neighboring urban communities who have experience in smart home use and who can complete human-computer interactions either independently or with the help of others, mainly focusing on the four sections: user characteristics, family situation, experience of use, and usage intention. The study used structural equation modeling (SEM) and factor analysis to analyze the completion of questionnaires. Finally, we conducted a validation analysis of the rationality and scientificity of the model and derived the six dimensions of the model of the influencing factors on the use of smart home products by the elderly and the weight sizes of their corresponding 13 influencing factors. Results The results show that perceived usefulness and perceived ease of use have a positive effect on users’ intention to use smart homes. Perceived ease of use has a positive effect on the perceived usefulness of smart homes. In addition, intergenerational technology support, perceived value, and perceived risk impact users’ perceived usefulness and perceived ease of use of the smart home. Conclusion This research aims to describe the factors influencing older users’ willingness to use smart homes. The findings are not only significant for the elderly in China but also of broad value to other regions and countries facing similar demographic challenges. The development of smart homes not only involves the elderly but is also closely related to all segments of society. The government should increase policy support and guide more social forces to participate in the development of the smart home industry. Service providers and designers should fully understand the demand situation and user experience of target users to develop easy-to-use smart home solutions. At the same time, smart homes, as intelligent products for the elderly, need to focus not only on the basic needs of the elderly such as material life and home safety, but also on the spiritual needs of elderly users. Children or caregivers should always pay attention to the psychological state of the elderly and actively guide them to use smart homes to help them realize their self-worth. We look forward to more research focusing on this area in the future and further exploring the specific issues and solutions involved.",['factor analysis'],"The research idea centers on the potential of smart home devices to enhance the quality of life, independence, health, safety, and comfort of older adults, particularly in the context of China where research on this topic remains limited. There is a need for more comprehensive and in-depth studies to understand the various factors that influence the acceptance and use of smart homes by elderly users. The study aims to describe the factors affecting older adults' willingness to use smart home technologies, recognizing that this issue is relevant not only in China but also in other regions facing similar demographic challenges. The research highlights the importance of addressing both the material and spiritual needs of the elderly to improve their experience with smart home products. The primary objective of the study is to identify and analyze the key factors influencing older users’ behavioral intentions toward using smart home services. This includes examining how perceived usefulness, ease of use, intergenerational support, perceived value, and perceived risk affect their willingness to adopt smart home technologies. The study seeks to provide insights that can guide policymakers, service providers, and designers in developing user-friendly smart home solutions that meet the diverse needs of the elderly population."
Medicine,An ensemble classification approach for cervical cancer prediction using behavioral risk factors,"Cervical cancer is a significant public health concern among females worldwide. Despite being preventable, it remains a leading cause of mortality. Early detection is crucial for successful treatment and improved survival rates. This study proposes an ensemble Machine Learning (ML) classifier for efficient and accurate identification of cervical cancer using medical data. The proposed methodology involves preparing two datasets using effective preprocessing techniques, extracting essential features using the scikit-learn package, and developing an ensemble classifier based on Random Forest, Support Vector Machine, Gaussian Naïve Bayes, and Decision Tree classifier traits. Comparison with other state-of-the-art algorithms using several ML techniques, including support vector machine, decision tree, random forest, Naïve Bayes, logistic regression, CatBoost, and AdaBoost, demonstrates that the proposed ensemble classifier outperforms them significantly, achieving accuracies of 98.06% and 95.45% for Dataset 1 and Dataset 2, respectively. The proposed ensemble classifier outperforms current state-of-the-art algorithms by 1.50% and 6.67% for Dataset 1 and Dataset 2, respectively, highlighting its superior performance compared to existing methods. The study also utilizes a five-fold cross-validation technique to analyze the benefits and drawbacks of the proposed methodology for predicting cervical cancer using medical data. The Receiver Operating Characteristic (ROC) curves with corresponding Area Under the Curve (AUC) values are 0.95 for Dataset 1 and 0.97 for Dataset 2, indicating the overall performance of the classifiers in distinguishing between the classes. Additionally, we employed SHapley Additive exPlanations (SHAP) as an Explainable Artificial Intelligence (XAI) technique to visualize the classifier's performance, providing insights into the important features contributing to cervical cancer identification. The results demonstrate that the proposed ensemble classifier can efficiently and accurately identify cervical cancer and potentially improve cervical cancer diagnosis and treatment.","['ensemble Machine Learning (ML) classifier', 'Random Forest', 'Support Vector Machine', 'Gaussian Naïve Bayes', 'Decision Tree classifier', 'support vector machine', 'decision tree', 'random forest', 'Naïve Bayes', 'logistic regression', 'CatBoost', 'AdaBoost', 'SHapley Additive exPlanations (SHAP)']","Cervical cancer is a significant public health concern among females worldwide and remains a leading cause of mortality despite being preventable. Early detection is crucial for successful treatment and improved survival rates. The study aims to develop an approach for efficient and accurate identification of cervical cancer using medical data. The primary objective is to improve cervical cancer diagnosis by proposing a method that can accurately distinguish between cases, thereby potentially enhancing treatment outcomes and patient survival."
Medicine,Comprehensive evaluation and performance analysis of machine learning in heart disease prediction,"Heart disease is a leading cause of mortality on a global scale. Accurately predicting cardiovascular disease poses a significant challenge within clinical data analysis. The present study introduces a prediction model that utilizes various combinations of information and employs multiple established classification approaches. The proposed technique combines the genetic algorithm (GA) and the recursive feature elimination method (RFEM) to select relevant features, thus enhancing the model's robustness. Techniques like the under sampling clustering oversampling method (USCOM) address the issue of data imbalance, thereby improving the model's predictive capabilities. The classification challenge employs a multilayer deep convolutional neural network (MLDCNN), trained using the adaptive elephant herd optimization method (AEHOM). The proposed machine learning-based heart disease prediction method (ML-HDPM) demonstrates outstanding performance across various crucial evaluation parameters, as indicated by its comprehensive assessment. During the training process, the ML-HDPM model exhibits a high level of performance, achieving an accuracy rate of 95.5% and a precision rate of 94.8%. The system's sensitivity (recall) performs with a high accuracy rate of 96.2%, while the F-score highlights its well-balanced performance, measuring 91.5%. It is worth noting that the specificity of ML-HDPM is recorded at a remarkable 89.7%. The findings underscore the potential of ML-HDPM to transform the prediction of heart disease and aid healthcare practitioners in providing precise diagnoses, exerting a substantial influence on patient care outcomes.","['genetic algorithm (GA)', 'multilayer deep convolutional neural network (MLDCNN)']","The study addresses the significant challenge of accurately predicting cardiovascular disease, which remains a leading cause of mortality worldwide. Improving the precision of heart disease diagnosis is crucial for enhancing patient care and outcomes. The primary aim of the study is to develop a method that effectively predicts heart disease by selecting relevant clinical features and addressing data imbalance issues. This approach seeks to provide healthcare practitioners with a reliable tool to support precise diagnoses and ultimately improve patient management."
Medicine,Enhancing breast cancer segmentation and classification: An Ensemble Deep Convolutional Neural Network and U-net approach on ultrasound images,"Breast cancer is a condition where the irregular growth of breast cells occurs uncontrollably, leading to the formation of tumors. It poses a significant threat to women's lives globally, emphasizing the need for enhanced methods of detecting and categorizing the disease. In this work, we propose an Ensemble Deep Convolutional Neural Network (EDCNN) model that exhibits superior accuracy compared to several transfer learning models and the Vision Transformer model. Our EDCNN model integrates the strengths of the MobileNet and Xception models to improve its performance in breast cancer detection and classification. We employ various preprocessing techniques, including image resizing, data normalization, and data augmentation, to prepare the data for analysis. By following these measures, the formatting is optimized, and the model's capacity to make generalizations is improved. We trained and evaluated our proposed EDCNN model using ultrasound images, a widely available modality for breast cancer imaging. The outcomes of our experiments illustrate that the EDCNN model attains an exceptional accuracy of 87.82% on Dataset 1 and 85.69% on Dataset 2, surpassing the performance of several well-known transfer learning models and the Vision Transformer model. Furthermore, an AUC value of 0.91 on Dataset 1 highlights the robustness and effectiveness of our proposed model. Moreover, we highlight the incorporation of the Grad-CAM Explainable Artificial Intelligence (XAI) technique to improve the interpretability and transparency of our proposed model. Additionally, we performed image segmentation using the U-Net segmentation technique on the input ultrasound images. This segmentation process allowed for the identification and isolation of specific regions of interest, facilitating a more comprehensive analysis of breast cancer characteristics. In conclusion, the study presents a creative approach to detecting and categorizing breast cancer, demonstrating the superior performance of the EDCNN model compared to well-established transfer learning models. Through advanced deep learning techniques and image segmentation, this study contributes to improving diagnosis and treatment outcomes in breast cancer.","['MobileNet', 'Xception', 'transfer learning models', 'Vision Transformer model', 'Grad-CAM Explainable Artificial Intelligence (XAI) technique', 'U-Net segmentation technique']","The research idea centers on addressing the significant threat breast cancer poses to women's lives worldwide by improving methods for detecting and categorizing the disease. Breast cancer involves the uncontrollable growth of breast cells leading to tumor formation, which necessitates enhanced diagnostic approaches to better identify and classify the condition. The study recognizes the importance of utilizing ultrasound imaging, a widely accessible modality, to aid in breast cancer diagnosis. The primary objective of the study is to develop and evaluate a novel approach that improves the accuracy and effectiveness of breast cancer detection and classification using ultrasound images. The study aims to demonstrate superior performance compared to existing methods, thereby contributing to better diagnosis and treatment outcomes for breast cancer patients."
Medicine,Employing machine learning for enhanced abdominal fat prediction in cavitation post-treatment,"This study investigates the application of cavitation in non-invasive abdominal fat reduction and body contouring, a topic of considerable interest in the medical and aesthetic fields. We explore the potential of cavitation to alter abdominal fat composition and delve into the optimization of fat prediction models using advanced hyperparameter optimization techniques, Hyperopt and Optuna. Our objective is to enhance the predictive accuracy of abdominal fat dynamics post-cavitation treatment. Employing a robust dataset with abdominal fat measurements and cavitation treatment parameters, we evaluate the efficacy of our approach through regression analysis. The performance of Hyperopt and Optuna regression models is assessed using metrics such as mean squared error, mean absolute error, and R-squared score. Our results reveal that both models exhibit strong predictive capabilities, with R-squared scores reaching 94.12% and 94.11% for post-treatment visceral fat, and 71.15% and 70.48% for post-treatment subcutaneous fat predictions, respectively. Additionally, we investigate feature selection techniques to pinpoint critical predictors within the fat prediction models. Techniques including F-value selection, mutual information, recursive feature elimination with logistic regression and random forests, variance thresholding, and feature importance evaluation are utilized. The analysis identifies key features such as BMI, waist circumference, and pretreatment fat levels as significant predictors of post-treatment fat outcomes. Our findings underscore the effectiveness of hyperparameter optimization in refining fat prediction models and offer valuable insights for the advancement of non-invasive fat reduction methods. This research holds important implications for both the scientific community and clinical practitioners, paving the way for improved treatment strategies in the realm of body contouring.","['mutual information', 'recursive feature elimination with logistic regression', 'recursive feature elimination with random forests', 'variance thresholding']","The study addresses the growing interest in non-invasive abdominal fat reduction and body contouring, focusing on the use of cavitation to alter abdominal fat composition. This area is significant in both medical and aesthetic fields due to the demand for effective and less invasive fat reduction methods. The research aims to improve the understanding of how cavitation treatment impacts abdominal fat dynamics. The primary objective of the study is to enhance the accuracy of predicting changes in abdominal fat following cavitation treatment by identifying key factors such as BMI, waist circumference, and pretreatment fat levels that influence post-treatment fat outcomes, thereby contributing to the development of more effective non-invasive fat reduction strategies."
Medicine,Advancements in Predictive Microbiology: Integrating New Technologies for Efficient Food Safety Models,"Predictive microbiology is a rapidly evolving field that has gained significant interest over the years due to its diverse application in food safety. Predictive models are widely used in food microbiology to estimate the growth of microorganisms in food products. These models represent the dynamic interactions between intrinsic and extrinsic food factors as mathematical equations and then apply these data to predict shelf life, spoilage, and microbial risk assessment. Due to their ability to predict the microbial risk, these tools are also integrated into hazard analysis critical control point (HACCP) protocols. However, like most new technologies, several limitations have been linked to their use. Predictive models have been found incapable of modeling the intricate microbial interactions in food colonized by different bacteria populations under dynamic environmental conditions. To address this issue, researchers are integrating several new technologies into predictive models to improve efficiency and accuracy. Increasingly, newer technologies such as whole genome sequencing (WGS), metagenomics, artificial intelligence, and machine learning are being rapidly adopted into newer-generation models. This has facilitated the development of devices based on robotics, the Internet of Things, and time-temperature indicators that are being incorporated into food processing both domestically and industrially globally. This study reviewed current research on predictive models, limitations, challenges, and newer technologies being integrated into developing more efficient models. Machine learning algorithms commonly employed in predictive modeling are discussed with emphasis on their application in research and industry and their advantages over traditional models.",['machine learning'],"The research idea centers on the importance of predictive microbiology in food safety, particularly its role in estimating the growth of microorganisms in food products to predict shelf life, spoilage, and microbial risk. Despite their widespread use and integration into hazard analysis critical control point (HACCP) protocols, current predictive models face limitations in accurately representing complex microbial interactions under dynamic environmental conditions. The study aims to review the current state of predictive models in food microbiology, focusing on their limitations and challenges. Its primary objective is to evaluate recent advancements and technologies integrated into predictive models to enhance their efficiency and accuracy in assessing microbial risks in food safety."
Medicine,Detection of Parkinson disease using multiclass machine learning approach,"Parkinson's Disease (PD) is a prevalent neurological condition characterized by motor and cognitive impairments, typically manifesting around the age of 50 and presenting symptoms such as gait difficulties and speech impairments. Although a cure remains elusive, symptom management through medication is possible. Timely detection is pivotal for effective disease management. In this study, we leverage Machine Learning (ML) and Deep Learning (DL) techniques, specifically K-Nearest Neighbor (KNN) and Feed-forward Neural Network (FNN) models, to differentiate between individuals with PD and healthy individuals based on voice signal characteristics. Our dataset, sourced from the University of California at Irvine (UCI), comprises 195 voice recordings collected from 31 patients. To optimize model performance, we employ various strategies including Synthetic Minority Over-sampling Technique (SMOTE) for addressing class imbalance, Feature Selection to identify the most relevant features, and hyperparameter tuning using RandomizedSearchCV. Our experimentation reveals that the FNN and KSVM models, trained on an 80-20 split of the dataset for training and testing respectively, yield the most promising results. The FNN model achieves an impressive overall accuracy of 99.11%, with 98.78% recall, 99.96% precision, and a 99.23% f1-score. Similarly, the KSVM model demonstrates strong performance with an overall accuracy of 95.89%, recall of 96.88%, precision of 98.71%, and an f1-score of 97.62%. Overall, our study showcases the efficacy of ML and DL techniques in accurately identifying PD from voice signals, underscoring the potential for these approaches to contribute significantly to early diagnosis and intervention strategies for Parkinson's Disease.","['K-Nearest Neighbor (KNN)', 'Feed-forward Neural Network (FNN)', 'Feature Selection', 'RandomizedSearchCV', 'KSVM']","Parkinson's Disease (PD) is a common neurological disorder marked by motor and cognitive impairments, including gait difficulties and speech impairments, typically appearing around the age of 50. Although there is no cure, managing symptoms through medication is possible, and timely detection is crucial for effective disease management. The study aims to differentiate individuals with Parkinson's Disease from healthy individuals by analyzing characteristics of voice signals. The primary objective is to accurately identify Parkinson's Disease at an early stage to support diagnosis and intervention strategies."
Medicine,Deep learning empowered breast cancer diagnosis: Advancements in detection and classification,"Recent advancements in AI, driven by big data technologies, have reshaped various industries, with a strong focus on data-driven approaches. This has resulted in remarkable progress in fields like computer vision, e-commerce, cybersecurity, and healthcare, primarily fueled by the integration of machine learning and deep learning models. Notably, the intersection of oncology and computer science has given rise to Computer-Aided Diagnosis (CAD) systems, offering vital tools to aid medical professionals in tumor detection, classification, recurrence tracking, and prognosis prediction. Breast cancer, a significant global health concern, is particularly prevalent in Asia due to diverse factors like lifestyle, genetics, environmental exposures, and healthcare accessibility. Early detection through mammography screening is critical, but the accuracy of mammograms can vary due to factors like breast composition and tumor characteristics, leading to potential misdiagnoses. To address this, an innovative CAD system leveraging deep learning and computer vision techniques was introduced. This system enhances breast cancer diagnosis by independently identifying and categorizing breast lesions, segmenting mass lesions, and classifying them based on pathology. Thorough validation using the Curated Breast Imaging Subset of Digital Database for Screening Mammography (CBIS-DDSM) demonstrated the CAD system’s exceptional performance, with a 99% success rate in detecting and classifying breast masses. While the accuracy of detection is 98.5%, when segmenting breast masses into separate groups for examination, the method’s performance was approximately 95.39%. Upon completing all the analysis, the system’s classification phase yielded an overall accuracy of 99.16% for classification. The potential for this integrated framework to outperform current deep learning techniques is proposed, despite potential challenges related to the high number of trainable parameters. Ultimately, this recommended framework offers valuable support to researchers and physicians in breast cancer diagnosis by harnessing cutting-edge AI and image processing technologies, extending recent advances in deep learning to the medical domain.",['deep learning'],"The study addresses the critical challenge of improving the accuracy of breast cancer diagnosis through mammography screening, which is essential due to the variability in mammogram interpretation caused by factors such as breast composition and tumor characteristics. Breast cancer remains a significant global health concern, especially in Asia, where diverse factors influence its prevalence, making early and precise detection vital to reduce misdiagnoses and improve patient outcomes. The primary aim of the study is to enhance breast cancer diagnosis by developing a method that can independently identify, categorize, and segment breast lesions based on pathology, thereby supporting medical professionals in more accurate detection and classification of breast masses. This approach seeks to provide valuable assistance to researchers and physicians in breast cancer diagnosis, ultimately improving the effectiveness of mammography screening."
Medicine,Brain structure ages—A new biomarker for multi‐disease classification,"Age is an important variable to describe the expected brain's anatomy status across the normal aging trajectory. The deviation from that normative aging trajectory may provide some insights into neurological diseases. In neuroimaging, predicted brain age is widely used to analyze different diseases. However, using only the brain age gap information (i.e., the difference between the chronological age and the estimated age) can be not enough informative for disease classification problems. In this paper, we propose to extend the notion of global brain age by estimating brain structure ages using structural magnetic resonance imaging. To this end, an ensemble of deep learning models is first used to estimate a 3D aging map (i.e., voxel-wise age estimation). Then, a 3D segmentation mask is used to obtain the final brain structure ages. This biomarker can be used in several situations. First, it enables to accurately estimate the brain age for the purpose of anomaly detection at the population level. In this situation, our approach outperforms several state-of-the-art methods. Second, brain structure ages can be used to compute the deviation from the normal aging process of each brain structure. This feature can be used in a multi-disease classification task for an accurate differential diagnosis at the subject level. Finally, the brain structure age deviations of individuals can be visualized, providing some insights about brain abnormality and helping clinicians in real medical contexts.",['ensemble of deep learning models'],"The research idea centers on the importance of age as a variable to describe the expected status of brain anatomy throughout the normal aging process, with deviations from this normative trajectory potentially offering insights into neurological diseases. Current approaches that use only the difference between chronological age and estimated brain age may not provide sufficient information for disease classification. The study aims to improve understanding of brain aging by estimating the ages of specific brain structures, which could enhance the detection of anomalies and support differential diagnosis of multiple diseases. The primary objective of the study is to accurately estimate brain structure ages using structural magnetic resonance imaging to identify deviations from normal aging processes at both the population and individual levels. This approach seeks to enable more precise anomaly detection, improve multi-disease classification, and provide visualizations that assist clinicians in identifying brain abnormalities in real medical contexts."
Medicine,Toward Improving Breast Cancer Classification Using an Adaptive Voting Ensemble Learning Algorithm,"Over the past decade, breast cancer has been the most common type of cancer in women. Different methods were proposed for breast cancer detection. These methods mainly classify and categorize malignant and Benign tumors. Machine learning is a practical approach for breast cancer classification. Data mining and classification are effective methods to predict and categorize breast cancer. The optimum classification for detecting Breast Cancer (BC) is ensemble-based. The ensemble approach involves using multiple ways to find the best possible solution. This study used the Wisconsin Breast Cancer Diagnostic (WBCD) dataset. We created a voting ensemble classifier that combines four different machine learning models: Extra Trees Classifier (ETC), Light Gradient Boosting Machine (LightGBM), Ridge Classifier (RC), and Linear Discriminant Analysis (LDA). The proposed ELRL-E approach achieved an accuracy of 97.6%, a precision of 96.4%, a recall of 100%, and an F1 score of 98.1%. Various output evaluations are used to evaluate the performance and efficiency of the proposed model and other classifiers. Overall, the recommended strategy performed better. Results are directly compared with the individual classifier and different recognized state-of-the-art classifiers. The primary objective of this study is to identify the most influential ensemble machine learning classifier for breast cancer detection and diagnosis in terms of accuracy and AUC score.","['Machine learning', 'ensemble-based classification', 'voting ensemble classifier', 'Extra Trees Classifier (ETC)', 'Light Gradient Boosting Machine (LightGBM)', 'Ridge Classifier (RC)', 'Linear Discriminant Analysis (LDA)']","Breast cancer has been the most common type of cancer in women over the past decade, and accurate detection and classification of malignant and benign tumors remain critical challenges. Various methods have been proposed to improve breast cancer detection, aiming to enhance the ability to correctly categorize tumor types for better diagnosis and treatment planning. The primary objective of this study is to identify the most effective approach for breast cancer detection and diagnosis by evaluating different classification strategies in terms of accuracy and diagnostic performance. This study specifically aims to determine which classification method provides the highest accuracy and reliability for breast cancer identification."
Medicine,"The Prediction of Clinical Mastitis in Dairy Cows Based on Milk Yield, Rumination Time, and Milk Electrical Conductivity Using Machine Learning Algorithms","In commercial dairy farms, mastitis is associated with increased antimicrobial use and associated resistance, which may affect milk production. This study aimed to develop sensor-based prediction models for naturally occurring clinical bovine mastitis using nine machine learning algorithms with data from 447 mastitic and 2146 healthy cows obtained from five commercial farms in Northeast China. The variables were related to daily activity, rumination time, and daily milk yield of cows, as well as milk electrical conductivity. Both Z-standardized and non-standardized datasets pertaining to four specific stages of lactation were used to train and test prediction models. For all four subgroups, the Z-standardized dataset yielded better results than those of the non-standardized one, with the multilayer artificial neural net algorithm showing the best performance. Variables of importance had a similar rank in this algorithm, indicating the consistency of these variables as predictors for bovine mastitis in commercial farms with similar automatic systems. Moreover, the peak milk yield (PMY) of mastitic cows was significantly higher than that of healthy cows (p &lt; 0.005), indicating that high-yielding cattle are more prone to mastitis. Our results show that machine learning algorithms are effective tools for predicting mastitis in dairy cows for immediate intervention and management in commercial farms.",['multilayer artificial neural net algorithm'],"The research idea addresses the problem of mastitis in commercial dairy farms, which is linked to increased antimicrobial use and resistance, potentially impacting milk production. Mastitis poses a significant challenge to dairy farming due to its effects on animal health and productivity. The study’s primary objective is to develop prediction models for naturally occurring clinical bovine mastitis using data related to cows’ daily activity, rumination time, milk yield, and milk electrical conductivity. This aims to enable early detection and timely intervention for mastitis in commercial dairy farms to improve management and reduce negative outcomes."
Medicine,"Machine learning in physical activity, sedentary, and sleep behavior research","Abstract The nature of human movement and non-movement behaviors is complex and multifaceted, making their study complicated and challenging. Thanks to the availability of wearable activity monitors, we can now monitor the full spectrum of physical activity, sedentary, and sleep behaviors better than ever before—whether the subjects are elite athletes, children, adults, or individuals with pre-existing medical conditions. The increasing volume of generated data, combined with the inherent complexities of human movement and non-movement behaviors, necessitates the development of new data analysis methods for the research of physical activity, sedentary, and sleep behaviors. The characteristics of machine learning (ML) methods, including their ability to deal with complicated data, make them suitable for such analysis and thus can be an alternative tool to deal with data of this nature. ML can potentially be an excellent tool for solving many traditional problems related to the research of physical activity, sedentary, and sleep behaviors such as activity recognition, posture detection, profile analysis, and correlates research. However, despite this potential, ML has not yet been widely utilized for analyzing and studying these behaviors. In this review, we aim to introduce experts in physical activity, sedentary behavior, and sleep research—individuals who may possess limited familiarity with ML—to the potential applications of these techniques for analyzing their data. We begin by explaining the underlying principles of the ML modeling pipeline, highlighting the challenges and issues that need to be considered when applying ML. We then present the types of ML: supervised and unsupervised learning, and introduce a few ML algorithms frequently used in supervised and unsupervised learning. Finally, we highlight three research areas where ML methodologies have already been used in physical activity, sedentary behavior, and sleep behavior research, emphasizing their successes and challenges. This paper serves as a resource for ML in physical activity, sedentary, and sleep behavior research, offering guidance and resources to facilitate its utilization.","['machine learning (ML)', 'supervised learning', 'unsupervised learning']","The study addresses the complexity and multifaceted nature of human movement and non-movement behaviors, which makes their investigation challenging. With the advent of wearable activity monitors, it is now possible to better monitor the full spectrum of physical activity, sedentary behavior, and sleep across diverse populations, including elite athletes, children, adults, and individuals with pre-existing medical conditions. However, the increasing volume and complexity of the data generated from these monitors require new approaches to effectively study these behaviors. The primary aim of the study is to introduce experts in physical activity, sedentary behavior, and sleep research to the potential applications of advanced analytical techniques for examining their data. The study seeks to provide guidance and resources to facilitate the utilization of these approaches in research, highlighting their successes and challenges in the context of physical activity, sedentary, and sleep behavior studies."
Medicine,Enhanced Jaya Optimization Algorithm with Deep Learning Assisted Oral Cancer Diagnosis on IoT Healthcare Systems,"Recently, healthcare systems integrate the power of deep learning (DL) models with the connectivity and data processing capabilities of the Internet of Things (IoT) to enhance the early recognition and diagnosis of disease. Oral cancer diagnosis comprises the detection of cancerous or pre-cancerous abrasions in the oral cavity. Timely identification is essential for successful treatment and enhanced prognosis. Here is an overview of the key aspects of oral cancer diagnosis. One potential benefit of utilizing DL for oral cancer detection is that it analyses huge counts of data fast and accurately, and it could not need clear programming of the rules for recognizing abnormalities. This can create the procedure of detecting oral cancer more effective and efficient. Thus, the study presents an Enhanced Jaya Optimization Algorithm with Deep Learning Based Oral Cancer Classification (EJOADL-OCC) method. The presented EJOADL-OCC method aims to classify and detect the existence of oral cancer accurately and effectively. To accomplish this, the presented EJOADL-OCC method initially exploits median filtering for the noise elimination. Next, the feature vector generation process is performed by the residual network (ResNetv2) model with EJOA as a hyperparameter optimizer. For accurate classification of oral cancer, a continuously restricted Boltzmann machine with a deep belief network (CRBM-DBN) model. The simulated validation of the EJOADL-OCC algorithm is tested by the series of simulations and the outcome demonstrates its supremacy over present DL approaches.","['Deep Learning (DL)', 'Residual Network (ResNetv2)']","The research idea focuses on improving the early recognition and diagnosis of oral cancer, which involves detecting cancerous or pre-cancerous lesions in the oral cavity. Timely identification of oral cancer is crucial for successful treatment and better prognosis, highlighting the need for more effective and efficient diagnostic methods. The primary objective of the study is to develop a method that accurately and effectively classifies and detects the presence of oral cancer. This aims to enhance the diagnostic process by improving the accuracy and efficiency of oral cancer detection."
Medicine,Discovering biomarkers associated and predicting cardiovascular disease with high accuracy using a novel nexus of machine learning techniques for precision medicine,"Abstract Personalized interventions are deemed vital given the intricate characteristics, advancement, inherent genetic composition, and diversity of cardiovascular diseases (CVDs). The appropriate utilization of artificial intelligence (AI) and machine learning (ML) methodologies can yield novel understandings of CVDs, enabling improved personalized treatments through predictive analysis and deep phenotyping. In this study, we proposed and employed a novel approach combining traditional statistics and a nexus of cutting-edge AI/ML techniques to identify significant biomarkers for our predictive engine by analyzing the complete transcriptome of CVD patients. After robust gene expression data pre-processing, we utilized three statistical tests (Pearson correlation, Chi-square test, and ANOVA) to assess the differences in transcriptomic expression and clinical characteristics between healthy individuals and CVD patients. Next, the recursive feature elimination classifier assigned rankings to transcriptomic features based on their relation to the case–control variable. The top ten percent of commonly observed significant biomarkers were evaluated using four unique ML classifiers (Random Forest, Support Vector Machine, Xtreme Gradient Boosting Decision Trees, and k-Nearest Neighbors). After optimizing hyperparameters, the ensembled models, which were implemented using a soft voting classifier, accurately differentiated between patients and healthy individuals. We have uncovered 18 transcriptomic biomarkers that are highly significant in the CVD population that were used to predict disease with up to 96% accuracy. Additionally, we cross-validated our results with clinical records collected from patients in our cohort. The identified biomarkers served as potential indicators for early detection of CVDs. With its successful implementation, our newly developed predictive engine provides a valuable framework for identifying patients with CVDs based on their biomarker profiles.","['Random Forest', 'Support Vector Machine', 'Xtreme Gradient Boosting Decision Trees', 'k-Nearest Neighbors', 'soft voting classifier']","The study addresses the complexity and diversity of cardiovascular diseases (CVDs), emphasizing the need for personalized interventions due to the intricate characteristics, progression, and genetic composition of these conditions. It highlights the importance of identifying significant biomarkers that can improve the understanding and treatment of CVDs. The primary aim of the study is to identify significant transcriptomic biomarkers associated with cardiovascular diseases by analyzing gene expression differences between healthy individuals and CVD patients. The study seeks to uncover potential indicators for early detection of CVDs and to provide a framework for accurately distinguishing patients with CVDs based on their biomarker profiles."
Medicine,Chatbots and Large Language Models in Radiology: A Practical Primer for Clinical and Research Applications,"Although chatbots have existed for decades, the emergence of transformer-based large language models (LLMs) has captivated the world through the most recent wave of artificial intelligence chatbots, including ChatGPT. Transformers are a type of neural network architecture that enables better contextual understanding of language and efficient training on massive amounts of unlabeled data, such as unstructured text from the internet. As LLMs have increased in size, their improved performance and emergent abilities have revolutionized natural language processing. Since language is integral to human thought, applications based on LLMs have transformative potential in many industries. In fact, LLM-based chatbots have demonstrated human-level performance on many professional benchmarks, including in radiology. LLMs offer numerous clinical and research applications in radiology, several of which have been explored in the literature with encouraging results. Multimodal LLMs can simultaneously interpret text and images to generate reports, closely mimicking current diagnostic pathways in radiology. Thus, from requisition to report, LLMs have the opportunity to positively impact nearly every step of the radiology journey. Yet, these impressive models are not without limitations. This article reviews the limitations of LLMs and mitigation strategies, as well as potential uses of LLMs, including multimodal models. Also reviewed are existing LLM-based applications that can enhance efficiency in supervised settings.","['transformer-based large language models (LLMs)', 'Transformers', 'Multimodal LLMs']","The research idea centers on the transformative potential of advanced language-based technologies in the field of radiology, highlighting their ability to understand and generate human-like language and to interpret both text and images in a manner that closely mimics current diagnostic processes. These technologies have demonstrated human-level performance on professional benchmarks and offer numerous clinical and research applications that could positively impact nearly every step of the radiology workflow, from requisition to report. The study aims to address the limitations of these technologies and explore strategies to mitigate them while examining their potential uses in enhancing efficiency within supervised clinical settings. The primary objective of the study is to review the limitations and mitigation strategies of these advanced language-based models, as well as to evaluate existing applications that utilize these models to improve efficiency and effectiveness in radiology practice."
Medicine,Improving large language models for clinical named entity recognition via prompt engineering,"Abstract Importance The study highlights the potential of large language models, specifically GPT-3.5 and GPT-4, in processing complex clinical data and extracting meaningful information with minimal training data. By developing and refining prompt-based strategies, we can significantly enhance the models’ performance, making them viable tools for clinical NER tasks and possibly reducing the reliance on extensive annotated datasets. Objectives This study quantifies the capabilities of GPT-3.5 and GPT-4 for clinical named entity recognition (NER) tasks and proposes task-specific prompts to improve their performance. Materials and Methods We evaluated these models on 2 clinical NER tasks: (1) to extract medical problems, treatments, and tests from clinical notes in the MTSamples corpus, following the 2010 i2b2 concept extraction shared task, and (2) to identify nervous system disorder-related adverse events from safety reports in the vaccine adverse event reporting system (VAERS). To improve the GPT models' performance, we developed a clinical task-specific prompt framework that includes (1) baseline prompts with task description and format specification, (2) annotation guideline-based prompts, (3) error analysis-based instructions, and (4) annotated samples for few-shot learning. We assessed each prompt's effectiveness and compared the models to BioClinicalBERT. Results Using baseline prompts, GPT-3.5 and GPT-4 achieved relaxed F1 scores of 0.634, 0.804 for MTSamples and 0.301, 0.593 for VAERS. Additional prompt components consistently improved model performance. When all 4 components were used, GPT-3.5 and GPT-4 achieved relaxed F1 socres of 0.794, 0.861 for MTSamples and 0.676, 0.736 for VAERS, demonstrating the effectiveness of our prompt framework. Although these results trail BioClinicalBERT (F1 of 0.901 for the MTSamples dataset and 0.802 for the VAERS), it is very promising considering few training samples are needed. Discussion The study’s findings suggest a promising direction in leveraging LLMs for clinical NER tasks. However, while the performance of GPT models improved with task-specific prompts, there's a need for further development and refinement. LLMs like GPT-4 show potential in achieving close performance to state-of-the-art models like BioClinicalBERT, but they still require careful prompt engineering and understanding of task-specific knowledge. The study also underscores the importance of evaluation schemas that accurately reflect the capabilities and performance of LLMs in clinical settings. Conclusion While direct application of GPT models to clinical NER tasks falls short of optimal performance, our task-specific prompt framework, incorporating medical knowledge and training samples, significantly enhances GPT models' feasibility for potential clinical applications.","['GPT-3.5', 'GPT-4', 'prompt-based strategies', 'few-shot learning', 'BioClinicalBERT']","The research idea centers on addressing the challenge of effectively extracting meaningful clinical information, such as medical problems, treatments, tests, and adverse events, from complex clinical data with minimal reliance on extensive annotated datasets. The study highlights the potential to improve clinical named entity recognition (NER) tasks by developing strategies that enhance performance despite limited training data. The primary objective of the study is to quantify the capabilities of specific language models for clinical NER tasks and to propose task-specific strategies aimed at improving their performance in extracting relevant clinical concepts from clinical notes and safety reports. This includes evaluating the effectiveness of these strategies in enhancing the identification of medical entities related to nervous system disorder adverse events and other clinical information."
Medicine,Solving olympiad geometry without human demonstrations,"Abstract Proving mathematical theorems at the olympiad level represents a notable milestone in human-level automated reasoning 1–4 , owing to their reputed difficulty among the world’s best talents in pre-university mathematics. Current machine-learning approaches, however, are not applicable to most mathematical domains owing to the high cost of translating human proofs into machine-verifiable format. The problem is even worse for geometry because of its unique translation challenges 1,5 , resulting in severe scarcity of training data. We propose AlphaGeometry, a theorem prover for Euclidean plane geometry that sidesteps the need for human demonstrations by synthesizing millions of theorems and proofs across different levels of complexity. AlphaGeometry is a neuro-symbolic system that uses a neural language model, trained from scratch on our large-scale synthetic data, to guide a symbolic deduction engine through infinite branching points in challenging problems. On a test set of 30 latest olympiad-level problems, AlphaGeometry solves 25, outperforming the previous best method that only solves ten problems and approaching the performance of an average International Mathematical Olympiad (IMO) gold medallist. Notably, AlphaGeometry produces human-readable proofs, solves all geometry problems in the IMO 2000 and 2015 under human expert evaluation and discovers a generalized version of a translated IMO theorem in 2004.","['neural language model', 'neuro-symbolic system']","The research idea addresses the significant challenge of proving complex mathematical theorems in Euclidean plane geometry, which are known for their difficulty even among top pre-university talents. There is a notable scarcity of training data for geometry due to the unique difficulties in translating human proofs into a verifiable format, hindering progress in automated reasoning for this domain. The study aims to overcome these obstacles by generating a large number of theorems and proofs across varying levels of complexity to facilitate advancements in theorem proving. The primary objective of the study is to develop a system capable of solving high-level geometry problems, such as those found in mathematical olympiads, and to produce human-readable proofs that demonstrate performance comparable to expert human mathematicians."
Medicine,The Image Biomarker Standardization Initiative: Standardized Convolutional Filters for Reproducible Radiomics and Enhanced Clinical Insights,"Filters are commonly used to enhance specific structures and patterns in images, such as vessels or peritumoral regions, to enable clinical insights beyond the visible image using radiomics. However, their lack of standardization restricts reproducibility and clinical translation of radiomics decision support tools. In this special report, teams of researchers who developed radiomics software participated in a three-phase study (September 2020 to December 2022) to establish a standardized set of filters. The first two phases focused on finding reference filtered images and reference feature values for commonly used convolutional filters: mean, Laplacian of Gaussian, Laws and Gabor kernels, separable and nonseparable wavelets (including decomposed forms), and Riesz transformations. In the first phase, 15 teams used digital phantoms to establish 33 reference filtered images of 36 filter configurations. In phase 2, 11 teams used a chest CT image to derive reference values for 323 of 396 features computed from filtered images using 22 filter and image processing configurations. Reference filtered images and feature values for Riesz transformations were not established. Reproducibility of standardized convolutional filters was validated on a public data set of multimodal imaging (CT, fluorodeoxyglucose PET, and T1-weighted MRI) in 51 patients with soft-tissue sarcoma. At validation, reproducibility of 486 features computed from filtered images using nine configurations × three imaging modalities was assessed using the lower bounds of 95% CIs of intraclass correlation coefficients. Out of 486 features, 458 were found to be reproducible across nine teams with lower bounds of 95% CIs of intraclass correlation coefficients greater than 0.75. In conclusion, eight filter types were standardized with reference filtered images and reference feature values for verifying and calibrating radiomics software packages. A web-based tool is available for compliance checking. © RSNA, 2024 Supplemental material is available for this article. See also the editorial by Huisman and D'Antonoli in this issue.",['nonseparable wavelets'],"The research idea addresses the challenge that filters used to enhance specific structures and patterns in medical images, such as vessels or peritumoral regions, lack standardization, which limits the reproducibility and clinical translation of radiomics decision support tools. This lack of consistency hinders the ability to reliably use radiomics features derived from filtered images for clinical insights. The primary objective of the study was to establish a standardized set of filters by creating reference filtered images and reference feature values for commonly used convolutional filters. The study aimed to validate the reproducibility of these standardized filters across multiple imaging modalities and teams, ultimately providing a foundation for verifying and calibrating radiomics software packages to improve clinical reliability."
Medicine,"Revolutionizing agriculture with artificial intelligence: plant disease detection methods, applications, and their limitations","Accurate and rapid plant disease detection is critical for enhancing long-term agricultural yield. Disease infection poses the most significant challenge in crop production, potentially leading to economic losses. Viruses, fungi, bacteria, and other infectious organisms can affect numerous plant parts, including roots, stems, and leaves. Traditional techniques for plant disease detection are time-consuming, require expertise, and are resource-intensive. Therefore, automated leaf disease diagnosis using artificial intelligence (AI) with Internet of Things (IoT) sensors methodologies are considered for the analysis and detection. This research examines four crop diseases: tomato, chilli, potato, and cucumber. It also highlights the most prevalent diseases and infections in these four types of vegetables, along with their symptoms. This review provides detailed predetermined steps to predict plant diseases using AI. Predetermined steps include image acquisition, preprocessing, segmentation, feature selection, and classification. Machine learning (ML) and deep understanding (DL) detection models are discussed. A comprehensive examination of various existing ML and DL-based studies to detect the disease of the following four crops is discussed, including the datasets used to evaluate these studies. We also provided the list of plant disease detection datasets. Finally, different ML and DL application problems are identified and discussed, along with future research prospects, by combining AI with IoT platforms like smart drones for field-based disease detection and monitoring. This work will help other practitioners in surveying different plant disease detection strategies and the limits of present systems.","['feature selection', 'machine learning (ML)', 'deep learning (DL)']","The research idea centers on the critical need for accurate and rapid detection of plant diseases to improve long-term agricultural yield, as disease infections caused by viruses, fungi, bacteria, and other infectious organisms pose significant challenges in crop production and can lead to economic losses. Traditional methods for detecting plant diseases are often time-consuming, require specialized expertise, and demand considerable resources, highlighting the necessity for more efficient approaches. The primary objective of the study is to examine and review the most prevalent diseases affecting four key crops—tomato, chilli, potato, and cucumber—along with their symptoms, and to provide a comprehensive overview of existing strategies for plant disease detection. This includes detailing predetermined steps for disease diagnosis and discussing the limitations of current detection methods to guide future research and practical applications in the field."
Medicine,Can large language models replace humans in systematic reviews? Evaluating <scp>GPT</scp>‐4's efficacy in screening and extracting data from peer‐reviewed and grey literature in multiple languages,"Systematic reviews are vital for guiding practice, research and policy, although they are often slow and labour-intensive. Large language models (LLMs) could speed up and automate systematic reviews, but their performance in such tasks has yet to be comprehensively evaluated against humans, and no study has tested Generative Pre-Trained Transformer (GPT)-4, the biggest LLM so far. This pre-registered study uses a ""human-out-of-the-loop"" approach to evaluate GPT-4's capability in title/abstract screening, full-text review and data extraction across various literature types and languages. Although GPT-4 had accuracy on par with human performance in some tasks, results were skewed by chance agreement and dataset imbalance. Adjusting for these caused performance scores to drop across all stages: for data extraction, performance was moderate, and for screening, it ranged from none in highly balanced literature datasets (~1:1) to moderate in those datasets where the ratio of inclusion to exclusion in studies was imbalanced (~1:3). When screening full-text literature using highly reliable prompts, GPT-4's performance was more robust, reaching ""human-like"" levels. Although our findings indicate that, currently, substantial caution should be exercised if LLMs are being used to conduct systematic reviews, they also offer preliminary evidence that, for certain review tasks delivered under specific conditions, LLMs can rival human performance.",['Generative Pre-Trained Transformer (GPT)-4'],"The research idea centers on the importance of systematic reviews for guiding clinical practice, research, and policy, while highlighting the challenges posed by their slow and labor-intensive nature. There is a need to explore ways to improve the efficiency of conducting systematic reviews without compromising accuracy. The study’s primary objective is to evaluate the capability of a large language model, specifically GPT-4, in performing key tasks involved in systematic reviews such as title and abstract screening, full-text review, and data extraction across diverse types of literature and languages. The aim is to compare its performance against human reviewers to determine whether it can reliably assist or potentially replace humans in these tasks under certain conditions."
Medicine,Improved Support Vector Machine based on CNN-SVD for vision-threatening diabetic retinopathy detection and classification,"The integration of artificial intelligence (AI) in diagnosing diabetic retinopathy, a major contributor to global vision impairment, is becoming increasingly pronounced. Notably, the detection of vision-threatening diabetic retinopathy (VTDR) has been significantly fortified through automated techniques. Traditionally, the reliance on manual analysis of retinal images, albeit slow and error-prone, constituted the conventional approach. Addressing this, our study introduces a novel methodology that amplifies the robustness and precision of the detection process. This is complemented by the groundbreaking Hierarchical Block Attention (HBA) and HBA-U-Net architecture, which notably propel attention mechanisms in image segmentation. This innovative model refines image processing without imposing excessive computational demands by honing in on individual pixel intricacies, spatial relationships, and channel-specific attention. Building upon this innovation, our proposed method employs a multi-stage strategy encompassing data pre-processing, feature extraction via a hybrid CNN-SVD model, and classification employing an amalgamation of Improved Support Vector Machine-Radial Basis Function (ISVM-RBF), DT, and KNN techniques. Rigorously tested on the IDRiD dataset classified into five severity tiers, the hybrid model yields remarkable performance, achieving a 99.18% accuracy, 98.15% sensitivity, and 100% specificity in VTDR detection, thus surpassing existing methods. These results underscore a more potent avenue for diagnosing and addressing this crucial ocular condition while underscoring AI's transformative potential in medical care, particularly in ophthalmology.","['hybrid CNN-SVD model', 'DT', 'KNN']","The study addresses the challenge of diagnosing diabetic retinopathy, a leading cause of vision impairment worldwide, with a particular focus on detecting vision-threatening diabetic retinopathy (VTDR). Traditional methods relying on manual analysis of retinal images are slow and prone to errors, highlighting the need for more accurate and efficient detection approaches. The primary aim of the study is to enhance the robustness and precision of VTDR detection by introducing an improved methodology that refines the diagnostic process. This approach seeks to provide a more effective means of diagnosing and managing this critical ocular condition, ultimately contributing to better patient outcomes in ophthalmology."
Medicine,Convolutional neural network classification of cancer cytopathology images: taking breast cancer as an example,"Breast cancer is a relatively common cancer among gynecological cancers. Its diagnosis often relies on the pathology of cells in the lesion. The pathological diagnosis of breast cancer not only requires professionals and time, but also sometimes involves subjective judgment. To address the challenges of dependence on pathologists expertise and the time-consuming nature of achieving accurate breast pathological image classification, this paper introduces an approach utilizing convolutional neural networks (CNNs) for the rapid categorization of pathological images, aiming to enhance the efficiency of breast pathological image detection. And the approach enables the rapid and automatic classification of pathological images into benign and malignant groups. The methodology involves utilizing a convolutional neural network (CNN) model leveraging the Inceptionv3 architecture and transfer learning algorithm for extracting features from pathological images. Utilizing a neural network with fully connected layers and employing the SoftMax function for image classification. Additionally, the concept of image partitioning is introduced to handle high-resolution images. To achieve the ultimate classification outcome, the classification probabilities of each image block are aggregated using three algorithms: summation, product, and maximum. Experimental validation was conducted on the BreaKHis public dataset, resulting in accuracy rates surpassing 0.92 across all four magnification coefficients (40X, 100X, 200X, and 400X). It demonstrates that the proposed method effectively enhances the accuracy in classifying pathological images of breast cancer.","['convolutional neural networks (CNNs)', 'Inceptionv3 architecture', 'transfer learning algorithm', 'neural network with fully connected layers']","The research idea addresses the challenges in diagnosing breast cancer through pathological examination, which requires specialized expertise, is time-consuming, and can involve subjective judgment. Accurate classification of breast pathological images is crucial for effective diagnosis but depends heavily on the availability and skill of pathologists. The study aims to improve the efficiency and accuracy of breast cancer pathological image classification to support timely and reliable diagnosis. The primary objective of the study is to develop a method for the rapid and automatic classification of breast pathological images into benign and malignant categories, thereby enhancing the accuracy and efficiency of breast cancer detection. The study seeks to validate this approach using a public dataset to demonstrate its effectiveness across different magnification levels of pathological images."
Medicine,Optimization of hepatological clinical guidelines interpretation by large language models: a retrieval augmented generation-based framework,"Abstract Large language models (LLMs) can potentially transform healthcare, particularly in providing the right information to the right provider at the right time in the hospital workflow. This study investigates the integration of LLMs into healthcare, specifically focusing on improving clinical decision support systems (CDSSs) through accurate interpretation of medical guidelines for chronic Hepatitis C Virus infection management. Utilizing OpenAI’s GPT-4 Turbo model, we developed a customized LLM framework that incorporates retrieval augmented generation (RAG) and prompt engineering. Our framework involved guideline conversion into the best-structured format that can be efficiently processed by LLMs to provide the most accurate output. An ablation study was conducted to evaluate the impact of different formatting and learning strategies on the LLM’s answer generation accuracy. The baseline GPT-4 Turbo model’s performance was compared against five experimental setups with increasing levels of complexity: inclusion of in-context guidelines, guideline reformatting, and implementation of few-shot learning. Our primary outcome was the qualitative assessment of accuracy based on expert review, while secondary outcomes included the quantitative measurement of similarity of LLM-generated responses to expert-provided answers using text-similarity scores. The results showed a significant improvement in accuracy from 43 to 99% ( p &lt; 0.001), when guidelines were provided as context in a coherent corpus of text and non-text sources were converted into text. In addition, few-shot learning did not seem to improve overall accuracy. The study highlights that structured guideline reformatting and advanced prompt engineering (data quality vs. data quantity) can enhance the efficacy of LLM integrations to CDSSs for guideline delivery.","['OpenAI’s GPT-4 Turbo model', 'retrieval augmented generation (RAG)', 'few-shot learning']","The research idea centers on the potential to improve healthcare delivery by providing accurate and timely information to healthcare providers within the hospital workflow, specifically addressing the challenge of interpreting medical guidelines for managing chronic Hepatitis C Virus infection. The study recognizes the need for enhancing clinical decision support systems to ensure that medical guidelines are accurately understood and applied in clinical practice. The primary objective of the study is to investigate how the integration of structured and well-formatted medical guidelines can improve the accuracy of clinical decision support systems in managing chronic Hepatitis C Virus infection. The study aims to evaluate the impact of different guideline presentation strategies on the accuracy of guideline interpretation, with the goal of enhancing the delivery and application of clinical guidelines in healthcare settings."
Medicine,Employing deep learning and transfer learning for accurate brain tumor detection,"Abstract Artificial intelligence-powered deep learning methods are being used to diagnose brain tumors with high accuracy, owing to their ability to process large amounts of data. Magnetic resonance imaging stands as the gold standard for brain tumor diagnosis using machine vision, surpassing computed tomography, ultrasound, and X-ray imaging in its effectiveness. Despite this, brain tumor diagnosis remains a challenging endeavour due to the intricate structure of the brain. This study delves into the potential of deep transfer learning architectures to elevate the accuracy of brain tumor diagnosis. Transfer learning is a machine learning technique that allows us to repurpose pre-trained models on new tasks. This can be particularly useful for medical imaging tasks, where labelled data is often scarce. Four distinct transfer learning architectures were assessed in this study: ResNet152, VGG19, DenseNet169, and MobileNetv3. The models were trained and validated on a dataset from benchmark database: Kaggle. Five-fold cross validation was adopted for training and testing. To enhance the balance of the dataset and improve the performance of the models, image enhancement techniques were applied to the data for the four categories: pituitary, normal, meningioma, and glioma. MobileNetv3 achieved the highest accuracy of 99.75%, significantly outperforming other existing methods. This demonstrates the potential of deep transfer learning architectures to revolutionize the field of brain tumor diagnosis.","['deep learning', 'deep transfer learning architectures', 'transfer learning', 'ResNet152', 'VGG19', 'DenseNet169', 'MobileNetv3']","The study addresses the challenge of accurately diagnosing brain tumors, which remains difficult due to the complex structure of the brain. Magnetic resonance imaging is recognized as the gold standard for brain tumor diagnosis, outperforming other imaging modalities such as computed tomography, ultrasound, and X-ray. Despite advances, improving the precision of brain tumor diagnosis continues to be a critical need in medical practice. The primary objective of this study is to explore methods to enhance the accuracy of brain tumor diagnosis by evaluating different approaches on a dataset containing various tumor categories, including pituitary, meningioma, glioma, and normal cases. The study aims to identify the most effective approach to improve diagnostic performance and contribute to better clinical outcomes in brain tumor detection."
Medicine,Liquid-metal-based three-dimensional microelectrode arrays integrated with implantable ultrathin retinal prosthesis for vision restoration,"Abstract Electronic retinal prostheses for stimulating retinal neurons are promising for vision restoration. However, the rigid electrodes of conventional retinal implants can inflict damage on the soft retina tissue. They also have limited selectivity due to their poor proximity to target cells in the degenerative retina. Here we present a soft artificial retina (thickness, 10 μm) where flexible ultrathin photosensitive transistors are integrated with three-dimensional stimulation electrodes of eutectic gallium–indium alloy. Platinum nanoclusters locally coated only on the tip of these three-dimensional liquid-metal electrodes show advantages in reducing the impedance of the stimulation electrodes. These microelectrodes can enhance the proximity to the target retinal ganglion cells and provide effective charge injections (72.84 mC cm −2 ) to elicit neural responses in the retina. Their low Young’s modulus (234 kPa), owing to their liquid form, can minimize damage to the retina. Furthermore, we used an unsupervised machine learning approach to effectively identify the evoked spikes to grade neural activities within the retinal ganglion cells. Results from in vivo experiments on a retinal degeneration mouse model reveal that the spatiotemporal distribution of neural responses on their retina can be mapped under selective localized illumination areas of light, suggesting the restoration of their vision.",['unsupervised machine learning'],"The research idea addresses the limitations of conventional retinal implants, which use rigid electrodes that can damage the soft retinal tissue and have limited selectivity due to poor proximity to target cells in degenerative retinas. There is a need for a retinal prosthesis that can minimize tissue damage while improving the effectiveness of neural stimulation for vision restoration. The primary objective of the study is to develop and evaluate a soft artificial retina with flexible, ultrathin stimulation electrodes that enhance proximity to retinal ganglion cells and provide effective charge injections to elicit neural responses. The study aims to demonstrate that this approach can minimize retinal damage and restore vision by mapping neural responses in a retinal degeneration mouse model under localized light stimulation."
Medicine,Transformative Breast Cancer Diagnosis using CNNs with Optimized ReduceLROnPlateau and Early Stopping Enhancements,"Abstract Breast cancer stands as a paramount public health concern worldwide, underscoring an imperative necessity within the research sphere for precision-driven and efficacious methodologies facilitating accurate detection. The existing diagnostic approaches in breast cancer often suffer from limitations in accuracy and efficiency, leading to delayed detection and subsequent challenges in personalized treatment planning. The primary focus of this research is to overcome these shortcomings by harnessing the power of advanced deep learning techniques, thereby revolutionizing the precision and reliability of breast cancer classification. This research addresses the critical need for improved breast cancer diagnostics by introducing a novel Convolutional Neural Network (CNN) model integrated with an Early Stopping callback and ReduceLROnPlateau callback. By enhancing the precision and reliability of breast cancer classification, the study aims to overcome the limitations of existing diagnostic methods, ultimately leading to better patient outcomes and reduced mortality rates. The comprehensive methodology includes diverse datasets, meticulous image preprocessing, robust model training, and validation strategies, emphasizing the model's adaptability and reliability in varied clinical contexts. The findings showcase the CNN model's exceptional performance, achieving a 95.2% accuracy rate in distinguishing cancerous and non-cancerous breast tissue in the integrated dataset, thereby demonstrating its potential for enhancing clinical decision-making and fostering the development of AI-driven diagnostic solutions.","['Convolutional Neural Network (CNN)', 'Early Stopping callback']","Breast cancer remains a significant public health challenge globally, highlighting the urgent need for more precise and effective methods to ensure accurate detection. Current diagnostic approaches often face limitations in accuracy and efficiency, which can result in delayed diagnosis and difficulties in tailoring personalized treatment plans. The study primarily aims to address these challenges by improving the precision and reliability of breast cancer classification. By enhancing diagnostic accuracy, the research seeks to overcome the shortcomings of existing methods, ultimately contributing to better patient outcomes and a reduction in mortality rates."
Medicine,"Making food systems more resilient to food safety risks by including artificial intelligence, big data, and internet of things into food safety early warning and emerging risk identification tools","Abstract To enhance the resilience of food systems to food safety risks, it is vitally important for national authorities and international organizations to be able to identify emerging food safety risks and to provide early warning signals in a timely manner. This review provides an overview of existing and experimental applications of artificial intelligence (AI), big data, and internet of things as part of early warning and emerging risk identification tools and methods in the food safety domain. There is an ongoing rapid development of systems fed by numerous, real‐time, and diverse data with the aim of early warning and identification of emerging food safety risks. The suitability of big data and AI to support such systems is illustrated by two cases in which climate change drives the emergence of risks, namely, harmful algal blooms affecting seafood and fungal growth and mycotoxin formation in crops. Automation and machine learning are crucial for the development of future real‐time food safety risk early warning systems. Although these developments increase the feasibility and effectiveness of prospective early warning and emerging risk identification tools, their implementation may prove challenging, particularly for low‐ and middle‐income countries due to low connectivity and data availability. It is advocated to overcome these challenges by improving the capability and capacity of national authorities, as well as by enhancing their collaboration with the private sector and international organizations.",['machine learning'],"The research idea centers on the critical need to enhance the resilience of food systems against food safety risks by enabling national authorities and international organizations to identify emerging food safety threats and provide timely early warning signals. This need is underscored by the increasing challenges posed by factors such as climate change, which contribute to risks like harmful algal blooms in seafood and fungal growth with mycotoxin formation in crops. The study highlights the importance of developing effective early warning and emerging risk identification tools to address these evolving food safety concerns. The primary objective of the study is to review and provide an overview of current and experimental approaches used for early warning and identification of emerging food safety risks, with a focus on illustrating their application through cases driven by climate change. Additionally, the study aims to discuss the challenges faced in implementing these approaches, particularly in low- and middle-income countries, and to advocate for strengthening the capabilities and collaboration of national authorities with private and international sectors to improve food safety risk management."
Medicine,Investigating Spatial Effects through Machine Learning and Leveraging Explainable AI for Child Malnutrition in Pakistan,"While socioeconomic gradients in regional health inequalities are firmly established, the synergistic interactions between socioeconomic deprivation and climate vulnerability within convenient proximity and neighbourhood locations with health disparities remain poorly explored and thus require deep understanding within a regional context. Furthermore, disregarding the importance of spatial spillover effects and nonlinear effects of covariates on childhood stunting are inevitable in dealing with an enduring issue of regional health inequalities. The present study aims to investigate the spatial inequalities in childhood stunting at the district level in Pakistan and validate the importance of spatial lag in predicting childhood stunting. Furthermore, it examines the presence of any nonlinear relationships among the selected independent features with childhood stunting. The study utilized data related to socioeconomic features from MICS 2017–2018 and climatic data from Integrated Contextual Analysis. A multi-model approach was employed to address the research questions, which included Ordinary Least Squares Regression (OLS), various Spatial Models, Machine Learning Algorithms and Explainable Artificial Intelligence methods. Firstly, OLS was used to analyse and test the linear relationships among selected variables. Secondly, Spatial Durbin Error Model (SDEM) was used to detect and capture the impact of spatial spillover on childhood stunting. Third, XGBoost and Random Forest machine learning algorithms were employed to examine and validate the importance of the spatial lag component. Finally, EXAI methods such as SHapley were utilized to identify potential nonlinear relationships. The study found a clear pattern of spatial clustering and geographical disparities in childhood stunting, with multidimensional poverty, high climate vulnerability and early marriage worsening childhood stunting. In contrast, low climate vulnerability, high exposure to mass media and high women’s literacy were found to reduce childhood stunting. The use of machine learning algorithms, specifically XGBoost and Random Forest, highlighted the significant role played by the average value in the neighbourhood in predicting childhood stunting in nearby districts, confirming that the spatial spillover effect is not bounded by geographical boundaries. Furthermore, EXAI methods such as partial dependency plot reveal the existence of a nonlinear relationship between multidimensional poverty and childhood stunting. The study’s findings provide valuable insights into the spatial distribution of childhood stunting in Pakistan, emphasizing the importance of considering spatial effects in predicting childhood stunting. Individual and household-level factors such as exposure to mass media and women’s literacy have shown positive implications for childhood stunting. It further provides a justification for the usage of EXAI methods to draw better insights and propose customised intervention policies accordingly.","['XGBoost', 'Random Forest', 'partial dependency plot']","The research idea addresses the persistent issue of regional health inequalities, focusing on the poorly explored interactions between socioeconomic deprivation and climate vulnerability within local neighborhoods and their impact on childhood stunting. It highlights the need to understand spatial spillover effects and nonlinear relationships among factors contributing to childhood stunting in a regional context. The study aims to investigate spatial inequalities in childhood stunting at the district level in Pakistan and to validate the significance of spatial influences in predicting childhood stunting. Additionally, it seeks to examine whether nonlinear relationships exist between selected socioeconomic and climatic factors and childhood stunting."
Medicine,"Detection of a facemask in real-time using deep learning methods:
  Prevention of Covid 19","A health crisis is raging all over the world with the rapid transmission of the novel-coronavirus disease (Covid-19). Out of the guidelines issued by the World Health Organisation (WHO) to protect us against Covid-19, wearing a facemask is the most effective. Many countries have necessitated the wearing of face masks, but monitoring a large number of people to ensure that they are wearing masks in a crowded place is a challenging task in itself. The novel-coronavirus disease (Covid-19) has already affected our day-to-day life as well as world trade movements. By the end of April 2021, the world has recorded 144,358,956 confirmed cases of novel-coronavirus disease (Covid-19) including 3,066,113 deaths according to the world health organization (WHO). These increasing numbers motivate automated techniques for the detection of a facemask in real-time scenarios for the prevention of Covid-19. We propose a technique using deep learning that works for single and multiple people in a frame recorded via webcam in still or in motion. We have also experimented with our approach in night light. The accuracy of our model is good compared to the other approaches in the literature; ranging from 74% for multiple people in a nightlight to 99% for a single person in daylight.",['deep learning'],"The rapid transmission of the novel-coronavirus disease (Covid-19) has created a global health crisis, significantly impacting daily life and world trade. Among the protective measures recommended by the World Health Organization (WHO), wearing a facemask is considered the most effective. However, ensuring that a large number of people wear masks in crowded places remains a challenging task. The increasing number of Covid-19 cases and deaths worldwide highlights the urgent need for effective monitoring of facemask usage to prevent the spread of the virus. The primary aim of this study is to develop a method for detecting facemask usage in real-time scenarios involving single or multiple people, including under varying lighting conditions such as daylight and nightlight. This approach seeks to support efforts in enforcing mask-wearing guidelines to reduce Covid-19 transmission."
Medicine,Unmasking bias in artificial intelligence: a systematic review of bias detection and mitigation strategies in electronic health record-based models,"Abstract Objectives Leveraging artificial intelligence (AI) in conjunction with electronic health records (EHRs) holds transformative potential to improve healthcare. However, addressing bias in AI, which risks worsening healthcare disparities, cannot be overlooked. This study reviews methods to handle various biases in AI models developed using EHR data. Materials and Methods We conducted a systematic review following the Preferred Reporting Items for Systematic Reviews and Meta-analyses guidelines, analyzing articles from PubMed, Web of Science, and IEEE published between January 01, 2010 and December 17, 2023. The review identified key biases, outlined strategies for detecting and mitigating bias throughout the AI model development, and analyzed metrics for bias assessment. Results Of the 450 articles retrieved, 20 met our criteria, revealing 6 major bias types: algorithmic, confounding, implicit, measurement, selection, and temporal. The AI models were primarily developed for predictive tasks, yet none have been deployed in real-world healthcare settings. Five studies concentrated on the detection of implicit and algorithmic biases employing fairness metrics like statistical parity, equal opportunity, and predictive equity. Fifteen studies proposed strategies for mitigating biases, especially targeting implicit and selection biases. These strategies, evaluated through both performance and fairness metrics, predominantly involved data collection and preprocessing techniques like resampling and reweighting. Discussion This review highlights evolving strategies to mitigate bias in EHR-based AI models, emphasizing the urgent need for both standardized and detailed reporting of the methodologies and systematic real-world testing and evaluation. Such measures are essential for gauging models’ practical impact and fostering ethical AI that ensures fairness and equity in healthcare.","['resampling', 'reweighting']","The research idea centers on the critical issue of bias in healthcare applications developed using electronic health records, which poses a risk of exacerbating healthcare disparities. Addressing these biases is essential to ensure fairness and equity in healthcare delivery. The study recognizes the transformative potential of improving healthcare outcomes but emphasizes that bias must be carefully managed to avoid negative consequences. The primary objective of the study is to review existing methods for identifying and mitigating various types of bias in healthcare models developed from electronic health record data. It aims to outline strategies for detecting and reducing bias and to analyze how bias assessment metrics are applied, with the goal of promoting ethical practices and ensuring that healthcare interventions are fair and effective in real-world settings."
Medicine,Large language models as assistance for glaucoma surgical cases: a ChatGPT vs. Google Gemini comparison,"Abstract Purpose The aim of this study was to define the capability of ChatGPT-4 and Google Gemini in analyzing detailed glaucoma case descriptions and suggesting an accurate surgical plan. Methods Retrospective analysis of 60 medical records of surgical glaucoma was divided into “ordinary” ( n = 40) and “challenging” ( n = 20) scenarios. Case descriptions were entered into ChatGPT and Bard’s interfaces with the question “What kind of surgery would you perform?” and repeated three times to analyze the answers’ consistency. After collecting the answers, we assessed the level of agreement with the unified opinion of three glaucoma surgeons. Moreover, we graded the quality of the responses with scores from 1 (poor quality) to 5 (excellent quality), according to the Global Quality Score (GQS) and compared the results. Results ChatGPT surgical choice was consistent with those of glaucoma specialists in 35/60 cases (58%), compared to 19/60 (32%) of Gemini ( p = 0.0001). Gemini was not able to complete the task in 16 cases (27%). Trabeculectomy was the most frequent choice for both chatbots (53% and 50% for ChatGPT and Gemini, respectively). In “challenging” cases, ChatGPT agreed with specialists in 9/20 choices (45%), outperforming Google Gemini performances (4/20, 20%). Overall, GQS scores were 3.5 ± 1.2 and 2.1 ± 1.5 for ChatGPT and Gemini ( p = 0.002). This difference was even more marked if focusing only on “challenging” cases (1.5 ± 1.4 vs. 3.0 ± 1.5, p = 0.001). Conclusion ChatGPT-4 showed a good analysis performance for glaucoma surgical cases, either ordinary or challenging. On the other side, Google Gemini showed strong limitations in this setting, presenting high rates of unprecise or missed answers.",['Google Gemini'],"The research idea centers on evaluating the ability to accurately analyze detailed glaucoma case descriptions and determine appropriate surgical plans, addressing the challenge of making precise surgical decisions in both ordinary and complex glaucoma cases. This study highlights the need for reliable assessment methods to support surgical planning in glaucoma treatment. The primary objective of the study was to define the capability of two different approaches in analyzing glaucoma cases and suggesting accurate surgical plans, by comparing their surgical choices with the consensus of glaucoma specialists and assessing the quality and consistency of their recommendations in both ordinary and challenging scenarios."
Medicine,Real-Time Plant Disease Dataset Development and Detection of Plant Disease Using Deep Learning,"Agriculture plays a significant role in meeting food needs and providing food security for the increasingly growing global population, which has increased by 0.88% since 2022. Plant diseases can reduce food production and affect food security. Worldwide crop loss due to plant disease is estimated to be around 14.1%. The lack of proper identification of plant disease at the early stages of infection can result in inappropriate disease control measures. Therefore, the automatic identification and diagnosis of plant diseases are highly recommended. Lack of availability of large amounts of data that are not processed to a large extent is one of the main challenges in plant disease diagnosis. In the current manuscript, we developed datasets for food grains specifically for rice, wheat, and maize to address the identified challenges. The developed datasets consider the common diseases (two bacterial diseases and two fungal diseases of rice, four fungal diseases of maize, and four fungal diseases of wheat) that affect crop yields and cause damage to the whole plant. The datasets developed were applied to eight fine-tuned deep learning models with the same training hyperparameters. The experimental results based on eight fine-tuned deep learning models show that, while recognizing maize leaf diseases, the models Xception and MobileNet performed best with a testing accuracy of 0.9580 and 0.9464 respectively. Similarly, while recognizing the wheat leaf diseases, the models MobileNetV2 and MobileNet performed best with a testing accuracy of 0.9632 and 0.9628 respectively. The Xception and Inception V3 models performed best, with a testing accuracy of 0.9728 and 0.9620, respectively, for recognizing rice leaf diseases. The research also proposes a new convolutional neural network (CNN) model trained from scratch on all three food grain datasets developed. The proposed model performs well and shows a testing accuracy of 0.9704, 0.9706, and 0.9808 respectively on the maize, rice, and wheat datasets.","['fine-tuned deep learning models', 'Xception', 'MobileNet', 'MobileNetV2', 'Inception V3', 'convolutional neural network (CNN) model trained from scratch']","The study addresses the significant impact of plant diseases on food production and food security, emphasizing that crop losses due to such diseases are substantial worldwide. Early and accurate identification of plant diseases is crucial to prevent inappropriate disease control measures and to protect crop yields. The research focuses on the challenge posed by the lack of properly processed data for diagnosing plant diseases affecting major food grains such as rice, wheat, and maize. The primary objective of the study is to develop comprehensive datasets for common bacterial and fungal diseases affecting these food grains and to evaluate the effectiveness of various approaches in accurately recognizing these diseases to support better disease diagnosis and management."
Medicine,Vision–language foundation model for echocardiogram interpretation,"Abstract The development of robust artificial intelligence models for echocardiography has been limited by the availability of annotated clinical data. Here, to address this challenge and improve the performance of cardiac imaging models, we developed EchoCLIP, a vision–language foundation model for echocardiography, that learns the relationship between cardiac ultrasound images and the interpretations of expert cardiologists across a wide range of patients and indications for imaging. After training on 1,032,975 cardiac ultrasound videos and corresponding expert text, EchoCLIP performs well on a diverse range of benchmarks for cardiac image interpretation, despite not having been explicitly trained for individual interpretation tasks. EchoCLIP can assess cardiac function (mean absolute error of 7.1% when predicting left ventricular ejection fraction in an external validation dataset) and identify implanted intracardiac devices (area under the curve (AUC) of 0.84, 0.92 and 0.97 for pacemakers, percutaneous mitral valve repair and artificial aortic valves, respectively). We also developed a long-context variant (EchoCLIP-R) using a custom tokenizer based on common echocardiography concepts. EchoCLIP-R accurately identified unique patients across multiple videos (AUC of 0.86), identified clinical transitions such as heart transplants (AUC of 0.79) and cardiac surgery (AUC 0.77) and enabled robust image-to-text search (mean cross-modal retrieval rank in the top 1% of candidate text reports). These capabilities represent a substantial step toward understanding and applying foundation models in cardiovascular imaging for preliminary interpretation of echocardiographic findings.",['vision–language foundation model'],"The research addresses the challenge of limited availability of annotated clinical data for echocardiography, which has hindered the development of robust methods for cardiac imaging interpretation. Improving the understanding and performance of cardiac ultrasound image analysis is crucial for accurate assessment of cardiac function and identification of intracardiac devices across diverse patient populations and clinical indications. The primary aim of the study is to develop a comprehensive approach that learns the relationship between cardiac ultrasound images and expert cardiologists’ interpretations to enhance the preliminary interpretation of echocardiographic findings. This includes accurately assessing cardiac function, identifying implanted devices, and recognizing significant clinical transitions such as heart transplants and cardiac surgery."
Medicine,Oral squamous cell carcinoma detection using EfficientNet on histopathological images,"Introduction Oral Squamous Cell Carcinoma (OSCC) poses a significant challenge in oncology due to the absence of precise diagnostic tools, leading to delays in identifying the condition. Current diagnostic methods for OSCC have limitations in accuracy and efficiency, highlighting the need for more reliable approaches. This study aims to explore the discriminative potential of histopathological images of oral epithelium and OSCC. By utilizing a database containing 1224 images from 230 patients, captured at varying magnifications and publicly available, a customized deep learning model based on EfficientNetB3 was developed. The model’s objective was to differentiate between normal epithelium and OSCC tissues by employing advanced techniques such as data augmentation, regularization, and optimization. Methods The research utilized a histopathological imaging database for Oral Cancer analysis, incorporating 1224 images from 230 patients. These images, taken at various magnifications, formed the basis for training a specialized deep learning model built upon the EfficientNetB3 architecture. The model underwent training to distinguish between normal epithelium and OSCC tissues, employing sophisticated methodologies including data augmentation, regularization techniques, and optimization strategies. Results The customized deep learning model achieved significant success, showcasing a remarkable 99% accuracy when tested on the dataset. This high accuracy underscores the model’s efficacy in effectively discerning between normal epithelium and OSCC tissues. Furthermore, the model exhibited impressive precision, recall, and F1-score metrics, reinforcing its potential as a robust diagnostic tool for OSCC. Discussion This research demonstrates the promising potential of employing deep learning models to address the diagnostic challenges associated with OSCC. The model’s ability to achieve a 99% accuracy rate on the test dataset signifies a considerable leap forward in earlier and more accurate detection of OSCC. Leveraging advanced techniques in machine learning, such as data augmentation and optimization, has shown promising results in improving patient outcomes through timely and precise identification of OSCC.",['deep learning model based on EfficientNetB3'],"Oral Squamous Cell Carcinoma (OSCC) presents a significant challenge in oncology due to the lack of precise diagnostic tools, which often results in delays in identifying the condition. Current diagnostic methods for OSCC are limited in accuracy and efficiency, underscoring the need for more reliable approaches to improve early detection. The primary aim of this study is to explore the discriminative potential of histopathological images of oral epithelium and OSCC to differentiate between normal and cancerous tissues. By analyzing a comprehensive database of images from patients, the study seeks to enhance the accuracy and reliability of OSCC diagnosis, ultimately contributing to earlier and more precise identification of the disease."
Medicine,Damage identification of steel bridge based on data augmentation and adaptive optimization neural network,"With the advancement of deep learning, data-driven structural damage identification (SDI) has shown considerable development. However, collecting vibration signals related to structural damage poses certain challenges, which can undermine the accuracy of the identification results produced by data-driven SDI methods in scenarios where data is scarce. This paper introduces an innovative approach to bridge SDI in a few-shot context by integrating an adaptive simulated annealing particle swarm optimization-convolutional neural network (ASAPSO-CNN) as the foundational framework, augmented by data enhancement techniques. Firstly, three specific types of noise are introduced to augment the source signals used for training. Subsequently, the source signals and augmented signals are recombined to construct a four-dimensional matrix as the input to the CNN, while defining the damage feature vector as the output. Secondly, a CNN is constructed to establish the mapping relationship between the input and output. Then, an adaptive fitness function is proposed that simultaneously considers the accuracy of SDI, model complexity, and training efficiency. The ASAPSO is employed to adaptively optimize the hyperparameters of the CNN. The proposed method is validated on an experimental model of a three-span continuous beam. It is compared with four other data-driven methods, demonstrating good effectiveness and robustness of SDI under cases of scarce data. Finally, the effectiveness of this SDI method is validated in a real-world case of a steel truss bridge.",['convolutional neural network (CNN)'],"The research idea addresses the challenge of accurately identifying structural damage when vibration signal data related to such damage is scarce, which can compromise the reliability of existing identification methods. Collecting sufficient and relevant vibration signals for structural damage detection is difficult, and this limitation affects the precision of damage identification results. The study aims to improve the effectiveness and robustness of structural damage identification in scenarios with limited data availability. The primary objective of the study is to develop and validate a novel approach that enhances structural damage identification performance under conditions of scarce data. This approach is tested on experimental models and real-world structures to demonstrate its accuracy and practical applicability in detecting damage in engineering structures."
Medicine,Enhancing heart disease prediction using a self-attention-based transformer model,"Abstract Cardiovascular diseases (CVDs) continue to be the leading cause of more than 17 million mortalities worldwide. The early detection of heart failure with high accuracy is crucial for clinical trials and therapy. Patients will be categorized into various types of heart disease based on characteristics like blood pressure, cholesterol levels, heart rate, and other characteristics. With the use of an automatic system, we can provide early diagnoses for those who are prone to heart failure by analyzing their characteristics. In this work, we deploy a novel self-attention-based transformer model, that combines self-attention mechanisms and transformer networks to predict CVD risk. The self-attention layers capture contextual information and generate representations that effectively model complex patterns in the data. Self-attention mechanisms provide interpretability by giving each component of the input sequence a certain amount of attention weight. This includes adjusting the input and output layers, incorporating more layers, and modifying the attention processes to collect relevant information. This also makes it possible for physicians to comprehend which features of the data contributed to the model's predictions. The proposed model is tested on the Cleveland dataset, a benchmark dataset of the University of California Irvine (UCI) machine learning (ML) repository. Comparing the proposed model to several baseline approaches, we achieved the highest accuracy of 96.51%. Furthermore, the outcomes of our experiments demonstrate that the prediction rate of our model is higher than that of other cutting-edge approaches used for heart disease prediction.","['self-attention-based transformer model', 'self-attention mechanisms', 'transformer networks']","Cardiovascular diseases (CVDs) remain the leading cause of over 17 million deaths worldwide, highlighting the critical need for early and accurate detection of heart failure to improve clinical outcomes and therapy. Identifying patients at risk by categorizing them based on characteristics such as blood pressure, cholesterol levels, and heart rate is essential for timely intervention. The primary aim of this study is to provide early diagnoses for individuals prone to heart failure by analyzing their clinical characteristics, thereby facilitating better risk prediction and management of cardiovascular diseases. This work focuses on improving the accuracy of heart disease prediction to support clinical decision-making and enhance patient care."
Medicine,SNC_Net: Skin Cancer Detection by Integrating Handcrafted and Deep Learning-Based Features Using Dermoscopy Images,"The medical sciences are facing a major problem with the auto-detection of disease due to the fast growth in population density. Intelligent systems assist medical professionals in early disease detection and also help to provide consistent treatment that reduces the mortality rate. Skin cancer is considered to be the deadliest and most severe kind of cancer. Medical professionals utilize dermoscopy images to make a manual diagnosis of skin cancer. This method is labor-intensive and time-consuming and demands a considerable level of expertise. Automated detection methods are necessary for the early detection of skin cancer. The occurrence of hair and air bubbles in dermoscopic images affects the diagnosis of skin cancer. This research aims to classify eight different types of skin cancer, namely actinic keratosis (AKs), dermatofibroma (DFa), melanoma (MELa), basal cell carcinoma (BCCa), squamous cell carcinoma (SCCa), melanocytic nevus (MNi), vascular lesion (VASn), and benign keratosis (BKs). In this study, we propose SNC_Net, which integrates features derived from dermoscopic images through deep learning (DL) models and handcrafted (HC) feature extraction methods with the aim of improving the performance of the classifier. A convolutional neural network (CNN) is employed for classification. Dermoscopy images from the publicly accessible ISIC 2019 dataset for skin cancer detection is utilized to train and validate the model. The performance of the proposed model is compared with four baseline models, namely EfficientNetB0 (B1), MobileNetV2 (B2), DenseNet-121 (B3), and ResNet-101 (B4), and six state-of-the-art (SOTA) classifiers. With an accuracy of 97.81%, a precision of 98.31%, a recall of 97.89%, and an F1 score of 98.10%, the proposed model outperformed the SOTA classifiers as well as the four baseline models. Moreover, an Ablation study is also performed on the proposed method to validate its performance. The proposed method therefore assists dermatologists and other medical professionals in early skin cancer detection.","['deep learning (DL) models', 'convolutional neural network (CNN)', 'EfficientNetB0', 'MobileNetV2', 'DenseNet-121', 'ResNet-101']","The medical sciences face a significant challenge in the early detection of diseases due to increasing population density, with skin cancer being one of the deadliest and most severe types of cancer. Manual diagnosis of skin cancer using dermoscopy images is labor-intensive, time-consuming, and requires considerable expertise, while factors such as hair and air bubbles in images can affect diagnostic accuracy. This study aims to classify eight different types of skin cancer, including actinic keratosis, dermatofibroma, melanoma, basal cell carcinoma, squamous cell carcinoma, melanocytic nevus, vascular lesion, and benign keratosis. The primary objective is to improve the accuracy and reliability of skin cancer classification to assist dermatologists and medical professionals in early detection and consistent treatment, thereby potentially reducing mortality rates."
Medicine,The diagnostic and triage accuracy of the GPT-3 artificial intelligence model: an observational study,"BackgroundArtificial intelligence (AI) applications in health care have been effective in many areas of medicine, but they are often trained for a single task using labelled data, making deployment and generalisability challenging. How well a general-purpose AI language model performs diagnosis and triage relative to physicians and laypeople is not well understood.MethodsWe compared the predictive accuracy of Generative Pre-trained Transformer 3 (GPT-3)'s diagnostic and triage ability for 48 validated synthetic case vignettes (<50 words; sixth-grade reading level or below) of both common (eg, viral illness) and severe (eg, heart attack) conditions to a nationally representative sample of 5000 lay people from the USA who could use the internet to find the correct options and 21 practising physicians at Harvard Medical School. There were 12 vignettes for each of four triage categories: emergent, within one day, within 1 week, and self-care. The correct diagnosis and triage category (ie, ground truth) for each vignette was determined by two general internists at Harvard Medical School. For each vignette, human respondents and GPT-3 were prompted to list diagnoses in order of likelihood, and the vignette was marked as correct if the ground-truth diagnosis was in the top three of the listed diagnoses. For triage accuracy, we examined whether the human respondents' and GPT-3's selected triage was exactly correct according to the four triage categories, or matched a dichotomised triage variable (emergent or within 1 day vs within 1 week or self-care). We estimated GPT-3's diagnostic and triage confidence on a given vignette using a modified bootstrap resampling procedure, and examined how well calibrated GPT-3's confidence was by computing calibration curves and Brier scores. We also performed subgroup analysis by case acuity, and an error analysis for triage advice to characterise how its advice might affect patients using this tool to decide if they should seek medical care immediately.FindingsAmong all cases, GPT-3 replied with the correct diagnosis in its top three for 88% (42/48, 95% CI 75–94) of cases, compared with 54% (2700/5000, 53–55) for lay individuals (p<0.0001) and 96% (637/666, 94–97) for physicians (p=0·012). GPT-3 triaged 70% correct (34/48, 57–82) versus 74% (3706/5000, 73–75; p=0.60) for lay individuals and 91% (608/666, 89–93%; p<0.0001) for physicians. As measured by the Brier score, GPT-3 confidence in its top prediction was reasonably well calibrated for diagnosis (Brier score=0·18) and triage (Brier score=0·22). We observed an inverse relationship between case acuity and GPT-3 accuracy (p<0·0001) with a fitted trend line of –8·33% decrease in accuracy for every level of increase in case acuity. For triage error analysis, GPT-3 deprioritised truly emergent cases in seven instances.InterpretationA general-purpose AI language model without any content-specific training could perform diagnosis at levels close to, but below, physicians and better than lay individuals. We found that GPT-3's performance was inferior to physicians for triage, sometimes by a large margin, and its performance was closer to that of lay individuals. Although the diagnostic performance of GPT-3 was comparable to physicians, it was significantly better than a typical person using a search engine.FundingThe National Heart, Lung, and Blood Institute.",['Generative Pre-trained Transformer 3 (GPT-3)'],"The study addresses the challenge of understanding how well a general-purpose diagnostic and triage tool performs compared to physicians and laypeople, particularly given the difficulty in deploying tools that are typically trained for single tasks. There is limited knowledge about the accuracy and reliability of such a tool in diagnosing and triaging a range of medical conditions, from common illnesses to severe emergencies. The primary aim of the study is to evaluate the diagnostic and triage accuracy of a general-purpose language-based tool using validated clinical case vignettes, comparing its performance directly to that of practicing physicians and lay individuals. The study seeks to determine how closely the tool’s diagnostic and triage decisions align with expert-established ground truth and to assess its potential impact on patient decision-making regarding seeking medical care."
Medicine,Machine Learning and Digital Biomarkers Can Detect Early Stages of Neurodegenerative Diseases,"Neurodegenerative diseases (NDs) such as Alzheimer’s Disease (AD) and Parkinson’s Disease (PD) are devastating conditions that can develop without noticeable symptoms, causing irreversible damage to neurons before any signs become clinically evident. NDs are a major cause of disability and mortality worldwide. Currently, there are no cures or treatments to halt their progression. Therefore, the development of early detection methods is urgently needed to delay neuronal loss as soon as possible. Despite advancements in Medtech, the early diagnosis of NDs remains a challenge at the intersection of medical, IT, and regulatory fields. Thus, this review explores “digital biomarkers” (tools designed for remote neurocognitive data collection and AI analysis) as a potential solution. The review summarizes that recent studies combining AI with digital biomarkers suggest the possibility of identifying pre-symptomatic indicators of NDs. For instance, research utilizing convolutional neural networks for eye tracking has achieved significant diagnostic accuracies. ROC-AUC scores reached up to 0.88, indicating high model performance in differentiating between PD patients and healthy controls. Similarly, advancements in facial expression analysis through tools have demonstrated significant potential in detecting emotional changes in ND patients, with some models reaching an accuracy of 0.89 and a precision of 0.85. This review follows a structured approach to article selection, starting with a comprehensive database search and culminating in a rigorous quality assessment and meaning for NDs of the different methods. The process is visualized in 10 tables with 54 parameters describing different approaches and their consequences for understanding various mechanisms in ND changes. However, these methods also face challenges related to data accuracy and privacy concerns. To address these issues, this review proposes strategies that emphasize the need for rigorous validation and rapid integration into clinical practice. Such integration could transform ND diagnostics, making early detection tools more cost-effective and globally accessible. In conclusion, this review underscores the urgent need to incorporate validated digital health tools into mainstream medical practice. This integration could indicate a new era in the early diagnosis of neurodegenerative diseases, potentially altering the trajectory of these conditions for millions worldwide. Thus, by highlighting specific and statistically significant findings, this review demonstrates the current progress in this field and the potential impact of these advancements on the global management of NDs.",['convolutional neural networks'],"The research idea addresses the critical challenge of neurodegenerative diseases such as Alzheimer’s Disease and Parkinson’s Disease, which often develop without noticeable symptoms and cause irreversible neuronal damage before clinical signs appear. These diseases are a leading cause of disability and mortality worldwide, and currently, there are no cures or treatments to stop their progression. Therefore, there is an urgent need for early detection methods to delay neuronal loss and improve patient outcomes. The study highlights the potential of emerging tools for remote neurocognitive data collection as a promising avenue to identify pre-symptomatic indicators of neurodegenerative diseases.

The primary objective of the study is to review and evaluate recent advancements in early detection approaches for neurodegenerative diseases, focusing on the potential of novel health tools to identify early signs before clinical symptoms emerge. The study aims to summarize current findings, assess the effectiveness and challenges of these approaches, and propose strategies for their rigorous validation and integration into clinical practice. Ultimately, the goal is to emphasize the importance of incorporating validated early detection tools into mainstream medicine to transform diagnostics and improve global management of neurodegenerative diseases."
Medicine,RanMerFormer: Randomized vision transformer with token merging for brain tumor classification,"Brains are the control center of the nervous system in human bodies, and brain tumor is one of the most deadly diseases. Currently, magnetic resonance imaging (MRI) is the most effective way to brain tumors early detection in clinical diagnoses due to its superior imaging quality for soft tissues. Manual analysis of brain MRI is error-prone which depends on empirical experience and the fatigue state of the radiologists to a large extent. Computer-aided diagnosis (CAD) systems are becoming more and more impactful because they can provide accurate prediction results based on medical images with advanced techniques from computer vision. Therefore, a novel CAD method for brain tumor classification named RanMerFormer is presented in this paper. A pre-trained vision transformer is used as the backbone model. Then, a merging mechanism is proposed to remove the redundant tokens in the vision transformer, which improves computing efficiency substantially. Finally, a randomized vector functional-link serves as the head in the proposed RanMerFormer, which can be trained swiftly. All the simulation results are obtained from two public benchmark datasets, which reveal that the proposed RanMerFormer can achieve state-of-the-art performance for brain tumor classification. The trained RanMerFormer can be applied in real-world scenarios to assist in brain tumor diagnosis.","['pre-trained vision transformer', 'randomized vector functional-link']","The study addresses the critical issue of brain tumors, which are among the most deadly diseases affecting the nervous system. Early detection of brain tumors is essential, and magnetic resonance imaging (MRI) is currently the most effective clinical method due to its superior imaging quality for soft tissues. However, manual analysis of brain MRI scans is prone to errors and heavily reliant on the radiologists' experience and fatigue levels, which can impact diagnostic accuracy. The primary aim of the study is to develop a novel approach to improve the classification of brain tumors, enhancing the accuracy and efficiency of diagnosis to better assist clinical decision-making in real-world scenarios."
Medicine,A hybrid deep CNN model for brain tumor image multi-classification,"Abstract The current approach to diagnosing and classifying brain tumors relies on the histological evaluation of biopsy samples, which is invasive, time-consuming, and susceptible to manual errors. These limitations underscore the pressing need for a fully automated, deep-learning-based multi-classification system for brain malignancies. This article aims to leverage a deep convolutional neural network (CNN) to enhance early detection and presents three distinct CNN models designed for different types of classification tasks. The first CNN model achieves an impressive detection accuracy of 99.53% for brain tumors. The second CNN model, with an accuracy of 93.81%, proficiently categorizes brain tumors into five distinct types: normal, glioma, meningioma, pituitary, and metastatic. Furthermore, the third CNN model demonstrates an accuracy of 98.56% in accurately classifying brain tumors into their different grades. To ensure optimal performance, a grid search optimization approach is employed to automatically fine-tune all the relevant hyperparameters of the CNN models. The utilization of large, publicly accessible clinical datasets results in robust and reliable classification outcomes. This article conducts a comprehensive comparison of the proposed models against classical models, such as AlexNet, DenseNet121, ResNet-101, VGG-19, and GoogleNet, reaffirming the superiority of the deep CNN-based approach in advancing the field of brain tumor classification and early detection.","['deep convolutional neural network (CNN)', 'AlexNet', 'DenseNet121', 'ResNet-101', 'VGG-19', 'GoogleNet']","The current approach to diagnosing and classifying brain tumors relies on the histological evaluation of biopsy samples, which is invasive, time-consuming, and susceptible to manual errors. These limitations highlight the need for improved methods that can facilitate early detection and accurate classification of brain malignancies. The primary aim of this study is to enhance early detection of brain tumors and to accurately classify them into different types and grades. This is achieved by developing and evaluating models designed for multi-classification tasks to improve the diagnosis and categorization of brain tumors."
Medicine,Automated Tool Support for Glaucoma Identification With Explainability Using Fundus Images,"Glaucoma is a progressive eye condition that causes irreversible vision loss due to damage to the optic nerve. Recent developments in deep learning and the accessibility of computing resources have provided tool support for automated glaucoma diagnosis. Despite deep learning's advances in disease diagnosis using medical images, generic convolutional neural networks are still not widely used in medical practices due to the limited trustworthiness of these models. Although deep learning-based glaucoma classification has gained popularity in recent years, only a few of them have addressed the explainability and interpretability of the models, which increases confidence in using such applications. This study presents state-of-the-art deep learning techniques to segment and classify fundus images to predict glaucoma conditions and applies visualization techniques to explain the results to ease understandability. Our predictions are based on U-Net with attention mechanisms with ResNet50 for the segmentation process and a modified Inception V3 architecture for the classification. Attention U-Net with modified ResNet50 backbone obtained 99.58% and 98.05% accuracies for optic disc segmentation and optic cup segmentation, respectively for the RIM-ONE dataset. Additionally, we generate heatmaps that highlight the regions that impacted the glaucoma diagnosis using both Gradient-weighted Class Activation Mapping (Grad-CAM) and Grad-CAM++. Our model that classifies the segmented images achieves accuracy, sensitivity, and specificity values of 98.97%, 99.42%, and 95.59%, respectively, with the RIM-ONE dataset. This model can be used as a support tool for automated glaucoma identification using fundus images.","['U-Net with attention mechanisms', 'ResNet50', 'modified Inception V3 architecture', 'Attention U-Net with modified ResNet50 backbone', 'Gradient-weighted Class Activation Mapping (Grad-CAM)', 'Grad-CAM++']","The research idea centers on addressing the challenge of diagnosing glaucoma, a progressive eye disease that leads to irreversible vision loss due to optic nerve damage. Despite advances in automated diagnosis using medical images, there remains limited trust and acceptance of these methods in clinical practice, partly because of insufficient explainability and interpretability of the diagnostic results. The study aims to improve confidence in automated glaucoma diagnosis by enhancing the clarity and understanding of the diagnostic process. The primary objective of the study is to develop an approach for segmenting and classifying fundus images to predict glaucoma conditions accurately, while also providing visual explanations of the diagnostic outcomes to facilitate better understanding and trust in the results."
Medicine,"Generative artificial intelligence in drug discovery: basic framework, recent advances, challenges, and opportunities","There are two main ways to discover or design small drug molecules. The first involves fine-tuning existing molecules or commercially successful drugs through quantitative structure-activity relationships and virtual screening. The second approach involves generating new molecules through de novo drug design or inverse quantitative structure-activity relationship. Both methods aim to get a drug molecule with the best pharmacokinetic and pharmacodynamic profiles. However, bringing a new drug to market is an expensive and time-consuming endeavor, with the average cost being estimated at around $2.5 billion. One of the biggest challenges is screening the vast number of potential drug candidates to find one that is both safe and effective. The development of artificial intelligence in recent years has been phenomenal, ushering in a revolution in many fields. The field of pharmaceutical sciences has also significantly benefited from multiple applications of artificial intelligence, especially drug discovery projects. Artificial intelligence models are finding use in molecular property prediction, molecule generation, virtual screening, synthesis planning, repurposing, among others. Lately, generative artificial intelligence has gained popularity across domains for its ability to generate entirely new data, such as images, sentences, audios, videos, novel chemical molecules, etc. Generative artificial intelligence has also delivered promising results in drug discovery and development. This review article delves into the fundamentals and framework of various generative artificial intelligence models in the context of drug discovery via de novo drug design approach. Various basic and advanced models have been discussed, along with their recent applications. The review also explores recent examples and advances in the generative artificial intelligence approach, as well as the challenges and ongoing efforts to fully harness the potential of generative artificial intelligence in generating novel drug molecules in a faster and more affordable manner. Some clinical-level assets generated form generative artificial intelligence have also been discussed in this review to show the ever-increasing application of artificial intelligence in drug discovery through commercial partnerships.","['inverse quantitative structure-activity relationship', 'generative artificial intelligence models']","The research idea centers on the significant challenges in discovering and designing small drug molecules, particularly the high cost and time required to bring new drugs to market. A major obstacle is efficiently screening the vast number of potential drug candidates to identify those that are both safe and effective, while achieving optimal pharmacokinetic and pharmacodynamic profiles. The study addresses the need for innovative approaches to accelerate and reduce the expense of drug discovery and development. The primary objective of the study is to review and discuss recent advances and applications in the generation of novel drug molecules through de novo drug design, highlighting the progress, challenges, and ongoing efforts to improve the speed and affordability of drug discovery. The study also aims to present examples of clinically relevant drug candidates developed using these novel approaches to demonstrate their growing impact in pharmaceutical sciences."
Medicine,Collaborative Enhancement of Consistency and Accuracy in US Diagnosis of Thyroid Nodules Using Large Language Models,"Background Large language models (LLMs) hold substantial promise for medical imaging interpretation. However, there is a lack of studies on their feasibility in handling reasoning questions associated with medical diagnosis. Purpose To investigate the viability of leveraging three publicly available LLMs to enhance consistency and diagnostic accuracy in medical imaging based on standardized reporting, with pathology as the reference standard. Materials and Methods US images of thyroid nodules with pathologic results were retrospectively collected from a tertiary referral hospital between July 2022 and December 2022 and used to evaluate malignancy diagnoses generated by three LLMs-OpenAI's ChatGPT 3.5, ChatGPT 4.0, and Google's Bard. Inter- and intra-LLM agreement of diagnosis were evaluated. Then, diagnostic performance, including accuracy, sensitivity, specificity, and area under the receiver operating characteristic curve (AUC), was evaluated and compared for the LLMs and three interactive approaches: human reader combined with LLMs, image-to-text model combined with LLMs, and an end-to-end convolutional neural network model. Results A total of 1161 US images of thyroid nodules (498 benign, 663 malignant) from 725 patients (mean age, 42.2 years ± 14.1 [SD]; 516 women) were evaluated. ChatGPT 4.0 and Bard displayed substantial to almost perfect intra-LLM agreement (κ range, 0.65-0.86 [95% CI: 0.64, 0.86]), while ChatGPT 3.5 showed fair to substantial agreement (κ range, 0.36-0.68 [95% CI: 0.36, 0.68]). ChatGPT 4.0 had an accuracy of 78%-86% (95% CI: 76%, 88%) and sensitivity of 86%-95% (95% CI: 83%, 96%), compared with 74%-86% (95% CI: 71%, 88%) and 74%-91% (95% CI: 71%, 93%), respectively, for Bard. Moreover, with ChatGPT 4.0, the image-to-text-LLM strategy exhibited an AUC (0.83 [95% CI: 0.80, 0.85]) and accuracy (84% [95% CI: 82%, 86%]) comparable to those of the human-LLM interaction strategy with two senior readers and one junior reader and exceeding those of the human-LLM interaction strategy with one junior reader. Conclusion LLMs, particularly integrated with image-to-text approaches, show potential in enhancing diagnostic medical imaging. ChatGPT 4.0 was optimal for consistency and diagnostic accuracy when compared with Bard and ChatGPT 3.5. © RSNA, 2024","['image-to-text model combined with LLMs', 'end-to-end convolutional neural network model']","The study addresses the challenge of improving consistency and diagnostic accuracy in medical imaging interpretation, particularly for thyroid nodule malignancy assessment, where standardized reporting and pathology serve as critical references. There is a need to explore new approaches that can support reliable and accurate diagnosis in medical imaging, given the complexity of reasoning involved in medical diagnosis. The primary aim of the study is to investigate the viability of leveraging publicly available tools to enhance consistency and diagnostic accuracy in medical imaging of thyroid nodules, using pathology as the reference standard. The study evaluates diagnostic performance and agreement in malignancy diagnoses to determine the effectiveness of these approaches in comparison to human readers."
Medicine,Foresight—a generative pretrained transformer for modelling of patient timelines using electronic health records: a retrospective modelling study,"BackgroundAn electronic health record (EHR) holds detailed longitudinal information about a patient's health status and general clinical history, a large portion of which is stored as unstructured, free text. Existing approaches to model a patient's trajectory focus mostly on structured data and a subset of single-domain outcomes. This study aims to evaluate the effectiveness of Foresight, a generative transformer in temporal modelling of patient data, integrating both free text and structured formats, to predict a diverse array of future medical outcomes, such as disorders, substances (eg, to do with medicines, allergies, or poisonings), procedures, and findings (eg, relating to observations, judgements, or assessments).MethodsForesight is a novel transformer-based pipeline that uses named entity recognition and linking tools to convert EHR document text into structured, coded concepts, followed by providing probabilistic forecasts for future medical events, such as disorders, substances, procedures, and findings. The Foresight pipeline has four main components: (1) CogStack (data retrieval and preprocessing); (2) the Medical Concept Annotation Toolkit (structuring of the free-text information from EHRs); (3) Foresight Core (deep-learning model for biomedical concept modelling); and (4) the Foresight web application. We processed the entire free-text portion from three different hospital datasets (King's College Hospital [KCH], South London and Maudsley [SLaM], and the US Medical Information Mart for Intensive Care III [MIMIC-III]), resulting in information from 811 336 patients and covering both physical and mental health institutions. We measured the performance of models using custom metrics derived from precision and recall.FindingsForesight achieved a precision@10 (ie, of 10 forecasted candidates, at least one is correct) of 0·68 (SD 0·0027) for the KCH dataset, 0·76 (0·0032) for the SLaM dataset, and 0·88 (0·0018) for the MIMIC-III dataset, for forecasting the next new disorder in a patient timeline. Foresight also achieved a precision@10 value of 0·80 (0·0013) for the KCH dataset, 0·81 (0·0026) for the SLaM dataset, and 0·91 (0·0011) for the MIMIC-III dataset, for forecasting the next new biomedical concept. In addition, Foresight was validated on 34 synthetic patient timelines by five clinicians and achieved a relevancy of 33 (97% [95% CI 91–100]) of 34 for the top forecasted candidate disorder. As a generative model, Foresight can forecast follow-on biomedical concepts for as many steps as required.InterpretationForesight is a general-purpose model for biomedical concept modelling that can be used for real-world risk forecasting, virtual trials, and clinical research to study the progression of disorders, to simulate interventions and counterfactuals, and for educational purposes.FundingNational Health Service Artificial Intelligence Laboratory, National Institute for Health and Care Research Biomedical Research Centre, and Health Data Research UK.","['generative transformer', 'named entity recognition']","The research idea addresses the challenge of utilizing the detailed longitudinal information contained in electronic health records (EHRs), much of which is stored as unstructured free text, to better understand and predict a patient’s future medical outcomes. Existing approaches primarily focus on structured data and limited clinical outcomes, leaving a gap in effectively integrating comprehensive patient information to forecast a wide range of medical events. This study is motivated by the need to improve temporal modeling of patient data by incorporating both free-text and structured formats to capture diverse clinical trajectories.

The primary objective of the study is to evaluate the effectiveness of a novel approach that integrates free-text and structured EHR data to predict a broad array of future medical outcomes, including disorders, substances related to medicines or allergies, procedures, and clinical findings. The study aims to assess the accuracy and relevance of these predictions across multiple hospital datasets, thereby demonstrating the potential for improved risk forecasting and clinical research applications focused on the progression and management of various health conditions."
Medicine,Evaluating the accuracy of a state-of-the-art large language model for prediction of admissions from the emergency room,"Abstract Background Artificial intelligence (AI) and large language models (LLMs) can play a critical role in emergency room operations by augmenting decision-making about patient admission. However, there are no studies for LLMs using real-world data and scenarios, in comparison to and being informed by traditional supervised machine learning (ML) models. We evaluated the performance of GPT-4 for predicting patient admissions from emergency department (ED) visits. We compared performance to traditional ML models both naively and when informed by few-shot examples and/or numerical probabilities. Methods We conducted a retrospective study using electronic health records across 7 NYC hospitals. We trained Bio-Clinical-BERT and XGBoost (XGB) models on unstructured and structured data, respectively, and created an ensemble model reflecting ML performance. We then assessed GPT-4 capabilities in many scenarios: through Zero-shot, Few-shot with and without retrieval-augmented generation (RAG), and with and without ML numerical probabilities. Results The Ensemble ML model achieved an area under the receiver operating characteristic curve (AUC) of 0.88, an area under the precision-recall curve (AUPRC) of 0.72 and an accuracy of 82.9%. The naïve GPT-4's performance (0.79 AUC, 0.48 AUPRC, and 77.5% accuracy) showed substantial improvement when given limited, relevant data to learn from (ie, RAG) and underlying ML probabilities (0.87 AUC, 0.71 AUPRC, and 83.1% accuracy). Interestingly, RAG alone boosted performance to near peak levels (0.82 AUC, 0.56 AUPRC, and 81.3% accuracy). Conclusions The naïve LLM had limited performance but showed significant improvement in predicting ED admissions when supplemented with real-world examples to learn from, particularly through RAG, and/or numerical probabilities from traditional ML models. Its peak performance, although slightly lower than the pure ML model, is noteworthy given its potential for providing reasoning behind predictions. Further refinement of LLMs with real-world data is necessary for successful integration as decision-support tools in care settings.","['GPT-4', 'XGBoost (XGB)', 'Ensemble model', 'Zero-shot', 'Few-shot', 'Retrieval-augmented generation (RAG)']","The research idea addresses the challenge of improving decision-making about patient admissions in emergency room operations by exploring new approaches to predict admissions from emergency department visits. There is a need to evaluate the effectiveness of emerging methods using real-world clinical data and scenarios to enhance the accuracy and reliability of admission predictions. The study aims to assess the potential of advanced language-based tools in comparison to traditional approaches for this critical healthcare task. The primary objective of the study is to evaluate the performance of a large language-based tool for predicting patient admissions from emergency department visits and to compare its effectiveness to that of established traditional methods. The study seeks to determine whether supplementing this tool with real-world examples and numerical probabilities from traditional methods can improve its predictive accuracy. Ultimately, the goal is to understand the feasibility of integrating such tools as decision-support aids in clinical care settings."
Medicine,Present and Future Innovations in AI and Cardiac MRI,"Cardiac MRI is used to diagnose and treat patients with a multitude of cardiovascular diseases. Despite the growth of clinical cardiac MRI, complicated image prescriptions and long acquisition protocols limit the specialty and restrain its impact on the practice of medicine. Artificial intelligence (AI)-the ability to mimic human intelligence in learning and performing tasks-will impact nearly all aspects of MRI. Deep learning (DL) primarily uses an artificial neural network to learn a specific task from example data sets. Self-driving scanners are increasingly available, where AI automatically controls cardiac image prescriptions. These scanners offer faster image collection with higher spatial and temporal resolution, eliminating the need for cardiac triggering or breath holding. In the future, fully automated inline image analysis will most likely provide all contour drawings and initial measurements to the reader. Advanced analysis using radiomic or DL features may provide new insights and information not typically extracted in the current analysis workflow. AI may further help integrate these features with clinical, genetic, wearable-device, and ""omics"" data to improve patient outcomes. This article presents an overview of AI and its application in cardiac MRI, including in image acquisition, reconstruction, and processing, and opportunities for more personalized cardiovascular care through extraction of novel imaging markers.","['Deep learning (DL)', 'artificial neural network']","The research idea addresses the challenges in cardiac MRI, including complicated image prescriptions and lengthy acquisition protocols, which limit its widespread use and impact in clinical practice for diagnosing and treating cardiovascular diseases. Despite the growth of cardiac MRI, these limitations restrain its full potential in improving patient care. The study’s primary objective is to explore advancements that can enhance cardiac MRI by enabling faster image collection with improved resolution and reducing patient burden during imaging. It aims to provide an overview of innovations that could lead to more personalized cardiovascular care through improved image acquisition and the extraction of novel imaging markers."
Medicine,Automated localization of mandibular landmarks in the construction of mandibular median sagittal plane,"Abstract Objective To use deep learning to segment the mandible and identify three-dimensional (3D) anatomical landmarks from cone-beam computed tomography (CBCT) images, the planes constructed from the mandibular midline landmarks were compared and analyzed to find the best mandibular midsagittal plane (MMSP). Methods A total of 400 participants were randomly divided into a training group ( n = 360) and a validation group ( n = 40). Normal individuals were used as the test group ( n = 50). The PointRend deep learning mechanism segmented the mandible from CBCT images and accurately identified 27 anatomic landmarks via PoseNet. 3D coordinates of 5 central landmarks and 2 pairs of side landmarks were obtained for the test group. Every 35 combinations of 3 midline landmarks were screened using the template mapping technique. The asymmetry index (AI) was calculated for each of the 35 mirror planes. The template mapping technique plane was used as the reference plane; the top four planes with the smallest AIs were compared through distance, volume difference, and similarity index to find the plane with the fewest errors. Results The mandible was segmented automatically in 10 ± 1.5 s with a 0.98 Dice similarity coefficient. The mean landmark localization error for the 27 landmarks was 1.04 ± 0.28 mm. MMSP should use the plane made by B (supramentale), Gn (gnathion), and F (mandibular foramen). The average AI grade was 1.6 (min–max: 0.59–3.61). There was no significant difference in distance or volume ( P &gt; 0.05); however, the similarity index was significantly different ( P &lt; 0.01). Conclusion Deep learning can automatically segment the mandible, identify anatomic landmarks, and address medicinal demands in people without mandibular deformities. The most accurate MMSP was the B-Gn-F plane.","['PointRend deep learning mechanism', 'PoseNet']",The research idea centers on the need to accurately segment the mandible and identify three-dimensional anatomical landmarks from cone-beam computed tomography images to improve the understanding and analysis of mandibular anatomy. Establishing the best mandibular midsagittal plane (MMSP) is important for assessing mandibular symmetry and anatomical relationships. The study aims to address challenges in defining an accurate reference plane for the mandible in individuals without mandibular deformities. The primary objective of the study is to determine the most accurate mandibular midsagittal plane by comparing and analyzing planes constructed from mandibular midline landmarks. This involves identifying key anatomical landmarks on the mandible and evaluating different combinations of these landmarks to find the plane with the fewest errors in terms of asymmetry and anatomical accuracy.
Medicine,Artificial intelligence-driven virtual rehabilitation for people living in the community: A scoping review,"Abstract Virtual Rehabilitation (VRehab) is a promising approach to improving the physical and mental functioning of patients living in the community. The use of VRehab technology results in the generation of multi-modal datasets collected through various devices. This presents opportunities for the development of Artificial Intelligence (AI) techniques in VRehab, namely the measurement, detection, and prediction of various patients’ health outcomes. The objective of this scoping review was to explore the applications and effectiveness of incorporating AI into home-based VRehab programs. PubMed/MEDLINE, Embase, IEEE Xplore, Web of Science databases, and Google Scholar were searched from inception until June 2023 for studies that applied AI for the delivery of VRehab programs to the homes of adult patients. After screening 2172 unique titles and abstracts and 51 full-text studies, 13 studies were included in the review. A variety of AI algorithms were applied to analyze data collected from various sensors and make inferences about patients’ health outcomes, most involving evaluating patients’ exercise quality and providing feedback to patients. The AI algorithms used in the studies were mostly fuzzy rule-based methods, template matching, and deep neural networks. Despite the growing body of literature on the use of AI in VRehab, very few studies have examined its use in patients’ homes. Current research suggests that integrating AI with home-based VRehab can lead to improved rehabilitation outcomes for patients. However, further research is required to fully assess the effectiveness of various forms of AI-driven home-based VRehab, taking into account its unique challenges and using standardized metrics.","['fuzzy rule-based methods', 'deep neural networks']","The research idea centers on the potential of virtual rehabilitation (VRehab) to enhance the physical and mental functioning of patients living in the community, particularly through home-based programs. Despite the promise of VRehab, there is limited understanding of its application and effectiveness when delivered in patients’ homes. The study’s primary objective was to explore the applications and effectiveness of incorporating advanced techniques into home-based VRehab programs for adult patients. This review aimed to assess how these approaches have been used to evaluate patients’ exercise quality and provide feedback, with the goal of improving rehabilitation outcomes in a home setting."
Medicine,A Lesion-Based Diabetic Retinopathy Detection Through Hybrid Deep Learning Model,"Diabetic retinopathy (DR) can be defined as visual impairment caused by prolonged diabetes affecting the blood vessels in the retina. Globally, it stands as the primary contributor to blindness, impacting approximately 191 million individuals. While prior research has addressed DR classification using retinal fundus images, existing methods often focus on isolated lesion detection, lacking a comprehensive framework for the simultaneous identification of all lesions. Previous studies concentrated on early-stage features like exudates, aneurysms, hemorrhages, and blood vessels, sidelining severe-stage lesions such as cotton wool spots, venous beading, very severe intraretinal microvascular abnormalities (IRMA), diffuse intraretinal hemorrhages, capillary degeneration, highly activated microglia, and retinal pigment epithelium (RPE) damage. In this study, a deep learning approach is proposed to classify DR fundus images by severity levels, utilizing GoogleNet and ResNet models based on adaptive particle swarm optimizer (APSO), for enhanced feature extraction. The extracted features from the hybrid model are further used with different machine learning models like random forest, support vector machine, decision tree, and linear regression models. Experimental results showcased the proposed hybrid framework outperforming advanced approaches with a remarkable 94% accuracy on the benchmark dataset. This method demonstrates potential enhancements in precision, recall, accuracy, and F1 score for different DR severity levels.","['deep learning', 'GoogleNet', 'ResNet', 'adaptive particle swarm optimizer (APSO)', 'random forest', 'support vector machine', 'decision tree', 'linear regression']","Diabetic retinopathy (DR) is a major cause of visual impairment and blindness worldwide, affecting approximately 191 million individuals due to damage to the blood vessels in the retina caused by prolonged diabetes. Existing research has primarily focused on detecting early-stage lesions in DR, such as exudates, aneurysms, hemorrhages, and blood vessel abnormalities, but has often overlooked the identification of severe-stage lesions like cotton wool spots, venous beading, and retinal pigment epithelium damage. The primary aim of this study is to develop a comprehensive approach for classifying diabetic retinopathy fundus images according to severity levels, enabling the simultaneous identification of both early and severe-stage lesions. This classification seeks to improve the accuracy and reliability of DR severity assessment to better support clinical diagnosis and treatment planning."
Medicine,Assessing ChatGPT 4.0’s test performance and clinical diagnostic accuracy on USMLE STEP 2 CK and clinical case reports,"Abstract While there is data assessing the test performance of artificial intelligence (AI) chatbots, including the Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0), there is scarce data on its diagnostic accuracy of clinical cases. We assessed the large language model (LLM), ChatGPT 4.0, on its ability to answer questions from the United States Medical Licensing Exam (USMLE) Step 2, as well as its ability to generate a differential diagnosis based on corresponding clinical vignettes from published case reports. A total of 109 Step 2 Clinical Knowledge (CK) practice questions were inputted into both ChatGPT 3.5 and ChatGPT 4.0, asking ChatGPT to pick the correct answer. Compared to its previous version, ChatGPT 3.5, we found improved accuracy of ChatGPT 4.0 when answering these questions, from 47.7 to 87.2% ( p = 0.035) respectively. Utilizing the topics tested on Step 2 CK questions, we additionally found 63 corresponding published case report vignettes and asked ChatGPT 4.0 to come up with its top three differential diagnosis. ChatGPT 4.0 accurately created a shortlist of differential diagnoses in 74.6% of the 63 case reports (74.6%). We analyzed ChatGPT 4.0’s confidence in its diagnosis by asking it to rank its top three differentials from most to least likely. Out of the 47 correct diagnoses, 33 were the first (70.2%) on the differential diagnosis list, 11 were second (23.4%), and three were third (6.4%). Our study shows the continued iterative improvement in ChatGPT’s ability to answer standardized USMLE questions accurately and provides insights into ChatGPT’s clinical diagnostic accuracy.","['Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0)', 'large language model (LLM)']","The research idea centers on the need to evaluate the diagnostic accuracy of clinical case assessments, as there is limited information on how well certain tools perform in this regard despite existing data on their general test performance. This study addresses the gap in understanding the ability to accurately answer clinical knowledge questions and generate differential diagnoses based on clinical vignettes. The primary objective of the study is to assess the accuracy of responses to United States Medical Licensing Exam Step 2 Clinical Knowledge questions and the ability to generate appropriate differential diagnoses from published clinical case reports. The study aims to compare performance improvements over previous versions and to evaluate the confidence in diagnostic rankings provided for clinical cases."
Medicine,Advanced Ensemble Machine Learning Techniques for Optimizing Diabetes Mellitus Prognostication: A Detailed Examination of Hospital Data,"Diabetes is a chronic disease that affects millions of people worldwide. Early diagnosis and effective management are crucial for reducing its complications. Diabetes is the fourth-highest cause of mortality due to its association with various comorbidities, including heart disease, nerve damage, blood vessel damage, and blindness. The potential of machine learning algorithms in predicting Diabetes and related conditions is significant, and mining diabetes data is an efficient method for extracting new insights.The primary objective of this study is to develop an enhanced ensemble model to predict Diabetes with improved accuracy by leveraging various machine learning algorithms.This study tested several popular machine learning algorithms commonly used in diabetes prediction, including Naive Bayes (NB), Generalized Linear Model (GLM), Logistic Regression (LR), Fast Large Margin (FLM), Deep Learning (DL), Decision Tree (DT), Random Forest (RF), Gradient Boosted Trees (GBT), and Support Vector Machine (SVM). The performance of these algorithms was compared, and two different ensemble techniques—stacking and voting—were used to build a more accurate predictive model.The top three algorithms based on accuracy were Deep Learning, Naive Bayes, and Gradient Boosted Trees. The machine learning algorithms revealed that individuals with Diabetes are significantly affected by the number of chronic conditions they have, as well as their gender and age. The ensemble models, particularly the stacking method, provided higher accuracy than individual algorithms. The stacking ensemble model achieved a slightly better accuracy of 99.94% compared to 99.34% for the voting method.Building an ensemble model significantly increased the accuracy of predicting Diabetes and related conditions. The stacking ensemble model, in particular, demonstrated superior performance, highlighting the importance of combining multiple machine learning approaches to enhance predictive accuracy","['Naive Bayes (NB)', 'Logistic Regression (LR)', 'Deep Learning (DL)', 'Decision Tree (DT)', 'Random Forest (RF)', 'Gradient Boosted Trees (GBT)', 'Support Vector Machine (SVM)', 'stacking ensemble', 'voting ensemble']","Diabetes is a chronic disease that affects millions of people worldwide and is a leading cause of mortality due to its association with various comorbidities such as heart disease, nerve damage, blood vessel damage, and blindness. Early diagnosis and effective management are crucial for reducing the complications associated with diabetes. The primary objective of this study is to improve the accuracy of diabetes prediction by developing an enhanced approach that combines multiple methods. This study aims to identify the most effective strategies for predicting diabetes and related conditions to support better clinical outcomes."
Medicine,Bias in medical AI: Implications for clinical decision-making,"Biases in medical artificial intelligence (AI) arise and compound throughout the AI lifecycle. These biases can have significant clinical consequences, especially in applications that involve clinical decision-making. Left unaddressed, biased medical AI can lead to substandard clinical decisions and the perpetuation and exacerbation of longstanding healthcare disparities. We discuss potential biases that can arise at different stages in the AI development pipeline and how they can affect AI algorithms and clinical decision-making. Bias can occur in data features and labels, model development and evaluation, deployment, and publication. Insufficient sample sizes for certain patient groups can result in suboptimal performance, algorithm underestimation, and clinically unmeaningful predictions. Missing patient findings can also produce biased model behavior, including capturable but nonrandomly missing data, such as diagnosis codes, and data that is not usually or not easily captured, such as social determinants of health. Expertly annotated labels used to train supervised learning models may reflect implicit cognitive biases or substandard care practices. Overreliance on performance metrics during model development may obscure bias and diminish a model's clinical utility. When applied to data outside the training cohort, model performance can deteriorate from previous validation and can do so differentially across subgroups. How end users interact with deployed solutions can introduce bias. Finally, where models are developed and published, and by whom, impacts the trajectories and priorities of future medical AI development. Solutions to mitigate bias must be implemented with care, which include the collection of large and diverse data sets, statistical debiasing methods, thorough model evaluation, emphasis on model interpretability, and standardized bias reporting and transparency requirements. Prior to real-world implementation in clinical settings, rigorous validation through clinical trials is critical to demonstrate unbiased application. Addressing biases across model development stages is crucial for ensuring all patients benefit equitably from the future of medical AI.","['supervised learning', 'statistical debiasing methods']","The research idea centers on the presence and impact of biases in medical decision-making tools, which can arise and accumulate throughout their development and use. These biases pose significant clinical risks by potentially leading to substandard decisions and worsening existing healthcare disparities among patient groups. The study highlights how biases can originate from various sources, including patient data limitations, annotation practices, and the interaction between users and deployed tools, ultimately affecting the fairness and effectiveness of clinical applications. The research objective is to explore the different stages at which bias can occur in the development and deployment of medical decision-making tools and to emphasize the importance of implementing careful strategies to mitigate these biases. The study aims to ensure that such tools are validated rigorously before clinical use to promote equitable benefits for all patients and to prevent the perpetuation of healthcare inequalities."
Medicine,Performance of Generative Pretrained Transformer on the National Medical Licensing Examination in Japan,"The remarkable performance of ChatGPT, launched in November 2022, has significantly impacted the field of natural language processing, inspiring the application of large language models as supportive tools in clinical practice and research worldwide. Although GPT-3.5 recently scored high on the United States Medical Licensing Examination, its performance on medical licensing examinations of other nations, especially non-English speaking nations, has not been sufficiently evaluated. This study assessed GPT’s performance on the National Medical Licensing Examination (NMLE) in Japan and compared it with the actual minimal passing rate for this exam. In particular, the performances of both the GPT-3.5 and GPT-4 models were considered for the comparative analysis. We initially used the GPT models and several prompts for 290 questions without image data from the 116 th NMLE (held in February 2022 in Japan) to maximize the performance for delivering correct answers and explanations of the questions. Thereafter, we tested the performance of the best GPT model (GPT-4) with optimized prompts on a dataset of 262 questions without images from the latest 117 th NMLE (held in February 2023). The best model with the optimized prompts scored 82.7% for the essential questions and 77.2% for the basic and clinical questions, both of which sufficed the minimum passing scoring rates of 80.0% and 74.6%, respectively. After an exploratory analysis of 56 incorrect answers from the model, we identified the three major factors contributing to the generation of the incorrect answers—insufficient medical knowledge, information on Japan-specific medical system and guidelines, and mathematical errors. In conclusion, GPT-4 with our optimized prompts achieved a minimum passing scoring rate in the latest 117 th NMLE in Japan. Beyond its original design of answering examination questions for humans, these artificial intelligence (AI) models can serve as one of the best “sidekicks” for solving problems and addressing the unmet needs in the medical and healthcare fields.","['GPT-3.5', 'GPT-4']","The study addresses the need to evaluate the performance of advanced language models on medical licensing examinations outside of English-speaking countries, focusing on Japan where such assessments have been insufficient. It highlights the importance of understanding how well these models can meet the standards required for medical knowledge and clinical reasoning in different national contexts. The primary aim of the study was to assess the performance of language models on the National Medical Licensing Examination (NMLE) in Japan and to compare their scores with the actual minimal passing rates for this exam. Specifically, the study sought to determine whether these models could achieve passing scores on essential, basic, and clinical questions from recent NMLE tests and to identify factors contributing to incorrect answers."
Medicine,A novel SpaSA based hyper-parameter optimized FCEDN with adaptive CNN classification for skin cancer detection,"Abstract Skin cancer is the most prevalent kind of cancer in people. It is estimated that more than 1 million people get skin cancer every year in the world. The effectiveness of the disease’s therapy is significantly impacted by early identification of this illness. Preprocessing is the initial detecting stage in enhancing the quality of skin images by removing undesired background noise and objects. This study aims is to compile preprocessing techniques for skin cancer imaging that are currently accessible. Researchers looking into automated skin cancer diagnosis might use this article as an excellent place to start. The fully convolutional encoder–decoder network and Sparrow search algorithm (FCEDN-SpaSA) are proposed in this study for the segmentation of dermoscopic images. The individual wolf method and the ensemble ghosting technique are integrated to generate a neighbour-based search strategy in SpaSA for stressing the correct balance between navigation and exploitation. The classification procedure is accomplished by using an adaptive CNN technique to discriminate between normal skin and malignant skin lesions suggestive of disease. Our method provides classification accuracies comparable to commonly used incremental learning techniques while using less energy, storage space, memory access, and training time (only network updates with new training samples, no network sharing). In a simulation, the segmentation performance of the proposed technique on the ISBI 2017, ISIC 2018, and PH2 datasets reached accuracies of 95.28%, 95.89%, 92.70%, and 98.78%, respectively, on the same dataset and assessed the classification performance. It is accurate 91.67% of the time. The efficiency of the suggested strategy is demonstrated through comparisons with cutting-edge methodologies.","['fully convolutional encoder–decoder network', 'Sparrow search algorithm (SpaSA)', 'adaptive CNN technique', 'incremental learning techniques']","The research idea addresses the high prevalence of skin cancer worldwide, with over 1 million new cases annually, emphasizing that early identification significantly impacts the effectiveness of therapy. Improving the quality of skin images by removing undesired background noise and objects during the initial detection stage is crucial for enhancing diagnosis. The study focuses on compiling existing preprocessing techniques for skin cancer imaging to support researchers in the field of automated diagnosis. The research objective is to develop and evaluate a method for segmenting and classifying dermoscopic images to accurately distinguish between normal skin and malignant skin lesions. The study aims to achieve high classification accuracy while optimizing resource use, thereby improving the diagnosis process for skin cancer."
Medicine,Investigating the impact of motion in the scanner on brain age predictions,"Abstract Brain Age Gap (BAG) is defined as the difference between the brain’s predicted age and the chronological age of an individual. Magnetic resonance imaging (MRI)-based BAG can quantify acceleration of brain aging, and is used to infer brain health as aging and disease interact. Motion in the scanner is a common occurrence that can affect the acquired MRI data and act as a major confound in the derived models. As such, age-related changes in head motion may impact the observed age-related differences. However, the relationship between head motion and BAG as estimated by structural MRI has not been systematically examined. The aim of this study is to assess the impact of motion on voxel-based morphometry (VBM) based BAG. Data were obtained from two sources: i) T1-weighted (T1w) MRIs from the Cambridge Centre for Ageing and Neuroscience (CamCAN) were used to train the brain age prediction model, and ii) T1w MRIs from the Movement-related artifacts (MR-ART) dataset were used to assess the impact of motion on BAG. MR-ART includes one motion-free and two motion-affected (one low and one high) 3D T1w MRIs. We also visually rated the motion levels of the MR-ART MRIs from 0 to 5, with 0 meaning no motion and 5 high motion levels. All images were pre-processed through a standard VBM pipeline. GM density across cortical and subcortical regions were then used to train the brain age prediction model and assess the relationship between BAG and MRI motion. Principal component analysis was used to perform dimension reduction and extract the VBM-based features. BAG was estimated by regressing out the portion of delta age explained by chronological age. Linear mixed-effects models were used to investigate the relationship between BAG and motion session as well as motion severity, including participant IDs as random effects. We repeated the same analysis using cortical thickness based on FreeSurfer 7.4.1 and to compare the results for volumetric versus surface-based measures of brain morphometry. In contrast with the session with no induced motion, predicted delta age was significantly higher for high motion sessions 2.35 years (t = 5.17, p &amp;lt; 0.0001), with marginal effect for low motion sessions 0.95 years (t = 2.11, p = 0.035) for VBM analysis as well as 3.46 years (t = 11.45, p &amp;lt; 0.0001) for high motion and 2.28 years (t = 7.54, p &amp;lt; 0.0001) for low motion based on cortical thickness. In addition, delta age was significantly associated with motion severity as evaluated by visual rating 0.45 years per rating level (t = 4.59, p &amp;lt; 0.0001) for VBM analysis and 0.83 years per motion level (t = 12.89, p &amp;lt; 0.0001) for cortical thickness analysis. Motion in the scanner can significantly impact brain age estimates, and needs to be accounted for as a confound, particularly when studying populations that are known to have higher levels of motion in the scanner. These results have significant implications for brain age studies in aging and neurodegeneration. Based on these findings, we recommend assessment and inclusion of visual motion ratings in such studies. In cases that the visual rating proves prohibitive, we recommend the inclusion of normalized Euler number from FreeSurfer as defined in the manuscript as a covariate in the models.","['principal component analysis', 'regression']","The study addresses the issue that motion during magnetic resonance imaging (MRI) scans can affect the accuracy of brain age estimates, which are used to assess brain health by quantifying accelerated brain aging. Since head motion is common and may vary with age, it could confound the interpretation of age-related brain changes, yet the relationship between head motion and brain age gap (BAG) derived from structural MRI has not been thoroughly investigated. The primary aim of this study is to evaluate the impact of motion on brain age gap measurements obtained from voxel-based morphometry (VBM) and cortical thickness analyses. The study seeks to determine how different levels of motion during MRI scanning influence brain age estimates and to provide recommendations for accounting for motion as a confounding factor in brain aging research."
Medicine,Reliability of ChatGPT for performing triage task in the emergency department using the Korean Triage and Acuity Scale,"Background Artificial intelligence (AI) technology can enable more efficient decision-making in healthcare settings. There is a growing interest in improving the speed and accuracy of AI systems in providing responses for given tasks in healthcare settings. Objective This study aimed to assess the reliability of ChatGPT in determining emergency department (ED) triage accuracy using the Korean Triage and Acuity Scale (KTAS). Methods Two hundred and two virtual patient cases were built. The gold standard triage classification for each case was established by an experienced ED physician. Three other human raters (ED paramedics) were involved and rated the virtual cases individually. The virtual cases were also rated by two different versions of the chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0). Inter-rater reliability was examined using Fleiss’ kappa and intra-class correlation coefficient (ICC). Results The kappa values for the agreement between the four human raters and ChatGPTs were .523 (version 4.0) and .320 (version 3.5). Of the five levels, the performance was poor when rating patients at levels 1 and 5, as well as case scenarios with additional text descriptions. There were differences in the accuracy of the different versions of GPTs. The ICC between version 3.5 and the gold standard was .520, and that between version 4.0 and the gold standard was .802. Conclusions A substantial level of inter-rater reliability was revealed when GPTs were used as KTAS raters. The current study showed the potential of using GPT in emergency healthcare settings. Considering the shortage of experienced manpower, this AI method may help improve triaging accuracy.","['chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0)']","The research idea addresses the challenge of ensuring accurate and efficient triage decisions in emergency department settings, which is critical for patient care and resource allocation. There is a recognized need to improve the speed and reliability of triage assessments to support healthcare providers, especially given the shortage of experienced personnel. The study focuses on evaluating the consistency and accuracy of triage classifications using the Korean Triage and Acuity Scale (KTAS) in emergency care scenarios. The primary objective of the study was to assess the reliability of ChatGPT in determining emergency department triage accuracy according to the KTAS. This involved comparing triage ratings from ChatGPT with those from experienced emergency department physicians and paramedics to evaluate agreement and consistency in triage decisions."
Medicine,Assessing generalisability of deep learning-based polyp detection and segmentation methods through a computer vision challenge,"Abstract Polyps are well-known cancer precursors identified by colonoscopy. However, variability in their size, appearance, and location makes the detection of polyps challenging. Moreover, colonoscopy surveillance and removal of polyps are highly operator-dependent procedures and occur in a highly complex organ topology. There exists a high missed detection rate and incomplete removal of colonic polyps. To assist in clinical procedures and reduce missed rates, automated methods for detecting and segmenting polyps using machine learning have been achieved in past years. However, the major drawback in most of these methods is their ability to generalise to out-of-sample unseen datasets from different centres, populations, modalities, and acquisition systems. To test this hypothesis rigorously, we, together with expert gastroenterologists, curated a multi-centre and multi-population dataset acquired from six different colonoscopy systems and challenged the computational expert teams to develop robust automated detection and segmentation methods in a crowd-sourcing Endoscopic computer vision challenge. This work put forward rigorous generalisability tests and assesses the usability of devised deep learning methods in dynamic and actual clinical colonoscopy procedures. We analyse the results of four top performing teams for the detection task and five top performing teams for the segmentation task. Our analyses demonstrate that the top-ranking teams concentrated mainly on accuracy over the real-time performance required for clinical applicability. We further dissect the devised methods and provide an experiment-based hypothesis that reveals the need for improved generalisability to tackle diversity present in multi-centre datasets and routine clinical procedures.","['machine learning', 'deep learning']","The research idea addresses the challenge of detecting colonic polyps during colonoscopy, which is complicated by variability in polyp size, appearance, and location, as well as the highly operator-dependent nature of surveillance and removal procedures within a complex organ topology. There is a significant issue with high missed detection rates and incomplete removal of polyps, which can impact cancer prevention efforts. The study is motivated by the need to improve the reliability and generalisability of polyp detection methods across diverse clinical settings and populations.

The primary objective of the study is to rigorously evaluate the generalisability and clinical applicability of automated polyp detection and segmentation methods using a multi-centre, multi-population dataset acquired from different colonoscopy systems. The study aims to assess the performance of these methods in real-world clinical procedures, identify limitations related to accuracy and real-time usability, and highlight the necessity for improved approaches that can effectively handle the diversity encountered in routine colonoscopy practice."
Medicine,"Clinical gait analysis using video-based pose estimation: Multiple perspectives, clinical populations, and measuring change","Gait dysfunction is common in many clinical populations and often has a profound and deleterious impact on independence and quality of life. Gait analysis is a foundational component of rehabilitation because it is critical to identify and understand the specific deficits that should be targeted prior to the initiation of treatment. Unfortunately, current state-of-the-art approaches to gait analysis (e.g., marker-based motion capture systems, instrumented gait mats) are largely inaccessible due to prohibitive costs of time, money, and effort required to perform the assessments. Here, we demonstrate the ability to perform quantitative gait analyses in multiple clinical populations using only simple videos recorded using low-cost devices (tablets). We report four primary advances: 1) a novel, versatile workflow that leverages an open-source human pose estimation algorithm (OpenPose) to perform gait analyses using videos recorded from multiple different perspectives (e.g., frontal, sagittal), 2) validation of this workflow in three different populations of participants (adults without gait impairment, persons post-stroke, and persons with Parkinson’s disease) via comparison to ground-truth three-dimensional motion capture, 3) demonstration of the ability to capture clinically relevant, condition-specific gait parameters, and 4) tracking of within-participant changes in gait, as is required to measure progress in rehabilitation and recovery. Importantly, our workflow has been made freely available and does not require prior gait analysis expertise. The ability to perform quantitative gait analyses in nearly any setting using only low-cost devices and computer vision offers significant potential for dramatic improvement in the accessibility of clinical gait analysis across different patient populations.",['human pose estimation algorithm (OpenPose)'],"Gait dysfunction is common in many clinical populations and often has a profound and deleterious impact on independence and quality of life. Gait analysis is a foundational component of rehabilitation because it is critical to identify and understand the specific deficits that should be targeted prior to the initiation of treatment. The study’s primary aim is to demonstrate the ability to perform quantitative gait analyses in multiple clinical populations using only simple videos recorded with low-cost devices. It seeks to validate this approach across different participant groups, capture clinically relevant gait parameters specific to conditions, and track changes in gait within individuals to measure rehabilitation progress."
Medicine,ELRL-MD: a deep learning approach for myocarditis diagnosis using cardiac magnetic resonance images with ensemble and reinforcement learning integration,"Abstract Objective. Myocarditis poses a significant health risk, often precipitated by viral infections like coronavirus disease, and can lead to fatal cardiac complications. As a less invasive alternative to the standard diagnostic practice of endomyocardial biopsy, which is highly invasive and thus limited to severe cases, cardiac magnetic resonance (CMR) imaging offers a promising solution for detecting myocardial abnormalities. Approach. This study introduces a deep model called ELRL-MD that combines ensemble learning and reinforcement learning (RL) for effective myocarditis diagnosis from CMR images. The model begins with pre-training via the artificial bee colony (ABC) algorithm to enhance the starting point for learning. An array of convolutional neural networks (CNNs) then works in concert to extract and integrate features from CMR images for accurate diagnosis. Leveraging the Z-Alizadeh Sani myocarditis CMR dataset, the model employs RL to navigate the dataset’s imbalance by conceptualizing diagnosis as a decision-making process. Main results. ELRL-DM demonstrates remarkable efficacy, surpassing other deep learning, conventional machine learning, and transfer learning models, achieving an F-measure of 88.2% and a geometric mean of 90.6%. Extensive experimentation helped pinpoint the optimal reward function settings and the perfect count of CNNs. Significance. The study addresses the primary technical challenge of inherent data imbalance in CMR imaging datasets and the risk of models converging on local optima due to suboptimal initial weight settings. Further analysis, leaving out ABC and RL components, confirmed their contributions to the model’s overall performance, underscoring the effectiveness of addressing these critical technical challenges.","['ensemble learning', 'reinforcement learning (RL)', 'artificial bee colony (ABC) algorithm', 'convolutional neural networks (CNNs)', 'deep learning', 'transfer learning']","Myocarditis is a serious health condition often caused by viral infections such as coronavirus disease, which can result in fatal cardiac complications. The standard diagnostic method, endomyocardial biopsy, is highly invasive and typically reserved for severe cases, creating a need for less invasive diagnostic alternatives. Cardiac magnetic resonance (CMR) imaging presents a promising non-invasive approach for detecting myocardial abnormalities associated with myocarditis. The primary aim of this study is to improve the diagnosis of myocarditis using CMR images as a less invasive alternative to biopsy, addressing challenges such as data imbalance and diagnostic accuracy to enhance early detection and patient outcomes."
Medicine,GPT-4 Turbo with Vision fails to outperform text-only GPT-4 Turbo in the Japan Diagnostic Radiology Board Examination,"Abstract Purpose To assess the performance of GPT-4 Turbo with Vision (GPT-4TV), OpenAI’s latest multimodal large language model, by comparing its ability to process both text and image inputs with that of the text-only GPT-4 Turbo (GPT-4 T) in the context of the Japan Diagnostic Radiology Board Examination (JDRBE). Materials and methods The dataset comprised questions from JDRBE 2021 and 2023. A total of six board-certified diagnostic radiologists discussed the questions and provided ground-truth answers by consulting relevant literature as necessary. The following questions were excluded: those lacking associated images, those with no unanimous agreement on answers, and those including images rejected by the OpenAI application programming interface. The inputs for GPT-4TV included both text and images, whereas those for GPT-4 T were entirely text. Both models were deployed on the dataset, and their performance was compared using McNemar’s exact test. The radiological credibility of the responses was assessed by two diagnostic radiologists through the assignment of legitimacy scores on a five-point Likert scale. These scores were subsequently used to compare model performance using Wilcoxon's signed-rank test. Results The dataset comprised 139 questions. GPT-4TV correctly answered 62 questions (45%), whereas GPT-4 T correctly answered 57 questions (41%). A statistical analysis found no significant performance difference between the two models (P = 0.44). The GPT-4TV responses received significantly lower legitimacy scores from both radiologists than the GPT-4 T responses. Conclusion No significant enhancement in accuracy was observed when using GPT-4TV with image input compared with that of using text-only GPT-4 T for JDRBE questions.",['GPT-4 Turbo (GPT-4 T)'],"The research idea centers on evaluating the effectiveness of incorporating both text and image inputs in assessing diagnostic radiology knowledge, specifically within the context of the Japan Diagnostic Radiology Board Examination (JDRBE). The study addresses the need to understand whether the addition of visual information improves the accuracy and credibility of responses to radiology examination questions. The primary objective of the study is to compare the performance of a multimodal approach that processes both text and images with a text-only approach in answering JDRBE questions. This comparison aims to determine if including image inputs leads to a significant enhancement in accuracy or radiological credibility of the responses."
Medicine,The role of artificial intelligence in generating original scientific research,"Artificial intelligence (AI) is a revolutionary technology that is finding wide application across numerous sectors. Large language models (LLMs) are an emerging subset technology of AI and have been developed to communicate using human languages. At their core, LLMs are trained with vast amounts of information extracted from the internet, including text and images. Their ability to create human-like, expert text in almost any subject means they are increasingly being used as an aid to presentation, particularly in scientific writing. However, we wondered whether LLMs could go further, generating original scientific research and preparing the results for publication. We tasked GPT-4, an LLM, to write an original pharmaceutics manuscript, on a topic that is itself novel. It was able to conceive a research hypothesis, define an experimental protocol, produce photo-realistic images of printlets, generate believable analytical data from a range of instruments and write a convincing publication-ready manuscript with evidence of critical interpretation. The model achieved all this is less than 1h. Moreover, the generated data were multi-modal in nature, including thermal analyses, vibrational spectroscopy and dissolution testing, demonstrating multi-disciplinary expertise in the LLM. One area in which the model failed, however, was in referencing to the literature. Since the generated experimental results appeared believable though, we suggest that LLMs could certainly play a role in scientific research but with human input, interpretation and data validation. We discuss the potential benefits and current bottlenecks for realising this ambition here.",['GPT-4'],"The research idea centers on exploring the potential of advanced technologies to generate original scientific research and prepare results for publication, particularly in the field of pharmaceutics. The study addresses the question of whether such technologies can conceive research hypotheses, define experimental protocols, produce realistic experimental data, and write convincing manuscripts independently. The motivation arises from the increasing use of these technologies as aids in scientific writing and the possibility of extending their role to more autonomous scientific research activities. The primary objective of the study is to evaluate the capability of these technologies to create an original pharmaceutics manuscript on a novel topic, including generating experimental data from various analytical techniques and producing a publication-ready document with critical interpretation. The study also aims to identify the limitations of these technologies, such as referencing to existing literature, and to discuss the potential benefits and current challenges in integrating them into scientific research with necessary human oversight."
Medicine,LBO-MPAM: Ladybug Beetle Optimization-based multilayer perceptron attention module for segmenting the skin lesion and automatic localization,"In recent years, skin cancer has been the most dangerous disease noticed among people worldwide. Skin cancer should be identified earlier to reduce the rate of mortality. Employing dermoscopic images can identify and categorise skin cancer effectively. But, the visual evaluation is a complex procedure to be done in the dermoscopic image. However, Deep learning (DL) is an efficient method for skin cancer detection; however, segmenting the skin lesion and automatic localisation in an earlier stage is complicated. In this paper, a novel Ladybug Beetle Optimization-Double Attention Based Multilevel 1-D CNN (LBO-DAM 1-D CNN) technique is proposed to detect and classify skin cancer. To improve skin lesion type discriminability, the two types of attention modules are introduced. The Ultra-Lightweight Subspace Attention Module (ULSAM) is utilised for classifying the feature maps into different stages to validate the frequency from different image samples. However, the multilayer perceptron attention module (MLPAM) is determined to provide information regarding skin cancer classification and diminish the noise and unwanted data. To minimise data loss, it is then combined with hierarchical complementarity during classification. Second, a modified MLPAM is used to extract significant feature spaces for network learning, select the most important information, and reduce feature space redundancy. The Ladybug Beetle Optimization (LBO) algorithm provides the optimal classification solution by minimising the loss rate of DAM 1-D CNN architecture. The experimentation is conducted on three different datasets such as ISIC2020, HAM10000, and the melanoma detection dataset. The experimental results revealed that the proposed method is compared with different existing methods such as IMFO-KELM, Mask RCNN, M-SVM, DCNN-9, and TL-CNN with different datasets. These methods attained 94.56, 92.65, 90.56, 88.65, and 95.5 for the ISIC2020 dataset but the proposed method enhanced the classification performance by attaining 97.02. Also, the validation is based on metrics, namely, accuracy, precision, sensitivity, and F1-score of 97.03%, 97.05%, 97.58%, and 97.27% for a total of 500 epochs.","['Deep learning (DL)', 'Mask RCNN', 'M-SVM']","The research idea addresses the critical need for early identification of skin cancer to reduce mortality rates, highlighting the challenges associated with visual evaluation of dermoscopic images for effective detection and categorization. The complexity of segmenting skin lesions and localizing them at an early stage presents a significant obstacle in improving diagnostic accuracy. The primary objective of the study is to develop a novel approach to detect and classify skin cancer more effectively by enhancing the discriminability of skin lesion types and minimizing data loss during classification. The study aims to improve classification performance on multiple skin cancer datasets, thereby contributing to more accurate and early diagnosis of the disease."
Medicine,Effective lung nodule detection using deep CNN with dual attention mechanisms,"Abstract Novel methods are required to enhance lung cancer detection, which has overtaken other cancer-related causes of death as the major cause of cancer-related mortality. Radiologists have long-standing methods for locating lung nodules in patients with lung cancer, such as computed tomography (CT) scans. Radiologists must manually review a significant amount of CT scan pictures, which makes the process time-consuming and prone to human error. Computer-aided diagnosis (CAD) systems have been created to help radiologists with their evaluations in order to overcome these difficulties. These systems make use of cutting-edge deep learning architectures. These CAD systems are designed to improve lung nodule diagnosis efficiency and accuracy. In this study, a bespoke convolutional neural network (CNN) with a dual attention mechanism was created, which was especially crafted to concentrate on the most important elements in images of lung nodules. The CNN model extracts informative features from the images, while the attention module incorporates both channel attention and spatial attention mechanisms to selectively highlight significant features. After the attention module, global average pooling is applied to summarize the spatial information. To evaluate the performance of the proposed model, extensive experiments were conducted using benchmark dataset of lung nodules. The results of these experiments demonstrated that our model surpasses recent models and achieves state-of-the-art accuracy in lung nodule detection and classification tasks.","['convolutional neural network (CNN)', 'dual attention mechanism', 'channel attention', 'spatial attention', 'global average pooling']","The study addresses the critical need for improved methods to enhance lung cancer detection, as lung cancer has become the leading cause of cancer-related mortality. Traditional approaches, such as manual review of computed tomography (CT) scans by radiologists, are time-consuming and susceptible to human error, highlighting the necessity for more efficient and accurate diagnostic techniques. The primary aim of the study is to develop a specialized approach that focuses on the most important features in lung nodule images to improve the efficiency and accuracy of lung nodule diagnosis. This approach is intended to assist radiologists in better identifying and classifying lung nodules, ultimately contributing to more effective lung cancer detection."
Medicine,A precise model for skin cancer diagnosis using hybrid U-Net and improved MobileNet-V3 with hyperparameters optimization,"Abstract Skin cancer is a frequently occurring and possibly deadly disease that necessitates prompt and precise diagnosis in order to ensure efficacious treatment. This paper introduces an innovative approach for accurately identifying skin cancer by utilizing Convolution Neural Network architecture and optimizing hyperparameters. The proposed approach aims to increase the precision and efficacy of skin cancer recognition and consequently enhance patients' experiences. This investigation aims to tackle various significant challenges in skin cancer recognition, encompassing feature extraction, model architecture design, and optimizing hyperparameters. The proposed model utilizes advanced deep-learning methodologies to extract complex features and patterns from skin cancer images. We enhance the learning procedure of deep learning by integrating Standard U-Net and Improved MobileNet-V3 with optimization techniques, allowing the model to differentiate malignant and benign skin cancers. Also substituted the crossed-entropy loss function of the Mobilenet-v3 mathematical framework with a bias loss function to enhance the accuracy. The model's squeeze and excitation component was replaced with the practical channel attention component to achieve parameter reduction. Integrating cross-layer connections among Mobile modules has been proposed to leverage synthetic features effectively. The dilated convolutions were incorporated into the model to enhance the receptive field. The optimization of hyperparameters is of utmost importance in improving the efficiency of deep learning models. To fine-tune the model's hyperparameter, we employ sophisticated optimization methods such as the Bayesian optimization method using pre-trained CNN architecture MobileNet-V3. The proposed model is compared with existing models, i.e., MobileNet, VGG-16, MobileNet-V2, Resnet-152v2 and VGG-19 on the “HAM-10000 Melanoma Skin Cancer dataset"". The empirical findings illustrate that the proposed optimized hybrid MobileNet-V3 model outperforms existing skin cancer detection and segmentation techniques based on high precision of 97.84%, sensitivity of 96.35%, accuracy of 98.86% and specificity of 97.32%. The enhanced performance of this research resulted in timelier and more precise diagnoses, potentially contributing to life-saving outcomes and mitigating healthcare expenditures.","['Standard U-Net', 'Improved MobileNet-V3', 'dilated convolutions', 'Bayesian optimization method', 'pre-trained CNN architecture MobileNet-V3']","The research idea centers on addressing the critical need for prompt and precise diagnosis of skin cancer, a common and potentially fatal disease, to ensure effective treatment and improve patient outcomes. The study recognizes significant challenges in accurately identifying skin cancer, including the extraction of relevant features and differentiation between malignant and benign cases. The research objective is to develop an approach that enhances the precision and efficacy of skin cancer recognition, thereby improving diagnostic accuracy and patient experiences. This investigation aims to overcome existing difficulties in skin cancer detection by improving the methods used to distinguish between different types of skin cancer, ultimately contributing to timelier and more accurate diagnoses."
Medicine,Leveraging artificial intelligence in vaccine development: A narrative review,"Vaccine development stands as a cornerstone of public health efforts, pivotal in curbing infectious diseases and reducing global morbidity and mortality. However, traditional vaccine development methods are often time-consuming, costly, and inefficient. The advent of artificial intelligence (AI) has ushered in a new era in vaccine design, offering unprecedented opportunities to expedite the process. This narrative review explores the role of AI in vaccine development, focusing on antigen selection, epitope prediction, adjuvant identification, and optimization strategies. AI algorithms, including machine learning and deep learning, leverage genomic data, protein structures, and immune system interactions to predict antigenic epitopes, assess immunogenicity, and prioritize antigens for experimentation. Furthermore, AI-driven approaches facilitate the rational design of immunogens and the identification of novel adjuvant candidates with optimal safety and efficacy profiles. Challenges such as data heterogeneity, model interpretability, and regulatory considerations must be addressed to realize the full potential of AI in vaccine development. Integrating emerging technologies, such as single-cell omics and synthetic biology, promises to enhance vaccine design precision and scalability. This review underscores the transformative impact of AI on vaccine development and highlights the need for interdisciplinary collaborations and regulatory harmonization to accelerate the delivery of safe and effective vaccines against infectious diseases.","['machine learning', 'deep learning']","The research idea centers on the critical role of vaccine development in public health as a means to control infectious diseases and reduce global morbidity and mortality. Traditional vaccine development methods are often slow, costly, and inefficient, creating a need for more effective approaches to expedite the process. The study highlights the challenges and opportunities involved in improving vaccine design to enhance safety, efficacy, and scalability. The primary objective of the study is to explore advancements that can accelerate vaccine development by improving antigen selection, epitope prediction, adjuvant identification, and optimization strategies. It aims to emphasize the importance of interdisciplinary collaboration and regulatory harmonization to facilitate the delivery of safe and effective vaccines against infectious diseases."
Medicine,Efficient pneumonia detection using Vision Transformers on chest X-rays,"Abstract Pneumonia is a widespread and acute respiratory infection that impacts people of all ages. Early detection and treatment of pneumonia are essential for avoiding complications and enhancing clinical results. We can reduce mortality, improve healthcare efficiency, and contribute to the global battle against a disease that has plagued humanity for centuries by devising and deploying effective detection methods. Detecting pneumonia is not only a medical necessity but also a humanitarian imperative and a technological frontier. Chest X-rays are a frequently used imaging modality for diagnosing pneumonia. This paper examines in detail a cutting-edge method for detecting pneumonia implemented on the Vision Transformer (ViT) architecture on a public dataset of chest X-rays available on Kaggle. To acquire global context and spatial relationships from chest X-ray images, the proposed framework deploys the ViT model, which integrates self-attention mechanisms and transformer architecture. According to our experimentation with the proposed Vision Transformer-based framework, it achieves a higher accuracy of 97.61%, sensitivity of 95%, and specificity of 98% in detecting pneumonia from chest X-rays. The ViT model is preferable for capturing global context, comprehending spatial relationships, and processing images that have different resolutions. The framework establishes its efficacy as a robust pneumonia detection solution by surpassing convolutional neural network (CNN) based architectures.","['Vision Transformer (ViT)', 'self-attention mechanisms', 'transformer architecture', 'convolutional neural network (CNN) based architectures']","Pneumonia is a widespread and acute respiratory infection that affects individuals of all ages, and early detection and treatment are crucial to prevent complications and improve clinical outcomes. Reducing mortality and enhancing healthcare efficiency in managing pneumonia remain significant challenges in the global fight against this longstanding disease. The primary aim of this study is to improve the detection of pneumonia using chest X-ray images, which are commonly employed for diagnosis. This research focuses on developing an effective approach to accurately identify pneumonia cases from chest X-rays to support timely and appropriate medical intervention."
Medicine,Collaborative threat intelligence: Enhancing IoT security through blockchain and machine learning integration,"Ensuring robust security in the Internet of Things (IoT) landscape is of paramount importance. This research article presents a novel approach to enhance IoT security by leveraging collaborative threat intelligence and integrating blockchain technology with machine learning (ML) models. The iOS application acts as a central control centre, facilitating the reporting and sharing of detected threats. The shared threat data is securely stored on a blockchain network, enabling ML models to access and learn from a diverse range of threat scenarios. The research focuses on implementing Random Forest, Decision Tree classifier, Ensemble, LSTM, and CNN models on the IoT23 dataset within the context of a Collaborative Threat Intelligence Framework for IoT Security. Through an iterative process, the models' accuracy is improved by reducing false negatives through the collaborative threat intelligence system. The article investigates the implementation details, privacy considerations, and the seamless integration of ML-based techniques for continuous model improvement. Experimental evaluations on the IoT23 dataset demonstrate the effectiveness of the proposed system in enhancing IoT security and mitigating potential threats. The research contributes to the advancement of collaborative threat intelligence and blockchain technology in the context of IoT security, paving the way for more secure and reliable IoT deployments.","['Random Forest', 'Decision Tree classifier', 'Ensemble', 'LSTM', 'CNN']","The research addresses the critical need for robust security measures in the Internet of Things (IoT) environment, focusing on the challenge of effectively detecting and mitigating potential threats to ensure safe and reliable IoT deployments. The study is motivated by the importance of enhancing security frameworks to protect interconnected devices from evolving cyber threats. The primary objective of the study is to develop and evaluate a collaborative approach that improves threat detection and sharing among IoT devices, aiming to reduce false negatives and enhance overall security. This approach seeks to enable continuous improvement in identifying and responding to diverse threat scenarios within the IoT landscape."
Medicine,Multimodal data integration for oncology in the era of deep neural networks: a review,"Cancer research encompasses data across various scales, modalities, and resolutions, from screening and diagnostic imaging to digitized histopathology slides to various types of molecular data and clinical records. The integration of these diverse data types for personalized cancer care and predictive modeling holds the promise of enhancing the accuracy and reliability of cancer screening, diagnosis, and treatment. Traditional analytical methods, which often focus on isolated or unimodal information, fall short of capturing the complex and heterogeneous nature of cancer data. The advent of deep neural networks has spurred the development of sophisticated multimodal data fusion techniques capable of extracting and synthesizing information from disparate sources. Among these, Graph Neural Networks (GNNs) and Transformers have emerged as powerful tools for multimodal learning, demonstrating significant success. This review presents the foundational principles of multimodal learning including oncology data modalities, taxonomy of multimodal learning, and fusion strategies. We delve into the recent advancements in GNNs and Transformers for the fusion of multimodal data in oncology, spotlighting key studies and their pivotal findings. We discuss the unique challenges of multimodal learning, such as data heterogeneity and integration complexities, alongside the opportunities it presents for a more nuanced and comprehensive understanding of cancer. Finally, we present some of the latest comprehensive multimodal pan-cancer data sources. By surveying the landscape of multimodal data integration in oncology, our goal is to underline the transformative potential of multimodal GNNs and Transformers. Through technological advancements and the methodological innovations presented in this review, we aim to chart a course for future research in this promising field. This review may be the first that highlights the current state of multimodal modeling applications in cancer using GNNs and transformers, presents comprehensive multimodal oncology data sources, and sets the stage for multimodal evolution, encouraging further exploration and development in personalized cancer care.","['deep neural networks', 'Graph Neural Networks (GNNs)', 'Transformers']","The research idea centers on the challenge of integrating diverse types of cancer-related data—ranging from screening and diagnostic imaging to histopathology slides, molecular data, and clinical records—to improve personalized cancer care. Traditional methods that analyze isolated data types are insufficient for capturing the complex and heterogeneous nature of cancer, highlighting the need for more comprehensive approaches to enhance the accuracy and reliability of cancer screening, diagnosis, and treatment. The primary objective of the study is to review and present the foundational principles and recent advancements in the integration of multimodal oncology data, emphasizing the potential to achieve a more nuanced and comprehensive understanding of cancer. This review aims to highlight current multimodal data sources and fusion strategies in oncology, discuss the challenges and opportunities of data integration, and set the stage for future research to advance personalized cancer care."
Medicine,A domain adaptation approach to damage classification with an application to bridge monitoring,"Data-driven machine-learning algorithms generally suffer from a lack of labelled health-state data, mainly those referring to damage conditions. To address such an issue, population-based structural health monitoring seeks to enrich the original dataset by transferring knowledge from a population of monitored structures. Within this context, this paper presents a transfer learning approach, based on domain adaptation, to leverage information from completely-labelled bridge structure data to accurately predict new instances of an unknown target domain. Since intrinsic structural differences may cause distribution shifts, domain adaptation attempts to minimise the distance between the domains and to learn a mapping within a shared feature space. Specifically, the methodology involves the long-term acquisition of natural frequencies from several structural scenarios. Such damage-sensitive features are then aligned via domain adaptation so that a machine-learning algorithm can effectively utilise the labelled source domain data and generalise well to the unlabelled target-domain data. The described procedure is applied to two case studies, including the Z24 and the S101 benchmark bridges and their finite element models, respectively. The results demonstrate the successful exchange of health-state labels to identify the damage class within a population of bridges equipped with SHM systems, showing potential to reduce computational efforts and to deal with scarce or poor data sets in application to bridge network monitoring.","['transfer learning', 'domain adaptation']","The research idea addresses the challenge of limited labeled health-state data related to damage conditions in structural health monitoring of bridges. This scarcity hinders accurate identification and assessment of damage within individual structures. The study is motivated by the need to improve damage detection by leveraging information from a population of monitored bridges to enhance the understanding of structural health states. The primary objective of the study is to develop an approach that enables the transfer of health-state information from fully labeled bridge data to new, unlabeled bridge instances, thereby improving the accuracy of damage classification across different bridge structures. The study aims to demonstrate the feasibility of exchanging health-state labels within a population of bridges to better identify damage classes and address the issue of scarce or poor data in bridge network monitoring."
Medicine,Exploring data mining and machine learning in gynecologic oncology,"Abstract Gynecologic (GYN) malignancies are gaining new and much-needed attention, perpetually fueling literature. Intra-/inter-tumor heterogeneity and “frightened” global distribution by race, ethnicity, and human development index, are pivotal clues to such ubiquitous interest. To advance “precision medicine” and downplay the heavy burden, data mining (DM) is timely in clinical GYN oncology. No consolidated work has been conducted to examine the depth and breadth of DM applicability as an adjunct to GYN oncology, emphasizing machine learning (ML)-based schemes. This systematic literature review (SLR) synthesizes evidence to fill knowledge gaps, flaws, and limitations. We report this SLR in compliance with Kitchenham and Charters’ guidelines. Defined research questions and PICO crafted a search string across five libraries: PubMed, IEEE Xplore, ScienceDirect, SpringerLink, and Google Scholar—over the past decade. Of the 3499 potential records, 181 primary studies were eligible for in-depth analysis. A spike (60.53%) corollary to cervical neoplasms is denoted onward 2019, predominantly featuring empirical solution proposals drawn from cohorts. Medical records led (23.77%, 53 art.). DM-ML in use is primarily built on neural networks (127 art.), appoint classification (73.19%, 172 art.) and diagnoses (42%, 111 art.), all devoted to assessment. Summarized evidence is sufficient to guide and support the clinical utility of DM schemes in GYN oncology. Gaps persist, inculpating the interoperability of single-institute scrutiny. Cross-cohort generalizability is needed to establish evidence while avoiding outcome reporting bias to locally, site-specific trained models. This SLR is exempt from ethics approval as it entails published articles.",['neural networks'],"The research idea addresses the growing attention toward gynecologic malignancies, highlighting the challenges posed by intra- and inter-tumor heterogeneity as well as variations influenced by race, ethnicity, and human development index. These factors contribute to the complexity and widespread interest in improving clinical outcomes for gynecologic cancers. The study aims to advance precision medicine in gynecologic oncology by exploring the applicability and clinical utility of various approaches to better understand and manage these malignancies. The primary objective of the study is to systematically review existing literature to synthesize evidence on the use of different approaches as adjuncts in gynecologic oncology, identify knowledge gaps, limitations, and flaws, and provide guidance to support their clinical utility while emphasizing the need for cross-cohort generalizability and addressing biases related to site-specific findings."
Medicine,Revolutionizing core muscle analysis in female sexual dysfunction based on machine learning,"Abstract The purpose of this study is to investigate the role of core muscles in female sexual dysfunction (FSD) and develop comprehensive rehabilitation programs to address this issue. We aim to answer the following research questions: what are the roles of core muscles in FSD, and how can machine and deep learning models accurately predict changes in core muscles during FSD? FSD is a common condition that affects women of all ages, characterized by symptoms such as decreased libido, difficulty achieving orgasm, and pain during intercourse. We conducted a comprehensive analysis of changes in core muscles during FSD using machine and deep learning. We evaluated the performance of multiple models, including multi-layer perceptron (MLP), long short-term memory (LSTM), convolutional neural network (CNN), recurrent neural network (RNN), ElasticNetCV, random forest regressor, SVR, and Bagging regressor. The models were evaluated based on mean squared error (MSE), mean absolute error (MAE), and R-squared (R 2 ) score. Our results show that CNN and random forest regressor are the most accurate models for predicting changes in core muscles during FSD. CNN achieved the lowest MSE (0.002) and the highest R 2 score (0.988), while random forest regressor also performed well with an MSE of 0.0021 and an R 2 score of 0.9905. Our study demonstrates that machine and deep learning models can accurately predict changes in core muscles during FSD. The neglected core muscles play a significant role in FSD, highlighting the need for comprehensive rehabilitation programs that address these muscles. By developing these programs, we can improve the quality of life for women with FSD and help them achieve optimal sexual health.","['multi-layer perceptron (MLP)', 'long short-term memory (LSTM)', 'convolutional neural network (CNN)', 'recurrent neural network (RNN)', 'ElasticNetCV', 'random forest regressor', 'SVR', 'Bagging regressor']","The research idea centers on the significant yet often overlooked role of core muscles in female sexual dysfunction (FSD), a condition affecting women of all ages and characterized by symptoms such as decreased libido, difficulty achieving orgasm, and pain during intercourse. Understanding how changes in core muscles contribute to FSD is crucial for addressing this common health issue. The study’s primary objective is to investigate the roles of core muscles in FSD and to develop comprehensive rehabilitation programs that specifically target these muscles. By focusing on these rehabilitation strategies, the study aims to improve the quality of life and sexual health outcomes for women experiencing FSD."
Medicine,The SAFE procedure: a practical stopping heuristic for active learning-based screening in systematic reviews and meta-analyses,"Abstract Active learning has become an increasingly popular method for screening large amounts of data in systematic reviews and meta-analyses. The active learning process continually improves its predictions on the remaining unlabeled records, with the goal of identifying all relevant records as early as possible. However, determining the optimal point at which to stop the active learning process is a challenge. The cost of additional labeling of records by the reviewer must be balanced against the cost of erroneous exclusions. This paper introduces the SAFE procedure, a practical and conservative set of stopping heuristics that offers a clear guideline for determining when to end the active learning process in screening software like ASReview. The eclectic mix of stopping heuristics helps to minimize the risk of missing relevant papers in the screening process. The proposed stopping heuristic balances the costs of continued screening with the risk of missing relevant records, providing a practical solution for reviewers to make informed decisions on when to stop screening. Although active learning can significantly enhance the quality and efficiency of screening, this method may be more applicable to certain types of datasets and problems. Ultimately, the decision to stop the active learning process depends on careful consideration of the trade-off between the costs of additional record labeling against the potential errors of the current model for the specific dataset and context.",['active learning'],"The research idea addresses the challenge of efficiently screening large volumes of records in systematic reviews and meta-analyses, focusing on the difficulty of determining the optimal point to stop the screening process. This is important because continuing to review records incurs additional costs, while stopping too early risks missing relevant studies, which can affect the quality and completeness of the review. The study aims to provide a practical approach to balance these competing concerns in the screening process. The primary objective of the study is to introduce a set of stopping guidelines that help reviewers decide when to end the screening process in order to minimize the risk of excluding relevant records while managing the costs associated with continued screening. These guidelines are intended to offer clear and conservative recommendations to improve decision-making during the screening of records in systematic reviews."
Medicine,Empowering personalized pharmacogenomics with generative AI solutions,"Abstract Objective This study evaluates an AI assistant developed using OpenAI’s GPT-4 for interpreting pharmacogenomic (PGx) testing results, aiming to improve decision-making and knowledge sharing in clinical genetics and to enhance patient care with equitable access. Materials and Methods The AI assistant employs retrieval-augmented generation (RAG), which combines retrieval and generative techniques, by harnessing a knowledge base (KB) that comprises data from the Clinical Pharmacogenetics Implementation Consortium (CPIC). It uses context-aware GPT-4 to generate tailored responses to user queries from this KB, further refined through prompt engineering and guardrails. Results Evaluated against a specialized PGx question catalog, the AI assistant showed high efficacy in addressing user queries. Compared with OpenAI’s ChatGPT 3.5, it demonstrated better performance, especially in provider-specific queries requiring specialized data and citations. Key areas for improvement include enhancing accuracy, relevancy, and representative language in responses. Discussion The integration of context-aware GPT-4 with RAG significantly enhanced the AI assistant’s utility. RAG’s ability to incorporate domain-specific CPIC data, including recent literature, proved beneficial. Challenges persist, such as the need for specialized genetic/PGx models to improve accuracy and relevancy and addressing ethical, regulatory, and safety concerns. Conclusion This study underscores generative AI’s potential for transforming healthcare provider support and patient accessibility to complex pharmacogenomic information. While careful implementation of large language models like GPT-4 is necessary, it is clear that they can substantially improve understanding of pharmacogenomic data. With further development, these tools could augment healthcare expertise, provider productivity, and the delivery of equitable, patient-centered healthcare services.",['retrieval-augmented generation (RAG)'],"The research idea centers on addressing the challenges in interpreting pharmacogenomic testing results to improve clinical decision-making and knowledge sharing in clinical genetics, ultimately enhancing patient care and ensuring equitable access to complex pharmacogenomic information. The study recognizes the need for better tools to support healthcare providers in understanding and utilizing pharmacogenomic data effectively. The primary objective of the study is to evaluate a newly developed assistant designed to interpret pharmacogenomic testing results with the aim of improving decision-making and knowledge dissemination among healthcare providers. The study seeks to assess the assistant’s effectiveness in supporting clinical genetics and enhancing patient care through improved accessibility and understanding of pharmacogenomic information."
Medicine,Analysis of human errors in human-autonomy collaboration in autonomous ships operations through shore control experimental data,"Human-autonomy collaboration plays a pivotal role in the development of Maritime autonomous surface ships (MASS), as Shore control center (SCC) operators may engage in the control loop by directly operating the MASS, or, in the supervisory loop, monitoring the MASS and taking over control when needed. Thus, efficient human performance during takeover control and operation is crucial for the safety of MASS operations. However, since the MASS is still in the early phase of development, the mechanism of human errors is unknown, and the data on human-autonomy collaborative operation is scarce. Human reliability analysis (HRA) aims to assess human errors qualitatively and quantitatively, and is widely used in various complex systems to help safety analysis. This study is dedicated to incorporating advanced HRA methods elements to identify and quantify human errors during taking over control and operation of a MASS in collision avoidance scenarios. It presents virtual experimental results, combined with theoretical human error identification and assessment methods. At first, we apply the Human-System Interaction in Autonomy (H-SIA) method to identify potential human errors; secondly, we identify relevant Performance Shaping Factors (PSFs) including Experience, Boredom, Task complexity, Available time and Pre-warning, and performance measures of the human errors, and implement them in the virtual experiment based on a full-scale autonomous ferry research vessel called milliAmpere2. Finally, we build a Bayesian Network (BN) to present causal and probabilistic relationships between PSFs and human errors through experimental data. The results show that available time has the highest impact on takeover performance of operators, followed by task complexity and pre-warning. Boredom does not present a significant sole impact unless combined with available time. Experience does not show a significant impact on human performance. In addition to the relevance of the human errors analysis to the safe development and operational design of MASS, the developed method benefits other human-autonomy collaborative systems. The developed BN model shows adaptability to assess human error probabilities, and the practical significance of integrating experimental data into the existing HRA methodologies for complex systems.",['Bayesian Network (BN)'],"The research idea centers on the critical role of human performance during takeover control and operation in Maritime autonomous surface ships (MASS) to ensure safety, highlighting that the mechanisms of human errors in this early development phase remain unknown and data on human-autonomy collaborative operation are scarce. Understanding and assessing human errors in this context is essential for improving safety in MASS operations. The primary objective of the study is to identify and quantify human errors during the takeover control and operation of a MASS in collision avoidance scenarios by incorporating elements of human reliability analysis. The study aims to evaluate the impact of various performance shaping factors on human errors to enhance the safe development and operational design of MASS."
Medicine,Performance of an Open-Source Large Language Model in Extracting Information from Free-Text Radiology Reports,"Purpose To assess the performance of a local open-source large language model (LLM) in various information extraction tasks from real-life emergency brain MRI reports. Materials and Methods All consecutive emergency brain MRI reports written in 2022 from a French quaternary center were retrospectively reviewed. Two radiologists identified MRI scans that were performed in the emergency department for headaches. Four radiologists scored the reports' conclusions as either normal or abnormal. Abnormalities were labeled as either headache-causing or incidental. Vicuna (LMSYS Org), an open-source LLM, performed the same tasks. Vicuna's performance metrics were evaluated using the radiologists' consensus as the reference standard. Results Among the 2398 reports during the study period, radiologists identified 595 that included headaches in the indication (median age of patients, 35 years [IQR, 26-51 years]; 68% [403 of 595] women). A positive finding was reported in 227 of 595 (38%) cases, 136 of which could explain the headache. The LLM had a sensitivity of 98.0% (95% CI: 96.5, 99.0) and specificity of 99.3% (95% CI: 98.8, 99.7) for detecting the presence of headache in the clinical context, a sensitivity of 99.4% (95% CI: 98.3, 99.9) and specificity of 98.6% (95% CI: 92.2, 100.0) for the use of contrast medium injection, a sensitivity of 96.0% (95% CI: 92.5, 98.2) and specificity of 98.9% (95% CI: 97.2, 99.7) for study categorization as either normal or abnormal, and a sensitivity of 88.2% (95% CI: 81.6, 93.1) and specificity of 73% (95% CI: 62, 81) for causal inference between MRI findings and headache. Conclusion An open-source LLM was able to extract information from free-text radiology reports with excellent accuracy without requiring further training.","['Vicuna (open-source large language model, LLM)']","The research idea addresses the challenge of accurately extracting clinically relevant information from emergency brain MRI reports, particularly in cases involving patients presenting with headaches. This is important for improving the interpretation and utilization of radiology reports in urgent medical settings. The study focuses on evaluating the ability to identify abnormalities that could explain headaches and distinguish them from incidental findings. The research objective is to assess the performance of a local open-source tool in extracting specific information from real-life emergency brain MRI reports, including detecting the presence of headache in the clinical context, use of contrast medium, categorization of studies as normal or abnormal, and determining the causal relationship between MRI findings and headache, using radiologists’ consensus as the reference standard."
Medicine,"Triage Performance Across Large Language Models, ChatGPT, and Untrained Doctors in Emergency Medicine: Comparative Study","Background Large language models (LLMs) have demonstrated impressive performances in various medical domains, prompting an exploration of their potential utility within the high-demand setting of emergency department (ED) triage. This study evaluated the triage proficiency of different LLMs and ChatGPT, an LLM-based chatbot, compared to professionally trained ED staff and untrained personnel. We further explored whether LLM responses could guide untrained staff in effective triage. Objective This study aimed to assess the efficacy of LLMs and the associated product ChatGPT in ED triage compared to personnel of varying training status and to investigate if the models’ responses can enhance the triage proficiency of untrained personnel. Methods A total of 124 anonymized case vignettes were triaged by untrained doctors; different versions of currently available LLMs; ChatGPT; and professionally trained raters, who subsequently agreed on a consensus set according to the Manchester Triage System (MTS). The prototypical vignettes were adapted from cases at a tertiary ED in Germany. The main outcome was the level of agreement between raters’ MTS level assignments, measured via quadratic-weighted Cohen κ. The extent of over- and undertriage was also determined. Notably, instances of ChatGPT were prompted using zero-shot approaches without extensive background information on the MTS. The tested LLMs included raw GPT-4, Llama 3 70B, Gemini 1.5, and Mixtral 8x7b. Results GPT-4–based ChatGPT and untrained doctors showed substantial agreement with the consensus triage of professional raters (κ=mean 0.67, SD 0.037 and κ=mean 0.68, SD 0.056, respectively), significantly exceeding the performance of GPT-3.5–based ChatGPT (κ=mean 0.54, SD 0.024; P&lt;.001). When untrained doctors used this LLM for second-opinion triage, there was a slight but statistically insignificant performance increase (κ=mean 0.70, SD 0.047; P=.97). Other tested LLMs performed similar to or worse than GPT-4–based ChatGPT or showed odd triaging behavior with the used parameters. LLMs and ChatGPT models tended toward overtriage, whereas untrained doctors undertriaged. Conclusions While LLMs and the LLM-based product ChatGPT do not yet match professionally trained raters, their best models’ triage proficiency equals that of untrained ED doctors. In its current form, LLMs or ChatGPT thus did not demonstrate gold-standard performance in ED triage and, in the setting of this study, failed to significantly improve untrained doctors’ triage when used as decision support. Notable performance enhancements in newer LLM versions over older ones hint at future improvements with further technological development and specific training.","['zero-shot approaches', 'GPT-4', 'Llama 3 70B', 'GPT-3.5']","The study addresses the challenge of accurately performing emergency department (ED) triage, a critical and high-demand medical task typically conducted by professionally trained staff. There is a need to explore alternative approaches that could potentially support or enhance triage decisions, especially by personnel with varying levels of training. The research aims to evaluate the effectiveness of different approaches in triaging ED cases compared to professional raters and to determine whether these approaches can improve the triage proficiency of untrained staff. Specifically, the study’s primary objective is to assess the triage performance of various methods relative to professionally trained ED personnel and to investigate if their use can enhance the accuracy of triage decisions made by untrained doctors."
Medicine,Evaluating AI and Machine Learning Models in Breast Cancer Detection: A Review of Convolutional Neural Networks (CNN) and Global Research Trends,"Numerous studies have highlighted the significance of artificial intelligence (AI) in breast cancer diagnosis. However, systematic reviews of AI applications in this field often lack cohesion, with each study adopting a unique approach. The aim of this study is to provide a detailed examination of AI's role in breast cancer diagnosis through citation analysis, helping to categorize the key areas that attract academic attention. It also includes a thematic analysis to identify the specific research topics within each category. A total of 30,200 studies related to breast cancer and AI, published between 2015 and 2024, were sourced from databases such as IEEE, Scopus, PubMed, Springer, and Google Scholar. After applying inclusion and exclusion criteria, 32 relevant studies were identified. Most of these studies utilized classification models for breast cancer prediction, with high accuracy being the most commonly reported performance metric. Convolutional Neural Networks (CNN) emerged as the preferred model in many studies. The findings indicate that both the quantity and quality of AI-based algorithms in breast cancer diagnosis are increases in the given years. AI is increasingly seen as a complement to healthcare sector and clinical expertise, with the target of enhancing the accessibility and affordability of quality healthcare worldwide.",['Convolutional Neural Networks (CNN)'],"The research idea centers on the growing importance of improving breast cancer diagnosis, recognizing that existing studies in this field often lack cohesion and adopt varied approaches. There is a need to better understand and categorize the key areas of academic focus to enhance the overall knowledge and application in breast cancer diagnosis. The primary objective of the study is to provide a detailed examination of the role of emerging technologies in breast cancer diagnosis by categorizing key research areas and identifying specific topics within each category. This aims to clarify the landscape of current research and highlight trends that could support advancements in breast cancer detection and healthcare delivery."
Medicine,Unlocking the Potential of XAI for Improved Alzheimer’s Disease Detection and Classification Using a ViT-GRU Model,"Alzheimer's Disease (AD) is a significant cause of dementia worldwide, and its progression from mild to severe affects an individual's ability to perform daily activities independently. The accurate and early diagnosis of AD is crucial for effective clinical intervention. However, interpreting AD from medical images can be challenging, even for experienced radiologists. Therefore, there is a need for an automatic diagnosis of AD, and researchers have investigated the potential of utilizing Artificial Intelligence (AI) techniques, particularly deep learning models, to address this challenge. This study proposes a framework that combines a Vision Transformer (ViT) and a Gated Recurrent Unit (GRU) to detect AD characteristics from Magnetic Resonance Imaging (MRI) images accurately and reliably. The ViT identifies crucial features from the input image, and the GRU establishes clear correlations between these features. The proposed model overcomes the class imbalance issue in the MRI image dataset and achieves superior accuracy and performance compared to existing methods. The model was trained on the Alzheimer's MRI Preprocessed Dataset obtained from Kaggle, achieving notable accuracies of 99.53% for 4-class and 99.69% for binary classification. It also demonstrated a high accuracy of 99.26% for 3-class on the AD Neuroimaging Initiative (ADNI) Baseline Database. These results were validated through a thorough 10-fold cross-validation process. Furthermore, Explainable AI (XAI) techniques were incorporated to make the model interpretable and explainable. This allows clinicians to understand the model's decision-making process and gain insights into the underlying factors driving the AD diagnosis.","['Vision Transformer (ViT)', 'Gated Recurrent Unit (GRU)']","Alzheimer's Disease (AD) is a major cause of dementia worldwide, and its progression from mild to severe stages significantly impairs an individual's ability to perform daily activities independently. Early and accurate diagnosis of AD is essential for effective clinical intervention, yet interpreting AD from medical images remains challenging even for experienced radiologists. The primary aim of this study is to develop a reliable approach for detecting characteristics of AD from Magnetic Resonance Imaging (MRI) images to improve diagnostic accuracy. This study seeks to address the difficulties in diagnosing AD by proposing a method that can accurately identify and classify different stages of the disease using MRI data, thereby supporting clinicians in making informed decisions."
Medicine,"Prediction of atmospheric PM2.5 level by machine learning techniques in Isfahan, Iran","Abstract With increasing levels of air pollution, air quality prediction has attracted more attention. Mathematical models are being developed by researchers to achieve precise predictions. Monitoring and prediction of atmospheric PM 2.5 levels, as a predominant pollutant, is essential in emission mitigation programs. In this study, meteorological datasets from 9 years in Isfahan city, a large metropolis of Iran, were applied to predict the PM 2.5 levels, using four machine learning algorithms including Artificial Neural |Networks (ANNs), K-Nearest-Neighbors (KNN), Support Vector |Machines (SVMs) and ensembles of classification trees Random Forest (RF). The data from 7 air quality monitoring stations located in Isfahan City were taken into consideration. The Confusion Matrix and Cross-Entropy Loss were used to analyze the performance of classification models. Several parameters, including sensitivity, specificity, accuracy, F1 score, precision, and the area under the curve (AUC), are computed to assess model performance. Finally, by introducing the predicted data for 2020 into ArcGIS software and using the IDW (Inverse Distance Weighting) method, interpolation was conducted for the area of Isfahan city and the pollution map was illustrated for each month of the year. The results showed that, based on the accuracy percentage, the ANN model has a better performance (90.1%) in predicting PM 2.5 grades compared to the other models for the applied meteorological dataset, followed by RF (86.1%), SVM (84.6%) and KNN (82.2%) models, respectively. Therefore, ANN modelling provides a feasible procedure for the managerial planning of air pollution control.","['Artificial Neural Networks (ANNs)', 'K-Nearest-Neighbors (KNN)', 'Support Vector Machines (SVMs)', 'Random Forest (RF)']","The study addresses the growing concern of air pollution and the critical need for accurate prediction of atmospheric PM 2.5 levels, which are a predominant pollutant affecting public health and environmental quality. Monitoring and predicting these pollutant levels are essential components of emission mitigation programs, especially in large urban areas like Isfahan city. The primary aim of the study is to predict PM 2.5 levels in Isfahan city using meteorological data collected over nine years from multiple air quality monitoring stations. This prediction is intended to support effective managerial planning and control of air pollution in the region."
Medicine,Machine Learning–Based Prediction of Suicidality in Adolescents With Allergic Rhinitis: Derivation and Validation in 2 Independent Nationwide Cohorts,"Background Given the additional risk of suicide-related behaviors in adolescents with allergic rhinitis (AR), it is important to use the growing field of machine learning (ML) to evaluate this risk. Objective This study aims to evaluate the validity and usefulness of an ML model for predicting suicide risk in patients with AR. Methods We used data from 2 independent survey studies, Korea Youth Risk Behavior Web-based Survey (KYRBS; n=299,468) for the original data set and Korea National Health and Nutrition Examination Survey (KNHANES; n=833) for the external validation data set, to predict suicide risks of AR in adolescents aged 13 to 18 years, with 3.45% (10,341/299,468) and 1.4% (12/833) of the patients attempting suicide in the KYRBS and KNHANES studies, respectively. The outcome of interest was the suicide attempt risks. We selected various ML-based models with hyperparameter tuning in the discovery and performed an area under the receiver operating characteristic curve (AUROC) analysis in the train, test, and external validation data. Results The study data set included 299,468 (KYRBS; original data set) and 833 (KNHANES; external validation data set) patients with AR recruited between 2005 and 2022. The best-performing ML model was the random forest model with a mean AUROC of 84.12% (95% CI 83.98%-84.27%) in the original data set. Applying this result to the external validation data set revealed the best performance among the models, with an AUROC of 89.87% (sensitivity 83.33%, specificity 82.58%, accuracy 82.59%, and balanced accuracy 82.96%). While looking at feature importance, the 5 most important features in predicting suicide attempts in adolescent patients with AR are depression, stress status, academic achievement, age, and alcohol consumption. Conclusions This study emphasizes the potential of ML models in predicting suicide risks in patients with AR, encouraging further application of these models in other conditions to enhance adolescent health and decrease suicide rates.",['random forest'],"The research idea addresses the increased risk of suicide-related behaviors in adolescents with allergic rhinitis (AR), highlighting the importance of evaluating this risk to improve adolescent health outcomes. Given the significant impact of suicide attempts among this population, there is a critical need to identify factors that contribute to suicide risk in patients with AR. The study’s primary objective is to assess the validity and usefulness of a predictive approach for identifying suicide risk in adolescents aged 13 to 18 years with AR. Specifically, the study aims to evaluate how well this approach can predict suicide attempts in this group, using data from large-scale surveys to inform prevention strategies and ultimately reduce suicide rates among adolescents with AR."
Medicine,Optimized Brain Tumor Detection: A Dual-Module Approach for MRI Image Enhancement and Tumor Classification,"Neurological and brain-related cancers are one of the main causes of death worldwide. A commonly used tool in diagnosing these conditions is Magnetic Resonance Imaging (MRI), yet the manual evaluation of MRI images by medical experts presents difficulties due to time constraints and variability. This research introduces a novel, two-module computerized method aimed at increasing the speed and accuracy of brain tumor detection. The first module, termed the Image Enhancement Technique, utilizes a trio of machine learning and imaging strategies—adaptive Wiener filtering, neural networks, and independent component analysis—to normalize images and combat issues such as noise and varying low region contrast. The second module uses Support Vector Machines to validate the output of the first module and perform tumor segmentation and classification. Applied to various types of brain tumors, including meningiomas and pituitary tumors, our method exhibited significant improvements in contrast and classification efficiency. It achieved an average sensitivity and specificity of 0.991, accuracy of 0.989, and a Dice score (DSC) of 0.981. Furthermore, the processing time of our method, averaging at 0.43 seconds, was markedly lower compared to existing methods. These results underscore the superior performance of our approach over current state-of-the-art methods in terms of sensitivity, specificity, precision, and DSC. Future enhancements will seek to increase the robustness of the tumor classification method by employing a standardized approach across a suite of classifiers.","['neural networks', 'independent component analysis', 'Support Vector Machines']","Neurological and brain-related cancers are among the leading causes of death worldwide, and accurate diagnosis is critical for effective treatment. Magnetic Resonance Imaging (MRI) is commonly used for diagnosing these conditions, but manual evaluation by medical experts is challenging due to time constraints and variability in interpretation. The primary aim of this study is to develop a method that increases the speed and accuracy of brain tumor detection using MRI images. Specifically, the study focuses on improving tumor segmentation and classification for various types of brain tumors, including meningiomas and pituitary tumors, to enhance diagnostic performance and reduce processing time."
Medicine,Artificial Intelligence (AI) for Early Diagnosis of Retinal Diseases,"Artificial intelligence (AI) has emerged as a transformative tool in the field of ophthalmology, revolutionizing disease diagnosis and management. This paper provides a comprehensive overview of AI applications in various retinal diseases, highlighting its potential to enhance screening efficiency, facilitate early diagnosis, and improve patient outcomes. Herein, we elucidate the fundamental concepts of AI, including machine learning (ML) and deep learning (DL), and their application in ophthalmology, underscoring the significance of AI-driven solutions in addressing the complexity and variability of retinal diseases. Furthermore, we delve into the specific applications of AI in retinal diseases such as diabetic retinopathy (DR), age-related macular degeneration (AMD), Macular Neovascularization, retinopathy of prematurity (ROP), retinal vein occlusion (RVO), hypertensive retinopathy (HR), Retinitis Pigmentosa, Stargardt disease, best vitelliform macular dystrophy, and sickle cell retinopathy. We focus on the current landscape of AI technologies, including various AI models, their performance metrics, and clinical implications. Furthermore, we aim to address challenges and pitfalls associated with the integration of AI in clinical practice, including the “black box phenomenon”, biases in data representation, and limitations in comprehensive patient assessment. In conclusion, this review emphasizes the collaborative role of AI alongside healthcare professionals, advocating for a synergistic approach to healthcare delivery. It highlights the importance of leveraging AI to augment, rather than replace, human expertise, thereby maximizing its potential to revolutionize healthcare delivery, mitigate healthcare disparities, and improve patient outcomes in the evolving landscape of medicine.","['machine learning (ML)', 'deep learning (DL)']","The research idea centers on the transformative potential of new technological advancements in improving the diagnosis and management of various retinal diseases. The study addresses the complexity and variability of retinal conditions such as diabetic retinopathy, age-related macular degeneration, and retinopathy of prematurity, emphasizing the need for enhanced screening efficiency, early diagnosis, and better patient outcomes. The research objective is to provide a comprehensive overview of current approaches in the detection and treatment of retinal diseases, highlighting their clinical implications and performance in practice. Additionally, the study aims to discuss the challenges and limitations associated with integrating these advancements into clinical settings, advocating for a collaborative approach that supports healthcare professionals in delivering improved patient care."
Medicine,"Developing Deep LSTMs With Later Temporal Attention for Predicting COVID-19 Severity, Clinical Outcome, and Antibody Level by Screening Serological Indicators Over Time","Objective: The clinical course of COVID-19, as well as the immunological reaction, is notable for its extreme variability. Identifying the main associated factors might help understand the disease progression and physiological status of COVID-19 patients. The dynamic changes of the antibody against Spike protein are crucial for understanding the immune response. This work explores a temporal attention (TA) mechanism of deep learning to predict COVID-19 disease severity, clinical outcomes, and Spike antibody levels by screening serological indicators over time. Methods: We use feature selection techniques to filter feature subsets that are highly correlated with the target. The specific deep Long Short-Term Memory (LSTM) models are employed to capture the dynamic changes of disease severity, clinical outcome, and Spike antibody level. We also propose deep LSTMs with a TA mechanism to emphasize the later blood test records because later records often attract more attention from doctors. Results: Risk factors highly correlated with COVID-19 are revealed. LSTM achieves the highest classification accuracy for disease severity prediction. Temporal Attention Long Short-Term Memory (TA-LSTM) achieves the best performance for clinical outcome prediction. For Spike antibody level prediction, LSTM achieves the best permanence. Conclusion: The experimental results demonstrate the effectiveness of the proposed models. The proposed models can provide a computer-aided medical diagnostics system by simply using time series of serological indicators.","['deep Long Short-Term Memory (LSTM) models', 'deep LSTMs with a temporal attention (TA) mechanism']","The clinical course of COVID-19 and the immunological response exhibit significant variability among patients, making it challenging to understand disease progression and physiological status. Identifying the main factors associated with COVID-19 severity and outcomes is essential for improving patient management. The dynamic changes in antibodies against the Spike protein are particularly important for understanding the immune response to the virus. This study aims to predict COVID-19 disease severity, clinical outcomes, and Spike antibody levels by examining the temporal changes in serological indicators over time. The primary objective is to identify risk factors correlated with COVID-19 and to assess the progression of disease severity, clinical outcomes, and immune response through monitoring serological markers longitudinally."
Medicine,A New Brain Network Construction Paradigm for Brain Disorder via Diffusion-Based Graph Contrastive Learning,"Brain network analysis plays an increasingly important role in studying brain function and the exploring of disease mechanisms. However, existing brain network construction tools have some limitations, including dependency on empirical users, weak consistency in repeated experiments and time-consuming processes. In this work, a diffusion-based brain network pipeline, DGCL is designed for end-to-end construction of brain networks. Initially, the brain region-aware module (BRAM) precisely determines the spatial locations of brain regions by the diffusion process, avoiding subjective parameter selection. Subsequently, DGCL employs graph contrastive learning to optimize brain connections by eliminating individual differences in redundant connections unrelated to diseases, thereby enhancing the consistency of brain networks within the same group. Finally, the node-graph contrastive loss and classification loss jointly constrain the learning process of the model to obtain the reconstructed brain network, which is then used to analyze important brain connections. Validation on two datasets, ADNI and ABIDE, demonstrates that DGCL surpasses traditional methods and other deep learning models in predicting disease development stages. Significantly, the proposed model improves the efficiency and generalization of brain network construction. In summary, the proposed DGCL can be served as a universal brain network construction scheme, which can effectively identify important brain connections through generative paradigms and has the potential to provide disease interpretability support for neuroscience research.","['diffusion process', 'graph contrastive learning']","The study addresses the challenges in brain network construction, which is crucial for understanding brain function and disease mechanisms. Existing tools for constructing brain networks face limitations such as reliance on subjective user input, inconsistency in repeated experiments, and time-consuming procedures. These issues hinder the accurate and efficient analysis of brain connections relevant to neurological diseases. The primary aim of the study is to develop a brain network construction approach that improves the precision and consistency of identifying brain regions and connections, reduces individual differences unrelated to diseases, and enhances the efficiency and generalizability of brain network analysis. This approach seeks to better identify important brain connections and support the interpretation of disease development stages in neuroscience research."
Medicine,Multi-Class Kidney Abnormalities Detecting Novel System Through Computed Tomography,"Impaired renal function poses a risk across all age groups. Because of the global shortage of nephrologists, the growing public health concern over renal failure, and technological improvements, there is a demand for an AI-driven system capable of autonomously detecting kidney abnormalities. Chronic kidney disease, commonly known as chronic renal failure, is characterized by a progressive decline in kidney function. Renal failure can be caused by a variety of reasons, including cysts, stones, and tumors. Chronic kidney disease may not have apparent symptoms at first, resulting in instances staying untreated until they reach an advanced state. Tumors are dense clumps of tissue that can cause direct injury to glands, spinal cells, and other organs. The presence of a substantial number of solids in the digestive tract causes kidney stone disease, also known as urolithiasis. This study used a deep learning model to detect kidney illnesses to solve the global scarcity of urologists. The project entailed obtaining and annotating a large dataset of 12,446 CT whole abdomen and urogram images, with an emphasis on kidney stones, cysts, and tumors, which are the most common types of renal illness. The dataset was divided into four categories: cyst, tumor, stone, and normal. Data was collected from several hospitals in the Dhaka area. This work presents an innovative and customizable platform for the clinical diagnosis of kidney diseases such as tumors, stones, and cysts. Our YOLOv8 model's enhanced accuracy opens up new possibilities for identifying kidney cysts, stones, and tumors. We used criteria like accuracy, precision, recall, F1 score, and specificity to evaluate its performance. The network attained an accuracy rate of 82.52%, 85.76% precision, 75.28% recall, 75.72% F1 score, and 93.12% specificity.","['deep learning model', 'YOLOv8']","The research addresses the significant health risk posed by impaired renal function across all age groups, highlighting the global shortage of nephrologists and the increasing public health concern related to renal failure. Chronic kidney disease, characterized by a progressive decline in kidney function, often remains undetected until advanced stages due to a lack of apparent early symptoms. The study focuses on common causes of renal failure such as cysts, stones, and tumors, which can directly damage kidney tissue and other organs. The primary objective of the study is to develop a reliable approach for the clinical diagnosis of kidney diseases, specifically targeting the detection of kidney stones, cysts, and tumors, to improve early identification and management of these conditions."
Medicine,A methodical exploration of imaging modalities from dataset to detection through machine learning paradigms in prominent lung disease diagnosis: a review,"Abstract Background Lung diseases, both infectious and non-infectious, are the most prevalent cause of mortality overall in the world. Medical research has identified pneumonia, lung cancer, and Corona Virus Disease 2019 (COVID-19) as prominent lung diseases prioritized over others. Imaging modalities, including X-rays, computer tomography (CT) scans, magnetic resonance imaging (MRIs), positron emission tomography (PET) scans, and others, are primarily employed in medical assessments because they provide computed data that can be utilized as input datasets for computer-assisted diagnostic systems. Imaging datasets are used to develop and evaluate machine learning (ML) methods to analyze and predict prominent lung diseases. Objective This review analyzes ML paradigms, imaging modalities' utilization, and recent developments for prominent lung diseases. Furthermore, the research also explores various datasets available publically that are being used for prominent lung diseases. Methods The well-known databases of academic studies that have been subjected to peer review, namely ScienceDirect, arXiv, IEEE Xplore, MDPI, and many more, were used for the search of relevant articles. Applied keywords and combinations used to search procedures with primary considerations for review, such as pneumonia, lung cancer, COVID-19, various imaging modalities, ML, convolutional neural networks (CNNs), transfer learning, and ensemble learning. Results This research finding indicates that X-ray datasets are preferred for detecting pneumonia, while CT scan datasets are predominantly favored for detecting lung cancer. Furthermore, in COVID-19 detection, X-ray datasets are prioritized over CT scan datasets. The analysis reveals that X-rays and CT scans have surpassed all other imaging techniques. It has been observed that using CNNs yields a high degree of accuracy and practicability in identifying prominent lung diseases. Transfer learning and ensemble learning are complementary techniques to CNNs to facilitate analysis. Furthermore, accuracy is the most favored metric for assessment.","['machine learning (ML)', 'convolutional neural networks (CNNs)', 'transfer learning', 'ensemble learning']","The research idea addresses the high prevalence and mortality caused by lung diseases worldwide, with a focus on pneumonia, lung cancer, and COVID-19 as the most prominent conditions. These diseases represent significant health challenges that require effective diagnostic approaches to improve patient outcomes. The study recognizes the importance of various imaging modalities, such as X-rays and CT scans, in medical assessments for detecting these lung diseases. The research objective is to review and analyze the utilization of imaging modalities and recent developments related to prominent lung diseases, specifically pneumonia, lung cancer, and COVID-19. Additionally, the study aims to explore the availability and use of publicly accessible imaging datasets for these diseases to better understand current diagnostic practices and trends."
Medicine,A novel fusion framework of deep bottleneck residual convolutional neural network for breast cancer classification from mammogram images,"With over 2.1 million new cases of breast cancer diagnosed annually, the incidence and mortality rate of this disease pose severe global health issues for women. Identifying the disease’s influence is the only practical way to lessen it immediately. Numerous research works have developed automated methods using different medical imaging to identify BC. Still, the precision of each strategy differs based on the available resources, the issue’s nature, and the dataset being used. We proposed a novel deep bottleneck convolutional neural network with a quantum optimization algorithm for breast cancer classification and diagnosis from mammogram images. Two novel deep architectures named three-residual blocks bottleneck and four-residual blocks bottle have been proposed with parallel and single paths. Bayesian Optimization (BO) has been employed to initialize hyperparameter values and train the architectures on the selected dataset. Deep features are extracted from the global average pool layer of both models. After that, a kernel-based canonical correlation analysis and entropy technique is proposed for the extracted deep features fusion. The fused feature set is further refined using an optimization technique named quantum generalized normal distribution optimization. The selected features are finally classified using several neural network classifiers, such as bi-layered and wide-neural networks. The experimental process was conducted on a publicly available mammogram imaging dataset named INbreast, and a maximum accuracy of 96.5% was obtained. Moreover, for the proposed method, the sensitivity rate is 96.45, the precision rate is 96.5, the F1 score value is 96.64, the MCC value is 92.97%, and the Kappa value is 92.97%, respectively. The proposed architectures are further utilized for the diagnosis process of infected regions. In addition, a detailed comparison has been conducted with a few recent techniques showing the proposed framework’s higher accuracy and precision rate.","['deep bottleneck convolutional neural network', 'Bayesian Optimization (BO)', 'kernel-based canonical correlation analysis', 'bi-layered neural network classifier', 'wide-neural network classifier']","The research idea addresses the significant global health challenge posed by breast cancer, with over 2.1 million new cases diagnosed annually and high incidence and mortality rates among women. The study emphasizes the urgent need for effective identification and diagnosis of breast cancer to reduce its impact promptly. Despite various existing methods using medical imaging for breast cancer detection, there remains variability in precision depending on resources and datasets. The research aims to improve the accuracy and reliability of breast cancer classification and diagnosis from mammogram images.

The primary objective of the study is to develop and evaluate novel deep learning architectures for the classification and diagnosis of breast cancer using mammogram images. The study seeks to enhance diagnostic performance by proposing new network structures and optimizing feature extraction and selection processes. The ultimate goal is to achieve high accuracy, sensitivity, and precision in identifying breast cancer to support better clinical decision-making."
Medicine,Artificial intelligence for radiographic imaging detection of caries lesions: a systematic review,"Abstract Background The aim of this systematic review is to evaluate the diagnostic performance of Artificial Intelligence (AI) models designed for the detection of caries lesion (CL). Materials and methods An electronic literature search was conducted on PubMed, Web of Science, SCOPUS, LILACS and Embase databases for retrospective, prospective and cross-sectional studies published until January 2023, using the following keywords: artificial intelligence (AI), machine learning (ML), deep learning (DL), artificial neural networks (ANN), convolutional neural networks (CNN), deep convolutional neural networks (DCNN), radiology, detection, diagnosis and dental caries (DC). The quality assessment was performed using the guidelines of QUADAS-2. Results Twenty articles that met the selection criteria were evaluated. Five studies were performed on periapical radiographs, nine on bitewings, and six on orthopantomography. The number of imaging examinations included ranged from 15 to 2900. Four studies investigated ANN models, fifteen CNN models, and two DCNN models. Twelve were retrospective studies, six cross-sectional and two prospective. The following diagnostic performance was achieved in detecting CL: sensitivity from 0.44 to 0.86, specificity from 0.85 to 0.98, precision from 0.50 to 0.94, PPV (Positive Predictive Value) 0.86, NPV (Negative Predictive Value) 0.95, accuracy from 0.73 to 0.98, area under the curve (AUC) from 0.84 to 0.98, intersection over union of 0.3–0.4 and 0.78, Dice coefficient 0.66 and 0.88, F1-score from 0.64 to 0.92. According to the QUADAS-2 evaluation, most studies exhibited a low risk of bias. Conclusion AI-based models have demonstrated good diagnostic performance, potentially being an important aid in CL detection. Some limitations of these studies are related to the size and heterogeneity of the datasets. Future studies need to rely on comparable, large, and clinically meaningful datasets. Protocol PROSPERO identifier: CRD42023470708","['Artificial Neural Networks (ANN)', 'Convolutional Neural Networks (CNN)', 'Deep Convolutional Neural Networks (DCNN)']","The research idea addresses the need to evaluate the effectiveness of current methods for detecting caries lesions, which is crucial for improving dental diagnosis and patient care. Accurate detection of caries lesions can significantly impact treatment decisions and outcomes, yet there is variability in diagnostic performance across different studies. This study is motivated by the importance of assessing the reliability and accuracy of these diagnostic approaches to ensure better clinical application.

The primary objective of this study is to systematically review and evaluate the diagnostic performance of existing methods used for the detection of caries lesions. The study aims to assess sensitivity, specificity, and overall accuracy reported in the literature to determine how well these methods perform in identifying caries lesions. Additionally, it seeks to identify limitations related to study design and dataset characteristics to guide future research toward more clinically meaningful and reliable diagnostic practices."
Medicine,Potential of Large Language Models in Health Care: Delphi Study,"Background A large language model (LLM) is a machine learning model inferred from text data that captures subtle patterns of language use in context. Modern LLMs are based on neural network architectures that incorporate transformer methods. They allow the model to relate words together through attention to multiple words in a text sequence. LLMs have been shown to be highly effective for a range of tasks in natural language processing (NLP), including classification and information extraction tasks and generative applications. Objective The aim of this adapted Delphi study was to collect researchers’ opinions on how LLMs might influence health care and on the strengths, weaknesses, opportunities, and threats of LLM use in health care. Methods We invited researchers in the fields of health informatics, nursing informatics, and medical NLP to share their opinions on LLM use in health care. We started the first round with open questions based on our strengths, weaknesses, opportunities, and threats framework. In the second and third round, the participants scored these items. Results The first, second, and third rounds had 28, 23, and 21 participants, respectively. Almost all participants (26/28, 93% in round 1 and 20/21, 95% in round 3) were affiliated with academic institutions. Agreement was reached on 103 items related to use cases, benefits, risks, reliability, adoption aspects, and the future of LLMs in health care. Participants offered several use cases, including supporting clinical tasks, documentation tasks, and medical research and education, and agreed that LLM-based systems will act as health assistants for patient education. The agreed-upon benefits included increased efficiency in data handling and extraction, improved automation of processes, improved quality of health care services and overall health outcomes, provision of personalized care, accelerated diagnosis and treatment processes, and improved interaction between patients and health care professionals. In total, 5 risks to health care in general were identified: cybersecurity breaches, the potential for patient misinformation, ethical concerns, the likelihood of biased decision-making, and the risk associated with inaccurate communication. Overconfidence in LLM-based systems was recognized as a risk to the medical profession. The 6 agreed-upon privacy risks included the use of unregulated cloud services that compromise data security, exposure of sensitive patient data, breaches of confidentiality, fraudulent use of information, vulnerabilities in data storage and communication, and inappropriate access or use of patient data. Conclusions Future research related to LLMs should not only focus on testing their possibilities for NLP-related tasks but also consider the workflows the models could contribute to and the requirements regarding quality, integration, and regulations needed for successful implementation in practice.","['large language model (LLM)', 'transformer methods']","The research idea centers on understanding the potential impact of large language models on health care by exploring their strengths, weaknesses, opportunities, and threats as perceived by experts in related medical fields. This study addresses the need to evaluate how these models might influence various aspects of health care delivery, including clinical tasks, documentation, medical research, and patient education, while also considering associated risks such as misinformation, ethical concerns, and data privacy issues. The primary objective of the study was to gather and reach consensus on researchers’ opinions regarding the influence of large language models in health care, focusing on their use cases, benefits, risks, reliability, adoption factors, and future implications. The study aimed to identify agreed-upon benefits such as improved efficiency, quality of care, personalized treatment, and enhanced patient-provider interaction, as well as to highlight key risks and privacy concerns that must be addressed for successful integration into health care practice."
Medicine,Tomato Leaf Disease Detection using Convolutional Neural Networks,"One of the most important crops that is grown in enormous amounts and has an excellent market value comprises the tomato. They are grown and eaten in large quantities not only in India but also globally. Disease is the primary factor affecting the quantity and quality of this crop’s production. In earlier research, the plant’s leaves solely were taken into account for disease identification; however, in many cases, the illness only affects the fruit, leaving the other plant parts healthy. Using the unaided eye to diagnose a disease can occasionally lead to a prognosis that is off, meaning the wrong pesticide is applied and the plant may get spoiled. The farmers find it challenging to diagnose the disease because specialists are scarce in many of the affected areas. It’s an expensive and time-consuming process, even though professionals are accessible in certain sectors. Early disease detection would lessen the impact on plants and increase agricultural yield. As a result, it is essential to recognise these illnesses accurately and use the appropriate pesticide. These is- sues can be resolved by an automated system. We have developed a system to tackle this problem, which employs a convolutional neural network (CNN) to detect the ailment and recommends a pesticide to aid in its eradication. Since CNN offers its highest level of accuracy, our system incorporates it.",['convolutional neural network (CNN)'],"The study addresses the significant problem of disease affecting tomato crops, which impacts both the quantity and quality of production. Traditional disease identification methods have focused mainly on the plant’s leaves, but many diseases affect only the fruit, making diagnosis by the unaided eye difficult and often inaccurate. This leads to incorrect pesticide application, crop spoilage, and challenges for farmers, especially in areas lacking specialists. Early and accurate disease detection is crucial to reduce damage to plants and improve agricultural yield. The primary aim of the study is to develop a method for accurate recognition of tomato diseases affecting different parts of the plant and to recommend appropriate pesticides for effective disease management. This approach seeks to assist farmers in timely and precise disease diagnosis to enhance crop protection and productivity."
Medicine,Generative Large Language Models for Detection of Speech Recognition Errors in Radiology Reports,"This study evaluated the ability of generative large language models (LLMs) to detect speech recognition errors in radiology reports. A dataset of 3233 CT and MRI reports was assessed by radiologists for speech recognition errors. Errors were categorized as clinically significant or not clinically significant. Performances of five generative LLMs—GPT-3.5-turbo, GPT-4, text-davinci-003, Llama-v2–70B-chat, and Bard—were compared in detecting these errors, using manual error detection as the reference standard. Prompt engineering was used to optimize model performance. GPT-4 demonstrated high accuracy in detecting clinically significant errors (precision, 76.9%; recall, 100%; F1 score, 86.9%) and not clinically significant errors (precision, 93.9%; recall, 94.7%; F1 score, 94.3%). Text-davinci-003 achieved F1 scores of 72% and 46.6% for clinically significant and not clinically significant errors, respectively. GPT-3.5-turbo obtained 59.1% and 32.2% F1 scores, while Llama-v2–70B-chat scored 72.8% and 47.7%. Bard showed the lowest accuracy, with F1 scores of 47.5% and 20.9%. GPT-4 effectively identified challenging errors of nonsense phrases and internally inconsistent statements. Longer reports, resident dictation, and overnight shifts were associated with higher error rates. In conclusion, advanced generative LLMs show potential for automatic detection of speech recognition errors in radiology reports. Keywords: CT, Large Language Model, Machine Learning, MRI, Natural Language Processing, Radiology Reports, Speech, Unsupervised Learning Supplemental material is available for this article. © RSNA, 2024","['generative large language models (LLMs)', 'GPT-3.5-turbo', 'GPT-4', 'text-davinci-003', 'Llama-v2–70B-chat']","The study addresses the problem of speech recognition errors in radiology reports, which can impact the accuracy and reliability of clinical documentation. These errors, particularly those that are clinically significant, pose challenges for patient care and diagnostic processes. Identifying and correcting such errors is crucial to ensure the quality and safety of radiological interpretations.

The primary aim of the study was to evaluate the ability to detect speech recognition errors in CT and MRI radiology reports, distinguishing between clinically significant and not clinically significant errors. The study sought to assess the accuracy of different approaches in identifying these errors, using manual error detection by radiologists as the reference standard."
Medicine,Performance of convolutional neural networks for the classification of brain tumors using magnetic resonance imaging,"Brain tumors are a diverse group of neoplasms that are challenging to detect and classify due to their varying characteristics. Deep learning techniques have proven to be effective in tumor classification. However, there is a lack of studies that compare these techniques using a common methodology. This work aims to analyze the performance of convolutional neural networks in the classification of brain tumors. We propose a network consisting of a few convolutional layers, batch normalization, and max-pooling. Then, we explore recent deep architectures, such as VGG, ResNet, EfficientNet, or ConvNeXt. The study relies on two magnetic resonance imaging datasets with over 3000 images of three types of tumors –gliomas, meningiomas, and pituitary tumors–, as well as images without tumors. We determine the optimal hyperparameters of the networks using the training and validation sets. The training and test sets are used to assess the performance of the models from different perspectives, including training from scratch, data augmentation, transfer learning, and fine-tuning. The experiments are performed using the TensorFlow and Keras libraries in Python. We compare the accuracy of the models and analyze their complexity based on the capacity of the networks, their training times, and image throughput. Several networks achieve high accuracy rates on both datasets, with the best model achieving 98.7% accuracy, which is on par with state-of-the-art methods. The average precision for each type of tumor is 94.3% for gliomas, 93.8% for meningiomas, 97.9% for pituitary tumors, and 95.3% for images without tumors. VGG is the largest model with over 171 million parameters, whereas MobileNet and EfficientNetB0 are the smallest ones with 3.2 and 5.9 million parameters, respectively. These two neural networks are also the fastest to train with 23.7 and 25.4 seconds per epoch, respectively. On the other hand, ConvNext is the slowest model with 58.2 seconds per epoch. Our custom model obtained the highest image throughput with 234.37 images per second, followed by MobileNet with 226 images per second. ConvNext obtained the smallest throughput with 97.35 images per second. ResNet, MobileNet, and EfficientNet are the most accurate networks, with MobileNet and EfficientNet demonstrating superior performance in terms of complexity. Most models achieve the best accuracy using transfer learning followed by a fine-tuning step. However, data augmentation does not contribute to increasing the accuracy of the models in general.","['convolutional neural networks', 'VGG', 'ResNet', 'EfficientNet', 'ConvNeXt', 'transfer learning', 'fine-tuning']","The study addresses the challenge of detecting and classifying brain tumors, which are a diverse group of neoplasms with varying characteristics that complicate accurate diagnosis. There is a need for a comprehensive comparison of different approaches to brain tumor classification using a consistent methodology. The primary aim of the study is to evaluate and compare the performance of various techniques in classifying brain tumors, specifically gliomas, meningiomas, and pituitary tumors, using magnetic resonance imaging datasets. The objective is to determine the effectiveness and accuracy of these classification methods across multiple tumor types and to identify the optimal approach for reliable tumor detection and classification."
Medicine,A Minimal and Multi-Source Recording Setup for Ankle Joint Kinematics Estimation During Walking Using Only Proximal Information From Lower Limb,"In this study, a minimal setup for the ankle joint kinematics estimation is proposed relying only on proximal information of the lower-limb, i.e. thigh muscles activity and joint kinematics. To this purpose, myoelectric activity of Rectus Femoris (RF), Biceps Femoris (BF), and Vastus Medialis (VM) were recorded by surface electromyography (sEMG) from six healthy subjects during unconstrained walking task. For each subject, the angular kinematics of hip and ankle joints were synchronously recorded with sEMG signal for a total of 288 gait cycles. Two feature sets were extracted from sEMG signals, i.e. time domain (TD) and wavelet (WT) and compared to have a compromise between the reliability and computational capacity, they were used for feeding three regression models, i.e. Artificial Neural Networks, Random Forest, and Least Squares - Support Vector Machine (LS-SVM). BF together with LS-SVM provided the best ankle angle estimation in both TD and WT domains (RMSE < 5.6 deg). The inclusion of Hip joint trajectory significantly enhanced the regression performances of the model (RMSE < 4.5 deg). Results showed the feasibility of estimating the ankle trajectory using only proximal and limited information from the lower limb which would maximize a potential transfemoral amputee user's comfortability while facing the challenge of having a small amount of information thus requiring robust data-driven models. These findings represent a significant step towards the development of a minimal setup useful for the control design of ankle active prosthetics and rehabilitative solutions.","['Artificial Neural Networks', 'Random Forest', 'Least Squares - Support Vector Machine (LS-SVM)']","The study addresses the challenge of estimating ankle joint movement using limited information from the proximal lower limb, specifically focusing on thigh muscle activity and joint kinematics. This approach aims to improve comfort and practicality for transfemoral amputees by minimizing the amount of required sensor data while still accurately capturing ankle kinematics. The primary objective of the study is to evaluate the feasibility of estimating ankle joint trajectories during walking using only proximal lower-limb information, such as the activity of specific thigh muscles and hip joint movement. The research seeks to demonstrate that this minimal setup can provide reliable ankle kinematics estimation, which could support the design of active ankle prosthetics and rehabilitative interventions."
Engineering,Advanced Modelling of Soil Organic Carbon Content in Coal Mining Areas Using Integrated Spectral Analysis: A Dengcao Coal Mine Case Study,"Effective modelling and integrated spectral analysis approaches can advance modelling precision. To develop an integrated spectral forecast modelling of soil organic carbon (SOC), this research investigated a mining coal in Dengcao Coal Mine Area, Zhengzhou. The study utilizes the Lasso and Ranger algorithms were utilized in spectral band analysis. Four primary models employed during this process include Artificial Neural Network (ANN), Support Vector Machine, Random Forest (RF), and Partial Least Squares Regression (PLSR). The ideal model was chosen. The results showed that, in contrast to when band collection was based on Lasso algorithm modelling, model precision was higher when it was based on the Ranger algorithm. ANN model had an ideal goodness acceptance, and the modelling developed by RF showed the steadiest modelling consequences. Based on the results, a distinct method is proposed in this study for band assortment at the earlier stage of integrated spectral modelling of SOC. The Ranger method can be used to check the spectral particles, and RF or ANN can be chosen to develop the prediction modelling based on different statistics sets, which is appropriate to create the prediction modelling of SOC content in Dengcao Coal Mine Area. This research avails a position for the integrated spectral of Analysis for Advanced Modelling of Soil Organic Carbon Content in Coal Sources alongside a theoretical foundation for innovating portable device for the integrated spectral assessment of SOC content in coal mining habitats. This study might be significant for the changing modelling and monitoring of SOC in mining and environmental areas.","['Lasso', 'Artificial Neural Network (ANN)', 'Support Vector Machine', 'Random Forest (RF)']","The research addresses the challenge of improving the precision of soil organic carbon (SOC) content estimation in coal mining areas through integrated spectral analysis. Accurate modelling of SOC is essential for monitoring and managing soil quality in mining environments, which has implications for environmental sustainability and resource management. The study focuses on the Dengcao Coal Mine Area in Zhengzhou, aiming to enhance the methods used for spectral forecasting of SOC content. The primary objective of the research is to develop an integrated spectral forecast approach for SOC by investigating and comparing different spectral band selection methods and modelling techniques to identify the most effective strategy for predicting SOC content in coal mining habitats. This work seeks to provide a theoretical foundation for advanced SOC assessment and to support the innovation of portable devices for on-site spectral evaluation in mining and environmental contexts."
Engineering,Fusion of finite element and machine learning methods to predict rock shear strength parameters,"Abstract The trial-and-error method for calibrating rock mechanics parameters has the disadvantages of complexity, being time-consuming, and difficulty in ensuring accuracy. Harnessing the repeatability and scalability intrinsic to numerical simulation calculations and amalgamating them with the data-driven attributes of machine learning methods, this study uses the finite element analysis software RS2 to establish 252 sets of sandstone sample data. The recursive feature elimination and cross-validation method is employed for feature selection. The shear strength parameters of sandstone are predicted using machine learning models optimized by the particle swarm optimization (PSO) algorithm, including the backpropagation neural network, Bayesian ridge regression, support vector regression (SVR), and light gradient boosting machine. The predicted value of cohesion is proposed as the input feature to predict the friction angle. The results indicate that the optimal input characteristics for predicting cohesion are elastic modulus, Poisson's ratio, peak stress, and peak strain, while the optimal input characteristics for predicting friction angle are peak stress and cohesion. The PSO-SVR model demonstrates the best performance. The maximum error between the predicted values of cohesion and friction angle and the calculated results of RSData program are 3.5% and 4.31%, respectively. The finite element calculation is in good agreement with the stress–strain curve obtained in the laboratory. The sensitivity analysis indicates that SVR's prediction performance for cohesion and friction angle tends to be stable when the sample size is &amp;gt;25. These results offer a valuable reference for accurately predicting rock mechanics parameters.","['recursive feature elimination', 'backpropagation neural network', 'Bayesian ridge regression', 'support vector regression (SVR)', 'light gradient boosting machine']","The research idea addresses the limitations of the traditional trial-and-error method for calibrating rock mechanics parameters, which is complex, time-consuming, and challenging to ensure accuracy. There is a need for a more efficient and reliable approach to determine the shear strength parameters of sandstone, which are critical for understanding rock behavior under stress. The study aims to improve the prediction of these parameters by leveraging numerical simulation data and identifying key influencing factors. The primary objective of the study is to accurately predict the shear strength parameters of sandstone, specifically cohesion and friction angle, by establishing relationships with mechanical properties such as elastic modulus, Poisson's ratio, peak stress, and peak strain. The research seeks to provide a reliable reference for predicting these rock mechanics parameters with improved precision and consistency, validated by comparison with laboratory stress–strain curves."
Engineering,Transformer-Based Visual Segmentation: A Survey,"Visual segmentation seeks to partition images, video frames, or point clouds into multiple segments or groups. This technique has numerous real-world applications, such as autonomous driving, image editing, robot sensing, and medical analysis. Over the past decade, deep learning-based methods have made remarkable strides in this area. Recently, transformers, a type of neural network based on self-attention originally designed for natural language processing, have considerably surpassed previous convolutional or recurrent approaches in various vision processing tasks. Specifically, vision transformers offer robust, unified, and even simpler solutions for various segmentation tasks. This survey provides a thorough overview of transformer-based visual segmentation, summarizing recent advancements. We first review the background, encompassing problem definitions, datasets, and prior convolutional methods. Next, we summarize a meta-architecture that unifies all recent transformer-based approaches. Based on this meta-architecture, we examine various method designs, including modifications to the meta-architecture and associated applications. We also present several specific subfields, including 3D point cloud segmentation, foundation model tuning, domain-aware segmentation, efficient segmentation, and medical segmentation. Additionally, we compile and re-evaluate the reviewed methods on several well-established datasets. Finally, we identify open challenges in this field and propose directions for future research. The project page can be found at <uri xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">https://github.com/lxtGH/Awesome-Segmentation-With-Transformer</uri> .","['transformers', 'convolutional approaches', 'recurrent approaches', 'vision transformers']","The research idea addresses the challenge of partitioning images, video frames, or point clouds into multiple segments or groups, which is essential for various engineering applications such as autonomous driving, image editing, robot sensing, and medical analysis. The study recognizes the importance of improving visual segmentation techniques to enhance the accuracy and efficiency of these applications. The primary objective of the study is to provide a comprehensive overview of recent advancements in visual segmentation, particularly focusing on approaches that unify different methods under a common framework. It aims to summarize existing designs, examine specific subfields including 3D point cloud and medical segmentation, re-evaluate methods on established datasets, and identify open challenges to guide future research directions in this area."
Engineering,The deep learning applications in IoT-based bio- and medical informatics: a systematic literature review,"Abstract Nowadays, machine learning (ML) has attained a high level of achievement in many contexts. Considering the significance of ML in medical and bioinformatics owing to its accuracy, many investigators discussed multiple solutions for developing the function of medical and bioinformatics challenges using deep learning (DL) techniques. The importance of DL in Internet of Things (IoT)-based bio- and medical informatics lies in its ability to analyze and interpret large amounts of complex and diverse data in real time, providing insights that can improve healthcare outcomes and increase efficiency in the healthcare industry. Several applications of DL in IoT-based bio- and medical informatics include diagnosis, treatment recommendation, clinical decision support, image analysis, wearable monitoring, and drug discovery. The review aims to comprehensively evaluate and synthesize the existing body of the literature on applying deep learning in the intersection of the IoT with bio- and medical informatics. In this paper, we categorized the most cutting-edge DL solutions for medical and bioinformatics issues into five categories based on the DL technique utilized: convolutional neural network , recurrent neural network , generative adversarial network , multilayer perception , and hybrid methods. A systematic literature review was applied to study each one in terms of effective properties, like the main idea, benefits, drawbacks, methods, simulation environment, and datasets. After that, cutting-edge research on DL approaches and applications for bioinformatics concerns was emphasized. In addition, several challenges that contributed to DL implementation for medical and bioinformatics have been addressed, which are predicted to motivate more studies to develop medical and bioinformatics research progressively. According to the findings, most articles are evaluated using features like accuracy, sensitivity, specificity, F -score, latency, adaptability, and scalability.","['convolutional neural network', 'recurrent neural network', 'generative adversarial network', 'hybrid methods']","The research idea centers on addressing the challenges in medical and bioinformatics by improving the analysis and interpretation of complex and diverse data to enhance healthcare outcomes and efficiency. The study highlights the significance of advanced approaches in the context of Internet of Things (IoT)-based bio- and medical informatics, where timely and accurate insights are crucial for applications such as diagnosis, treatment recommendation, clinical decision support, image analysis, wearable monitoring, and drug discovery. The research objective is to comprehensively evaluate and synthesize the existing literature on innovative solutions applied to medical and bioinformatics problems within the IoT framework. This includes categorizing the most advanced approaches based on their characteristics, assessing their benefits and drawbacks, and addressing the challenges that hinder their implementation, with the aim of motivating further progress in medical and bioinformatics research."
Engineering,Battery safety: Machine learning-based prognostics,"Lithium-ion batteries play a pivotal role in a wide range of applications, from electronic devices to large-scale electrified transportation systems and grid-scale energy storage. Nevertheless, they are vulnerable to both progressive aging and unexpected failures, which can result in catastrophic events such as explosions or fires. Given their expanding global presence, the safety of these batteries and potential hazards from serious malfunctions are now major public concerns. Over the past decade, scholars and industry experts are intensively exploring methods to monitor battery safety, spanning from materials to cell, pack and system levels and across various spectral, spatial, and temporal scopes. In this Review, we start by summarizing the mechanisms and nature of battery failures. Following this, we explore the intricacies in predicting battery system evolution and delve into the specialized knowledge essential for data-driven, machine learning models. We offer an exhaustive review spotlighting the latest strides in battery fault diagnosis and failure prognosis via an array of machine learning approaches. Our discussion encompasses: (1) supervised and reinforcement learning integrated with battery models, apt for predicting faults/failures and probing into failure causes and safety protocols at the cell level; (2) unsupervised, semi-supervised, and self-supervised learning, advantageous for harnessing vast data sets from battery modules/packs; (3) few-shot learning tailored for gleaning insights from scarce examples, alongside physics-informed machine learning to bolster model generalization and optimize training in data-scarce settings. We conclude by casting light on the prospective horizons of comprehensive, real-world battery prognostics and management.","['supervised learning', 'reinforcement learning', 'unsupervised learning', 'semi-supervised learning', 'self-supervised learning', 'few-shot learning', 'physics-informed machine learning']","The research idea centers on the critical importance of lithium-ion battery safety due to their widespread use in electronic devices, transportation systems, and energy storage, coupled with their susceptibility to aging and unexpected failures that can lead to hazardous events such as explosions or fires. As these batteries become more prevalent globally, addressing the risks associated with their malfunctions has become a significant public concern. The study’s primary objective is to review and summarize the mechanisms and nature of battery failures, as well as to examine current advancements in fault diagnosis and failure prognosis at various levels of battery architecture. This includes exploring approaches to monitor battery safety and predict system evolution to enhance understanding and management of battery faults and failures."
Engineering,Machine learning-based predictive model for thermal comfort and energy optimization in smart buildings,"In the current context of energy transition and increasing climate change, optimizing building performance has become a critical objective. Efficient energy use and occupant comfort are paramount considerations in building design and operation. To address these challenges, this study introduces a predictive model leveraging Machine Learning (ML) algorithms. The model aims to predict thermal comfort levels and optimize energy consumption in Heating, Ventilation, and Air Conditioning (HVAC) systems. Four distinct ML algorithms Support Vector Machine (SVM), Artificial Neural Network (ANN), Random Forest (RF), and EXtreme Gradient Boosting (XGBOOST) are employed for this purpose. Data for the model is collected using a network of Raspberry Pi boards equipped with multiple sensors. Performance evaluation of the ML algorithms is conducted using statistical error metrics, including, Root Mean Square Error (RMSE), Mean Square Error (MSE), Mean Absolute Error (MAE), and coefficient of determination (R2). Results reveal that the RF and XGBOOST algorithms exhibit superior performance, achieving accuracies of 96.7% and 9.64% respectively. In contrast, the SVM algorithm demonstrates inferior performance with a R2 of 81.1%. These findings underscore the predictive capability of the RF and XGBOOST model in forecasting Predicted Mean Vote (PMV) values. The proposed model holds promise for enhancing occupant thermal comfort in buildings while simultaneously optimizing energy consumption in HVAC systems. Further research could explore the practical applications of these findings in building design and operation.","['Support Vector Machine (SVM)', 'Artificial Neural Network (ANN)', 'Random Forest (RF)', 'EXtreme Gradient Boosting (XGBOOST)']","The study addresses the critical need to optimize building performance amid the ongoing energy transition and increasing climate change concerns. It focuses on improving efficient energy use and enhancing occupant comfort, which are essential factors in building design and operation. The primary aim of the study is to develop a method to predict thermal comfort levels and optimize energy consumption in Heating, Ventilation, and Air Conditioning (HVAC) systems. This objective seeks to enhance occupant thermal comfort in buildings while simultaneously improving the efficiency of energy use within HVAC operations."
Engineering,"Big data, machine learning, and digital twin assisted additive manufacturing: A review","Additive manufacturing (AM) has undergone significant development over the past decades, resulting in vast amounts of data that carry valuable information. Numerous research studies have been conducted to extract insights from AM data and utilize it for optimizing various aspects such as the manufacturing process, supply chain, and real-time monitoring. Data integration into proposed digital twin frameworks and the application of machine learning techniques is expected to play pivotal roles in advancing AM in the future. In this paper, we provide an overview of machine learning and digital twin-assisted AM. On one hand, we discuss the research domain and highlight the machine-learning methods utilized in this field, including material analysis, design optimization, process parameter optimization, defect detection and monitoring, and sustainability. On the other hand, we examine the status of digital twin-assisted AM from the current research status to the technical approach and offer insights into future developments and perspectives in this area. This review paper aims to examine present research and development in the convergence of big data, machine learning, and digital twin-assisted AM. Although there are numerous review papers on machine learning for additive manufacturing and others on digital twins for AM, no existing paper has considered how these concepts are intrinsically connected and interrelated. Our paper is the first to integrate the three concepts big data, machine learning, and digital twins and propose a cohesive framework for how they can work together to improve the efficiency, accuracy, and sustainability of AM processes. By exploring latest advancements and applications within these domains, our objective is to emphasize the potential advantages and future possibilities associated with integration of these technologies in AM.",['machine learning'],"The research idea addresses the significant development of additive manufacturing (AM) over recent decades, which has generated vast amounts of valuable information that can be used to optimize various aspects such as the manufacturing process, supply chain, and real-time monitoring. Despite numerous studies focusing on different facets of AM, there is a lack of comprehensive understanding regarding the intrinsic connections and interrelations among the key components influencing AM advancements. The primary objective of the study is to provide an overview of the current research and development in additive manufacturing by examining how the integration of multiple emerging concepts can collectively enhance the efficiency, accuracy, and sustainability of AM processes. This paper aims to highlight the potential advantages and future possibilities associated with the convergence of these concepts to improve AM technologies."
Engineering,"A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection in Industrial Time Series: Methods, Applications, and Directions","Automating the monitoring of industrial processes has the potential to enhance efficiency and optimize quality by promptly detecting abnormal events and thus facilitating timely interventions. Deep learning, with its capacity to discern non-trivial patterns within large datasets, plays a pivotal role in this process. Standard deep learning methods are suitable to solve a specific task given a specific type of data. During training, deep learning demands large volumes of labeled data. However, due to the dynamic nature of the industrial processes and environment, it is impractical to acquire large-scale labeled data for standard deep learning training for every slightly different case anew. Deep transfer learning offers a solution to this problem. By leveraging knowledge from related tasks and accounting for variations in data distributions, the transfer learning framework solves new tasks with little or even no additional labeled data. The approach bypasses the need to retrain a model from scratch for every new setup and dramatically reduces the labeled data requirement. This survey first provides an in-depth review of deep transfer learning, examining the problem settings of transfer learning and classifying the prevailing deep transfer learning methods. Moreover, we delve into applications of deep transfer learning in the context of a broad spectrum of time series anomaly detection tasks prevalent in primary industrial domains, e.g., manufacturing process monitoring, predictive maintenance, energy management, and infrastructure facility monitoring. We discuss the challenges and limitations of deep transfer learning in industrial contexts and conclude the survey with practical directions and actionable suggestions to address the need to leverage diverse time series data for anomaly detection in an increasingly dynamic production environment.","['deep learning', 'deep transfer learning', 'transfer learning framework']","The research idea centers on improving the monitoring of industrial processes to enhance efficiency and optimize quality by enabling the prompt detection of abnormal events, which facilitates timely interventions. The dynamic nature of industrial environments makes it impractical to obtain large-scale labeled data for every variation in process conditions, creating a challenge for effective monitoring across different scenarios. The primary objective of the study is to explore approaches that address the need for effective anomaly detection in industrial time series data despite limited labeled data availability for each new case. The study aims to review and classify existing methods that leverage knowledge from related tasks to reduce the requirement for extensive labeled data, thereby supporting anomaly detection across diverse industrial domains such as manufacturing process monitoring, predictive maintenance, energy management, and infrastructure facility monitoring."
Engineering,Enhancing precision agriculture: A comprehensive review of machine learning and AI vision applications in all-terrain vehicle for farm automation,"The automation of all-terrain vehicles (ATVs) through the integration of advanced technologies such as machine learning (ML) and artificial intelligence (AI) vision has significantly changed precision agriculture. This paper aims to analyse and develop trends to provide comprehensive knowledge of the current state of ATV-based precision agriculture and the future possibilities of ML and AI. A bibliometric analysis was conducted through network diagram with keywords taken from previous publications in the domain. This review comprehensively analyses the potential of machine learning and artificial intelligence in transforming farming operations through the automation of tasks and the deployment of all-terrain vehicles. The research extensively analyses how machine learning methods have influenced several aspects of agricultural activities, such as planting, harvesting, spraying, weeding, crop monitoring, and others. AI vision systems are being researched for their ability to enhance precise and prompt decision-making in ATV-driven agricultural automation. These technologies have been thoroughly tested to show how they can improve crop yield, reducing overall investment, and make farming more efficient. Examples include machine learning-based seeding accuracy, AI-enabled crop health monitoring, and the use of AI vision for accurate pesticide application. The assessment examines challenges such as data privacy problems and scalability constraints, along with potential advancements and future prospects in the field. This will assist researchers and practitioners in making well-informed judgments regarding farming practices that are efficient, sustainable, and technologically robust.",['machine learning'],"The research addresses the transformation of precision agriculture through the automation of all-terrain vehicles (ATVs), focusing on improving farming operations such as planting, harvesting, spraying, weeding, and crop monitoring. The study highlights the motivation to enhance crop yield, reduce overall investment, and increase the efficiency and sustainability of agricultural practices by integrating advanced technologies into ATV-driven farming. The primary objective of the study is to analyze and develop trends in ATV-based precision agriculture, providing comprehensive knowledge of the current state and future possibilities in this domain. It aims to assist researchers and practitioners in making well-informed decisions regarding efficient, sustainable, and technologically robust farming practices by examining the potential benefits, challenges, and advancements related to the automation of agricultural tasks using ATVs."
Engineering,A novel framework for developing environmentally sustainable and cost-effective ultra-high-performance concrete (UHPC) using advanced machine learning and multi-objective optimization techniques,"This study aims to propose a novel framework for strength prediction and multi-objective optimization (MOO) of economical and environmentally sustainable ultra-high-performance concrete (UHPC) which aids in intelligent, sustainable, and resilient construction. Different tree- and boosting ensemble-based machine learning (ML) models are integrated to form an accurate and reliable prediction model for the uniaxial compressive strength of UHPC. The optimized models are integrated into a super learner model, resulting in a robust predictive model that is used as one of the objective functions in the MOO problem. A total of 19 objective functions are considered, including cost, uniaxial compressive strength, and 17 environmental impact categories that comprehensively evaluate the environmental sustainability of the UHPC mix. The resulting impacts from the mid-point indicators were calculated using the Eco-invent v3.7 Life Cycle Inventory database. The results showed that the super learner model accurately predicted the uniaxial compressive strength of UHPC. The MOO resulted in Pareto fronts, demonstrating the trade-off among the uniaxial compressive strength, cost, and environmental sustainability of the mix and a broad range of solutions that can be obtained for the 19 objectives. The study provides a useful tool for designers and decision-makers to select the optimal UHPC mixture that meets specific project requirements. Finally, for the practical application of the ML predictive model and MOO algorithm for UHPC, a graphical user interface-based software tool, FAI-OSUSCONCRET, was developed. This software tool offers fast, accurate, and intelligent predictions and multi-objective optimizations tailored to specific project requirements, thus resulting in a UHPC mixture that perfectly meets project needs.","['tree-based ensemble machine learning models', 'boosting ensemble-based machine learning models', 'super learner model']","The research addresses the challenge of developing ultra-high-performance concrete (UHPC) that is both economical and environmentally sustainable, aiming to support intelligent, sustainable, and resilient construction practices. It focuses on balancing multiple factors such as cost, compressive strength, and various environmental impact categories to comprehensively evaluate and improve the sustainability of UHPC mixtures. The primary objective of the study is to establish a framework for predicting the uniaxial compressive strength of UHPC and to perform multi-objective optimization considering cost, strength, and environmental impacts. This framework aims to provide designers and decision-makers with a practical tool to select optimal UHPC mixtures that meet specific project requirements while addressing economic and environmental sustainability."
Engineering,Utilizing Hybrid Machine Learning and Soft Computing Techniques for Landslide Susceptibility Mapping in a Drainage Basin,"The hydrological system of thebasin of Lake Urmia is complex, deriving its supply from a network comprising 13 perennial rivers, along withnumerous small springs and direct precipitation onto the lake’s surface. Among these contributors, approximately half of the inflow is attributed to the Zarrineh River and the Simineh River. Remarkably, Lake Urmia lacks a natural outlet, with its water loss occurring solely through evaporation processes. This study employed a comprehensive methodology integrating ground surveys, remote sensing analyses, and meticulous documentation of historical landslides within the basin as primary information sources. Through this investigative approach, we preciselyidentified and geolocated a total of 512 historical landslide occurrences across the Urmia Lake drainage basin, leveraging GPS technology for precision. Thisarticle introduces a suite of hybrid machine learning predictive models, such as support-vector machine (SVM), random forest (RF), decision trees (DT), logistic regression (LR), fuzzy logic (FL), and the technique for order of preference by similarity to the ideal solution (TOPSIS). These models were strategically deployed to assess landslide susceptibility within the region. The outcomes of the landslide susceptibility assessment reveal that the main high susceptible zones for landslide occurrence are concentrated in the northwestern, northern, northeastern, and some southern and southeastern areas of the region. Moreover, when considering the implementation of predictions using different algorithms, it became evident that SVM exhibited superior performance regardingboth accuracy (0.89) and precision (0.89), followed by RF, with and accuracy of 0.83 and a precision of 0.83. However, it is noteworthy that TOPSIS yielded the lowest accuracy value among the algorithms assessed.","['support-vector machine (SVM)', 'random forest (RF)', 'decision trees (DT)', 'logistic regression (LR)']","The hydrological system of the Lake Urmia basin is complex, receiving water from 13 perennial rivers, numerous small springs, and direct precipitation, with about half of the inflow coming from the Zarrineh and Simineh Rivers. Lake Urmia has no natural outlet, and water loss occurs solely through evaporation, making the understanding of factors influencing the basin’s stability critical. This study focuses on the identification and spatial distribution of historical landslides within the basin, which are significant for assessing regional geological hazards. The primary objective of the study is to assess landslide susceptibility across the Urmia Lake drainage basin by precisely identifying and geolocating historical landslide occurrences, thereby determining the main zones prone to landslides in the region."
Engineering,Comparison of Random Forest and XGBoost Classifiers Using Integrated Optical and SAR Features for Mapping Urban Impervious Surface,"The integration of optical and SAR datasets through ensemble machine learning models shows promising results in urban remote sensing applications. The integration of multi-sensor datasets enhances the accuracy of information extraction. This research presents a comparison of two ensemble machine learning classifiers (random forest and extreme gradient boost (XGBoost)) classifiers using an integration of optical and SAR features and simple layer stacking (SLS) techniques. Therefore, Sentinel-1 (SAR) and Landsat 8 (optical) datasets were used with SAR textures and enhanced modified indices to extract features for the year 2023. The classification process utilized two machine learning algorithms, random forest and XGBoost, for urban impervious surface extraction. The study focused on three significant East Asian cities with diverse urban dynamics: Jakarta, Manila, and Seoul. This research proposed a novel index called the Normalized Blue Water Index (NBWI), which distinguishes water from other features and was utilized as an optical feature. Results showed an overall accuracy of 81% for UIS classification using XGBoost and 77% with RF while classifying land use land cover into four major classes (water, vegetation, bare soil, and urban impervious). However, the proposed framework with the XGBoost classifier outperformed the RF algorithm and Dynamic World (DW) data product and comparatively showed higher classification accuracy. Still, all three results show poor separability with bare soil class compared to ground truth data. XGBoost outperformed random forest and Dynamic World in classification accuracy, highlighting its potential use in urban remote sensing applications.","['ensemble machine learning models', 'random forest', 'extreme gradient boost (XGBoost)']","The research addresses the challenge of accurately extracting urban impervious surfaces by integrating optical and synthetic aperture radar (SAR) datasets, which enhances the precision of information retrieval in urban remote sensing. The study is motivated by the need to improve land use and land cover classification in rapidly changing urban environments, particularly in diverse East Asian cities such as Jakarta, Manila, and Seoul. The primary objective of the study is to compare the effectiveness of different classification approaches using combined optical and SAR features for urban impervious surface extraction. Additionally, the research aims to introduce and utilize a novel index, the Normalized Blue Water Index (NBWI), to better distinguish water bodies from other land cover types and to evaluate classification accuracy across major land cover classes including water, vegetation, bare soil, and urban impervious surfaces."
Engineering,Firefly algorithm based WSN-IoT security enhancement with machine learning for intrusion detection,"Abstract A Wireless Sensor Network (WSN) aided by the Internet of Things (IoT) is a collaborative system of WSN systems and IoT networks are work to exchange, gather, and handle data. The primary objective of this collaboration is to enhance data analysis and automation to facilitate improved decision-making. Securing IoT with the assistance of WSN necessitates the implementation of protective measures to confirm the safety and reliability of the interconnected WSN and IoT components. This research significantly advances the current state of the art in IoT and WSN security by synergistically harnessing the potential of machine learning and the Firefly Algorithm. The contributions of this work are twofold: firstly, the proposed FA-ML technique exhibits an exceptional capability to enhance intrusion detection accuracy within the WSN-IoT landscape. Secondly, the amalgamation of the Firefly Algorithm and machine learning introduces a novel dimension to the domain of security-oriented optimization techniques. The implications of this research resonate across various sectors, ranging from critical infrastructure protection to industrial automation and beyond, where safeguarding the integrity of interconnected systems are of paramount importance. The amalgamation of cutting-edge machine learning and bio-inspired algorithms marks a pivotal step forward in crafting robust and intelligent security measures for the evolving landscape of IoT-driven technologies. For intrusion detection in the WSN-IoT, the FA-ML method employs a support vector machine (SVM) machine model for classification with parameter tuning accomplished using a Grey Wolf Optimizer (GWO) algorithm. The experimental evaluation is simulated using NSL-KDD Dataset, revealing the remarkable enhancement of the FA-ML technique, achieving a maximum accuracy of 99.34%. In comparison, the KNN-PSO and XGBoost models achieved lower accuracies of 96.42% and 95.36%, respectively. The findings validate the potential of the FA-ML technique as an active security solution for WSN-IoT systems, harnessing the power of machine learning and the Firefly Algorithm to bolster intrusion detection capabilities.","['Firefly Algorithm', 'machine learning', 'support vector machine (SVM)', 'Grey Wolf Optimizer (GWO)', 'XGBoost']","The research idea centers on the need to secure the interconnected components of Wireless Sensor Networks (WSN) and Internet of Things (IoT) networks to ensure the safety and reliability of these collaborative systems. Enhancing protection measures is crucial for maintaining the integrity of WSN-IoT environments, which are increasingly important in sectors such as critical infrastructure and industrial automation. The study addresses the challenge of improving intrusion detection within these integrated networks to support better decision-making and system resilience. The primary objective of the study is to develop and demonstrate an approach that significantly enhances intrusion detection accuracy in WSN-IoT systems, thereby advancing security measures for these interconnected technologies. This objective aims to provide a robust solution that can effectively safeguard the integrity of WSN-IoT components against unauthorized access and threats, contributing to the protection of critical and industrial applications."
Engineering,Peak and ultimate stress-strain model of confined ultra-high-performance concrete (UHPC) using hybrid machine learning model with conditional tabular generative adversarial network,"Ultra-high-performance concrete (UHPC) has gained prominence owing to its exceptional physical and mechanical properties and improved sustainability, making it ideal for large-scale structural applications. While numerous analytical studies have focused on predicting the stress-strain response of unconfined UHPC, there remains a lack of a reliable model for predicting the stress-strain response of confined UHPC, which poses challenges to efficient design and broader adoption, particularly in seismically active regions. To bridge this gap, the present study introduces a framework that implements machine learning (ML) models augmented by a state-of-the-art conditional tabular generative adversarial network (CTGAN) and Optuna, which a next-generation optimization framework, to accurately predict the peak and ultimate axial stress-strain responses of UHPC confined with either normal-strength steel or high-strength steel. The Optuna-optimized CTGAN is employed to address the issue of limited data by generating synthetic datasets of hypothetical confined UHPC specimens. A comprehensive database of confined UHPC stress-strain responses was compiled from existing literature and used to condition the CTGAN. The augmented database is then leveraged to develop a hybrid ML model that integrates extreme gradient boosting, gradient boosting machine, support vector regression, and K-nearest neighbors for predicting peak and ultimate stress-strain responses of confined UHPC. The predictive accuracy of the proposed hybrid ML model is evaluated and compared with a diverse set of ML models of varying complexity, and the results demonstrate its superior performance in predicting the peak and ultimate stress-strain response of confined UHPC. Furthermore, a graphical user interface of the proposed model is developed to facilitate its practical implementation and provide a rapid, autonomous, and accurate prediction of the stress-strain response of confined UHPC at both peak and ultimate states.","['conditional tabular generative adversarial network (CTGAN)', 'extreme gradient boosting', 'gradient boosting machine', 'support vector regression', 'K-nearest neighbors']","The research addresses the challenge of accurately predicting the stress-strain response of ultra-high-performance concrete (UHPC) when it is confined, which is critical for efficient design and wider application in structural engineering, especially in seismically active regions. Despite extensive studies on unconfined UHPC, there is a lack of reliable methods to characterize the behavior of confined UHPC, limiting its practical use. The primary objective of the study is to develop a reliable approach to predict the peak and ultimate axial stress-strain responses of UHPC confined with either normal-strength steel or high-strength steel. This aims to enhance the understanding and design capabilities for confined UHPC, facilitating its broader adoption in large-scale structural applications."
Engineering,Multi-Source and Multi-modal Deep Network Embedding for Cross-Network Node Classification,"In recent years, to address the issue of networked data sparsity in node classification tasks, cross-network node classification (CNNC) leverages the richer information from a source network to enhance the performance of node classification in the target network, which typically has sparser information. However, in real-world applications, labeled nodes may be collected from multiple sources with multiple modalities (e.g., text, vision, and video). Naive application of single-source and single-modal CNNC methods may result in sub-optimal solutions. To this end, in this article, we propose a model called Multi-source and Multi-modal Cross-network Deep Network Embedding (M 2 CDNE) for cross-network node classification. In M 2 CDNE, we propose a deep multi-modal network embedding approach that combines the extracted deep multi-modal features to make the node vector representations network invariant. In addition, we apply dynamic adversarial adaptation to assess the significance of marginal and conditional probability distributions between each source and target network to make node vector representations label discriminative. Furthermore, we devise to classify nodes in the target network through the related source classifier and aggregate different predictions utilizing respective network weights, corresponding to the discrepancy between each source and target network. Extensive experiments performed on real-world datasets demonstrate that the proposed M 2 CDNE significantly outperforms the state-of-the-art approaches.",['deep multi-modal network embedding'],"The research addresses the challenge of sparse information in networked data for node classification tasks, particularly when labeled nodes are collected from multiple sources with various modalities such as text, vision, and video. This sparsity and multimodal nature of real-world data complicate the effective classification of nodes in target networks. The study aims to improve the performance of node classification in target networks by leveraging richer information from multiple source networks with different modalities. The primary objective is to develop an approach that integrates information from multiple sources and modalities to enhance the accuracy and reliability of node classification in networks with sparse data."
Engineering,A vehicular network based intelligent transport system for smart cities using machine learning algorithms,"Abstract Smart cities and the Internet of Things have enabled the integration of communicating devices for efficient decision-making. Notably, traffic congestion is one major problem faced by daily commuters in urban cities. In developed countries, specialized sensors are deployed to gather traffic information to predict traffic patterns. Any traffic updates are shared with the commuters via the Internet. Such solutions become impracticable when physical infrastructure and Internet connectivity are either non-existent or very limited. In case of developing countries, no roadside units are available and Internet connectivity is still an issue in remote areas. Internet traffic analysis is a thriving field of study due to the myriad ways in which it may be put to practical use. In the intelligent Internet-of-Vehicles (IOVs), traffic congestion can be predicted and identified using cutting-edge technologies. Using tree-based decision-tree, random-forest, extra-tree, and XGBoost machine learning (ML) strategies, this research proposes an intelligent-transport-system for the IOVs-based vehicular network traffic in a smart city set-up. The suggested system uses ensemble learning and averages the selection of crucial features to give high detection accuracy at minimal computational costs, as demonstrated by the simulation results. For IOV-based vehicular network traffic, the tree-based ML approaches with feature-selection (FS) outperformed those without FS. When contrasted to the lowest KNN accuracy of 96.6% and the highest SVM accuracy of 98.01%, the Stacking approach demonstrates superior accuracy as 99.05%.","['decision-tree', 'random-forest', 'extra-tree', 'XGBoost', 'ensemble learning', 'feature-selection (FS)', 'KNN', 'SVM', 'Stacking']","The study addresses the significant challenge of traffic congestion faced by daily commuters in urban cities, particularly highlighting the limitations in developing countries where physical infrastructure and Internet connectivity are inadequate or absent. It emphasizes the impracticality of existing traffic information gathering methods that rely on specialized sensors and Internet connectivity, which are often unavailable in remote or underdeveloped areas. The primary aim of the research is to develop an intelligent transport solution tailored for vehicular network traffic within a smart city context, focusing on improving the detection and prediction of traffic congestion. This objective seeks to enhance traffic management by utilizing approaches that effectively identify crucial traffic features to achieve high accuracy in congestion detection while minimizing resource requirements."
Engineering,Conventional to Deep Ensemble Methods for Hyperspectral Image Classification: A Comprehensive Survey,"Hyperspectral image classification has become a hot research topic. HSI has been widely used in a wide range of real-world application areas due to the in-depth spectral information stored within each pixel. Noticeably, the detailed features - i.e., a nonlinear correlation between the obtained spectral data and the correlating HSI data object, generate efficient classification results that are complex for traditional techniques. Deep Learning (DL) has recently been validated as an influential feature extractor that efficiently identifies the nonlinear issues that have arisen in various computer vision challenges. This motivates using DL for Hyperspectral Image Classification (HSIC), which shows promising results. This survey provides a brief description of DL for HSIC and compares cutting-edge methodologies in the field. We will first summarize the key challenges for HSIC, and then we will discuss the superiority of DL and DL-ensemble in addressing these issues. In this article, we divide the state-of-the-art DL methodologies and DL with ensemble into spectral features, spatial features, and combined spatial-spectral features in order to comprehensively and critically evaluate the progress (future research directions as well) of such methodologies for HSIC. Furthermore, we will take into account that DL involves a substantial percentage of labeled training images, whereas obtaining such a number for HSI is time and cost-consuming. As a result, this survey describes some methodologies for improving the classification performance of DL techniques, which can serve as future recommendations.",['Deep Learning (DL)'],"The research idea focuses on the challenge of classifying hyperspectral images, which contain detailed spectral information within each pixel that is crucial for various real-world applications. Traditional techniques struggle to effectively handle the complex nonlinear relationships present in hyperspectral data, making accurate classification difficult. The study addresses the need to improve classification performance by overcoming these challenges inherent in hyperspectral image analysis. The primary objective of the study is to review and critically evaluate recent advancements in methodologies for hyperspectral image classification, highlighting key challenges and progress in extracting spectral, spatial, and combined spatial-spectral features. Additionally, the study aims to discuss approaches that enhance classification accuracy while considering the practical limitations related to the availability of labeled hyperspectral images."
Engineering,AI-Driven Digital Twin Model for Reliable Lithium-Ion Battery Discharge Capacity Predictions,"The present study proposes a novel method for predicting the discharge capabilities of lithium-ion (Li-ion) batteries using a digital twin model in practice. By combining cutting-edge machine learning techniques, such as AdaBoost and long short-term memory (LSTM) network, with a semiempirical mathematical structure, the digital twin (DT)—a virtual representation that mimics the behavior of actual batteries in real time is constructed. Various metaheuristic optimization methods, such as antlion, grey wolf optimization (GWO), and improved grey wolf optimization (IGWO), are used to adjust hyperparameters in order to optimize the models. As indicators of performance, mean absolute error (MAE) and root-mean-square error (RMSE) are applied to the models after they have undergone extensive training and ten-fold cross-validation. The models are rigorously trained and cross-validated using the NASA battery aging dataset, a widely accepted benchmark dataset for battery research. The IGWO-AdaBoost digital twin model emerges as the standout performer, achieving exceptional accuracy in predicting the discharge capacity. This model demonstrates the lowest mean absolute error (MAE) of 0.01, showcasing its superior precision in estimating discharge capabilities. Additionally, the root mean square error (RMSE) for the IGWO-AdaBoost DT model is also the lowest at 0.01. The findings of this study offer insightful information about the potential utilization of the digital twin model to accurately predict the discharge capacity of batteries.","['AdaBoost', 'long short-term memory (LSTM) network', 'antlion optimization', 'grey wolf optimization (GWO)', 'improved grey wolf optimization (IGWO)']","The study addresses the challenge of accurately predicting the discharge capabilities of lithium-ion batteries, which is crucial for optimizing battery performance and lifespan in practical applications. Understanding and forecasting battery discharge behavior is essential for enhancing energy storage solutions and ensuring reliable operation in various engineering contexts. The primary aim of the study is to develop and validate a digital twin model that can precisely estimate the discharge capacity of lithium-ion batteries in real time. This objective focuses on constructing a virtual representation that closely mimics the actual behavior of batteries to provide accurate predictions of their discharge performance."
Engineering,Automated data processing and feature engineering for deep learning and big data applications: A survey,"Modern approach to artificial intelligence (AI) aims to design algorithms that learn directly from data. This approach has achieved impressive results and has contributed significantly to the progress of AI, particularly in the sphere of supervised deep learning. It has also simplified the design of machine learning systems as the learning process is highly automated. However, not all data processing tasks in conventional deep learning pipelines have been automated. In most cases data has to be manually collected, preprocessed and further extended through data augmentation before they can be effective for training. Recently, special techniques for automating these tasks have emerged. The automation of data processing tasks is driven by the need to utilize large volumes of complex, heterogeneous data for machine learning and big data applications. Today, end-to-end automated data processing systems based on automated machine learning (AutoML) techniques are capable of taking raw data and transforming them into useful features for Big Data tasks by automating all intermediate processing stages. In this work, we present a thorough review of approaches for automating data processing tasks in deep learning pipelines, including automated data preprocessing– e.g., data cleaning, labeling, missing data imputation, and categorical data encoding–as well as data augmentation (including synthetic data generation using generative AI methods) and feature engineering–specifically, automated feature extraction, feature construction and feature selection. In addition to automating specific data processing tasks, we discuss the use of AutoML methods and tools to simultaneously optimize all stages of the machine learning pipeline.","['supervised deep learning', 'automated machine learning (AutoML)', 'synthetic data generation using generative AI methods', 'feature construction', 'feature selection']","The research addresses the challenge of managing and preparing large volumes of complex and heterogeneous data for effective use in advanced engineering applications. It highlights the need to automate various data processing tasks such as data collection, preprocessing, and augmentation to improve efficiency and effectiveness in handling such data. The study aims to review and evaluate approaches for automating these data processing tasks, including data cleaning, labeling, missing data imputation, categorical data encoding, and data augmentation, as well as feature extraction, construction, and selection. The primary objective is to provide a comprehensive overview of methods that enable the automation of all intermediate stages involved in preparing data for engineering-related tasks, thereby optimizing the entire data processing workflow."
Engineering,Data-driven evolution of water quality models: An in-depth investigation of innovative outlier detection approaches-A case study of Irish Water Quality Index (IEWQI) model,"Recently, there has been a significant advancement in the water quality index (WQI) models utilizing data-driven approaches, especially those integrating machine learning and artificial intelligence (ML/AI) technology. Although, several recent studies have revealed that the data-driven model has produced inconsistent results due to the data outliers, which significantly impact model reliability and accuracy. The present study was carried out to assess the impact of data outliers on a recently developed Irish Water Quality Index (IEWQI) model, which relies on data-driven techniques. To the author's best knowledge, there has been no systematic framework for evaluating the influence of data outliers on such models. For the purposes of assessing the outlier impact of the data outliers on the water quality (WQ) model, this was the first initiative in research to introduce a comprehensive approach that combines machine learning with advanced statistical techniques. The proposed framework was implemented in Cork Harbour, Ireland, to evaluate the IEWQI model's sensitivity to outliers in input indicators to assess the water quality. In order to detect the data outlier, the study utilized two widely used ML techniques, including Isolation Forest (IF) and Kernel Density Estimation (KDE) within the dataset, for predicting WQ with and without these outliers. For validating the ML results, the study used five commonly used statistical measures. The performance metric (R2) indicates that the model performance improved slightly (R2 increased from 0.92 to 0.95) in predicting WQ after removing the data outlier from the input. But the IEWQI scores revealed that there were no statistically significant differences among the actual values, predictions with outliers, and predictions without outliers, with a 95% confidence interval at p < 0.05. The results of model uncertainty also revealed that the model contributed <1% uncertainty to the final assessment results for using both datasets (with and without outliers). In addition, all statistical measures indicated that the ML techniques provided reliable results that can be utilized for detecting outliers and their impacts on the IEWQI model. The findings of the research reveal that although the data outliers had no significant impact on the IEWQI model architecture, they had moderate impacts on the rating schemes' of the model. This finding indicated that detecting the data outliers could improve the accuracy of the IEWQI model in rating WQ as well as be helpful in mitigating the model eclipsing problem. In addition, the results of the research provide evidence of how the data outliers influenced the data-driven model in predicting WQ and reliability, particularly since the study confirmed that the IEWQI model's could be effective for accurately rating WQ despite the presence of the data outliers in the input. It could occur due to the spatio-temporal variability inherent in WQ indicators. However, the research assesses the influence of data input outliers on the IEWQI model and underscores important areas for future investigation. These areas include expanding temporal analysis using multi-year data, examining spatial outlier patterns, and evaluating detection methods. Moreover, it is essential to explore the real-world impacts of revised rating categories, involve stakeholders in outlier management, and fine-tune model parameters. Analysing model performance across varying temporal and spatial resolutions and incorporating additional environmental data can significantly enhance the accuracy of WQ assessment. Consequently, this study offers valuable insights to strengthen the IEWQI model's robustness and provides avenues for enhancing its utility in broader WQ assessment applications. Moreover, the study successfully adopted the framework for evaluating how data input outliers affect the data-driven model, such as the IEWQI model. The current study has been carried out in Cork Harbour for only a single year of WQ data. The framework should be tested across various domains for evaluating the response of the IEWQI model's in terms of the spatio-temporal resolution of the domain. Nevertheless, the study recommended that future research should be conducted to adjust or revise the IEWQI model's rating schemes and investigate the practical effects of data outliers on updated rating categories. However, the study provides potential recommendations for enhancing the IEWQI model's adaptability and reveals its effectiveness in expanding its applicability in more general WQ assessment scenarios.",['Isolation Forest (IF)'],"The research idea centers on addressing the challenges posed by data outliers in water quality assessment models, specifically focusing on the recently developed Irish Water Quality Index (IEWQI). Although advancements have been made in water quality index models, inconsistent results caused by data outliers have raised concerns about the reliability and accuracy of these assessments. This study highlights the need for a systematic evaluation of how such outliers influence the performance and rating schemes of water quality models. The motivation is to improve the robustness and accuracy of water quality evaluations despite the inherent variability in water quality indicators.

The primary objective of the study is to assess the impact of data outliers on the IEWQI model’s ability to rate water quality accurately. The research aims to evaluate the sensitivity of the IEWQI model to outliers in input indicators and determine whether removing these outliers significantly affects the model’s predictions and rating outcomes. Additionally, the study seeks to provide insights into improving the model’s rating schemes and to offer recommendations for enhancing the model’s adaptability and applicability in broader water quality assessment contexts."
Engineering,Machine learning for multi-dimensional performance optimization and predictive modelling of nanopowder-mixed electric discharge machining (EDM),"Abstract Aluminium 6061 (Al6061) is a widely used material for various industrial applications due to low density and high strength. Nevertheless, the conventional machining operations are not the best choice for the machining purposes. Therefore, amongst all the non-conventional machining operations, electric discharge machining (EDM) is opted to carry out the research due to its wide ability to cut the materials. But the high electrode wear rate (EWR) and high dimensional inaccuracy or overcut (OC) of EDM limit its usage. Consequently, nanopowder is added to the dielectric medium to address the abovementioned issues. Nanopowder mixed EDM (NPMEDM) process is a complex process in terms of performance predictability for different materials. Similarly, the interactions between the process parameters such as peak current ( I p ), spark voltage ( S v ), pulse on time ( P on ) and powder concentration ( C p ) in dielectric enhance the parametric sensitivity. In addition, the cryogenic treatment (CT) of electrodes makes the process complex limiting conventional simulation approaches for modelling inter-relationships. An alternative approach requires experimental exploration and systematic investigation to model EWR and overcutting problems of EDM. Thus, artificial neural networks (ANNs) are used for predictive modelling of the process which are integrated with multi-objective genetic algorithm (MOGA) for parametric optimization. The approach uses experimental data based on response surface methodology (RSM) design of experiments. Moreover, the process physics is thoroughly discussed with parametric effect analysis supported with evidence of microscopic images, scanning electron microscopy (SEM) and 3D surface topographic images. Based on multi-dimensional optimization results, the NT brass electrode showed an improvement of 65.02% in EWR and 59.73% in OC using deionized water. However, CT brass electrode showed 78.41% reduction in EWR and 67.79% improved dimensional accuracy in deionized water. In addition to that, CT brass electrode gave 27.69% less EWR and 81.40% improved OC in deionized water compared to kerosene oil.","['artificial neural networks (ANNs)', 'multi-objective genetic algorithm (MOGA)']","The research addresses the challenges associated with machining Aluminium 6061, a material valued for its low density and high strength, where conventional machining methods are inadequate. Specifically, electric discharge machining (EDM), despite its capability to cut various materials, suffers from high electrode wear rate (EWR) and dimensional inaccuracies such as overcut (OC), which limit its practical application. To overcome these issues, the study explores modifications in the EDM process, including the addition of nanopowder to the dielectric medium and the use of cryogenic treatment on electrodes, aiming to improve machining performance and accuracy.

The primary objective of the study is to systematically investigate and model the effects of process parameters on electrode wear rate and overcut in EDM of Aluminium 6061. The research aims to optimize these parameters to reduce electrode wear and enhance dimensional accuracy, thereby improving the overall efficiency and precision of the EDM process for this material. Additionally, the study seeks to provide a thorough understanding of the process physics through experimental exploration and parametric effect analysis supported by microscopic and surface imaging techniques."
Engineering,Predicting the mechanical properties of plastic concrete: An optimization method by using genetic programming and ensemble learners,"This study presents a comparative analysis of individual and ensemble learning algorithms (ELAs) to predict the compressive strength (CS) and flexural strength (FS) of plastic concrete. Multilayer perceptron neuron network (MLPNN), Support vector machine (SVM), random forest (RF), and decision tree (DT) were used as base learners, which were then combined with bagging and Adaboost methods to improve the predictive performance. In addition, gene expression programming (GEP) was used to develop computational equations that can be used to predict the CS and FS of plastic concrete. An extensive database containing 357 and 125 data points was obtained from the literature, and the eight most impactful ingredients were used in the model's development. The accuracy of all models was assessed using several statistical measures, including an error matrix, Akaike information criterion (AIC), K-fold cross-validation, and other external validation equations. Furthermore, sensitivity and SHAP analysis were performed to evaluate input variables' relative significance and impact on the anticipated CS and FS. Based on statistical measures and other validation criteria, GEP outpaces all other individual models, whereas, in ELAs, the SVR ensemble with Adaboost and RF modified with the Bagging technique demonstrated superior performance. SHapley Additive exPlanations (SHAP) and sensitivity analysis reveal that plastic, cement, water, and the age of the specimens have the highest influence, while superplasticizer has the lowest impact, which is consistent with experimental studies. Moreover, GUI and GEP-based simple mathematical correlation can enhance the practical scope of this study and be an effective tool for the pre-mix design of plastic concrete.","['Multilayer perceptron neuron network (MLPNN)', 'Support vector machine (SVM)', 'random forest (RF)', 'decision tree (DT)', 'bagging', 'Adaboost', 'gene expression programming (GEP)', 'SVR ensemble with Adaboost']","The research idea addresses the challenge of accurately predicting the compressive strength and flexural strength of plastic concrete, which are critical properties for ensuring the material's performance and durability in construction applications. Understanding the influence of various ingredients on these strength parameters is essential for optimizing the mix design and improving the quality of plastic concrete. The study aims to enhance the ability to estimate these mechanical properties reliably using available experimental data.

The primary objective of the study is to develop and compare different approaches for predicting the compressive strength and flexural strength of plastic concrete based on key ingredient inputs. The research seeks to identify the most effective predictive approach and to establish simple mathematical correlations that can be practically applied for pre-mix design. Additionally, the study aims to evaluate the relative significance of input variables affecting the strength characteristics to support better material formulation decisions."
Engineering,Machine learning-assisted in-situ adaptive strategies for the control of defects and anomalies in metal additive manufacturing,"In metal additive manufacturing (AM), the material microstructure and part geometry are formed incrementally. Consequently, the resulting part could be defect- and anomaly-free if sufficient care is taken to deposit each layer under optimal process conditions. Conventional closed-loop control (CLC) engineering solutions which sought to achieve this were deterministic and rule-based, thus resulting in limited success in the stochastic environment experienced in the highly dynamic AM process. On the other hand, emerging machine learning (ML) based strategies are better suited to providing the robustness, scope, flexibility, and scalability required for process control in an uncertain environment. Offline ML models that help optimise AM process parameters before a build begins and online ML models that efficiently processed in-situ sensory data to detect and diagnose flaws in real-time (or near-real-time) have been developed. However, ML models that enable a process to take evasive or corrective actions in relation to flaws via on the fly decision-making are only emerging. These models must possess prognostic capabilities to provide context-sensitive recommendations for in-situ process control based on real-time diagnostics. In this article, we pinpoint the shortcomings in traditional CLC strategies, and provide a framework for defect and anomaly control through ML-assisted CLC in AM. We discuss flaws in terms of their causes, in-situ detectability, and controllability, and examine their management under three scenarios: avoidance, mitigation, and repair. Then, we summarise the research into ML models developed for offline optimisation and in-situ diagnosis before initiating a detailed conversation on the implementation of ML-assisted in-situ process control. We found that researchers favoured reinforcement learning approaches or inverse ML models for making rapid, situation-aware control decisions. We also observed that, to-date, the defects addressed were those that may be quantified relatively easily autonomously, and that mitigation (rather than avoidance or repair) was the aim of ML-assisted in-situ control strategies. Additionally, we highlight the various technologies that must seamlessly combine to advance the field of autonomous in-situ control so that it becomes a reality in industrial settings. Finally, we raise awareness of seldom discussed, yet highly pertinent, topics relevant to adaptive control. Our work closes a significant gap in the current AM literature by broaching wide-ranging discussions on matters relevant to in-situ adaptive control in AM.","['online ML models', 'reinforcement learning approaches']","The research idea centers on the challenge of achieving defect- and anomaly-free parts in metal additive manufacturing by carefully controlling the deposition of each layer under optimal process conditions. Traditional closed-loop control methods have shown limited success due to the highly dynamic and stochastic nature of the additive manufacturing process. There is a need for more robust and flexible approaches to manage defects and anomalies during the build process to improve part quality and reliability. The study addresses the shortcomings of existing control strategies and explores ways to enhance in-situ process control for better defect management.

The primary objective of the study is to provide a comprehensive framework for defect and anomaly control in metal additive manufacturing through advanced closed-loop control strategies that enable avoidance, mitigation, and repair of flaws during the build. The research aims to examine the causes, detectability, and controllability of defects and to discuss the implementation of adaptive in-situ process control that can respond effectively to real-time diagnostics. Additionally, the study seeks to highlight the integration of various technologies necessary to realize autonomous in-situ control in industrial settings and to raise awareness of important considerations relevant to adaptive control in additive manufacturing."
Engineering,Performance assessment of machine learning algorithms for mapping of land use/land cover using remote sensing data,"The rapid increase in population accelerates the rate of change of Land use/Land cover (LULC) in various parts of the world. This phenomenon caused a huge strain for natural resources. Hence, continues monitoring of LULC changes gained a significant importance for management of natural resources and assessing the climate change impacts. Recently, application of machine learning algorithms on RS (remote sensing) data for rapid and accurate mapping of LULC gained significant importance due to growing need of LULC estimation for ecosystem services, natural resource management and environmental management. Hence, it is crucial to access and compare the performance of different machine learning classifiers for accurate mapping of LULC. The primary objective of this study was to compare the performance of CART (Classification and Regression Tree), RF (Random Forest) and SVM (Support Vector Machine) for LULC estimation by processing RS data on Google Earth Engine (GEE). In total four classes of LULC (Water Bodies, Vegetation Cover, Urban Land and Barren Land) for city of Lahore were extracted using satellite images from Landsat-7, Landsat-8 and Landsat-9 for years 2008, 2015 and 2022, respectively. According to results, RF is the best performing classifier with maximum overall accuracy of 95.2% and highest Kappa coefficient value of 0.87, SVM achieved maximum accuracy of 89.8% with highest Kappa of 0.84 and CART showed maximum overall accuracy of 89.7% with Kappa value of 0.79. Results from this study can give assistance for decision makers, planners and RS experts to choose a suitable machine learning algorithm for LULC classification in an unplanned urbanized city like Lahore.","['Classification and Regression Tree (CART)', 'Random Forest (RF)', 'Support Vector Machine (SVM)']","The rapid increase in population has accelerated the rate of Land Use/Land Cover (LULC) changes in various parts of the world, placing significant strain on natural resources. Continuous monitoring of these LULC changes is essential for effective management of natural resources and for assessing the impacts of climate change. The primary objective of this study was to compare the performance of different classification approaches for accurate mapping of LULC in the city of Lahore. Specifically, the study aimed to evaluate and contrast the effectiveness of three classification methods in extracting four LULC classes—Water Bodies, Vegetation Cover, Urban Land, and Barren Land—using satellite imagery from multiple years to support better decision-making and planning in an unplanned urbanized environment."
Engineering,Groundwater Quality Assessment and Irrigation Water Quality Index Prediction Using Machine Learning Algorithms,"The evaluation of groundwater quality is crucial for irrigation purposes; however, due to financial constraints in developing countries, such evaluations suffer from insufficient sampling frequency, hindering comprehensive assessments. Therefore, associated with machine learning approaches and the irrigation water quality index (IWQI), this research aims to evaluate the groundwater quality in Naama, a region in southwest Algeria. Hydrochemical parameters (cations, anions, pH, and EC), qualitative indices (SAR,RSC,Na%,MH,and PI), as well as geospatial representations were used to determine the groundwater’s suitability for irrigation in the study area. In addition, efficient machine learning approaches for forecasting IWQI utilizing Extreme Gradient Boosting (XGBoost), Support vector regression (SVR), and K-Nearest Neighbours (KNN) models were implemented. In this research, 166 groundwater samples were used to calculate the irrigation index. The results showed that 42.18% of them were of excellent quality, 34.34% were of very good quality, 6.63% were good quality, 9.64% were satisfactory, and 4.21% were considered unsuitable for irrigation. On the other hand, results indicate that XGBoost excels in accuracy and stability, with a low RMSE (of 2.8272 and a high R of 0.9834. SVR with only four inputs (Ca2+, Mg2+, Na+, and K) demonstrates a notable predictive capability with a low RMSE of 2.6925 and a high R of 0.98738, while KNN showcases robust performance. The distinctions between these models have important implications for making informed decisions in agricultural water management and resource allocation within the region.","['Extreme Gradient Boosting (XGBoost)', 'Support Vector Regression (SVR)', 'K-Nearest Neighbours (KNN)']","The evaluation of groundwater quality is essential for irrigation purposes, particularly in regions where financial constraints limit the frequency of sampling, resulting in incomplete assessments. This issue is significant in developing countries, where insufficient data hinders the ability to comprehensively determine water suitability for agricultural use. The study focuses on assessing the groundwater quality in Naama, a region in southwest Algeria, by examining various hydrochemical parameters and qualitative indices to establish its appropriateness for irrigation. The primary aim of the research is to evaluate the groundwater quality in the study area using these parameters and indices to calculate the irrigation water quality index, thereby providing a detailed classification of water suitability for irrigation and supporting informed decisions in agricultural water management and resource allocation."
Engineering,Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning,"Recent development in computing power has resulted in performance improvements on holistic(none-occluded) person Re-Identification (ReID) tasks. Nevertheless, the precision of the recent research will diminish when a pedestrian is obstructed by obstacles. Within the realm of 2D space, the loss of information from obstructed objects continues to pose significant challenges in the context of person ReID. Person is a 3D non-grid object, and thus semantic representation learning in only 2D space limits the understanding of occluded person. In the present work, we propose a network based on 3D multi-view learning, allowing it to acquire geometric and shape details of an occluded pedestrian from 3D space. Simultaneously, it capitalizes on advancements in 2D-based networks to extract semantic representations from 3D multi-views. Specifically, the surface random selection strategy is proposed to convert images of 2D RGB into 3D multi-views. Using this strategy, we build four extensive 3D multi-view data collections for person ReID. After that, Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning(MV-3DSReID), is proposed for identifying the person by learning person geometry and structure representation from the groups of multi-view images. In comparison to alternative data formats (e.g., 2D RGB, 3D point cloud), multi-view images complement each other's detailed features of the 3D object by adjusting rendering viewpoints, thus facilitating a more comprehensive understanding of the person for both holistic and occluded ReID situations. Experiments on occluded and holistic ReID tasks demonstrate performance levels comparable to state-of-the-art methods, validating the effectiveness of our proposed approach in tackling challenges related to occlusion. The code is available at https://github.com/hangjiaqi1/MV-TransReID.",['3D multi-view learning'],"The research addresses the challenge of accurately identifying pedestrians when they are partially obstructed by obstacles, which leads to a loss of information in traditional two-dimensional representations. Since a person is a three-dimensional object, relying solely on 2D space limits the ability to understand and recognize occluded individuals effectively. The study focuses on overcoming the difficulties posed by occlusion in person identification by enhancing the geometric and shape understanding of pedestrians in 3D space. The primary objective of the study is to improve person identification by learning the geometry and structural representation of pedestrians through multiple views in three-dimensional space. This approach aims to provide a more comprehensive understanding of both fully visible and occluded pedestrians by integrating detailed features from various viewpoints, thereby addressing the limitations of existing 2D-based methods in occluded scenarios."
Engineering,The use of machine learning techniques to investigate the properties of metakaolin-based geopolymer concrete,"The construction industry significantly contributes to global greenhouse gas emissions, highlighting the imperative for developing environmentally friendly construction materials. Geopolymers, particularly those utilizing metakaolin (MK), have emerged as a promising green alternative to conventional concrete. However, the acquisition of MK-based geopolymer concrete with optimal mechanical properties poses challenges due to numerous influential factors, disagreement over various findings, and the lack of a reliable predictive model. This study aimed to address this gap by employing a wide range of machine learning methods, namely gradient boosting machine, random forest, decision tree, artificial neural network, and support vector machine. Different optimization and regularization techniques were used to comprehensively understand the factors affecting the compressive strength of MK-based geopolymer concrete, including mixture design, chemical characteristics of the initial binder and activators, and different curing regimes. The results demonstrated the exceptional performance of the gradient boosting machine in predicting the compressive strength of MK-based geopolymer concrete, achieving a coefficient of determination of 0.983 and a mean absolute error of 1.615 MPa. Additionally, the study employed partial dependence plots, feature importance analysis, and SHapley Additive exPlanations (SHAP) to elucidate the proposed models. The coarse-to-fine aggregate ratio, H2O/Na2O molar ratio, extra water content, and sodium hydroxide concentration were identified as the most critical parameters affecting the compressive strength of MK-based geopolymer concrete. This research contributes to advancing the development of sustainable construction materials, streamlining experimental tasks, minimizing the need for labor and materials, improving time efficiency, and providing valuable insights for optimizing the design of MK-based geopolymer concrete.","['gradient boosting machine', 'random forest', 'decision tree', 'artificial neural network', 'support vector machine']","The construction industry significantly contributes to global greenhouse gas emissions, creating an urgent need for environmentally friendly construction materials. Geopolymers based on metakaolin (MK) have emerged as a promising sustainable alternative to conventional concrete, but achieving MK-based geopolymer concrete with optimal mechanical properties remains challenging due to multiple influencing factors and inconsistent findings. The primary objective of this study is to comprehensively understand the factors affecting the compressive strength of MK-based geopolymer concrete, including mixture design, chemical characteristics of the initial binder and activators, and different curing regimes. This research aims to provide valuable insights for optimizing the design of MK-based geopolymer concrete to advance sustainable construction materials while improving efficiency and reducing resource consumption."
Engineering,A machine learning-based framework for clustering residential electricity load profiles to enhance demand response programs,"Load shapes derived from smart meter data are frequently employed to analyze daily energy consumption patterns, particularly in the context of applications like Demand Response (DR). Nevertheless, one of the most important challenges to this endeavor lies in identifying the most suitable consumer clusters with similar consumption behaviors. In this paper, we present a novel machine learning based framework in order to achieve optimal load profiling through a real case study, utilizing data from almost 5000 households in London. Four widely used clustering algorithms are applied specifically K-means, K-medoids, Hierarchical Agglomerative Clustering and Density-based Spatial Clustering. An empirical analysis as well as multiple evaluation metrics are leveraged to assess those algorithms. Following that, we redefine the problem as a probabilistic classification one, with the classifier emulating the behavior of a clustering algorithm, leveraging Explainable AI (xAI) to enhance the interpretability of our solution. According to the clustering algorithm analysis the optimal number of clusters for this case is seven. Despite that, our methodology shows that two of the clusters, almost 10% of the dataset, exhibit significant internal dissimilarity. As a result, these clusters have been excluded from consideration for DR programs. The scalability and versatility of our solution makes it an ideal choice for power utility companies aiming to segment their users for creating more targeted DR programs.","['K-means', 'K-medoids', 'Hierarchical Agglomerative Clustering', 'Density-based Spatial Clustering', 'probabilistic classification', 'Explainable AI (xAI)']","The study addresses the challenge of accurately identifying consumer groups with similar daily energy consumption patterns to improve the effectiveness of Demand Response (DR) programs. This problem is critical because appropriate clustering of consumers enables better understanding and management of energy usage behaviors. The primary aim of the research is to achieve optimal load profiling by determining the most suitable number and composition of consumer clusters based on real household energy consumption data. The study seeks to refine the identification of consumer groups to exclude those with significant internal dissimilarity, thereby enhancing the targeting of DR initiatives for power utility companies."
Engineering,The diagnostic and triage accuracy of the GPT-3 artificial intelligence model: an observational study,"BackgroundArtificial intelligence (AI) applications in health care have been effective in many areas of medicine, but they are often trained for a single task using labelled data, making deployment and generalisability challenging. How well a general-purpose AI language model performs diagnosis and triage relative to physicians and laypeople is not well understood.MethodsWe compared the predictive accuracy of Generative Pre-trained Transformer 3 (GPT-3)'s diagnostic and triage ability for 48 validated synthetic case vignettes (<50 words; sixth-grade reading level or below) of both common (eg, viral illness) and severe (eg, heart attack) conditions to a nationally representative sample of 5000 lay people from the USA who could use the internet to find the correct options and 21 practising physicians at Harvard Medical School. There were 12 vignettes for each of four triage categories: emergent, within one day, within 1 week, and self-care. The correct diagnosis and triage category (ie, ground truth) for each vignette was determined by two general internists at Harvard Medical School. For each vignette, human respondents and GPT-3 were prompted to list diagnoses in order of likelihood, and the vignette was marked as correct if the ground-truth diagnosis was in the top three of the listed diagnoses. For triage accuracy, we examined whether the human respondents' and GPT-3's selected triage was exactly correct according to the four triage categories, or matched a dichotomised triage variable (emergent or within 1 day vs within 1 week or self-care). We estimated GPT-3's diagnostic and triage confidence on a given vignette using a modified bootstrap resampling procedure, and examined how well calibrated GPT-3's confidence was by computing calibration curves and Brier scores. We also performed subgroup analysis by case acuity, and an error analysis for triage advice to characterise how its advice might affect patients using this tool to decide if they should seek medical care immediately.FindingsAmong all cases, GPT-3 replied with the correct diagnosis in its top three for 88% (42/48, 95% CI 75–94) of cases, compared with 54% (2700/5000, 53–55) for lay individuals (p<0.0001) and 96% (637/666, 94–97) for physicians (p=0·012). GPT-3 triaged 70% correct (34/48, 57–82) versus 74% (3706/5000, 73–75; p=0.60) for lay individuals and 91% (608/666, 89–93%; p<0.0001) for physicians. As measured by the Brier score, GPT-3 confidence in its top prediction was reasonably well calibrated for diagnosis (Brier score=0·18) and triage (Brier score=0·22). We observed an inverse relationship between case acuity and GPT-3 accuracy (p<0·0001) with a fitted trend line of –8·33% decrease in accuracy for every level of increase in case acuity. For triage error analysis, GPT-3 deprioritised truly emergent cases in seven instances.InterpretationA general-purpose AI language model without any content-specific training could perform diagnosis at levels close to, but below, physicians and better than lay individuals. We found that GPT-3's performance was inferior to physicians for triage, sometimes by a large margin, and its performance was closer to that of lay individuals. Although the diagnostic performance of GPT-3 was comparable to physicians, it was significantly better than a typical person using a search engine.FundingThe National Heart, Lung, and Blood Institute.",['Generative Pre-trained Transformer 3 (GPT-3)'],"The research addresses the challenge of accurately diagnosing and triaging medical conditions, highlighting the difficulty in achieving reliable performance comparable to physicians and the general public. It focuses on understanding how well a general-purpose approach can perform these critical healthcare tasks across a range of common and severe conditions. The study aims to evaluate the diagnostic and triage accuracy of a general-purpose language-based tool relative to practicing physicians and laypeople, using validated clinical case scenarios. Specifically, it seeks to determine the tool’s ability to correctly identify diagnoses and appropriate triage categories, assess its confidence calibration, and analyze its performance variations with case severity."
Engineering,Internet of things sensors and support vector machine integrated intelligent irrigation system for agriculture industry,"Abstract Because there is more demand for freshwater around the world and the world’s population is growing at the same time, there is a severe lack of freshwater resources in the central part of the planet. The world’s current population of 7.2 billion people is expected to grow to over 9 billion by the year 2050. The vast majority of freshwater is used for things like cooking, cleaning, and farming. Most industrialised countries are in desperate need of smart irrigation systems, which are now a must-have because of how quickly technology is improving. In article presents IoT based Sensor integrated intelligent irrigation system for agriculture industry. IoT based humidity and soil sensors are used to collect soil related data. This data is stored in a centralized cloud. Features are selected by CFS algorithm. This will help in discarding irrelevant data. Clustering of data is performed by K means algorithm. This will help in keeping similar data together. Then classification model is build using the SVM, Random Forest and Naïve Bayes algorithm. Model is trained, validated and tested using the acquired data. Historical soil and humidity related data is also used in training the model. K-means SVM hybrid classifier is achieving better results for classification, prediction of water demand and saving fresh water by intelligent irrigation. K-means SVM hybrid classifier has achieved accuracy rate of 98.5 percent. Specificity, recall and precision of K-means SVM hybrid classifier is also higher than random forest and naïve bayes classifier.","['CFS algorithm', 'K means algorithm', 'SVM', 'Random Forest', 'Naïve Bayes algorithm']","The research addresses the critical issue of freshwater scarcity driven by the increasing global population and the growing demand for water in essential activities such as cooking, cleaning, and farming. There is an urgent need for efficient irrigation solutions in industrialized countries to conserve freshwater resources amid these challenges. The primary objective of the study is to develop an intelligent irrigation approach that optimizes water usage in agriculture by utilizing soil and humidity information to better predict water demand. This aims to contribute to freshwater conservation by enabling more precise and effective irrigation practices."
Engineering,Energy and economic analysis of building integrated photovoltaic thermal system: Seasonal dynamic modeling assisted with machine learning-aided method and multi-objective genetic optimization,"Building integrated photovoltaic thermal (BIPV/T) systems offer a highly effective means of generating clean energy for both electricity and heating purposes in residential buildings. Hence, this article introduces a new BIPV/T system to optimally minimize the energy consumption of a household residential building. The meticulous design of the proposed BIPV/T system is accomplished through MATLAB/Simulink® dynamic modeling. Performance analysis for the BIPV/T system is performed under different seasonal conditions with in-depth techno-economic analyses to estimate the expected enhancement in the thermal, electrical, and economic performance of the system. Moreover, a sensitivity analysis is conducted to explore the impact of various factors on the energetic and economic performances of the proposed BIPV/T system. More so, the two-layer feed-forward back-propagation artificial neural network modeling is developed to accurately predict the hourly solar radiation and ambient temperature for the BIPV/T. Additionally, a multi-objective optimization using the NSGA-II method is also conducted for the minimization of the total BIPV/T plant area and maximization of the total efficiency and net thermal power of the system as well as to estimate the optimized operating conditions for input variables across different seasons within the provided ranges. The sensitivity analysis revealed that higher solar flux levels lead to increased electric output power of the BIPV/T plant, but total efficiency decreases due to higher thermal losses. Moreover, the proposed NSGA-II shows a feasible method to attain a maximum net thermal power and optimal total efficiency of 5320 W and 63% with a minimal total plant area of 32.89 m2 that attained a very low deviation index from the ideal solution. The levelised cost of electricity is obtained as 0.10 $/kWh under the optimal conditions. Thus, these findings offer valuable insights into the potential of BIPV/T systems as a sustainable and efficient energy solution for residential applications.",['two-layer feed-forward back-propagation artificial neural network'],"The research idea centers on the need for effective solutions to generate clean energy for both electricity and heating in residential buildings, highlighting the potential of building integrated photovoltaic thermal (BIPV/T) systems to reduce household energy consumption. This study addresses the challenge of optimizing such systems to enhance their thermal, electrical, and economic performance across different seasonal conditions. The research objective is to introduce and evaluate a new BIPV/T system designed to minimize the energy consumption of a residential building by improving its overall efficiency and net thermal power output. Additionally, the study aims to identify the optimal operating conditions and plant area that maximize system performance while providing a cost-effective energy solution for residential applications."
Engineering,RanMerFormer: Randomized vision transformer with token merging for brain tumor classification,"Brains are the control center of the nervous system in human bodies, and brain tumor is one of the most deadly diseases. Currently, magnetic resonance imaging (MRI) is the most effective way to brain tumors early detection in clinical diagnoses due to its superior imaging quality for soft tissues. Manual analysis of brain MRI is error-prone which depends on empirical experience and the fatigue state of the radiologists to a large extent. Computer-aided diagnosis (CAD) systems are becoming more and more impactful because they can provide accurate prediction results based on medical images with advanced techniques from computer vision. Therefore, a novel CAD method for brain tumor classification named RanMerFormer is presented in this paper. A pre-trained vision transformer is used as the backbone model. Then, a merging mechanism is proposed to remove the redundant tokens in the vision transformer, which improves computing efficiency substantially. Finally, a randomized vector functional-link serves as the head in the proposed RanMerFormer, which can be trained swiftly. All the simulation results are obtained from two public benchmark datasets, which reveal that the proposed RanMerFormer can achieve state-of-the-art performance for brain tumor classification. The trained RanMerFormer can be applied in real-world scenarios to assist in brain tumor diagnosis.","['pre-trained vision transformer', 'randomized vector functional-link']","The research addresses the critical challenge of early and accurate detection of brain tumors, which are among the most deadly diseases affecting the human nervous system. Magnetic resonance imaging (MRI) is currently the most effective clinical tool for identifying brain tumors due to its high-quality imaging of soft tissues, but manual interpretation of these images is prone to errors and heavily reliant on the experience and fatigue levels of radiologists. The primary objective of the study is to develop a novel approach for brain tumor classification that enhances diagnostic accuracy and efficiency. This approach aims to improve the process of analyzing brain MRI scans to support timely and reliable brain tumor diagnosis in clinical practice."
Engineering,Improving Forest Above-Ground Biomass Estimation by Integrating Individual Machine Learning Models,"The accurate estimation of forest above-ground biomass (AGB) is crucial for sustainable forest management and tracking the carbon cycle of forest ecosystem. Machine learning algorithms have been proven to have great potential in forest AGB estimation with remote sensing data. Though many studies have demonstrated that a single machine learning model can produce highly accurate estimations of forest AGB in many situations, efforts are still required to explore the possible improvement in forest AGB estimation for a specific scenario under study. This study aims to investigate the performance of novel ensemble machine learning methods for forest AGB estimation and analyzes whether these methods are affected by forest types, independent variables, and spatial autocorrelation. Four well-known machine learning models (CatBoost, LightGBM, random forest (RF), and XGBoost) were compared for forest AGB estimation in the study using eight scenarios devised on the basis of two study regions, two variable types, and two validation strategies. Subsequently, a hybrid model combining the strengths of these individual models was proposed for forest AGB estimation. The findings indicated that no individual model outperforms the others in all scenarios. The RF model demonstrates superior performance in scenarios 5, 6, and 7, while the CatBoost model shows the best performance in the remaining scenarios. Moreover, the proposed hybrid model consistently has the best performance in all scenarios in spite of some uncertainties. The ensemble strategy developed in this study for the hybrid model substantially improves estimation accuracy and exhibits greater stability, effectively addressing the challenge of model selection encountered in the forest AGB forecasting process.","['CatBoost', 'LightGBM', 'random forest (RF)', 'XGBoost', 'ensemble machine learning methods']","The accurate estimation of forest above-ground biomass (AGB) is essential for sustainable forest management and monitoring the carbon cycle within forest ecosystems. Despite existing methods providing highly accurate estimations in many cases, there remains a need to improve the precision of forest AGB estimation for specific scenarios and conditions. This study aims to evaluate the effectiveness of various approaches for estimating forest AGB and to determine how factors such as forest types, variable selection, and spatial relationships influence estimation performance. The primary objective is to investigate and compare different estimation methods across multiple scenarios and to develop a combined approach that enhances accuracy and stability in forest AGB estimation, thereby addressing challenges related to method selection in this context."
Engineering,Short-term power load forecasting based on AC-BiLSTM model,"The practice of ultra-short-term power load forecasting serves as a critical strategy for enabling rapid response and real-time dispatch in power systems. By improving the accuracy of load forecasting, both the safety of power systems and the efficiency of electricity usage can be significantly enhanced. Addressing the challenges posed by the non-linear and temporal characteristics of grid load data, this study introduces a novel ultra-short-term power load forecasting model, integrating Convolutional Neural Networks (CNN), Bidirectional Long Short-Term Memory networks (BiLSTM), and an Attention mechanism, referred to as the AC-BiLSTM model. This innovative approach harnesses the power of CNN and BiLSTM to extract spatio-temporal features of load data, while the Attention mechanism allocates optimal weights to the hidden states of the BiLSTM model, thereby amplifying crucial historical load sequence data and minimizing information loss. The final output of the model is then determined through a fully connected layer. To validate the efficacy of this approach, an empirical study was conducted using real load data from a specific region. The results, obtained from two contrasting experimental scenarios, demonstrate a significant enhancement in forecasting accuracy. This finding underscores the potential of the AC-BiLSTM model as a reliable tool for both strategic planning and maintaining operational stability in power systems.","['Convolutional Neural Networks (CNN)', 'Bidirectional Long Short-Term Memory networks (BiLSTM)', 'Attention mechanism']","The research addresses the critical need for ultra-short-term power load forecasting to enable rapid response and real-time dispatch in power systems. Improving the accuracy of load forecasting is essential for enhancing both the safety of power systems and the efficiency of electricity usage, particularly given the complex non-linear and temporal characteristics of grid load data. The primary objective of the study is to develop and validate a novel approach for ultra-short-term power load forecasting that effectively captures the spatio-temporal features of load data and emphasizes important historical load sequences. This aims to significantly improve forecasting accuracy, thereby supporting strategic planning and maintaining operational stability in power systems."
Engineering,Assessment of surrogate models for flood inundation: The physics-guided LSG model vs. state-of-the-art machine learning models,"Hydrodynamic models can accurately simulate flood inundation but are limited by their high computational demand that scales non-linearly with model complexity, resolution, and domain size. Therefore, it is often not feasible to use high-resolution hydrodynamic models for real-time flood predictions or when a large number of predictions are needed for probabilistic flood design. Computationally efficient surrogate models have been developed to address this issue. The recently developed Low-fidelity, Spatial analysis, and Gaussian Process Learning (LSG) model has shown strong performance in both computational efficiency and simulation accuracy. The LSG model is a physics-guided surrogate model that simulates flood inundation by first using an extremely coarse and simplified (i.e. low-fidelity) hydrodynamic model to provide an initial estimate of flood inundation. Then, the low-fidelity estimate is upskilled via Empirical Orthogonal Functions (EOF) analysis and Sparse Gaussian Process models to provide accurate high-resolution predictions. Despite the promising results achieved thus far, the LSG model has not been benchmarked against other surrogate models. Such a comparison is needed to fully understand the value of the LSG model and to provide guidance for future research efforts in flood inundation simulation. This study compares the LSG model to four state-of-the-art surrogate flood inundation models. The surrogate models are assessed for their ability to simulate the temporal and spatial evolution of flood inundation for events both within and beyond the range used for model training. The models are evaluated for three distinct case studies in Australia and the United Kingdom. The LSG model is found to be superior in accuracy for both flood extent and water depth, including when applied to flood events outside the range of training data used, while achieving high computational efficiency. In addition, the low-fidelity model is found to play a crucial role in achieving the overall superior performance of the LSG model.","['Gaussian Process Learning', 'Sparse Gaussian Process models']","The research addresses the challenge of using high-resolution hydrodynamic models for flood inundation simulation, which are limited by their high computational demand that increases non-linearly with model complexity, resolution, and domain size. This limitation makes it difficult to apply such models for real-time flood predictions or for generating numerous predictions needed in probabilistic flood design. The study focuses on evaluating alternative approaches that can provide accurate flood inundation predictions with greater computational efficiency. The primary objective of the study is to compare the recently developed Low-fidelity, Spatial analysis, and Gaussian Process Learning (LSG) model against four other surrogate flood inundation models to assess their ability to simulate the temporal and spatial evolution of flood inundation for various events. The evaluation is conducted through three distinct case studies in Australia and the United Kingdom, with the aim of determining the accuracy and computational efficiency of the LSG model relative to existing methods, including its performance on flood events beyond the range of training data."
Engineering,Prompt Engineering or Fine-Tuning? A Case Study on Phishing Detection with Large Language Models,"Large Language Models (LLMs) are reshaping the landscape of Machine Learning (ML) application development. The emergence of versatile LLMs capable of undertaking a wide array of tasks has reduced the necessity for intensive human involvement in training and maintaining ML models. Despite these advancements, a pivotal question emerges: can these generalized models negate the need for task-specific models? This study addresses this question by comparing the effectiveness of LLMs in detecting phishing URLs when utilized with prompt-engineering techniques versus when fine-tuned. Notably, we explore multiple prompt-engineering strategies for phishing URL detection and apply them to two chat models, GPT-3.5-turbo and Claude 2. In this context, the maximum result achieved was an F1-score of 92.74% by using a test set of 1000 samples. Following this, we fine-tune a range of base LLMs, including GPT-2, Bloom, Baby LLaMA, and DistilGPT-2—all primarily developed for text generation—exclusively for phishing URL detection. The fine-tuning approach culminated in a peak performance, achieving an F1-score of 97.29% and an AUC of 99.56% on the same test set, thereby outperforming existing state-of-the-art methods. These results highlight that while LLMs harnessed through prompt engineering can expedite application development processes, achieving a decent performance, they are not as effective as dedicated, task-specific LLMs.",['fine-tuning'],"The research idea centers on evaluating whether generalized models can replace task-specific models in the context of detecting phishing URLs, addressing the challenge of reducing the need for intensive human involvement in developing specialized detection methods. This study investigates the effectiveness of different approaches to phishing URL detection to determine if versatile models can achieve comparable performance to those tailored specifically for this task. The primary objective of the study is to compare the performance of generalized models against task-specific models in phishing URL detection, aiming to identify which approach yields higher accuracy and reliability. The study seeks to demonstrate whether dedicated models fine-tuned for phishing URL detection can outperform more generalized approaches, thereby informing the development of more effective detection techniques."
Engineering,Artificial intelligence-based evaluation of the factors affecting the sales of an iron and steel company,"It is important to predict the sales of an iron and steel company and to identify the variables that influence these sales for future planning. The aim in this study was to identify and model the key factors that influence the sales volume of an iron and steel company using artificial neural networks (ANNs). We attempted to obtain an integrated result from the performance/sales levels of 5 models, to use the ANN approach with hybrid algorithms, and also to present an exemplary application in the base metals industry, where there is a limited number of studies. This study contributes to the literature as the first application of artificial intelligence methods in the iron and steel industry. The ANN models incorporated 6 macroeconomic variables and price-to-sales data and their results were evaluated. An ordinary least squares regression model was also used to facilitate the comparison of results, while gray relational analysis (GRA) was used to draw a comprehensive conclusion based on the ANN results. The results showed that the variables USD/TL exchange rate, product prices, and interest rates, in descending order, had the highest degree of influence in determining the sales of the iron and steel company. Furthermore, these variables are crucial for forecasting future sales and strategic planning. The study showed that the ANN outperformed classical regression models in terms of prediction accuracy. In the model applications conducted for 5 different product groups, it was observed that 3 models (models 2, 3, and 4), including model 4, which sold a higher volume of products than the total of the other products, had an overall performance above 80%. In addition, GRA was found to be a valuable tool for synthesizing insights from different ANN models based on their respective performance levels.","['artificial neural networks (ANNs)', 'ordinary least squares regression model']","The research addresses the importance of predicting sales and identifying the key variables that influence sales volume in an iron and steel company to support future planning and strategic decision-making. Understanding these influential factors is critical for the base metals industry, where limited studies exist on sales forecasting. The primary objective of the study was to identify and model the key factors affecting the sales volume of an iron and steel company by examining the impact of macroeconomic variables and price-to-sales data. The study aimed to determine which variables have the highest influence on sales and to provide insights that can be used for forecasting future sales and enhancing strategic planning within the industry."
Engineering,A machine learning approach to predict the efficiency of corrosion inhibition by natural product-based organic inhibitors,"Abstract This paper presents a quantitative structure–property relationship (QSPR)-based machine learning (ML) framework designed for predicting corrosion inhibition efficiency (CIE) values in natural organic inhibitor compounds. The modeling dataset comprises 50 natural organic compounds, with 11 quantum chemical properties (QCP) serving as input features, and the target variable being the corrosion inhibition efficiency (CIE) value. To enhance the predictive accuracy of the ML model, the kernel density estimation (KDE) function is employed to generate virtual samples during the training process, with the overarching goal of refining the precision of the ML model. Three distinct models, namely random forest (RF), gradient boosting (GB), and k-nearest neighbor (KNN), are tested in the study. The results demonstrate a noteworthy enhancement in the prediction performance of the models, attributable to the incorporation of virtual samples that effectively improve the correlation between input features and target values. Consequently, the accuracy of the predicted CIE values is significantly augmented, aligning more closely with the actual CIE values. Performance improvements were evident across all models after the incorporation of virtual samples. The GB, RF, and KNN models exhibited increments in R 2 values from 0.557 to 0.996, 0.522 to 0.999, and 0.415 to 0.994, respectively, concomitant with the introduction of 500 virtual samples. Additionally, each model demonstrated a notable reduction in RMSE values, transitioning from 1.41 to 0.19, 1.27 to 0.10, and 1.22 to 0.16, respectively. While the GB model initially outperformed others before the addition of virtual samples, the performance of the model exhibited fluctuation as the number of virtual samples varied. This behavior suggests that the KDE function provides a certain level of resilience against model variations. The proposed approach contributes to the effective design and exploration of corrosion inhibitor candidates, offering a reliable and accurate predictive tool that bridges the gap between theoretical studies and experimental synthesis.","['random forest (RF)', 'gradient boosting (GB)', 'k-nearest neighbor (KNN)']","The research addresses the challenge of accurately predicting the corrosion inhibition efficiency of natural organic compounds, which is crucial for the effective design and exploration of corrosion inhibitors. Improving the precision of corrosion inhibition efficiency values is important to bridge the gap between theoretical studies and experimental synthesis in corrosion engineering. The primary aim of the study is to enhance the accuracy of corrosion inhibition efficiency predictions for natural organic inhibitor compounds by refining the relationship between their chemical properties and inhibition performance. This objective supports the development of reliable and precise tools to aid in the selection and design of effective corrosion inhibitors."
Engineering,Cost-sensitive learning for imbalanced medical data: a review,"Abstract Integrating Machine Learning (ML) in medicine has unlocked many opportunities to harness complex medical data, enhancing patient outcomes and advancing the field. However, the inherent imbalanced distribution of medical data poses a significant challenge, resulting in biased ML models that perform poorly on minority classes. Mitigating the impact of class imbalance has prompted researchers to explore various strategies, wherein Cost-Sensitive Learning (CSL) arises as a promising approach to improve the accuracy and reliability of ML models. This paper presents the first review of CSL for imbalanced medical data. A comprehensive exploration of the existing literature encompassed papers published from January 2010 to December 2022 and sourced from five major digital libraries. A total of 173 papers were selected, analysed, and classified based on key criteria, including publication years, channels and sources, research types, empirical types, medical sub-fields, medical tasks, CSL approaches, strengths and weaknesses of CSL, frequently used datasets and data types, evaluation metrics, and development tools. The results indicate a noteworthy publication rise, particularly since 2020, and a strong preference for CSL direct approaches. Data type analysis unveiled diverse modalities, with medical images prevailing. The underutilisation of cost-related metrics and the prevalence of Python as the primary programming tool are highlighted. The strengths and weaknesses analysis covered three aspects: CSL strategy, CSL approaches, and relevant works. This study serves as a valuable resource for researchers seeking to explore the current state of research, identify strengths and gaps in the existing literature and advance CSL’s application for imbalanced medical data.","['Machine Learning (ML)', 'Cost-Sensitive Learning (CSL)']","The research idea addresses the challenge posed by the imbalanced distribution of medical data, which leads to biased outcomes and poor performance in handling minority classes within medical applications. This imbalance significantly affects the accuracy and reliability of approaches used to interpret complex medical information, thereby impacting patient outcomes and the advancement of the medical field. The study recognizes the need to explore strategies that can effectively mitigate these issues to improve the handling of imbalanced medical data. The primary objective of the study is to present a comprehensive review of cost-sensitive learning approaches applied to imbalanced medical data, analyzing a wide range of literature published between 2010 and 2022. It aims to classify and evaluate existing research based on various criteria such as medical sub-fields, tasks, strengths and weaknesses of the approaches, and data types, thereby providing a valuable resource to identify current trends, gaps, and opportunities for advancing the application of cost-sensitive strategies in this context."
Engineering,Remote sensing based forest cover classification using machine learning,"Abstract Pakistan falls significantly below the recommended forest coverage level of 20 to 30 percent of total area, with less than 6 percent of its land under forest cover. This deficiency is primarily attributed to illicit deforestation for wood and charcoal, coupled with a failure to embrace advanced techniques for forest estimation, monitoring, and supervision. Remote sensing techniques leveraging Sentinel-2 satellite images were employed. Both single-layer stacked images and temporal layer stacked images from various dates were utilized for forest classification. The application of an artificial neural network (ANN) supervised classification algorithm yielded notable results. Using a single-layer stacked image from Sentinel-2, an impressive 91.37% training overall accuracy and 0.865 kappa coefficient were achieved, along with 93.77% testing overall accuracy and a 0.902 kappa coefficient. Furthermore, the temporal layer stacked image approach demonstrated even better results. This method yielded 98.07% overall training accuracy, 97.75% overall testing accuracy, and kappa coefficients of 0.970 and 0.965, respectively. The random forest (RF) algorithm, when applied, achieved 99.12% overall training accuracy, 92.90% testing accuracy, and kappa coefficients of 0.986 and 0.882. Notably, with the temporal layer stacked image of the Sentinel-2 satellite, the RF algorithm reached exceptional performance with 99.79% training accuracy, 96.98% validation accuracy, and kappa coefficients of 0.996 and 0.954. In terms of forest cover estimation, the ANN algorithm identified 31.07% total forest coverage in the District Abbottabad region. In comparison, the RF algorithm recorded a slightly higher 31.17% of the total forested area. This research highlights the potential of advanced remote sensing techniques and machine learning algorithms in improving forest cover assessment and monitoring strategies.","['artificial neural network (ANN) supervised classification algorithm', 'random forest (RF) algorithm']","The study addresses the critical issue of Pakistan's forest coverage being significantly below the recommended level of 20 to 30 percent, with less than 6 percent of land currently under forest cover. This shortfall is mainly due to illegal deforestation for wood and charcoal, as well as inadequate adoption of advanced methods for forest estimation, monitoring, and supervision. The primary aim of the research is to improve the assessment and monitoring of forest cover in Pakistan, specifically in the District Abbottabad region, by employing advanced remote sensing techniques to achieve more accurate forest classification and coverage estimation. The study seeks to provide enhanced strategies for forest cover evaluation to support better management and conservation efforts."
Engineering,Explainability and Interpretability in Electric Load Forecasting Using Machine Learning Techniques – A Review,"Electric Load Forecasting (ELF) is the central instrument for planning and controlling demand response programs, electricity trading, and consumption optimization. Due to the increasing automation of these processes, meaningful and transparent forecasts become more and more important. Still, at the same time, the complexity of the used machine learning models and architectures increases. Because there is an increasing interest in interpretable and explainable load forecasting methods, this work conducts a literature review to present already applied approaches regarding explainability and interpretability for load forecasts using Machine Learning. Based on extensive literature research covering eight publication portals, recurring modeling approaches, trends, and modeling techniques are identified and clustered by properties to achieve more interpretable and explainable load forecasts. The results on interpretability show an increase in the use of probabilistic models, methods for time series decomposition and the use of fuzzy logic in addition to classically interpretable models. Dominant explainable approaches are Feature Importance and Attention mechanisms. The discussion shows that a lot of knowledge from the related field of time series forecasting still needs to be adapted to the problems in ELF. Compared to other applications of explainable and interpretable methods such as clustering, there are currently relatively few research results, but with an increasing trend.","['probabilistic models', 'Attention mechanisms']","The research idea addresses the critical role of electric load forecasting in planning and controlling demand response programs, electricity trading, and consumption optimization, emphasizing the growing need for meaningful and transparent forecasts amid increasing automation. The study highlights the challenge posed by the rising complexity of forecasting approaches and the corresponding demand for more interpretable and explainable methods in this engineering context. The primary objective of the study is to review existing approaches related to interpretability and explainability in electric load forecasting by examining and clustering recurring methods and trends found in the literature. This aims to provide insights into how current techniques can be adapted and improved to enhance the transparency and understanding of load forecasts in engineering applications."
Engineering,A Deep Learning-Based CAE Approach for Simulating 3D Vehicle Wheels Under Real-World Conditions,"The implementation of deep learning (DL) in computer-aided engineering (CAE) can significantly improve the accuracy and efficiency of simulating 3D vehicle wheels under real-world conditions. While traditional CAE methods can be time-consuming and computationally expensive, DL can reduce simulation time and development cycles across all industries. This work explores the role of DL and AI in virtual manufacturing and CAE and investigates how they can be used to improve the accuracy and efficiency of simulations for 3D vehicle wheels. Deep learning models can learn the complex relationships between different wheel design parameters, such as tire load distribution, stress distribution, and fatigue life. Once trained, these models can be embedded into CAE software, allowing for faster and more accurate simulations of wheel performance. This interdisciplinary study uses various deep learning techniques, including convolutional neural networks (CNNs), generative adversarial networks (GANs), and recurrent neural networks (RNNs), to create a more efficient and accurate relationship between CAD modeling and CAE simulation. The research aims to leverage the potential of deep learning models to automate 3D CAD design, accurately predict CAE results, and provide in-depth explanations and verifications. The benefits of this research are expected to extend to the automotive industry's pursuit of more robust and resilient wheel designs. By streamlining the product development process from conceptual design to engineering performance evaluation, this study has the potential to revolutionize the automotive industry's product development cycle.","['deep learning (DL)', 'convolutional neural networks (CNNs)', 'generative adversarial networks (GANs)', 'recurrent neural networks (RNNs)']","The research addresses the challenge of improving the accuracy and efficiency of simulating 3D vehicle wheels under real-world conditions, noting that traditional engineering methods for such simulations are often time-consuming and resource-intensive. The motivation lies in enhancing the simulation process to better capture complex relationships among wheel design parameters like tire load distribution, stress distribution, and fatigue life, ultimately supporting the development of more robust and resilient wheel designs. The primary objective of the study is to improve the simulation accuracy and efficiency for 3D vehicle wheels by establishing a more effective connection between computer-aided design and engineering performance evaluation. This aims to streamline the product development process in the automotive industry, from conceptual design through to engineering assessment, thereby accelerating development cycles and enhancing wheel performance evaluation."
Engineering,A new intelligently optimized model reference adaptive controller using GA and WOA-based MPPT techniques for photovoltaic systems,"Recently, the integration of renewable energy sources, specifically photovoltaic (PV) systems, into power networks has grown in significance for sustainable energy generation. Researchers have investigated different control algorithms for maximum power point tracking (MPPT) to enhance the efficiency of PV systems. This article presents an innovative method to address the problem of maximum power point tracking in photovoltaic systems amidst swiftly changing weather conditions. MPPT techniques supply maximum power to the load during irradiance fluctuations and ambient temperatures. A novel optimal model reference adaptive controller is developed and designed based on the MIT rule to seek global maximum power without ripples rapidly. The suggested controller is also optimized through two popular meta-heuristic algorithms: The genetic algorithm (GA) and the whale optimization algorithm (WOA). These meta-heuristic approaches have been exploited to overcome the difficulty of selecting the adaptation gain of the MRAC controller. The reference voltage for MPPT is generated in the study through an adaptive neuro-fuzzy inference system. The suggested controller's performance is tested via MATLAB/Simulink software under varying temperature and radiation circumstances. Simulation is carried out using a Soltech 1sth-215-p module coupled to a boost converter, which powers a resistive load. Furthermore, to emphasize the recommended algorithm's performance, a comparative study was done between the optimal MRAC using GA and WOA and the conventional incremental conductance (INC) method.","['genetic algorithm (GA)', 'whale optimization algorithm (WOA)', 'adaptive neuro-fuzzy inference system']","The integration of photovoltaic (PV) systems into power networks has become increasingly important for sustainable energy generation, particularly due to the challenges posed by rapidly changing weather conditions such as fluctuations in irradiance and ambient temperature. Ensuring that PV systems can consistently supply maximum power to the load under these varying environmental factors is a critical issue in enhancing their overall efficiency and reliability. This study aims to develop an effective approach for maximum power point tracking (MPPT) in photovoltaic systems that can quickly and accurately respond to changes in weather conditions to maintain optimal power output. The primary objective is to design and optimize a controller that can achieve global maximum power extraction without ripples, improving performance compared to conventional methods under different temperature and radiation scenarios."
Engineering,Optimizing landslide susceptibility mapping using machine learning and geospatial techniques,"Landslides present a substantial risk to human lives, the environment, and infrastructure. Consequently, it is crucial to highlight the regions prone to future landslides by examining the correlation between past landslides and various geo-environmental factors. This study aims to investigate the optimal data selection and machine learning model, or ensemble technique, for evaluating the vulnerability of areas to landslides and determining the most accurate approach. To attain our objectives, we considered two different scenarios for selecting landslide-free random points (a slope threshold and a buffer-based approach) and performed a comparative analysis of five machine learning models for landslide susceptibility mapping, namely: Support Vector Machine (SVM), Logistic Regression (LR), Linear Discriminant Analysis (LDA), Random Forest (RF), and Extreme Gradient Boosting (XGBoost). The study area for this research is an area in Polk County in Western North Carolina that has experienced fatal landslides, leading to casualties and significant damage to infrastructure, properties, and road networks. The model construction process involves the utilization of a dataset comprising 1215 historical landslide occurrences and 1215 non-landslide points. We integrated a total of fourteen geospatial data layers, consisting of topographic variables, soil data, geological data, and land cover attributes. We use various metrics to assess the models' performance, including accuracy, F1-score, Kappa score, and AUC-ROC. In addition, we used the seeded-cell area index (SCAI) to evaluate map consistency. The ensemble of the five models using Weighted Average produces outstanding results, with an AUC-ROC of 99.4% for the slope threshold scenario and 91.8% for the buffer-based scenario. Our findings emphasize the significant impact of non-landslide random sampling on model performance in landslide susceptibility mapping. Furthermore, by optimally identifying landslide-prone regions and hotspots that need urgent risk management and land use planning, our study demonstrates the effectiveness of machine learning models in analyzing landslide susceptibility and providing valuable insights for informed decision-making and disaster risk reduction initiatives.","['Support Vector Machine (SVM)', 'Logistic Regression (LR)', 'Linear Discriminant Analysis (LDA)', 'Random Forest (RF)', 'Extreme Gradient Boosting (XGBoost)', 'ensemble technique using Weighted Average']","Landslides pose a significant threat to human lives, the environment, and infrastructure, making it essential to identify regions susceptible to future landslides by examining the relationship between past landslide occurrences and various geo-environmental factors. Understanding these vulnerable areas is critical for effective risk management and land use planning to prevent casualties and damage. The primary objective of this study is to evaluate different approaches for selecting landslide-free locations and to determine the most accurate method for assessing landslide susceptibility in a region of Polk County, Western North Carolina, which has experienced fatal landslides. The study aims to identify landslide-prone regions and hotspots that require urgent attention for disaster risk reduction and informed decision-making."
Engineering,Assessment of technical water quality in mining based on machine learning methods,"Introduction. Mining requires water treatment and wastewater processing, abstraction and discharge during mining increases consumption several times. Since water consumption in mining and processing is usually associated with domestic, industrial and technical needs, the need for water supply systems required for water treatment increases. Water from different sources can be used for treatment: incoming water, process and reused water, and wastewater. But the water obtained from any of the sources must meet all the norms and requirements. Water quality is determined by physical, chemical and bacteriological properties. The main directions for improving water consumption by mining enterprises are to reduce the consumption of drinking water from rivers, lakes and municipal water supply, as well as to expand the use of mine and quarry water for domestic and technical needs. Materials and methods. As training data for training the neural network, a dataset that includes water quality data obtained from fresh water sources was selected for the methods work, and using machine learning, develops a model that predicts whether the water is suitable for technical use in mines. This dataset includes 2293 values (samples) as well as 9 attributes. Correlation, neural network, and decision tree methods were used to build the models in this study. Results. Various machine learning methods (neural network and decision trees) were used to build a predictive model to assess the quality of water that would be suitable for use in the mining industry for technical purposes. With the help of the built models were processed data obtained from public sources, when analyzing which it was found that the method of decision trees was more accurate. The constructed model, for determining dependencies, thus, has high accuracy (small error). To increase the practical significance of the study, a number of transformations of the initial data set were carried out, in particular, an experiment with the division of attributes into groups of importance, in relation to the data, taking into account the subject area. The results obtained made it clear that checking only for hazardous impurities does not guarantee the suitability of water, but almost completely excludes (low significance factor) samples with impurities that do not meet the requirements, and the model can have practical significance. Allocation of the group for rapid quality determination, showed that for the express test, in an emergency situation or under time constraints, the possibility of practical use of the obtained model, has a justification, due to the small error. In general, the conducted experiments have shown that when taking into account the costs (total) for data collection, it makes sense to use models, taking into account the reduction of collected data, on the parameters (factors) of technical water. Discussion. In general, on the basis of the conducted research, we can talk about the successful application of machine learning methods in determining the suitability of technical water in the mining industry. During the experiments, the decision tree method performed particularly well, with the lowest error values. In addition, further work can be carried out to reduce the error in the models, in particular, by possibly increasing the number of attributes, as well as more fine-tuning of the applied machine learning methods. Conclusions. The authors conclude that machine learning techniques can be successfully integrated to determine the quality and suitability of process water in the mining industry in today’s world. Resume. The paper compares machine learning methods such as decision trees and neural network method. The comparative analysis of these methods and their quality of information processing is shown on the example of a set of data on water quality in the mining industry. With the help of built models were processed data obtained from open sources, when analyzing which it was found that the method of decision trees was more accurate. The constructed model for determining dependencies has high accuracy (small error). Suggestions for practical applications and future research directions. This study can form the basis for research in this or related fields to conduct further studies on the reliability and accuracy of using machine learning to predict the quality of water used in the mining industry. Continued work in the above direction may be the rationale for wider use of the above methods to improve various meaningful production performance in this or related areas.","['neural network', 'decision tree']","The research addresses the significant challenge of managing water consumption and ensuring water quality in the mining industry, where water is required for domestic, industrial, and technical purposes. Mining activities increase water consumption substantially, and there is a critical need to reduce the use of drinking water from natural and municipal sources by expanding the use of mine and quarry water while meeting all physical, chemical, and bacteriological quality standards. The study focuses on improving water consumption practices by identifying suitable water sources for technical use in mining operations. The primary objective of the study is to develop a reliable approach to assess the suitability of water from various sources for technical use in mining, ensuring that it meets all necessary quality norms and requirements. This includes evaluating water quality parameters to determine whether water can be safely and effectively used for mining processes, with an emphasis on practical application for rapid and accurate water quality determination in operational settings."
Engineering,Machine learning prediction of mechanical properties in metal additive manufacturing,"Predicting mechanical properties in metal additive manufacturing (MAM) is essential for ensuring the performance and reliability of printed parts, as well as their suitability for specific applications. However, conducting experiments to estimate mechanical properties in MAM processes can be laborious and expensive, and they are often limited to specific materials and processes. Machine learning (ML) methods offer a more flexible and cost-effective approach to predicting mechanical properties based on processing parameters and material properties. In this study, we introduce a comprehensive framework for benchmarking ML models for predicting mechanical properties. We compiled an extensive experimental dataset from over 90 MAM articles and data sheets from a diverse range of sources, encompassing 140 different MAM data sheets. This dataset includes information on MAM processing conditions, machines, materials, and resulting mechanical properties such as yield strength, ultimate tensile strength, elastic modulus, elongation, hardness, and surface roughness. Our framework incorporates physics-aware featurization specific to MAM, adjustable ML models, and tailored evaluation metrics to construct a comprehensive learning framework for predicting mechanical properties. Additionally, we explore the Explainable AI method, specifically SHAP analysis, to elucidate and interpret the predicted values of ML models for mechanical properties. Furthermore, data-driven explicit models were developed to estimate mechanical properties based on processing parameters and material properties, offering enhanced interpretability compared to conventional ML models.",['SHAP analysis'],"The research addresses the challenge of predicting mechanical properties in metal additive manufacturing (MAM), which is crucial for ensuring the performance, reliability, and application suitability of printed parts. Experimental methods to estimate these properties are often labor-intensive, costly, and limited to specific materials and processes, creating a need for more efficient approaches. The primary aim of the study is to develop a comprehensive framework for predicting mechanical properties in MAM by compiling an extensive experimental dataset from diverse sources and incorporating relevant processing conditions, machines, materials, and resulting mechanical properties. This framework seeks to provide a thorough basis for estimating key mechanical characteristics such as yield strength, tensile strength, elastic modulus, elongation, hardness, and surface roughness based on processing parameters and material properties."
Engineering,Charging management of electric vehicles with the presence of renewable resources,"Considering the increasing use of electric vehicles, the establishment of charging stations to exchange power between the grid and electric devices, and the integration of charging stations with solar power generation sources, the optimal use of electric vehicle charging stations in the power system. The purpose of cost reduction in the presence of the intelligent environment is a challenge that must be investigated so that this platform is suitable for predicting the behaviour of vehicles and, as a result, optimizing their presence in the power network. This research presents a relatively complete radial distribution network development planning model in two scenarios. In the first scenario, the effects of electric vehicles are not considered, and only the effects of distributed production (renewable and dispatchable) are considered. Studies have been done on a sample 54-bus network, a common system in most Distribution expansion planning (DEP) articles for distribution networks. In addition, the real data of American highways have been used to create raw input data. Also, due to the distance limit, the information on vehicles under 100 miles has been received as electric vehicle information. The clustering method and Capiola multivariate probability distribution functions have created suitable vehicle scenarios during different planning years. Capiola's method increases the accuracy of vehicle load forecasting according to a predetermined growth rate. The DEP problem in this research is modeled as an optimization problem based on scenario, dynamic, and in 5 one-year time frames (5-year time horizon and one-year accuracy). The results indicate that, in the presence of electric vehicles and distributed production sources, the technical characteristics of the network are improved. Similarly, the use of DGs, in addition to reducing the cost of equipment, has reduced undistributed energy in the system. But 10,000 vehicles, which have been applied to the network as an uncontrolled load, have caused an increase in undistributed energy. The cost of equipment required for the network development is almost as much as 5%.",['clustering method'],"The research idea addresses the growing integration of electric vehicles and solar power generation into the power distribution network, focusing on the challenges of optimally utilizing electric vehicle charging stations within the power system to reduce costs and improve network performance. With the increasing presence of electric vehicles, there is a need to understand their impact on the distribution network and how to effectively plan for their integration alongside distributed energy resources. The primary objective of the study is to develop a comprehensive planning model for radial distribution network expansion over a five-year horizon, considering scenarios both with and without the effects of electric vehicles and distributed generation sources. This model aims to evaluate the technical and economic impacts of electric vehicles and distributed production on the network, ultimately improving network characteristics and reducing equipment costs and energy losses."
Engineering,Machine learning for the management of biochar yield and properties of biomass sources for sustainable energy,"Abstract Biochar is emerging as a potential solution for biomass conversion to meet the ever increasing demand for sustainable energy. Efficient management systems are needed in order to exploit fully the potential of biochar. Modern machine learning (ML) techniques, and in particular ensemble approaches and explainable AI methods, are valuable for forecasting the properties and efficiency of biochar properly. Machine‐learning‐based forecasts, optimization, and feature selection are critical for improving biomass management techniques. In this research, we explore the influences of these techniques on the accurate forecasting of biochar yield and properties for a range of biomass sources. We emphasize the importance of the interpretability of a model, as this improves human comprehension and trust in ML predictions. Sensitivity analysis is shown to be an effective technique for finding crucial biomass characteristics that influence the synthesis of biochar. Precision prognostics have far‐reaching ramifications, influencing industries such as biomass logistics, conversion technologies, and the successful use of biomass as renewable energy. These advances can make a substantial contribution to a greener future and can encourage the development of a circular biobased economy. This work emphasizes the importance of using sophisticated data‐driven methodologies such as ML in biochar synthesis, to usher in ecologically friendly energy solutions. These breakthroughs hold the key to a more sustainable and environmentally friendly future.","['ensemble approaches', 'feature selection']","The research addresses the growing need for sustainable energy solutions through the conversion of biomass into biochar, highlighting the importance of efficient management systems to fully exploit biochar's potential. It recognizes the critical role of accurately forecasting biochar yield and properties from various biomass sources to improve biomass management techniques and support industries such as biomass logistics and conversion technologies. The primary aim of the study is to explore factors influencing the accurate prediction of biochar yield and properties across different biomass types, with a focus on identifying key biomass characteristics that affect biochar synthesis. This objective seeks to enhance the effective use of biomass as a renewable energy source, contributing to the development of a greener and more circular biobased economy."
Engineering,Effective lung nodule detection using deep CNN with dual attention mechanisms,"Abstract Novel methods are required to enhance lung cancer detection, which has overtaken other cancer-related causes of death as the major cause of cancer-related mortality. Radiologists have long-standing methods for locating lung nodules in patients with lung cancer, such as computed tomography (CT) scans. Radiologists must manually review a significant amount of CT scan pictures, which makes the process time-consuming and prone to human error. Computer-aided diagnosis (CAD) systems have been created to help radiologists with their evaluations in order to overcome these difficulties. These systems make use of cutting-edge deep learning architectures. These CAD systems are designed to improve lung nodule diagnosis efficiency and accuracy. In this study, a bespoke convolutional neural network (CNN) with a dual attention mechanism was created, which was especially crafted to concentrate on the most important elements in images of lung nodules. The CNN model extracts informative features from the images, while the attention module incorporates both channel attention and spatial attention mechanisms to selectively highlight significant features. After the attention module, global average pooling is applied to summarize the spatial information. To evaluate the performance of the proposed model, extensive experiments were conducted using benchmark dataset of lung nodules. The results of these experiments demonstrated that our model surpasses recent models and achieves state-of-the-art accuracy in lung nodule detection and classification tasks.","['convolutional neural network (CNN)', 'dual attention mechanism', 'channel attention', 'spatial attention', 'global average pooling']","The research addresses the critical need for improved methods to enhance lung cancer detection, given that lung cancer has become the leading cause of cancer-related mortality. Traditional approaches require radiologists to manually review numerous computed tomography (CT) scan images, a process that is both time-consuming and susceptible to human error. The study focuses on overcoming these challenges to increase the efficiency and accuracy of identifying lung nodules in patients. The primary objective of the study is to develop a specialized approach that concentrates on the most important features within lung nodule images to improve diagnosis. This approach aims to extract informative characteristics from CT scans and emphasize significant elements to facilitate more accurate lung nodule detection and classification, ultimately enhancing diagnostic performance."
Engineering,Transfer learning with graph neural networks for improved molecular property prediction in the multi-fidelity setting,"Abstract We investigate the potential of graph neural networks for transfer learning and improving molecular property prediction on sparse and expensive to acquire high-fidelity data by leveraging low-fidelity measurements as an inexpensive proxy for a targeted property of interest. This problem arises in discovery processes that rely on screening funnels for trading off the overall costs against throughput and accuracy. Typically, individual stages in these processes are loosely connected and each one generates data at different scale and fidelity. We consider this setup holistically and demonstrate empirically that existing transfer learning techniques for graph neural networks are generally unable to harness the information from multi-fidelity cascades. Here, we propose several effective transfer learning strategies and study them in transductive and inductive settings. Our analysis involves a collection of more than 28 million unique experimental protein-ligand interactions across 37 targets from drug discovery by high-throughput screening and 12 quantum properties from the dataset QMugs. The results indicate that transfer learning can improve the performance on sparse tasks by up to eight times while using an order of magnitude less high-fidelity training data. Moreover, the proposed methods consistently outperform existing transfer learning strategies for graph-structured data on drug discovery and quantum mechanics datasets.","['graph neural networks', 'transfer learning', 'transfer learning strategies']","The research addresses the challenge of improving molecular property prediction when high-fidelity data is sparse and costly to obtain, by utilizing low-fidelity measurements as a more accessible proxy. This issue is significant in discovery processes that involve screening funnels, where there is a need to balance overall costs with throughput and accuracy, and where different stages produce data at varying scales and fidelities. The primary aim of the study is to explore strategies that enhance the transfer of information across multiple fidelity levels in molecular property prediction tasks. The objective is to improve prediction performance on sparse high-fidelity data by effectively leveraging low-fidelity measurements, thereby reducing the amount of expensive data required while maintaining or increasing accuracy in applications such as drug discovery and quantum property evaluation."
Engineering,Optimal design of steel exoskeleton for the retrofitting of RC buildings via genetic algorithm,"In recent decades, steel exoskeletons have gathered significant attention as a seismic retrofitting technique for existing structures. The design methods proposed so far are focused on the identification of the system's overall parameters through simplified models. Although these methodologies provide helpful guidance at the preliminary design stage, they do not consider aspects such as the distribution of the exoskeletons and sizing of their components. To overcome these limitations, an optimization process based on the Genetic Algorithm is proposed in this paper to identify the optimal exoskeleton number and spatial arrangement, and to determine the optimal size of their constituent elements. The algorithm aims to minimize the weight of the retrofit solution while keeping the whole existing structure in the elastic field and ensuring the structural verification of the exoskeleton's elements. The analyses have been conducted using a finite-element code with an Open Application Programming Interface, which allows the models to be handled through automatic routines. The proposed optimization tool has been applied to several case studies, considering two different layouts for the exoskeletons. Finally, the effectiveness of the retrofit method has been demonstrated, and the proposed optimization tool has been able to significantly reduce the weight and cost of the intervention.",['Genetic Algorithm'],"The research idea addresses the limitations of current design methods for steel exoskeletons used in seismic retrofitting of existing structures, which primarily rely on simplified models focusing on overall system parameters. These existing methodologies do not adequately consider the distribution and sizing of exoskeleton components, which are critical for effective retrofitting. The study aims to overcome these shortcomings by identifying optimal configurations that improve the retrofit design. The primary objective of the study is to determine the optimal number, spatial arrangement, and sizing of steel exoskeleton elements to minimize the weight of the retrofit solution while ensuring that the existing structure remains within the elastic range and that the exoskeleton components meet structural verification requirements. The research seeks to demonstrate the effectiveness of this optimized retrofit approach through application to various case studies, ultimately reducing the weight and cost of seismic interventions."
Engineering,Transformer-based Generative Adversarial Networks in Computer Vision: A Comprehensive Survey,"Generative Adversarial Networks (GANs) have been very successful for synthesizing the images in a given dataset. The artificially generated images by GANs are very realistic. The GANs have shown potential usability in several computer vision applications, including image generation, image-to-image translation, video synthesis, etc. Conventionally, the generator network is the backbone of GANs, which generates the samples and the discriminator network is used to facilitate the training of the generator network. The generator and discriminator networks are usually a Convolutional Neural Network (CNN). The convolution-based networks exploit the local relationship in a layer, which requires the deep networks to extract the abstract features. However, recently developed Transformer networks are able to exploit the global relationship with tremendous performance improvement for several problems in computer vision. Motivated from the success of Transformer networks and GANs, recent works have tried to exploit the Transformers in GAN framework for the image/video synthesis. This paper presents a comprehensive survey on the developments and advancements in GANs utilizing the Transformer networks for computer vision applications. The performance comparison for several applications on benchmark datasets is also performed and analyzed. The conducted survey will be very useful to understand the research trends & gaps related with Transformer-based GANs and to develop the advanced GAN architectures by exploiting the global and local relationships for different applications.","['Generative Adversarial Networks (GANs)', 'Convolutional Neural Network (CNN)', 'Transformer networks']","The research idea addresses the challenge of improving the synthesis of realistic images and videos by exploring new approaches that can better capture both local and global relationships within visual data. Traditional methods rely heavily on local feature extraction, which often requires deep structures to achieve abstract representations, while recent advancements suggest that incorporating global relationships can significantly enhance performance in image and video generation tasks. This study is motivated by the need to understand and advance the techniques that combine these aspects to improve the quality and applicability of synthesized visual content. The primary objective of the study is to provide a comprehensive survey of recent developments and advancements in image and video synthesis techniques that integrate global and local relationship exploitation. It aims to analyze and compare the performance of these approaches across various benchmark applications, identify current research trends and gaps, and support the development of improved architectures for generating realistic visual content in engineering applications."
Engineering,A new integrated intelligent computing paradigm for predicting joints shear strength,"Joints shear strength is a critical parameter during the design and construction of geotechnical engineering structures. The prevailing models mostly adopt the form of empirical functions, employing mathematical regression techniques to represent experimental data. As an alternative approach, this paper proposes a new integrated intelligent computing paradigm that aims to predict joints shear strength. Five metaheuristic optimization algorithms, including the chameleon swarm algorithm (CSA), slime mold algorithm, transient search optimization algorithm, equilibrium optimizer and social network search algorithm, were employed to enhance the performance of the multilayered perception (MLP) model. Efficiency comparisons were conducted between the proposed CSA-MLP model and twelve classical models, employing statistical indicators such as root mean square error (RMSE), correlation coefficient (R2), mean absolute error (MAE), and variance accounted for (VAF) to evaluate the performance of each model. The sensitivity analysis of parameters that impact joints shear strength was conducted. Finally, the feasibility and limitations of this study were discussed. The results revealed that, in comparison to other models, the CSA-MLP model exhibited the most appropriate performance in terms of R2 (0.88), RMSE (0.19), MAE (0.15), and VAF (90.32%) values. The result of sensitivity analysis showed that the normal stress and the joint roughness coefficient were the most critical factors influencing joints shear strength. This paper presented an efficacious attempt toward swift prediction of joints shear strength, thus avoiding the need for costly in-site and laboratory tests.","['slime mold algorithm', 'equilibrium optimizer']","The research addresses the critical importance of accurately determining joints shear strength in the design and construction of geotechnical engineering structures, highlighting the limitations of prevailing empirical models that rely on mathematical regression to represent experimental data. The study is motivated by the need for a more effective approach to predict joints shear strength, which is essential for ensuring structural stability and safety while potentially reducing the reliance on expensive and time-consuming in-site and laboratory testing. The primary objective of the study is to develop and evaluate a new approach for predicting joints shear strength that improves prediction accuracy compared to existing models. Additionally, the study aims to identify the key parameters influencing joints shear strength, with a focus on enhancing the understanding of factors such as normal stress and joint roughness coefficient that critically affect shear strength outcomes."
Engineering,"A Comprehensive Review on the Role of Artificial Intelligence in Power System Stability, Control, and Protection: Insights and Future Directions","This review comprehensively examines the burgeoning field of intelligent techniques to enhance power systems’ stability, control, and protection. As global energy demands increase and renewable energy sources become more integrated, maintaining the stability and reliability of both conventional power systems and smart grids is crucial. Traditional methods are increasingly insufficient for handling today’s power grids’ complex, dynamic nature. This paper discusses the adoption of advanced intelligence methods, including artificial intelligence (AI), deep learning (DL), machine learning (ML), metaheuristic optimization algorithms, and other AI techniques such as fuzzy logic, reinforcement learning, and model predictive control to address these challenges. It underscores the critical importance of power system stability and the new challenges of integrating diverse energy sources. The paper reviews various intelligent methods used in power system analysis, emphasizing their roles in predictive maintenance, fault detection, real-time control, and monitoring. It details extensive research on the capabilities of AI and ML algorithms to enhance the precision and efficiency of protection systems, showing their effectiveness in accurately identifying and resolving faults. Additionally, it explores the potential of fuzzy logic in decision-making under uncertainty, reinforcement learning for dynamic stability control, and the integration of IoT and big data analytics for real-time system monitoring and optimization. Case studies from the literature are presented, offering valuable insights into practical applications. The review concludes by identifying current limitations and suggesting areas for future research, highlighting the need for more robust, flexible, and scalable intelligent systems in the power sector. This paper is a valuable resource for researchers, engineers, and policymakers, providing a detailed understanding of the current and future potential of intelligent techniques in power system stability, control, and protection.","['deep learning (DL)', 'machine learning (ML)', 'reinforcement learning']","The research idea centers on addressing the increasing challenges in maintaining the stability, control, and protection of power systems amid rising global energy demands and the growing integration of renewable energy sources. Traditional methods are becoming inadequate for managing the complex and dynamic nature of modern power grids, including both conventional systems and smart grids. Ensuring the reliability and stability of these evolving power systems is critical due to the diverse energy sources and operational complexities involved. The research objective is to comprehensively examine and evaluate advanced approaches aimed at enhancing power system stability, control, and protection. The study aims to provide a detailed understanding of various techniques that improve fault detection, real-time control, monitoring, and decision-making under uncertainty, thereby contributing to more robust and efficient power system operations."
Engineering,Application of ANFIS approach for prediction of performance measures in wire electric discharge machining of SAE 1010,"Due to its exceptional quality, SAE 1010 is highly recommended for automotive applications, particularly in the manufacturing of headed fasteners and bolts. The primary application of this technology is in automobiles, while it also holds significant potential for various other technological disciplines. Utilizing alternative techniques for removing material has proven to be essential in overcoming numerous machining challenges that were previously difficult to solve. It possesses numerous practical applications in aircraft engineering and exhibits significant potential for implementation in other technical domains. Manufacturing complicated curved components using traditional machining methods might provide challenges. In order to prevent such issues, a wide range of cutting-edge machining methods have been developed. Wire Electrical Discharge Machining (WEDM) is a variance of Electrical Discharge Machining (EDM) that is suitable for this particular use. This study employs Taguchi's technique to examine the Wire Electrical Discharge Machining (WEDM) of SAE 1010 steel from an environmentally friendly viewpoint by employing a natural dielectric fluid in order to minimize its ecological footprint. This study aims to optimize the process variable and develop a hybrid predictive model based on grey approach for foretelling the necessary performance measures by considering various performance metrics, including material removal rate, surface roughness, and tolerance errors. The significance of process variables has been determined with the help of Analysis of variance (ANOVA) and it is inferred that pulse on duration is the most contributing factor for all the desired performance measures. A hybrid technique was used by an artificial intelligence technology to project the selected output measure. The outcomes on performance of the evolved ANFIS model shows the prediction capability of the model developed with least errors (MAPE – 0.0417, RMSE − 0.00023, MAE – 0.000419, Correlation coefficient 0.9997). The outcomes of the analysis indicate that the model is both efficient and accurate in its predictions, could be valuable to the manufacturer since it establishes targets for important performance indicators.","['hybrid predictive model based on grey approach', 'ANFIS model']","The research addresses the challenges associated with machining SAE 1010 steel, a material highly valued in automotive and aircraft engineering for manufacturing components such as headed fasteners and bolts. Traditional machining methods face difficulties when producing complex curved components, necessitating alternative material removal techniques to overcome these issues. The study focuses on improving the machining process of SAE 1010 steel to enhance performance while considering environmental impacts by using a natural dielectric fluid. The primary objective of the study is to optimize the machining process variables to improve key performance measures, including material removal rate, surface roughness, and tolerance errors, thereby providing valuable insights for manufacturers to achieve better machining outcomes with reduced ecological footprint."
Engineering,A domain adaptation approach to damage classification with an application to bridge monitoring,"Data-driven machine-learning algorithms generally suffer from a lack of labelled health-state data, mainly those referring to damage conditions. To address such an issue, population-based structural health monitoring seeks to enrich the original dataset by transferring knowledge from a population of monitored structures. Within this context, this paper presents a transfer learning approach, based on domain adaptation, to leverage information from completely-labelled bridge structure data to accurately predict new instances of an unknown target domain. Since intrinsic structural differences may cause distribution shifts, domain adaptation attempts to minimise the distance between the domains and to learn a mapping within a shared feature space. Specifically, the methodology involves the long-term acquisition of natural frequencies from several structural scenarios. Such damage-sensitive features are then aligned via domain adaptation so that a machine-learning algorithm can effectively utilise the labelled source domain data and generalise well to the unlabelled target-domain data. The described procedure is applied to two case studies, including the Z24 and the S101 benchmark bridges and their finite element models, respectively. The results demonstrate the successful exchange of health-state labels to identify the damage class within a population of bridges equipped with SHM systems, showing potential to reduce computational efforts and to deal with scarce or poor data sets in application to bridge network monitoring.","['transfer learning', 'domain adaptation']","The research addresses the challenge of limited availability of labeled health-state data related to damage conditions in structural health monitoring, particularly for bridge structures. This scarcity hinders effective assessment and identification of damage within individual structures. The study aims to enhance the monitoring process by utilizing information from a population of monitored bridges to improve damage detection in new, unlabelled structures. Specifically, the objective is to accurately identify damage classes in bridges by leveraging long-term measurements of natural frequencies from various structural scenarios, thereby enabling the exchange of health-state information across different bridge structures and improving the reliability of bridge network monitoring despite limited data."
Engineering,Enhancing photovoltaic parameter estimation: integration of non-linear hunting and reinforcement learning strategies with golden jackal optimizer,"Abstract The advancement of Photovoltaic (PV) systems hinges on the precise optimization of their parameters. Among the numerous optimization techniques, the effectiveness of each often rests on their inherent parameters. This research introduces a new methodology, the Reinforcement Learning-based Golden Jackal Optimizer (RL-GJO). This approach uniquely combines reinforcement learning with the Golden Jackal Optimizer to enhance its efficiency and adaptability in handling various optimization problems. Furthermore, the research incorporates an advanced non-linear hunting strategy to optimize the algorithm’s performance. The proposed algorithm is first validated using 29 CEC2017 benchmark test functions and five engineering-constrained design problems. Secondly, rigorous testing on PV parameter estimation benchmark datasets, including the single-diode model, double-diode model, three-diode model, and a representative PV module, was carried out to highlight the superiority of RL-GJO. The results were compelling: the root mean square error values achieved by RL-GJO were markedly lower than those of the original algorithm and other prevalent optimization methods. The synergy between reinforcement learning and GJO in this approach facilitates faster convergence and improved solution quality. This integration not only improves the performance metrics but also ensures a more efficient optimization process, especially in complex PV scenarios. With an average Freidman’s rank test values of 1.564 for numerical and engineering design problems and 1.742 for parameter estimation problems, the proposed RL-GJO is performing better than the original GJO and other peers. The proposed RL-GJO stands out as a reliable tool for PV parameter estimation. By seamlessly combining reinforcement learning with the golden jackal optimizer, it sets a new benchmark in PV optimization, indicating a promising avenue for future research and applications.",['Reinforcement Learning'],"The research addresses the critical need for precise optimization of parameters in Photovoltaic (PV) systems, which is essential for advancing their performance and efficiency. It highlights the challenge that the effectiveness of optimization techniques depends heavily on their inherent parameters, particularly in complex PV scenarios. The study aims to enhance the optimization process for PV parameter estimation by introducing a novel approach that improves efficiency and adaptability in handling various optimization problems. The primary objective is to validate this new approach through rigorous testing on benchmark functions and engineering-constrained design problems, as well as on PV parameter estimation datasets, to demonstrate its superior accuracy and reliability compared to existing methods."
Engineering,Machine learning assisted prediction of solar to liquid fuel production: a case study,"In this era of heightened environmental awareness, the global community faces the critical challenge of climate change. Renewable energy (RE) emerges as a vital contender to mitigate global warming and meet increasing energy needs. Nonetheless, the fluctuating nature of renewable energy sources underscores the necessity for efficient conversion and storage strategies. This pioneering research focuses on the transformation of solar energy (SE) into liquid fuels, with a specific emphasis on formic acid (FA) as a case study, done in Binh Thuan, Vietnam. The paper unveils a technology designed to convert solar energy into formic acid, ensuring its stability and storage at ambient conditions. It involves detailed simulations to quantify the daily and monthly electricity output from photovoltaic (PV) systems and the corresponding mass of formic acid producible through solar energy. The simulation of a dual-axis solar tracking system for the PV panels, intended to maximize solar energy capture, is one of the project's illustrations. The elevation and azimuth angles, which are two essential tracking system parameters, are extensively studied in the present research. The project makes use of machine learning algorithms in the field of predictive modeling, specifically Artificial Neural Networks (ANN) and Support Vector Machines (SVM). These tools play a crucial role in modeling PV power output and formic acid production while accounting for a variety of influencing factors. A comparative study shows that SVM outperforms ANN in accurately predicting the production of FA and PV power generation, both of which are the major goals. This model is a predictive tool that can be used to forecast these goals based on certain causal variables. Overall, it is observed that the maximum power produced with 2-axis solar tracker was achieved in February as 2355 kW resulting in the highest formic acid production of 2.25 ×106 grams. The study's broad ramifications demonstrate solar liquid fuel technology's potential as a long-term fix in the field of renewable energy. In addition to advancing the field of renewable energy storage, the study represents a major step toward tackling the global challenge of climate change.","['Artificial Neural Networks (ANN)', 'Support Vector Machines (SVM)']","The research addresses the critical challenge of climate change by focusing on renewable energy as a key solution to reduce global warming and meet growing energy demands. It highlights the fluctuating nature of renewable energy sources, emphasizing the need for effective conversion and storage methods to ensure energy stability. Specifically, the study explores the transformation of solar energy into liquid fuels, using formic acid as a case study, to provide a stable and storable energy carrier under ambient conditions. The research aims to quantify the potential daily and monthly production of formic acid derived from solar energy captured by photovoltaic systems equipped with dual-axis solar tracking. The primary objective is to evaluate the performance of solar energy conversion into formic acid, maximizing energy capture through optimized tracking parameters, and demonstrating the feasibility of solar liquid fuel technology as a sustainable and long-term solution in renewable energy storage to address climate change."
Engineering,Statistical Machine Learning for Power Flow Analysis Considering the Influence of Weather Factors on Photovoltaic Power Generation,"It is generally accepted that the impact of weather variation is gradually increasing in modern distribution networks with the integration of high-proportion photovoltaic (PV) power generation and weather-sensitive loads. This article analyzes power flow using a novel stochastic weather generator (SWG) based on statistical machine learning (SML). The proposed SML model, which incorporates generative adversarial networks (GANs), probability theory, and information theory, enables the generation and evaluation of simulated hourly weather data throughout the year. The GAN model captures various weather variation characteristics, including weather uncertainties, diurnal variations, and seasonal patterns. Compared to shallow learning models, the proposed deep learning model exhibits significant advantages in stochastic weather simulation. The simulated data generated by the proposed model closely resemble real data in terms of time-series regularity, integrity, and stochasticity. The SWG is applied to model PV power generation and weather-sensitive loads. Then, we actively conduct a power flow analysis (PFA) on a real distribution network in Guangdong, China, using simulated data for an entire year. The results provide evidence that the GAN-based SWG surpasses the shallow machine learning approach in terms of accuracy. The proposed model ensures accurate analysis of weather-related power flow and provides valuable insights for the analysis, planning, and design of distribution networks.","['statistical machine learning (SML)', 'generative adversarial networks (GANs)', 'shallow learning models', 'deep learning model']","The study addresses the increasing impact of weather variation on modern distribution networks, particularly due to the integration of high proportions of photovoltaic power generation and weather-sensitive loads. This growing influence of weather fluctuations poses challenges for accurately assessing power flow within these networks. The primary aim of the study is to enable accurate analysis of weather-related power flow by generating and evaluating simulated hourly weather data throughout the year. This objective supports improved analysis, planning, and design of distribution networks by providing reliable information on the effects of weather variations on power flow."
Engineering,Short-term wind speed forecasting using an optimized three-phase convolutional neural network fused with bidirectional long short-term memory network model,"Wind energy is an environment friendly, low-carbon, and cost-effective renewable energy source. It is, however, difficult to integrate wind energy into a mixed energy grid due to its high volatility and intermittency. For wind energy conversion systems to be reliable and efficient, accurate wind speed (WS) forecasting is fundamental. This study cascades a convolutional neural network (CNN) with a bidirectional long short-term memory (BiLSTM) in order to obtain a model for hourly WS forecasting by utilizing several meteorological variables as model inputs to study their effects on predicted WS. For input selection, the mutation grey wolf optimizer (TMGWO) is used. For efficient optimization of CBiLSTM hyperparameters, a hybrid Bayesian Optimization and HyperBand (BOHB) algorithm is used. The combined usage of TMGWO, BOHB, and CBiLSTM leads to a three-phase hybrid model (i.e., 3P-CBiLSTM). The performance of 3P-CBiLSTM is benchmarked against the standalone and hybrid BiLSTMs, LSTMs, gradient boosting (GBRs), random forest (RFRs), and decision tree regressors (DTRs). The statistical analysis of forecasted WS reveals that the 3P-CBiLSTM is highly effective over the other benchmark forecasting methods. This objective model also registers the highest percentage of forecasted errors (≈ 53.4 – 81.8%) within the smallest error range ≤ |0.25| ms−1 amongst all tested study sites. Despite the remarkable results achieved, the CBiLSTM model cannot be generally understood, so the eXplainable Artificial Intelligence (xAI) technique was used for explaining local and global model outputs, based on Local Interpretable Model-Agnostic Explanations (LIME) and SHapley Additive exPlanations (SHAP). Both of the xAI methods determined that the antecedent WS is the most significant predictor of the short-term WS forecasting. Therefore, we aver that the proposed model can be employed to help wind farm operators in making quality decisions in maximizing wind power integration into the grid with reduced intermittency.","['convolutional neural network (CNN)', 'bidirectional long short-term memory (BiLSTM)', 'mutation grey wolf optimizer (TMGWO)', 'hybrid Bayesian Optimization and HyperBand (BOHB) algorithm', 'long short-term memory (LSTM)', 'gradient boosting regressors (GBRs)', 'random forest regressors (RFRs)', 'decision tree regressors (DTRs)', 'Local Interpretable Model-Agnostic Explanations (LIME)', 'SHapley Additive exPlanations (SHAP)']","The research idea addresses the challenge of integrating wind energy into mixed energy grids due to its high volatility and intermittency, emphasizing the need for accurate wind speed forecasting to ensure the reliability and efficiency of wind energy conversion systems. The study recognizes that precise short-term wind speed predictions are fundamental for maximizing wind power integration while minimizing fluctuations. The primary objective of the study is to develop an effective approach for hourly wind speed forecasting by utilizing various meteorological variables to understand their impact on predicted wind speed. This aims to support wind farm operators in making informed decisions to enhance wind power integration into the grid with reduced intermittency."
Engineering,Geographically weighted machine learning for modeling spatial heterogeneity in traffic crash frequency and determinants in US,"Spatial analyses of traffic crashes have drawn much interest due to the nature of the spatial dependence and spatial heterogeneity in the crash data. This study makes the best of Geographically Weighted Random Forest (GW-RF) model to explore the local associations between crash frequency and various influencing factors in the US, including road network attributes, socio-economic characteristics, and land use factors collected from multiple data sources. Special emphasis is put on modeling the spatial heterogeneity in the effects of a factor on crash frequency in different geographical areas in a data-driven way. The GW-RF model outperforms global models (e.g. Random Forest) and conventional geographically weighted regression, demonstrating superior predictive accuracy and elucidating spatial variations. The GW-RF model reveals spatial distinctions in the effects of certain factors on crash frequency. For example, the importance of intersection density varies significantly across regions, with high significance in the southern and northeastern areas. Low-grade road density emerges as influential in specific cities. The findings highlight the significance of different factors in influencing crash frequency across zones. Road network factors, particularly intersection density, exhibit high importance universally, while socioeconomic variables demonstrate moderate effects. Interestingly, land use variables show relatively lower importance. The outcomes could help to allocate resources and implement tailored interventions to reduce the likelihood of crashes.","['Geographically Weighted Random Forest (GW-RF)', 'Random Forest']","The research idea addresses the spatial dependence and heterogeneity present in traffic crash data, emphasizing the need to understand how various factors such as road network attributes, socio-economic characteristics, and land use influence crash frequency differently across geographical areas in the US. This study is motivated by the importance of capturing local variations in the effects of these factors to better comprehend the spatial distinctions in crash occurrences. The primary objective of the study is to explore the local associations between crash frequency and multiple influencing factors, with a focus on modeling the spatial heterogeneity in their effects across different regions. The study aims to identify the varying significance of factors like intersection density and road density in different areas to support targeted resource allocation and interventions for reducing crash likelihood."
Engineering,"Hybrid physics-machine learning models for predicting rate of penetration in the Halahatang oil field, Tarim Basin","Abstract Rate of penetration (ROP) is a key factor in drilling optimization, cost reduction and drilling cycle shortening. Due to the systematicity, complexity and uncertainty of drilling operations, however, it has always been a problem to establish a highly accurate and interpretable ROP prediction model to guide and optimize drilling operations. To solve this problem in the Tarim Basin, this study proposes four categories of hybrid physics-machine learning (ML) methods for modeling. One of which is residual modeling, in which an ML model learns to predict errors or residuals, via a physical model; the second is integrated coupling, in which the output of the physical model is used as an input to the ML model; the third is simple average, in which predictions from both the physical model and the ML model are combined; and the last is bootstrap aggregating (bagging), which follows the idea of ensemble learning to combine different physical models’ advantages. A total of 5655 real data points from the Halahatang oil field were used to test the performance of the various models. The results showed that the residual modeling model, with an R 2 of 0.9936, had the best performance, followed by the simple average model and bagging with R 2 values of 0.9394 and 0.5998, respectively. From the view of prediction accuracy, and model interpretability, the hybrid physics-ML model with residual modeling is the optimal method for ROP prediction.","['residual modeling', 'bootstrap aggregating (bagging)']","The research idea centers on the challenge of accurately predicting the rate of penetration (ROP) during drilling operations, which is crucial for optimizing drilling performance, reducing costs, and shortening the drilling cycle. Due to the complexity, systematic nature, and uncertainty inherent in drilling processes, establishing a highly accurate and interpretable ROP prediction approach has been a persistent problem, particularly in the Tarim Basin. The primary objective of the study is to develop and evaluate different hybrid modeling approaches that combine physical understanding with other methods to improve the accuracy and interpretability of ROP predictions. The study aims to identify the most effective approach for guiding and optimizing drilling operations by testing these methods with real data from the Halahatang oil field."
Engineering,Simulation-based multi-objective genetic optimization for promoting energy efficiency and thermal comfort in existing buildings of hot climate,"This study conducts a detailed analysis to improve to enhance the energy performance of residential buildings in UAE through various retrofit measures. The applied methodology involved developing a calibrated building energy model for a two-story residential building, followed by a parametric analysis of six design variables, including wall and roof insulation, glazing, infiltration rate, window shading, and setpoint and setback temperatures to evaluate their impact on annual energy consumption. Additionally, a sensitivity analysis was conducted to assess the importance of the investigated design variables on building energy use. An optimization approach using the non-dominated sorting genetic algorithm (NSGA-II) was then implemented to optimize energy consumption while minimizing discomfort conditions. The key findings from the parametric simulations show significant energy savings: a 38.8 % reduction from improved wall insulation (achieving a U-value of 0.14 W/m2K), a 2.3 % decrease with better roof insulation, a 9.8 % saving from using triple clear glass glazing, a 9.6 % reduction by lowering the infiltration rate to 2.5 m³/h.m2, 7.5 % savings from window shading, and a 25.7 % decrease by optimizing cooling setpoints. A sensitivity analysis highlighted the dominant impact of wall insulation and cooling setpoint temperatures on energy usage. Followed by the cooling setpoint temperature. The subsequent NSGA-II optimization yielded 106 Pareto optimal solutions from 1897 iterations, offering a balance between reducing energy consumption (10,942 to 20,250 kWh/year, averaging 60 % savings) and minimizing discomfort hours (296–1230 h). These results provide actionable insights for stakeholders in the retrofitting process, emphasizing the significant energy-saving potential of specific retrofit measures.",['non-dominated sorting genetic algorithm (NSGA-II)'],"The research idea focuses on addressing the challenge of improving the energy performance of residential buildings in the UAE by exploring various retrofit measures. The study is motivated by the need to reduce annual energy consumption in buildings through enhancements in building components such as insulation, glazing, infiltration rates, window shading, and temperature settings. The research objective is to evaluate the impact of different design variables on energy use in a two-story residential building and to identify retrofit strategies that significantly reduce energy consumption while maintaining occupant comfort. The study aims to provide practical insights into effective retrofit measures that can achieve substantial energy savings in residential buildings."
Engineering,A comprehensive review of critical analysis of biodegradable waste PCM for thermal energy storage systems using machine learning and deep learning to predict dynamic behavior,"This article explores the use of phase change materials (PCMs) derived from waste, in energy storage systems. It emphasizes the potential of these PCMs in addressing concerns related to fossil fuel usage and environmental impact. This article also highlights the aspects of these PCMs including reduced reliance on renewable resources minimized greenhouse gas emissions and waste reduction. The study also discusses approaches such as integrating nanotechnology to enhance thermal conductivity and utilizing machine learning and deep learning techniques for predicting dynamic behavior. The article provides an overall view of research on biodegradable waste-based PCMs and how they can play a promising role in achieving energy-efficient and sustainable thermal storage systems. However, specific conclusions drawn from the presented results are not explicitly outlined, leaving room, for investigation and exploration in this evolving field. Artificial neural network (ANN) predictive models for thermal energy storage devices perform differently. With a 4% adjusted mean absolute error, the Gaussian radial basis function kernel Support Vector Regression (SVR) model captured heat-related charging and discharging issues. The ANN model predicted finned tube heat and heat flux better than the numerical model. SVM models outperformed ANN and ANFIS in some datasets. Material property predictions favored gradient boosting, but Linear Regression and SVR models performed better, emphasizing application- and dataset-specific model selection. These predictive models provide insights into the complex thermal performance of building structures, aiding in the design and operation of energy-efficient systems. Biodegradable waste-based PCMs' sustainability includes carbon footprint, waste reduction, biodegradability, and circular economy alignment. Nanotechnology, machine learning, and deep learning improve thermal conductivity and prediction. Circular economy principles include waste reduction and carbon footprint reduction. Specific results-based conclusions are not stated. Presenting a comprehensive overview of current research highlights biodegradable waste-based PCMs' potential for energy-efficient and sustainable thermal storage systems.","['machine learning', 'deep learning', 'Artificial neural network (ANN)', 'Gaussian radial basis function kernel Support Vector Regression (SVR)', 'ANN model', 'SVM models', 'ANFIS', 'gradient boosting', 'Linear Regression']","The research idea centers on exploring phase change materials (PCMs) derived from biodegradable waste as a sustainable solution for energy storage systems, addressing environmental concerns related to fossil fuel consumption and greenhouse gas emissions. These waste-based PCMs offer potential benefits such as reduced reliance on non-renewable resources, minimized carbon footprint, and alignment with circular economy principles through waste reduction and biodegradability. The study aims to provide a comprehensive overview of the current research on biodegradable waste-based PCMs and their role in enhancing energy efficiency and sustainability in thermal storage applications. The primary objective is to investigate the potential of these PCMs in achieving energy-efficient and sustainable thermal storage systems, emphasizing their environmental advantages and contribution to reducing the impact of traditional energy storage methods."
Engineering,Enhancing Skin Cancer Diagnosis Using Swin Transformer with Hybrid Shifted Window-Based Multi-head Self-attention and SwiGLU-Based MLP,"Abstract Skin cancer is one of the most frequently occurring cancers worldwide, and early detection is crucial for effective treatment. Dermatologists often face challenges such as heavy data demands, potential human errors, and strict time limits, which can negatively affect diagnostic outcomes. Deep learning–based diagnostic systems offer quick, accurate testing and enhanced research capabilities, providing significant support to dermatologists. In this study, we enhanced the Swin Transformer architecture by implementing the hybrid shifted window-based multi-head self-attention (HSW-MSA) in place of the conventional shifted window-based multi-head self-attention (SW-MSA). This adjustment enables the model to more efficiently process areas of skin cancer overlap, capture finer details, and manage long-range dependencies, while maintaining memory usage and computational efficiency during training. Additionally, the study replaces the standard multi-layer perceptron (MLP) in the Swin Transformer with a SwiGLU-based MLP, an upgraded version of the gated linear unit (GLU) module, to achieve higher accuracy, faster training speeds, and better parameter efficiency. The modified Swin model-base was evaluated using the publicly accessible ISIC 2019 skin dataset with eight classes and was compared against popular convolutional neural networks (CNNs) and cutting-edge vision transformer (ViT) models. In an exhaustive assessment on the unseen test dataset, the proposed Swin-Base model demonstrated exceptional performance, achieving an accuracy of 89.36%, a recall of 85.13%, a precision of 88.22%, and an F1-score of 86.65%, surpassing all previously reported research and deep learning models documented in the literature.","['Swin Transformer architecture', 'shifted window-based multi-head self-attention (SW-MSA)', 'multi-layer perceptron (MLP)', 'SwiGLU-based MLP', 'gated linear unit (GLU) module', 'convolutional neural networks (CNNs)', 'vision transformer (ViT) models']","The research addresses the critical challenge of early and accurate detection of skin cancer, which is essential for effective treatment but is hindered by limitations such as heavy workload, potential human errors, and time constraints faced by dermatologists. Improving diagnostic accuracy and efficiency in identifying various types of skin cancer remains a significant concern in the medical engineering field. The primary objective of the study is to enhance the capability of diagnostic approaches for skin cancer by refining the processing of overlapping skin cancer regions and capturing finer details to improve detection accuracy. This is achieved by modifying existing techniques to better manage complex skin cancer characteristics while maintaining efficiency, ultimately aiming to provide more reliable and precise diagnostic outcomes."
Engineering,Sustainable electric discharge machining using alumina-mixed deionized water as dielectric: Process modelling by artificial neural networks underpinning net-zero from industry,"The requirement for materials possessing both high strength and low density has garnered significant attention from industries and researchers in recent times. Among these materials, aluminum 6061 (Al6061) exhibits the desired properties. However, due to its diverse machining capabilities, powder-mixed electric discharge machining (PMEDM) has emerged as a viable option for cutting such materials. This method has been criticized for its high energy consumption and limited cutting efficiency. Furthermore, conventional dielectric (kerosene) employed in EDM has drastic environmental and operator's health concerns. To address the abovementioned issues, deionized water has been employed in this study which enhances the reusability of resources and minimizes the cost of the dielectric. Herein, to make the process sustainable, and to keep the environment free from hazardous fumes, generated during the machining process, deionized water has been used. In addition to that, to uplift the machining responses, alumina (Al2O3) nano-powder has been engaged. To conduct the study, response surface methodology (RSM) was employed. This investigation aimed to analyze the impact on the material removal rate (MRR), surface roughness (SR), and specific energy consumption (SEC) by using microscopy analysis, scanning electron microscopy (SEM), 3D surfaces profilometry, energy dispersive x-ray (EDX) analysis and after that, the machining responses are modelled using the artificial neural networks (ANN) technique. It was observed that by utilizing non-dominated sorting genetic algorithms (NSGA-II) an improvement of 87.42 % in MRR, 3.4 % better surface finish and 0.7 % better SEC have been obtained. Notably, CO2 emissions were found to be 94.27 % lower by using the deionized water as dielectric compared to those produced by kerosene oil.","['artificial neural networks (ANN)', 'non-dominated sorting genetic algorithms (NSGA-II)']","The research idea centers on the need for materials that combine high strength with low density, with aluminum 6061 being a prominent example due to its favorable properties. However, conventional machining methods for such materials face challenges including high energy consumption, limited cutting efficiency, and environmental and health concerns associated with the use of kerosene as a dielectric fluid. To address these issues, the study explores the use of deionized water as an alternative dielectric to enhance sustainability, reduce hazardous emissions, and lower costs. Additionally, the incorporation of alumina nano-powder aims to improve machining performance while maintaining environmental safety.

The primary objective of the study is to investigate the effects of using deionized water as a dielectric fluid, combined with alumina nano-powder, on key machining responses such as material removal rate, surface roughness, and specific energy consumption during the machining of aluminum 6061. The study seeks to demonstrate improvements in machining efficiency and surface quality while significantly reducing CO2 emissions compared to traditional kerosene-based processes. Ultimately, the research aims to develop a more sustainable and environmentally friendly machining approach for aluminum 6061."
Engineering,A Novel Fuzzy Neural Network Architecture Search Framework for Defect Recognition With Uncertainties,"Defect recognition is an important task in intelligent manufacturing. Due to the subjectivity of human annotation, the collected defect data usually contains a lot of noise and unpredictable uncertainties, which have a great negative influence on defect recognition. It is a significant challenge to discover an effective defect recognition model with satisfactory uncertainty processing ability. A natural way is to automatically search for an efficient deep model, which can be realized by neural architecture search (NAS). To achieve this, we propose an efficient fuzzy NAS framework for defect recognition, where the searched architecture can effectively handle uncertain information from the given datasets. Specifically, we first design a fuzzy search space and the related encoding strategy for fuzzy NAS. Then, we propose a comparator-based evolutionary search approach, where an online end-to-end comparator is learned to directly determine the selection of candidate architectures from the evolutionary population. The comparator works in an end-to-end way and it transforms the complex ranking problem of evaluating architectures into a simple classification task, which overcomes the rank disorder issue suffered from traditional performance predictors. A series of experimental results demonstrate that the architecture with fewer #Params (1.22 M) search by fuzzy neural architecture search framework for defect recognition method achieves higher accuracy (92.26%) compared to the state-of-the-art results (i.e., DARTS-PV) on the ELPV dataset, as well as competitive results (accuracy = 76.4%, #Params = 1.04 M) on the CODEBRIM dataset. Experimental results show the effectiveness and efficiency of our proposed method in handling uncertain problems.",['neural architecture search (NAS)'],"The research idea addresses the challenge of defect recognition in intelligent manufacturing, where the presence of noise and unpredictable uncertainties in defect data due to subjective human annotation negatively impacts the accuracy of defect identification. Effectively managing these uncertainties is crucial for improving defect recognition performance. The primary objective of the study is to develop an approach that can effectively handle uncertain information in defect datasets to enhance the accuracy and reliability of defect recognition. The study aims to achieve this by designing a framework that improves the processing of uncertain data, thereby advancing the capability to accurately identify defects in manufacturing contexts."
Engineering,Machinability investigation of natural fibers reinforced polymer matrix composite under drilling: Leveraging machine learning in bioengineering applications,"The growing demand for fiber-reinforced polymer (FRP) in industrial applications has prompted the exploration of natural fiber-based composites as a viable alternative to synthetic fibers. Using jute–rattan fiber-reinforced composite offers the potential for environmentally sustainable waste material decomposition and cost reduction compared to conventional fiber materials. This article focuses on the impact of different machining constraints on surface roughness and delamination during the drilling process of the jute–rattan FRP composite. Inspired by this unexplored research area, this article emphasizes the influence of various machining constraints on surface roughness and delamination in drilling jute–rattan FRP composite. Response surface methodology designs the experiment using drill bit material, spindle speed, and feed rate as input variables to measure surface roughness and delamination factors. The technique of order of preference by similarity to the ideal solution method is used to optimize the machining parameters, and for predicting surface roughness and delamination, two machine learning-based models named random forest (RF) and support vector machine (SVM) are utilized. To evaluate the accuracy of the predicted values, the correlation coefficient (R2), mean absolute percentage error, and mean squared error were used. RF performed better in comparison with SVM, with a higher value of R2 for both testing and training datasets, which is 0.997, 0.981, and 0.985 for surface roughness, entry delamination, and exit delamination, respectively. Hence, this study presents an innovative methodology for predicting surface roughness and delamination through machine learning techniques.","['random forest (RF)', 'support vector machine (SVM)']","The growing demand for fiber-reinforced polymer (FRP) in industrial applications has prompted the exploration of natural fiber-based composites as a viable alternative to synthetic fibers. Using jute–rattan fiber-reinforced composite offers the potential for environmentally sustainable waste material decomposition and cost reduction compared to conventional fiber materials. This study addresses the need to understand how different machining constraints affect surface roughness and delamination during the drilling process of jute–rattan FRP composites. The primary objective of the study is to investigate the influence of various machining parameters, such as drill bit material, spindle speed, and feed rate, on surface roughness and delamination factors in drilling jute–rattan FRP composites, aiming to optimize these parameters to improve machining quality."
Engineering,AISClean: AIS data-driven vessel trajectory reconstruction under uncertain conditions,"In maritime transportation, intelligent vessel surveillance has become increasingly prevalent and widespread by collecting and analyzing high massive spatial data from automatic identification system (AIS). The state-of-the-art AIS devices contain various functionalities, such as position transmission, tracking navigation, etc. Widely equipped shipboard AIS devices provide a large amount of real-time and historical vessel trajectory data for maritime management. However, the original AIS data often suffers from unwanted noise (i.e., poorly tracked timestamped points for vessel trajectories) and missing (i.e., no data is received or transmitted for a long term) data during signal acquisition, transmission, and analog-to-digital conversion. This degradation in data quality poses significant risks, including potential miscalculations in vessel collision avoidance systems, inaccuracies in emission calculations, and challenges in port management. In this work, a data-driven vessel trajectory reconstruction framework considering historical features is proposed to enhance the reliability of vessel trajectory. Specifically, a series of statistical methods are proposed to identify noisy data and missing data. Then, a model combining Geohash and dynamic time warping algorithms is developed to restore the trajectories degraded by random noise and missing data in vessel trajectories. Comparative experiments with baseline methods on multiple datasets verify the effectiveness of the proposed data-driven model.",['dynamic time warping'],"The research addresses the challenge of degraded vessel trajectory data quality in maritime transportation caused by noise and missing information during signal acquisition and transmission. This degradation poses significant risks such as errors in vessel collision avoidance, inaccuracies in emission calculations, and difficulties in port management. The study aims to enhance the reliability of vessel trajectory information by reconstructing trajectories that have been compromised by noise and missing data. The primary objective is to develop a framework that identifies and restores degraded vessel trajectory data to improve maritime management and safety."
Engineering,Eco-friendly mix design of slag-ash-based geopolymer concrete using explainable deep learning,"Geopolymer concrete is a sustainable and eco-friendly substitute for traditional OPC (Ordinary Portland Cement) based concrete, as it reduces greenhouse gas emissions. With various supplementary cementitious materials, the compressive strength of geopolymer concrete should be accurately predicted. Recent studies have applied deep learning techniques to predict the compressive strength of geopolymer concrete yet its hidden decision-making criteria diminish the end-users' trust in predictions. To bridge this gap, the authors first developed three deep learning models: an artificial neural network (ANN), a deep neural network (DNN), and a 1D convolution neural network (CNN) to predict the compressive strength of slag ash-based geopolymer concrete. The performance indices for accuracy revealed that the DNN model outperforms the other two models. Subsequently, Shapley additive explanations (SHAP) were used to explain the best-performed deep learning model, DNN, and its compressive strength predictions. SHAP exhibited how the importance of each feature and its relationship contributes to the compressive strength prediction of the DNN model. Finally, the authors developed a novel DNN-based open-source software interface to predict the mix design proportions for a given target compressive strength (using inverse modeling technique) for slag ash-based geopolymer concrete. Additionally, the software calculates the Global Warming Potential (kg CO2 equivalent) for each mix design to select the mix designs with low greenhouse emissions.","['artificial neural network (ANN)', 'deep neural network (DNN)', '1D convolution neural network (CNN)', 'Shapley additive explanations (SHAP)']","The research addresses the need for sustainable and eco-friendly alternatives to traditional Ordinary Portland Cement (OPC) based concrete by focusing on geopolymer concrete, which reduces greenhouse gas emissions. Accurately predicting the compressive strength of geopolymer concrete made with various supplementary cementitious materials is essential for its effective application. The primary aim of the study is to develop a reliable approach to predict the compressive strength of slag ash-based geopolymer concrete and to provide a means to determine appropriate mix design proportions for achieving a target compressive strength. Additionally, the study seeks to evaluate the environmental impact of different mix designs by calculating their associated greenhouse gas emissions, thereby facilitating the selection of more sustainable concrete mixtures."
Engineering,Metal–Organic Framework Stability in Water and Harsh Environments from Data-Driven Models Trained on the Diverse WS24 Data Set,"Metal-organic frameworks (MOFs) are porous materials with applications in gas separations and catalysis, but a lack of water stability often limits their practical use given the ubiquity of water. Consequently, it is useful to predict whether a MOF is water-stable before investing time and resources into synthesis. Existing heuristics for designing water-stable MOFs lack generality and limit the diversity of explored chemistry due to narrowly defined criteria. Machine learning (ML) models offer the promise to improve the generality of predictions but require data. In an improvement on previous efforts, we enlarge the available training data for MOF water stability prediction by over 400%, adding 911 MOFs with water stability labels assigned through semiautomated manuscript analysis to curate the new data set WS24. The additional data are shown to improve ML model performance (test ROC-AUC > 0.8) over diverse chemistry for the prediction of both water stability and stability in harsher acidic conditions. We illustrate how the expanded data set and models can be used with a previously developed activation stability model in combination with genetic algorithms to quickly screen ∼10,000 MOFs from a space of hundreds of thousands for candidates with multivariate stability (upon activation, in water, and in acid). We uncover metal- and geometry-specific design rules for robust MOFs. The data set and ML models developed in this work, which we disseminate through an easy-to-use web interface, are expected to contribute toward the accelerated discovery of novel, water-stable MOFs for applications such as direct air gas capture and water treatment.",['genetic algorithms'],"The research addresses the challenge of water instability in metal-organic frameworks (MOFs), which limits their practical applications in gas separations and catalysis due to the widespread presence of water. Existing design guidelines for water-stable MOFs are not sufficiently general, restricting the exploration of diverse chemical compositions. The primary aim of the study is to enhance the prediction of MOF water stability by significantly expanding the available data set with additional MOFs labeled for water stability, thereby improving the ability to identify candidates that maintain stability under various conditions, including activation, water exposure, and acidic environments. This work seeks to uncover specific design principles related to metal types and geometries that contribute to robust MOFs, ultimately facilitating the accelerated discovery of novel water-stable materials for engineering applications such as direct air gas capture and water treatment."
Engineering,Deep learning approaches for visual faults diagnosis of photovoltaic systems: State-of-the-Art review,"PV systems are prone to external environmental conditions that affect PV system operations. Visual inspection of the impacts of faults on PV system is considered a better practice rather than onsite fault detection mechanisms. Faults such as hotspot, dark area, cracks, glass break, wavy lines, snail tracks, corrosion, discoloration, junction box failure and delamination faults have different visual symptoms. EL technology, infrared thermography, and photoluminescence approaches are used to extract and visualize the impact of faults on PV modules. DL based algorithms such as, CNN, ANN, RNN, AE, DBN, TL and hybrid algorithms have shown promising results in domain of visual PV fault detection. This article critically overviews working mechanism of DL algorithms in terms of their limitations, complexity, interpretability, training dataset requirements and capability to work with another DL algorithms. This research article also reviews, critically analyzes, and systematically presents different clustering algorithms based on their clustering mechanism, distance metrics, convergence criteria. Additionally, their performance is also evaluated in terms of DI, CHI, DBI, S-score, and homogeneity. Moreover, this research work explicitly identifies and explains the limitations and contributions of recent and older techniques employed for features extraction, data preprocessing, and decision making by performing SWOT analysis. This research work also recommends future research directions for industry and academia.","['CNN', 'ANN', 'RNN', 'AE', 'clustering algorithms']","The research addresses the challenge of identifying and understanding the impacts of various faults on photovoltaic (PV) systems caused by external environmental conditions, which affect their operation and efficiency. Visual inspection is emphasized as a preferred approach for detecting faults such as hotspots, cracks, corrosion, and delamination, each exhibiting distinct visual symptoms that influence PV module performance. The primary objective of the study is to critically review and analyze existing methods used to visualize and detect faults in PV modules, focusing on their mechanisms, limitations, and effectiveness. Additionally, the research aims to evaluate different clustering approaches for fault characterization and to identify the strengths and weaknesses of current techniques, ultimately providing recommendations for future advancements in the field."
Engineering,Metaheuristic optimization algorithms-based prediction modeling for titanium dioxide-Assisted photocatalytic degradation of air contaminants,"Airborne contaminants pose significant environmental and health challenges. Titanium dioxide (TiO2) has emerged as a leading photocatalyst in the degradation of air contaminants compared to other photocatalysts due to its inherent inertness, cost-effectiveness, and photostability. To assess its effectiveness, laboratory examinations are frequently employed to measure the photocatalytic degradation rate of TiO2. However, this approach involves time-consuming requirements, labor-intensive tasks, and high costs. In literature, ensemble or standalone models are commonly used for assessing the performance of TiO2 photocatalytic degradation of water and air contaminants. Nonetheless, the application of metaheuristic hybrid models has the potential to be more effective in predictive accuracy and efficiency. Accordingly, this research utilized hybrid machine learning (ML) algorithms to estimate the photo-degradation rate constants of organic air pollutants using TiO2 nanoparticles and exposure to ultraviolet light. Six metaheuristics optimization algorithms, namely, nuclear reaction optimization (NRO), differential evolution algorithm (DEA), human felicity algorithm (HFA), lightning search algorithm (LSA), Harris hawks algorithm (HHA), and tunicate swarm algorithm (TSA) were combined with random forest (RF) technique to establish the hybrid models. A database of 200 data points was acquired from experimental studies for model training and testing. Furthermore, multiple statistical indicators and 10-fold cross-validation were employed to examine the established hybrid model's accuracy and robustness. The TSA-RF model demonstrated superior prediction accuracy among the six suggested models, achieving an impressive correlation (R) of 0.90 and a lower root mean square error (RMSE) of 0.25. In contrast, the HFA-RF, HHA-RF, and NRO-RF models exhibited a slightly lower R-value of 0.88, with RMSE scores of 0.32. The DEA-RF and LSA-RF models, while effective, showed a marginally lower R-value of 0.85, with RMSE values of 0.45 and 0.44, respectively. Moreover, the SHapley Additive exPlanation (SHAP) results indicated that the degradation rates of air contaminants through photocatalysis were most notably influenced by factors such as the reactor sizes, photocatalyst dosage, humidity, and intensity.","['random forest (RF)', 'differential evolution algorithm (DEA)', 'Harris hawks algorithm (HHA)', 'SHapley Additive exPlanation (SHAP)']","The research addresses the significant environmental and health challenges posed by airborne contaminants and focuses on the use of titanium dioxide (TiO2) as a photocatalyst for degrading these contaminants due to its inertness, cost-effectiveness, and photostability. Traditional laboratory methods for assessing the photocatalytic degradation rate of TiO2 are time-consuming, labor-intensive, and costly, highlighting the need for more efficient approaches. The primary aim of the study is to estimate the photo-degradation rate constants of organic air pollutants using TiO2 nanoparticles under ultraviolet light exposure. This objective seeks to improve the understanding of factors influencing the degradation rates, such as reactor size, photocatalyst dosage, humidity, and light intensity, to enhance the effectiveness of TiO2 in air contaminant removal."
Engineering,Artificial intelligence alphafold model for molecular biology and drug discovery: a machine-learning-driven informatics investigation,"AlphaFold model has reshaped biological research. However, vast unstructured data in the entire AlphaFold field requires further analysis to fully understand the current research landscape and guide future exploration. Thus, this scientometric analysis aimed to identify critical research clusters, track emerging trends, and highlight underexplored areas in this field by utilizing machine-learning-driven informatics methods. Quantitative statistical analysis reveals that the AlphaFold field is enjoying an astonishing development trend (Annual Growth Rate = 180.13%) and global collaboration (International Co-authorship = 33.33%). Unsupervised clustering algorithm, time series tracking, and global impact assessment point out that Cluster 3 (Artificial Intelligence-Powered Advancements in AlphaFold for Structural Biology) has the greatest influence (Average Citation = 48.36 ± 184.98). Additionally, regression curve and hotspot burst analysis highlight ""structure prediction"" (s = 12.40, R2 = 0.9480, p = 0.0051), ""artificial intelligence"" (s = 5.00, R2 = 0.8096, p = 0.0375), ""drug discovery"" (s = 1.90, R2 = 0.7987, p = 0.0409), and ""molecular dynamics"" (s = 2.40, R2 = 0.8000, p = 0.0405) as core hotspots driving the research frontier. More importantly, the Walktrap algorithm further reveals that ""structure prediction, artificial intelligence, molecular dynamics"" (Relevance Percentage[RP] = 100%, Development Percentage[DP] = 25.0%), ""sars-cov-2, covid-19, vaccine design"" (RP = 97.8%, DP = 37.5%), and ""homology modeling, virtual screening, membrane protein"" (RP = 89.9%, DP = 26.1%) are closely intertwined with the AlphaFold model but remain underexplored, which implies a broad exploration space. In conclusion, through the machine-learning-driven informatics methods, this scientometric analysis offers an objective and comprehensive overview of global AlphaFold research, identifying critical research clusters and hotspots while prospectively pointing out underexplored critical areas.",['unsupervised clustering algorithm'],"The research addresses the challenge of managing and understanding the vast and unstructured body of research related to the AlphaFold model within the field of structural biology. There is a need to comprehensively map the current research landscape to identify key areas of focus, emerging trends, and gaps that require further exploration. The primary objective of the study is to provide an objective and comprehensive overview of global research on AlphaFold by identifying critical research clusters, tracking emerging trends, and highlighting underexplored areas that could guide future investigations in this domain. This aims to facilitate a clearer understanding of the development and impact of AlphaFold-related research in structural biology and related applications."
Engineering,Hybrid KNN-SVM machine learning approach for solar power forecasting,"Predictions about solar power will have a significant impact on large-scale renewable energy plants. Photovoltaic (PV) power generation forecasting is particularly sensitive to measuring the uncertainty in weather conditions. Although several conventional techniques like long short-term memory (LSTM), support vector machine (SVM), etc. are available, but due to some restrictions, their application is limited. To enhance the precision of forecasting solar power from solar farms, a hybrid machine learning model that includes blends of the K-Nearest Neighbor (KNN) machine learning technique with the SVM to increase reliability for power system operators is proposed in this investigation. The conventional LSTM technique is also implemented to compare the performance of the proposed hybrid technique. The suggested hybrid model is improved by the use of structural diversity and data diversity in KNN and SVM, respectively. For the solar power predictions, the suggested method was tested on the Jodhpur real-time series dataset obtained from the data centers of weather stations using Meteonorm. The data set includes metrics such as Hourly Average Temperature (HAT), Hourly Total Sunlight Duration (HTSD), Hourly Total Global Solar Radiation (HTGSR), and Hourly Total Photovoltaic Energy Generation (HTPEG). The collated data has been segmented into training data, validation data, and testing data. Furthermore, the proposed technique performed better when evaluated on the three performance indices, viz., accuracy, sensitivity, and specificity. Compared with the conventional LSTM technique, the hybrid technique improved the prediction with 98% accuracy.","['long short-term memory (LSTM)', 'support vector machine (SVM)', 'K-Nearest Neighbor (KNN)', 'hybrid machine learning model (KNN + SVM)']","The research idea addresses the critical need for accurate solar power forecasting in large-scale renewable energy plants, emphasizing the challenge posed by uncertainty in weather conditions that affect photovoltaic power generation. Improving the precision of solar power predictions is essential for enhancing the reliability and operational efficiency of power system operators managing solar farms. The primary objective of this study is to develop a method that increases the accuracy and reliability of solar power forecasts by leveraging diverse approaches to better capture the variability in weather-related factors. The study aims to test and validate this approach using real-time solar and weather data to demonstrate improved forecasting performance compared to existing conventional techniques."
Engineering,A Reliable and Robust Deep Learning Model for Effective Recyclable Waste Classification,"In response to the growing waste problem caused by industrialization and modernization, the need for an automated waste sorting and recycling system for sustainable waste management has become ever more pressing. Deep learning has made significant advancements in image classification, making it ideally suited for waste sorting applications. This application depends on the development of a suitable deep learning model capable of accurately categorizing various categories of waste. In this study, we present RWC-Net (recyclable waste classification network), a novel deep learning model designed for the classification of six distinct waste categories using the TrashNet dataset of 2,527 images of waste. The performance of our model is subjected to intensive quantitative and qualitative evaluations and is compared to various state-of-art waste classification techniques. The proposed model outperformed several state-of-the-art models by obtaining a remarkable overall accuracy rate of 95.01 percent. In addition, it receives high F1-scores for each of the six waste categories: 97.24% for cardboard, 96.18% for glass, 94% for metal, 95.73% for paper, 93.67% for plastic, and 88.55% for litter. The reliability of the model is demonstrated qualitatively through the saliency maps generated by Score-CAM (class activation mapping) model, which provide visual insights into its performance across various waste categories. These results highlight the model's accuracy and demonstrate its potential as an effective automated waste classification and management solution.","['Deep learning', 'Score-CAM (class activation mapping)']","The increasing waste problem resulting from industrialization and modernization has created an urgent need for an automated waste sorting and recycling solution to support sustainable waste management. Efficient classification of various waste categories is essential to improve recycling processes and reduce environmental impact. The primary aim of this study is to develop a method capable of accurately categorizing six distinct types of recyclable waste, thereby enhancing the effectiveness of waste sorting. This approach seeks to achieve high accuracy in identifying different waste materials to facilitate better recycling and waste management practices."
Engineering,Learning optimal inter-class margin adaptively for few-shot class-incremental learning via neural collapse-based meta-learning,"Few-Shot Class-Incremental Learning (FSCIL) aims to learn new classes incrementally with a limited number of samples per class. It faces issues of forgetting previously learned classes and overfitting on few-shot classes. An efficient strategy is to learn features that are discriminative in both base and incremental sessions. Current methods improve discriminability by manually designing inter-class margins based on empirical observations, which can be suboptimal. The emerging Neural Collapse (NC) theory provides a theoretically optimal inter-class margin for classification, serving as a basis for adaptively computing the margin. Yet, it is designed for closed, balanced data, not for sequential or few-shot imbalanced data. To address this gap, we propose a Meta-learning- and NC-based FSCIL method, MetaNC-FSCIL, to compute the optimal margin adaptively and maintain it at each incremental session. Specifically, we first compute the theoretically optimal margin based on the NC theory. Then we introduce a novel loss function to ensure that the loss value is minimized precisely when the inter-class margin reaches its theoretically best. Motivated by the intuition that ""learn how to preserve the margin"" matches the meta-learning's goal of ""learn how to learn"", we embed the loss function in base-session meta-training to preserve the margin for future meta-testing sessions. Experimental results demonstrate the effectiveness of MetaNC-FSCIL, achieving superior performance on multiple datasets. The code is available at https://github.com/qihangran/metaNC-FSCIL.","['Few-Shot Class-Incremental Learning (FSCIL)', 'Neural Collapse (NC) theory', 'Meta-learning']","The research addresses the challenge of incrementally learning new categories with very limited samples while preventing the loss of knowledge about previously learned categories and avoiding overfitting on the new, scarce data. It highlights the difficulty in maintaining discriminative features across both initial and subsequent learning phases, especially when existing approaches rely on manually set class separation margins that may not be optimal. The primary objective of the study is to develop a strategy that adaptively computes and preserves an optimal separation margin between classes during each incremental learning phase, ensuring consistent discriminability as new categories are introduced. This approach aims to maintain the best possible class separation throughout the learning process to improve overall classification performance in scenarios with limited and sequentially introduced data."
Engineering,Hybrid deep learning models for time series forecasting of solar power,"Abstract Forecasting solar power production accurately is critical for effectively planning and managing renewable energy systems. This paper introduces and investigates novel hybrid deep learning models for solar power forecasting using time series data. The research analyzes the efficacy of various models for capturing the complex patterns present in solar power data. In this study, all of the possible combinations of convolutional neural network (CNN), long short-term memory (LSTM), and transformer (TF) models are experimented. These hybrid models also compared with the single CNN, LSTM and TF models with respect to different kinds of optimizers. Three different evaluation metrics are also employed for performance analysis. Results show that the CNN–LSTM–TF hybrid model outperforms the other models, with a mean absolute error (MAE) of 0.551% when using the Nadam optimizer. However, the TF–LSTM model has relatively low performance, with an MAE of 16.17%, highlighting the difficulties in making reliable predictions of solar power. This result provides valuable insights for optimizing and planning renewable energy systems, highlighting the significance of selecting appropriate models and optimizers for accurate solar power forecasting. This is the first time such a comprehensive work presented that also involves transformer networks in hybrid models for solar power forecasting.","['convolutional neural network (CNN)', 'long short-term memory (LSTM)', 'transformer (TF)', 'CNN–LSTM–TF hybrid model']",The research addresses the critical need for accurate forecasting of solar power production to enable effective planning and management of renewable energy systems. It focuses on the challenge of capturing the complex patterns present in solar power data to improve the reliability of predictions. The primary aim of the study is to investigate and compare various combinations of forecasting approaches to determine their effectiveness in predicting solar power output. This includes evaluating different configurations to identify the most accurate method for supporting the optimization and planning of renewable energy systems.
Engineering,Exploring the role of skin temperature in thermal sensation and thermal comfort: A comprehensive review,"The role of skin temperature as a determinant of human thermal sensation and comfort has gained increasing recognition, prompting a need for a systematic review. This review examines the relationship between skin temperature and thermal sensation, synthesizing insights from 172 studies published since 2000. It uniquely focuses on the indispensable roles of local and mean skin temperatures, a perspective not comprehensively explored in previous literature. The review reveals that the most common measurement points for skin temperature are the face and hands, attributed to their higher thermal sensitivity and the practical ease of measurement. It establishes a clear linear relationship between mean skin temperature and user thermal sensation, though affected by the choice of measurement locations and number of points. A notable finding is the varying impact of local skin temperature on overall thermal sensation in changing environments, with local heating less influential than cooling. The review also uncovers significant demographic variations in thermal sensation, strongly influenced by differing skin temperatures across age groups, genders, and climatic regions. For example, elderly populations exhibit a decreased temperature sensitivity, especially towards warmth. Gender differences are also significant, with females experiencing higher skin temperatures in warmer environments and lower in colder ones. Machine learning (ML)-based methods, especially classification tree-based and support vector machine (SVM) techniques, dominate in predicting thermal sensation and comfort, leveraging skin temperature data. While ML methods are prevalent, statistical regression-based approaches offer valuable empirical insights. Thermo-physiological model-based methods provide reliable results by incorporating detailed skin temperature dynamics. The review identifies a gap in understanding how gender, age, and regional differences influence thermal comfort in diverse environments. The study recommends conducting more nuanced experiments to dissect the impact of these factors and proposes the integration of individual demographic variables into ML models to personalize thermal comfort predictions.","['support vector machine (SVM)', 'statistical regression-based approaches']","The research idea centers on the increasing recognition of skin temperature as a key factor influencing human thermal sensation and comfort, highlighting the need for a comprehensive review of its role. This study addresses the gap in understanding the distinct contributions of local and mean skin temperatures to thermal sensation, as well as the demographic variations in thermal comfort across different age groups, genders, and climatic regions. The research objective is to systematically examine and synthesize findings from numerous studies to clarify the relationship between skin temperature and thermal sensation, with particular attention to the effects of measurement locations and demographic differences. Additionally, the study aims to identify gaps in current knowledge regarding how gender, age, and regional factors affect thermal comfort, recommending further experimental investigations to better understand these influences."
Engineering,A novel framework for predicting active flow control by combining deep reinforcement learning and masked deep neural network,"Active flow control (AFC) through deep reinforcement learning (DRL) is computationally demanding. To address this, a masked deep neural network (MDNN), aiming to replace the computational fluid dynamics (CFD) environment, is developed to predict unsteady flow fields under the influence of arbitrary object motion. Then, a novel DRL-MDNN framework that combines the MDNN-based environment with the DRL algorithm is proposed. To validate the reliability of the framework, a blind test in a pulsating baffle system is designed. Vibration damping is considered to be the objective, and a traditional DRL-CFD framework is constructed for comparison. After training, a spatiotemporal evolution of 200 time steps under the influence of arbitrary object motion is predicted by the MDNN. The details of the flow field are compared with the CFD results, and a relative error within 5% is achieved, which satisfies the accuracy of serving as an interactive environment for DRL algorithms. The DRL-MDNN and traditional DRL-CFD frameworks are then applied to the pulsating baffle system to find the optimal control strategy. The results indicate that both frameworks achieve similar control performance, reducing vibration by 90%. Considering the resources expended in establishing the database, the computational resource consumption of the DRL-MDNN framework is reduced by 95%, and the interactive response time during each episode is decreased by 98.84% compared to the traditional DRL-CFD framework.",['deep reinforcement learning (DRL)'],"The research addresses the challenge of efficiently controlling unsteady flow fields influenced by arbitrary object motion, which is critical for applications such as vibration damping in engineering systems. Traditional approaches to active flow control require significant computational resources, limiting their practical use in real-time or resource-constrained environments. The study aims to develop a more resource-efficient method for predicting flow behavior and optimizing control strategies in systems experiencing complex fluid-structure interactions. The primary objective of the study is to create and validate a framework that can accurately predict unsteady flow fields and achieve effective vibration reduction in a pulsating baffle system while significantly reducing computational resource consumption and response time compared to conventional methods."
Engineering,Characterizing land use/land cover change dynamics by an enhanced random forest machine learning model: a Google Earth Engine implementation,"Abstract Land use and land cover (LULC) analysis is crucial for understanding societal development and assessing changes during the Anthropocene era. Conventional LULC mapping faces challenges in capturing changes under cloud cover and limited ground truth data. To enhance the accuracy and comprehensiveness of the descriptions of LULC changes, this investigation employed a combination of advanced techniques. Specifically, multitemporal 30 m resolution Landsat-8 satellite imagery was utilized, in addition to the cloud computing capabilities of the Google Earth Engine (GEE) platform. Additionally, the study incorporated the random forest (RF) algorithm. This study aimed to generate continuous LULC maps for 2014 and 2020 for the Shrirampur area of Maharashtra, India. A novel multiple composite RF approach based on LULC classification was utilized to generate the final LULC classification maps utilizing the RF-50 and RF-100 tree models. Both RF models utilized seven input bands (B1 to B7) as the dataset for LULC classification. By incorporating these bands, the models were able to influence the spectral information captured by each band to classify the LULC categories accurately. The inclusion of multiple bands enhanced the discrimination capabilities of the classifiers, increasing the comprehensiveness of the assessment of the LULC classes. The analysis indicated that RF-100 exhibited higher training and validation/testing accuracy for 2014 and 2020 (0.99 and 0.79/0.80, respectively). The study further revealed that agricultural land, built-up land, and water bodies have changed adequately and have undergone substantial variation among the LULC classes in the study area. Overall, this research provides novel insights into the application of machine learning (ML) models for LULC mapping and emphasizes the importance of selecting the optimal tree combination for enhancing the accuracy and reliability of LULC maps based on the GEE and different RF tree models. The present investigation further enabled the interpretation of pixel-level LULC interactions while improving image classification accuracy and suggested the best models for the classification of LULC maps through the identification of changes in LULC classes.",['random forest (RF) algorithm'],"The study addresses the challenge of accurately mapping land use and land cover (LULC) changes, which is essential for understanding societal development and environmental transformations during the Anthropocene era. Conventional LULC mapping methods face difficulties in capturing changes due to factors such as cloud cover and limited availability of ground truth data, which affect the comprehensiveness and precision of LULC assessments. The primary objective of the research is to generate continuous and accurate LULC maps for the years 2014 and 2020 in the Shrirampur area of Maharashtra, India. This involves improving the classification and discrimination of various LULC categories, such as agricultural land, built-up areas, and water bodies, to better identify and interpret the substantial variations and changes occurring within the study region."
Engineering,Analysing LULC transformations using remote sensing data: insights from a multilayer perceptron neural network approach,"The study examines the complex dynamics of changes in LULC over three decades, focused on the years 1992, 2002, 2012, and 2022. The research highlights the significance of comprehending these alterations within the framework of environmental and socio-economic consequences. The changes in land use and land cover (LULC) have significant and far-reaching effects on ecosystems, biodiversity, and human livelihoods. This study offers useful information for politicians, conservationists, and urban planners by examining historical patterns and forecasting future changes. The study utilized a Multilayer Perceptron Neural Network (MLP-NN), a well-known machine learning technique that excels at collecting intricate patterns. This model's design had three layers: input, hidden, and output. The model underwent 10,000 iterations during its training process, and a thorough statistical analysis was conducted to assess the impact of each driving component. The MLP-NN model demonstrated impressive performance, with a skill measure of 0.8724 and an accuracy rate of 89.08%. The accuracy of the LULC estimates for 2022 was verified by comparing them with observed data, ensuring the model's reliability. Moreover, the presence of evidence likely was found to be a significant factor that had a substantial impact on the accuracy of the model. The study highlights the effectiveness of the MLP-NN model in accurately predicting changes in LULC. The model's exceptional accuracy and proficiency make it a powerful tool for future LULC forecasts. Identifying the primary causes of model performance and understanding their implications may help to enhance land management strategies, encourage spatial planning, guide accurate decision-making, and facilitate the development of policies that align with sustainable growth and development.",['Multilayer Perceptron Neural Network (MLP-NN)'],"The study addresses the complex dynamics of changes in land use and land cover (LULC) over three decades, emphasizing the importance of understanding these alterations due to their significant environmental and socio-economic consequences. Changes in LULC have far-reaching effects on ecosystems, biodiversity, and human livelihoods, making it crucial to examine historical patterns and anticipate future developments. The primary aim of the study is to provide useful information for policymakers, conservationists, and urban planners by examining past LULC changes and forecasting future trends. This objective supports the enhancement of land management strategies, spatial planning, and the development of policies that promote sustainable growth and development."
Engineering,Seeking in Ride-on-Demand Service: A Reinforcement Learning Model With Dynamic Price Prediction,"Recent years witness the increasing popularity of ride-on-demand (RoD) services such as Uber and Didi. Compared with traditional taxi, RoD service is more ""data-driven"" and adopts dynamic pricing to manipulate the supply and demand in real time. Dynamic price could be viewed as an accurate and quantitative indicator of the supply and demand, and could provide clues to drivers, passengers, and the service providers, possibly reshaping the ways in which some problems are solved. In this paper, we focus on the seeking route recommendation problem that aims at increasing driver revenue by recommending highly profitable seeking routes to drivers of vacant cars with the help of dynamic prices. We first justify our motivation by showing the importance of route recommendation and answering why it is necessary to consider dynamic prices, based on the analysis of real service data. We then design a dynamic price prediction model to generate the dynamic prices at any given time and location based on multi-source urban data. After that, a reinforcement learning model is adopted to perform seeking route recommendation based on predicted dynamic prices. We conduct extensive experiments in different spatio-temporal combinations and make comparisons with multiple baselines. Results first show that our dynamic price prediction model achieves an accuracy ranging from 83.82% to 90.67% under different settings. It also proves that considering the real-time predicted dynamic prices significantly increases driver revenue by, for example, 12% and 47.5% during weekday evening rush hours, than merely using the average prices or completely ignoring dynamic prices.",['reinforcement learning model'],"The research idea addresses the growing use of ride-on-demand services and the role of dynamic pricing as a precise and quantitative indicator of supply and demand, which influences drivers, passengers, and service providers. This dynamic pricing mechanism has the potential to reshape how certain operational challenges, such as route selection for vacant vehicles, are approached in order to enhance efficiency and profitability. The study’s primary objective is to increase driver revenue by recommending highly profitable seeking routes to drivers of vacant cars through the consideration of dynamic prices. It aims to demonstrate the importance of route recommendation in the context of dynamic pricing and to validate that incorporating real-time price variations can significantly improve driver earnings compared to using average or static pricing information."
Engineering,Data oversampling and imbalanced datasets: an investigation of performance for machine learning and feature engineering,"Abstract The classification of imbalanced datasets is a prominent task in text mining and machine learning. The number of samples in each class is not uniformly distributed; one class contains a large number of samples while the other has a small number. Overfitting of the model occurs as a result of imbalanced datasets, resulting in poor performance. In this study, we compare different oversampling techniques like synthetic minority oversampling technique (SMOTE), support vector machine SMOTE (SVM-SMOTE), Border-line SMOTE, K-means SMOTE, and adaptive synthetic (ADASYN) oversampling to address the issue of imbalanced datasets and enhance the performance of machine learning models. Preprocessing significantly enhances the quality of input data by reducing noise, redundant data, and unnecessary data. This enables the machines to identify crucial patterns that facilitate the extraction of significant and pertinent information from the preprocessed data. This study preprocesses the data using various top-level preprocessing steps. Furthermore, two imbalanced Twitter datasets are used to compare the performance of oversampling techniques with six machine learning models including random forest (RF), SVM, K-nearest neighbor (KNN), AdaBoost (ADA), logistic regression (LR), and decision tree (DT). In addition, the bag of words (BoW) and term frequency and inverse document frequency (TF-IDF) features extraction approaches are used to extract features from the tweets. The experiments indicate that SMOTE and ADASYN perform much better than other techniques thus providing higher accuracy. Additionally, overall results show that SVM with ’linear’ kernel tends to attain the highest accuracy and recall score of 99.67% and 1.00% on ADASYN oversampled datasets and 99.57% accuracy on SMOTE oversampled dataset with TF-IDF features. The SVM model using 10-fold cross-validation experiments achieved 97.40 mean accuracy with a 0.008 standard deviation. Our approach achieved 2.62% greater accuracy as compared to other current methods.","['synthetic minority oversampling technique (SMOTE)', 'Border-line SMOTE', 'K-means SMOTE', 'adaptive synthetic (ADASYN) oversampling', 'random forest (RF)', 'SVM', 'K-nearest neighbor (KNN)', 'AdaBoost (ADA)', 'logistic regression (LR)', 'decision tree (DT)']","The research idea addresses the challenge of imbalanced datasets, where the number of samples in each class is unevenly distributed, leading to overfitting and poor performance in classification tasks. This imbalance affects the ability to accurately identify important patterns and extract relevant information from the data. The study aims to improve the quality of input data by applying preprocessing steps that reduce noise and redundancy, thereby enhancing the overall effectiveness of classification. The primary objective of the study is to compare various oversampling techniques to mitigate the issue of imbalanced datasets and improve classification performance. The research specifically evaluates these techniques on imbalanced Twitter datasets to determine which approach yields higher accuracy and better results in handling class imbalance."
Engineering,Making Sense of Machine Learning: A Review of Interpretation Techniques and Their Applications,"Transparency in AI models is essential for promoting human–AI collaboration and ensuring regulatory compliance. However, interpreting these models is a complex process influenced by various methods and datasets. This study presents a comprehensive overview of foundational interpretation techniques, meticulously referencing the original authors and emphasizing their pivotal contributions. Recognizing the seminal work of these pioneers is imperative for contextualizing the evolutionary trajectory of interpretation in the field of AI. Furthermore, this research offers a retrospective analysis of interpretation techniques, critically evaluating their inherent strengths and limitations. We categorize these techniques into model-based, representation-based, post hoc, and hybrid methods, delving into their diverse applications. Furthermore, we analyze publication trends over time to see how the adoption of advanced computational methods within various categories of interpretation techniques has shaped the development of AI interpretability over time. This analysis highlights a notable preference shift towards data-driven approaches in the field. Moreover, we consider crucial factors such as the suitability of these techniques for generating local or global insights and their compatibility with different data types, including images, text, and tabular data. This structured categorization serves as a guide for practitioners navigating the landscape of interpretation techniques in AI. In summary, this review not only synthesizes various interpretation techniques but also acknowledges the contributions of their original authors. By emphasizing the origins of these techniques, we aim to enhance AI model explainability and underscore the importance of recognizing biases, uncertainties, and limitations inherent in the methods and datasets. This approach promotes the ethical and practical use of interpretation insights, empowering AI practitioners, researchers, and professionals to make informed decisions when selecting techniques for responsible AI implementation in real-world scenarios.","['model-based methods', 'representation-based methods', 'hybrid methods']","The research addresses the challenge of understanding and interpreting complex models to promote effective collaboration and ensure compliance with regulations. It highlights the importance of recognizing foundational contributions to the development of interpretation techniques and the need to critically evaluate their strengths, limitations, and applicability across different types of data. The study aims to provide a comprehensive overview and structured categorization of various interpretation techniques, emphasizing their evolution and practical relevance. By doing so, it seeks to guide practitioners in selecting appropriate methods for generating meaningful insights while acknowledging inherent biases and uncertainties, ultimately supporting responsible and ethical application in engineering contexts."
Engineering,Real-life data-driven model predictive control for building energy systems comparing different machine learning models,"By considering forecasts and exploiting storage effects, model predictive control can achieve significant energy and cost savings in the building sector. However, due to the high individual modeling effort, model predictive control lacks practical applicability. For that reason, data-driven process models, approximating the system behavior based on measurements, have become increasingly popular in recent years. Still, scientific literature lacks consent about the most promising model types and efficient workflows to integrate different machine learning models into a model predictive controller. With this work, we present a workflow to provide efficient model predictive controllers based on measurement data automatically. The main idea is to translate different machine learning models into optimization syntax to enable efficient optimization with full access to gradients. We currently consider artificial neural networks, gaussian process regression, and simple linear regression process models. We use a generic model ontology to automatize the controller generation further and test the methodology on two real-life use cases. The first use case is the application of five office rooms with smart thermostat valves. The second use case is a test hall with an air handling unit and a concrete core activation. Using only two days of initial training data, we deploy controllers based on the different model types for six weeks in the offices and apply online learning to improve the models continuously. We observe only minor differences in controller performance despite the artificial neural networks showing the highest prediction accuracy. The second use case shows that the simple linear models require less controller tuning effort. Thus, for practical applications, we recommend linear regression models.","['artificial neural networks', 'gaussian process regression', 'linear regression']","The research addresses the challenge of achieving significant energy and cost savings in the building sector through advanced control strategies that consider forecasts and storage effects. However, the practical applicability of these strategies is limited due to the high individual modeling effort required. There is also a lack of consensus in the scientific literature regarding the most effective types of process models and workflows for integrating various modeling approaches into building control applications. The study aims to develop and present an efficient workflow for automatically generating building control strategies based on measurement data, enabling practical deployment with minimal tuning effort. This workflow is tested on real-life use cases involving office rooms and a test hall to evaluate the performance and practicality of different process model types in building climate control."
Engineering,Enhancing MPPT performance for partially shaded photovoltaic arrays through backstepping control with Genetic Algorithm-optimized gains,"As the significance and complexity of solar panel performance, particularly at their maximum power point (MPP), continue to grow, there is a demand for improved monitoring systems. The presence of variable weather conditions in Maroua, including potential partial shadowing caused by cloud cover or urban buildings, poses challenges to the efficiency of solar systems. This study introduces a new approach to tracking the Global Maximum Power Point (GMPP) in photovoltaic systems within the context of solar research conducted in Cameroon. The system utilizes Genetic Algorithm (GA) and Backstepping Controller (BSC) methodologies. The Backstepping Controller (BSC) dynamically adjusts the duty cycle of the Single Ended Primary Inductor Converter (SEPIC) to align with the reference voltage of the Genetic Algorithm (GA) in Maroua's dynamic environment. This environment, characterized by intermittent sunlight and the impact of local factors and urban shadowing, affects the production of energy. The Genetic Algorithm is employed to enhance the efficiency of BSC gains in Maroua's solar environment. This optimization technique expedites the tracking process and minimizes oscillations in the GMPP. The adaptability of the learning algorithm to specific conditions improves energy generation, even in the challenging environment of Maroua. This study introduces a novel approach to enhance the efficiency of photovoltaic systems in Maroua, Cameroon, by tailoring them to the specific solar dynamics of the region. In terms of performance, our approach surpasses the INC-BSC, P&O-BSC, GA-BSC, and PSO-BSC methodologies. In practice, the stabilization period following shadowing typically requires fewer than three iterations. Additionally, our Maximum Power Point Tracking (MPPT) technology is based on the Global Maximum Power Point (GMPP) methodology, contrasting with alternative technologies that prioritize the Local Maximum Power Point (LMPP). This differentiation is particularly relevant in areas with partial shading, such as Maroua, where the use of LMPP-based technologies can result in power losses. The proposed method demonstrates significant performance by achieving a minimum 33% reduction in power losses.",['Genetic Algorithm (GA)'],"The research addresses the growing importance and complexity of optimizing solar panel performance, especially at their maximum power point, under challenging environmental conditions. In Maroua, Cameroon, variable weather and partial shadowing from clouds and urban structures significantly reduce the efficiency of photovoltaic systems, creating a need for improved approaches to maintain energy production. The study focuses on overcoming these challenges by enhancing the ability to track the global maximum power point in solar panels despite the dynamic and intermittent sunlight conditions characteristic of the region. The primary objective of the study is to develop and implement a novel approach tailored to the specific solar dynamics of Maroua that improves the efficiency of photovoltaic systems by reducing power losses caused by partial shading and environmental variability. This approach aims to achieve faster stabilization after shadowing events and to minimize power loss by prioritizing the global maximum power point rather than local maxima, thereby significantly enhancing energy generation in the local context."
Engineering,Advanced Modelling of Soil Organic Carbon Content in Coal Mining Areas Using Integrated Spectral Analysis: A Dengcao Coal Mine Case Study,"Effective modelling and integrated spectral analysis approaches can advance modelling precision. To develop an integrated spectral forecast modelling of soil organic carbon (SOC), this research investigated a mining coal in Dengcao Coal Mine Area, Zhengzhou. The study utilizes the Lasso and Ranger algorithms were utilized in spectral band analysis. Four primary models employed during this process include Artificial Neural Network (ANN), Support Vector Machine, Random Forest (RF), and Partial Least Squares Regression (PLSR). The ideal model was chosen. The results showed that, in contrast to when band collection was based on Lasso algorithm modelling, model precision was higher when it was based on the Ranger algorithm. ANN model had an ideal goodness acceptance, and the modelling developed by RF showed the steadiest modelling consequences. Based on the results, a distinct method is proposed in this study for band assortment at the earlier stage of integrated spectral modelling of SOC. The Ranger method can be used to check the spectral particles, and RF or ANN can be chosen to develop the prediction modelling based on different statistics sets, which is appropriate to create the prediction modelling of SOC content in Dengcao Coal Mine Area. This research avails a position for the integrated spectral of Analysis for Advanced Modelling of Soil Organic Carbon Content in Coal Sources alongside a theoretical foundation for innovating portable device for the integrated spectral assessment of SOC content in coal mining habitats. This study might be significant for the changing modelling and monitoring of SOC in mining and environmental areas.","['Lasso', 'Artificial Neural Network (ANN)', 'Support Vector Machine', 'Random Forest (RF)']","The research addresses the challenge of improving the precision of soil organic carbon (SOC) content estimation in coal mining areas through integrated spectral analysis. Accurate modelling of SOC is crucial for monitoring and managing soil quality in mining environments, which has implications for environmental sustainability and resource management. The study focuses on the Dengcao Coal Mine Area in Zhengzhou, where effective spectral forecasting of SOC can enhance understanding and control of soil conditions affected by mining activities. The primary aim of the study is to develop an integrated spectral forecast approach for SOC content by investigating and comparing different spectral band selection methods and modelling techniques to identify the most precise and reliable approach for SOC prediction in the coal mining context. This objective includes proposing a method for early-stage spectral band selection and establishing a theoretical foundation for future development of portable devices for SOC assessment in mining habitats."
Engineering,Autopilot control unmanned aerial vehicle system for sewage defect detection using deep learning,"Abstract This work proposes the use of an unmanned aerial vehicle (UAV) with an autopilot to identify the defects present in municipal sewerage pipes. The framework also includes an effective autopilot control mechanism that can direct the flight path of a UAV within a sewer line. Both of these breakthroughs have been addressed throughout this work. The UAV's camera proved useful throughout a sewage inspection, providing important contextual data that helped analyze the sewerage line's internal condition. A plethora of information useful for understanding the sewerage line's inner functioning and extracting interior visual details can be obtained from camera‐recorded sewerage imagery if a defect is present. In the case of sewerage inspections, nevertheless, the impact of a false negative is significantly higher than that of a false positive. One of the trickiest parts of the procedure is identifying defective sewerage pipelines and false negatives. In order to get rid of the false negative outcome or false positive outcome, a guided image filter (GIF) is implemented in this proposed method during the pre‐processing stage. Afterwards, the algorithms Gabor transform (GT) and stroke width transform (SWT) were used to obtain the features of the UAV‐captured surveillance image. The UAV camera's sewerage image is then classified as “defective” or “not defective” using the obtained features by a Weighted Naive Bayes Classifier (WNBC). Next, images of the sewerage lines captured by the UAV are analyzed using speed‐up robust features (SURF) and deep learning to identify different types of defects. As a result, the proposed methodology achieved more favorable outcomes than prior existing approaches in terms of the following metrics: mean PSNR (71.854), mean MSE (0.0618), mean RMSE (0.2485), mean SSIM (98.71%), mean accuracy (98.372), mean specificity (97.837%), mean precision (93.296%), mean recall (94.255%), mean F1‐score (93.773%), and mean processing time (35.43 min).","['Weighted Naive Bayes Classifier (WNBC)', 'deep learning']","The research addresses the challenge of identifying defects in municipal sewerage pipes, emphasizing the importance of accurately detecting damaged sections to maintain the integrity and functionality of sewer systems. It highlights the difficulty in minimizing false negatives during sewer inspections, as overlooking defects can lead to significant issues in sewer maintenance and operation. The primary objective of the study is to develop a method for inspecting sewerage lines using an unmanned aerial vehicle equipped with a camera to capture internal images of the pipes. This approach aims to accurately classify sewerage pipe conditions as defective or not defective, thereby improving the detection of various types of defects within the sewer infrastructure."
Engineering,DEA-Net: Single Image Dehazing Based on Detail-Enhanced Convolution and Content-Guided Attention,"Single image dehazing is a challenging ill-posed problem which estimates latent haze-free images from observed hazy images. Some existing deep learning based methods are devoted to improving the model performance via increasing the depth or width of convolution. The learning ability of Convolutional Neural Network (CNN) structure is still under-explored. In this paper, a Detail-Enhanced Attention Block (DEAB) consisting of Detail-Enhanced Convolution (DEConv) and Content-Guided Attention (CGA) is proposed to boost the feature learning for improving the dehazing performance. Specifically, the DEConv contains difference convolutions which can integrate prior information to complement the vanilla one and enhance the representation capacity. Then by using the re-parameterization technique, DEConv is equivalently converted into a vanilla convolution to reduce parameters and computational cost. By assigning the unique Spatial Importance Map (SIM) to every channel, CGA can attend more useful information encoded in features. In addition, a CGA-based mixup fusion scheme is presented to effectively fuse the features and aid the gradient flow. By combining above mentioned components, we propose our Detail-Enhanced Attention Network (DEA-Net) for recovering high-quality haze-free images. Extensive experimental results demonstrate the effectiveness of our DEA-Net, outperforming the state-of-the-art (SOTA) methods by boosting the PSNR index over 41 dB with only 3.653 M parameters. (The source code of our DEA-Net is available at https://github.com/cecret3350/DEA-Net.).","['Convolutional Neural Network (CNN)', 're-parameterization technique']","The research idea addresses the challenging problem of recovering clear, haze-free images from single hazy images, which is an ill-posed issue in image restoration. Existing approaches have focused on enhancing performance by increasing the complexity of convolution operations, but the potential of improving feature learning within the convolutional structure itself remains insufficiently explored. The study aims to improve the quality of dehazed images by enhancing the representation and extraction of important image details. The primary objective of the study is to develop a novel approach that enhances feature learning to improve image dehazing performance, ultimately recovering high-quality haze-free images with greater accuracy and efficiency. This involves integrating prior information to strengthen feature representation and effectively combining features to aid the restoration process, resulting in superior image clarity compared to existing methods."
Engineering,Hardware implementation of memristor-based artificial neural networks,"Abstract Artificial Intelligence (AI) is currently experiencing a bloom driven by deep learning (DL) techniques, which rely on networks of connected simple computing units operating in parallel. The low communication bandwidth between memory and processing units in conventional von Neumann machines does not support the requirements of emerging applications that rely extensively on large sets of data. More recent computing paradigms, such as high parallelization and near-memory computing, help alleviate the data communication bottleneck to some extent, but paradigm- shifting concepts are required. Memristors, a novel beyond-complementary metal-oxide-semiconductor (CMOS) technology, are a promising choice for memory devices due to their unique intrinsic device-level properties, enabling both storing and computing with a small, massively-parallel footprint at low power. Theoretically, this directly translates to a major boost in energy efficiency and computational throughput, but various practical challenges remain. In this work we review the latest efforts for achieving hardware-based memristive artificial neural networks (ANNs), describing with detail the working principia of each block and the different design alternatives with their own advantages and disadvantages, as well as the tools required for accurate estimation of performance metrics. Ultimately, we aim to provide a comprehensive protocol of the materials and methods involved in memristive neural networks to those aiming to start working in this field and the experts looking for a holistic approach.","['deep learning (DL)', 'artificial neural networks (ANNs)']","The research idea addresses the limitations of conventional computing architectures, particularly the low communication bandwidth between memory and processing units, which hinders the performance of applications requiring extensive data handling. Emerging computing paradigms such as high parallelization and near-memory computing offer partial solutions, but fundamentally new concepts are necessary to overcome these bottlenecks. Memristors, as a novel memory technology with unique device-level properties, present a promising opportunity to enhance energy efficiency and throughput in memory devices by enabling both storage and computation within a compact and low-power footprint. The study recognizes that despite the theoretical advantages, practical challenges remain in realizing these benefits.

The primary objective of the study is to review the latest developments in hardware implementations of memristive devices, detailing the operational principles and design alternatives of each component involved. It aims to provide a comprehensive overview of the materials and methods used in memristive memory technologies, along with the advantages and disadvantages of different design choices. Ultimately, the work seeks to offer a holistic protocol to guide researchers and practitioners interested in advancing this emerging field of memory device engineering."
Engineering,TransUNet: Rethinking the U-Net architecture design for medical image segmentation through the lens of transformers,"Medical image segmentation is crucial for healthcare, yet convolution-based methods like U-Net face limitations in modeling long-range dependencies. To address this, Transformers designed for sequence-to-sequence predictions have been integrated into medical image segmentation. However, a comprehensive understanding of Transformers' self-attention in U-Net components is lacking. TransUNet, first introduced in 2021, is widely recognized as one of the first models to integrate Transformer into medical image analysis. In this study, we present the versatile framework of TransUNet that encapsulates Transformers' self-attention into two key modules: (1) a Transformer encoder tokenizing image patches from a convolution neural network (CNN) feature map, facilitating global context extraction, and (2) a Transformer decoder refining candidate regions through cross-attention between proposals and U-Net features. These modules can be flexibly inserted into the U-Net backbone, resulting in three configurations: Encoder-only, Decoder-only, and Encoder+Decoder. TransUNet provides a library encompassing both 2D and 3D implementations, enabling users to easily tailor the chosen architecture. Our findings highlight the encoder's efficacy in modeling interactions among multiple abdominal organs and the decoder's strength in handling small targets like tumors. It excels in diverse medical applications, such as multi-organ segmentation, pancreatic tumor segmentation, and hepatic vessel segmentation. Notably, our TransUNet achieves a significant average Dice improvement of 1.06% and 4.30% for multi-organ segmentation and pancreatic tumor segmentation, respectively, when compared to the highly competitive nn-UNet, and surpasses the top-1 solution in the BrasTS2021 challenge. 2D/3D Code and models are available at https://github.com/Beckschen/TransUNet and https://github.com/Beckschen/TransUNet-3D, respectively.","['U-Net', 'Transformers', 'TransUNet', 'Transformer encoder', 'Transformer decoder', 'convolution neural network (CNN)', 'nn-UNet']","The research addresses the challenge of improving medical image segmentation, which is essential for healthcare, by overcoming the limitations of existing convolution-based methods in capturing long-range dependencies within images. There is a need for a better understanding of how self-attention mechanisms can be effectively incorporated into key components of segmentation frameworks to enhance performance in identifying complex anatomical structures and small targets such as tumors. The primary objective of the study is to present a versatile framework that integrates self-attention mechanisms into different modules of a segmentation architecture, allowing flexible configurations to improve the extraction of global context and refinement of candidate regions. This framework aims to enhance segmentation accuracy across various medical applications, including multi-organ segmentation, pancreatic tumor segmentation, and hepatic vessel segmentation, demonstrating measurable improvements over existing competitive approaches."
Engineering,Fusion of finite element and machine learning methods to predict rock shear strength parameters,"Abstract The trial-and-error method for calibrating rock mechanics parameters has the disadvantages of complexity, being time-consuming, and difficulty in ensuring accuracy. Harnessing the repeatability and scalability intrinsic to numerical simulation calculations and amalgamating them with the data-driven attributes of machine learning methods, this study uses the finite element analysis software RS2 to establish 252 sets of sandstone sample data. The recursive feature elimination and cross-validation method is employed for feature selection. The shear strength parameters of sandstone are predicted using machine learning models optimized by the particle swarm optimization (PSO) algorithm, including the backpropagation neural network, Bayesian ridge regression, support vector regression (SVR), and light gradient boosting machine. The predicted value of cohesion is proposed as the input feature to predict the friction angle. The results indicate that the optimal input characteristics for predicting cohesion are elastic modulus, Poisson's ratio, peak stress, and peak strain, while the optimal input characteristics for predicting friction angle are peak stress and cohesion. The PSO-SVR model demonstrates the best performance. The maximum error between the predicted values of cohesion and friction angle and the calculated results of RSData program are 3.5% and 4.31%, respectively. The finite element calculation is in good agreement with the stress–strain curve obtained in the laboratory. The sensitivity analysis indicates that SVR's prediction performance for cohesion and friction angle tends to be stable when the sample size is &amp;gt;25. These results offer a valuable reference for accurately predicting rock mechanics parameters.","['recursive feature elimination', 'backpropagation neural network', 'Bayesian ridge regression', 'support vector regression (SVR)', 'light gradient boosting machine']","The study addresses the challenges associated with the traditional trial-and-error method for calibrating rock mechanics parameters, which is complex, time-consuming, and difficult to ensure accuracy. There is a need for a more efficient and reliable approach to determine the shear strength parameters of sandstone, which are critical for understanding its mechanical behavior. The primary aim of the study is to accurately predict the shear strength parameters of sandstone, specifically cohesion and friction angle, by identifying optimal input characteristics and validating the predictions against finite element calculations and laboratory stress–strain curves. This objective seeks to provide a valuable reference for improving the precision and efficiency of rock mechanics parameter estimation."
Engineering,Deep learning-based structural health monitoring,"This article provides a comprehensive review of deep learning-based structural health monitoring (DL-based SHM). It encompasses a broad spectrum of DL theories and applications including nondestructive approaches; computer vision-based methods, digital twins, unmanned aerial vehicles (UAVs), and their integration with DL; vibration-based strategies including sensor fault and data recovery methods; and physics-informed DL approaches. Connections between traditional machine learning and DL-based methods as well as relations of local to global approaches including their extensive integrations are established. The state-of-the-art methods, including their advantages and limitations are presented. The review draws on current literature on the topic, also providing a synergistic analysis leading to the understanding of the evolution of DL as a basis for presenting the future research and development needs. Our overall finding is that despite the rapid progression of digital technology along with the progression of DL, the DL-based SHM appears to be in its infant stages with enormous potential for future developments to bring the SHM technology to a common practical use with wide scope applications, performance reliability, cost, and degree of automation. It is anticipated that this review paper will serve as a basic resource for readers seeking comprehensive and holistic understanding of the subject matter.","['deep learning (DL)', 'physics-informed deep learning (DL) approaches']","The research idea centers on addressing the current state and challenges of structural health monitoring (SHM) technologies, emphasizing the need for advancements that enhance practical application, performance reliability, cost-effectiveness, and automation in the field. Despite significant technological progress, SHM methods remain in early stages of development with substantial potential for future improvements to broaden their scope and usability. The primary objective of the study is to provide a comprehensive review of existing SHM approaches, highlighting their advantages and limitations, and to offer a thorough understanding of the evolution and future research needs in SHM technology. This review aims to serve as a foundational resource for advancing SHM toward widespread practical implementation with improved efficiency and reliability."
Engineering,TTST: A Top-<i>k</i> Token Selective Transformer for Remote Sensing Image Super-Resolution,"Transformer-based method has demonstrated promising performance in image super-resolution tasks, due to its long-range and global aggregation capability. However, the existing Transformer brings two critical challenges for applying it in large-area earth observation scenes: (1) redundant token representation due to most irrelevant tokens; (2) single-scale representation which ignores scale correlation modeling of similar ground observation targets. To this end, this paper proposes to adaptively eliminate the interference of irreverent tokens for a more compact self-attention calculation. Specifically, we devise a Residual Token Selective Group (RTSG) to grasp the most crucial token by dynamically selecting the top- <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> <tex-math notation=""LaTeX"">$k$ </tex-math></inline-formula> keys in terms of score ranking for each query. For better feature aggregation, a Multi-scale Feed-forward Layer (MFL) is developed to generate an enriched representation of multi-scale feature mixtures during feed-forward process. Moreover, we also proposed a Global Context Attention (GCA) to fully explore the most informative components, thus introducing more inductive bias to the RTSG for an accurate reconstruction. In particular, multiple cascaded RTSGs form our final Top- <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> <tex-math notation=""LaTeX"">$k$ </tex-math></inline-formula> Token Selective Transformer (TTST) to achieve progressive representation. Extensive experiments on simulated and real-world remote sensing datasets demonstrate our TTST could perform favorably against state-of-the-art CNN-based and Transformer-based methods, both qualitatively and quantitatively. In brief, TTST outperforms the state-of-the-art approach (HAT-L) in terms of PSNR by 0.14 dB on average, but only accounts for 47.26% and 46.97% of its computational cost and parameters. The code and pre-trained TTST will be available at <uri xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">https://github.com/XY-boy/TTST</uri> for validation.","['Transformer-based method', 'Global Context Attention (GCA)']","The research addresses the challenges in enhancing image super-resolution for large-area earth observation scenes, focusing on issues such as redundant representation of irrelevant information and the lack of multi-scale correlation modeling for similar ground observation targets. These challenges limit the effectiveness of current approaches in accurately reconstructing high-resolution images from earth observation data. The primary objective of the study is to improve the quality of image super-resolution in remote sensing by selectively focusing on the most relevant information and incorporating multi-scale feature representations to achieve more accurate and efficient reconstruction of earth observation images. The study aims to demonstrate that this approach can outperform existing methods in terms of reconstruction quality while reducing computational resources."
Engineering,Transformer-Based Visual Segmentation: A Survey,"Visual segmentation seeks to partition images, video frames, or point clouds into multiple segments or groups. This technique has numerous real-world applications, such as autonomous driving, image editing, robot sensing, and medical analysis. Over the past decade, deep learning-based methods have made remarkable strides in this area. Recently, transformers, a type of neural network based on self-attention originally designed for natural language processing, have considerably surpassed previous convolutional or recurrent approaches in various vision processing tasks. Specifically, vision transformers offer robust, unified, and even simpler solutions for various segmentation tasks. This survey provides a thorough overview of transformer-based visual segmentation, summarizing recent advancements. We first review the background, encompassing problem definitions, datasets, and prior convolutional methods. Next, we summarize a meta-architecture that unifies all recent transformer-based approaches. Based on this meta-architecture, we examine various method designs, including modifications to the meta-architecture and associated applications. We also present several specific subfields, including 3D point cloud segmentation, foundation model tuning, domain-aware segmentation, efficient segmentation, and medical segmentation. Additionally, we compile and re-evaluate the reviewed methods on several well-established datasets. Finally, we identify open challenges in this field and propose directions for future research. The project page can be found at <uri xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">https://github.com/lxtGH/Awesome-Segmentation-With-Transformer</uri> .","['transformers', 'convolutional approaches', 'recurrent approaches', 'vision transformers']","The research idea addresses the challenge of partitioning images, video frames, or point clouds into multiple segments or groups, which is essential for various engineering applications such as autonomous driving, image editing, robot sensing, and medical analysis. The study recognizes the importance of improving visual segmentation techniques to enhance the accuracy and efficiency of these applications. The primary objective of the study is to provide a comprehensive overview of recent advancements in visual segmentation, focusing on a unified framework that encompasses various approaches and applications. It aims to summarize existing methods, evaluate their performance on established datasets, and identify open challenges and future directions in the field of visual segmentation."
Engineering,"Generative AI for Transformative Healthcare: A Comprehensive Study of Emerging Models, Applications, Case Studies, and Limitations","Generative artificial intelligence (GAI) can be broadly described as an artificial intelligence system capable of generating images, text, and other media types with human prompts. GAI models like ChatGPT, DALL-E, and Bard have recently caught the attention of industry and academia equally. GAI applications span various industries like art, gaming, fashion, and healthcare. In healthcare, GAI shows promise in medical research, diagnosis, treatment, and patient care and is already making strides in real-world deployments. There has yet to be any detailed study concerning the applications and scope of GAI in healthcare. Addressing this research gap, we explore several applications, real-world scenarios, and limitations of GAI in healthcare. We examine how GAI models like ChatGPT and DALL-E can be leveraged to aid in the applications of medical imaging, drug discovery, personalized patient treatment, medical simulation and training, clinical trial optimization, mental health support, healthcare operations and research, medical chatbots, human movement simulation, and a few more applications. Along with applications, we cover four real-world healthcare scenarios that employ GAI: visual snow syndrome diagnosis, molecular drug optimization, medical education, and dentistry. We also provide an elaborate discussion on seven healthcare-customized LLMs like Med-PaLM, BioGPT, DeepHealth, etc.,Since GAI is still evolving, it poses challenges like the lack of professional expertise in decision making, risk of patient data privacy, issues in integrating with existing healthcare systems, and the problem of data bias which are elaborated on in this work along with several other challenges. We also put forward multiple directions for future research in GAI for healthcare.","['healthcare-customized LLMs like Med-PaLM', 'healthcare-customized LLMs like BioGPT']","The research idea centers on the emerging role and potential of generative artificial intelligence in healthcare, highlighting its applications across medical research, diagnosis, treatment, and patient care. Despite its growing use, there is a lack of detailed studies exploring the full scope and practical implications of these technologies within healthcare settings. The study aims to address this gap by investigating various applications and real-world scenarios where generative AI contributes to fields such as medical imaging, drug discovery, personalized treatment, medical simulation and training, clinical trial optimization, mental health support, healthcare operations, and human movement simulation. The primary objective of the study is to explore and evaluate the applications, real-world use cases, and limitations of generative AI in healthcare, while also discussing challenges related to professional expertise, patient data privacy, system integration, and data bias, and proposing directions for future research in this area."
Engineering,The deep learning applications in IoT-based bio- and medical informatics: a systematic literature review,"Abstract Nowadays, machine learning (ML) has attained a high level of achievement in many contexts. Considering the significance of ML in medical and bioinformatics owing to its accuracy, many investigators discussed multiple solutions for developing the function of medical and bioinformatics challenges using deep learning (DL) techniques. The importance of DL in Internet of Things (IoT)-based bio- and medical informatics lies in its ability to analyze and interpret large amounts of complex and diverse data in real time, providing insights that can improve healthcare outcomes and increase efficiency in the healthcare industry. Several applications of DL in IoT-based bio- and medical informatics include diagnosis, treatment recommendation, clinical decision support, image analysis, wearable monitoring, and drug discovery. The review aims to comprehensively evaluate and synthesize the existing body of the literature on applying deep learning in the intersection of the IoT with bio- and medical informatics. In this paper, we categorized the most cutting-edge DL solutions for medical and bioinformatics issues into five categories based on the DL technique utilized: convolutional neural network , recurrent neural network , generative adversarial network , multilayer perception , and hybrid methods. A systematic literature review was applied to study each one in terms of effective properties, like the main idea, benefits, drawbacks, methods, simulation environment, and datasets. After that, cutting-edge research on DL approaches and applications for bioinformatics concerns was emphasized. In addition, several challenges that contributed to DL implementation for medical and bioinformatics have been addressed, which are predicted to motivate more studies to develop medical and bioinformatics research progressively. According to the findings, most articles are evaluated using features like accuracy, sensitivity, specificity, F -score, latency, adaptability, and scalability.","['convolutional neural network', 'recurrent neural network', 'generative adversarial network', 'hybrid methods']","The research idea centers on addressing the challenges in medical and bioinformatics by improving the ability to analyze and interpret large amounts of complex and diverse data in real time, which is crucial for enhancing healthcare outcomes and increasing efficiency in the healthcare industry. The study recognizes the significance of advanced approaches in supporting various applications such as diagnosis, treatment recommendation, clinical decision support, image analysis, wearable monitoring, and drug discovery. The primary objective of the study is to comprehensively evaluate and synthesize the existing literature on solutions applied at the intersection of the Internet of Things with bio- and medical informatics. This includes categorizing the most advanced approaches for medical and bioinformatics issues, highlighting their effective properties, benefits, drawbacks, and addressing the challenges that influence their implementation to motivate further progressive research in the field."
Engineering,Battery safety: Machine learning-based prognostics,"Lithium-ion batteries play a pivotal role in a wide range of applications, from electronic devices to large-scale electrified transportation systems and grid-scale energy storage. Nevertheless, they are vulnerable to both progressive aging and unexpected failures, which can result in catastrophic events such as explosions or fires. Given their expanding global presence, the safety of these batteries and potential hazards from serious malfunctions are now major public concerns. Over the past decade, scholars and industry experts are intensively exploring methods to monitor battery safety, spanning from materials to cell, pack and system levels and across various spectral, spatial, and temporal scopes. In this Review, we start by summarizing the mechanisms and nature of battery failures. Following this, we explore the intricacies in predicting battery system evolution and delve into the specialized knowledge essential for data-driven, machine learning models. We offer an exhaustive review spotlighting the latest strides in battery fault diagnosis and failure prognosis via an array of machine learning approaches. Our discussion encompasses: (1) supervised and reinforcement learning integrated with battery models, apt for predicting faults/failures and probing into failure causes and safety protocols at the cell level; (2) unsupervised, semi-supervised, and self-supervised learning, advantageous for harnessing vast data sets from battery modules/packs; (3) few-shot learning tailored for gleaning insights from scarce examples, alongside physics-informed machine learning to bolster model generalization and optimize training in data-scarce settings. We conclude by casting light on the prospective horizons of comprehensive, real-world battery prognostics and management.","['supervised learning', 'reinforcement learning', 'unsupervised learning', 'semi-supervised learning', 'self-supervised learning', 'few-shot learning', 'physics-informed machine learning']","The research idea centers on the critical importance of lithium-ion battery safety due to their widespread use in electronic devices, transportation systems, and energy storage, coupled with their susceptibility to aging and unexpected failures that can lead to catastrophic events such as explosions or fires. As these batteries become more prevalent globally, addressing the potential hazards arising from serious malfunctions has become a major public concern. The research objective is to comprehensively review the mechanisms and nature of battery failures and to explore the challenges involved in predicting the evolution of battery systems. The study aims to provide an extensive overview of recent advancements in diagnosing faults and forecasting failures in lithium-ion batteries, with a focus on improving safety protocols at various levels from individual cells to larger battery packs."
Engineering,Chained machine learning model for predicting load capacity and ductility of steel fiber–reinforced concrete beams,"Abstract One of the main issues associated with steel fiber–reinforced concrete (SFRC) beams is the ability to anticipate their flexural response. With a comprehensive grid search, several stacked models (i.e., chained, parallel) consisting of various machine learning (ML) algorithms and artificial neural networks (ANNs) were developed to predict the flexural response of SFRC beams. The flexural performance of SFRC beams under bending was assessed based on 193 experimental specimens from real‐life beam models. The ML techniques were applied to predict SFRC beam responses to bending load as functions of the steel fiber properties, concrete elastic modulus, beam dimensions, and reinforcement details. The accuracy of the models was evaluated using the coefficient of determination (), mean absolute error (MAE), and root mean square error (RMSE) of actual versus predicted values. The findings revealed that the proposed technique exhibited notably superior performance, delivering faster and more accurate predictions compared to both the ANNs and parallel models. Shapley diagrams were used to analyze variable contributions quantitatively. Shapley values show that the chained model prediction of ductility index is highly affected by two other targets (peak load and peak deflection) that show the chained algorithm utilizing the prediction of previous steps for enhancing the prediction of the target feature. The proposed model can be viewed as a function of significant input variables that permit the quick assessment of the likely performance of SFRC beams in bending.","['stacked models (chained)', 'artificial neural networks (ANNs)']","The research addresses the challenge of accurately anticipating the flexural response of steel fiber–reinforced concrete (SFRC) beams, which is a critical issue in understanding their performance under bending loads. This problem is significant due to the complex interaction of factors such as steel fiber properties, concrete elastic modulus, beam dimensions, and reinforcement details that influence the beams' behavior. The primary aim of the study is to develop an approach that enables the reliable prediction of the flexural performance of SFRC beams based on experimental data from real-life beam specimens. The objective is to provide a method that allows for quick and accurate assessment of the likely bending response of SFRC beams, facilitating better design and evaluation in engineering practice."
Engineering,DA-TransUNet: integrating spatial and channel dual attention with transformer U-net for medical image segmentation,"Accurate medical image segmentation is critical for disease quantification and treatment evaluation. While traditional U-Net architectures and their transformer-integrated variants excel in automated segmentation tasks. Existing models also struggle with parameter efficiency and computational complexity, often due to the extensive use of Transformers. However, they lack the ability to harness the image’s intrinsic position and channel features. Research employing Dual Attention mechanisms of position and channel have not been specifically optimized for the high-detail demands of medical images. To address these issues, this study proposes a novel deep medical image segmentation framework, called DA-TransUNet, aiming to integrate the Transformer and dual attention block (DA-Block) into the traditional U-shaped architecture. Also, DA-TransUNet tailored for the high-detail requirements of medical images, optimizes the intermittent channels of Dual Attention (DA) and employs DA in each skip-connection to effectively filter out irrelevant information. This integration significantly enhances the model’s capability to extract features, thereby improving the performance of medical image segmentation. DA-TransUNet is validated in medical image segmentation tasks, consistently outperforming state-of-the-art techniques across 5 datasets. In summary, DA-TransUNet has made significant strides in medical image segmentation, offering new insights into existing techniques. It strengthens model performance from the perspective of image features, thereby advancing the development of high-precision automated medical image diagnosis. The codes and parameters of our model will be publicly available at https://github.com/SUN-1024/DA-TransUnet .","['U-Net architectures', 'Dual Attention mechanisms', 'DA-TransUNet']","The research addresses the challenge of achieving accurate medical image segmentation, which is essential for disease quantification and treatment evaluation. Existing approaches face difficulties related to parameter efficiency and computational complexity, and they do not fully utilize the intrinsic positional and channel features of medical images. The study aims to develop a segmentation framework tailored to the high-detail requirements of medical images by optimizing the use of dual attention mechanisms in the architecture. The primary objective is to enhance the capability to extract relevant image features and improve the performance of medical image segmentation, thereby advancing high-precision automated medical image diagnosis."
Engineering,"Artificial intelligence for geoscience: Progress, challenges and perspectives","Public summary•What does AI bring to geoscience? AI has been accelerating and deepening our understanding of Earth Systems in an unprecedented way, including the atmosphere, lithosphere, hydrosphere, cryosphere, biosphere, anthroposphere and the interactions between spheres.•What are the noteworthy challenges of AI in geoscience? As we embrace the huge potential of AI in geoscience, several challenges arise including reliability and interpretability, ethical issues, data security, and high demand and cost.•What is the future of AI in geoscience? The synergy between traditional principles and modern AI-driven techniques holds immense promise and will shape the trajectory of geoscience in upcoming years.AbstractThis paper explores the evolution of geoscientific inquiry, tracing the progression from traditional physics-based models to modern data-driven approaches facilitated by significant advancements in artificial intelligence (AI) and data collection techniques. Traditional models, which are grounded in physical and numerical frameworks, provide robust explanations by explicitly reconstructing underlying physical processes. However, their limitations in comprehensively capturing Earth's complexities and uncertainties pose challenges in optimization and real-world applicability. In contrast, contemporary data-driven models, particularly those utilizing machine learning (ML) and deep learning (DL), leverage extensive geoscience data to glean insights without requiring exhaustive theoretical knowledge. ML techniques have shown promise in addressing Earth science-related questions. Nevertheless, challenges such as data scarcity, computational demands, data privacy concerns, and the ""black-box"" nature of AI models hinder their seamless integration into geoscience. The integration of physics-based and data-driven methodologies into hybrid models presents an alternative paradigm. These models, which incorporate domain knowledge to guide AI methodologies, demonstrate enhanced efficiency and performance with reduced training data requirements. This review provides a comprehensive overview of geoscientific research paradigms, emphasizing untapped opportunities at the intersection of advanced AI techniques and geoscience. It examines major methodologies, showcases advances in large-scale models, and discusses the challenges and prospects that will shape the future landscape of AI in geoscience. The paper outlines a dynamic field ripe with possibilities, poised to unlock new understandings of Earth's complexities and further advance geoscience exploration.Graphical abstract","['machine learning (ML)', 'deep learning (DL)', 'hybrid models']","The research idea centers on the evolving approaches in geoscientific inquiry, highlighting the limitations of traditional physics-based models in fully capturing the complexities and uncertainties of Earth's systems. There is a recognized need to overcome challenges related to optimizing these models for real-world applicability and addressing the intricate interactions within various Earth spheres. The study acknowledges the potential benefits and difficulties associated with integrating new methodologies to enhance understanding of geoscience phenomena. The primary objective of the study is to provide a comprehensive overview of the progression in geoscientific research paradigms, focusing on the opportunities and challenges that arise from combining established physical principles with emerging approaches. It aims to examine major methodologies, discuss advances in large-scale modeling, and outline the prospects that will influence the future development of geoscience exploration."
Engineering,Optimizing renewable energy systems through artificial intelligence: Review and future prospects,"The global transition toward sustainable energy sources has prompted a surge in the integration of renewable energy systems (RES) into existing power grids. To improve the efficiency, reliability, and economic viability of these systems, the synergistic application of artificial intelligence (AI) methods has emerged as a promising avenue. This study presents a comprehensive review of the current state of research at the intersection of renewable energy and AI, highlighting key methodologies, challenges, and achievements. It covers a spectrum of AI utilizations in optimizing different facets of RES, including resource assessment, energy forecasting, system monitoring, control strategies, and grid integration. Machine learning algorithms, neural networks, and optimization techniques are explored for their role in complex data sets, enhancing predictive capabilities, and dynamically adapting RES. Furthermore, the study discusses the challenges faced in the implementation of AI in RES, such as data variability, model interpretability, and real-time adaptability. The potential benefits of overcoming these challenges include increased energy yield, reduced operational costs, and improved grid stability. The review concludes with an exploration of prospects and emerging trends in the field. Anticipated advancements in AI, such as explainable AI, reinforcement learning, and edge computing, are discussed in the context of their potential impact on optimizing RES. Additionally, the paper envisions the integration of AI-driven solutions into smart grids, decentralized energy systems, and the development of autonomous energy management systems. This investigation provides important insights into the current landscape of AI applications in RES.","['neural networks', 'reinforcement learning']","The global shift toward sustainable energy sources has led to increased integration of renewable energy systems into existing power grids, creating a need to enhance their efficiency, reliability, and economic viability. Addressing the challenges associated with optimizing various aspects of renewable energy systems, such as resource assessment, energy forecasting, system monitoring, control strategies, and grid integration, is critical for advancing sustainable energy deployment. The primary aim of this study is to comprehensively review the current state of research focused on improving renewable energy systems, highlighting key challenges and achievements in optimizing their performance. The study seeks to provide insights into overcoming operational challenges to increase energy yield, reduce costs, and improve grid stability, while exploring future prospects and trends in the field."
Engineering,Dynamic Event-Triggered Control for a Class of Uncertain Strict-Feedback Systems via an Improved Adaptive Neural Networks Backstepping Approach,"This article focuses on a dynamic event-triggered adaptive neural networks backstepping control for a class of uncertain strict-feedback systems with communication constraints. The uncertain terms including external disturbances and unknown nonlinear functions are approximated by radial basis function neural networks, in which the weight update laws are obtained via the gradient descent algorithm, ensuring the local boundedness of the approximation error of neural networks. Then, to enhance the transmission efficiency of control signals, a dynamic event-triggered mechanism is introduced, which enables the dynamic adjustment of threshold parameters in response to the actual tracking performance. It is strictly proved via the Lyapunov stability criterion that the tracking error can converge to a desired small neighborhood of the origin, and all signals in the closed-loop system are bounded. Finally, the validity of the control strategy is demonstrated through a simulation example. <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">Note to Practitioners</i> — In practical network control systems, control signals are typically transmitted continuously or periodically to devices through the communication network in the form of data packets. As communication networks are usually shared by various system nodes, and resources such as communication channel bandwidth and computational capabilities are limited, improving the transmission efficiency of control signals becomes a crucial design problem for controllers in network control systems. Therefore, This study introduces a control method via event-triggered sampling, aiming to enhance sampling efficiency while ensuring the stability and reliability of the system. The proposed control method is suitable for a broad category of strict-feedback nonlinear systems with communication constraints, offering notable advantages such as low-complexity design and straightforward implementation.","['radial basis function neural networks', 'gradient descent algorithm']","The research idea addresses the challenge of improving the transmission efficiency of control signals in network control systems, where communication resources such as channel bandwidth are limited and control signals are typically transmitted continuously or periodically. This limitation creates a crucial design problem for controllers, especially in systems with uncertain dynamics and external disturbances. The study is motivated by the need to enhance sampling efficiency while maintaining system stability and reliability under communication constraints. The research objective is to develop a control approach that dynamically adjusts the transmission of control signals based on actual tracking performance, ensuring that the tracking error converges to a small neighborhood of the origin and that all system signals remain bounded. This approach aims to provide a low-complexity and straightforward solution suitable for a broad class of strict-feedback nonlinear systems operating under communication limitations."
Engineering,Mental-LLM,"Advances in large language models (LLMs) have empowered a variety of applications. However, there is still a significant gap in research when it comes to understanding and enhancing the capabilities of LLMs in the field of mental health. In this work, we present a comprehensive evaluation of multiple LLMs on various mental health prediction tasks via online text data, including Alpaca, Alpaca-LoRA, FLAN-T5, GPT-3.5, and GPT-4. We conduct a broad range of experiments, covering zero-shot prompting, few-shot prompting, and instruction fine-tuning. The results indicate a promising yet limited performance of LLMs with zero-shot and few-shot prompt designs for mental health tasks. More importantly, our experiments show that instruction finetuning can significantly boost the performance of LLMs for all tasks simultaneously. Our best-finetuned models, Mental-Alpaca and Mental-FLAN-T5, outperform the best prompt design of GPT-3.5 (25 and 15 times bigger) by 10.9% on balanced accuracy and the best of GPT-4 (250 and 150 times bigger) by 4.8%. They further perform on par with the state-of-the-art task-specific language model. We also conduct an exploratory case study on LLMs' capability on mental health reasoning tasks, illustrating the promising capability of certain models such as GPT-4. We summarize our findings into a set of action guidelines for potential methods to enhance LLMs' capability for mental health tasks. Meanwhile, we also emphasize the important limitations before achieving deployability in real-world mental health settings, such as known racial and gender bias. We highlight the important ethical risks accompanying this line of research.","['zero-shot prompting', 'few-shot prompting', 'instruction fine-tuning']","The research addresses the significant gap in understanding and improving the capabilities of advanced language technologies in the context of mental health applications. It focuses on evaluating the effectiveness of these technologies in predicting mental health conditions through online text data, highlighting the challenges and limitations in their current performance. The primary objective of the study is to comprehensively assess multiple language technologies on various mental health prediction tasks and to identify approaches that can enhance their accuracy and reliability. Additionally, the study aims to provide guidelines for improving these capabilities while acknowledging important ethical considerations and limitations related to bias and real-world deployment."
Engineering,Human-AI collaboration patterns in AI-assisted academic writing,"Artificial Intelligence (AI) has increasingly influenced higher education, notably in academic writing where AI-powered assisting tools offer both opportunities and challenges. Recently, the rapid growth of generative AI (GAI) has brought its impacts into sharper focus, yet the dynamics of its utilisation in academic writing remain largely unexplored. This paper focuses on examining the nature of human-AI interactions in academic writing, specifically investigating the strategies doctoral students employ when collaborating with a GAI-powered assisting tool. This study involves 626 recorded activities on how ten doctoral students interact with GAI-powered assisting tool during academic writing. AI-driven learning analytics approach was adopted for three layered analyses: (1) data pre-processing and analysis with quantitative content analysis, (2) sequence analysis with Hidden Markov Model (HMM) and hierarchical sequence clustering, and (3) pattern analysis with process mining. Findings indicate that doctoral students engaging in iterative, highly interactive processes with the GAI-powered assisting tool generally achieve better performance in the writing task. In contrast, those who use GAI merely as a supplementary information source, maintaining a linear writing approach, tend to get lower writing performance. This study points to the need for further investigations into human-AI collaboration in learning in higher education, with implications for tailored educational strategies and solutions.",['Hidden Markov Model (HMM)'],"The research addresses the growing influence of advanced assisting tools in academic writing within higher education, highlighting both the opportunities and challenges they present. It focuses on understanding how doctoral students engage with these tools during the writing process, an area that remains largely unexplored. The study aims to examine the nature of interactions between doctoral students and the assisting tool in academic writing, specifically investigating the strategies employed by the students when collaborating with the tool. By analyzing recorded activities of doctoral students, the study seeks to identify patterns of engagement that correlate with writing performance, thereby informing future educational strategies and solutions."
Engineering,FI-NPI: Exploring Optimal Control in Parallel Platform Systems,"Typically, the current and speed loop closure of servo motor of the parallel platform is accomplished with incremental PI regulation. The control method has strong robustness, but the parameter tuning process is cumbersome, and it is difficult to achieve the optimal control state. In order to further optimize the performance, this paper proposes a double-loop control structure based on fuzzy integral and neuron proportional integral (FI-NPI). The structure makes full use of the control advantages of the fuzzy controller and integrator to improve the performance of speed closed-loop control. And through the feedforward branch, the speed error is used as the teacher signal for neuron supervised learning, which improves the effect of current closed-loop control. Through comparative simulation experiments, this paper verifies that the FI-NPI controller has a faster dynamic response speed than the traditional PI controller. Finally, in this paper, the FI-NPI controller is implemented in C language in the servo-driven lower computer, and the speed closed-loop test of the BLDC motor is carried out. The experimental results show that the FI-NPI double-loop controller is better than the traditional double-PI controller in performance indicators such as convergence rate and RMSE, which confirms that the FI-NPI double-loop controller is more suitable for BLDC servo control.",['fuzzy integral'],"The research addresses the challenge of optimizing the current and speed loop closure of servo motors in parallel platforms, where the conventional incremental PI regulation method, despite its robustness, involves a cumbersome parameter tuning process and struggles to achieve optimal control performance. The study aims to enhance the speed closed-loop control performance by proposing a double-loop control structure that leverages the advantages of fuzzy integral and neuron proportional integral components. The primary objective is to improve the dynamic response and overall control effectiveness of the servo motor, specifically for brushless DC (BLDC) motors, by implementing and testing the proposed double-loop controller and demonstrating its superiority over traditional double-PI controllers in terms of convergence rate and error metrics."
Engineering,"A review on microgrid optimization with meta-heuristic techniques: Scopes, trends and recommendation","Microgrids (MGs) use renewable sources to meet the growing demand for energy with increasing consumer needs and technological advancement. They operate independently as small-scale energy networks using distributed energy resources. However, the intermittent nature of renewable energy sources and poor power quality are essential operational problems that must be mitigated to improve the MG's performance. To address these challenges, researchers have introduced heuristic optimization mechanisms for MGs. However, local minima and the inability to find a global minimum in heuristic methods create errors in non-linear and nonconvex optimization, posing challenges in dealing with several operational aspects of MG such as energy management optimization, cost-effective dispatch, dependability, storage sizing, cyber-attack minimization, and grid integration. These challenges affect MG's performance by adding complexity to the management of storage capacity, cost minimization, reliability assurance, and balance of renewable sources, which accelerates the need for meta-heuristic optimization algorithms (MHOAs). This paper presents a state-of-the-art review of MHOAs and their role in improving the operational performance of MGs. Firstly, the fundamentals of MG optimization are discussed to explore the scopes, requisites, and opportunities of MHOAs in MG networks. Secondly, several MHOAs in the MG domain are described, and their recent trends in MG's techno-economic analysis, load forecasting, resiliency improvement, control operation, fault diagnosis, and energy management are summarized. The summary reveals that nearly 25% of the research in these areas utilizes the particle swarm optimization method, while the genetic and grey wolf algorithms are utilized by nearly 10% and 5% of the works studied in this paper, respectively, for optimizing the MG's performance. This result summarizes that MHOA presents a system-agnostic optimization approach, offering a new avenue for enhancing the effectiveness of future MGs. Finally, we highlight some challenges that emerge during the integration of MHOAs into MGs, potentially motivating researchers to conduct further studies in this area.","['genetic algorithm', 'grey wolf algorithm']","The research idea centers on addressing the operational challenges faced by microgrids (MGs) that utilize renewable energy sources, particularly the intermittent nature of these sources and poor power quality, which hinder the overall performance of MGs. These challenges complicate the management of energy storage, cost minimization, reliability, and the balance of renewable energy integration within MGs. The study aims to explore optimization approaches that can overcome issues such as local minima and nonconvex optimization problems affecting various operational aspects like energy management, cost-effective dispatch, dependability, storage sizing, and grid integration. The primary objective of the study is to review and summarize the role of advanced optimization strategies in enhancing the operational performance of microgrids by examining their applications in techno-economic analysis, load forecasting, resiliency improvement, control operation, fault diagnosis, and energy management. Additionally, the study seeks to identify current trends and challenges in applying these optimization approaches to microgrids, thereby providing insights that could guide future research efforts in improving MG effectiveness."
Engineering,A novel Swin transformer approach utilizing residual multi-layer perceptron for diagnosing brain tumors in MRI images,"Abstract Serious consequences due to brain tumors necessitate a timely and accurate diagnosis. However, obstacles such as suboptimal imaging quality, issues with data integrity, varying tumor types and stages, and potential errors in interpretation hinder the achievement of precise and prompt diagnoses. The rapid identification of brain tumors plays a pivotal role in ensuring patient safety. Deep learning-based systems hold promise in aiding radiologists to make diagnoses swiftly and accurately. In this study, we present an advanced deep learning approach based on the Swin Transformer. The proposed method introduces a novel Hybrid Shifted Windows Multi-Head Self-Attention module (HSW-MSA) along with a rescaled model. This enhancement aims to improve classification accuracy, reduce memory usage, and simplify training complexity. The Residual-based MLP (ResMLP) replaces the traditional MLP in the Swin Transformer, thereby improving accuracy, training speed, and parameter efficiency. We evaluate the Proposed-Swin model on a publicly available brain MRI dataset with four classes, using only test data. Model performance is enhanced through the application of transfer learning and data augmentation techniques for efficient and robust training. The Proposed-Swin model achieves a remarkable accuracy of 99.92%, surpassing previous research and deep learning models. This underscores the effectiveness of the Swin Transformer with HSW-MSA and ResMLP improvements in brain tumor diagnosis. This method introduces an innovative diagnostic approach using HSW-MSA and ResMLP in the Swin Transformer, offering potential support to radiologists in timely and accurate brain tumor diagnosis, ultimately improving patient outcomes and reducing risks.","['Swin Transformer', 'Residual-based MLP (ResMLP)', 'transfer learning']","The research addresses the critical challenge of achieving timely and accurate diagnosis of brain tumors, which is essential due to the serious consequences associated with delayed or incorrect identification. Difficulties such as suboptimal imaging quality, variability in tumor types and stages, and potential errors in interpretation complicate the diagnostic process and hinder prompt and precise detection. The primary objective of the study is to develop an enhanced approach that improves the accuracy and efficiency of brain tumor classification, thereby supporting rapid identification. This aims to facilitate better diagnostic outcomes, ultimately improving patient safety and reducing associated risks."
Engineering,Machine learning-based predictive model for thermal comfort and energy optimization in smart buildings,"In the current context of energy transition and increasing climate change, optimizing building performance has become a critical objective. Efficient energy use and occupant comfort are paramount considerations in building design and operation. To address these challenges, this study introduces a predictive model leveraging Machine Learning (ML) algorithms. The model aims to predict thermal comfort levels and optimize energy consumption in Heating, Ventilation, and Air Conditioning (HVAC) systems. Four distinct ML algorithms Support Vector Machine (SVM), Artificial Neural Network (ANN), Random Forest (RF), and EXtreme Gradient Boosting (XGBOOST) are employed for this purpose. Data for the model is collected using a network of Raspberry Pi boards equipped with multiple sensors. Performance evaluation of the ML algorithms is conducted using statistical error metrics, including, Root Mean Square Error (RMSE), Mean Square Error (MSE), Mean Absolute Error (MAE), and coefficient of determination (R2). Results reveal that the RF and XGBOOST algorithms exhibit superior performance, achieving accuracies of 96.7% and 9.64% respectively. In contrast, the SVM algorithm demonstrates inferior performance with a R2 of 81.1%. These findings underscore the predictive capability of the RF and XGBOOST model in forecasting Predicted Mean Vote (PMV) values. The proposed model holds promise for enhancing occupant thermal comfort in buildings while simultaneously optimizing energy consumption in HVAC systems. Further research could explore the practical applications of these findings in building design and operation.","['Support Vector Machine (SVM)', 'Artificial Neural Network (ANN)', 'Random Forest (RF)', 'EXtreme Gradient Boosting (XGBOOST)']","The research addresses the critical need to optimize building performance amid the ongoing energy transition and the challenges posed by climate change. It emphasizes the importance of efficient energy use and maintaining occupant comfort as key factors in building design and operation. The study aims to develop a method to predict thermal comfort levels and improve energy consumption in Heating, Ventilation, and Air Conditioning (HVAC) systems. The primary objective is to enhance occupant thermal comfort in buildings while simultaneously optimizing energy consumption in HVAC systems, thereby contributing to more sustainable and efficient building management."
Engineering,"Big data, machine learning, and digital twin assisted additive manufacturing: A review","Additive manufacturing (AM) has undergone significant development over the past decades, resulting in vast amounts of data that carry valuable information. Numerous research studies have been conducted to extract insights from AM data and utilize it for optimizing various aspects such as the manufacturing process, supply chain, and real-time monitoring. Data integration into proposed digital twin frameworks and the application of machine learning techniques is expected to play pivotal roles in advancing AM in the future. In this paper, we provide an overview of machine learning and digital twin-assisted AM. On one hand, we discuss the research domain and highlight the machine-learning methods utilized in this field, including material analysis, design optimization, process parameter optimization, defect detection and monitoring, and sustainability. On the other hand, we examine the status of digital twin-assisted AM from the current research status to the technical approach and offer insights into future developments and perspectives in this area. This review paper aims to examine present research and development in the convergence of big data, machine learning, and digital twin-assisted AM. Although there are numerous review papers on machine learning for additive manufacturing and others on digital twins for AM, no existing paper has considered how these concepts are intrinsically connected and interrelated. Our paper is the first to integrate the three concepts big data, machine learning, and digital twins and propose a cohesive framework for how they can work together to improve the efficiency, accuracy, and sustainability of AM processes. By exploring latest advancements and applications within these domains, our objective is to emphasize the potential advantages and future possibilities associated with integration of these technologies in AM.",['machine learning'],"The research idea addresses the significant development of additive manufacturing (AM) over recent decades, which has generated extensive information valuable for optimizing various aspects such as the manufacturing process, supply chain, and real-time monitoring. Despite numerous studies focusing on different facets of AM, there is a lack of comprehensive understanding regarding the intrinsic connections and interrelations among the key components influencing AM advancements. The study aims to provide a cohesive overview of current research and development in the integration of these components to enhance the efficiency, accuracy, and sustainability of AM processes. The primary objective of the study is to examine the present state of research in this integrated context and to highlight the potential advantages and future possibilities that arise from combining these elements to improve additive manufacturing."
Engineering,"A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection in Industrial Time Series: Methods, Applications, and Directions","Automating the monitoring of industrial processes has the potential to enhance efficiency and optimize quality by promptly detecting abnormal events and thus facilitating timely interventions. Deep learning, with its capacity to discern non-trivial patterns within large datasets, plays a pivotal role in this process. Standard deep learning methods are suitable to solve a specific task given a specific type of data. During training, deep learning demands large volumes of labeled data. However, due to the dynamic nature of the industrial processes and environment, it is impractical to acquire large-scale labeled data for standard deep learning training for every slightly different case anew. Deep transfer learning offers a solution to this problem. By leveraging knowledge from related tasks and accounting for variations in data distributions, the transfer learning framework solves new tasks with little or even no additional labeled data. The approach bypasses the need to retrain a model from scratch for every new setup and dramatically reduces the labeled data requirement. This survey first provides an in-depth review of deep transfer learning, examining the problem settings of transfer learning and classifying the prevailing deep transfer learning methods. Moreover, we delve into applications of deep transfer learning in the context of a broad spectrum of time series anomaly detection tasks prevalent in primary industrial domains, e.g., manufacturing process monitoring, predictive maintenance, energy management, and infrastructure facility monitoring. We discuss the challenges and limitations of deep transfer learning in industrial contexts and conclude the survey with practical directions and actionable suggestions to address the need to leverage diverse time series data for anomaly detection in an increasingly dynamic production environment.","['deep learning', 'deep transfer learning', 'transfer learning framework']","The research addresses the challenge of monitoring industrial processes efficiently to enhance operational quality by promptly detecting abnormal events, which enables timely interventions. A significant problem is the impracticality of acquiring large volumes of labeled data for every variation in dynamic industrial environments, making traditional approaches less effective for new or slightly different cases. The primary aim of the study is to explore methods that reduce the need for extensive labeled data by leveraging knowledge from related tasks and adapting to variations in data distributions, thereby facilitating anomaly detection across diverse industrial applications such as manufacturing process monitoring, predictive maintenance, energy management, and infrastructure facility monitoring. The study also seeks to identify challenges and limitations within these approaches and provide practical recommendations to improve anomaly detection in dynamic production settings."
Engineering,Predicting the thermal distribution in a convective wavy fin using a novel training physics-informed neural network method,"Abstract Fins are widely used in many industrial applications, including heat exchangers. They benefit from a relatively economical design cost, are lightweight, and are quite miniature. Thus, this study investigates the influence of a wavy fin structure subjected to convective effects with internal heat generation. The thermal distribution, considered a steady condition in one dimension, is described by a unique implementation of a physics-informed neural network (PINN) as part of machine-learning intelligent strategies for analyzing heat transfer in a convective wavy fin. This novel research explores the use of PINNs to examine the effect of the nonlinearity of temperature equation and boundary conditions by altering the hyperparameters of the architecture. The non-linear ordinary differential equation (ODE) involved with heat transfer is reduced into a dimensionless form utilizing the non-dimensional variables to simplify the problem. Furthermore, Runge–Kutta Fehlberg’s fourth–fifth order (RKF-45) approach is implemented to evaluate the simplified equations numerically. To predict the wavy fin's heat transfer properties, an advanced neural network model is created without using a traditional data-driven approach, the ability to solve ODEs explicitly by incorporating a mean squared error-based loss function. The obtained results divulge that an increase in the thermal conductivity variable upsurges the thermal distribution. In contrast, a decrease in temperature profile is caused due to the augmentation in the convective-conductive variable values.",['physics-informed neural network (PINN)'],"The research idea centers on the widespread use of fins in industrial applications such as heat exchangers, highlighting their economical design, lightweight nature, and compact size. This study addresses the need to understand the thermal behavior of wavy fin structures subjected to convective effects with internal heat generation, focusing on how these factors influence heat transfer performance. The primary objective of the study is to investigate the thermal distribution within a wavy fin under steady-state conditions in one dimension, examining the effects of varying thermal conductivity and convective-conductive parameters on temperature profiles. The research aims to provide insights into how changes in these variables impact heat transfer characteristics in wavy fins, thereby contributing to the optimization of fin design for improved thermal management."
Engineering,Enhancing precision agriculture: A comprehensive review of machine learning and AI vision applications in all-terrain vehicle for farm automation,"The automation of all-terrain vehicles (ATVs) through the integration of advanced technologies such as machine learning (ML) and artificial intelligence (AI) vision has significantly changed precision agriculture. This paper aims to analyse and develop trends to provide comprehensive knowledge of the current state of ATV-based precision agriculture and the future possibilities of ML and AI. A bibliometric analysis was conducted through network diagram with keywords taken from previous publications in the domain. This review comprehensively analyses the potential of machine learning and artificial intelligence in transforming farming operations through the automation of tasks and the deployment of all-terrain vehicles. The research extensively analyses how machine learning methods have influenced several aspects of agricultural activities, such as planting, harvesting, spraying, weeding, crop monitoring, and others. AI vision systems are being researched for their ability to enhance precise and prompt decision-making in ATV-driven agricultural automation. These technologies have been thoroughly tested to show how they can improve crop yield, reducing overall investment, and make farming more efficient. Examples include machine learning-based seeding accuracy, AI-enabled crop health monitoring, and the use of AI vision for accurate pesticide application. The assessment examines challenges such as data privacy problems and scalability constraints, along with potential advancements and future prospects in the field. This will assist researchers and practitioners in making well-informed judgments regarding farming practices that are efficient, sustainable, and technologically robust.",['machine learning'],"The research idea centers on the transformation of precision agriculture through the automation of all-terrain vehicles (ATVs), addressing the need for improved efficiency and effectiveness in farming operations such as planting, harvesting, spraying, weeding, and crop monitoring. The study highlights the significance of integrating advanced technologies to enhance crop yield, reduce investment costs, and promote sustainable farming practices. The research objective is to analyze and develop trends in ATV-based precision agriculture by providing a comprehensive understanding of the current state and future possibilities in this domain. It aims to assess the impact of these advancements on farming activities, examine associated challenges such as scalability and privacy concerns, and support informed decision-making for efficient and sustainable agricultural practices."
Engineering,A novel and dynamic land use/cover change research framework based on an improved PLUS model and a fuzzy multiobjective programming model,"Spatial reconstruction and scenario simulation of historical processes and future trends of land use/cover change (LUCC) can help to reveal the historical background of land conversion and the spatial distribution of future land. Moreover, there is a close relationship between the spatiotemporal dynamics of land use/cover and changes in different ecosystem services (ESs). Using this relationship to simulate future land use scenarios is important. In this study, an LUCC dynamic analysis framework (LSTM-PLUS-FMOP) was constructed based on a deep learning time series forecasting model (LSTM), a parallelized urban land use simulation (PLUS) model and a fuzzy multiobjective programming (FMOP) model. The PLUS model was used to analyze the driving mechanism of land expansion and explore the land conversion pattern. In addition, three land conversion scenarios were established: natural land expansion (NLE), economic development priority (EDP) and regional sustainable development (RSD). The FMOP model and the relationship between LUCC and ES were used to perform a spatial simulation of land conversion. The uncertainty parameters in the model were treated by intuitionistic fuzzy numbers (IFSs). This study applied the constructed framework to the Yellow River Basin of Shaanxi Province (YRB-SX). The results showed that (1) from 2000 to 2020, the cropland area of the YRB-SX continuously decreased by 12.67 × 104 ha, while the built-up area continuously increased by 28.25 × 104 ha. The net reduction in woodland and grassland area was 13.90 × 104 ha. (2) The relative error range of land prediction using the LSTM model was 0.0003– 0.0042. This model had better accuracy than the Markov chain prediction model. (3) The cropland area decreased by 0.26% (NLE), 0.85% (EDP) and 1.68% (RSD) under the three scenarios. The built-up area increased by 25.01%, 32.76% and 14.72%, respectively. The RSD scenario followed the principles of ecological protection and spatial constraints, which mitigated the degradation of the ecosystem to some extent. This coupled simulation framework will help to obtain land allocation schemes that meet the requirements of ecological protection and provide solutions for rational land management.",['LSTM'],"The research addresses the challenge of understanding and simulating the spatial and temporal changes in land use and land cover, which are closely linked to variations in ecosystem services. It emphasizes the importance of reconstructing historical land conversion processes and projecting future land distribution to reveal the underlying mechanisms driving land expansion and conversion patterns. The study recognizes the need to explore different land conversion scenarios to support sustainable land management and ecological protection.

The primary objective of the study is to develop and apply a dynamic analysis framework for land use and land cover change in the Yellow River Basin of Shaanxi Province. This framework aims to analyze the driving forces behind land expansion, establish multiple land conversion scenarios, and perform spatial simulations of land conversion to assess their impacts on ecosystem services. The goal is to provide land allocation schemes that balance ecological protection with regional development needs, thereby offering practical solutions for rational land management."
Engineering,Utilizing Hybrid Machine Learning and Soft Computing Techniques for Landslide Susceptibility Mapping in a Drainage Basin,"The hydrological system of thebasin of Lake Urmia is complex, deriving its supply from a network comprising 13 perennial rivers, along withnumerous small springs and direct precipitation onto the lake’s surface. Among these contributors, approximately half of the inflow is attributed to the Zarrineh River and the Simineh River. Remarkably, Lake Urmia lacks a natural outlet, with its water loss occurring solely through evaporation processes. This study employed a comprehensive methodology integrating ground surveys, remote sensing analyses, and meticulous documentation of historical landslides within the basin as primary information sources. Through this investigative approach, we preciselyidentified and geolocated a total of 512 historical landslide occurrences across the Urmia Lake drainage basin, leveraging GPS technology for precision. Thisarticle introduces a suite of hybrid machine learning predictive models, such as support-vector machine (SVM), random forest (RF), decision trees (DT), logistic regression (LR), fuzzy logic (FL), and the technique for order of preference by similarity to the ideal solution (TOPSIS). These models were strategically deployed to assess landslide susceptibility within the region. The outcomes of the landslide susceptibility assessment reveal that the main high susceptible zones for landslide occurrence are concentrated in the northwestern, northern, northeastern, and some southern and southeastern areas of the region. Moreover, when considering the implementation of predictions using different algorithms, it became evident that SVM exhibited superior performance regardingboth accuracy (0.89) and precision (0.89), followed by RF, with and accuracy of 0.83 and a precision of 0.83. However, it is noteworthy that TOPSIS yielded the lowest accuracy value among the algorithms assessed.","['support-vector machine (SVM)', 'random forest (RF)', 'decision trees (DT)', 'logistic regression (LR)']","The hydrological system of the Lake Urmia basin is complex, receiving water from 13 perennial rivers, numerous small springs, and direct precipitation, with about half of the inflow coming from the Zarrineh and Simineh Rivers. Lake Urmia has no natural outlet, and water loss occurs solely through evaporation, making the understanding of factors influencing the basin’s stability critical. This study aims to identify and geolocate historical landslides within the Urmia Lake drainage basin to better understand landslide susceptibility in the region. The primary objective is to assess and map the areas most susceptible to landslides across the basin, particularly focusing on the northwestern, northern, northeastern, southern, and southeastern zones, to inform risk management and mitigation efforts."
Engineering,Comparison of Random Forest and XGBoost Classifiers Using Integrated Optical and SAR Features for Mapping Urban Impervious Surface,"The integration of optical and SAR datasets through ensemble machine learning models shows promising results in urban remote sensing applications. The integration of multi-sensor datasets enhances the accuracy of information extraction. This research presents a comparison of two ensemble machine learning classifiers (random forest and extreme gradient boost (XGBoost)) classifiers using an integration of optical and SAR features and simple layer stacking (SLS) techniques. Therefore, Sentinel-1 (SAR) and Landsat 8 (optical) datasets were used with SAR textures and enhanced modified indices to extract features for the year 2023. The classification process utilized two machine learning algorithms, random forest and XGBoost, for urban impervious surface extraction. The study focused on three significant East Asian cities with diverse urban dynamics: Jakarta, Manila, and Seoul. This research proposed a novel index called the Normalized Blue Water Index (NBWI), which distinguishes water from other features and was utilized as an optical feature. Results showed an overall accuracy of 81% for UIS classification using XGBoost and 77% with RF while classifying land use land cover into four major classes (water, vegetation, bare soil, and urban impervious). However, the proposed framework with the XGBoost classifier outperformed the RF algorithm and Dynamic World (DW) data product and comparatively showed higher classification accuracy. Still, all three results show poor separability with bare soil class compared to ground truth data. XGBoost outperformed random forest and Dynamic World in classification accuracy, highlighting its potential use in urban remote sensing applications.","['ensemble machine learning models', 'random forest', 'extreme gradient boost (XGBoost)']","The study addresses the challenge of accurately extracting urban impervious surfaces by integrating optical and synthetic aperture radar (SAR) datasets, which enhances the precision of information retrieval in urban remote sensing. The motivation stems from the need to improve land use and land cover classification in rapidly changing urban environments, particularly in diverse East Asian cities. The primary objective of the research is to compare the effectiveness of different classification approaches using combined optical and SAR features for urban impervious surface extraction. Additionally, the study aims to introduce and utilize a novel index, the Normalized Blue Water Index (NBWI), to better distinguish water bodies from other land cover types in the classification process."
Engineering,A Multilevel Multimodal Fusion Transformer for Remote Sensing Semantic Segmentation,"Accurate semantic segmentation of remote sensing data plays a crucial role in the success of geoscience research and applications. Recently, multimodal fusion-based segmentation models have attracted much attention due to their outstanding performance as compared to conventional single-modal techniques. However, most of these models perform their fusion operation using convolutional neural networks (CNN) or the vision transformer (Vit), resulting in insufficient local-global contextual modeling and representative capabilities. In this work, a multilevel multimodal fusion scheme called FTransUNet is proposed to provide a robust and effective multimodal fusion backbone for semantic segmentation by integrating both CNN and Vit into one unified fusion framework. Firstly, the shallow-level features are first extracted and fused through convolutional layers and shallow-level feature fusion (SFF) modules. After that, deep-level features characterizing semantic information and spatial relationships are extracted and fused by a well-designed Fusion Vit (FVit). It applies Adaptively Mutually Boosted Attention (Ada-MBA) layers and Self-Attention (SA) layers alternately in a three-stage scheme to learn cross-modality representations of high inter-class separability and low intra-class variations. Specifically, the proposed Ada-MBA computes SA and Cross-Attention (CA) in parallel to enhance intra- and cross-modality contextual information simultaneously while steering attention distribution towards semantic-aware regions. As a result, FTransUNet can fuse shallow-level and deep-level features in a multilevel manner, taking full advantage of CNN and transformer to accurately characterize local details and global semantics, respectively. Extensive experiments confirm the superior performance of the proposed FTransUNet compared with other multimodal fusion approaches on two fine-resolution remote sensing datasets, namely ISPRS Vaihingen and Potsdam. The source code in this work is available at https://github.com/sstary/SSRS.","['convolutional neural networks (CNN)', 'vision transformer (Vit)', 'Self-Attention (SA) layers', 'Cross-Attention (CA)']","The research addresses the challenge of achieving accurate semantic segmentation of remote sensing data, which is essential for advancing geoscience research and its practical applications. Existing multimodal fusion approaches often lack sufficient capability to effectively capture both local details and global contextual information, limiting their performance in representing complex spatial and semantic relationships. The primary objective of the study is to develop a robust and effective multimodal fusion approach that integrates features at multiple levels to enhance the characterization of local details and global semantics in remote sensing imagery. This approach aims to improve the accuracy of semantic segmentation by better capturing semantic information and spatial relationships across different modalities."
Engineering,Firefly algorithm based WSN-IoT security enhancement with machine learning for intrusion detection,"Abstract A Wireless Sensor Network (WSN) aided by the Internet of Things (IoT) is a collaborative system of WSN systems and IoT networks are work to exchange, gather, and handle data. The primary objective of this collaboration is to enhance data analysis and automation to facilitate improved decision-making. Securing IoT with the assistance of WSN necessitates the implementation of protective measures to confirm the safety and reliability of the interconnected WSN and IoT components. This research significantly advances the current state of the art in IoT and WSN security by synergistically harnessing the potential of machine learning and the Firefly Algorithm. The contributions of this work are twofold: firstly, the proposed FA-ML technique exhibits an exceptional capability to enhance intrusion detection accuracy within the WSN-IoT landscape. Secondly, the amalgamation of the Firefly Algorithm and machine learning introduces a novel dimension to the domain of security-oriented optimization techniques. The implications of this research resonate across various sectors, ranging from critical infrastructure protection to industrial automation and beyond, where safeguarding the integrity of interconnected systems are of paramount importance. The amalgamation of cutting-edge machine learning and bio-inspired algorithms marks a pivotal step forward in crafting robust and intelligent security measures for the evolving landscape of IoT-driven technologies. For intrusion detection in the WSN-IoT, the FA-ML method employs a support vector machine (SVM) machine model for classification with parameter tuning accomplished using a Grey Wolf Optimizer (GWO) algorithm. The experimental evaluation is simulated using NSL-KDD Dataset, revealing the remarkable enhancement of the FA-ML technique, achieving a maximum accuracy of 99.34%. In comparison, the KNN-PSO and XGBoost models achieved lower accuracies of 96.42% and 95.36%, respectively. The findings validate the potential of the FA-ML technique as an active security solution for WSN-IoT systems, harnessing the power of machine learning and the Firefly Algorithm to bolster intrusion detection capabilities.","['Firefly Algorithm', 'machine learning', 'support vector machine (SVM)', 'Grey Wolf Optimizer (GWO)', 'XGBoost']","The research idea centers on the need to secure the interconnected components of Wireless Sensor Networks (WSN) and Internet of Things (IoT) networks to ensure their safety and reliability. This collaboration between WSN and IoT aims to enhance data exchange and automation, which are critical for improved decision-making across various sectors such as critical infrastructure protection and industrial automation. The study addresses the challenge of protecting these integrated systems from intrusions that could compromise their integrity. The primary objective of the study is to improve intrusion detection accuracy within the WSN-IoT environment by developing advanced security measures that safeguard the integrity of these interconnected systems. The research aims to introduce innovative approaches that significantly enhance the detection of unauthorized access or attacks, thereby strengthening the overall security framework of WSN-IoT applications."
Engineering,Peak and ultimate stress-strain model of confined ultra-high-performance concrete (UHPC) using hybrid machine learning model with conditional tabular generative adversarial network,"Ultra-high-performance concrete (UHPC) has gained prominence owing to its exceptional physical and mechanical properties and improved sustainability, making it ideal for large-scale structural applications. While numerous analytical studies have focused on predicting the stress-strain response of unconfined UHPC, there remains a lack of a reliable model for predicting the stress-strain response of confined UHPC, which poses challenges to efficient design and broader adoption, particularly in seismically active regions. To bridge this gap, the present study introduces a framework that implements machine learning (ML) models augmented by a state-of-the-art conditional tabular generative adversarial network (CTGAN) and Optuna, which a next-generation optimization framework, to accurately predict the peak and ultimate axial stress-strain responses of UHPC confined with either normal-strength steel or high-strength steel. The Optuna-optimized CTGAN is employed to address the issue of limited data by generating synthetic datasets of hypothetical confined UHPC specimens. A comprehensive database of confined UHPC stress-strain responses was compiled from existing literature and used to condition the CTGAN. The augmented database is then leveraged to develop a hybrid ML model that integrates extreme gradient boosting, gradient boosting machine, support vector regression, and K-nearest neighbors for predicting peak and ultimate stress-strain responses of confined UHPC. The predictive accuracy of the proposed hybrid ML model is evaluated and compared with a diverse set of ML models of varying complexity, and the results demonstrate its superior performance in predicting the peak and ultimate stress-strain response of confined UHPC. Furthermore, a graphical user interface of the proposed model is developed to facilitate its practical implementation and provide a rapid, autonomous, and accurate prediction of the stress-strain response of confined UHPC at both peak and ultimate states.","['conditional tabular generative adversarial network (CTGAN)', 'extreme gradient boosting', 'gradient boosting machine', 'support vector regression', 'K-nearest neighbors']","The research addresses the challenge of accurately predicting the stress-strain response of ultra-high-performance concrete (UHPC) when it is confined, which is critical for efficient design and wider application in large-scale structural projects, especially in seismically active regions. Despite extensive studies on unconfined UHPC, there is a notable lack of reliable approaches for confined UHPC, limiting its practical use and safety assurance under axial loading conditions. The primary aim of the study is to develop a reliable predictive framework for the peak and ultimate axial stress-strain responses of UHPC confined with either normal-strength or high-strength steel. This objective seeks to enhance the understanding and design capabilities for confined UHPC, thereby supporting its broader adoption in structural engineering applications."
Engineering,Sentiment Analysis in the Age of Generative AI,"Abstract In the rapidly advancing age of Generative AI, Large Language Models (LLMs) such as ChatGPT stand at the forefront of disrupting marketing practice and research. This paper presents a comprehensive exploration of LLMs’ proficiency in sentiment analysis, a core task in marketing research for understanding consumer emotions, opinions, and perceptions. We benchmark the performance of three state-of-the-art LLMs, i.e., GPT-3.5, GPT-4, and Llama 2, against established, high-performing transfer learning models. Despite their zero-shot nature, our research reveals that LLMs can not only compete with but in some cases also surpass traditional transfer learning methods in terms of sentiment classification accuracy. We investigate the influence of textual data characteristics and analytical procedures on classification accuracy, shedding light on how data origin, text complexity, and prompting techniques impact LLM performance. We find that linguistic features such as the presence of lengthy, content-laden words improve classification performance, while other features such as single-sentence reviews and less structured social media text documents reduce performance. Further, we explore the explainability of sentiment classifications generated by LLMs. The findings indicate that LLMs, especially Llama 2, offer remarkable classification explanations, highlighting their advanced human-like reasoning capabilities. Collectively, this paper enriches the current understanding of sentiment analysis, providing valuable insights and guidance for the selection of suitable methods by marketing researchers and practitioners in the age of Generative AI.","['GPT-3.5', 'GPT-4', 'Llama 2', 'transfer learning models']","The research addresses the challenge of accurately understanding consumer emotions, opinions, and perceptions through sentiment analysis, which is a fundamental task in marketing research. It focuses on evaluating the effectiveness of different approaches in classifying sentiment from textual data, considering factors such as text complexity and data origin that influence classification accuracy. The primary aim of the study is to benchmark the performance of various advanced language-based approaches against established methods in sentiment classification, examining how linguistic features and text characteristics affect their accuracy. Additionally, the study seeks to provide insights into the interpretability of sentiment classifications to enhance the understanding and application of sentiment analysis in marketing contexts."
Engineering,Multi-Source and Multi-modal Deep Network Embedding for Cross-Network Node Classification,"In recent years, to address the issue of networked data sparsity in node classification tasks, cross-network node classification (CNNC) leverages the richer information from a source network to enhance the performance of node classification in the target network, which typically has sparser information. However, in real-world applications, labeled nodes may be collected from multiple sources with multiple modalities (e.g., text, vision, and video). Naive application of single-source and single-modal CNNC methods may result in sub-optimal solutions. To this end, in this article, we propose a model called Multi-source and Multi-modal Cross-network Deep Network Embedding (M 2 CDNE) for cross-network node classification. In M 2 CDNE, we propose a deep multi-modal network embedding approach that combines the extracted deep multi-modal features to make the node vector representations network invariant. In addition, we apply dynamic adversarial adaptation to assess the significance of marginal and conditional probability distributions between each source and target network to make node vector representations label discriminative. Furthermore, we devise to classify nodes in the target network through the related source classifier and aggregate different predictions utilizing respective network weights, corresponding to the discrepancy between each source and target network. Extensive experiments performed on real-world datasets demonstrate that the proposed M 2 CDNE significantly outperforms the state-of-the-art approaches.",['deep multi-modal network embedding'],"The research addresses the challenge of sparse information in networked data for node classification tasks, where leveraging richer information from multiple source networks with various modalities can improve classification performance in a target network. The study highlights the limitations of existing approaches that rely on single-source and single-modal data, which may lead to sub-optimal results in practical applications involving diverse data types such as text, vision, and video. The primary objective of the study is to enhance node classification in target networks by effectively utilizing labeled nodes collected from multiple sources and modalities. This involves developing a method to integrate multi-modal information from different networks to improve the accuracy and reliability of node classification outcomes."
Engineering,A vehicular network based intelligent transport system for smart cities using machine learning algorithms,"Abstract Smart cities and the Internet of Things have enabled the integration of communicating devices for efficient decision-making. Notably, traffic congestion is one major problem faced by daily commuters in urban cities. In developed countries, specialized sensors are deployed to gather traffic information to predict traffic patterns. Any traffic updates are shared with the commuters via the Internet. Such solutions become impracticable when physical infrastructure and Internet connectivity are either non-existent or very limited. In case of developing countries, no roadside units are available and Internet connectivity is still an issue in remote areas. Internet traffic analysis is a thriving field of study due to the myriad ways in which it may be put to practical use. In the intelligent Internet-of-Vehicles (IOVs), traffic congestion can be predicted and identified using cutting-edge technologies. Using tree-based decision-tree, random-forest, extra-tree, and XGBoost machine learning (ML) strategies, this research proposes an intelligent-transport-system for the IOVs-based vehicular network traffic in a smart city set-up. The suggested system uses ensemble learning and averages the selection of crucial features to give high detection accuracy at minimal computational costs, as demonstrated by the simulation results. For IOV-based vehicular network traffic, the tree-based ML approaches with feature-selection (FS) outperformed those without FS. When contrasted to the lowest KNN accuracy of 96.6% and the highest SVM accuracy of 98.01%, the Stacking approach demonstrates superior accuracy as 99.05%.","['decision-tree', 'random-forest', 'extra-tree', 'XGBoost', 'ensemble learning', 'feature-selection (FS)', 'KNN', 'SVM', 'Stacking']","The research addresses the significant challenge of traffic congestion faced by daily commuters in urban cities, particularly highlighting the limitations of existing traffic monitoring solutions in developing countries where physical infrastructure and Internet connectivity are inadequate or absent. The study is motivated by the need for effective traffic information gathering and dissemination methods that can function in environments with limited roadside units and poor Internet access. The primary aim of the study is to develop an intelligent transport approach for vehicular network traffic within a smart city context that enhances the detection and prediction of traffic congestion. This objective focuses on improving traffic management by utilizing advanced strategies to achieve high accuracy in traffic condition identification while minimizing resource requirements."
Engineering,Conventional to Deep Ensemble Methods for Hyperspectral Image Classification: A Comprehensive Survey,"Hyperspectral image classification has become a hot research topic. HSI has been widely used in a wide range of real-world application areas due to the in-depth spectral information stored within each pixel. Noticeably, the detailed features - i.e., a nonlinear correlation between the obtained spectral data and the correlating HSI data object, generate efficient classification results that are complex for traditional techniques. Deep Learning (DL) has recently been validated as an influential feature extractor that efficiently identifies the nonlinear issues that have arisen in various computer vision challenges. This motivates using DL for Hyperspectral Image Classification (HSIC), which shows promising results. This survey provides a brief description of DL for HSIC and compares cutting-edge methodologies in the field. We will first summarize the key challenges for HSIC, and then we will discuss the superiority of DL and DL-ensemble in addressing these issues. In this article, we divide the state-of-the-art DL methodologies and DL with ensemble into spectral features, spatial features, and combined spatial-spectral features in order to comprehensively and critically evaluate the progress (future research directions as well) of such methodologies for HSIC. Furthermore, we will take into account that DL involves a substantial percentage of labeled training images, whereas obtaining such a number for HSI is time and cost-consuming. As a result, this survey describes some methodologies for improving the classification performance of DL techniques, which can serve as future recommendations.",['Deep Learning (DL)'],"The research idea centers on the challenge of classifying hyperspectral images, which contain detailed spectral information within each pixel that is crucial for various real-world applications. Traditional techniques struggle to effectively handle the complex nonlinear relationships present in the spectral data, making accurate classification difficult. The study is motivated by the need to address these challenges and improve the classification performance of hyperspectral images. The primary objective of the study is to provide a comprehensive overview of current methodologies for hyperspectral image classification, summarize the key challenges in the field, and evaluate the progress and future directions for improving classification accuracy, particularly considering the limitations related to the availability of labeled training images."
Engineering,Business analytics and decision science: A review of techniques in strategic business decision making,"Business analytics and decision science have emerged as pivotal domains in enhancing strategic business decision-making processes. This review delves into various techniques that organizations employ to optimize their operations and achieve competitive advantages. At the forefront of strategic decision-making is data analytics, where vast amounts of data are analyzed to extract valuable insights. Descriptive analytics provides a historical perspective by examining past data trends, enabling businesses to understand their performance over time. This retrospective analysis serves as a foundation for predictive analytics, which utilizes statistical models and machine learning algorithms to forecast future trends and outcomes. By leveraging predictive analytics, organizations can anticipate market shifts, customer preferences, and potential risks, thereby making informed decisions. Prescriptive analytics uses predictive models to guide strategic decision-making, utilizing optimization algorithms and simulation tools to identify optimal actions. Decision science integrates analytical techniques with human judgment, focusing on consumer behavior and psychological factors to tailor marketing strategies and product offerings. Additionally, artificial intelligence (AI) and machine learning (ML) technologies are revolutionizing strategic decision-making by automating complex tasks and providing real-time insights. Natural language processing (NLP) algorithms analyze unstructured data sources, such as customer reviews and social media posts, to extract valuable information and sentiment analysis. This enables businesses to gauge customer satisfaction levels and identify areas for improvement promptly. Decision trees, regression analysis, and clustering techniques are widely used in business analytics to segment customers, identify patterns, forecast sales trends, evaluate alternatives, assess risks, and optimize resource allocation. In conclusion, business analytics and decision science offer a plethora of techniques that empower organizations to make informed, data-driven decisions. By leveraging descriptive, predictive, and prescriptive analytics, along with AI and ML technologies, businesses can navigate complex environments, capitalize on opportunities, and mitigate risks effectively. This review underscores the importance of integrating analytical techniques with human expertise to achieve strategic objectives and sustainable growth.","['decision trees', 'regression analysis', 'clustering techniques']","The research idea centers on the critical role of business analytics and decision science in enhancing strategic business decision-making processes to optimize operations and achieve competitive advantages. It addresses the need for organizations to understand past performance, anticipate future trends, and identify optimal actions to navigate complex business environments effectively. The study highlights the importance of integrating analytical insights with human judgment to tailor strategies that respond to consumer behavior and market dynamics. The primary objective of the study is to review and elucidate various techniques employed by organizations to improve strategic decision-making, enabling them to capitalize on opportunities, mitigate risks, and promote sustainable growth through informed and effective business practices."
Engineering,NAVIGATING THE FUTURE: INTEGRATING AI AND MACHINE LEARNING IN HR PRACTICES FOR A DIGITAL WORKFORCE,"As organizations navigate the complexities of the digital age, the role of Human Resources (HR) is evolving to meet the demands of a digital workforce. This review explores the integration of Artificial Intelligence (AI) and Machine Learning (ML) in HR practices to enhance efficiency, effectiveness, and employee satisfaction in the digital era. AI and ML technologies offer HR departments the opportunity to streamline operations, improve decision-making processes, and enhance employee experiences. By leveraging AI and ML, HR professionals can automate routine tasks such as recruitment, onboarding, training, and performance evaluation, allowing them to focus on more strategic initiatives that drive organizational success. One of the key advantages of integrating AI and ML in HR practices is the ability to personalize employee experiences. These technologies can analyze large volumes of data to identify patterns and trends, enabling HR professionals to tailor programs and policies to meet the unique needs of individual employees. This personalization can lead to higher levels of employee engagement, satisfaction, and retention. Furthermore, AI and ML can help HR departments make more informed decisions by providing data-driven insights. These technologies can analyze employee data to identify areas for improvement, predict future trends, and develop strategies to address challenges proactively. By leveraging these insights, HR professionals can make strategic decisions that align with the organization's goals and objectives. However, integrating AI and ML in HR practices also presents challenges, such as data privacy concerns, ethical considerations, and the need for upskilling HR professionals to use these technologies effectively. Organizations must address these challenges to realize the full potential of AI and ML in HR practices. In conclusion, integrating AI and ML in HR practices offers organizations the opportunity to enhance efficiency, effectiveness, and employee satisfaction in the digital age. By leveraging these technologies, HR departments can streamline operations, personalize employee experiences, and make more informed decisions that drive organizational success. As organizations increasingly turn to digital solutions, the role of artificial intelligence (AI) and machine learning (ML) in Human Resources becomes pivotal. This paper will focus on how AI and ML are being integrated into HR functions such as recruitment, onboarding, and employee engagement. It will also discuss the ethical implications and the challenges of maintaining human touch in an increasingly automated workplace. Case studies of companies leading in digital HR practices will be highlighted to provide real-world insights. Keywords: Digital Force, HR Practices, AI, Machine Learning, Future.",['Machine Learning (ML)'],"The research addresses the evolving role of Human Resources (HR) in response to the demands of a digital workforce, focusing on how HR practices can be enhanced to improve efficiency, effectiveness, and employee satisfaction in the digital era. It highlights the need for HR departments to streamline operations, personalize employee experiences, and make more informed decisions to better support organizational success. The primary aim of the study is to explore the integration of advanced technologies in HR functions such as recruitment, onboarding, training, and performance evaluation, while also examining the ethical considerations and challenges involved in maintaining a human-centered approach within increasingly automated HR environments. The study seeks to provide insights into how these integrations can drive strategic initiatives and improve overall HR outcomes in organizations adapting to digital transformation."
Engineering,AI-Driven Digital Twin Model for Reliable Lithium-Ion Battery Discharge Capacity Predictions,"The present study proposes a novel method for predicting the discharge capabilities of lithium-ion (Li-ion) batteries using a digital twin model in practice. By combining cutting-edge machine learning techniques, such as AdaBoost and long short-term memory (LSTM) network, with a semiempirical mathematical structure, the digital twin (DT)—a virtual representation that mimics the behavior of actual batteries in real time is constructed. Various metaheuristic optimization methods, such as antlion, grey wolf optimization (GWO), and improved grey wolf optimization (IGWO), are used to adjust hyperparameters in order to optimize the models. As indicators of performance, mean absolute error (MAE) and root-mean-square error (RMSE) are applied to the models after they have undergone extensive training and ten-fold cross-validation. The models are rigorously trained and cross-validated using the NASA battery aging dataset, a widely accepted benchmark dataset for battery research. The IGWO-AdaBoost digital twin model emerges as the standout performer, achieving exceptional accuracy in predicting the discharge capacity. This model demonstrates the lowest mean absolute error (MAE) of 0.01, showcasing its superior precision in estimating discharge capabilities. Additionally, the root mean square error (RMSE) for the IGWO-AdaBoost DT model is also the lowest at 0.01. The findings of this study offer insightful information about the potential utilization of the digital twin model to accurately predict the discharge capacity of batteries.","['AdaBoost', 'long short-term memory (LSTM) network', 'antlion optimization', 'grey wolf optimization (GWO)', 'improved grey wolf optimization (IGWO)']","The study addresses the challenge of accurately predicting the discharge capabilities of lithium-ion batteries, which is crucial for enhancing battery performance and reliability in practical applications. Understanding and forecasting battery discharge behavior is essential for optimizing battery usage and extending its lifespan. The primary aim of the study is to develop a method that can precisely estimate the discharge capacity of lithium-ion batteries by constructing a virtual representation that closely mimics the real-time behavior of actual batteries. This approach seeks to provide accurate and reliable predictions of battery discharge performance to support better battery management and utilization."
Engineering,Multi-USV Task Planning Method Based on Improved Deep Reinforcement Learning,"A safe and reliable task planning method is a prerequisite for the collaborative execution of ocean observation data collection tasks by multiple unmanned surface vessels (multi-USVs). Deep Reinforcement Learning (DRL) combines the powerful nonlinear function-fitting capabilities of deep neural networks with the decision-making and control abilities of reinforcement learning, providing a novel approach to solving the multi-USV task planning problem. However, when applied to the field of multi-USV task planning, it faces challenges such as a vast exploration space, extended training times, and unstable training process. To this end, this paper proposes a multi-USV task planning method based on improved deep reinforcement learning. The proposed method draws on the idea of a value decomposition network, breaking down the multi-USV task planning problem into two subproblems: task allocation and autonomous collision avoidance. Different state spaces, action spaces, and reward functions are designed for the various subproblems. Based on this, a deep neural network is used to map the state space of each subproblem to the action space of each USV, and the generated strategy of the deep neural network is assessed based on the corresponding reward function. This successfully integrates task allocation and path planning into a comprehensive task planning framework. Deep neural networks consist of the Actor networks and the Critic networks. During the training phase of the Critic network, different methods are used to train different Critic networks to improve the convergence speed of the algorithm. An improved temporal difference error method is specifically applied to train the Critic network for evaluating autonomous collision avoidance strategies, resulting in improving the autonomous collision avoidance ability of USVs. At the same time, to improve the efficiency of task allocation, hierarchical mechanisms, and regional division mechanisms are introduced to construct sub-system task planning models, which further decompose the task planning problem. A combination of successor features and an improved temporal difference error method is specifically applied to train another Critic network for evaluating the sub-systems task allocation schemes and collaborative motion trajectories, aiming to enhance the allocation efficiency of the sub-systems. Furthermore, transfer learning is employed to merge the sub-system task planning, using it as a constraint to direct the exploration and assessment of both the cluster task allocation schemes and the cluster collaborative motion trajectories. This enables rapid and accurate learning for task allocation within the multi-USV cluster. During the training phase of the Actor network, the introduction of the experience replay method and target network technique is employed to enhance the proximal policy optimization algorithm. This facilitates distributed joint training of the Actor network, thereby improving the accuracy of the algorithm. Simulation results validate the effectiveness and superiority of this method.","['Deep Reinforcement Learning (DRL)', 'deep neural network', 'Actor networks', 'Critic networks', 'successor features', 'transfer learning', 'experience replay method', 'target network technique', 'proximal policy optimization algorithm']","The research addresses the challenge of safely and reliably planning tasks for multiple unmanned surface vessels (multi-USVs) engaged in collaborative ocean observation data collection. It focuses on overcoming difficulties such as vast exploration spaces, extended training times, and instability in the task planning process to ensure effective coordination among the vessels. The primary aim of the study is to develop a comprehensive task planning approach that integrates task allocation and autonomous collision avoidance for multi-USVs. This approach seeks to improve the efficiency and accuracy of task distribution and path planning within multi-USV clusters, ultimately enhancing their collaborative execution capabilities."
Engineering,Automated data processing and feature engineering for deep learning and big data applications: A survey,"Modern approach to artificial intelligence (AI) aims to design algorithms that learn directly from data. This approach has achieved impressive results and has contributed significantly to the progress of AI, particularly in the sphere of supervised deep learning. It has also simplified the design of machine learning systems as the learning process is highly automated. However, not all data processing tasks in conventional deep learning pipelines have been automated. In most cases data has to be manually collected, preprocessed and further extended through data augmentation before they can be effective for training. Recently, special techniques for automating these tasks have emerged. The automation of data processing tasks is driven by the need to utilize large volumes of complex, heterogeneous data for machine learning and big data applications. Today, end-to-end automated data processing systems based on automated machine learning (AutoML) techniques are capable of taking raw data and transforming them into useful features for Big Data tasks by automating all intermediate processing stages. In this work, we present a thorough review of approaches for automating data processing tasks in deep learning pipelines, including automated data preprocessing– e.g., data cleaning, labeling, missing data imputation, and categorical data encoding–as well as data augmentation (including synthetic data generation using generative AI methods) and feature engineering–specifically, automated feature extraction, feature construction and feature selection. In addition to automating specific data processing tasks, we discuss the use of AutoML methods and tools to simultaneously optimize all stages of the machine learning pipeline.","['supervised deep learning', 'automated machine learning (AutoML)', 'synthetic data generation using generative AI methods', 'feature construction', 'feature selection']","The research addresses the challenge of managing and preparing large volumes of complex and heterogeneous data for effective use in advanced data processing tasks. It highlights the need to automate various stages of data handling, such as collection, preprocessing, and augmentation, which are traditionally performed manually and can be time-consuming and labor-intensive. The study is motivated by the importance of streamlining these processes to improve efficiency and effectiveness in handling extensive datasets. The primary objective of the study is to review and evaluate approaches for automating data processing tasks, including data cleaning, labeling, missing data imputation, categorical data encoding, data augmentation, and feature engineering. Additionally, the study aims to explore methods that optimize all stages of the data preparation pipeline to enhance the overall workflow in managing complex data."
Engineering,Data-driven evolution of water quality models: An in-depth investigation of innovative outlier detection approaches-A case study of Irish Water Quality Index (IEWQI) model,"Recently, there has been a significant advancement in the water quality index (WQI) models utilizing data-driven approaches, especially those integrating machine learning and artificial intelligence (ML/AI) technology. Although, several recent studies have revealed that the data-driven model has produced inconsistent results due to the data outliers, which significantly impact model reliability and accuracy. The present study was carried out to assess the impact of data outliers on a recently developed Irish Water Quality Index (IEWQI) model, which relies on data-driven techniques. To the author's best knowledge, there has been no systematic framework for evaluating the influence of data outliers on such models. For the purposes of assessing the outlier impact of the data outliers on the water quality (WQ) model, this was the first initiative in research to introduce a comprehensive approach that combines machine learning with advanced statistical techniques. The proposed framework was implemented in Cork Harbour, Ireland, to evaluate the IEWQI model's sensitivity to outliers in input indicators to assess the water quality. In order to detect the data outlier, the study utilized two widely used ML techniques, including Isolation Forest (IF) and Kernel Density Estimation (KDE) within the dataset, for predicting WQ with and without these outliers. For validating the ML results, the study used five commonly used statistical measures. The performance metric (R2) indicates that the model performance improved slightly (R2 increased from 0.92 to 0.95) in predicting WQ after removing the data outlier from the input. But the IEWQI scores revealed that there were no statistically significant differences among the actual values, predictions with outliers, and predictions without outliers, with a 95% confidence interval at p < 0.05. The results of model uncertainty also revealed that the model contributed <1% uncertainty to the final assessment results for using both datasets (with and without outliers). In addition, all statistical measures indicated that the ML techniques provided reliable results that can be utilized for detecting outliers and their impacts on the IEWQI model. The findings of the research reveal that although the data outliers had no significant impact on the IEWQI model architecture, they had moderate impacts on the rating schemes' of the model. This finding indicated that detecting the data outliers could improve the accuracy of the IEWQI model in rating WQ as well as be helpful in mitigating the model eclipsing problem. In addition, the results of the research provide evidence of how the data outliers influenced the data-driven model in predicting WQ and reliability, particularly since the study confirmed that the IEWQI model's could be effective for accurately rating WQ despite the presence of the data outliers in the input. It could occur due to the spatio-temporal variability inherent in WQ indicators. However, the research assesses the influence of data input outliers on the IEWQI model and underscores important areas for future investigation. These areas include expanding temporal analysis using multi-year data, examining spatial outlier patterns, and evaluating detection methods. Moreover, it is essential to explore the real-world impacts of revised rating categories, involve stakeholders in outlier management, and fine-tune model parameters. Analysing model performance across varying temporal and spatial resolutions and incorporating additional environmental data can significantly enhance the accuracy of WQ assessment. Consequently, this study offers valuable insights to strengthen the IEWQI model's robustness and provides avenues for enhancing its utility in broader WQ assessment applications. Moreover, the study successfully adopted the framework for evaluating how data input outliers affect the data-driven model, such as the IEWQI model. The current study has been carried out in Cork Harbour for only a single year of WQ data. The framework should be tested across various domains for evaluating the response of the IEWQI model's in terms of the spatio-temporal resolution of the domain. Nevertheless, the study recommended that future research should be conducted to adjust or revise the IEWQI model's rating schemes and investigate the practical effects of data outliers on updated rating categories. However, the study provides potential recommendations for enhancing the IEWQI model's adaptability and reveals its effectiveness in expanding its applicability in more general WQ assessment scenarios.",['Isolation Forest (IF)'],"The research addresses the challenge of inconsistent results in water quality assessment due to the presence of data outliers, which affect the reliability and accuracy of the Irish Water Quality Index (IEWQI) model. Despite advancements in water quality evaluation, there has been no systematic approach to understanding how these outliers influence the model’s performance and rating schemes. The study aims to assess the impact of data outliers on the IEWQI model’s ability to rate water quality accurately. It seeks to evaluate the sensitivity of the IEWQI model to outliers in input indicators and to provide insights into improving the model’s robustness and rating accuracy for water quality assessment, particularly within the context of Cork Harbour, Ireland."
Engineering,Predicting the mechanical properties of plastic concrete: An optimization method by using genetic programming and ensemble learners,"This study presents a comparative analysis of individual and ensemble learning algorithms (ELAs) to predict the compressive strength (CS) and flexural strength (FS) of plastic concrete. Multilayer perceptron neuron network (MLPNN), Support vector machine (SVM), random forest (RF), and decision tree (DT) were used as base learners, which were then combined with bagging and Adaboost methods to improve the predictive performance. In addition, gene expression programming (GEP) was used to develop computational equations that can be used to predict the CS and FS of plastic concrete. An extensive database containing 357 and 125 data points was obtained from the literature, and the eight most impactful ingredients were used in the model's development. The accuracy of all models was assessed using several statistical measures, including an error matrix, Akaike information criterion (AIC), K-fold cross-validation, and other external validation equations. Furthermore, sensitivity and SHAP analysis were performed to evaluate input variables' relative significance and impact on the anticipated CS and FS. Based on statistical measures and other validation criteria, GEP outpaces all other individual models, whereas, in ELAs, the SVR ensemble with Adaboost and RF modified with the Bagging technique demonstrated superior performance. SHapley Additive exPlanations (SHAP) and sensitivity analysis reveal that plastic, cement, water, and the age of the specimens have the highest influence, while superplasticizer has the lowest impact, which is consistent with experimental studies. Moreover, GUI and GEP-based simple mathematical correlation can enhance the practical scope of this study and be an effective tool for the pre-mix design of plastic concrete.","['Multilayer perceptron neuron network (MLPNN)', 'Support vector machine (SVM)', 'random forest (RF)', 'decision tree (DT)', 'bagging', 'Adaboost', 'gene expression programming (GEP)', 'SHapley Additive exPlanations (SHAP)']","The research addresses the challenge of accurately predicting the compressive strength and flexural strength of plastic concrete, which are critical properties for ensuring the material's performance and durability in construction applications. Understanding the influence of various ingredients on these strength parameters is essential for optimizing the mix design and improving the quality of plastic concrete. The primary aim of the study is to develop reliable predictive equations and comparative assessments that can estimate the compressive and flexural strength of plastic concrete based on key ingredient proportions and specimen age. This objective seeks to provide practical tools that enhance the pre-mix design process and support better decision-making in concrete formulation."
Engineering,Groundwater level prediction using an improved SVR model integrated with hybrid particle swarm optimization and firefly algorithm,"The demand for water resources has increased due to rapid increase of metropolitan areas brought on by growth in population and industrialisation. In addition, the groundwater recharge is being afftected by shifting land use pattern caused by urban development. Using precise and trustworthy estimates of groundwater level is vital for the sustainable groundwater resources management in the face of changing climatic circumstances. In this context, machine learning (ML) methods offer a new and promising approach for accurately forecasting long-term changes in the groundwater level (GWL) without computational effort of developing a comprehensive flow model. In order to simulate GWL, five data-driven (DD) models, including the hybridization of support vector regression (SVR) with two optimisation algorithms i.e., firefly algorithm and particle swarm optimisation (FFAPSO), SVR-FFA, SVR-PSO, SVR and Multilayer perception (MLP), have been examined in the present study. Spatial clustering was utilised to choose four observation wells within Cuttack district in order to study and assess the water levels. Six scenarios were created by incorporating numerous variables, such as GWL in the previous months, evapotranspiration, temperature, precipitation, and river discharge. The goal was to identify the variables that were most efficient in predicting GWL. The SVR-FFAPSO model performs best in GWL forecasting for Khuntuni station, according to the quantitative analysis with correlation coefficient (R) = 0.9978, Nash–Sutcliffe efficiency (NSE) = 0.9933, mean absolute error (MAE) = 0.00025 (m), root mean squared error (RMSE) = 0.00775 (m) during the training phase. It is advised that groundwater monitoring network and data collecting system are strengthen in India for ensuring effective modelling of long-term management of groundwater resources.","['support vector regression (SVR)', 'firefly algorithm', 'SVR-PSO']","The study addresses the increasing demand for water resources driven by rapid urbanization and industrial growth, which has also impacted groundwater recharge due to changing land use patterns. Accurate estimation of groundwater levels is crucial for sustainable management of groundwater resources, especially under changing climatic conditions. The primary aim of the study is to simulate and forecast long-term changes in groundwater levels by examining various influencing factors such as previous groundwater levels, evapotranspiration, temperature, precipitation, and river discharge. The research seeks to identify the most effective variables for predicting groundwater levels to support improved groundwater resource management and recommends strengthening groundwater monitoring and data collection networks in India for this purpose."
Engineering,Machine learning-assisted in-situ adaptive strategies for the control of defects and anomalies in metal additive manufacturing,"In metal additive manufacturing (AM), the material microstructure and part geometry are formed incrementally. Consequently, the resulting part could be defect- and anomaly-free if sufficient care is taken to deposit each layer under optimal process conditions. Conventional closed-loop control (CLC) engineering solutions which sought to achieve this were deterministic and rule-based, thus resulting in limited success in the stochastic environment experienced in the highly dynamic AM process. On the other hand, emerging machine learning (ML) based strategies are better suited to providing the robustness, scope, flexibility, and scalability required for process control in an uncertain environment. Offline ML models that help optimise AM process parameters before a build begins and online ML models that efficiently processed in-situ sensory data to detect and diagnose flaws in real-time (or near-real-time) have been developed. However, ML models that enable a process to take evasive or corrective actions in relation to flaws via on the fly decision-making are only emerging. These models must possess prognostic capabilities to provide context-sensitive recommendations for in-situ process control based on real-time diagnostics. In this article, we pinpoint the shortcomings in traditional CLC strategies, and provide a framework for defect and anomaly control through ML-assisted CLC in AM. We discuss flaws in terms of their causes, in-situ detectability, and controllability, and examine their management under three scenarios: avoidance, mitigation, and repair. Then, we summarise the research into ML models developed for offline optimisation and in-situ diagnosis before initiating a detailed conversation on the implementation of ML-assisted in-situ process control. We found that researchers favoured reinforcement learning approaches or inverse ML models for making rapid, situation-aware control decisions. We also observed that, to-date, the defects addressed were those that may be quantified relatively easily autonomously, and that mitigation (rather than avoidance or repair) was the aim of ML-assisted in-situ control strategies. Additionally, we highlight the various technologies that must seamlessly combine to advance the field of autonomous in-situ control so that it becomes a reality in industrial settings. Finally, we raise awareness of seldom discussed, yet highly pertinent, topics relevant to adaptive control. Our work closes a significant gap in the current AM literature by broaching wide-ranging discussions on matters relevant to in-situ adaptive control in AM.","['online ML models', 'reinforcement learning approaches']","The research idea centers on the challenge of achieving defect- and anomaly-free parts in metal additive manufacturing by carefully controlling the deposition of each layer under optimal process conditions. Traditional closed-loop control methods have shown limited success due to the highly dynamic and stochastic nature of the additive manufacturing process. There is a need for more robust and flexible approaches to manage defects and anomalies during the build process to improve part quality and reliability. The study addresses the shortcomings of existing control strategies and explores advanced approaches for in-situ defect management.

The primary objective of the study is to provide a comprehensive framework for defect and anomaly control in metal additive manufacturing through enhanced closed-loop control strategies. It aims to examine the causes, detectability, and controllability of flaws and to manage them under scenarios of avoidance, mitigation, and repair. The study seeks to advance the implementation of adaptive in-situ process control to enable real-time decision-making for flaw management, thereby closing a significant gap in the current understanding and practice of process control in additive manufacturing."
Engineering,A comprehensive evaluation of large Language models on benchmark biomedical text processing tasks,"Recently, Large Language Models (LLMs) have demonstrated impressive capability to solve a wide range of tasks. However, despite their success across various tasks, no prior work has investigated their capability in the biomedical domain yet. To this end, this paper aims to evaluate the performance of LLMs on benchmark biomedical tasks. For this purpose, a comprehensive evaluation of 4 popular LLMs in 6 diverse biomedical tasks across 26 datasets has been conducted. To the best of our knowledge, this is the first work that conducts an extensive evaluation and comparison of various LLMs in the biomedical domain. Interestingly, we find based on our evaluation that in biomedical datasets that have smaller training sets, zero-shot LLMs even outperform the current state-of-the-art models when they were fine-tuned only on the training set of these datasets. This suggests that pre-training on large text corpora makes LLMs quite specialized even in the biomedical domain. We also find that not a single LLM can outperform other LLMs in all tasks, with the performance of different LLMs may vary depending on the task. While their performance is still quite poor in comparison to the biomedical models that were fine-tuned on large training sets, our findings demonstrate that LLMs have the potential to be a valuable tool for various biomedical tasks that lack large annotated data.","['zero-shot learning', 'fine-tuning']","The research idea addresses the challenge of evaluating the effectiveness of recently developed large language models within the biomedical domain, an area that has not been previously explored despite their success in other fields. The study is motivated by the need to understand how these models perform on diverse biomedical tasks, especially given the limited availability of large annotated datasets in this field. The primary objective of the study is to conduct a comprehensive evaluation of multiple large language models across various biomedical tasks and datasets to assess their performance and potential utility. This evaluation aims to identify the strengths and limitations of these models in biomedical applications, particularly in scenarios with smaller training sets, and to compare their effectiveness relative to existing specialized biomedical approaches."
Engineering,Performance assessment of machine learning algorithms for mapping of land use/land cover using remote sensing data,"The rapid increase in population accelerates the rate of change of Land use/Land cover (LULC) in various parts of the world. This phenomenon caused a huge strain for natural resources. Hence, continues monitoring of LULC changes gained a significant importance for management of natural resources and assessing the climate change impacts. Recently, application of machine learning algorithms on RS (remote sensing) data for rapid and accurate mapping of LULC gained significant importance due to growing need of LULC estimation for ecosystem services, natural resource management and environmental management. Hence, it is crucial to access and compare the performance of different machine learning classifiers for accurate mapping of LULC. The primary objective of this study was to compare the performance of CART (Classification and Regression Tree), RF (Random Forest) and SVM (Support Vector Machine) for LULC estimation by processing RS data on Google Earth Engine (GEE). In total four classes of LULC (Water Bodies, Vegetation Cover, Urban Land and Barren Land) for city of Lahore were extracted using satellite images from Landsat-7, Landsat-8 and Landsat-9 for years 2008, 2015 and 2022, respectively. According to results, RF is the best performing classifier with maximum overall accuracy of 95.2% and highest Kappa coefficient value of 0.87, SVM achieved maximum accuracy of 89.8% with highest Kappa of 0.84 and CART showed maximum overall accuracy of 89.7% with Kappa value of 0.79. Results from this study can give assistance for decision makers, planners and RS experts to choose a suitable machine learning algorithm for LULC classification in an unplanned urbanized city like Lahore.","['Classification and Regression Tree (CART)', 'Random Forest (RF)', 'Support Vector Machine (SVM)']","The rapid increase in population has accelerated the rate of Land Use/Land Cover (LULC) changes in various parts of the world, placing significant strain on natural resources. Continuous monitoring of these changes is essential for effective management of natural resources and for assessing the impacts of climate change. The primary objective of this study was to compare the performance of different classification approaches for accurate mapping of LULC in the city of Lahore. Specifically, the study aimed to evaluate and contrast the effectiveness of three classification methods in extracting four LULC classes—Water Bodies, Vegetation Cover, Urban Land, and Barren Land—using satellite images from multiple years to support decision-making in urban and environmental planning."
Engineering,Transformer and Graph Convolution-Based Unsupervised Detection of Machine Anomalous Sound Under Domain Shifts,"Thanks to the development of deep learning, machine abnormal sound detection (MASD) based on unsupervised learning has exhibited excellent performance. However, in the task of unsupervised MASD, there are discrepancies between the acoustic characteristics of the test set and the training set under the physical parameter changes (domain shifts) of the same machine's operating conditions. Existing methods not only struggle to stably learn the sound signal features under various domain shifts but also inevitably increase computational overhead. To address these issues, we propose an unsupervised machine abnormal sound detection model based on Transformer and Dynamic Graph Convolution (Unsuper-TDGCN) in this paper. Firstly, we design a network that models time-frequency domain features to capture both global and local spatial and time-frequency interactions, thus improving the model's stability under domain shifts. Then, we introduce a Dynamic Graph Convolutional Network (DyGCN) to model the dependencies between features under domain shifts, enhancing the model's ability to perceive changes in domain features. Finally, a Domain Self-adaptive Network (DSN) is employed to compensate for the performance decline caused by domain shifts, thereby improving the model's adaptive ability for detecting anomalous sounds in MASD tasks under domain shifts. The effectiveness of our proposed model has been validated on multiple datasets.","['unsupervised learning', 'Transformer', 'Dynamic Graph Convolutional Network (DyGCN)']","The research addresses the challenge of detecting abnormal sounds in machines when there are changes in the physical operating conditions that cause variations in acoustic characteristics between training and testing environments. These variations, known as domain shifts, make it difficult to consistently identify sound anomalies and maintain stable detection performance. The study aims to improve the stability and adaptability of abnormal sound detection in machines under varying operating conditions by enhancing the ability to capture and respond to changes in sound features caused by domain shifts. The primary objective is to develop a method that can effectively detect anomalous machine sounds despite differences in acoustic characteristics due to changes in the machine’s physical parameters, thereby improving detection reliability across diverse operating scenarios."
Engineering,Artificial intelligence for literature reviews: opportunities and challenges,"Abstract This paper presents a comprehensive review of the use of Artificial Intelligence (AI) in Systematic Literature Reviews (SLRs). A SLR is a rigorous and organised methodology that assesses and integrates prior research on a given topic. Numerous tools have been developed to assist and partially automate the SLR process. The increasing role of AI in this field shows great potential in providing more effective support for researchers, moving towards the semi-automatic creation of literature reviews. Our study focuses on how AI techniques are applied in the semi-automation of SLRs, specifically in the screening and extraction phases. We examine 21 leading SLR tools using a framework that combines 23 traditional features with 11 AI features. We also analyse 11 recent tools that leverage large language models for searching the literature and assisting academic writing. Finally, the paper discusses current trends in the field, outlines key research challenges, and suggests directions for future research. We highlight three primary research challenges: integrating advanced AI solutions, such as large language models and knowledge graphs, improving usability, and developing a standardised evaluation framework. We also propose best practices to ensure more robust evaluations in terms of performance, usability, and transparency. Overall, this review offers a detailed overview of AI-enhanced SLR tools for researchers and practitioners, providing a foundation for the development of next-generation AI solutions in this field.",['knowledge graphs'],"The research idea addresses the need for more effective support in conducting systematic literature reviews (SLRs), which are rigorous and organized methodologies for assessing and integrating prior research on a given topic. The study recognizes the growing importance of semi-automating the SLR process, particularly in the screening and extraction phases, to enhance efficiency and accuracy. It highlights the challenges involved in improving usability and establishing standardized evaluation frameworks for tools that assist in literature reviews. The research objective is to examine and evaluate existing tools designed to support the semi-automation of systematic literature reviews, focusing on their features and capabilities in the screening and extraction stages. The study aims to identify current trends, key challenges, and best practices to guide the development of more robust and user-friendly solutions for conducting systematic literature reviews in the future."
Engineering,Joint Optimization Risk Factor and Energy Consumption in IoT Networks With TinyML-Enabled Internet of UAVs,"The high mobility of Internet of Unmanned Aerial Vehicles (IUAVs) has attracted attention in the field of data collection. With the rapid development of the Internet of Things (IoT), more and more data are generated by IoT networks. IUAV-aided IoT networks can efficiently collect data in specific areas, which is of great significance in disaster relief. In the data collection task, it is necessary to plan the flight trajectory for the data collector—IUAV, so that the IUAV can collect data efficiently. However, existing research basically only considers the efficiency of data collection by IUAVs, but rarely considers the safety of IUAVs during flight. Therefore, this paper proposes an IUAV trajectory planning algorithm that integrates energy efficiency and safety using local search to address the issues mentioned above. At the same time, a Tiny Machine Learning (TinyML) algorithm is designed to assist the IUAV in making real-time decisions during flight. First, we build a general mathematical model that describes the risk in a particular region. Then consider guiding the IUAV to a safer trajectory by introducing virtual nodes in the flight trajectory. Furthermore, we designed a local search algorithm for the three tasks of IUAV access sequence, IoT Networks cluster heads selection and virtual nodes selection, and solved them through iterative optimization. We also consider the unreachable situation of the virtual nodes and use TinyML technology to help the IUAV adjust the position of the virtual nodes in real time in case of an emergency.In the end, an IUAV trajectory is obtained that can efficiently collect IoT networks' data and fly safely. We have conducted a large number of simulation experiments to demonstrate the efficiency of the proposed algorithm compared to the baseline algorithm.",['Tiny Machine Learning (TinyML)'],"The research addresses the challenge of efficiently collecting data in Internet of Things (IoT) networks using Unmanned Aerial Vehicles (UAVs) while ensuring the safety of the UAVs during flight. Although UAVs have been recognized for their high mobility and effectiveness in data collection, especially in disaster relief scenarios, existing approaches primarily focus on collection efficiency without adequately considering flight safety. The study aims to develop a flight trajectory planning approach for UAVs that balances both energy efficiency and safety. Specifically, the objective is to create a trajectory that enables UAVs to collect data from IoT networks effectively while minimizing risks during flight by guiding the UAV along safer paths and addressing potential obstacles or emergencies in real time."
Engineering,Groundwater Quality Assessment and Irrigation Water Quality Index Prediction Using Machine Learning Algorithms,"The evaluation of groundwater quality is crucial for irrigation purposes; however, due to financial constraints in developing countries, such evaluations suffer from insufficient sampling frequency, hindering comprehensive assessments. Therefore, associated with machine learning approaches and the irrigation water quality index (IWQI), this research aims to evaluate the groundwater quality in Naama, a region in southwest Algeria. Hydrochemical parameters (cations, anions, pH, and EC), qualitative indices (SAR,RSC,Na%,MH,and PI), as well as geospatial representations were used to determine the groundwater’s suitability for irrigation in the study area. In addition, efficient machine learning approaches for forecasting IWQI utilizing Extreme Gradient Boosting (XGBoost), Support vector regression (SVR), and K-Nearest Neighbours (KNN) models were implemented. In this research, 166 groundwater samples were used to calculate the irrigation index. The results showed that 42.18% of them were of excellent quality, 34.34% were of very good quality, 6.63% were good quality, 9.64% were satisfactory, and 4.21% were considered unsuitable for irrigation. On the other hand, results indicate that XGBoost excels in accuracy and stability, with a low RMSE (of 2.8272 and a high R of 0.9834. SVR with only four inputs (Ca2+, Mg2+, Na+, and K) demonstrates a notable predictive capability with a low RMSE of 2.6925 and a high R of 0.98738, while KNN showcases robust performance. The distinctions between these models have important implications for making informed decisions in agricultural water management and resource allocation within the region.","['Extreme Gradient Boosting (XGBoost)', 'Support Vector Regression (SVR)', 'K-Nearest Neighbours (KNN)']","The evaluation of groundwater quality is crucial for irrigation purposes, but in developing countries, financial constraints lead to insufficient sampling frequency, which hinders comprehensive assessments. This limitation affects the ability to accurately determine the suitability of groundwater for agricultural use, particularly in regions like Naama in southwest Algeria. The primary aim of this study is to evaluate the groundwater quality in the Naama region by assessing hydrochemical parameters and qualitative indices to determine its suitability for irrigation. The research seeks to provide a detailed assessment of groundwater quality to support informed decisions in agricultural water management and resource allocation within the area."
Engineering,Artificial intelligence (AI) in renewable energy: A review of predictive maintenance and energy optimization,"The integration of Artificial Intelligence (AI) in the renewable energy sector has emerged as a transformative force, enhancing the efficiency and sustainability of energy systems. This paper provides a comprehensive review of the application of AI in two critical aspects of renewable energy in relation to predictive maintenance and energy optimization. Predictive maintenance, enabled by AI, has revolutionized the renewable energy landscape by predicting and preventing equipment failures before they occur. Utilizing machine learning algorithms, AI analyzes vast amounts of data from sensors and historical performance to identify patterns indicative of potential faults. This proactive approach not only minimizes downtime but also extends the lifespan of renewable energy infrastructure, resulting in substantial cost savings and improved reliability. Furthermore, AI plays a pivotal role in optimizing the energy output of renewable sources. Through advanced data analytics and real-time monitoring, AI algorithms can adapt to changing environmental conditions, predicting energy production patterns and optimizing resource allocation. This ensures maximum energy yield from renewable sources, making them more competitive with traditional energy sources. The paper delves into specific AI techniques such as deep learning, neural networks, and predictive analytics employed for predictive maintenance and energy optimization in various renewable energy systems like solar, wind, and hydropower. Challenges and opportunities associated with implementing AI in renewable energy are discussed, including data security, interoperability, and the need for standardized frameworks. The synthesis of AI technologies with renewable energy not only addresses operational challenges but also contributes to the global transition towards sustainable and clean energy solutions. This review serves as a valuable resource for researchers, practitioners, and policymakers seeking insights into the evolving landscape of AI applications in the renewable energy sector. As technology continues to advance, the synergies between AI and renewable energy are poised to shape the future of the global energy paradigm.","['deep learning', 'neural networks']","The research idea centers on improving the efficiency and sustainability of renewable energy systems by addressing critical challenges related to equipment maintenance and energy output optimization. The study highlights the importance of proactive maintenance to prevent equipment failures and extend the lifespan of renewable energy infrastructure, thereby reducing downtime and costs. Additionally, it emphasizes the need to maximize energy yield from renewable sources by adapting to changing environmental conditions and optimizing resource allocation. The research objective is to comprehensively review the advancements in enhancing predictive maintenance and energy optimization within renewable energy systems, focusing on how these improvements contribute to operational reliability and increased competitiveness of renewable energy compared to traditional sources. The study aims to provide insights into overcoming challenges such as data security and interoperability while supporting the global transition toward sustainable and clean energy solutions."
Engineering,Generative Pre-Trained Transformer (GPT) in Research: A Systematic Review on Data Augmentation,"GPT (Generative Pre-trained Transformer) represents advanced language models that have significantly reshaped the academic writing landscape. These sophisticated language models offer invaluable support throughout all phases of research work, facilitating idea generation, enhancing drafting processes, and overcoming challenges like writer’s block. Their capabilities extend beyond conventional applications, contributing to critical analysis, data augmentation, and research design, thereby elevating the efficiency and quality of scholarly endeavors. Strategically narrowing its focus, this review explores alternative dimensions of GPT and LLM applications, specifically data augmentation and the generation of synthetic data for research. Employing a meticulous examination of 412 scholarly works, it distills a selection of 77 contributions addressing three critical research questions: (1) GPT on Generating Research data, (2) GPT on Data Analysis, and (3) GPT on Research Design. The systematic literature review adeptly highlights the central focus on data augmentation, encapsulating 48 pertinent scholarly contributions, and extends to the proactive role of GPT in critical analysis of research data and shaping research design. Pioneering a comprehensive classification framework for “GPT’s use on Research Data”, the study classifies existing literature into six categories and 14 sub-categories, providing profound insights into the multifaceted applications of GPT in research data. This study meticulously compares 54 pieces of literature, evaluating research domains, methodologies, and advantages and disadvantages, providing scholars with profound insights crucial for the seamless integration of GPT across diverse phases of their scholarly pursuits.",['Generative Pre-trained Transformer (GPT)'],"The research addresses the evolving role of advanced language models in enhancing various phases of academic research, particularly focusing on their impact on data augmentation and the generation of synthetic research data. It highlights the significance of these models in improving the efficiency and quality of scholarly work by supporting critical analysis and research design. The primary aim of the study is to systematically review and classify existing literature on the use of these language models in research data, specifically examining their applications in generating research data, data analysis, and research design. By developing a comprehensive classification framework and comparing numerous scholarly contributions, the study seeks to provide detailed insights into the advantages, disadvantages, and diverse applications of these models within the research process."
Engineering,GraphGST: Graph Generative Structure-Aware Transformer for Hyperspectral Image Classification,"Transformer holds significance in deep learning (DL) research. Node embedding (NE) and positional encoding (PE) are usually two indispensable components in a Transformer. The former can excavate hidden correlations from the data, while the latter can store locational relationships between nodes. Recently, the Transformer has been applied for hyperspectral image (HSI) classification because the model can capture long-range dependencies to aggregate global features for representation learning. In an HSI, adjacent pixels tend to be homogeneous, while the NE does not identify the positional information of pixels. Therefore, PE is crucial for Transformers to understand locational relationships between pixels. However, in this area, most Transformer-based methods randomly generate PEs without considering their physical meaning, which leads to weak representations. This article proposes a new graph generative structure-aware Transformer (GraphGST) to solve the above-mentioned PE problem when implementing HSI classification. In our GraphGST, a new absolute PE (APE) is established to acquire pixels' absolute positional sequences (APSs) and is integrated into the Transformer architecture. Moreover, a generative mechanism with self-supervised learning is developed to achieve cross-view contrastive learning (CL), aiming to enhance the representation learning of the Transformer. The proposed GraphGST model can capture local-to-global correlations, and the extracted APSs can complement the spectral features of pixels to assist in NE. Several experiments with real HSIs are conducted to evaluate the effectiveness of our GraphGST. The proposed method demonstrates very competitive performance compared with other state-of-the-art (SOTA) approaches. Our source codes will be provided in the following link <uri xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">https://github.com/yuanchaosu/TGRS-graphGST</uri> .","['Transformer', 'Node embedding (NE)', 'Absolute positional encoding (APE)', 'Self-supervised learning', 'Cross-view contrastive learning (CL)']","The research addresses the challenge of accurately capturing positional information in hyperspectral images, where adjacent pixels tend to be homogeneous but their locational relationships are often not effectively represented. This lack of meaningful positional encoding leads to weak representations in existing approaches for hyperspectral image classification. The primary objective of the study is to develop a new method for establishing absolute positional sequences of pixels that can be integrated into the classification process to better capture local-to-global correlations. The aim is to enhance the representation of spectral features by incorporating physically meaningful positional information, thereby improving the overall effectiveness of hyperspectral image classification."
Engineering,Learning to Aggregate Multi-Scale Context for Instance Segmentation in Remote Sensing Images,"The task of instance segmentation in remote sensing images, aiming at performing per-pixel labeling of objects at the instance level, is of great importance for various civil applications. Despite previous successes, most existing instance segmentation methods designed for natural images encounter sharp performance degradations when they are directly applied to top-view remote sensing images. Through careful analysis, we observe that the challenges mainly come from the lack of discriminative object features due to severe scale variations, low contrasts, and clustered distributions. In order to address these problems, a novel context aggregation network (CATNet) is proposed to improve the feature extraction process. The proposed model exploits three lightweight plug-and-play modules, namely, dense feature pyramid network (DenseFPN), spatial context pyramid (SCP), and hierarchical region of interest extractor (HRoIE), to aggregate global visual context at feature, spatial, and instance domains, respectively. DenseFPN is a multi-scale feature propagation module that establishes more flexible information flows by adopting interlevel residual connections, cross-level dense connections, and feature reweighting strategy. Leveraging the attention mechanism, SCP further augments the features by aggregating global spatial context into local regions. For each instance, HRoIE adaptively generates RoI features for different downstream tasks. Extensive evaluations of the proposed scheme on iSAID, DIOR, NWPU VHR-10, and HRSID datasets demonstrate that the proposed approach outperforms state-of-the-arts under similar computational costs. Source code and pretrained models are available at https://github.com/yeliudev/CATNet.","['dense feature pyramid network (DenseFPN)', 'attention mechanism']","The research addresses the challenge of accurately identifying and labeling individual objects in top-view remote sensing images, which is crucial for various civil applications. Existing methods that work well on natural images often perform poorly on remote sensing images due to issues such as severe scale variations, low contrasts, and clustered object distributions that reduce the distinctiveness of object features. The primary objective of the study is to enhance the feature extraction process in remote sensing images to overcome these challenges. This is aimed at improving the accuracy and reliability of instance-level object labeling in remote sensing imagery across multiple benchmark datasets."
Engineering,Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning,"Recent development in computing power has resulted in performance improvements on holistic(none-occluded) person Re-Identification (ReID) tasks. Nevertheless, the precision of the recent research will diminish when a pedestrian is obstructed by obstacles. Within the realm of 2D space, the loss of information from obstructed objects continues to pose significant challenges in the context of person ReID. Person is a 3D non-grid object, and thus semantic representation learning in only 2D space limits the understanding of occluded person. In the present work, we propose a network based on 3D multi-view learning, allowing it to acquire geometric and shape details of an occluded pedestrian from 3D space. Simultaneously, it capitalizes on advancements in 2D-based networks to extract semantic representations from 3D multi-views. Specifically, the surface random selection strategy is proposed to convert images of 2D RGB into 3D multi-views. Using this strategy, we build four extensive 3D multi-view data collections for person ReID. After that, Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning(MV-3DSReID), is proposed for identifying the person by learning person geometry and structure representation from the groups of multi-view images. In comparison to alternative data formats (e.g., 2D RGB, 3D point cloud), multi-view images complement each other's detailed features of the 3D object by adjusting rendering viewpoints, thus facilitating a more comprehensive understanding of the person for both holistic and occluded ReID situations. Experiments on occluded and holistic ReID tasks demonstrate performance levels comparable to state-of-the-art methods, validating the effectiveness of our proposed approach in tackling challenges related to occlusion. The code is available at https://github.com/hangjiaqi1/MV-TransReID.",['3D multi-view learning'],"The research addresses the challenge of accurately identifying pedestrians when they are partially obstructed by obstacles, which leads to a loss of critical information in traditional two-dimensional representations. Since a person is a three-dimensional object, relying solely on 2D spatial information limits the ability to understand and recognize occluded individuals effectively. The study aims to improve the understanding of pedestrian geometry and shape by incorporating three-dimensional multi-view representations, which provide a more comprehensive capture of the person's structure. The primary objective of the study is to develop an approach that leverages 3D multi-view information to enhance person identification performance under both occluded and non-occluded conditions, thereby overcoming the limitations posed by 2D-only representations and improving recognition accuracy in complex environments."
Engineering,The use of machine learning techniques to investigate the properties of metakaolin-based geopolymer concrete,"The construction industry significantly contributes to global greenhouse gas emissions, highlighting the imperative for developing environmentally friendly construction materials. Geopolymers, particularly those utilizing metakaolin (MK), have emerged as a promising green alternative to conventional concrete. However, the acquisition of MK-based geopolymer concrete with optimal mechanical properties poses challenges due to numerous influential factors, disagreement over various findings, and the lack of a reliable predictive model. This study aimed to address this gap by employing a wide range of machine learning methods, namely gradient boosting machine, random forest, decision tree, artificial neural network, and support vector machine. Different optimization and regularization techniques were used to comprehensively understand the factors affecting the compressive strength of MK-based geopolymer concrete, including mixture design, chemical characteristics of the initial binder and activators, and different curing regimes. The results demonstrated the exceptional performance of the gradient boosting machine in predicting the compressive strength of MK-based geopolymer concrete, achieving a coefficient of determination of 0.983 and a mean absolute error of 1.615 MPa. Additionally, the study employed partial dependence plots, feature importance analysis, and SHapley Additive exPlanations (SHAP) to elucidate the proposed models. The coarse-to-fine aggregate ratio, H2O/Na2O molar ratio, extra water content, and sodium hydroxide concentration were identified as the most critical parameters affecting the compressive strength of MK-based geopolymer concrete. This research contributes to advancing the development of sustainable construction materials, streamlining experimental tasks, minimizing the need for labor and materials, improving time efficiency, and providing valuable insights for optimizing the design of MK-based geopolymer concrete.","['gradient boosting machine', 'random forest', 'decision tree', 'artificial neural network', 'support vector machine']","The construction industry significantly contributes to global greenhouse gas emissions, creating an urgent need for environmentally friendly construction materials. Geopolymers based on metakaolin (MK) have emerged as a promising green alternative to conventional concrete, but achieving MK-based geopolymer concrete with optimal mechanical properties remains challenging due to multiple influencing factors and inconsistent findings. The primary objective of this study is to comprehensively understand the factors affecting the compressive strength of MK-based geopolymer concrete, including mixture design, chemical characteristics of the initial binder and activators, and different curing regimes. This research aims to provide valuable insights for optimizing the design of MK-based geopolymer concrete to advance sustainable construction materials while improving efficiency and reducing resource consumption."
Engineering,Sequence Training and Data Shuffling to Enhance the Accuracy of Recurrent Neural Network Based Battery Voltage Models,"&lt;div class=""section abstract""&gt;&lt;div class=""htmlview paragraph""&gt;Battery terminal voltage modelling is crucial for various applications, including electric vehicles, renewable energy systems, and portable electronics. Terminal voltage models are used to determine how a battery will respond under load and can be used to calculate run-time, power capability, and heat generation and as a component of state estimation approaches, such as for state of charge. Previous studies have shown better voltage modelling accuracy for long short-term memory (LSTM) recurrent neural networks than other traditional methods (e.g., equivalent circuit and electrochemical models). This study presents two new approaches – sequence training and data shuffling – to improve LSTM battery voltage models further, making them an even better candidate for the high-accuracy modelling of lithium-ion batteries. Because the LSTM memory captures information from past time steps, it must typically be trained using one series of continuous data. Instead, the proposed sequence training approach feeds a fixed window of prior data (e.g., 100 seconds) into the LSTM at each time step to initialize the memory states properly and then only uses the output at the current time step. With this method, the LSTM just requires the prior data window to be continuous, thereby allowing the handling of discontinuities. This also means that during the training process, the data can be shuffled randomly, enabling mini-batches to speed up the training significantly. When these approaches were applied, LSTM voltage estimation error was reduced by 22%, from 28.5 mV to 22.3 mV RMS error over four drive cycles and temperatures from -20 to 25°C.&lt;/div&gt;&lt;/div&gt;","['long short-term memory (LSTM) recurrent neural networks', 'sequence training']","The research addresses the critical need for accurate battery terminal voltage modeling, which is essential for applications such as electric vehicles, renewable energy systems, and portable electronics. Accurate voltage models help predict battery response under load, enabling the calculation of run-time, power capability, and heat generation, as well as supporting state estimation tasks like determining the state of charge. The primary objective of the study is to enhance the accuracy of lithium-ion battery voltage models by introducing new approaches that improve the handling of prior data during the modeling process. This aims to reduce voltage estimation errors across various operating conditions, including different drive cycles and temperature ranges."
Engineering,Semantic and Instance Segmentation in Coastal Urban Spatial Perception: A Multi-Task Learning Framework with an Attention Mechanism,"With the continuous acceleration of urbanization, urban planning and design require more in-depth research and development. Street view images can express rich urban features and guide residents’ emotions toward a city, thereby providing the most intuitive reflection of their perception of the city’s spatial quality. However, current researchers mainly conduct research on urban spatial quality through subjective experiential judgment, which includes problems such as a high cost and a low judgment accuracy. In response to these problems, this study proposes a multi-task learning urban spatial attribute perception model that integrates an attention mechanism. Via this model, the existing attributes of urban street scenes are analyzed. Then, the model is improved by introducing semantic segmentation and instance segmentation to identify and match the qualities of the urban space. The experimental results show that the multi-task learning urban spatial attribute perception model with an integrated attention mechanism has prediction accuracies of 79.54%, 78.62%, 79.68%, 77.42%, 78.45%, and 76.98% for the urban spatial attributes of beauty, boredom, depression, liveliness, safety, and richness, respectively. The accuracy of the multi-task learning urban spatial scene feature image segmentation model with an integrated attention mechanism is 95.4, 94.8, 96.2, 92.1, and 96.7 for roads, walls, sky, vehicles, and buildings, respectively. The multi-task learning urban spatial scene feature image segmentation model with an integrated attention mechanism has a higher recognition accuracy for urban spatial buildings than other models. These research results indicate the model’s effectiveness in matching urban spatial quality with public perception.","['multi-task learning', 'attention mechanism', 'semantic segmentation', 'instance segmentation']","The research addresses the challenge of accurately assessing urban spatial quality, which is essential for urban planning and design amid rapid urbanization. Traditional methods rely heavily on subjective experiential judgment, leading to high costs and low accuracy in evaluating the spatial attributes of urban environments. The study aims to improve the evaluation of urban street scenes by analyzing existing urban spatial attributes and enhancing the identification and matching of these qualities within urban spaces. The primary objective is to develop and validate an approach that effectively matches urban spatial quality with public perception, thereby providing a more accurate and objective assessment of urban environments."
Engineering,"The Convergence of Intelligent Tutoring, Robotics, and IoT in Smart Education for the Transition from Industry 4.0 to 5.0","This review paper provides a comprehensive analysis of the automation of smart education in the context of Industry 5.0 from 78 papers, focusing on the integration of advanced technologies and the development of innovative, effective, and ethical educational solutions for the future workforce. As the world transitions into an era characterized by human–machine collaboration and rapidly evolving technologies, there is an urgent need to recognize the pivotal role of smart education in preparing individuals for the opportunities and challenges presented by the new industrial landscape. The paper examines key components of smart education, including intelligent tutoring systems, adaptive learning environments, learning analytics, and the application of the Internet of Things (IoT) in education. It also discusses the role of advanced technologies such as artificial intelligence (AI), machine learning (ML), robotics, and augmented and virtual reality (AR/VR) in shaping personalized and immersive learning experiences. The review highlights the importance of smart education in addressing the growing demand for upskilling and reskilling, fostering a culture of lifelong learning, and promoting adaptability, resilience, and self-improvement among learners. Furthermore, the paper delves into the challenges and ethical considerations associated with the implementation of smart education, addressing issues such as data privacy, the digital divide, teacher and student readiness, and the potential biases in AI-driven systems. Through a presentation of case studies and examples of successful smart education initiatives, the review aims to inspire educators, policymakers, and industry stakeholders to collaborate and innovate in the design and implementation of effective smart education solutions. Conclusively, the paper outlines emerging trends, future directions, and potential research opportunities in the field of smart education, emphasizing the importance of continuous improvement and the integration of new technologies to ensure that education remains relevant and effective in the context of Industry 5.0. By providing a holistic understanding of the key components, challenges, and potential solutions associated with smart education, this review paper seeks to contribute to the ongoing discourse surrounding the automation of smart education and its role in preparing the workforce for the future of work.",['machine learning (ML)'],"The research idea centers on the critical need to prepare individuals for the evolving industrial landscape characterized by human–machine collaboration and rapidly advancing technologies. It addresses the importance of smart education in equipping the future workforce with the skills required to meet the opportunities and challenges of Industry 5.0, emphasizing upskilling, reskilling, lifelong learning, adaptability, and resilience. The study recognizes the growing demand for innovative and effective educational solutions that integrate emerging technologies to enhance learning experiences while considering ethical and practical challenges. The primary objective of the study is to provide a comprehensive review of the automation of smart education within the context of Industry 5.0 by examining key components, challenges, and potential solutions. It aims to inspire collaboration among educators, policymakers, and industry stakeholders to design and implement effective smart education initiatives that ensure education remains relevant and effective in preparing the workforce for the future of work."
Engineering,A comprehensive analysis of the emerging modern trends in research on photovoltaic systems and desalination in the era of artificial intelligence and machine learning,"Integration of photovoltaic (PV) systems, desalination technologies, and Artificial Intelligence (AI) combined with Machine Learning (ML) has introduced a new era of remarkable research and innovation. This review article thoroughly examines the recent advancements in the field, focusing on the interplay between PV systems and water desalination within the framework of AI and ML applications, along with it analyses current research to identify significant patterns, obstacles, and prospects in this interdisciplinary field. Furthermore, review examines the incorporation of AI and ML methods in improving the performance of PV systems. This includes raising their efficiency, implementing predictive maintenance strategies, and enabling real-time monitoring. It also explores the transformative influence of intelligent algorithms on desalination techniques, specifically addressing concerns pertaining to energy usage, scalability, and environmental sustainability. This article provides a thorough analysis of the current literature, identifying areas where research is lacking and suggesting potential future avenues for investigation. These advancements have resulted in increased efficiency, decreased expenses, and improved sustainability of PV system. By utilizing artificial intelligence technologies, freshwater productivity can increase by 10 % and efficiency. This review offers significant and informative perspectives for researchers, engineers, and policymakers involved in renewable energy and water technology. It sheds light on the latest advancements in photovoltaic systems and desalination, which are facilitated by AI and ML. The review aims to guide towards a more sustainable and technologically advanced future.",['Machine Learning (ML)'],"The research idea centers on the integration of photovoltaic systems and water desalination technologies to address challenges related to energy usage, scalability, and environmental sustainability in renewable energy and water treatment. The study highlights the need to improve the efficiency and sustainability of these systems to meet growing demands for freshwater production and energy optimization. The primary objective of the study is to thoroughly review recent advancements in photovoltaic systems and desalination technologies, focusing on their performance improvements and the potential for increased freshwater productivity. Additionally, the study aims to identify current obstacles, significant patterns, and future research directions to support the development of more efficient, cost-effective, and sustainable solutions in this interdisciplinary field."
Engineering,Optimum tuned mass damper inerter under near-fault pulse-like ground motions of buildings including soil-structure interaction,"This study investigates the effectiveness of the tuned mass damper inerter (TMDI) in mitigating building response, considering the soil structure interaction (SSI). Three types of models are examined: single degree of freedom (SDOF), low-rise multi-degree of freedom (MDOF), and high-rise MDOF. Additionally, the natural period of the SDOF model is varied to explore the TMDI's efficacy across different ranges. Frequency and time domain analysis are conducted under pulse-like ground motions. The H2 and genetic algorithm (GA) are used to optimize the parameters of the TMDI. In this optimization method the transfer function for displacement response is minimized. In time domain analysis we used Newmark's integration method to solve the equation of motion for all the cases considered. It is found that the optimized TMDI proves highly effective in mitigating the displacement response of the buildings, accounting for SSI. Notably, its efficiency is more pronounced when pulse period aligns closely with the buildings' natural period. In addition, a notable pattern emerges, wherein the TMDI excels in mitigating response for buildings experiencing large motion, thereby enhancing safety under severe conditions. These findings offer valuable insights into the application and optimization of the TMDI to enhance seismic performance in various buildings, while considering complex interaction with the soil.",['genetic algorithm (GA)'],"The research idea centers on addressing the challenge of mitigating building responses during seismic events by considering the interaction between the soil and the structure. The study focuses on evaluating the effectiveness of a tuned mass damper inerter (TMDI) in reducing displacement responses in buildings of varying heights and dynamic characteristics under pulse-like ground motions. It highlights the importance of accounting for soil-structure interaction to improve the accuracy and reliability of vibration mitigation strategies. The primary objective of the study is to investigate the performance of the TMDI in controlling building displacement responses across different structural models, including single degree of freedom and multi-degree of freedom systems, while varying the natural period to assess its efficacy under different conditions. The study aims to demonstrate how optimizing the TMDI parameters can enhance seismic safety, particularly when the pulse period of ground motion closely matches the natural period of the building, thereby providing insights for improving seismic performance in buildings considering complex soil-structure interactions."
Engineering,3DUV-NetR+: A 3D hybrid semantic architecture using transformers for brain tumor segmentation with MultiModal MR images,"Brain tumor segmentation plays a substantial role in Medical Image Analysis (MIS). In this regard, automatic segmentation methods facilitate precise and efficient segmentation, significantly contributing to diagnosis and treatment planning in medical applications. Recently, several Deep Learning-based architectures have been proposed to revolutionize the MIS field. Particularly, the combination of Convolution Neural Networks (CNNs) and Transformers has greatly enhanced and developed segmentation results. Moreover, the Attention mechanism in Transformers allows the modeling of long-range contextual features extracted from CNNs' encoder part. This paper proposes a hybrid advanced 3D model for brain tumor segmentation using multi-modal magnetic resonance images. The model benefits from the features extracted from the encoder of 3DU-Net and V-Net architectures at each depth. Then, a concatenation between these features and their fusion is carried out at each decoder depth to build new significant features followed by a 3D convolution layer and Transformers block for more contextual information. In addition, a final convolution block is applied to get the segmented tumor. To this end, the model is evaluated on the BraTS 2020 dataset to segment different sub-regions of brain tumors. The obtained results demonstrate the effectiveness of the proposed model in terms of dice similarity coefficient (DSC) and Hausdorff Distance (HD). For DSC, 91.95% and 82.80% and 81.70% for Whole Tumor(WT), Tumor Core (TC), and Enhancing Tumor(ET), respectively are archived, while for HD, 4.9 mm, 6.0 mm and 3.8 mm for WT, TC and ET are accomplished.","['Convolution Neural Networks (CNNs)', 'Transformers', 'Attention mechanism in Transformers', '3DU-Net', 'V-Net', '3D convolution layer']","The research addresses the critical need for precise and efficient brain tumor segmentation in medical imaging, which is essential for accurate diagnosis and effective treatment planning. Improving segmentation methods can significantly enhance the identification and delineation of different tumor sub-regions, thereby supporting better clinical outcomes. The study aims to develop an advanced approach for segmenting brain tumors using multi-modal magnetic resonance images. Specifically, the primary objective is to achieve accurate segmentation of various tumor sub-regions, including the whole tumor, tumor core, and enhancing tumor, to improve the reliability and effectiveness of medical image analysis in brain tumor cases."
Engineering,A machine learning-based framework for clustering residential electricity load profiles to enhance demand response programs,"Load shapes derived from smart meter data are frequently employed to analyze daily energy consumption patterns, particularly in the context of applications like Demand Response (DR). Nevertheless, one of the most important challenges to this endeavor lies in identifying the most suitable consumer clusters with similar consumption behaviors. In this paper, we present a novel machine learning based framework in order to achieve optimal load profiling through a real case study, utilizing data from almost 5000 households in London. Four widely used clustering algorithms are applied specifically K-means, K-medoids, Hierarchical Agglomerative Clustering and Density-based Spatial Clustering. An empirical analysis as well as multiple evaluation metrics are leveraged to assess those algorithms. Following that, we redefine the problem as a probabilistic classification one, with the classifier emulating the behavior of a clustering algorithm, leveraging Explainable AI (xAI) to enhance the interpretability of our solution. According to the clustering algorithm analysis the optimal number of clusters for this case is seven. Despite that, our methodology shows that two of the clusters, almost 10% of the dataset, exhibit significant internal dissimilarity. As a result, these clusters have been excluded from consideration for DR programs. The scalability and versatility of our solution makes it an ideal choice for power utility companies aiming to segment their users for creating more targeted DR programs.","['K-means', 'K-medoids', 'Hierarchical Agglomerative Clustering', 'Density-based Spatial Clustering', 'probabilistic classification', 'Explainable AI (xAI)']","The study addresses the challenge of accurately identifying consumer groups with similar daily energy consumption patterns to improve the effectiveness of Demand Response (DR) programs. This problem is critical because proper segmentation of consumers based on their load profiles enables more targeted and efficient energy management strategies. The primary objective of the research is to achieve optimal load profiling by analyzing consumption data from nearly 5000 households in London, determining the most appropriate number of consumer clusters, and refining the segmentation to exclude groups with significant internal dissimilarity. This aims to support power utility companies in better segmenting their users for the development of more effective DR initiatives."
Engineering,The diagnostic and triage accuracy of the GPT-3 artificial intelligence model: an observational study,"BackgroundArtificial intelligence (AI) applications in health care have been effective in many areas of medicine, but they are often trained for a single task using labelled data, making deployment and generalisability challenging. How well a general-purpose AI language model performs diagnosis and triage relative to physicians and laypeople is not well understood.MethodsWe compared the predictive accuracy of Generative Pre-trained Transformer 3 (GPT-3)'s diagnostic and triage ability for 48 validated synthetic case vignettes (<50 words; sixth-grade reading level or below) of both common (eg, viral illness) and severe (eg, heart attack) conditions to a nationally representative sample of 5000 lay people from the USA who could use the internet to find the correct options and 21 practising physicians at Harvard Medical School. There were 12 vignettes for each of four triage categories: emergent, within one day, within 1 week, and self-care. The correct diagnosis and triage category (ie, ground truth) for each vignette was determined by two general internists at Harvard Medical School. For each vignette, human respondents and GPT-3 were prompted to list diagnoses in order of likelihood, and the vignette was marked as correct if the ground-truth diagnosis was in the top three of the listed diagnoses. For triage accuracy, we examined whether the human respondents' and GPT-3's selected triage was exactly correct according to the four triage categories, or matched a dichotomised triage variable (emergent or within 1 day vs within 1 week or self-care). We estimated GPT-3's diagnostic and triage confidence on a given vignette using a modified bootstrap resampling procedure, and examined how well calibrated GPT-3's confidence was by computing calibration curves and Brier scores. We also performed subgroup analysis by case acuity, and an error analysis for triage advice to characterise how its advice might affect patients using this tool to decide if they should seek medical care immediately.FindingsAmong all cases, GPT-3 replied with the correct diagnosis in its top three for 88% (42/48, 95% CI 75–94) of cases, compared with 54% (2700/5000, 53–55) for lay individuals (p<0.0001) and 96% (637/666, 94–97) for physicians (p=0·012). GPT-3 triaged 70% correct (34/48, 57–82) versus 74% (3706/5000, 73–75; p=0.60) for lay individuals and 91% (608/666, 89–93%; p<0.0001) for physicians. As measured by the Brier score, GPT-3 confidence in its top prediction was reasonably well calibrated for diagnosis (Brier score=0·18) and triage (Brier score=0·22). We observed an inverse relationship between case acuity and GPT-3 accuracy (p<0·0001) with a fitted trend line of –8·33% decrease in accuracy for every level of increase in case acuity. For triage error analysis, GPT-3 deprioritised truly emergent cases in seven instances.InterpretationA general-purpose AI language model without any content-specific training could perform diagnosis at levels close to, but below, physicians and better than lay individuals. We found that GPT-3's performance was inferior to physicians for triage, sometimes by a large margin, and its performance was closer to that of lay individuals. Although the diagnostic performance of GPT-3 was comparable to physicians, it was significantly better than a typical person using a search engine.FundingThe National Heart, Lung, and Blood Institute.",['Generative Pre-trained Transformer 3 (GPT-3)'],"The research idea addresses the challenge of evaluating how well a general-purpose diagnostic and triage approach performs in comparison to physicians and laypeople, particularly given the difficulty of deploying tools that are typically trained for single tasks and may lack generalizability across different medical conditions. The study is motivated by the need to understand the accuracy and reliability of such an approach in identifying both common and severe health conditions and providing appropriate triage recommendations. The primary objective of the study is to compare the diagnostic and triage accuracy of a general-purpose approach against that of practicing physicians and lay individuals using a set of validated synthetic medical case vignettes. The aim is to assess the correctness of diagnoses and triage decisions across varying levels of case acuity and to evaluate how well confidence in these decisions corresponds to actual accuracy."
Engineering,Deep Learning for Integrated Origin–Destination Estimation and Traffic Sensor Location Problems,"Traffic control and management applications require the full realization of traffic flow data. Frequently, such data are acquired by traffic sensors with two issues: it is not practicable or even possible to place traffic sensors on every link in a network; sensors do not provide direct information about origin–destination (O–D) demand flows. Therefore, it is imperative to locate the best places to deploy traffic sensors and then augment the knowledge obtained from this link flow sample to predict the entire traffic flow of the network. This article provides a resilient deep learning (DL) architecture combined with a global sensitivity analysis tool to solve O–D estimation and sensor location problems simultaneously. The proposed DL architecture is based on the stacked sparse autoencoder (SAE) model for accurately estimating the entire O–D flows of the network using link flows, thus reversing the conventional traffic assignment problem. The SAE model extracts traffic flow characteristics and derives a meaningful relationship between traffic flow data and network topology. To train the proposed DL architecture, synthetic link flow data were created randomly from the historical demand data of the network. Finally, a global sensitivity analysis was implemented to prioritize the importance of each link in the O–D estimation step to solve the sensor location problem. Two networks of different sizes were used to validate the performance of the model. The efficiency of the proposed method for solving the combination of traffic flow estimation and sensor location problems was confirmed from a low root-mean-square error with a reduction in the number of link flows required.",['stacked sparse autoencoder (SAE) model'],"The research addresses the challenge of obtaining comprehensive traffic flow data for effective traffic control and management, given the practical limitations of placing sensors on every network link and the inability of sensors to directly measure origin–destination demand flows. It is crucial to determine optimal locations for traffic sensor deployment and to enhance the information gathered from limited link flow measurements to estimate the complete traffic flow across the network. The primary objective of the study is to accurately estimate the entire origin–destination traffic flows within a network using available link flow data while simultaneously identifying the best locations for sensor placement. This aims to improve the understanding of traffic patterns and optimize sensor deployment to support more effective traffic management strategies."
Engineering,Evaluation of artificial intelligence-powered screening for sexually transmitted infections-related skin lesions using clinical images and metadata,"Abstract Background Sexually transmitted infections (STIs) pose a significant global public health challenge. Early diagnosis and treatment reduce STI transmission, but rely on recognising symptoms and care-seeking behaviour of the individual. Digital health software that distinguishes STI skin conditions could improve health-seeking behaviour. We developed and evaluated a deep learning model to differentiate STIs from non-STIs based on clinical images and symptoms. Methods We used 4913 clinical images of genital lesions and metadata from the Melbourne Sexual Health Centre collected during 2010–2023. We developed two binary classification models to distinguish STIs from non-STIs: (1) a convolutional neural network (CNN) using images only and (2) an integrated model combining both CNN and fully connected neural network (FCN) using images and metadata. We evaluated the model performance by the area under the ROC curve (AUC) and assessed metadata contributions to the Image-only model. Results Our study included 1583 STI and 3330 non-STI images. Common STI diagnoses were syphilis (34.6%), genital warts (24.5%) and herpes (19.4%), while most non-STIs (80.3%) were conditions such as dermatitis, lichen sclerosis and balanitis. In both STI and non-STI groups, the most frequently observed groups were 25–34 years (48.6% and 38.2%, respectively) and heterosexual males (60.3% and 45.9%, respectively). The Image-only model showed a reasonable performance with an AUC of 0.859 (SD 0.013). The Image + Metadata model achieved a significantly higher AUC of 0.893 (SD 0.018) compared to the Image-only model ( p &lt; 0.01). Out of 21 metadata, the integration of demographic and dermatological metadata led to the most significant improvement in model performance, increasing AUC by 6.7% compared to the baseline Image-only model. Conclusions The Image + Metadata model outperformed the Image-only model in distinguishing STIs from other skin conditions. Using it as a screening tool in a clinical setting may require further development and evaluation with larger datasets.","['convolutional neural network (CNN)', 'fully connected neural network (FCN)']","The research addresses the significant global public health challenge posed by sexually transmitted infections (STIs), emphasizing the importance of early diagnosis and treatment to reduce transmission. The study highlights the need for improved recognition of STI-related skin conditions to enhance health-seeking behavior among individuals. The primary objective of the study is to develop and evaluate a method to differentiate STIs from non-STIs based on clinical images and associated patient information. This aims to improve the accuracy of distinguishing STI skin conditions from other dermatological issues, potentially serving as a screening tool in clinical settings."
Social Sciences,Systematic literature review: Quantum machine learning and its applications,"Quantum physics has changed the way we understand our environment, and one of its branches, quantum mechanics, has demonstrated accurate and consistent theoretical results. Quantum computing is the process of performing calculations using quantum mechanics. This field studies the quantum behavior of certain subatomic particles (photons, electrons, etc.) for subsequent use in performing calculations, as well as for large-scale information processing. These advantages are achieved through the use of quantum features, such as entanglement or superposition. These capabilities can give quantum computers an advantage in terms of computational time and cost over classical computers. Nowadays, scientific challenges are impossible to perform by classical computation due to computational complexity (more bytes than atoms in the observable universe) or the time it would take (thousands of years), and quantum computation is the only known answer. However, current quantum devices do not have yet the necessary qubits and are not fault-tolerant enough to achieve these goals. Nonetheless, there are other fields like machine learning, finance, or chemistry where quantum computation could be useful with current quantum devices. This manuscript aims to present a review of the literature published between 2017 and 2023 to identify, analyze, and classify the different types of algorithms used in quantum machine learning and their applications. The methodology follows the guidelines related to Systematic Literature Review methods, such as the one proposed by Kitchenham and other authors in the software engineering field. Consequently, this study identified 94 articles that used quantum machine learning techniques and algorithms and shows their implementation using computational quantum circuits or ansatzs. The main types of found algorithms are quantum implementations of classical machine learning algorithms, such as support vector machines or the k-nearest neighbor model, and classical deep learning algorithms, like quantum neural networks. One of the most relevant applications in the machine learning field is image classification. Many articles, especially within the classification, try to solve problems currently answered by classical machine learning but using quantum devices and algorithms. Even though results are promising, quantum machine learning is far from achieving its full potential. An improvement in quantum hardware is required for this potential to be achieved since the existing quantum computers lack enough quality, speed, and scale to allow quantum computing to achieve its full potential.","['support vector machines', 'k-nearest neighbor model', 'quantum neural networks']","The research idea centers on the limitations of current computational methods in addressing complex scientific challenges due to their extensive time and resource requirements, highlighting the potential of emerging technologies to overcome these barriers. It recognizes that while traditional approaches struggle with problems of immense complexity, alternative computational paradigms offer promising advantages that could transform various fields such as finance and chemistry. The research objective is to review and categorize the existing literature from 2017 to 2023 to identify and analyze different approaches and their applications within this emerging computational paradigm. The study aims to provide a comprehensive overview of the types of techniques employed and their practical uses, emphasizing the current state of development and the need for advancements in underlying technology to fully realize their potential."
Social Sciences,Unmasking bias in artificial intelligence: a systematic review of bias detection and mitigation strategies in electronic health record-based models,"Abstract Objectives Leveraging artificial intelligence (AI) in conjunction with electronic health records (EHRs) holds transformative potential to improve healthcare. However, addressing bias in AI, which risks worsening healthcare disparities, cannot be overlooked. This study reviews methods to handle various biases in AI models developed using EHR data. Materials and Methods We conducted a systematic review following the Preferred Reporting Items for Systematic Reviews and Meta-analyses guidelines, analyzing articles from PubMed, Web of Science, and IEEE published between January 01, 2010 and December 17, 2023. The review identified key biases, outlined strategies for detecting and mitigating bias throughout the AI model development, and analyzed metrics for bias assessment. Results Of the 450 articles retrieved, 20 met our criteria, revealing 6 major bias types: algorithmic, confounding, implicit, measurement, selection, and temporal. The AI models were primarily developed for predictive tasks, yet none have been deployed in real-world healthcare settings. Five studies concentrated on the detection of implicit and algorithmic biases employing fairness metrics like statistical parity, equal opportunity, and predictive equity. Fifteen studies proposed strategies for mitigating biases, especially targeting implicit and selection biases. These strategies, evaluated through both performance and fairness metrics, predominantly involved data collection and preprocessing techniques like resampling and reweighting. Discussion This review highlights evolving strategies to mitigate bias in EHR-based AI models, emphasizing the urgent need for both standardized and detailed reporting of the methodologies and systematic real-world testing and evaluation. Such measures are essential for gauging models’ practical impact and fostering ethical AI that ensures fairness and equity in healthcare.","['resampling', 'reweighting']","The research idea centers on the critical issue of bias in healthcare applications that utilize electronic health records, which poses a risk of exacerbating existing healthcare disparities. Addressing these biases is essential to ensure fairness and equity in healthcare delivery. The study recognizes the transformative potential of improving healthcare outcomes but emphasizes that bias cannot be overlooked in this context. The primary objective of the study is to review and synthesize existing approaches for identifying and mitigating various types of bias in healthcare-related applications using electronic health records. It aims to highlight the need for standardized reporting and real-world evaluation to assess the practical impact of these approaches and promote ethical practices that support fairness in healthcare."
Social Sciences,Larger and more instructable language models become less reliable,"Abstract The prevailing methods to make large language models more powerful and amenable have been based on continuous scaling up (that is, increasing their size, data volume and computational resources 1 ) and bespoke shaping up (including post-filtering 2,3 , fine tuning or use of human feedback 4,5 ). However, larger and more instructable large language models may have become less reliable. By studying the relationship between difficulty concordance, task avoidance and prompting stability of several language model families, here we show that easy instances for human participants are also easy for the models, but scaled-up, shaped-up models do not secure areas of low difficulty in which either the model does not err or human supervision can spot the errors. We also find that early models often avoid user questions but scaled-up, shaped-up models tend to give an apparently sensible yet wrong answer much more often, including errors on difficult questions that human supervisors frequently overlook. Moreover, we observe that stability to different natural phrasings of the same question is improved by scaling-up and shaping-up interventions, but pockets of variability persist across difficulty levels. These findings highlight the need for a fundamental shift in the design and development of general-purpose artificial intelligence, particularly in high-stakes areas for which a predictable distribution of errors is paramount.","['post-filtering', 'fine tuning', 'use of human feedback']","The research idea centers on the challenges associated with improving the reliability and accuracy of large language models, particularly as they become larger and more complex. The study addresses the problem that despite advancements aimed at enhancing these models, they may still produce errors that are difficult for human supervisors to detect, especially on tasks of varying difficulty. The research objective is to investigate the relationship between task difficulty, error occurrence, and response consistency in different language model versions. The study aims to understand how scaling and refinement efforts impact the models’ ability to handle easy versus difficult tasks and to highlight the implications for designing more dependable systems in contexts where error predictability is critical."
Social Sciences,Data extraction for evidence synthesis using a large language model: A proof‐of‐concept study,"Abstract Data extraction is a crucial, yet labor‐intensive and error‐prone part of evidence synthesis. To date, efforts to harness machine learning for enhancing efficiency of the data extraction process have fallen short of achieving sufficient accuracy and usability. With the release of large language models (LLMs), new possibilities have emerged to increase efficiency and accuracy of data extraction for evidence synthesis. The objective of this proof‐of‐concept study was to assess the performance of an LLM (Claude 2) in extracting data elements from published studies, compared with human data extraction as employed in systematic reviews. Our analysis utilized a convenience sample of 10 English‐language, open‐access publications of randomized controlled trials included in a single systematic review. We selected 16 distinct types of data, posing varying degrees of difficulty (160 data elements across 10 studies). We used the browser version of Claude 2 to upload the portable document format of each publication and then prompted the model for each data element. Across 160 data elements, Claude 2 demonstrated an overall accuracy of 96.3% with a high test–retest reliability (replication 1: 96.9%; replication 2: 95.0% accuracy). Overall, Claude 2 made 6 errors on 160 data items. The most common errors ( n = 4) were missed data items. Importantly, Claude 2's ease of use was high; it required no technical expertise or labeled training data for effective operation (i.e., zero‐shot learning). Based on findings of our proof‐of‐concept study, leveraging LLMs has the potential to substantially enhance the efficiency and accuracy of data extraction for evidence syntheses.",['zero‐shot learning'],"The research idea addresses the challenge that data extraction in evidence synthesis is a crucial but labor-intensive and error-prone process, with previous efforts to improve efficiency and accuracy falling short. This study is motivated by the need to find more effective ways to enhance the accuracy and usability of data extraction in systematic reviews. The primary objective of the study was to assess the performance of a new approach in extracting data elements from published studies, comparing its accuracy and reliability to human data extraction methods commonly used in systematic reviews. The study aimed to evaluate whether this approach could improve the efficiency and accuracy of data extraction for evidence synthesis without requiring specialized expertise or training."
Social Sciences,Artificial intelligence-driven virtual rehabilitation for people living in the community: A scoping review,"Abstract Virtual Rehabilitation (VRehab) is a promising approach to improving the physical and mental functioning of patients living in the community. The use of VRehab technology results in the generation of multi-modal datasets collected through various devices. This presents opportunities for the development of Artificial Intelligence (AI) techniques in VRehab, namely the measurement, detection, and prediction of various patients’ health outcomes. The objective of this scoping review was to explore the applications and effectiveness of incorporating AI into home-based VRehab programs. PubMed/MEDLINE, Embase, IEEE Xplore, Web of Science databases, and Google Scholar were searched from inception until June 2023 for studies that applied AI for the delivery of VRehab programs to the homes of adult patients. After screening 2172 unique titles and abstracts and 51 full-text studies, 13 studies were included in the review. A variety of AI algorithms were applied to analyze data collected from various sensors and make inferences about patients’ health outcomes, most involving evaluating patients’ exercise quality and providing feedback to patients. The AI algorithms used in the studies were mostly fuzzy rule-based methods, template matching, and deep neural networks. Despite the growing body of literature on the use of AI in VRehab, very few studies have examined its use in patients’ homes. Current research suggests that integrating AI with home-based VRehab can lead to improved rehabilitation outcomes for patients. However, further research is required to fully assess the effectiveness of various forms of AI-driven home-based VRehab, taking into account its unique challenges and using standardized metrics.","['fuzzy rule-based methods', 'deep neural networks']","The research idea centers on the potential of virtual rehabilitation (VRehab) to enhance the physical and mental functioning of patients living in the community, particularly through home-based programs. Despite the increasing interest in VRehab, there is limited understanding of its application and effectiveness when delivered in patients’ homes. The study aims to explore how integrating advanced techniques into home-based VRehab programs can improve rehabilitation outcomes for adult patients. The primary objective of the study was to examine the applications and effectiveness of incorporating these techniques into home-based virtual rehabilitation programs by reviewing existing research on their use with adult patients in community settings."
Social Sciences,CFSSynergy: Combining Feature-Based and Similarity-Based Methods for Drug Synergy Prediction,"Drug synergy prediction plays a vital role in cancer treatment. Because experimental approaches are labor-intensive and expensive, computational-based approaches get more attention. There are two types of computational methods for drug synergy prediction: feature-based and similarity-based. In feature-based methods, the main focus is to extract more discriminative features from drug pairs and cell lines to pass to the task predictor. In similarity-based methods, the similarities among all drugs and cell lines are utilized as features and fed into the task predictor. In this work, a novel approach, called CFSSynergy, that combines these two viewpoints is proposed. First, a discriminative representation is extracted for paired drugs and cell lines as input. We have utilized transformer-based architecture for drugs. For cell lines, we have created a similarity matrix between proteins using the Node2Vec algorithm. Then, the new cell line representation is computed by multiplying the protein–protein similarity matrix and the initial cell line representation. Next, we compute the similarity between unique drugs and unique cells using the learned representation for paired drugs and cell lines. Then, we compute a new representation for paired drugs and cell lines based on the similarity-based features and the learned features. Finally, these features are fed to XGBoost as a task predictor. Two well-known data sets were used to evaluate the performance of our proposed method: DrugCombDB and OncologyScreen. The CFSSynergy approach consistently outperformed existing methods in comparative evaluations. This substantiates the efficacy of our approach in capturing complex synergistic interactions between drugs and cell lines, setting it apart from conventional similarity-based or feature-based methods.","['transformer-based architecture', 'Node2Vec algorithm', 'XGBoost']","The research addresses the challenge of predicting drug synergy in cancer treatment, emphasizing the importance of identifying effective drug combinations to improve therapeutic outcomes. Experimental methods for determining drug synergy are labor-intensive and costly, creating a need for more efficient approaches to support cancer therapy development. The study aims to enhance the prediction of synergistic drug interactions by integrating different perspectives on drug and cell line characteristics. Specifically, the primary objective is to develop a novel approach that combines distinct viewpoints on drug pairs and cell lines to better capture the complex interactions that contribute to drug synergy, ultimately improving the accuracy of synergy predictions in cancer treatment."
Social Sciences,A voting gray wolf optimizer-based ensemble learning models for intrusion detection in the Internet of Things,"Abstract The Internet of Things (IoT) has garnered considerable attention from academic and industrial circles as a pivotal technology in recent years. The escalation of security risks is observed to be associated with the growing interest in IoT applications. Intrusion detection systems (IDS) have been devised as viable instruments for identifying and averting malicious actions in this context. Several techniques described in academic papers are thought to be very accurate, but they cannot be used in the real world because the datasets used to build and test the models do not accurately reflect and simulate the IoT network. Existing methods, on the other hand, deal with these issues, but they are not good enough for commercial use because of their lack of precision, low detection rate, receiver operating characteristic (ROC), and false acceptance rate (FAR). The effectiveness of these solutions is predominantly dependent on individual learners and is consequently influenced by the inherent limitations of each learning algorithm. This study introduces a new approach for detecting intrusion attacks in an IoT network, which involves the use of an ensemble learning technique based on gray wolf optimizer (GWO). The novelty of this study lies in the proposed voting gray wolf optimizer (GWO) ensemble model, which incorporates two crucial components: a traffic analyzer and a classification phase engine. The model employs a voting technique to combine the probability averages of the base learners. Secondly, the combination of feature selection and feature extraction techniques is to reduce dimensionality. Thirdly, the utilization of GWO is employed to optimize the parameters of ensemble models. Similarly, the approach employs the most authentic intrusion detection datasets that are accessible and amalgamates multiple learners to generate ensemble learners. The hybridization of information gain (IG) and principal component analysis (PCA) was employed to reduce dimensionality. The study utilized a novel GWO ensemble learning approach that incorporated a decision tree, random forest, K-nearest neighbor, and multilayer perceptron for classification. To evaluate the efficacy of the proposed model, two authentic datasets, namely, BoT-IoT and UNSW-NB15, were scrutinized. The GWO-optimized ensemble model demonstrates superior accuracy when compared to other machine learning-based and deep learning models. Specifically, the model achieves an accuracy rate of 99.98%, a DR of 99.97%, a precision rate of 99.94%, an ROC rate of 99.99%, and an FAR rate of 1.30 on the BoT-IoT dataset. According to the experimental results, the proposed ensemble model optimized by GWO achieved an accuracy of 100%, a DR of 99.9%, a precision of 99.59%, an ROC of 99.40%, and an FAR of 1.5 when tested on the UNSW-NB15 dataset.","['ensemble learning technique', 'gray wolf optimizer (GWO)', 'voting technique', 'feature selection', 'information gain (IG)', 'principal component analysis (PCA)', 'decision tree', 'random forest', 'K-nearest neighbor', 'multilayer perceptron']","The research idea centers on the increasing security risks associated with the widespread adoption of Internet of Things (IoT) applications, highlighting the challenge of effectively identifying and preventing malicious actions within IoT networks. Existing solutions for intrusion detection are limited in their real-world applicability due to issues such as lack of precision, low detection rates, and high false acceptance rates, which hinder their commercial viability. The study is motivated by the need to develop more accurate and reliable methods to address these security concerns in IoT environments. The primary objective of the study is to propose and evaluate a novel approach for detecting intrusion attacks in IoT networks that improves accuracy and detection performance. This approach aims to overcome the limitations of current methods by enhancing the identification of malicious activities, thereby contributing to more secure IoT applications."
Social Sciences,UANet: An Uncertainty-Aware Network for Building Extraction From Remote Sensing Images,"Building extraction aims to segment building pixels from remote sensing images and plays an essential role in many applications, such as city planning and urban dynamic monitoring. Over the past few years, deep learning methods with encoder–decoder architectures have achieved remarkable performance due to their powerful feature representation capability. Nevertheless, due to the varying scales and styles of buildings, conventional deep learning models always suffer from uncertain predictions and cannot accurately distinguish the complete footprints of the building from the complex distribution of ground objects, leading to a large degree of omission and commission. In this paper, we realize the importance of uncertain prediction and propose a novel and straightforward Uncertainty-Aware Network (UANet) to alleviate this problem. Specifically, we first apply a general encoder–decoder network to obtain a building extraction map with relatively high uncertainty. Second, in order to aggregate the useful information in the highest-level features, we design a Prior Information Guide Module to guide the highest-level features in learning the prior information from the conventional extraction map. Third, based on the uncertain extraction map, we introduce an Uncertainty Rank Algorithm to measure the uncertainty level of each pixel belonging to the foreground and the background. We further combine this algorithm with the proposed Uncertainty-Aware Fusion Module to facilitate level-by-level feature refinement and obtain the final refined extraction map with low uncertainty. To verify the performance of our proposed UANet, we conduct extensive experiments on three public building datasets, including the WHU building dataset, the Massachusetts building dataset, and the Inria aerial image dataset. Results demonstrate that the proposed UANet outperforms other state-of-the-art algorithms by a large margin. The source code of the proposed UANet is available at https://github.com/Henryjiepanli/Uncertainty-aware-Network.","['deep learning methods with encoder–decoder architectures', 'encoder–decoder network']","The research addresses the challenge of accurately identifying building footprints from remote sensing images, which is crucial for applications such as city planning and monitoring urban dynamics. The problem arises due to the varying scales and styles of buildings, as well as the complex distribution of ground objects, leading to uncertain and incomplete building extraction results. The primary aim of the study is to improve the precision of building segmentation by addressing the uncertainty in predictions and enhancing the completeness of building footprint identification from remote sensing imagery. This objective seeks to reduce errors of omission and commission in building extraction to support more reliable urban analysis and planning."
Social Sciences,One-Step Multi-View Clustering With Diverse Representation,"Multi-View clustering has attracted broad attention due to its capacity to utilize consistent and complementary information among views. Although tremendous progress has been made recently, most existing methods undergo high complexity, preventing them from being applied to large-scale tasks. Multi-View clustering via matrix factorization is a representative to address this issue. However, most of them map the data matrices into a fixed dimension, limiting the model's expressiveness. Moreover, a range of methods suffers from a two-step process, i.e., multimodal learning and the subsequent <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> <tex-math notation=""LaTeX"">$k$</tex-math> </inline-formula> -means, inevitably causing a suboptimal clustering result. In light of this, we propose a one-step multi-view clustering with diverse representation (OMVCDR) method, which incorporates multi-view learning and <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> <tex-math notation=""LaTeX"">$k$</tex-math> </inline-formula> -means into a unified framework. Specifically, we first project original data matrices into various latent spaces to attain comprehensive information and auto-weight them in a self-supervised manner. Then, we directly use the information matrices under diverse dimensions to obtain consensus discrete clustering labels. The unified work of representation learning and clustering boosts the quality of the final results. Furthermore, we develop an efficient optimization algorithm with proven convergence to solve the resultant problem. Comprehensive experiments on various datasets demonstrate the promising clustering performance of our proposed method. The code is publicly available at https://github.com/wanxinhang/OMVCDR.","['Multi-View clustering via matrix factorization', 'k-means', 'multi-view learning', 'representation learning']","The research idea centers on addressing the challenges in multi-view clustering, particularly the limitations posed by high complexity and fixed-dimensional data representation, which hinder the applicability and expressiveness of existing methods in handling large-scale tasks. The study highlights the problem of suboptimal clustering results caused by the common two-step process of multimodal learning followed by clustering. The primary objective of the study is to develop a unified approach that integrates multi-view learning and clustering into a single framework to improve the quality of clustering outcomes. This approach aims to capture comprehensive information from diverse data representations and achieve consensus clustering labels more effectively than previous methods."
Social Sciences,Crafting personalized learning paths with AI for lifelong learning: a systematic literature review,"The rapid evolution of knowledge requires constantly acquiring and updating skills, making lifelong learning crucial. Despite decades of artificial intelligence, recent advances promote new solutions to personalize learning in this context. The purpose of this article is to explore the current state of research on the development of artificial intelligence-mediated solutions for the design of personalized learning paths. To achieve this, a systematic literature review (SRL) of 78 articles published between 2019 and 2024 from the Scopus and Web or Science databases was conducted, answering seven questions grouped into three themes: characteristics of the published research, context of the research, and type of solution analyzed. This study identified that: (a) the greatest production of scientific research on the topic is developed in China, India and the United States, (b) the focus is mainly directed towards the educational context at the higher education level with areas of opportunity for application in the work context, and (c) the development of adaptive learning technologies predominates; however, there is a growing interest in the application of generative language models. This article contributes to the growing interest and literature related to personalized learning under artificial intelligence mediated solutions that will serve as a basis for academic institutions and organizations to design programs under this model.",['generative language models'],"The rapid evolution of knowledge necessitates continuous skill acquisition and updating, making lifelong learning increasingly important. This study addresses the growing need to understand how personalized learning paths can be designed to support individuals in this context. The primary aim of the study is to explore the current state of research on the development of solutions for personalized learning paths by reviewing existing literature. It seeks to identify key characteristics, contexts, and types of solutions in the field to inform academic institutions and organizations in designing effective personalized learning programs."
Social Sciences,Applications and challenges of neural networks in otolaryngology (Review),"Artificial Intelligence (AI) has become a topic of interest that is frequently debated in all research fields. The medical field is no exception, where several unanswered questions remain. When and how this field can benefit from AI support in daily routines are the most frequently asked questions. The present review aims to present the types of neural networks (NNs) available for development, discussing their advantages, disadvantages and how they can be applied practically. In addition, the present review summarizes how NNs (combined with various other features) have already been applied in studies in the ear nose throat research field, from assisting diagnosis to treatment management. Although the answer to this question regarding AI remains elusive, understanding the basics and types of applicable NNs can lead to future studies possibly using more than one type of NN. This approach may bypass the actual limitations in accuracy and relevance of information generated by AI. The proposed studies, the majority of which used convolutional NNs, obtained accuracies varying 70-98%, with a number of studies having the AI trained on a limited number of cases (<100 patients). The lack of standardization in AI protocols for research negatively affects data homogeneity and transparency of databases.","['neural networks (NNs)', 'convolutional neural networks (convolutional NNs)']","The research idea centers on the ongoing debate and unresolved questions within the medical field regarding the appropriate timing and manner in which emerging technologies can support daily clinical routines. There is a need to understand the practical applications, advantages, and limitations of these technologies in specific medical specialties, such as ear, nose, and throat research. The study highlights concerns about the lack of standardization in research protocols, which affects the consistency and transparency of information used in this area. The primary objective of the study is to review and summarize the existing types of these technologies available for development, discussing their practical applications, benefits, and drawbacks in the medical field, particularly focusing on their use in diagnosis and treatment management within ear, nose, and throat research. Additionally, the study aims to provide a foundation for future research that may overcome current limitations related to accuracy and relevance of information by exploring combined approaches."
Social Sciences,Making Sense of Machine Learning: A Review of Interpretation Techniques and Their Applications,"Transparency in AI models is essential for promoting human–AI collaboration and ensuring regulatory compliance. However, interpreting these models is a complex process influenced by various methods and datasets. This study presents a comprehensive overview of foundational interpretation techniques, meticulously referencing the original authors and emphasizing their pivotal contributions. Recognizing the seminal work of these pioneers is imperative for contextualizing the evolutionary trajectory of interpretation in the field of AI. Furthermore, this research offers a retrospective analysis of interpretation techniques, critically evaluating their inherent strengths and limitations. We categorize these techniques into model-based, representation-based, post hoc, and hybrid methods, delving into their diverse applications. Furthermore, we analyze publication trends over time to see how the adoption of advanced computational methods within various categories of interpretation techniques has shaped the development of AI interpretability over time. This analysis highlights a notable preference shift towards data-driven approaches in the field. Moreover, we consider crucial factors such as the suitability of these techniques for generating local or global insights and their compatibility with different data types, including images, text, and tabular data. This structured categorization serves as a guide for practitioners navigating the landscape of interpretation techniques in AI. In summary, this review not only synthesizes various interpretation techniques but also acknowledges the contributions of their original authors. By emphasizing the origins of these techniques, we aim to enhance AI model explainability and underscore the importance of recognizing biases, uncertainties, and limitations inherent in the methods and datasets. This approach promotes the ethical and practical use of interpretation insights, empowering AI practitioners, researchers, and professionals to make informed decisions when selecting techniques for responsible AI implementation in real-world scenarios.","['model-based methods', 'representation-based methods', 'hybrid methods']","The research idea centers on the importance of transparency to promote effective collaboration and ensure compliance with regulations, highlighting the complexity involved in interpreting models due to the variety of methods and datasets. The study recognizes the significance of acknowledging foundational contributions to understand the development and evolution of interpretation approaches. The primary objective of the study is to provide a comprehensive overview and retrospective evaluation of interpretation techniques, categorizing them and examining their applications, strengths, and limitations. Additionally, the research aims to emphasize the ethical and practical considerations in using these techniques, encouraging informed and responsible decision-making in real-world contexts."
Social Sciences,Artificial Intelligence to Automate Network Meta-Analyses: Four Case Studies to Evaluate the Potential Application of Large Language Models,"The emergence of artificial intelligence, capable of human-level performance on some tasks, presents an opportunity to revolutionise development of systematic reviews and network meta-analyses (NMAs). In this pilot study, we aim to assess use of a large-language model (LLM, Generative Pre-trained Transformer 4 [GPT-4]) to automatically extract data from publications, write an R script to conduct an NMA and interpret the results. We considered four case studies involving binary and time-to-event outcomes in two disease areas, for which an NMA had previously been conducted manually. For each case study, a Python script was developed that communicated with the LLM via application programming interface (API) calls. The LLM was prompted to extract relevant data from publications, to create an R script to be used to run the NMA and then to produce a small report describing the analysis. The LLM had a > 99% success rate of accurately extracting data across 20 runs for each case study and could generate R scripts that could be run end-to-end without human input. It also produced good quality reports describing the disease area, analysis conducted, results obtained and a correct interpretation of the results. This study provides a promising indication of the feasibility of using current generation LLMs to automate data extraction, code generation and NMA result interpretation, which could result in significant time savings and reduce human error. This is provided that routine technical checks are performed, as recommend for human-conducted analyses. Whilst not currently 100% consistent, LLMs are likely to improve with time.","['large-language model (LLM, Generative Pre-trained Transformer 4 [GPT-4])']","The study addresses the challenge of efficiently conducting systematic reviews and network meta-analyses, which are traditionally time-consuming and prone to human error. It highlights the potential to transform these processes by automating key tasks involved in data extraction and interpretation, thereby improving the speed and accuracy of evidence synthesis in healthcare research. The primary aim of the study is to evaluate the feasibility of automating the extraction of data from publications, the generation of scripts for network meta-analyses, and the interpretation of results across multiple case studies. This pilot investigation seeks to determine whether such automation can produce accurate and reliable outputs that may ultimately enhance the efficiency and quality of systematic reviews and meta-analyses."
Social Sciences,Artificial intelligence for oral squamous cell carcinoma detection based on oral photographs: A comprehensive literature review,"Abstract Introduction Oral squamous cell carcinoma (OSCC) presents a significant global health challenge. The integration of artificial intelligence (AI) and computer vision holds promise for the early detection of OSCC through the analysis of digitized oral photographs. This literature review explores the landscape of AI‐driven OSCC automatic detection, assessing both the performance and limitations of the current state of the art. Materials and Methods An electronic search using several data base was conducted, and a systematic review performed in accordance with PRISMA guidelines (CRD42023441416). Results Several studies have demonstrated remarkable results for this task, consistently achieving sensitivity rates exceeding 85% and accuracy rates surpassing 90%, often encompassing around 1000 images. The review scrutinizes these studies, shedding light on their methodologies, including the use of recent machine learning and pattern recognition approaches coupled with different supervision strategies. However, comparing the results from different papers is challenging due to variations in the datasets used. Discussion Considering these findings, this review underscores the urgent need for more robust and reliable datasets in the field of OSCC detection. Furthermore, it highlights the potential of advanced techniques such as multi‐task learning, attention mechanisms, and ensemble learning as crucial tools in enhancing the accuracy and sensitivity of OSCC detection through oral photographs. Conclusion These insights collectively emphasize the transformative impact of AI‐driven approaches on early OSCC diagnosis, with the potential to significantly improve patient outcomes and healthcare practices.","['machine learning', 'multi-task learning', 'attention mechanisms', 'ensemble learning']","The research addresses the significant global health challenge posed by oral squamous cell carcinoma (OSCC) and the importance of early detection to improve patient outcomes. It highlights the current landscape of efforts aimed at identifying OSCC through the examination of oral photographs, emphasizing the need for more reliable and robust datasets to support these efforts. The primary objective of the study is to review and assess the existing literature on automatic detection of OSCC, focusing on the performance and limitations of current approaches. This review aims to provide insights that could enhance early diagnosis practices and ultimately contribute to better healthcare outcomes for patients affected by OSCC."
Social Sciences,Diagnostic Performance Comparison between Generative AI and Physicians: A Systematic Review and Meta-Analysis,"Abstract Background The rapid advancement of generative artificial intelligence (AI) has led to the wide dissemination of models with exceptional understanding and generation of human language. Their integration into healthcare has shown potential for improving medical diagnostics, yet a comprehensive diagnostic performance evaluation of generative AI models and the comparison of their diagnostic performance with that of physicians has not been extensively explored. Methods In this systematic review and meta-analysis, a comprehensive search of Medline, Scopus, Web of Science, Cochrane Central, and MedRxiv was conducted for studies published from June 2018 through December 2023, focusing on those that validate generative AI models for diagnostic tasks. The risk of bias was assessed using the Prediction Model Study Risk of Bias Assessment Tool. Meta-regression was performed to summarize the performance of the models and to compare the accuracy of the models with that of physicians. Results The search resulted in 54 studies being included in the meta-analysis. Nine generative AI models were evaluated across 17 medical specialties. The quality assessment indicated a high risk of bias in the majority of studies, primarily due to small sample sizes. The overall accuracy for generative AI models across 54 studies was 56.9% (95% confidence interval [CI]: 51.0–62.7%). The meta-analysis demonstrated that, on average, physicians exceeded the accuracy of the models (difference in accuracy: 14.4% [95% CI: 4.9–23.8%], p-value =0.004). However, both Prometheus (Bing) and GPT-4 showed slightly better performance compared to non-experts (-2.3% [95% CI: -27.0–22.4%], p-value = 0.848 and -0.32% [95% CI: -14.4–13.7%], p-value = 0.962), but slightly underperformed when compared to experts (10.9% [95% CI: -13.1–35.0%], p-value = 0.356 and 12.9% [95% CI: 0.15–25.7%], p-value = 0.048). The sub-analysis revealed significantly improved accuracy in the fields of Gynecology, Pediatrics, Orthopedic surgery, Plastic surgery, and Otolaryngology, while showing reduced accuracy for Neurology, Psychiatry, Rheumatology, and Endocrinology compared to that of General Medicine. No significant heterogeneity was observed based on the risk of bias. Conclusions Generative AI exhibits promising diagnostic capabilities, with accuracy varying significantly by model and medical specialty. Although they have not reached the reliability of expert physicians, the findings suggest that generative AI models have the potential to enhance healthcare delivery and medical education, provided they are integrated with caution and their limitations are well-understood. Key Points Question: What is the diagnostic accuracy of generative AI models and how does this accuracy compare to that of physicians? Findings: This meta-analysis found that generative AI models have a pooled accuracy of 56.9% (95% confidence interval: 51.0–62.7%). The accuracy of expert physicians exceeds that of AI in all specialties, however, some generative AI models are comparable to non-expert physicians. Meaning: The diagnostic performance of generative AI models suggests that they do not match the level of experienced physicians but that they may have potential applications in healthcare delivery and medical education.",['generative AI models'],"The research idea addresses the growing integration of advanced language-based technologies into healthcare, highlighting the need to understand their diagnostic performance compared to human physicians. Despite the potential for improving medical diagnostics, there has been limited comprehensive evaluation of how these technologies perform across various medical specialties and in comparison to expert and non-expert physicians. The study aims to fill this gap by systematically reviewing and synthesizing existing evidence on diagnostic accuracy. The primary objective of the study is to evaluate the diagnostic accuracy of these technologies across multiple medical specialties and to compare their performance directly with that of physicians, both experts and non-experts. This comparison seeks to determine the extent to which these technologies can support or enhance healthcare delivery and medical education while acknowledging their current limitations relative to experienced medical professionals."
Social Sciences,Methodological insights into ChatGPT’s screening performance in systematic reviews,"Abstract Background The screening process for systematic reviews and meta-analyses in medical research is a labor-intensive and time-consuming task. While machine learning and deep learning have been applied to facilitate this process, these methods often require training data and user annotation. This study aims to assess the efficacy of ChatGPT, a large language model based on the Generative Pretrained Transformers (GPT) architecture, in automating the screening process for systematic reviews in radiology without the need for training data. Methods A prospective simulation study was conducted between May 2nd and 24th, 2023, comparing ChatGPT’s performance in screening abstracts against that of general physicians (GPs). A total of 1198 abstracts across three subfields of radiology were evaluated. Metrics such as sensitivity, specificity, positive and negative predictive values (PPV and NPV), workload saving, and others were employed. Statistical analyses included the Kappa coefficient for inter-rater agreement, ROC curve plotting, AUC calculation, and bootstrapping for p-values and confidence intervals. Results ChatGPT completed the screening process within an hour, while GPs took an average of 7–10 days. The AI model achieved a sensitivity of 95% and an NPV of 99%, slightly outperforming the GPs’ sensitive consensus (i.e., including records if at least one person includes them). It also exhibited remarkably low false negative counts and high workload savings, ranging from 40 to 83%. However, ChatGPT had lower specificity and PPV compared to human raters. The average Kappa agreement between ChatGPT and other raters was 0.27. Conclusions ChatGPT shows promise in automating the article screening phase of systematic reviews, achieving high sensitivity and workload savings. While not entirely replacing human expertise, it could serve as an efficient first-line screening tool, particularly in reducing the burden on human resources. Further studies are needed to fine-tune its capabilities and validate its utility across different medical subfields.","['machine learning', 'deep learning', 'Generative Pretrained Transformers (GPT) architecture']","The research addresses the challenge of the labor-intensive and time-consuming screening process for systematic reviews and meta-analyses in medical research, which requires significant human effort and resources. This study is motivated by the need to find more efficient ways to manage the screening workload without compromising accuracy. The primary objective of the study is to evaluate the effectiveness of an automated approach in conducting the screening process for systematic reviews in radiology, aiming to reduce the burden on human reviewers while maintaining high sensitivity and reliability. The study seeks to determine whether this approach can serve as a useful first-line screening tool to improve efficiency in the review process across different medical subfields."
Social Sciences,Machine Learning-Assisted Design of Advanced Polymeric Materials,"ConspectusPolymeric material research is encountering a new paradigm driven by machine learning (ML) and big data. The ML-assisted design has proven to be a successful approach for designing novel high-performance polymeric materials. This goal is mainly achieved through the following procedure: structure representation and database construction, establishment of a ML-based property prediction model, virtual design and high-throughput screening. The key to this approach lies in training ML models that delineate structure–property relationships based on available polymer data (e.g., structure, component, and property data), enabling the screening of promising polymers that satisfy the targeted property requirements. However, the relative scarcity of high-quality polymer data and the complex polymeric multiscale structure–property relationships pose challenges for this ML-assisted design method, such as data and modeling challenges.In this Account, we summarize the state-of-the-art advancements concerning the ML-assisted design of polymeric materials. Regarding structure representation and database construction, the digital representations of polymers are the predominant methods in cheminformatics along with some newly developed methods that integrate the polymeric multiscale structure characteristics. When establishing a ML-based property prediction model, the key is choosing and optimizing ML models to attain high-precision predictions across a vast chemical structure space. Advanced ML algorithms, such as transfer learning and multitask learning, have been utilized to address the data and modeling challenges. During the ML-assisted screening process, by defining and combining polymer genes, virtual polymer candidates are generated, and subsequently, their properties are predicted and high-throughput screened using ML property prediction models. Finally, the promising polymers identified through this approach are verified by computer simulations and experiments.We provide an overview of our recent efforts toward developing ML-assisted design approaches for discovering advanced polymeric materials and emphasize the intricate nature of polymer structural design. To well describe the multiscale structures of polymers, new structure representation methods, such as polymer fingerprint and cross-linking descriptors, were developed. Moreover, a multifidelity learning method was proposed to leverage the multisource isomerous polymer data from experiments and simulations. Additionally, graph neural networks and Bayesian optimization methods have been developed and applied for predicting polymer properties as well as designing polymer structures and compositions.Finally, we identify the current challenges and point out the development directions in this emerging field. It is highly desirable to establish new structure representation and advanced ML modeling methods for polymeric materials, particularly when constructing polymer large models based on chemical language. Through this Account, we seek to stimulate further interest and foster active collaborations for developing ML-assisted design approaches and realizing the innovation of advanced polymeric materials.","['transfer learning', 'multifidelity learning', 'graph neural networks', 'Bayesian optimization']","The research idea centers on addressing the challenges in designing novel high-performance polymeric materials, particularly due to the complexity of polymer multiscale structures and the scarcity of high-quality polymer data. The study highlights the need for improved approaches to represent polymer structures and understand their relationships with material properties to facilitate the discovery of promising polymers that meet targeted requirements. The primary objective of the study is to summarize recent advancements in methods for designing advanced polymeric materials, emphasizing the development of new structure representation techniques and strategies to overcome data limitations. Additionally, the study aims to identify current challenges and future directions to stimulate further research and collaboration in the innovation of polymeric materials."
Social Sciences,The Sociodemographic Biases in Machine Learning Algorithms: A Biomedical Informatics Perspective,"Artificial intelligence models represented in machine learning algorithms are promising tools for risk assessment used to guide clinical and other health care decisions. Machine learning algorithms, however, may house biases that propagate stereotypes, inequities, and discrimination that contribute to socioeconomic health care disparities. The biases include those related to some sociodemographic characteristics such as race, ethnicity, gender, age, insurance, and socioeconomic status from the use of erroneous electronic health record data. Additionally, there is concern that training data and algorithmic biases in large language models pose potential drawbacks. These biases affect the lives and livelihoods of a significant percentage of the population in the United States and globally. The social and economic consequences of the associated backlash cannot be underestimated. Here, we outline some of the sociodemographic, training data, and algorithmic biases that undermine sound health care risk assessment and medical decision-making that should be addressed in the health care system. We present a perspective and overview of these biases by gender, race, ethnicity, age, historically marginalized communities, algorithmic bias, biased evaluations, implicit bias, selection/sampling bias, socioeconomic status biases, biased data distributions, cultural biases and insurance status bias, conformation bias, information bias and anchoring biases and make recommendations to improve large language model training data, including de-biasing techniques such as counterfactual role-reversed sentences during knowledge distillation, fine-tuning, prefix attachment at training time, the use of toxicity classifiers, retrieval augmented generation and algorithmic modification to mitigate the biases moving forward.","['knowledge distillation', 'fine-tuning', 'retrieval augmented generation']","The research addresses the problem of biases related to sociodemographic characteristics such as race, ethnicity, gender, age, insurance, and socioeconomic status that contribute to health care disparities and undermine sound health care risk assessment and medical decision-making. These biases, stemming from erroneous data and other sources, perpetuate stereotypes, inequities, and discrimination that affect a significant portion of the population both in the United States and globally, leading to serious social and economic consequences. The primary aim of the study is to outline and provide a comprehensive overview of the various sociodemographic and systemic biases that impact health care risk assessment and decision-making. Additionally, the study seeks to offer recommendations to address and mitigate these biases within the health care system to improve fairness and equity in health outcomes."
Social Sciences,Collective Constitutional AI: Aligning a Language Model with Public Input,"There is growing consensus that language model (LM) developers should not be the sole deciders of LM behavior, creating a need for methods that enable the broader public to collectively shape the behavior of LM systems that affect them. To address this need, we present Collective Constitutional AI (CCAI): a multi-stage process for sourcing and integrating public input into LMs—from identifying a target population to sourcing principles to training and evaluating a model. We demonstrate the real-world practicality of this approach by creating what is, to our knowledge, the first LM fine-tuned with collectively sourced public input and evaluating this model against a baseline model trained with established principles from a LM developer. Our quantitative evaluations demonstrate several benefits of our approach: the CCAI-trained model shows lower bias across nine social dimensions compared to the baseline model, while maintaining equivalent performance on language, math, and helpful-harmless evaluations. Qualitative comparisons of the models suggest that the models differ on the basis of their respective constitutions, e.g., when prompted with contentious topics, the CCAI-trained model tends to generate responses that reframe the matter positively instead of a refusal. These results demonstrate a promising, tractable pathway toward publicly informed development of language models.",['fine-tuning'],"The research addresses the growing concern that developers alone should not determine the behavior of language systems that impact the public, highlighting the need for approaches that allow broader public participation in shaping these behaviors. This reflects a motivation to democratize the influence over technologies that affect society by incorporating diverse public perspectives. The primary objective of the study is to explore and demonstrate a process for sourcing and integrating public input into the development of language systems, aiming to create outputs that reflect collectively sourced principles rather than solely developer-established guidelines. The study seeks to evaluate the effectiveness of this approach in producing responses that reduce bias across various social dimensions while maintaining overall performance, thereby offering a pathway toward more publicly informed development practices."
Social Sciences,AI-POWERED FRAUD DETECTION IN BANKING: SAFEGUARDING FINANCIAL TRANSACTIONS,"The banking industry's metamorphosis through digitalization has unquestionably revolutionized accessibility and convenience for customers worldwide. However, this paradigm shift has ushered in a new era of challenges, most notably in the realm of cybersecurity. Conventional rule-based fraud detection strategies have struggled to keep pace with the rapid evolution of cyber threats, prompting a surge of interest in more adaptive approaches like unsupervised learning. Furthermore, the COVID-19 pandemic has exacerbated the issue of bank fraud due to the widespread transition to online platforms and the proliferation of charitable funds, which present ripe opportunities for exploitation by cybercriminals. In response to these pressing concerns, this study delves into the realm of machine learning algorithms for the analysis and identification of fraudulent banking transactions. Notably, it contributes scientific novelty by developing models specifically tailored to this purpose and implementing innovative preprocessing techniques to enhance detection accuracy. Utilizing a diverse array of algorithms, including Random Forest, K-Nearest Neighbor (KNN), Naïve Bayes, Decision Trees, and Logistic Regression, the study showcases promising results. In particular, logistic regression and decision tree models exhibit impressive accuracy and Area Under the Curve (AUC) values of approximately 0.98, 0.97 and 0.95, 0.94, respectively. Given the pervasive nature of banking fraud in our digital society, the utilization of artificial intelligence algorithms for fraud detection stands as a critical and timely endeavor, promising enhanced security and trust in the financial ecosystem.","['unsupervised learning', 'Random Forest', 'K-Nearest Neighbor (KNN)', 'Naïve Bayes', 'Decision Trees', 'Logistic Regression']","The banking industry’s transformation through digitalization has significantly improved customer accessibility and convenience but has also introduced new challenges, particularly in the area of cybersecurity. The rapid evolution of cyber threats has rendered traditional fraud detection methods less effective, while the COVID-19 pandemic has intensified the problem of bank fraud due to increased online activity and the rise of charitable fund transactions vulnerable to exploitation. This study aims to address these pressing concerns by focusing on the identification and analysis of fraudulent banking transactions. Its primary objective is to develop and implement approaches specifically designed to enhance the detection of bank fraud, thereby contributing to improved security and trust within the financial sector."
Social Sciences,Do large language models show decision heuristics similar to humans? A case study using GPT-3.5.,"A Large Language Model (LLM) is an artificial intelligence system trained on vast amounts of natural language data, enabling it to generate human-like responses to written or spoken language input. Generative Pre-Trained Transformer (GPT)-3.5 is an example of an LLM that supports a conversational agent called ChatGPT. In this work, we used a series of novel prompts to determine whether ChatGPT shows heuristics and other context-sensitive responses. We also tested the same prompts on human participants. Across four studies, we found that ChatGPT was influenced by random anchors in making estimates (anchoring, Study 1); it judged the likelihood of two events occurring together to be higher than the likelihood of either event occurring alone, and it was influenced by anecdotal information (representativeness and availability heuristic, Study 2); it found an item to be more efficacious when its features were presented positively rather than negatively-even though both presentations contained statistically equivalent information (framing effect, Study 3); and it valued an owned item more than a newly found item even though the two items were objectively identical (endowment effect, Study 4). In each study, human participants showed similar effects. Heuristics and context-sensitive responses in humans are thought to be driven by cognitive and affective processes such as loss aversion and effort reduction. The fact that an LLM-which lacks these processes-also shows such responses invites consideration of the possibility that language is sufficiently rich to carry these effects and may play a role in generating these effects in humans. (PsycInfo Database Record (c) 2024 APA, all rights reserved).",['Generative Pre-Trained Transformer (GPT)-3.5'],"The research idea centers on understanding whether certain cognitive biases and context-sensitive responses, typically observed in human judgment and decision-making, can also be exhibited by a language-based conversational agent. This inquiry is motivated by the observation that humans display heuristics such as anchoring, representativeness, availability, framing effects, and the endowment effect, which are thought to arise from cognitive and affective processes. The study explores the possibility that language itself may carry these effects and contribute to their manifestation in human cognition. The primary objective of the study is to investigate whether a conversational agent demonstrates similar heuristics and context-sensitive responses as humans do across various judgment tasks. By comparing the agent’s responses to those of human participants, the study aims to assess the extent to which language alone might account for these cognitive biases."
Social Sciences,Predicting ground vibration during rock blasting using relevance vector machine improved with dual kernels and metaheuristic algorithms,"The ground vibration caused by rock blasting is an extremely hazardous outcome of the blasting operation. Blasting activity has detrimental effects on both the ecology and the human population living in proximity to the area. Evaluating the magnitude of blasting vibrations requires careful evaluation of the peak particle velocity (PPV) as a fundamental and essential parameter for quantifying vibration velocity. Therefore, this study employs models using the relevance vector machine (RVM) approach for predicting the PPV resulting from quarry blasting. This investigation utilized the conventional and optimized RVM models for the first time in ground vibration prediction. This work compares thirty-three RVM models to choose the most efficient performance model. The following conclusions have been mapped from the outcomes of the several analyses. The performance evaluation of each RVM model demonstrates each model achieved a performance of more than 0.85 during the testing phase, there was a strong correlation observed between the actual ground vibrations and the predicted ones. The analysis of performance metrics (RMSE = 21.2999 mm/s, 16.2272 mm/s, R = 0.9175, PI = 1.59, IOA = 0.8239, IOS = 0.2541), score analysis (= 93), REC curve (= 6.85E-03, close to the actual, i.e., 0), curve fitting (= 1.05 close to best fit, i.e., 1), AD test (= 11.607 close to the actual, i.e., 9.790), Wilcoxon test (= 95%), Uncertainty analysis (WCB = 0.0134), and computational cost (= 0.0180) demonstrate that PSO_DRVM model MD29 outperformed better than other RVM models in the testing phase. This study will help mining and civil engineers and blasting experts to select the best kernel function and its hyperparameters in estimating ground vibration during rock blasting project. In the context of the mining and civil industry, the application of this study offers significant potential for enhancing safety protocols and optimizing operational efficiency.","['relevance vector machine (RVM)', 'conventional RVM', 'optimized RVM']","The study addresses the hazardous impact of ground vibration caused by rock blasting, which poses significant risks to both the ecology and the human population living near blasting sites. Evaluating the magnitude of these vibrations is crucial for understanding and mitigating their detrimental effects. The primary aim of the study is to predict the peak particle velocity (PPV) resulting from quarry blasting in order to better quantify vibration velocity. This research seeks to assist mining and civil engineers, as well as blasting experts, in selecting the most effective approach for estimating ground vibration, thereby contributing to improved safety protocols and operational efficiency in the mining and civil industries."
Social Sciences,Triplet Contrastive Representation Learning for Unsupervised Vehicle Re-identification,"Part feature learning plays a crucial role in achieving fine-grained semantic understanding in unsupervised vehicle re-identification. However, existing approaches directly model part and global features, which can easily lead to severe gradient vanishing issues due to their unequal feature information and unreliable pseudo-labels. To address this problem, in this paper, we propose a triplet contrastive representation learning (TCRL) framework, which leverages cluster features to bridge the part features and global features for unsupervised vehicle re-identification. Specifically, TCRL devises three memory banks to store the instance/cluster features and proposes a proxy contrastive loss (PCL) to make contrastive learning between adjacent memory banks, thus presenting the associations between the part and global features as a transition of the part-cluster and cluster-global associations. Since the cluster memory bank copes with all the vehicle features, it can summarize them into a discriminative feature representation. To deeply exploit the instance/cluster information, TCRL proposes two additional loss functions. For the instance-level feature, a hybrid contrastive loss (HCL) re-defines the sample correlations by approaching the positive instance features and pushing all negative instance features away. For the cluster-level feature, a weighted regularization cluster contrastive loss (WRCCL) refines the pseudo labels by penalizing the mislabeled images according to the instance similarity. Extensive experiments show that TCRL outperforms many state-of-the-art unsupervised vehicle re-identification approaches.","['contrastive learning', 'proxy contrastive loss (PCL)', 'hybrid contrastive loss (HCL)']","The research idea centers on the challenge of achieving detailed semantic understanding in identifying vehicles without supervision, highlighting the difficulty caused by the imbalance and unreliability of part and global feature information. This imbalance can lead to significant issues in effectively distinguishing vehicles, which hampers progress in fine-grained vehicle recognition tasks. The study aims to overcome these challenges by improving the way different levels of vehicle features are connected and represented to enhance identification accuracy. The primary objective of the study is to develop a framework that better integrates and relates part-level and global-level vehicle features to improve unsupervised vehicle identification. It seeks to create a more discriminative and reliable representation of vehicle features by addressing the inconsistencies and errors in feature labeling, ultimately enhancing the performance of vehicle re-identification without relying on labeled data."
Social Sciences,Likelihood-based feature representation learning combined with neighborhood information for predicting circRNA–miRNA associations,"Connections between circular RNAs (circRNAs) and microRNAs (miRNAs) assume a pivotal position in the onset, evolution, diagnosis and treatment of diseases and tumors. Selecting the most potential circRNA-related miRNAs and taking advantage of them as the biological markers or drug targets could be conducive to dealing with complex human diseases through preventive strategies, diagnostic procedures and therapeutic approaches. Compared to traditional biological experiments, leveraging computational models to integrate diverse biological data in order to infer potential associations proves to be a more efficient and cost-effective approach. This paper developed a model of Convolutional Autoencoder for CircRNA-MiRNA Associations (CA-CMA) prediction. Initially, this model merged the natural language characteristics of the circRNA and miRNA sequence with the features of circRNA-miRNA interactions. Subsequently, it utilized all circRNA-miRNA pairs to construct a molecular association network, which was then fine-tuned by labeled samples to optimize the network parameters. Finally, the prediction outcome is obtained by utilizing the deep neural networks classifier. This model innovatively combines the likelihood objective that preserves the neighborhood through optimization, to learn the continuous feature representation of words and preserve the spatial information of two-dimensional signals. During the process of 5-fold cross-validation, CA-CMA exhibited exceptional performance compared to numerous prior computational approaches, as evidenced by its mean area under the receiver operating characteristic curve of 0.9138 and a minimal SD of 0.0024. Furthermore, recent literature has confirmed the accuracy of 25 out of the top 30 circRNA-miRNA pairs identified with the highest CA-CMA scores during case studies. The results of these experiments highlight the robustness and versatility of our model.","['Convolutional Autoencoder', 'deep neural networks classifier']","The study addresses the critical role of connections between circular RNAs (circRNAs) and microRNAs (miRNAs) in the onset, progression, diagnosis, and treatment of diseases and tumors. It highlights the importance of identifying the most promising circRNA-related miRNAs to serve as biological markers or drug targets, which could enhance preventive strategies, diagnostic procedures, and therapeutic approaches for complex human diseases. The primary aim of the study is to select and predict potential associations between circRNAs and miRNAs that can be utilized as biological markers or targets for disease management. This objective focuses on improving the identification of these associations to support more effective prevention, diagnosis, and treatment of diseases."
Social Sciences,DisenSemi: Semi-Supervised Graph Classification via Disentangled Representation Learning,"Graph classification is a critical task in numerous multimedia applications, where graphs are employed to represent diverse types of multimedia data, including images, videos, and social networks. Nevertheless, in the real world, labeled graph data are always limited or scarce. To address this issue, we focus on the semi-supervised graph classification task, which involves both supervised and unsupervised models learning from labeled and unlabeled data. In contrast to recent approaches that transfer the entire knowledge from the unsupervised model to the supervised one, we argue that an effective transfer should only retain the relevant semantics that align well with the supervised task. We introduce a novel framework termed in this article, which learns disentangled representation for semi-supervised graph classification. Specifically, a disentangled graph encoder is proposed to generate factorwise graph representations for both supervised and unsupervised models. Then, we train two models via supervised objective and mutual information (MI)-based constraints, respectively. To ensure the meaningful transfer of knowledge from the unsupervised encoder to the supervised one, we further define an MI-based disentangled consistency regularization between two models and identify the corresponding rationale that aligns well with the current graph classification task. Experiments conducted on various publicly available datasets demonstrate the effectiveness of our .","['semi-supervised graph classification', 'disentangled graph encoder']","The research addresses the challenge of limited labeled data in graph classification tasks, which are important for representing various types of multimedia data such as images, videos, and social networks. The study is motivated by the need to improve the learning process when both labeled and unlabeled data are available, emphasizing the importance of transferring only relevant semantic information that aligns with the supervised classification task. The primary objective of the study is to develop a framework that effectively leverages both labeled and unlabeled data for graph classification by ensuring meaningful knowledge transfer that aligns with the supervised task, thereby enhancing classification performance in scenarios with scarce labeled data."
Social Sciences,Smart energy management in residential buildings: the impact of knowledge and behavior,"Abstract A new technology called smart energy management makes use of IoT concepts to enhance energy efficiency and lower waste in structures. The goal of this study is to comprehend how household energy management knowledge affects energy usage, user behavior, related expenses, and environmental effect. Through a survey of 100 valid replies in Palestine, the research model assessed the knowledge and consumption habits of building occupants. Smart PLS software was used to analyze the research model using partial least squares structural equation modeling (PLS-SEM). Using path coefficients and behavior as a mediating variable, the structural model connected the latent variables. The mediation hypotheses were tested using the Preacher and Hayes method, and the indirect effect and confidence intervals were estimated and calculated using bootstrapping. The findings demonstrated that by lowering energy use and enhancing overall building performance, residential buildings that implement smart energy consumption management systems may move toward a more sustainable future. Furthermore, the study found that education and awareness campaigns are necessary to increase residents’ knowledge of these systems to promote energy savings. The results also indicated statistically significant indirect effects, supporting the existence of mediation of the behavior construct. Path coefficient values and P -values were presented to further support the study’s hypotheses. Such smart energy management systems represent an important innovation in building management and can help create more sustainable and efficient buildings.",['bootstrapping'],"The research idea centers on understanding how household energy management knowledge influences energy consumption, user behavior, associated costs, and environmental impact within residential buildings. The study addresses the broader motivation of promoting sustainability by reducing energy waste and improving building performance through informed occupant behavior. The primary objective of the study is to examine the relationship between residents’ knowledge of energy management and their energy usage patterns, as well as to assess the role of behavior as a mediating factor in this relationship. Additionally, the study aims to highlight the importance of education and awareness campaigns in enhancing residents’ understanding of energy management to foster energy savings and support sustainable building practices."
Social Sciences,Variation in social media sensitivity across people and contexts,"Abstract Social media impacts people’s wellbeing in different ways, but relatively little is known about why this is the case. Here we introduce the construct of “social media sensitivity” to understand how social media and wellbeing associations differ across people and the contexts in which these platforms are used. In a month-long large-scale intensive longitudinal study (total n = 1632; total number of observations = 120,599), we examined for whom and under which circumstances social media was associated with positive and negative changes in social and affective wellbeing. Applying a combination of frequentist and Bayesian multilevel models, we found a small negative average association between social media use AND subsequent wellbeing, but the associations were heterogenous across people. People with psychologically vulnerable dispositions (e.g., those who were depressed, lonely, not satisfied with life) tended to experience heightened negative social media sensitivity in comparison to people who were not psychologically vulnerable. People also experienced heightened negative social media sensitivity when in certain types of places (e.g., in social places, in nature) and while around certain types of people (e.g., around family members, close ties), as compared to using social media in other contexts. Our results suggest that an understanding of the effects of social media on wellbeing should account for the psychological dispositions of social media users, and the physical and social contexts surrounding their use. We discuss theoretical and practical implications of social media sensitivity for scholars, policymakers, and those in the technology industry.",['Bayesian multilevel models'],"The research idea addresses the varying impact of social media on individuals' wellbeing and the limited understanding of why these effects differ across people and contexts. It introduces the concept of “social media sensitivity” to explore how associations between social media use and wellbeing change depending on individual psychological dispositions and the environments in which social media is used. The study’s primary objective is to examine for whom and under which circumstances social media use is linked to positive or negative changes in social and affective wellbeing. It aims to highlight the role of psychological vulnerability and contextual factors, such as physical locations and social surroundings, in shaping the relationship between social media and wellbeing."
Social Sciences,Machine learning models for predicting preeclampsia: a systematic review,"Abstract Background This systematic review provides an overview of machine learning (ML) approaches for predicting preeclampsia. Method This review adhered to the Preferred Reporting Items for Systematic Reviews and Meta-Analyzes (PRISMA) guidelines. We searched the Cochrane Central Register, PubMed, EMBASE, ProQuest, Scopus, and Google Scholar up to February 2023. Search terms were limited to “preeclampsia” AND “artificial intelligence” OR “machine learning” OR “deep learning.” All studies that used ML-based analysis for predicting preeclampsia in pregnant women were considered. Non-English articles and those that are unrelated to the topic were excluded. The PROBAST was used to assess the risk of bias and applicability of each included study. Results The search strategy yielded 128 citations; after duplicates were removed and title and abstract screening was completed, 18 full-text articles were evaluated for eligibility. Four studies were included in this review. Two studies were at low risk of bias, and two had low to moderate risk. All of the study designs included were retrospective cohort studies. Nine distinct models were chosen as ML models from the four studies. Maternal characteristics, medical history, medication intake, obstetrical history, and laboratory and ultrasound findings obtained during prenatal care visits were candidate predictors to train the ML model. Elastic net, stochastic gradient boosting, extreme gradient boosting, and Random forest were among the best models to predict preeclampsia. All four studies used metrics such as the area under the curve, true positive rate, negative positive rate, accuracy, precision, recall, and F1 score. The AUC of ML models varied from 0.860 to 0.973 in four studies. Conclusion The results of studies yielded high prediction performance of ML models for preeclampsia risk from routine early pregnancy information.","['Elastic net', 'stochastic gradient boosting', 'extreme gradient boosting', 'Random forest']","The research idea centers on addressing the challenge of predicting preeclampsia in pregnant women by utilizing information routinely collected during early pregnancy. Preeclampsia is a significant health concern that can lead to serious complications for both the mother and the fetus, making early identification of risk crucial for improving prenatal care and outcomes. The study aims to provide an overview of existing approaches that leverage maternal characteristics, medical history, medication intake, obstetrical history, and prenatal clinical findings to enhance the prediction of preeclampsia risk. The primary objective of the study is to systematically review and evaluate the effectiveness of current predictive approaches for preeclampsia, focusing on their ability to identify high-risk pregnancies based on early pregnancy information. This review seeks to assess the performance and applicability of these approaches to inform future research and clinical practice in prenatal risk assessment."
Social Sciences,UniLog: Automatic Logging via LLM and In-Context Learning,"Logging, which aims to determine the position of logging statements, the verbosity levels, and the log messages, is a crucial process for software reliability enhancement. In recent years, numerous automatic logging tools have been designed to assist developers in one of the logging tasks (e.g., providing suggestions on whether to log in try-catch blocks). These tools are useful in certain situations yet cannot provide a comprehensive logging solution in general. Moreover, although recent research has started to explore end-to-end logging, it is still largely constrained by the high cost of fine-tuning, hindering its practical usefulness in software development. To address these problems, this paper proposes UniLog, an automatic logging framework based on the in-context learning (ICL) paradigm of large language models (LLMs). Specifically, UniLog can generate an appropriate logging statement with only a prompt containing five demonstration examples without any model tuning. In addition, UniLog can further enhance its logging ability after warmup with only a few hundred random samples. We evaluated UniLog on a large dataset containing 12,012 code snippets extracted from 1,465 GitHub repositories. The results show that UniLog achieved the state-of-the-art performance in automatic logging: (1) 76.9% accuracy in selecting logging positions, (2) 72.3% accuracy in predicting verbosity levels, and (3) 27.1 BLEU-4 score in generating log messages. Meanwhile, UniLog requires less than 4% of the parameter tuning time needed by fine-tuning the same LLM.","['in-context learning (ICL) paradigm of large language models (LLMs)', 'fine-tuning']","The study addresses the challenge of improving the process of logging in software development, which is essential for enhancing software reliability. Existing automatic logging tools offer limited assistance and do not provide a comprehensive solution, while current approaches to end-to-end logging face practical limitations due to high costs. The primary aim of the study is to develop a more efficient and effective approach to automatic logging that can generate appropriate logging statements with minimal input and reduced resource requirements. This approach seeks to improve the accuracy of selecting logging positions, predicting verbosity levels, and generating log messages, thereby supporting developers in the logging process more comprehensively."
Social Sciences,A Survey on Malware Detection with Graph Representation Learning,"Malware detection has become a major concern due to the increasing number and complexity of malware. Traditional detection methods based on signatures and heuristics are used for malware detection, but unfortunately, they suffer from poor generalization to unknown attacks and can be easily circumvented using obfuscation techniques. In recent years, Machine Learning (ML) and notably Deep Learning (DL) achieved impressive results in malware detection by learning useful representations from data and have become a solution preferred over traditional methods. Recently, the application of Graph Representation Learning (GRL) techniques on graph-structured data has demonstrated impressive capabilities in malware detection. This success benefits notably from the robust structure of graphs, which are challenging for attackers to alter, and their intrinsic explainability capabilities. In this survey, we provide an in-depth literature review to summarize and unify existing works under the common approaches and architectures. We notably demonstrate that Graph Neural Networks (GNNs) reach competitive results in learning robust embeddings from malware represented as expressive graph structures such as Function Call Graphs (FCGs) and Control Flow Graphs (CFGs). This study also discusses the robustness of GRL-based methods to adversarial attacks, contrasts their effectiveness with other ML/DL approaches, and outlines future research for practical deployment.","['Machine Learning (ML)', 'Deep Learning (DL)', 'Graph Representation Learning (GRL)', 'Graph Neural Networks (GNNs)']","The research addresses the growing concern of malware detection due to the increasing number and complexity of malware, highlighting the limitations of traditional detection methods that rely on signatures and heuristics, which struggle to generalize to unknown attacks and can be easily bypassed. The study is motivated by the need for more effective and robust approaches to identify malware, especially given the challenges posed by obfuscation techniques used by attackers. The primary objective of the study is to provide a comprehensive review of existing approaches that utilize graph-structured representations of malware, summarizing and unifying these works to demonstrate their effectiveness in capturing robust features for malware detection. Additionally, the study aims to discuss the resilience of these approaches against adversarial attacks, compare their performance with other existing methods, and suggest directions for future research to enhance practical application."
Social Sciences,Artificial intelligence performance in detecting lymphoma from medical imaging: a systematic review and meta-analysis,"Abstract Background Accurate diagnosis and early treatment are essential in the fight against lymphatic cancer. The application of artificial intelligence (AI) in the field of medical imaging shows great potential, but the diagnostic accuracy of lymphoma is unclear. This study was done to systematically review and meta-analyse researches concerning the diagnostic performance of AI in detecting lymphoma using medical imaging for the first time. Methods Searches were conducted in Medline, Embase, IEEE and Cochrane up to December 2023. Data extraction and assessment of the included study quality were independently conducted by two investigators. Studies that reported the diagnostic performance of an AI model/s for the early detection of lymphoma using medical imaging were included in the systemic review. We extracted the binary diagnostic accuracy data to obtain the outcomes of interest: sensitivity (SE), specificity (SP), and Area Under the Curve (AUC). The study was registered with the PROSPERO, CRD42022383386. Results Thirty studies were included in the systematic review, sixteen of which were meta-analyzed with a pooled sensitivity of 87% (95%CI 83–91%), specificity of 94% (92–96%), and AUC of 97% (95–98%). Satisfactory diagnostic performance was observed in subgroup analyses based on algorithms types (machine learning versus deep learning, and whether transfer learning was applied), sample size (≤ 200 or &gt; 200), clinicians versus AI models and geographical distribution of institutions (Asia versus non-Asia). Conclusions Even if possible overestimation and further studies with a better standards for application of AI algorithms in lymphoma detection are needed, we suggest the AI may be useful in lymphoma diagnosis.","['machine learning', 'deep learning', 'transfer learning']","The research idea centers on the critical importance of accurate diagnosis and early treatment in combating lymphatic cancer, highlighting uncertainty regarding the effectiveness of current diagnostic approaches for lymphoma. There is a need to better understand the diagnostic performance of emerging methods in detecting lymphoma through medical imaging. The primary objective of the study is to systematically review and synthesize existing research on the diagnostic accuracy of these approaches in identifying lymphoma at an early stage. This study aims to provide a comprehensive evaluation of their sensitivity and specificity to inform future clinical applications and improve lymphoma diagnosis."
Social Sciences,Adaptive Attention-Based Graph Representation Learning to Detect Phishing Accounts on the Ethereum Blockchain,"With Ethereum blockchain advancement, the Ethereum platform gathers numerous users. In this context, traditional phishing appears new fraud methods, resulting in significant losses. Currently, network embedding methods are considered effective solutions in the field of phishing detection. However, investigating existing Ethereum phishing node detection algorithms finds they are not optimal and still face two issues. Firstly, the Ethereum network's topology is unsatisfactory, with nodes exhibiting a long-tail distribution in their degree. Current technologies typically allow high-degree nodes to acquire high-quality embeddings, while low-degree nodes, constrained by limited structure, obtain embeddings of lower quality, significantly impacting the detection accuracy of downstream tasks. Secondly, different features of nodes will suffer losses during the fusion process, resulting in the final learned feature embedding being suboptimal. This paper presents an attention-based graphical representation learning approach (ABGRL) to address these problems. ABGRL extracts different feature information by means of multiple channels, and fuses the different feature information using adaptive attention convolution to select the feature information that has the greatest impact on the downstream task. Then the tail node feature information is enhanced by a self-supervised regression model with robust tail node embedding. Finally, the effectiveness of the proposed model was validated through extensive experiments.",['network embedding methods'],"The research idea centers on the challenges posed by new fraud methods, specifically phishing, within the Ethereum platform, which has seen a significant increase in users. Traditional phishing detection approaches face difficulties due to the unsatisfactory network structure and the uneven distribution of node connections, leading to lower detection accuracy. Additionally, the fusion of different node features often results in information loss, further hindering effective identification of fraudulent activities. The study aims to address these issues to improve the detection of phishing nodes in the Ethereum network. The primary objective of the study is to develop a method that enhances the quality of feature representation for nodes, particularly those with fewer connections, and to optimize the integration of diverse node features to improve phishing detection accuracy. The study seeks to validate the effectiveness of this approach in overcoming the limitations of existing detection techniques within the Ethereum network."
Social Sciences,Risk predictions of surgical wound complications based on a machine learning algorithm: A systematic review,"Abstract Surgical wounds may arise due to harm inflicted upon soft tissue during surgical intervention, and many complications and injuries may accompany them. These complications can lead to prolonged hospitalization and poorer clinical outcomes. Also, Machine learning (ML) is a Section of artificial intelligence (AI) that has emerged in medical care and is increasingly used for diagnosis, complications, prognosis and recurrence prediction. This study aims to investigate surgical wound risk predictions and management using a ML algorithm by R programming language analysis. The systematic review, following PRISMA guidelines, spanned electronic databases using search terms like ‘machine learning’, ‘surgical’ and ‘wound’. Inclusion criteria covered experimental studies from 1990 to the present on ML's application in surgical wound evaluation. Exclusion criteria included studies lacking full text, focusing on ML in all surgeries, neglecting wound assessment and duplications. Two authors rigorously assessed titles, abstracts and full texts, excluding reviews and guidelines. Ultimately, relevant articles were then analysed. The present study identified nine articles employing ML for surgical wound management. The analysis encompassed various surgical procedures, including Cardiothoracic, Caesarean total abdominal colectomy, Burn plastic surgery, facial plastic surgery, laparotomy, minimal invasive surgery, hernia repair and unspecified surgeries. ML was skillful in evaluating surgical site infections (SSI) in seven studies, while two extended its use to burn‐grade diagnosis and wound classification. Support Vector Machine (SVM) and Convolutional Neural Network (CNN) were the most utilized algorithms. ANN achieved a 96% accuracy in facial plastic surgery wound management. CNN demonstrated commendable accuracies in various surgeries, and SVM exhibited high accuracy in multiple surgeries and burn plastic surgery. In sum, these findings underscore ML's potential for significant improvements in postoperative management and the development of enhanced care techniques, particularly in surgical wound management.","['Support Vector Machine (SVM)', 'Convolutional Neural Network (CNN)', 'Artificial Neural Network (ANN)']","The research idea centers on the challenges posed by surgical wounds, which result from tissue damage during surgical procedures and are often accompanied by complications that can lead to extended hospital stays and poorer clinical outcomes. Addressing these complications is crucial for improving patient recovery and overall healthcare quality. The primary objective of the study is to investigate the prediction and management of surgical wound risks, aiming to enhance postoperative care and develop better techniques specifically for surgical wound management. This involves examining existing approaches to evaluating surgical wounds across various types of surgeries to identify opportunities for improving clinical outcomes."
Social Sciences,Wind farm site selection using geographic information system and fuzzy decision making model,"As the demand for renewable energy sources increases, finding the right places to install wind turbines becomes more and more important. The goal of this research is to create and implement a technique that uses geographic information system (GIS) technology to discover appropriate wind farm locations utilizing multi-criteria decision-making (MCDM) approaches. The complexity of this decision-making process, which includes multiple criteria and uncertainty, requires the use of advanced techniques. Fuzzy MCDM methods provide a framework for evaluating and prioritizing potential wind farm sites, taking into account subjective judgments and linguistic terms. In this article, Fuzzy Stepwise Weight Evaluation Ratio Analysis (F-SWARA) is preferred for prioritizing and ranking the criteria in the wind farm installation, while Fuzzy Measurement Alternatives and Ranking by Compromise Solution (F-MARCOS) are used to determine the most suitable location for the wind farm. A database of alternatives and criteria was created using GIS, which was converted into a fuzzy decision matrix via triangular fuzzy numbers. In order to make this evaluation, Sivas province, located in the middle of Turkey, was chosen as the study area. Results obtained show that 36,5% of the whole study area is very suitable for wind farm, and Gürün and Kangal districts are suitable for wind farm. According to the result of F-SWARA method used to evaluate the criteria, wind speed is the most important criteria with a weight of 0,45039. According to the F-MARCOS method used for wind farm site selection, Ulaş district was determined the most suitable location. Furthermore, a sensitivity analysis was performed to test the robustness of the proposed methodology and the results revealed that the proposed integrated MCDM framework is feasible.","['Fuzzy Stepwise Weight Evaluation Ratio Analysis (F-SWARA)', 'Fuzzy Measurement Alternatives and Ranking by Compromise Solution (F-MARCOS)']","The research addresses the growing importance of identifying suitable locations for wind turbine installations in response to increasing demand for renewable energy sources. It highlights the complexity involved in making decisions about wind farm siting, which requires consideration of multiple criteria and uncertainty. The study aims to develop a method that incorporates geographic information to evaluate and prioritize potential sites for wind farms effectively. The primary objective of the study is to determine the most appropriate locations for wind farm installation in Sivas province, Turkey, by assessing various criteria and identifying areas with high suitability for wind energy development."
Social Sciences,CARLA: Self-supervised contrastive representation learning for time series anomaly detection,"One main challenge in time series anomaly detection (TSAD) is the lack of labelled data in many real-life scenarios. Most of the existing anomaly detection methods focus on learning the normal behaviour of unlabelled time series in an unsupervised manner. The normal boundary is often defined tightly, resulting in slight deviations being classified as anomalies, consequently leading to a high false positive rate and a limited ability to generalise normal patterns. To address this, we introduce a novel end-to-end self-supervised ContrAstive Representation Learning approach for time series Anomaly detection (CARLA). While existing contrastive learning methods assume that augmented time series windows are positive samples and temporally distant windows are negative samples, we argue that these assumptions are limited as augmentation of time series can transform them to negative samples, and a temporally distant window can represent a positive sample. Existing approaches to contrastive learning for time series have directly copied methods developed for image analysis. We argue that these methods do not transfer well. Instead, our contrastive approach leverages existing generic knowledge about time series anomalies and injects various types of anomalies as negative samples. Therefore, CARLA not only learns normal behaviour but also learns deviations indicating anomalies. It creates similar representations for temporally close windows and distinct ones for anomalies. Additionally, it leverages the information about representations' neighbours through a self-supervised approach to classify windows based on their nearest/furthest neighbours to further enhance the performance of anomaly detection. In extensive tests on seven major real-world TSAD datasets, CARLA shows superior performance (F1 and AU-PR) over state-of-the-art self-supervised, semi-supervised, and unsupervised TSAD methods for univariate time series and multivariate time series. Our research highlights the immense potential of contrastive representation learning in advancing the TSAD field, thus paving the way for novel applications and in-depth exploration.","['self-supervised ContrAstive Representation Learning', 'contrastive learning', 'self-supervised approach', 'semi-supervised methods', 'unsupervised methods']","The research addresses the challenge of accurately identifying unusual patterns in time-based data when there is a lack of labeled examples, which often leads to misclassifying minor variations as anomalies and limits the understanding of normal behavior. Existing approaches tend to define normal behavior too narrowly, resulting in a high rate of false alarms and poor generalization across different scenarios. The study aims to improve the detection of anomalies in time series data by developing a method that better distinguishes between normal variations and true anomalies. Specifically, the objective is to create a framework that not only learns what constitutes normal behavior but also incorporates knowledge about various types of anomalies to enhance the identification of deviations, thereby reducing false positives and improving overall detection performance."
Social Sciences,Toward Improving Breast Cancer Classification Using an Adaptive Voting Ensemble Learning Algorithm,"Over the past decade, breast cancer has been the most common type of cancer in women. Different methods were proposed for breast cancer detection. These methods mainly classify and categorize malignant and Benign tumors. Machine learning is a practical approach for breast cancer classification. Data mining and classification are effective methods to predict and categorize breast cancer. The optimum classification for detecting Breast Cancer (BC) is ensemble-based. The ensemble approach involves using multiple ways to find the best possible solution. This study used the Wisconsin Breast Cancer Diagnostic (WBCD) dataset. We created a voting ensemble classifier that combines four different machine learning models: Extra Trees Classifier (ETC), Light Gradient Boosting Machine (LightGBM), Ridge Classifier (RC), and Linear Discriminant Analysis (LDA). The proposed ELRL-E approach achieved an accuracy of 97.6%, a precision of 96.4%, a recall of 100%, and an F1 score of 98.1%. Various output evaluations are used to evaluate the performance and efficiency of the proposed model and other classifiers. Overall, the recommended strategy performed better. Results are directly compared with the individual classifier and different recognized state-of-the-art classifiers. The primary objective of this study is to identify the most influential ensemble machine learning classifier for breast cancer detection and diagnosis in terms of accuracy and AUC score.","['Machine learning', 'ensemble-based classification', 'voting ensemble classifier', 'Extra Trees Classifier (ETC)', 'Light Gradient Boosting Machine (LightGBM)', 'Ridge Classifier (RC)', 'Linear Discriminant Analysis (LDA)']","The research idea centers on addressing the critical issue of breast cancer detection, which remains the most common type of cancer among women. The study highlights the importance of accurately classifying and categorizing malignant and benign tumors to improve diagnosis and treatment outcomes. Given the variety of existing methods, there is a need to identify the most effective approach for breast cancer classification. The research objective is to determine the most influential classification method for breast cancer detection and diagnosis by evaluating its accuracy and effectiveness. Specifically, the study aims to identify which approach provides the highest performance in distinguishing between malignant and benign tumors to enhance diagnostic precision."
Social Sciences,From explainable to interpretable deep learning for natural language processing in healthcare: How far from reality?,"Deep learning (DL) has substantially enhanced natural language processing (NLP) in healthcare research. However, the increasing complexity of DL-based NLP necessitates transparent model interpretability, or at least explainability, for reliable decision-making. This work presents a thorough scoping review of explainable and interpretable DL in healthcare NLP. The term ""eXplainable and Interpretable Artificial Intelligence"" (XIAI) is introduced to distinguish XAI from IAI. Different models are further categorized based on their functionality (model-, input-, output-based) and scope (local, global). Our analysis shows that attention mechanisms are the most prevalent emerging IAI technique. The use of IAI is growing, distinguishing it from XAI. The major challenges identified are that most XIAI does not explore ""global"" modelling processes, the lack of best practices, and the lack of systematic evaluation and benchmarks. One important opportunity is to use attention mechanisms to enhance multi-modal XIAI for personalized medicine. Additionally, combining DL with causal logic holds promise. Our discussion encourages the integration of XIAI in Large Language Models (LLMs) and domain-specific smaller models. In conclusion, XIAI adoption in healthcare requires dedicated in-house expertise. Collaboration with domain experts, end-users, and policymakers can lead to ready-to-use XIAI methods across NLP and medical tasks. While challenges exist, XIAI techniques offer a valuable foundation for interpretable NLP algorithms in healthcare.","['deep learning (DL)', 'attention mechanisms']","The research addresses the growing need for transparency and interpretability in the use of advanced language processing techniques within healthcare research to ensure reliable decision-making. It highlights challenges such as the limited exploration of comprehensive modeling processes, the absence of established best practices, and the lack of systematic evaluation and benchmarks in this area. The study aims to provide a comprehensive overview of explainable and interpretable approaches in healthcare language processing, categorizing existing methods and identifying prevailing trends and challenges. It seeks to encourage collaboration among domain experts, end-users, and policymakers to develop practical and accessible interpretability methods that can be effectively applied across various healthcare and medical tasks."
Social Sciences,Deep Learning for Pneumonia Detection in Chest X-ray Images: A Comprehensive Survey,"This paper addresses the significant problem of identifying the relevant background and contextual literature related to deep learning (DL) as an evolving technology in order to provide a comprehensive analysis of the application of DL to the specific problem of pneumonia detection via chest X-ray (CXR) imaging, which is the most common and cost-effective imaging technique available worldwide for pneumonia diagnosis. This paper in particular addresses the key period associated with COVID-19, 2020–2023, to explain, analyze, and systematically evaluate the limitations of approaches and determine their relative levels of effectiveness. The context in which DL is applied as both an aid to and an automated substitute for existing expert radiography professionals, who often have limited availability, is elaborated in detail. The rationale for the undertaken research is provided, along with a justification of the resources adopted and their relevance. This explanatory text and the subsequent analyses are intended to provide sufficient detail of the problem being addressed, existing solutions, and the limitations of these, ranging in detail from the specific to the more general. Indeed, our analysis and evaluation agree with the generally held view that the use of transformers, specifically, vision transformers (ViTs), is the most promising technique for obtaining further effective results in the area of pneumonia detection using CXR images. However, ViTs require extensive further research to address several limitations, specifically the following: biased CXR datasets, data and code availability, the ease with which a model can be explained, systematic methods of accurate model comparison, the notion of class imbalance in CXR datasets, and the possibility of adversarial attacks, the latter of which remains an area of fundamental research.","['deep learning (DL)', 'transformers', 'vision transformers (ViTs)']","The research idea centers on the challenge of comprehensively understanding and evaluating the application of emerging technologies to the detection of pneumonia through chest X-ray imaging, which remains the most common and cost-effective diagnostic method worldwide. This study is motivated by the need to address the limitations and effectiveness of various approaches during the critical period of the COVID-19 pandemic from 2020 to 2023, particularly in contexts where expert radiography professionals are scarce. The research objective is to explain, analyze, and systematically evaluate the existing solutions for pneumonia detection using chest X-rays, highlighting their limitations and relative effectiveness. The study aims to provide detailed insights into the problem, existing methods, and the challenges that remain, thereby informing future research directions in this important area of healthcare."
Social Sciences,GraphCL-DTA: A Graph Contrastive Learning With Molecular Semantics for Drug-Target Binding Affinity Prediction,"Drug-target binding affinity prediction plays an important role in the early stages of drug discovery, which can infer the strength of interactions between new drugs and new targets. However, the performance of previous computational models is limited by the following drawbacks. The learning of drug representation relies only on supervised data without considering the information in the molecular graph itself. Moreover, most previous studies tended to design complicated representation learning modules, while uniformity used to measure representation quality is ignored. In this study, we propose GraphCL-DTA, a graph contrastive learning with molecular semantics for drug-target binding affinity prediction. This graph contrastive learning framework replaces the dropout-based data augmentation strategy by performing data augmentation in the embedding space, thereby better preserving the semantic information of the molecular graph. A more essential and effective drug representation can be learned through this graph contrastive framework without additional supervised data. Next, we design a new loss function that can be directly used to adjust the uniformity of drug and target representations. By directly optimizing the uniformity of representations, the representation quality of drugs and targets can be improved. The effectiveness of the above innovative elements is verified on two real datasets, KIBA and Davis. Compared with the GraphDTA model, the relative improvement of the GraphCL-DTA model on the two datasets is 2.7% and 4.5%. The graph contrastive learning framework and uniformity function in the GraphCL-DTA model can be embedded into other computational models as independent modules to improve their generalization capability.","['graph contrastive learning', 'data augmentation in the embedding space']","The study addresses the challenge of accurately predicting the strength of interactions between new drugs and their targets, which is crucial in the early stages of drug discovery. Existing approaches face limitations due to reliance on supervised data and neglect of important structural information inherent in molecular representations, as well as overlooking measures that assess the quality of these representations. The primary aim of the study is to develop a framework that enhances the representation of drugs and targets by preserving essential molecular information and improving the uniformity of these representations. This objective seeks to improve the prediction of drug-target binding affinity, thereby contributing to more effective drug discovery processes."
Social Sciences,Enhancing Multi-UAV Reconnaissance and Search Through Double Critic DDPG With Belief Probability Maps,"Unmanned Aerial Vehicles (UAVs) have recently attracted significant attention due to their potential applications in reconnaissance and search. This paper aims to investigate the issue of multi-UAV cooperative reconnaissance and search (MCRS) to ensure ample coverage of the mission area and precise localization of static targets. The MCRS problem is modeled as a multi-objective optimization problem, taking into account the credibility of search results. To achieve this, we design a belief probability map based on the Dempster-Shafer (DS) evidence theory, comprising an uncertainty map and two target maps. This representation enables a clear depiction of both the presence of the target and the uncertainty within the map. Subsequently, we reformulate this multi-objective optimization problem within the framework of Decentralized Partially Observable Markov Decision Process (Dec-POMDP). To address this reformulation, a new deep reinforcement learning approach called Double Critic Deep Deterministic Policy Gradient (DCDDPG) is proposed. Specifically, we introduce both a centralized critic and a local critic for each UAV agent to estimate the action-value function. This approach helps balance the bias in the action-value function estimation and the variance in the policy updates, thereby improving the coordination effect. Extensive simulation results demonstrate that DCDDPG outperforms existing techniques in terms of search efficiency and coverage.",['Decentralized Partially Observable Markov Decision Process (Dec-POMDP)'],"The research idea centers on addressing the challenge of coordinating multiple unmanned aerial vehicles to effectively conduct reconnaissance and search operations, ensuring thorough coverage of the mission area and accurate identification of static targets. The study recognizes the importance of managing the credibility of search results to improve the reliability of the reconnaissance process. The primary objective of the study is to investigate the problem of multi-UAV cooperative reconnaissance and search with the goal of achieving ample mission area coverage and precise localization of static targets. The research aims to develop a framework that accounts for the uncertainty and presence of targets to enhance the coordination and effectiveness of multi-UAV search efforts."
Social Sciences,PEGA: A Privacy-Preserving Genetic Algorithm for Combinatorial Optimization,"Evolutionary algorithms (EAs), such as the genetic algorithm (GA), offer an elegant way to handle combinatorial optimization problems (COPs). However, limited by expertise and resources, most users lack the capability to implement EAs for solving COPs. An intuitive and promising solution is to outsource evolutionary operations to a cloud server, however, it poses privacy concerns. To this end, this article proposes a novel computing paradigm called evolutionary computation as a service (ECaaS), where a cloud server renders evolutionary computation services for users while ensuring their privacy. Following the concept of ECaaS, this article presents privacy-preserving genetic algorithm (PEGA), a privacy-preserving GA designed specifically for COPs. PEGA enables users, regardless of their domain expertise or resource availability, to outsource COPs to the cloud server that holds a competitive GA and approximates the optimal solution while safeguarding privacy. Notably, PEGA features the following characteristics. First, PEGA empowers users without domain expertise or sufficient resources to solve COPs effectively. Second, PEGA protects the privacy of users by preventing the leakage of optimization problem details. Third, PEGA performs comparably to the conventional GA when approximating the optimal solution. To realize its functionality, we implement PEGA falling in a twin-server architecture and evaluate it on two widely known COPs: 1) the traveling Salesman problem (TSP) and 2) the 0/1 knapsack problem (KP). Particularly, we utilize encryption cryptography to protect users' privacy and carefully design a suite of secure computing protocols to support evolutionary operators of GA on encrypted chromosomes. Privacy analysis demonstrates that PEGA successfully preserves the confidentiality of COP contents. Experimental evaluation results on several TSP datasets and KP datasets reveal that PEGA performs equivalently to the conventional GA in approximating the optimal solution.","['evolutionary algorithms (EAs)', 'genetic algorithm (GA)']","The research idea addresses the challenge faced by users who lack the expertise and resources to solve complex combinatorial optimization problems, highlighting the potential of outsourcing such tasks to external services while raising concerns about privacy protection. The study is motivated by the need to enable users to effectively solve these problems without compromising the confidentiality of their sensitive information. The primary objective of the study is to develop a solution that allows users, regardless of their domain knowledge or resource availability, to outsource combinatorial optimization problems to an external service that can approximate optimal solutions while ensuring the privacy of the users’ problem details. The study aims to demonstrate that this approach can protect user privacy and perform comparably to traditional methods in solving these problems."
Social Sciences,A soft voting ensemble learning approach for credit card fraud detection,"With the advancement of e-commerce and modern technological development, credit cards are widely used for both online and offline purchases, which has increased the number of daily fraudulent transactions. Many organizations and financial institutions worldwide lose billions of dollars annually because of credit card fraud. Due to the global distribution of both legitimate and fraudulent transactions, it is difficult to discern between the two. Furthermore, because only a small proportion of transactions are fraudulent, there is a problem of class imbalance. Hence, an effective fraud-detection methodology is required to sustain the reliability of the payment system. Machine learning has recently emerged as a viable substitute for identifying this type of fraud. However, ML approaches have difficulty identifying fraud with high prediction accuracy, while also decreasing misclassification costs due to the size of the imbalanced data. In this research, a soft voting ensemble learning approach for detecting credit card fraud on imbalanced data is proposed. To do this, the proposed approach is evaluated and compared with numerous sophisticated sampling techniques (i.e., oversampling, undersampling, and hybrid sampling) to overcome the class imbalance problem. We develop several credit card fraud classifiers, including ensemble classifiers, with and without sampling techniques. According to the experimental results, the proposed soft-voting approach outperforms individual classifiers. With a false negative rate (FNR) of 0.0306, it achieves a precision of 0.9870, recall of 0.9694, f1-score of 0.8764, and AUROC of 0.9936.","['soft voting ensemble learning', 'undersampling', 'ensemble classifiers']","The research idea centers on the increasing prevalence of credit card fraud due to the widespread use of credit cards for online and offline purchases, which causes significant financial losses for organizations and financial institutions globally. The challenge lies in accurately distinguishing between legitimate and fraudulent transactions, especially given the global distribution of transactions and the imbalance where fraudulent transactions constitute only a small proportion. The study highlights the need for an effective approach to maintain the reliability of payment systems amidst these challenges. The primary objective of the study is to develop and evaluate a method for detecting credit card fraud that addresses the issue of class imbalance in transaction data, aiming to improve the accuracy of fraud identification while reducing misclassification costs. The research seeks to compare different approaches to overcome the imbalance problem and identify a solution that enhances the detection of fraudulent transactions."
Social Sciences,Towards development of functional climate-driven early warning systems for climate-sensitive infectious diseases: Statistical models and recommendations,"Climate, weather and environmental change have significantly influenced patterns of infectious disease transmission, necessitating the development of early warning systems to anticipate potential impacts and respond in a timely and effective way. Statistical modelling plays a pivotal role in understanding the intricate relationships between climatic factors and infectious disease transmission. For example, time series regression modelling and spatial cluster analysis have been employed to identify risk factors and predict spatial and temporal patterns of infectious diseases. Recently advanced spatio-temporal models and machine learning offer an increasingly robust framework for modelling uncertainty, which is essential in climate-driven disease surveillance due to the dynamic and multifaceted nature of the data. Moreover, Artificial Intelligence (AI) techniques, including deep learning and neural networks, excel in capturing intricate patterns and hidden relationships within climate and environmental data sets. Web-based data has emerged as a powerful complement to other datasets encompassing climate variables and disease occurrences. However, given the complexity and non-linearity of climate-disease interactions, advanced techniques are required to integrate and analyse these diverse data to obtain more accurate predictions of impending outbreaks, epidemics or pandemics. This article presents an overview of an approach to creating climate-driven early warning systems with a focus on statistical model suitability and selection, along with recommendations for utilizing spatio-temporal and machine learning techniques. By addressing the limitations and embracing the recommendations for future research, we could enhance preparedness and response strategies, ultimately contributing to the safeguarding of public health in the face of evolving climate challenges.","['spatio-temporal models', 'machine learning', 'deep learning', 'neural networks']","The study addresses the significant influence of climate, weather, and environmental change on the patterns of infectious disease transmission, highlighting the need for early warning systems to anticipate potential impacts and enable timely and effective responses. It emphasizes the complexity and dynamic nature of climate-disease interactions, which pose challenges for understanding and predicting outbreaks, epidemics, or pandemics. The primary aim of the study is to present an overview of approaches to developing climate-driven early warning systems, focusing on the suitability and selection of statistical models. Additionally, it seeks to provide recommendations to improve preparedness and response strategies, thereby contributing to the protection of public health amid evolving climate challenges."
Social Sciences,Health equity assessment of machine learning performance (HEAL): a framework and dermatology AI model case study,"BackgroundArtificial intelligence (AI) has repeatedly been shown to encode historical inequities in healthcare. We aimed to develop a framework to quantitatively assess the performance equity of health AI technologies and to illustrate its utility via a case study.MethodsHere, we propose a methodology to assess whether health AI technologies prioritise performance for patient populations experiencing worse outcomes, that is complementary to existing fairness metrics. We developed the Health Equity Assessment of machine Learning performance (HEAL) framework designed to quantitatively assess the performance equity of health AI technologies via a four-step interdisciplinary process to understand and quantify domain-specific criteria, and the resulting HEAL metric. As an illustrative case study (analysis conducted between October 2022 and January 2023), we applied the HEAL framework to a dermatology AI model. A set of 5420 teledermatology cases (store-and-forward cases from patients of 20 years or older, submitted from primary care providers in the USA and skin cancer clinics in Australia), enriched for diversity in age, sex and race/ethnicity, was used to retrospectively evaluate the AI model's HEAL metric, defined as the likelihood that the AI model performs better for subpopulations with worse average health outcomes as compared to others. The likelihood that AI performance was anticorrelated to pre-existing health outcomes was estimated using bootstrap methods as the probability that the negated Spearman's rank correlation coefficient (i.e., ""R"") was greater than zero. Positive values of R suggest that subpopulations with poorer health outcomes have better AI model performance. Thus, the HEAL metric, defined as p (R >0), measures how likely the AI technology is to prioritise performance for subpopulations with worse average health outcomes as compared to others (presented as a percentage below). Health outcomes were quantified as disability-adjusted life years (DALYs) when grouping by sex and age, and years of life lost (YLLs) when grouping by race/ethnicity. AI performance was measured as top-3 agreement with the reference diagnosis from a panel of 3 dermatologists per case.FindingsAcross all dermatologic conditions, the HEAL metric was 80.5% for prioritizing AI performance of racial/ethnic subpopulations based on YLLs, and 92.1% and 0.0% respectively for prioritizing AI performance of sex and age subpopulations based on DALYs. Certain dermatologic conditions were significantly associated with greater AI model performance compared to a reference category of less common conditions. For skin cancer conditions, the HEAL metric was 73.8% for prioritizing AI performance of age subpopulations based on DALYs.InterpretationAnalysis using the proposed HEAL framework showed that the dermatology AI model prioritised performance for race/ethnicity, sex (all conditions) and age (cancer conditions) subpopulations with respect to pre-existing health disparities. More work is needed to investigate ways of promoting equitable AI performance across age for non-cancer conditions and to better understand how AI models can contribute towards improving equity in health outcomes.FundingGoogle LLC.",['bootstrap methods'],"The research idea addresses the issue of historical inequities in healthcare and the need to evaluate whether health technologies perform equitably across different patient populations, particularly those experiencing worse health outcomes. The study is motivated by concerns that existing health interventions may not adequately prioritize or improve outcomes for disadvantaged groups defined by factors such as race, sex, and age. The research objective is to develop a framework that quantitatively assesses the equity of health technology performance across diverse subpopulations, with the aim of determining if these technologies prioritize better performance for groups with poorer average health outcomes. The study further aims to illustrate the utility of this framework through a case study in dermatology, evaluating how well the technology addresses disparities related to race/ethnicity, sex, and age in health outcomes."
Social Sciences,A sentiment analysis approach for understanding users’ perception of metaverse marketplace,"This research explores the user perceptions of the Metaverse Marketplace, analyzing a substantial dataset of over 860,000 Twitter posts through sentiment analysis and topic modeling techniques. The study aims to uncover the driving factors behind user engagement and sentiment in this novel digital trading space. Key findings highlight a predominantly positive user sentiment, with significant enthusiasm for the marketplace's revenue generation and entertainment potential, particularly within the gaming sector. Users express appreciation for the innovative opportunities the Metaverse Marketplace offers for artists, designers, and traders in handling and trading digital assets. This positive outlook is tempered by notable concerns regarding security and privacy within the Metaverse, pointing to a critical area for development and assurance. The study also reveals a substantial neutral sentiment, reflecting users' cautious but interested stance, particularly regarding the marketplace's role in investment and passive income opportunities. This balanced view underscores the evolving nature of user perceptions in this emerging field. Theoretically, the research enriches the discourse on technology adoption, particularly in virtual environments, by highlighting perceived benefits and enjoyment as significant adoption drivers. These insights are invaluable for stakeholders in the Metaverse Marketplace, guiding the development of more secure, engaging, and user-friendly platforms. While providing a pioneering perspective on Metaverse user perceptions, the study acknowledges its limitation to Twitter data, suggesting the need for broader research methodologies for a more holistic understanding.",['topic modeling'],"The research addresses the evolving user perceptions of the Metaverse Marketplace, focusing on understanding the factors that influence engagement and sentiment within this emerging digital trading environment. It highlights the balance between enthusiasm for the marketplace’s revenue and entertainment potential, especially in gaming, and concerns about security and privacy, reflecting the complexities of user attitudes in this novel context. The primary objective of the study is to uncover the driving factors behind user engagement and sentiment in the Metaverse Marketplace, emphasizing the perceived benefits, enjoyment, and cautious interest users express regarding investment and passive income opportunities. By doing so, the research aims to provide insights that can guide stakeholders in developing more secure, engaging, and user-friendly platforms within this virtual environment."
Social Sciences,BEVSOC: Self-Supervised Contrastive Learning for Calibration-Free BEV 3-D Object Detection,"3D object detection based on multi-view cameras and bird's-eye view (BEV) representation is a key task for autonomous driving, as it enables the perception systems to understand the surrounding scenes. However, most existing BEV representation methods rely on the projection matrix of camera intrinsic and extrinsic parameters, which requires a complex and time-consuming calibration process that may introduce errors and degrade the detection performance. Moreover, the calibration results may vary due to environmental changes and affect the stability of the detection system. To address this problem, we propose a calibration-free 3D object detection method that leverages a group-equivariant convolutional network to extract features from multi-view images and a projection network module to learn the implicit 3D-to-2D projection relationship for obtaining BEV representation. Furthermore, we employ contrastive learning to pre-train the projection network module without using manually annotated data. By exploiting the multi-view camera data through contrastive learning, our proposed method eliminates the need for tedious calibration, avoids calibration errors, and reduces the dependence on a large amount of annotated data for calibration-free 3D object detection. We evaluate our method on the nuScenes dataset and demonstrate its competitive performance. Our method improves the stability and reliability of 3D object detection in long-term autonomous driving.","['group-equivariant convolutional network', 'contrastive learning']","The research idea addresses the challenge of accurately perceiving surrounding scenes in autonomous driving, focusing on the difficulties caused by complex and error-prone calibration processes required for existing methods. These calibration procedures are time-consuming and susceptible to environmental changes, which can negatively impact the stability and reliability of detection systems. The study is motivated by the need to improve the consistency and effectiveness of scene understanding without relying on such calibration. The primary objective of the study is to develop a method for 3D object detection that eliminates the need for manual calibration by learning the relationship between different camera views and spatial representation. This approach aims to enhance the stability and reliability of object detection over time, reducing dependence on extensive manual annotation and improving performance in autonomous driving contexts."
Social Sciences,ac4C-AFL: A high-precision identification of human mRNA N4-acetylcytidine sites based on adaptive feature representation learning,"RNA N4-acetylcytidine (ac4C) is a highly conserved RNA modification that plays a crucial role in controlling mRNA stability, processing, and translation. Consequently, accurate identification of ac4C sites across the genome is critical for understanding gene expression regulation mechanisms. In this study, we have developed ac4C-AFL, a bioinformatics tool that precisely identifies ac4C sites from primary RNA sequences. In ac4C-AFL, we identified the optimal sequence length for model building and implemented an adaptive feature representation strategy that is capable of extracting the most representative features from RNA. To identify the most relevant features, we proposed a novel ensemble feature importance scoring strategy to rank features effectively. We then used this information to conduct the sequential forward search, which individually determine the optimal feature set from the 16 sequence-derived feature descriptors. Utilizing these optimal feature descriptors, we constructed 176 baseline models using 11 popular classifiers. The most efficient baseline models were identified using the two-step feature selection approach, whose predicted scores were integrated and trained with the appropriate classifier to develop the final prediction model. Our rigorous cross-validations and independent tests demonstrate that ac4C-AFL surpasses contemporary tools in predicting ac4C sites. Moreover, we have developed a publicly accessible web server at https://balalab-skku.org/ac4C-AFL/.",['sequential forward search'],"The research idea centers on the importance of accurately identifying RNA N4-acetylcytidine (ac4C) sites across the genome, as ac4C is a highly conserved RNA modification that plays a crucial role in controlling mRNA stability, processing, and translation. Understanding the precise locations of ac4C sites is critical for elucidating the mechanisms of gene expression regulation. The primary objective of the study is to develop a method that can precisely identify ac4C sites from primary RNA sequences, thereby enhancing the understanding of gene expression regulation mechanisms through accurate site identification."
Social Sciences,CrossHAR: Generalizing Cross-dataset Human Activity Recognition via Hierarchical Self-Supervised Pretraining,"The increasing availability of low-cost wearable devices and smartphones has significantly advanced the field of sensor-based human activity recognition (HAR), attracting considerable research interest. One of the major challenges in HAR is the domain shift problem in cross-dataset activity recognition, which occurs due to variations in users, device types, and sensor placements between the source dataset and the target dataset. Although domain adaptation methods have shown promise, they typically require access to the target dataset during the training process, which might not be practical in some scenarios. To address these issues, we introduce CrossHAR, a new HAR model designed to improve model performance on unseen target datasets. CrossHAR involves three main steps: (i) CrossHAR explores the sensor data generation principle to diversify the data distribution and augment the raw sensor data. (ii) CrossHAR then employs a hierarchical self-supervised pretraining approach with the augmented data to develop a generalizable representation. (iii) Finally, CrossHAR fine-tunes the pretrained model with a small set of labeled data in the source dataset, enhancing its performance in cross-dataset HAR. Our extensive experiments across multiple real-world HAR datasets demonstrate that CrossHAR outperforms current state-of-the-art methods by 10.83% in accuracy, demonstrating its effectiveness in generalizing to unseen target datasets.","['domain adaptation methods', 'fine-tuning']","The research addresses the challenge of recognizing human activities across different datasets, which is complicated by variations in users, device types, and sensor placements. This domain shift problem limits the effectiveness of activity recognition when applied to new or unseen datasets, posing practical difficulties in real-world applications. The study aims to improve the performance of human activity recognition on unseen target datasets by developing an approach that enhances the generalizability of activity recognition models. Specifically, the objective is to create a method that can better handle variations between datasets without requiring access to the target dataset during the training process, thereby making activity recognition more robust and applicable across diverse settings."
Social Sciences,Transferable deep generative modeling of intrinsically disordered protein conformations,"Intrinsically disordered proteins have dynamic structures through which they play key biological roles. The elucidation of their conformational ensembles is a challenging problem requiring an integrated use of computational and experimental methods. Molecular simulations are a valuable computational strategy for constructing structural ensembles of disordered proteins but are highly resource-intensive. Recently, machine learning approaches based on deep generative models that learn from simulation data have emerged as an efficient alternative for generating structural ensembles. However, such methods currently suffer from limited transferability when modeling sequences and conformations absent in the training data. Here, we develop a novel generative model that achieves high levels of transferability for intrinsically disordered protein ensembles. The approach, named idpSAM, is a latent diffusion model based on transformer neural networks. It combines an autoencoder to learn a representation of protein geometry and a diffusion model to sample novel conformations in the encoded space. IdpSAM was trained on a large dataset of simulations of disordered protein regions performed with the ABSINTH implicit solvent model. Thanks to the expressiveness of its neural networks and its training stability, idpSAM faithfully captures 3D structural ensembles of test sequences with no similarity in the training set. Our study also demonstrates the potential for generating full conformational ensembles from datasets with limited sampling and underscores the importance of training set size for generalization. We believe that idpSAM represents a significant progress in transferable protein ensemble modeling through machine learning.","['deep generative models', 'latent diffusion model', 'transformer neural networks', 'autoencoder', 'diffusion model']","The study addresses the challenge of understanding the dynamic structures of intrinsically disordered proteins, which play key biological roles but are difficult to characterize due to their flexible conformational ensembles. Accurately elucidating these ensembles is important for advancing knowledge of protein behavior and function. The primary aim of the study is to develop a method that can reliably generate structural ensembles of intrinsically disordered proteins, including those with sequences and conformations not previously observed, thereby improving the ability to represent diverse protein structures and enhance generalization from limited experimental data."
Social Sciences,A machine learning-based classification model to support university students with dyslexia with personalized tools and strategies,"Abstract Dyslexia is a specific learning disorder that causes issues related to reading, which affects around 10% of the worldwide population. This can compromise comprehension and memorization skills, and result in anxiety and lack of self-esteem, if no support is provided. Moreover, this support should be highly personalized, to be actually helpful. In this paper, a model to classify the most useful methodologies to support students with dyslexia has been created, with a focus on university alumni. The prediction algorithm is based on supervised machine learning techniques; starting from the issues that dyslexic students experience during their career, it is capable of suggesting customized support digital tools and learning strategies for each of them. The algorithm was trained and tested on data acquired through a self-evaluation questionnaire, which was designed and then spread to more than 1200 university students. It allowed 17 useful tools and 22 useful strategies to be detected. The results of the testing showed an average prediction accuracy higher than 90%, which rises to 94% by renouncing to guess the less-predictable 8 tools/strategies. In the light of this, it is possible to state that the implemented algorithm can achieve the set goal and, thus, reduce the gap between dyslexic and non-dyslexic students. This achievement paves the way for a new modality of facing the problem of dyslexia by university institutions, which aims at modifying teaching activities toward students’ needs, instead of simply reducing their study load or duties. This complies with the definition and the aims of inclusivity.",['supervised machine learning techniques'],"The study addresses the challenges faced by individuals with dyslexia, a specific learning disorder affecting reading abilities and impacting around 10% of the global population. Dyslexia can hinder comprehension and memorization skills, leading to anxiety and low self-esteem if adequate support is not provided. The research highlights the importance of highly personalized support to effectively assist students with dyslexia, particularly focusing on university alumni. The primary aim of the study is to identify and classify the most useful methodologies and strategies to support dyslexic students during their academic careers. By understanding the specific difficulties these students encounter, the study seeks to suggest customized tools and learning approaches that can help reduce the educational gap between dyslexic and non-dyslexic students, promoting inclusivity within higher education institutions."
Social Sciences,Supervised Machine Learning Approaches for Predicting Key Pollutants and for the Sustainable Enhancement of Urban Air Quality: A Systematic Review,"Urban air pollution is a pressing global issue driven by factors such as swift urbanization, population expansion, and heightened industrial activities. To address this challenge, the integration of Machine Learning (ML) into smart cities presents a promising avenue. Our article offers comprehensive insights into recent advancements in air quality research, employing the PRISMA method as a cornerstone for the reviewing process, while simultaneously exploring the application of frequently employed ML methodologies. Focusing on supervised learning algorithms, the study meticulously analyzes air quality data, elucidating their unique benefits and challenges. These frequently employed ML techniques, including LSTM (Long Short-Term Memory), RF (Random Forest), ANN (Artificial Neural Networks), and SVR (Support Vector Regression), are instrumental in our quest for cleaner, healthier urban environments. By accurately predicting key pollutants such as particulate matter (PM), nitrogen oxides (NOx), carbon monoxide (CO), and ozone (O3), these methods offer tangible solutions for society. They enable informed decision-making for urban planners and policymakers, leading to proactive, sustainable strategies to combat urban air pollution. As a result, the well-being and health of urban populations are significantly improved. In this revised abstract, the importance of frequently employed ML methods in the context of air quality is explicitly emphasized, underlining their role in improving urban environments and enhancing the well-being of urban populations.","['LSTM (Long Short-Term Memory)', 'RF (Random Forest)', 'ANN (Artificial Neural Networks)', 'SVR (Support Vector Regression)']","The research addresses the pressing global issue of urban air pollution, which is exacerbated by rapid urbanization, population growth, and increased industrial activities. This environmental challenge significantly impacts the health and well-being of urban populations, necessitating effective strategies for cleaner and healthier urban environments. The primary aim of the study is to provide comprehensive insights into recent advancements in air quality research, focusing on understanding key pollutants such as particulate matter, nitrogen oxides, carbon monoxide, and ozone. The study seeks to inform urban planners and policymakers to develop proactive and sustainable strategies to combat urban air pollution and improve the quality of life in cities."
Social Sciences,"Real Estate Industry Sustainable Solution (Environmental, Social, and Governance) Significance Assessment—AI-Powered Algorithm Implementation","As the global imperative for sustainable development intensifies, the real estate industry stands at the intersection of environmental responsibility and economic viability. This paper presents a comprehensive exploration of the significance of sustainable solutions within the real estate sector, employing advanced artificial intelligence (AI) algorithms to assess their impact. This study focuses on the integration of AI-powered tools in a decision-making process analysis. The research methodology involves the development and implementation of AI algorithms capable of analyzing vast datasets related to real estate attributes. By leveraging machine learning techniques, the algorithm assesses the significance of energy efficiency solutions along with other intrinsic and extrinsic attributes. This paper examines the effectiveness of these solutions in relation to the influence on property prices with a framework based on an AI-driven algorithm. The findings aim to inform real estate professionals and investors about the tangible advantages of integrating AI technologies into sustainable solutions, promoting a more informed and responsible approach to industry practices. This research contributes to the growing interest in the connection of the real estate sector, sustainability, and AI, offering insights that can guide strategic decision making. By implementing the random forest method in the real estate feature significance assessment original methodology, it has been shown that AI-powered algorithms can be a useful tool from the perspective of real estate price prediction. The methodology’s ability to handle non-linear relationships and provide insights into feature importance proved advantageous in comparison to the multiple regression analysis.",['random forest method'],"The research addresses the growing importance of sustainable development within the real estate industry, highlighting the challenge of balancing environmental responsibility with economic viability. It explores the significance of sustainable solutions in real estate and their impact on property values, emphasizing the need for informed decision-making in this sector. The primary aim of the study is to examine the effectiveness of energy efficiency and other sustainability-related solutions in influencing property prices. The research seeks to provide real estate professionals and investors with insights that promote a more responsible and strategic approach to integrating sustainability into industry practices."
Social Sciences,A Survey on Information Bottleneck,"This survey is for the remembrance of one of the creators of the information bottleneck theory, Prof. Naftali Tishby, passing away at the age of 68 on August, 2021. Information bottleneck (IB), a novel information theoretic approach for pattern analysis and representation learning, has gained widespread popularity since its birth in 1999. It provides an elegant balance between data compression and information preservation, and improves its prediction or representation ability accordingly. This survey summarizes both the theoretical progress and practical applications on IB over the past 20-plus years, where its basic theory, optimization, extensive models and task-oriented algorithms are systematically explored. Existing IB methods are roughly divided into two parts: traditional and deep IB, where the former contains the IBs optimized by traditional machine learning analysis techniques without involving any neural networks, and the latter includes the IBs involving the interpretation, optimization and improvement of deep neural works (DNNs). Specifically, based on the technique taxonomy, traditional IBs are further classified into three categories: Basic, Informative and Propagating IB; While the deep IBs, based on the taxonomy of problem settings, contain Debate: Understanding DNNs with IB, Optimizing DNNs Using IB, and DNN-based IB methods. Furthermore, some potential issues deserving future research are discussed. This survey attempts to draw a more complete picture of IB, from which the subsequent studies can benefit.",['Information bottleneck (IB)'],"The research idea centers on commemorating the contributions of Prof. Naftali Tishby, one of the creators of the information bottleneck theory, and highlighting the significance of this theory in balancing data compression and information preservation for improved pattern analysis and representation. The study addresses the development and impact of this theoretical approach over more than two decades, emphasizing its role in advancing understanding and applications in the field. The primary objective of the study is to provide a comprehensive summary of the theoretical progress and practical applications of the information bottleneck theory since its inception in 1999. It aims to systematically explore the basic theory, various categories, and task-oriented approaches, as well as to discuss potential issues for future research, thereby offering a complete overview that can benefit subsequent studies."
Social Sciences,"Geographic and Demographic Differences in the Proportion of Individuals Living in Households With a Firearm, 1990-2018","Importance Measures of the proportion of individuals living in households with a firearm (HFR), over time, across states, and by demographic groups are needed to evaluate disparities in firearm violence and the effects of firearm policies. Objective To estimate HFR across states, years, and demographic groups in the US. Design, Setting, and Participants In this survey study, substate HFR totals from 1990 to 2018 were estimated using bayesian multilevel regression with poststratification to analyze survey data on HFR from the Behavioral Risk Factor Surveillance System and the General Social Survey. HFR was estimated for 16 substate demographic groups defined by gender, race, marital status, and urbanicity in each state and year. Exposures Survey responses indicating household firearm ownership were analyzed and compared with a common proxy for firearm ownership, the fraction of suicides completed with a firearm (FSS). Main Outcome and Measure HFR, FSS, and their correlations and differences. Results Among US adults in 2018, HFR was significantly higher among married, nonurban, non-Hispanic White and American Indian male individuals (65.0%; 95% credible interval [CI], 61.5%-68.7%) compared with their unmarried, urban, female counterparts from other racial and ethnic groups (7.3%; 95% CIs, 6.0%-9.2%). Marginal HFR rates for larger demographic groups also revealed important differences, with racial minority groups and urban dwellers having less than half the HFR of either White and American Indian (39.5%; 95% CI, 37.4%-42.9% vs 17.2%; 95% CI, 15.5%-19.9%) or nonurban populations (46.0%; 95% CI, 43.8%-49.5% vs 23.1%; 95% CI, 21.3%-26.2%). Population growth among groups less likely to own firearms, rather than changes in ownership within demographic groups, explains 30% of the 7 percentage point decline in HFR nationally from 1990 to 2018. Comparing HFR estimates with FSS revealed the expected high overall correlation across states (r = 0.84), but scaled FSS differed from HFR by as many as 20 percentage points for some states and demographic groups. Conclusions and Relevance This survey study of HFR providing detailed, publicly available HFR estimates highlights key disparities among individuals in households with firearms across states and demographic groups; it also identifies potential biases in the use of FSS as a proxy for firearm ownership rates. These findings are essential for researchers, policymakers, and public health experts looking to address geographic and demographic disparities in firearm violence.",['bayesian multilevel regression with poststratification'],"The research idea centers on the need to understand the proportion of individuals living in households with firearms (HFR) over time, across different states, and among various demographic groups in the United States. This understanding is crucial for evaluating disparities in firearm violence and assessing the impact of firearm policies. The study addresses significant differences in firearm ownership related to factors such as marital status, race, urbanicity, and gender, highlighting the importance of detailed demographic and geographic information. The primary objective of the study is to estimate the proportion of individuals living in households with firearms across states, years, and demographic groups in the US. By providing detailed estimates of HFR, the study aims to reveal key disparities and inform researchers, policymakers, and public health experts in their efforts to address geographic and demographic differences in firearm violence."
Social Sciences,Augmenting Reinforcement Learning With Transformer-Based Scene Representation Learning for Decision-Making of Autonomous Driving,"Decision-making for urban autonomous driving is challenging due to the stochastic nature of interactive traffic participants and the complexity of road structures. Although reinforcement learning (RL)-based decision-making schemes are promising to handle urban driving scenarios, they suffer from low sample efficiency and poor adaptability. In this paper, we propose the Scene-Rep Transformer to enhance RL decision-making capabilities through improved scene representation encoding and sequential predictive latent distillation. Specifically, a multi-stage Transformer (MST) encoder is constructed to model not only the interaction awareness between the ego vehicle and its neighbors but also intention awareness between the agents and their candidate routes. A sequential latent Transformer (SLT) with self-supervised learning objectives is employed to distill future predictive information into the latent scene representation, in order to reduce the exploration space and speed up training. The final decision-making module based on soft actor-critic (SAC) takes as input the refined latent scene representation from the Scene-Rep Transformer and generates decisions. The framework is validated in five challenging simulated urban scenarios with dense traffic, and its performance is manifested quantitatively by substantial improvements in data efficiency and performance in terms of success rate, safety, and efficiency. Qualitative results reveal that our framework is able to extract the intentions of neighbor agents, enabling better decision-making and more diversified driving behaviors.","['reinforcement learning (RL)', 'Transformer', 'self-supervised learning', 'soft actor-critic (SAC)']","The research idea addresses the challenges of decision-making in urban driving environments, which are complicated by the unpredictable behavior of traffic participants and the complexity of road structures. The study is motivated by the need to improve decision-making capabilities in these scenarios to enhance safety, efficiency, and adaptability. The primary objective of the study is to develop a framework that better captures the interactions and intentions of traffic participants to support more effective and diverse decision-making in urban driving contexts. This aims to improve overall performance in terms of success rate, safety, and efficiency in complex urban traffic situations."
Social Sciences,Machine learning study using 2020 SDHS data to determine poverty determinants in Somalia,"Abstract Extensive research has been conducted on poverty in developing countries using conventional regression analysis, which has limited prediction capability. This study aims to address this gap by applying advanced machine learning (ML) methods to predict poverty in Somalia. Utilizing data from the first-ever 2020 Somalia Demographic and Health Survey (SDHS), a cross-sectional study design is considered. ML methods, including random forest (RF), decision tree (DT), support vector machine (SVM), and logistic regression, are tested and applied using R software version 4.1.2, while conventional methods are analyzed using STATA version 17. Evaluation metrics, such as confusion matrix, accuracy, precision, sensitivity, specificity, recall, F1 score, and area under the receiver operating characteristic (AUROC), are employed to assess the performance of predictive models. The prevalence of poverty in Somalia is notable, with approximately seven out of ten Somalis living in poverty, making it one of the highest rates in the region. Among nomadic pastoralists, agro-pastoralists, and internally displaced persons (IDPs), the poverty average stands at 69%, while urban areas have a lower poverty rate of 60%. The accuracy of prediction ranged between 67.21% and 98.36% for the advanced ML methods, with the RF model demonstrating the best performance. The results reveal geographical region, household size, respondent age group, husband employment status, age of household head, and place of residence as the top six predictors of poverty in Somalia. The findings highlight the potential of ML methods to predict poverty and uncover hidden information that traditional statistical methods cannot detect, with the RF model identified as the best classifier for predicting poverty in Somalia.","['random forest (RF)', 'decision tree (DT)', 'support vector machine (SVM)', 'logistic regression']","The study addresses the significant issue of poverty in Somalia, where approximately seven out of ten individuals live in poverty, representing one of the highest rates in the region. It highlights the limitations of conventional approaches in effectively predicting poverty and the need for improved methods to better understand the factors contributing to poverty in different population groups, including nomadic pastoralists, agro-pastoralists, internally displaced persons, and urban residents. The primary aim of the study is to enhance the prediction of poverty in Somalia by utilizing data from the 2020 Somalia Demographic and Health Survey to identify key predictors of poverty. The study seeks to uncover important socioeconomic and demographic factors influencing poverty, such as geographical region, household size, age groups, employment status, and place of residence, to provide deeper insights into poverty dynamics within the country."
Social Sciences,TimesURL: Self-Supervised Contrastive Learning for Universal Time Series Representation Learning,"Learning universal time series representations applicable to various types of downstream tasks is challenging but valuable in real applications. Recently, researchers have attempted to leverage the success of self-supervised contrastive learning (SSCL) in Computer Vision(CV) and Natural Language Processing(NLP) to tackle time series representation. Nevertheless, due to the special temporal characteristics, relying solely on empirical guidance from other domains may be ineffective for time series and difficult to adapt to multiple downstream tasks. To this end, we review three parts involved in SSCL including 1) designing augmentation methods for positive pairs, 2) constructing (hard) negative pairs, and 3) designing SSCL loss. For 1) and 2), we find that unsuitable positive and negative pair construction may introduce inappropriate inductive biases, which neither preserve temporal properties nor provide sufficient discriminative features. For 3), just exploring segment- or instance-level semantics information is not enough for learning universal representation. To remedy the above issues, we propose a novel self-supervised framework named TimesURL. Specifically, we first introduce a frequency-temporal-based augmentation to keep the temporal property unchanged. And then, we construct double Universums as a special kind of hard negative to guide better contrastive learning. Additionally, we introduce time reconstruction as a joint optimization objective with contrastive learning to capture both segment-level and instance-level information. As a result, TimesURL can learn high-quality universal representations and achieve state-of-the-art performance in 6 different downstream tasks, including short- and long-term forecasting, imputation, classification, anomaly detection and transfer learning.",['self-supervised contrastive learning (SSCL)'],"The study addresses the challenge of developing universal representations for time series data that can be effectively applied across various practical tasks. It highlights the difficulty of adapting approaches from other fields due to the unique temporal characteristics of time series, which require preserving temporal properties and capturing sufficient discriminative features. The research aims to improve the understanding and construction of representations that maintain these temporal aspects and are broadly applicable. The primary objective of the study is to propose a framework that enhances the learning of universal time series representations by addressing limitations in current methods, ultimately enabling better performance across multiple downstream tasks such as forecasting, imputation, classification, anomaly detection, and transfer learning."
Social Sciences,MS-BACL: enhancing metabolic stability prediction through bond graph augmentation and contrastive learning,"Abstract Motivation Accurately predicting molecular metabolic stability is of great significance to drug research and development, ensuring drug safety and effectiveness. Existing deep learning methods, especially graph neural networks, can reveal the molecular structure of drugs and thus efficiently predict the metabolic stability of molecules. However, most of these methods focus on the message passing between adjacent atoms in the molecular graph, ignoring the relationship between bonds. This makes it difficult for these methods to estimate accurate molecular representations, thereby being limited in molecular metabolic stability prediction tasks. Results We propose the MS-BACL model based on bond graph augmentation technology and contrastive learning strategy, which can efficiently and reliably predict the metabolic stability of molecules. To our knowledge, this is the first time that bond-to-bond relationships in molecular graph structures have been considered in the task of metabolic stability prediction. We build a bond graph based on ‘atom-bond-atom’, and the model can simultaneously capture the information of atoms and bonds during the message propagation process. This enhances the model’s ability to reveal the internal structure of the molecule, thereby improving the structural representation of the molecule. Furthermore, we perform contrastive learning training based on the molecular graph and its bond graph to learn the final molecular representation. Multiple sets of experimental results on public datasets show that the proposed MS-BACL model outperforms the state-of-the-art model. Availability and Implementation The code and data are publicly available at https://github.com/taowang11/MS.","['deep learning', 'graph neural networks', 'contrastive learning strategy']","The study addresses the challenge of accurately predicting molecular metabolic stability, which is crucial for ensuring drug safety and effectiveness in drug research and development. Existing approaches often overlook the relationships between bonds within molecular structures, limiting the ability to obtain precise representations necessary for reliable predictions. The primary aim of the study is to improve the prediction of molecular metabolic stability by considering the interactions between bonds in molecular structures, thereby enhancing the understanding of the internal molecular configuration. This objective seeks to provide a more accurate and reliable representation of molecules to support better prediction outcomes in the context of drug development."
Social Sciences,"Advancements in machine visions for fruit sorting and grading: A bibliometric analysis, systematic review, and future research directions","This research conducted a bibliometric analysis of scholarly literature on fruit sorting and grading using machine vision, identifying primary themes, sources, most-cited publications, and countries. The literature and bibliometric analysis were thoroughly evaluated to consolidate knowledge, identify research trends, and propose specific research opportunities within the context of machine vision for fruit sorting and grading. Research articles from 2011 to 2023, indexed in the main collections of the Dimensions, Web-of-science, and Scopus databases, were examined. Findings were presented quantitatively, using tables and graphs to emphasize the key performance factors for article writing and citation. Upon applying inclusion and exclusion criteria, 129 out of 1,812 discovered articles were included for examination, while 1,683 studies were excluded due to non-compliance with the requirements and duplicates. Thirty-four (34) case study publications on machine vision applications for fruit sorting and grading were comprehensively examined to identify the adopted methodologies and future research opportunities. Covered methodologies include fruit varieties, data volumes, data collection, classification methods, and accuracy metrics. The study's findings indicate a significant increase in deep learning applications for fruit recognition in the recent five years (2019-2023), with excellent results achieved either by utilizing new models or with pre-trained networks for transfer learning. The research also identifies gaps and future directions for machine vision in fruit sorting and grading, such as enhancing system robustness, scalability, and adaptability, integrating multiple sensors and technological methods, and developing evaluation and comparison standards and criteria. The paper concludes that machine vision holds promise as a potent tool for fruit quality assessment, but further research and development are needed to address existing challenges and meet the growing demands of the fruit industry.","['deep learning', 'pre-trained networks for transfer learning']","The research addresses the growing need to consolidate knowledge and identify trends within the scholarly literature on fruit sorting and grading, focusing on the challenges and opportunities in improving fruit quality assessment. It highlights the importance of understanding current research themes, sources, and influential publications to better support advancements in this area. The study aims to thoroughly evaluate existing literature to propose specific research opportunities and identify gaps that need to be addressed to enhance the effectiveness and applicability of fruit sorting and grading practices. Its primary objective is to examine and synthesize research articles from 2011 to 2023 to identify key factors influencing fruit quality assessment, highlight future research directions, and support the development of more robust, scalable, and adaptable approaches to meet the evolving demands of the fruit industry."
Social Sciences,Sequential predictive learning is a unifying theory for hippocampal representation and replay,"Abstract The mammalian hippocampus contains a cognitive map that represents an animal’s position in the environment 1 and generates offline “replay” 2,3 for the purposes of recall 4 , planning 5,6 , and forming long term memories 7 . Recently, it’s been found that artificial neural networks trained to predict sensory inputs develop spatially tuned cells 8 , aligning with predictive theories of hippocampal function 9–11 . However, whether predictive learning can also account for the ability to produce offline replay is unknown. Here, we find that spatially-tuned cells, which robustly emerge from all forms of predictive learning, do not guarantee the presence of a cognitive map with the ability to generate replay. Offline simulations only emerged in networks that used recurrent connections and head-direction information to predict multi-step observation sequences, which promoted the formation of a continuous attractor reflecting the geometry of the environment. These offline trajectories were able to show wake-like statistics, autonomously replay recently experienced locations, and could be directed by a virtual head direction signal. Further, we found that networks trained to make cyclical predictions of future observation sequences were able to rapidly learn a cognitive map and produced sweeping representations of future positions reminiscent of hippocampal theta sweeps 12 . These results demonstrate how hippocampal-like representation and replay can emerge in neural networks engaged in predictive learning, and suggest that hippocampal theta sequences reflect a circuit that implements a data-efficient algorithm for sequential predictive learning. Together, this framework provides a unifying theory for hippocampal functions and hippocampal-inspired approaches to artificial intelligence.","['artificial neural networks', 'recurrent connections']","The research idea centers on understanding how the mammalian hippocampus forms a cognitive map that represents spatial position and generates offline replay, which is crucial for recall, planning, and long-term memory formation. The study addresses the question of whether predictive learning alone can explain the hippocampus's ability to produce offline replay, a key feature of spatial cognition. The research objective is to investigate the conditions under which spatially-tuned cells contribute to the formation of a cognitive map capable of generating offline replay. Specifically, the study aims to determine how certain factors, such as recurrent connections and directional information, influence the emergence of continuous spatial representations and replay phenomena that resemble hippocampal activity patterns observed during navigation and memory processes."
Social Sciences,Combating the Challenges of False Positives in AI-Driven Anomaly Detection Systems and Enhancing Data Security in the Cloud,"Anomaly detection is critical for network security, fraud detection, and system health monitoring applications. Traditional methods like statistical approaches and distance-based techniques often struggle with high-dimensional and complex data, leading to high false positive rates. This study addresses the challenge by investigating advanced AI-driven techniques to reduce false positives and enhance data security within cloud computing environments. This study employs deep learning models, integrates contextual data, and incorporates comprehensive security measures to enhance anomaly detection performance. Data from synthetic sources, such as the NSL-KDD dataset and real-world cloud environments, were utilized to capture user behavior logs, system states, and network traffic. Over 50 academic journals were reviewed, and 21 were selected based on inclusion criteria, such as relevance to AI-driven anomaly detection, empirical performance metrics, and the focus on cloud environments, and exclusion criteria that filtered out studies lacking empirical data or not specific to cloud-based systems. Methodologically, the research involves a comparative analysis of different AI techniques and their impact on false positive rates, accuracy, precision, and recall. The findings demonstrate that deep learning techniques significantly outperform traditional methods, achieving a lower false positive rate and higher accuracy. The results underscore the importance of contextual data and robust security protocols in reliable anomaly detection. This research fills a gap by thoroughly evaluating advanced AI techniques for reducing false positives in cloud environments. The study's significance lies in guiding the development of more effective anomaly detection systems, thereby enhancing security and reliability across various applications. Additionally, organizations should invest in continuously developing and integrating AI-driven anomaly detection systems with comprehensive security measures to improve their effectiveness the study suggests that further study be conducted with large datasets to evaluate the effectiveness of Hybrid anomaly detection systems in detecting and addressing false positives.",['Hybrid anomaly detection systems'],"The study addresses the critical challenge of improving anomaly detection to enhance network security, fraud detection, and system health monitoring, particularly within cloud computing environments. Traditional approaches often face difficulties handling complex and high-dimensional data, resulting in high false positive rates that undermine security effectiveness. The primary aim of the research is to investigate advanced techniques to reduce false positives and improve the reliability of anomaly detection in cloud environments. By thoroughly evaluating these approaches, the study seeks to guide the development of more effective security measures that enhance overall system reliability and protection."
Social Sciences,Long-Term Preference Mining With Temporal and Spatial Fusion for Point-of-Interest Recommendation,"The growth of the tourism industry has greatly boosted the Point-of-Interest (POI) recommendation tasks using Location-based Social Networks (LBSNs). The ever-evolving nature of user preferences poses a major problem. To address this, we propose a Long-Term Preference Mining (LTPM) approach that utilizes the Temporal Recency (TR) measure in the visits along with the location-aware recommendation based on Spatial Proximity (SP) to the user's location. The temporal dynamics and changing preferences are exploited based on the modified Long Short-term Memory (LSTM) that utilizes the time decay. The spatial considerations are modeled in two aspects: geographical proximity based on enhanced representation learning using orthogonal mapping. Second, the Region-of-Interest (ROI) is based on spatial griding and metric learning to capture the spatial relationships between POIs to enhance the metric space representation. The final recommendations are based on a multi-head attention mechanism that allocates the weights to different features. The combination of three models, called, LTPM-TRSP approach captures the user-POI, POI-POI, and POI-time relationships by focusing on the informative representation of sequential and spatial data. The category-aware final recommendations based on comprehensive historical behavior and geographical context are quite efficacious. The experimentation on three real-world datasets, Gowalla, Foursquare, and Weeplaces, also suggests the potency compared to other state-of-the-art approaches.","['Long Short-term Memory (LSTM)', 'metric learning', 'multi-head attention mechanism']","The research idea centers on the challenge posed by the ever-evolving nature of user preferences within the tourism industry, particularly in relation to recommending points of interest (POIs) through location-based social networks. This dynamic change in preferences creates difficulties in providing accurate and relevant recommendations that reflect both temporal and spatial factors. The study aims to address the need for capturing long-term user preferences while considering the geographical context and temporal dynamics of user visits. The primary objective of the study is to develop an approach that effectively incorporates temporal recency and spatial proximity to improve the recommendation of POIs by focusing on users' comprehensive historical behavior and geographical context. The study seeks to enhance the understanding of user-POI interactions over time and space to provide more accurate and category-aware recommendations in the tourism sector."
Social Sciences,Gas adsorption meets deep learning: voxelizing the potential energy surface of metal-organic frameworks,"Abstract Intrinsic properties of metal-organic frameworks (MOFs), such as their ultra porosity and high surface area, deem them promising solutions for problems involving gas adsorption. Nevertheless, due to their combinatorial nature, a huge number of structures is feasible which renders cumbersome the selection of the best candidates with traditional techniques. Recently, machine learning approaches have emerged as efficient tools to deal with this challenge, by allowing researchers to rapidly screen large databases of MOFs via predictive models. The performance of the latter is tightly tied to the mathematical representation of a material, thus necessitating the use of informative descriptors. In this work, a generalized framework to predict gaseous adsorption properties is presented, using as one and only descriptor the capstone of chemical information: the potential energy surface (PES). In order to be machine understandable, the PES is voxelized and subsequently a 3D convolutional neural network (CNN) is exploited to process this 3D energy image. As a proof of concept, the proposed pipeline is applied on predicting $${\hbox {CO}_{2}}$$ <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""> <mml:msub> <mml:mtext>CO</mml:mtext> <mml:mn>2</mml:mn> </mml:msub> </mml:math> uptake in MOFs. The resulting model outperforms a conventional model built with geometric descriptors and requires two orders of magnitude less training data to reach a given level of performance. Moreover, the transferability of the approach to different host-guest systems is demonstrated, examining $${\hbox {CH}_4}$$ <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""> <mml:msub> <mml:mtext>CH</mml:mtext> <mml:mn>4</mml:mn> </mml:msub> </mml:math> uptake in COFs. The generic character of the proposed methodology, inherited from the PES, renders it applicable to fields other than reticular chemistry.",['3D convolutional neural network (CNN)'],"The research idea centers on addressing the challenge of selecting the best candidates among a vast number of metal-organic frameworks (MOFs) for gas adsorption applications, given their intrinsic properties such as ultra porosity and high surface area. The combinatorial nature of these structures makes traditional selection techniques cumbersome and inefficient. The study is motivated by the need for more effective approaches to rapidly and accurately identify MOFs with optimal gas adsorption capabilities. The primary objective of the study is to develop a generalized framework that can predict gaseous adsorption properties in MOFs using a comprehensive chemical descriptor, focusing specifically on carbon dioxide uptake as a proof of concept. Additionally, the study aims to demonstrate the transferability of this approach to different host-guest systems, such as methane uptake in covalent organic frameworks (COFs), thereby highlighting the broader applicability of the methodology beyond the initial chemical context."
Social Sciences,Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model,"Recently the state space models (SSMs) with efficient hardware-aware designs, i.e., the Mamba deep learning model, have shown great potential for long sequence modeling. Meanwhile building efficient and generic vision backbones purely upon SSMs is an appealing direction. However, representing visual data is challenging for SSMs due to the position-sensitivity of visual data and the requirement of global context for visual understanding. In this paper, we show that the reliance on self-attention for visual representation learning is not necessary and propose a new generic vision backbone with bidirectional Mamba blocks (Vim), which marks the image sequences with position embeddings and compresses the visual representation with bidirectional state space models. On ImageNet classification, COCO object detection, and ADE20k semantic segmentation tasks, Vim achieves higher performance compared to well-established vision transformers like DeiT, while also demonstrating significantly improved computation & memory efficiency. For example, Vim is 2.8$\times$ faster than DeiT and saves 86.8% GPU memory when performing batch inference to extract features on images with a resolution of 1248$\times$1248. The results demonstrate that Vim is capable of overcoming the computation & memory constraints on performing Transformer-style understanding for high-resolution images and it has great potential to be the next-generation backbone for vision foundation models. Code is available at https://github.com/hustvl/Vim.","['state space models (SSMs)', 'vision transformers', 'DeiT']","The research idea centers on addressing the challenges of representing visual data effectively, particularly the position-sensitivity of such data and the need for capturing global context in visual understanding. There is a motivation to develop efficient and versatile frameworks for visual representation that do not rely on conventional approaches typically used in this domain. The study aims to propose a new approach for building a generic vision backbone that improves performance in image classification, object detection, and semantic segmentation tasks. The primary objective is to demonstrate that this new vision backbone can achieve higher accuracy and greater efficiency in computation and memory usage compared to existing well-established methods, thereby overcoming current limitations in processing high-resolution images for visual understanding."
Social Sciences,Generative AI in Medical Practice: In-Depth Exploration of Privacy and Security Challenges,"As advances in artificial intelligence (AI) continue to transform and revolutionize the field of medicine, understanding the potential uses of generative AI in health care becomes increasingly important. Generative AI, including models such as generative adversarial networks and large language models, shows promise in transforming medical diagnostics, research, treatment planning, and patient care. However, these data-intensive systems pose new threats to protected health information. This Viewpoint paper aims to explore various categories of generative AI in health care, including medical diagnostics, drug discovery, virtual health assistants, medical research, and clinical decision support, while identifying security and privacy threats within each phase of the life cycle of such systems (ie, data collection, model development, and implementation phases). The objectives of this study were to analyze the current state of generative AI in health care, identify opportunities and privacy and security challenges posed by integrating these technologies into existing health care infrastructure, and propose strategies for mitigating security and privacy risks. This study highlights the importance of addressing the security and privacy threats associated with generative AI in health care to ensure the safe and effective use of these systems. The findings of this study can inform the development of future generative AI systems in health care and help health care organizations better understand the potential benefits and risks associated with these systems. By examining the use cases and benefits of generative AI across diverse domains within health care, this paper contributes to theoretical discussions surrounding AI ethics, security vulnerabilities, and data privacy regulations. In addition, this study provides practical insights for stakeholders looking to adopt generative AI solutions within their organizations.",['generative adversarial networks'],"The research idea centers on the growing importance of understanding the potential uses and implications of emerging technologies in health care, particularly as they transform medical diagnostics, research, treatment planning, and patient care. While these advancements offer promising benefits, they also introduce new threats to the security and privacy of protected health information, raising critical concerns that need to be addressed. The study aims to explore various applications within health care and identify associated security and privacy challenges throughout different phases of their implementation. The primary objective of the study is to analyze the current state of these technologies in health care, identify opportunities alongside privacy and security challenges posed by their integration into existing health care infrastructure, and propose strategies to mitigate these risks. By doing so, the study seeks to highlight the importance of addressing security and privacy threats to ensure the safe and effective use of these innovations, thereby informing health care organizations and contributing to ethical and regulatory discussions in the field."
Social Sciences,Comprehensive systematic review of information fusion methods in smart cities and urban environments,"Smart cities result from integrating advanced technologies and intelligent sensors into modern urban infrastructure. The Internet of Things (IoT) and data integration are pivotal in creating interconnected and intelligent urban spaces. In this literature review, we explore the different methods of information fusion used in smart cities, along with their advantages and challenges. However, there are notable challenges in managing diverse data sources, handling large data volumes, and meeting the near-real-time demands of various smart city applications. The review aims to examine smart city applications in detail, incorporating quality evaluation and information fusion techniques and identifying critical issues while outlining promising research directions. In order to accomplish our goal, we conducted a comprehensive search of literature and applied selective criteria. We identified 59 recent studies addressing machine learning (ML) and deep learning (DL) techniques in smart city applications. These studies were obtained from various databases such as ScienceDirect (SD), Scopus, Web of Science (WoS), and IEEE Xplore. The main objective of this study is to provide more detailed insights into smart cities by supplementing existing research. The word cloud visualisation of machine learning/deep learning and information fusion in smart cities papers shows a diverse landscape, covering both technical aspects of artificial intelligence and practical applications in urban settings. Apart from technical exploration, the study also delves into the ethical and privacy implications arising in smart cities. Moreover, it thoroughly examines the challenges that must be addressed to realise this urban revolution's potential fully.","['machine learning (ML)', 'deep learning (DL)']","The research idea centers on the development of smart cities through the integration of advanced technologies into urban infrastructure, highlighting the challenges in managing diverse information sources, large volumes of data, and the demands of real-time urban applications. This study recognizes the complexity of creating interconnected and intelligent urban spaces while addressing critical issues such as ethical and privacy implications. The primary objective of the study is to provide a detailed examination of smart city applications by reviewing existing research, evaluating quality aspects, and identifying key challenges and promising directions for future exploration. Additionally, the study aims to supplement current knowledge by offering deeper insights into the practical and societal dimensions of smart cities."
Social Sciences,Systematic literature review: Quantum machine learning and its applications,"Quantum physics has changed the way we understand our environment, and one of its branches, quantum mechanics, has demonstrated accurate and consistent theoretical results. Quantum computing is the process of performing calculations using quantum mechanics. This field studies the quantum behavior of certain subatomic particles (photons, electrons, etc.) for subsequent use in performing calculations, as well as for large-scale information processing. These advantages are achieved through the use of quantum features, such as entanglement or superposition. These capabilities can give quantum computers an advantage in terms of computational time and cost over classical computers. Nowadays, scientific challenges are impossible to perform by classical computation due to computational complexity (more bytes than atoms in the observable universe) or the time it would take (thousands of years), and quantum computation is the only known answer. However, current quantum devices do not have yet the necessary qubits and are not fault-tolerant enough to achieve these goals. Nonetheless, there are other fields like machine learning, finance, or chemistry where quantum computation could be useful with current quantum devices. This manuscript aims to present a review of the literature published between 2017 and 2023 to identify, analyze, and classify the different types of algorithms used in quantum machine learning and their applications. The methodology follows the guidelines related to Systematic Literature Review methods, such as the one proposed by Kitchenham and other authors in the software engineering field. Consequently, this study identified 94 articles that used quantum machine learning techniques and algorithms and shows their implementation using computational quantum circuits or ansatzs. The main types of found algorithms are quantum implementations of classical machine learning algorithms, such as support vector machines or the k-nearest neighbor model, and classical deep learning algorithms, like quantum neural networks. One of the most relevant applications in the machine learning field is image classification. Many articles, especially within the classification, try to solve problems currently answered by classical machine learning but using quantum devices and algorithms. Even though results are promising, quantum machine learning is far from achieving its full potential. An improvement in quantum hardware is required for this potential to be achieved since the existing quantum computers lack enough quality, speed, and scale to allow quantum computing to achieve its full potential.","['support vector machines', 'k-nearest neighbor model', 'quantum neural networks']","The research idea centers on the limitations of current computational methods in addressing complex scientific challenges due to their extensive time and resource requirements, highlighting the potential of emerging technologies to overcome these barriers. It recognizes that while traditional approaches struggle with problems of immense complexity, alternative computational paradigms offer promising advantages that could transform various fields such as finance and chemistry. The research objective is to review and categorize the existing literature from 2017 to 2023 concerning the different approaches and their applications within this emerging computational paradigm. The study aims to identify the types of approaches used, analyze their implementation, and assess their current capabilities and limitations in practical applications, emphasizing the need for advancements in underlying technology to fully realize their potential."
Social Sciences,"Generative AI for Transformative Healthcare: A Comprehensive Study of Emerging Models, Applications, Case Studies, and Limitations","Generative artificial intelligence (GAI) can be broadly described as an artificial intelligence system capable of generating images, text, and other media types with human prompts. GAI models like ChatGPT, DALL-E, and Bard have recently caught the attention of industry and academia equally. GAI applications span various industries like art, gaming, fashion, and healthcare. In healthcare, GAI shows promise in medical research, diagnosis, treatment, and patient care and is already making strides in real-world deployments. There has yet to be any detailed study concerning the applications and scope of GAI in healthcare. Addressing this research gap, we explore several applications, real-world scenarios, and limitations of GAI in healthcare. We examine how GAI models like ChatGPT and DALL-E can be leveraged to aid in the applications of medical imaging, drug discovery, personalized patient treatment, medical simulation and training, clinical trial optimization, mental health support, healthcare operations and research, medical chatbots, human movement simulation, and a few more applications. Along with applications, we cover four real-world healthcare scenarios that employ GAI: visual snow syndrome diagnosis, molecular drug optimization, medical education, and dentistry. We also provide an elaborate discussion on seven healthcare-customized LLMs like Med-PaLM, BioGPT, DeepHealth, etc.,Since GAI is still evolving, it poses challenges like the lack of professional expertise in decision making, risk of patient data privacy, issues in integrating with existing healthcare systems, and the problem of data bias which are elaborated on in this work along with several other challenges. We also put forward multiple directions for future research in GAI for healthcare.","['healthcare-customized LLMs like Med-PaLM', 'healthcare-customized LLMs like BioGPT']","The research idea centers on the emerging role and potential of generative artificial intelligence in healthcare, highlighting its applications across various medical fields such as medical imaging, drug discovery, personalized treatment, and mental health support. Despite its growing use, there is a notable lack of detailed studies examining the scope, real-world applications, and limitations of this technology within healthcare settings. The study aims to address this gap by exploring how generative AI can be utilized in diverse healthcare scenarios and by discussing the challenges it presents, including issues related to professional decision-making, patient data privacy, system integration, and data bias. The primary objective of the study is to investigate and document the applications, real-world scenarios, and limitations of generative AI in healthcare, providing a comprehensive overview of its current use and proposing directions for future research to enhance its integration and effectiveness in medical practice."
Social Sciences,Human-AI collaboration patterns in AI-assisted academic writing,"Artificial Intelligence (AI) has increasingly influenced higher education, notably in academic writing where AI-powered assisting tools offer both opportunities and challenges. Recently, the rapid growth of generative AI (GAI) has brought its impacts into sharper focus, yet the dynamics of its utilisation in academic writing remain largely unexplored. This paper focuses on examining the nature of human-AI interactions in academic writing, specifically investigating the strategies doctoral students employ when collaborating with a GAI-powered assisting tool. This study involves 626 recorded activities on how ten doctoral students interact with GAI-powered assisting tool during academic writing. AI-driven learning analytics approach was adopted for three layered analyses: (1) data pre-processing and analysis with quantitative content analysis, (2) sequence analysis with Hidden Markov Model (HMM) and hierarchical sequence clustering, and (3) pattern analysis with process mining. Findings indicate that doctoral students engaging in iterative, highly interactive processes with the GAI-powered assisting tool generally achieve better performance in the writing task. In contrast, those who use GAI merely as a supplementary information source, maintaining a linear writing approach, tend to get lower writing performance. This study points to the need for further investigations into human-AI collaboration in learning in higher education, with implications for tailored educational strategies and solutions.",['Hidden Markov Model (HMM)'],"The study addresses the growing influence of generative AI on academic writing in higher education, highlighting both the opportunities and challenges it presents. Despite the rapid adoption of these tools, the ways in which doctoral students utilize such assistance in their writing processes remain largely unexplored. The research aims to examine the nature of interactions between doctoral students and generative AI tools during academic writing. Specifically, it investigates the strategies employed by these students when collaborating with AI-assisted tools to understand how different approaches impact their writing performance."
Social Sciences,"A comprehensive survey of research towards AI-enabled unmanned aerial systems in pre-, active-, and post-wildfire management","Wildfires have emerged as one of the most destructive natural disasters worldwide, causing catastrophic losses. These losses have underscored the urgent need to improve public knowledge and advance existing techniques in wildfire management. Recently, the use of Artificial Intelligence (AI) in wildfires, propelled by the integration of Unmanned Aerial Vehicles (UAVs) and deep learning models, has created an unprecedented momentum to implement and develop more effective wildfire management. Although existing survey papers have explored learning-based approaches in wildfire, drone use in disaster management, and wildfire risk assessment, a comprehensive review emphasizing the application of AI-enabled UAV systems and investigating the role of learning-based methods throughout the overall workflow of multi-stage wildfire management, including pre-fire (e.g., vision-based vegetation fuel measurement), active-fire (e.g., fire growth modeling), and post-fire tasks (e.g., evacuation planning) is notably lacking. This survey synthesizes and integrates state-of-the-science reviews and research at the nexus of wildfire observations and modeling, AI, and UAVs - topics at the forefront of advances in wildfire management, elucidating the role of AI in performing monitoring and actuation tasks from pre-fire, through the active-fire stage, to post-fire management. To this aim, we provide an extensive analysis of the existing remote sensing systems with a particular focus on the UAV advancements, device specifications, and sensor technologies relevant to wildfire management. We also examine the pre-fire and post-fire management approaches, including fuel monitoring, prevention strategies, as well as evacuation planning, damage assessment, and operation strategies. Additionally, we review and summarize a wide range of computer vision techniques in active-fire management, with an emphasis on Machine Learning (ML), Reinforcement Learning (RL), and Deep Learning (DL) algorithms for wildfire classification, segmentation, detection, and monitoring tasks. Ultimately, we underscore the substantial advancement in wildfire modeling through the integration of cutting-edge AI techniques and UAV-based data, providing novel insights and enhanced predictive capabilities to understand dynamic wildfire behavior.","['Machine Learning (ML)', 'Reinforcement Learning (RL)', 'Deep Learning (DL)']","The research addresses the critical issue of wildfires as one of the most destructive natural disasters globally, causing catastrophic losses and highlighting the urgent need to improve public knowledge and enhance wildfire management practices. Despite existing studies on wildfire risk assessment and disaster management, there is a notable gap in comprehensive reviews that focus on the integration of advanced technologies throughout the entire process of wildfire management, including pre-fire, active-fire, and post-fire stages. The primary objective of the study is to provide an extensive synthesis and integration of current knowledge on wildfire observations and management, with particular attention to advancements in remote sensing and monitoring technologies relevant to wildfire prevention, active management, and post-fire recovery. The study aims to examine and summarize various approaches to fuel monitoring, prevention strategies, evacuation planning, damage assessment, and operational strategies to offer novel insights and improve understanding of dynamic wildfire behavior."
Social Sciences,AI-Driven Clinical Decision Support Systems: An Ongoing Pursuit of Potential,"Clinical Decision Support Systems (CDSS) are essential tools in contemporary healthcare, enhancing clinicians' decisions and patient outcomes. The integration of artificial intelligence (AI) is now revolutionizing CDSS even further. This review delves into AI technologies transforming CDSS, their applications in healthcare decision-making, associated challenges, and the potential trajectory toward fully realizing AI-CDSS's potential. The review begins by laying the groundwork with a definition of CDSS and its function within the healthcare field. It then highlights the increasingly significant role that AI is playing in enhancing CDSS effectiveness and efficiency, underlining its evolving prominence in shaping healthcare practices. It examines the integration of AI technologies into CDSS, including machine learning algorithms like neural networks and decision trees, natural language processing, and deep learning. It also addresses the challenges associated with AI integration, such as interpretability and bias. We then shift to AI applications within CDSS, with real-life examples of AI-driven diagnostics, personalized treatment recommendations, risk prediction, early intervention, and AI-assisted clinical documentation. The review emphasizes user-centered design in AI-CDSS integration, addressing usability, trust, workflow, and ethical and legal considerations. It acknowledges prevailing obstacles and suggests strategies for successful AI-CDSS adoption, highlighting the need for workflow alignment and interdisciplinary collaboration. The review concludes by summarizing key findings, underscoring AI's transformative potential in CDSS, and advocating for continued research and innovation. It emphasizes the need for collaborative efforts to realize a future where AI-powered CDSS optimizes healthcare delivery and improves patient outcomes.","['neural networks', 'decision trees', 'deep learning']","The study addresses the growing importance of Clinical Decision Support Systems (CDSS) in healthcare and the transformative impact of integrating advanced technologies to enhance clinical decision-making and patient outcomes. It highlights the challenges and opportunities associated with evolving CDSS, emphasizing the need to understand their role within healthcare practices and the implications for usability, trust, workflow, and ethical considerations. The primary aim of the study is to review the current state and applications of these technologies within CDSS, explore the challenges related to their integration, and propose strategies for successful adoption. Additionally, the study seeks to underscore the importance of interdisciplinary collaboration and user-centered design to optimize healthcare delivery and improve patient outcomes through enhanced decision support."
Social Sciences,A systematic review of trustworthy artificial intelligence applications in natural disasters,"Artificial intelligence (AI) holds significant promise for advancing natural disaster management through the use of predictive models that analyze extensive datasets, identify patterns, and forecast potential disasters. These models facilitate proactive measures such as early warning systems (EWSs), evacuation planning, and resource allocation, addressing the substantial challenges associated with natural disasters. This study offers a comprehensive exploration of trustworthy AI applications in natural disasters, encompassing disaster management, risk assessment, and disaster prediction. This research is underpinned by an extensive review of reputable sources, including Science Direct (SD), Scopus, IEEE Xplore (IEEE), and Web of Science (WoS). Three queries were formulated to retrieve 981 papers from the earliest documented scientific production until February 2024. After meticulous screening, deduplication, and application of the inclusion and exclusion criteria, 108 studies were included in the quantitative synthesis. This study provides a specific taxonomy of AI applications in natural disasters and explores the motivations, challenges, recommendations, and limitations of recent advancements. It also offers an overview of recent techniques and developments in disaster management using explainable artificial intelligence (XAI), data fusion, data mining, machine learning (ML), deep learning (DL), fuzzy logic, and multicriteria decision-making (MCDM). This systematic contribution addresses seven open issues and provides critical solutions through essential insights, laying the groundwork for various future works in trustworthiness AI-based natural disaster management. Despite the potential benefits, challenges persist in the application of AI to natural disaster management. In these contexts, this study identifies several unused and used areas in natural disaster-based AI theory, collects the disaster datasets, ML, and DL techniques, and offers a valuable XAI approach to unravel the complex relationships and dynamics involved and the utilization of data fusion techniques in decision-making processes related to natural disasters. Finally, the study extensively analyzed ethical considerations, bias, and consequences in natural disaster-based AI.","['machine learning (ML)', 'deep learning (DL)']","The research idea centers on addressing the substantial challenges associated with natural disasters by exploring advancements that facilitate proactive measures such as early warning systems, evacuation planning, and resource allocation. The study recognizes the importance of trustworthy approaches in improving disaster management, risk assessment, and disaster prediction to better handle the complexities and dynamics involved in natural disaster contexts. The primary objective of the study is to provide a comprehensive exploration of applications related to natural disaster management, including a detailed taxonomy of current practices, motivations, challenges, recommendations, and limitations. Additionally, the study aims to identify open issues and offer critical insights and solutions that lay the groundwork for future research focused on enhancing the trustworthiness and effectiveness of disaster management strategies."
Social Sciences,Integration of Generative AI Techniques and Applications in Student Behavior and Cognitive Achievement in Arab Higher Education,"The integration of Artificial Intelligence (AI) in higher education has the power to revolutionize the learning experience by fostering engagement, personalization, efficiency, and innovation. AI offers a wide range of exciting possibilities where AI-powered tools enable students to receive tailored feedback and guidance, enabling them to learn at their own pace and excel academically. This research aims to investigate the effects of generative AI techniques and applications on students' cognitive achievement through student behavior. Data was collected through surveys in three Arab countries including Oman, Jordan and Yemen. 768 students from these Arab country's universities were participated in completing surveys randomly. Structure Equation Modeling SEM-PLS was adopted to analysis data. Results reveal that generative AI techniques and applications have positive and significant effects on students' cognitive achievement in Arab higher education institutions. Results also reveal that student behavior enhances the relationship among AI techniques, applications and cognitive achievement. These results highlight the crucial role of AI applications among students in higher education while the integration of this emerging technology is still at the first stage, students' interaction with and utility of these applications show high satisfactory level of their impact on students' behavior and cognitive achievement. This research contributes to literature of generative AI applications giving evidence from Arab region and filling the gap regarding usage of these applications in higher education.",['generative AI techniques'],"The research addresses the transformative potential of emerging technologies in higher education, focusing on how these innovations can enhance student engagement, personalization, and academic success. It highlights the importance of understanding the impact of such technologies on students' cognitive achievement and behavior within the context of Arab higher education institutions. The primary aim of the study is to investigate the effects of these technologies and their applications on students' cognitive achievement through the lens of student behavior. The research seeks to provide evidence from universities in Oman, Jordan, and Yemen to fill the gap in knowledge regarding the use and impact of these applications in higher education in the Arab region."
Social Sciences,Hallucination Rates and Reference Accuracy of ChatGPT and Bard for Systematic Reviews: Comparative Analysis,"Background Large language models (LLMs) have raised both interest and concern in the academic community. They offer the potential for automating literature search and synthesis for systematic reviews but raise concerns regarding their reliability, as the tendency to generate unsupported (hallucinated) content persist. Objective The aim of the study is to assess the performance of LLMs such as ChatGPT and Bard (subsequently rebranded Gemini) to produce references in the context of scientific writing. Methods The performance of ChatGPT and Bard in replicating the results of human-conducted systematic reviews was assessed. Using systematic reviews pertaining to shoulder rotator cuff pathology, these LLMs were tested by providing the same inclusion criteria and comparing the results with original systematic review references, serving as gold standards. The study used 3 key performance metrics: recall, precision, and F1-score, alongside the hallucination rate. Papers were considered “hallucinated” if any 2 of the following information were wrong: title, first author, or year of publication. Results In total, 11 systematic reviews across 4 fields yielded 33 prompts to LLMs (3 LLMs×11 reviews), with 471 references analyzed. Precision rates for GPT-3.5, GPT-4, and Bard were 9.4% (13/139), 13.4% (16/119), and 0% (0/104) respectively (P&lt;.001). Recall rates were 11.9% (13/109) for GPT-3.5 and 13.7% (15/109) for GPT-4, with Bard failing to retrieve any relevant papers (P&lt;.001). Hallucination rates stood at 39.6% (55/139) for GPT-3.5, 28.6% (34/119) for GPT-4, and 91.4% (95/104) for Bard (P&lt;.001). Further analysis of nonhallucinated papers retrieved by GPT models revealed significant differences in identifying various criteria, such as randomized studies, participant criteria, and intervention criteria. The study also noted the geographical and open-access biases in the papers retrieved by the LLMs. Conclusions Given their current performance, it is not recommended for LLMs to be deployed as the primary or exclusive tool for conducting systematic reviews. Any references generated by such models warrant thorough validation by researchers. The high occurrence of hallucinations in LLMs highlights the necessity for refining their training and functionality before confidently using them for rigorous academic purposes.","['GPT-3.5', 'GPT-4']","The research idea centers on the growing interest and concern within the academic community regarding the use of large language models for automating literature search and synthesis in systematic reviews, particularly focusing on their reliability due to the tendency to generate unsupported or inaccurate content. This issue raises questions about the trustworthiness of such tools in producing valid scientific references. The primary objective of the study is to assess the performance of large language models in generating references within the context of scientific writing, specifically evaluating their ability to replicate the results of human-conducted systematic reviews related to shoulder rotator cuff pathology. The study aims to determine the accuracy and reliability of these models in producing valid references and to highlight any biases or errors that may affect their use in academic research."
Social Sciences,The applications of nature‐inspired algorithms in Internet of Things‐based healthcare service: A systematic literature review,"Abstract Nature‐inspired algorithms revolve around the intersection of nature‐inspired algorithms and the IoT within the healthcare domain. This domain addresses the emerging trends and potential synergies between nature‐inspired computational approaches and IoT technologies for advancing healthcare services. Our research aims to fill gaps in addressing algorithmic integration challenges, real‐world implementation issues, and the efficacy of nature‐inspired algorithms in IoT‐based healthcare. We provide insights into the practical aspects and limitations of such applications through a systematic literature review. Specifically, we address the need for a comprehensive understanding of the applications of nature‐inspired algorithms in IoT‐based healthcare, identifying gaps such as the lack of standardized evaluation metrics and studies on integration challenges and security considerations. By bridging these gaps, our paper offers insights and directions for future research in this domain, exploring the diverse landscape of nature‐inspired algorithms in healthcare. Our chosen methodology is a Systematic Literature Review (SLR) to investigate related papers rigorously. Categorizing these algorithms into groups such as genetic algorithms, particle swarm optimization, cuckoo algorithms, ant colony optimization, other approaches, and hybrid methods, we employ meticulous classification based on critical criteria. MATLAB emerges as the predominant programming language, constituting 37.9% of cases, showcasing a prevalent choice among researchers. Our evaluation emphasizes adaptability as the paramount parameter, accounting for 18.4% of considerations. By shedding light on attributes, limitations, and potential directions for future research and development, this review aims to contribute to a comprehensive understanding of nature‐inspired algorithms in the dynamic landscape of IoT‐based healthcare services.","['genetic algorithms', 'cuckoo algorithms', 'hybrid methods']","The research idea centers on addressing the emerging trends and potential synergies within the healthcare domain, specifically focusing on the challenges related to integrating innovative approaches with healthcare services. There is a recognized need for a comprehensive understanding of the practical applications, limitations, and evaluation standards in this area, particularly concerning real-world implementation and security considerations. The study aims to fill existing gaps by exploring these issues to advance healthcare services effectively. The primary objective of the study is to provide insights into the practical aspects and limitations of these approaches in healthcare, identify gaps such as the lack of standardized evaluation metrics and integration challenges, and offer directions for future research to enhance the understanding and development of healthcare services in this evolving context."
Social Sciences,Unmasking bias in artificial intelligence: a systematic review of bias detection and mitigation strategies in electronic health record-based models,"Abstract Objectives Leveraging artificial intelligence (AI) in conjunction with electronic health records (EHRs) holds transformative potential to improve healthcare. However, addressing bias in AI, which risks worsening healthcare disparities, cannot be overlooked. This study reviews methods to handle various biases in AI models developed using EHR data. Materials and Methods We conducted a systematic review following the Preferred Reporting Items for Systematic Reviews and Meta-analyses guidelines, analyzing articles from PubMed, Web of Science, and IEEE published between January 01, 2010 and December 17, 2023. The review identified key biases, outlined strategies for detecting and mitigating bias throughout the AI model development, and analyzed metrics for bias assessment. Results Of the 450 articles retrieved, 20 met our criteria, revealing 6 major bias types: algorithmic, confounding, implicit, measurement, selection, and temporal. The AI models were primarily developed for predictive tasks, yet none have been deployed in real-world healthcare settings. Five studies concentrated on the detection of implicit and algorithmic biases employing fairness metrics like statistical parity, equal opportunity, and predictive equity. Fifteen studies proposed strategies for mitigating biases, especially targeting implicit and selection biases. These strategies, evaluated through both performance and fairness metrics, predominantly involved data collection and preprocessing techniques like resampling and reweighting. Discussion This review highlights evolving strategies to mitigate bias in EHR-based AI models, emphasizing the urgent need for both standardized and detailed reporting of the methodologies and systematic real-world testing and evaluation. Such measures are essential for gauging models’ practical impact and fostering ethical AI that ensures fairness and equity in healthcare.","['resampling', 'reweighting']","The research idea centers on the critical issue of bias in healthcare applications, which poses a risk of exacerbating existing disparities in healthcare delivery. The study recognizes the transformative potential of integrating advanced approaches with electronic health records to improve healthcare outcomes but emphasizes that addressing bias is essential to ensure fairness and equity. The primary objective of the study is to review and synthesize existing methods for identifying and mitigating various types of bias in healthcare-related developments using electronic health records. It aims to highlight strategies for bias detection and reduction, assess the effectiveness of these approaches, and underscore the need for standardized reporting and real-world evaluation to promote ethical and equitable healthcare practices."
Social Sciences,Artificial intelligence for literature reviews: opportunities and challenges,"Abstract This paper presents a comprehensive review of the use of Artificial Intelligence (AI) in Systematic Literature Reviews (SLRs). A SLR is a rigorous and organised methodology that assesses and integrates prior research on a given topic. Numerous tools have been developed to assist and partially automate the SLR process. The increasing role of AI in this field shows great potential in providing more effective support for researchers, moving towards the semi-automatic creation of literature reviews. Our study focuses on how AI techniques are applied in the semi-automation of SLRs, specifically in the screening and extraction phases. We examine 21 leading SLR tools using a framework that combines 23 traditional features with 11 AI features. We also analyse 11 recent tools that leverage large language models for searching the literature and assisting academic writing. Finally, the paper discusses current trends in the field, outlines key research challenges, and suggests directions for future research. We highlight three primary research challenges: integrating advanced AI solutions, such as large language models and knowledge graphs, improving usability, and developing a standardised evaluation framework. We also propose best practices to ensure more robust evaluations in terms of performance, usability, and transparency. Overall, this review offers a detailed overview of AI-enhanced SLR tools for researchers and practitioners, providing a foundation for the development of next-generation AI solutions in this field.",['knowledge graphs'],"The research idea centers on the growing importance and potential of enhancing the process of systematic literature reviews (SLRs), which are rigorous and organized methodologies for assessing and integrating prior research on a given topic. The study addresses the need for more effective support in conducting SLRs, particularly in the phases of screening and extraction, to improve the efficiency and quality of literature reviews. The research objective is to comprehensively review the current tools used to assist in the semi-automation of systematic literature reviews, focusing on their features and capabilities. Additionally, the study aims to identify key challenges in the field, such as improving usability and establishing standardized evaluation frameworks, while proposing best practices to enhance the robustness and transparency of future developments in this area."
Social Sciences,Larger and more instructable language models become less reliable,"Abstract The prevailing methods to make large language models more powerful and amenable have been based on continuous scaling up (that is, increasing their size, data volume and computational resources 1 ) and bespoke shaping up (including post-filtering 2,3 , fine tuning or use of human feedback 4,5 ). However, larger and more instructable large language models may have become less reliable. By studying the relationship between difficulty concordance, task avoidance and prompting stability of several language model families, here we show that easy instances for human participants are also easy for the models, but scaled-up, shaped-up models do not secure areas of low difficulty in which either the model does not err or human supervision can spot the errors. We also find that early models often avoid user questions but scaled-up, shaped-up models tend to give an apparently sensible yet wrong answer much more often, including errors on difficult questions that human supervisors frequently overlook. Moreover, we observe that stability to different natural phrasings of the same question is improved by scaling-up and shaping-up interventions, but pockets of variability persist across difficulty levels. These findings highlight the need for a fundamental shift in the design and development of general-purpose artificial intelligence, particularly in high-stakes areas for which a predictable distribution of errors is paramount.","['post-filtering', 'fine tuning', 'use of human feedback']","The research idea centers on the challenges associated with improving the reliability and accuracy of large language models, particularly as they become larger and more complex. The study addresses concerns that despite advancements, these models may still produce errors that are difficult for human supervisors to detect, especially on tasks of varying difficulty. It highlights the importance of understanding how task difficulty and response stability affect the performance and trustworthiness of these models in critical applications. The primary objective of the study is to investigate the relationship between task difficulty, error occurrence, and response consistency in different language model families, with the aim of identifying limitations in current approaches and emphasizing the need for a fundamental change in the development of general-purpose tools used in high-stakes contexts where predictable error patterns are crucial."
Social Sciences,Data extraction for evidence synthesis using a large language model: A proof‐of‐concept study,"Abstract Data extraction is a crucial, yet labor‐intensive and error‐prone part of evidence synthesis. To date, efforts to harness machine learning for enhancing efficiency of the data extraction process have fallen short of achieving sufficient accuracy and usability. With the release of large language models (LLMs), new possibilities have emerged to increase efficiency and accuracy of data extraction for evidence synthesis. The objective of this proof‐of‐concept study was to assess the performance of an LLM (Claude 2) in extracting data elements from published studies, compared with human data extraction as employed in systematic reviews. Our analysis utilized a convenience sample of 10 English‐language, open‐access publications of randomized controlled trials included in a single systematic review. We selected 16 distinct types of data, posing varying degrees of difficulty (160 data elements across 10 studies). We used the browser version of Claude 2 to upload the portable document format of each publication and then prompted the model for each data element. Across 160 data elements, Claude 2 demonstrated an overall accuracy of 96.3% with a high test–retest reliability (replication 1: 96.9%; replication 2: 95.0% accuracy). Overall, Claude 2 made 6 errors on 160 data items. The most common errors ( n = 4) were missed data items. Importantly, Claude 2's ease of use was high; it required no technical expertise or labeled training data for effective operation (i.e., zero‐shot learning). Based on findings of our proof‐of‐concept study, leveraging LLMs has the potential to substantially enhance the efficiency and accuracy of data extraction for evidence syntheses.",['zero-shot learning'],"The research addresses the challenge of data extraction in evidence synthesis, which is a critical but labor-intensive and error-prone process. Despite previous efforts to improve efficiency, achieving sufficient accuracy and usability in data extraction remains problematic. The study is motivated by the need to find more effective ways to enhance the accuracy and efficiency of extracting data from published studies for systematic reviews. The primary objective of the study was to assess the performance of a new approach in extracting data elements from published randomized controlled trials, comparing its accuracy and reliability to that of human data extraction methods commonly used in systematic reviews. The study aimed to evaluate whether this approach could improve the efficiency and accuracy of data extraction in evidence synthesis without requiring specialized expertise or training."
Social Sciences,Integrating artificial intelligence to assess emotions in learning environments: a systematic literature review,"Introduction Artificial Intelligence (AI) is transforming multiple sectors within our society, including education. In this context, emotions play a fundamental role in the teaching-learning process given that they influence academic performance, motivation, information retention, and student well-being. Thus, the integration of AI in emotional assessment within educational environments offers several advantages that can transform how we understand and address the socio-emotional development of students. However, there remains a lack of comprehensive approach that systematizes advancements, challenges, and opportunities in this field. Aim This systematic literature review aims to explore how artificial intelligence (AI) is used to evaluate emotions within educational settings. We provide a comprehensive overview of the current state of research, focusing on advancements, challenges, and opportunities in the domain of AI-driven emotional assessment within educational settings. Method The review involved a search across the following academic databases: Pubmed, Web of Science, PsycINFO and Scopus. Forty-one articles were selected that meet the established inclusion criteria. These articles were analyzed to extract key insights related to the integration of AI and emotional assessment within educational environments. Results The findings reveal a variety of AI-driven approaches that were developed to capture and analyze students’ emotional states during learning activities. The findings are summarized in four fundamental topics: (1) emotion recognition in education, (2) technology integration and learning outcomes, (3) special education and assistive technology, (4) affective computing. Among the key AI techniques employed are machine learning and facial recognition, which are used to assess emotions. These approaches demonstrate promising potential in enhancing pedagogical strategies and creating adaptive learning environments that cater to individual emotional needs. The review identified emerging factors that, while important, require further investigation to understand their relationships and implications fully. These elements could significantly enhance the use of AI in assessing emotions within educational settings. Specifically, we are referring to: (1) federated learning, (2) convolutional neural network (CNN), (3) recurrent neural network (RNN), (4) facial expression databases, and (5) ethics in the development of intelligent systems. Conclusion This systematic literature review showcases the significance of AI in revolutionizing educational practices through emotion assessment. While advancements are evident, challenges related to accuracy, privacy, and cross-cultural validity were also identified. The synthesis of existing research highlights the need for further research into refining AI models for emotion recognition and emphasizes the importance of ethical considerations in implementing AI technologies within educational contexts.","['machine learning', 'federated learning', 'convolutional neural network (CNN)', 'recurrent neural network (RNN)']","The study addresses the growing importance of emotions in the teaching-learning process, recognizing their influence on academic performance, motivation, information retention, and student well-being. It highlights the transformative potential of integrating emotional assessment within educational environments to better understand and support the socio-emotional development of students. However, there is a lack of a comprehensive approach that systematizes the advancements, challenges, and opportunities in this area. The primary aim of the study is to explore how emotions are evaluated within educational settings, providing a comprehensive overview of the current state of research with a focus on advancements, challenges, and opportunities related to emotional assessment in education. The study seeks to synthesize existing knowledge to inform future research and practice in enhancing pedagogical strategies that address students’ emotional needs."
Social Sciences,Artificial intelligence-driven virtual rehabilitation for people living in the community: A scoping review,"Abstract Virtual Rehabilitation (VRehab) is a promising approach to improving the physical and mental functioning of patients living in the community. The use of VRehab technology results in the generation of multi-modal datasets collected through various devices. This presents opportunities for the development of Artificial Intelligence (AI) techniques in VRehab, namely the measurement, detection, and prediction of various patients’ health outcomes. The objective of this scoping review was to explore the applications and effectiveness of incorporating AI into home-based VRehab programs. PubMed/MEDLINE, Embase, IEEE Xplore, Web of Science databases, and Google Scholar were searched from inception until June 2023 for studies that applied AI for the delivery of VRehab programs to the homes of adult patients. After screening 2172 unique titles and abstracts and 51 full-text studies, 13 studies were included in the review. A variety of AI algorithms were applied to analyze data collected from various sensors and make inferences about patients’ health outcomes, most involving evaluating patients’ exercise quality and providing feedback to patients. The AI algorithms used in the studies were mostly fuzzy rule-based methods, template matching, and deep neural networks. Despite the growing body of literature on the use of AI in VRehab, very few studies have examined its use in patients’ homes. Current research suggests that integrating AI with home-based VRehab can lead to improved rehabilitation outcomes for patients. However, further research is required to fully assess the effectiveness of various forms of AI-driven home-based VRehab, taking into account its unique challenges and using standardized metrics.","['fuzzy rule-based methods', 'deep neural networks']","The research idea centers on the potential of virtual rehabilitation (VRehab) to enhance the physical and mental functioning of patients living in the community, particularly through home-based programs. Despite the increasing interest in VRehab, there is limited understanding of its application and effectiveness when delivered in patients’ homes. The study aims to explore how incorporating advanced techniques into home-based VRehab programs can improve rehabilitation outcomes for adult patients. The primary objective of the study was to examine the applications and effectiveness of integrating such approaches into home-based virtual rehabilitation programs by reviewing existing research on their use with adult patients, with a focus on evaluating patient exercise quality and feedback mechanisms."
Social Sciences,Firefighter Skill Advancement through IoT-Enabled Virtual Reality and CNN-Based Training,"To maintain the safety and efficacy of firefighters in various circumstances, modern firefighting necessitates constantly improving skills and training techniques. Utilizing the Internet of Things (IoT), virtual reality (VR), and convolutional neural networks (CNN), this paper details a novel method for training firefighters. The proposed system collects real-time data on ambient variables, equipment state, and firefighter biometrics via integrating IoT sensors into firefighting equipment and training settings. Using this information, it can develop lifelike VR training simulations of difficult and potentially dangerous scenarios. To make the training settings more realistic and malleable, CNN-based algorithms are used to assess the data. The capacity to simulate a wide variety of firefighting situations, customize training difficulty depending on individual and team performance, and provide instant feedback and performance metrics to trainees are all major benefits of this method. The method also allows teachers to check in and evaluate their learners remotely, improving instruction quality. An IoT-enabled VR and CNN-based training technique has shown promising preliminary results in pilot trials, suggesting it might greatly enhance firefighter competence, situational awareness, and decision-making ability. Because of this, it has the potential to completely alter the way firefighters are informed and prepared for the ever-changing dangers users may encounter on the job.",['convolutional neural networks (CNN)'],"The research idea centers on the need to continuously improve the skills and training techniques of firefighters to ensure their safety and effectiveness in various challenging circumstances. Given the complex and hazardous nature of firefighting, there is a motivation to develop more realistic and adaptable training environments that can better prepare firefighters for diverse and dangerous scenarios. The study aims to enhance firefighter competence, situational awareness, and decision-making ability by providing innovative training approaches that reflect the dynamic risks encountered on the job. The primary objective of the study is to develop a novel training method that can simulate a wide range of firefighting situations, customize training difficulty based on individual and team performance, and offer immediate feedback and performance evaluation to trainees. Additionally, the study seeks to improve the quality of instruction by enabling instructors to monitor and assess learners remotely, ultimately transforming how firefighters are educated and prepared for their roles."
Social Sciences,Adaptive Segmentation Enhanced Asynchronous Federated Learning for Sustainable Intelligent Transportation Systems,"The proliferation of advanced embedded and communication technologies has facilitated the possibility of modern Intelligent Transportation System (ITS). The hierarchical nature of such large-scale and distributed systems brings obvious challenges in creating a scalable and sustainable computing environment, and hence the development and application of edge intelligence become critical. Federated learning (FL), as an emerging distributed machine learning paradigm, aims to offer secure knowledge sharing and effective learning across multiple devices. However, conventional FL may fall into trouble when facing large-scale and network-agnostic systems with fast moving devices and changing network attributes. In this study, we propose an Adaptive Segmentation enhanced Asynchronous Federated Learning (AS-AFL) model, aiming to improve the learning efficiency and reliability in sustainable ITS via a decentralized fashion. Specifically, a meta-learning based adaptive segmentation scheme is designed to automatically separate the client nodes (e.g., vehicles) into multiple edge groups according to their homogeneous attributes. An integrated aggregation mechanism is then developed to realize the horizontal FL among a group of similar client nodes via the so-called intra-group synchronous aggregation, while allowing the vertical FL across different groups via the so-called inter-group asynchronous aggregation. Experiment and evaluation results based on an open-source dataset demonstrate the outstanding learning and communication performance of our proposed model, compared with several conventional FL schemes in a distributed ITS application scenario.","['Federated learning (FL)', 'meta-learning based adaptive segmentation']","The research idea addresses the challenges posed by the hierarchical and large-scale nature of modern Intelligent Transportation Systems (ITS), which complicate the creation of scalable and sustainable environments for effective operation. The study recognizes the difficulties in managing secure knowledge sharing and learning across multiple devices within such distributed systems, especially when dealing with fast-moving entities and changing network conditions. The primary objective of the study is to improve the efficiency and reliability of learning processes in sustainable ITS by developing a decentralized approach that organizes client nodes into groups based on shared characteristics. This approach aims to enhance collaboration within and across these groups to better support the dynamic and distributed nature of ITS environments."
Social Sciences,CFSSynergy: Combining Feature-Based and Similarity-Based Methods for Drug Synergy Prediction,"Drug synergy prediction plays a vital role in cancer treatment. Because experimental approaches are labor-intensive and expensive, computational-based approaches get more attention. There are two types of computational methods for drug synergy prediction: feature-based and similarity-based. In feature-based methods, the main focus is to extract more discriminative features from drug pairs and cell lines to pass to the task predictor. In similarity-based methods, the similarities among all drugs and cell lines are utilized as features and fed into the task predictor. In this work, a novel approach, called CFSSynergy, that combines these two viewpoints is proposed. First, a discriminative representation is extracted for paired drugs and cell lines as input. We have utilized transformer-based architecture for drugs. For cell lines, we have created a similarity matrix between proteins using the Node2Vec algorithm. Then, the new cell line representation is computed by multiplying the protein–protein similarity matrix and the initial cell line representation. Next, we compute the similarity between unique drugs and unique cells using the learned representation for paired drugs and cell lines. Then, we compute a new representation for paired drugs and cell lines based on the similarity-based features and the learned features. Finally, these features are fed to XGBoost as a task predictor. Two well-known data sets were used to evaluate the performance of our proposed method: DrugCombDB and OncologyScreen. The CFSSynergy approach consistently outperformed existing methods in comparative evaluations. This substantiates the efficacy of our approach in capturing complex synergistic interactions between drugs and cell lines, setting it apart from conventional similarity-based or feature-based methods.","['transformer-based architecture', 'Node2Vec algorithm', 'XGBoost']","The research idea centers on addressing the challenge of predicting drug synergy in cancer treatment, which is crucial due to the labor-intensive and costly nature of experimental approaches. The study highlights the need for more effective methods to understand how different drugs interact synergistically to improve therapeutic outcomes. The primary objective of the study is to develop a novel approach that integrates multiple perspectives to better capture the complex interactions between drug pairs and cancer cell lines. This approach aims to enhance the prediction of drug synergy, thereby contributing to more efficient and effective cancer treatment strategies."
Social Sciences,GPT-4 Turbo with Vision fails to outperform text-only GPT-4 Turbo in the Japan Diagnostic Radiology Board Examination,"Abstract Purpose To assess the performance of GPT-4 Turbo with Vision (GPT-4TV), OpenAI’s latest multimodal large language model, by comparing its ability to process both text and image inputs with that of the text-only GPT-4 Turbo (GPT-4 T) in the context of the Japan Diagnostic Radiology Board Examination (JDRBE). Materials and methods The dataset comprised questions from JDRBE 2021 and 2023. A total of six board-certified diagnostic radiologists discussed the questions and provided ground-truth answers by consulting relevant literature as necessary. The following questions were excluded: those lacking associated images, those with no unanimous agreement on answers, and those including images rejected by the OpenAI application programming interface. The inputs for GPT-4TV included both text and images, whereas those for GPT-4 T were entirely text. Both models were deployed on the dataset, and their performance was compared using McNemar’s exact test. The radiological credibility of the responses was assessed by two diagnostic radiologists through the assignment of legitimacy scores on a five-point Likert scale. These scores were subsequently used to compare model performance using Wilcoxon's signed-rank test. Results The dataset comprised 139 questions. GPT-4TV correctly answered 62 questions (45%), whereas GPT-4 T correctly answered 57 questions (41%). A statistical analysis found no significant performance difference between the two models (P = 0.44). The GPT-4TV responses received significantly lower legitimacy scores from both radiologists than the GPT-4 T responses. Conclusion No significant enhancement in accuracy was observed when using GPT-4TV with image input compared with that of using text-only GPT-4 T for JDRBE questions.",['GPT-4 Turbo (GPT-4 T)'],"The research idea centers on evaluating the effectiveness of incorporating both text and image inputs in addressing complex diagnostic radiology examination questions, specifically within the context of the Japan Diagnostic Radiology Board Examination. The study addresses the problem of whether multimodal input enhances the accuracy and credibility of responses compared to text-only input. The primary objective of the study is to assess and compare the performance of two approaches—one utilizing both text and images and the other using text alone—in correctly answering questions from the Japan Diagnostic Radiology Board Examination. Additionally, the study aims to evaluate the radiological credibility of the responses provided by each approach as judged by board-certified diagnostic radiologists."
Social Sciences,A voting gray wolf optimizer-based ensemble learning models for intrusion detection in the Internet of Things,"Abstract The Internet of Things (IoT) has garnered considerable attention from academic and industrial circles as a pivotal technology in recent years. The escalation of security risks is observed to be associated with the growing interest in IoT applications. Intrusion detection systems (IDS) have been devised as viable instruments for identifying and averting malicious actions in this context. Several techniques described in academic papers are thought to be very accurate, but they cannot be used in the real world because the datasets used to build and test the models do not accurately reflect and simulate the IoT network. Existing methods, on the other hand, deal with these issues, but they are not good enough for commercial use because of their lack of precision, low detection rate, receiver operating characteristic (ROC), and false acceptance rate (FAR). The effectiveness of these solutions is predominantly dependent on individual learners and is consequently influenced by the inherent limitations of each learning algorithm. This study introduces a new approach for detecting intrusion attacks in an IoT network, which involves the use of an ensemble learning technique based on gray wolf optimizer (GWO). The novelty of this study lies in the proposed voting gray wolf optimizer (GWO) ensemble model, which incorporates two crucial components: a traffic analyzer and a classification phase engine. The model employs a voting technique to combine the probability averages of the base learners. Secondly, the combination of feature selection and feature extraction techniques is to reduce dimensionality. Thirdly, the utilization of GWO is employed to optimize the parameters of ensemble models. Similarly, the approach employs the most authentic intrusion detection datasets that are accessible and amalgamates multiple learners to generate ensemble learners. The hybridization of information gain (IG) and principal component analysis (PCA) was employed to reduce dimensionality. The study utilized a novel GWO ensemble learning approach that incorporated a decision tree, random forest, K-nearest neighbor, and multilayer perceptron for classification. To evaluate the efficacy of the proposed model, two authentic datasets, namely, BoT-IoT and UNSW-NB15, were scrutinized. The GWO-optimized ensemble model demonstrates superior accuracy when compared to other machine learning-based and deep learning models. Specifically, the model achieves an accuracy rate of 99.98%, a DR of 99.97%, a precision rate of 99.94%, an ROC rate of 99.99%, and an FAR rate of 1.30 on the BoT-IoT dataset. According to the experimental results, the proposed ensemble model optimized by GWO achieved an accuracy of 100%, a DR of 99.9%, a precision of 99.59%, an ROC of 99.40%, and an FAR of 1.5 when tested on the UNSW-NB15 dataset.","['ensemble learning technique', 'gray wolf optimizer (GWO)', 'voting technique', 'feature selection', 'information gain (IG)', 'principal component analysis (PCA)', 'decision tree', 'random forest', 'K-nearest neighbor', 'multilayer perceptron']","The research idea centers on the increasing security risks associated with the growing use of Internet of Things (IoT) applications, highlighting the challenge of effectively identifying and preventing malicious actions within IoT networks. Existing solutions for intrusion detection are limited in their practical applicability due to issues such as lack of precision, low detection rates, and high false acceptance rates, which hinder their commercial viability. The study is motivated by the need to develop more reliable and accurate methods to address these security concerns in real-world IoT environments. The primary objective of the study is to introduce and evaluate a novel approach for detecting intrusion attacks in IoT networks that improves accuracy and detection performance by combining multiple components, including traffic analysis and classification phases. The study aims to enhance the effectiveness of intrusion detection by optimizing the integration of various techniques and validating the approach using authentic datasets to demonstrate superior performance compared to existing methods."
Social Sciences,Artificial intelligence and multimodal data fusion for smart healthcare: topic modeling and bibliometrics,"Abstract Advancements in artificial intelligence (AI) have driven extensive research into developing diverse multimodal data analysis approaches for smart healthcare. There is a scarcity of large-scale analysis of literature in this field based on quantitative approaches. This study performed a bibliometric and topic modeling examination on 683 articles from 2002 to 2022, focusing on research topics and trends, journals, countries/regions, institutions, authors, and scientific collaborations. Results showed that, firstly, the number of articles has grown from 1 in 2002 to 220 in 2022, with a majority being published in interdisciplinary journals that link healthcare and medical research and information technology and AI. Secondly, the significant rise in the quantity of research articles can be attributed to the increasing contribution of scholars from non-English speaking countries/regions and the noteworthy contributions made by authors in the USA and India. Thirdly, researchers show a high interest in diverse research issues, especially, cross-modality magnetic resonance imaging (MRI) for brain tumor analysis, cancer prognosis through multi-dimensional data analysis, and AI-assisted diagnostics and personalization in healthcare, with each topic experiencing a significant increase in research interest. There is an emerging trend towards issues such as applying generative adversarial networks and contrastive learning for multimodal medical image fusion and synthesis and utilizing the combined spatiotemporal resolution of functional MRI and electroencephalogram in a data-centric manner. This study is valuable in enhancing researchers’ and practitioners’ understanding of the present focal points and upcoming trajectories in AI-powered smart healthcare based on multimodal data analysis.","['generative adversarial networks', 'contrastive learning']","The research addresses the growing body of literature on multimodal data analysis in smart healthcare, highlighting a lack of large-scale quantitative examination of research trends, topics, and collaborations within this field. It focuses on understanding how scholarly contributions have evolved over time, particularly noting the increasing involvement of researchers from diverse countries and the prominence of interdisciplinary journals linking healthcare with other domains. The study aims to provide a comprehensive overview of the development and current focal points in research related to multimodal approaches in healthcare. Its primary objective is to analyze the literature from 2002 to 2022 to identify key research topics, trends, geographic and institutional contributions, and patterns of scientific collaboration, thereby enhancing the understanding of present and emerging directions in smart healthcare research."
Social Sciences,Developing a Multi-Criteria Decision-Making model for nuclear power plant location selection using Fuzzy Analytic Hierarchy Process and Fuzzy VIKOR methods focused on socio-economic factors,"In response to its position as the fourth most populous country globally, Indonesia is exploring constructing nuclear power plants (NPPs) as a sustainable energy solution. A pivotal step in this initiative is selecting an appropriate NPP site. This study employs two Multi-Criteria Decision-Making (MCDM) methods, the Fuzzy Analytic Hierarchy Process (Fuzzy-AHP) and Fuzzy VIKOR, to identify the most suitable location for an NPP, focusing on socio-economic factors. The Fuzzy-AHP method is utilized to prioritize ten sub-criteria: transmission network, operating costs, economic impact, security, transportation network, legal considerations, the impact of tourism, land ownership, historical sites, and public acceptance. Following this, the Fuzzy VIKOR method leverages these prioritized criteria to evaluate two potential sites: East Kalimantan and West Kalimantan. The analysis reveals that security, transmission, and transportation networks emerge as the top priorities. The application of the Fuzzy VIKOR algorithm identifies West Kalimantan as the optimal site for NPP construction, evidenced by its lower VIKOR index of 0.3599, indicating a higher overall preference based on the evaluated criteria. The study demonstrates that the integration of Fuzzy-AHP and Fuzzy VIKOR methods prioritizes critical socio-economic factors and quantitatively assesses potential sites, offering a systematic and objective approach to support decision-making in NPP site selection.",['Fuzzy VIKOR'],"The research idea centers on Indonesia’s need to identify a suitable location for constructing nuclear power plants as part of its strategy to develop sustainable energy solutions, given its status as the fourth most populous country globally. A critical challenge in this initiative is selecting an appropriate site that accounts for various socio-economic factors impacting the feasibility and acceptance of nuclear power plants. The study aims to prioritize these socio-economic criteria to support informed decision-making in site selection. The primary objective of the study is to determine the most suitable location for a nuclear power plant in Indonesia by evaluating and prioritizing key socio-economic factors such as security, transmission and transportation networks, economic impact, legal considerations, and public acceptance. Specifically, the study seeks to compare potential sites in East Kalimantan and West Kalimantan to identify the optimal site based on these prioritized criteria."
Social Sciences,"Foundation models in robotics: Applications, challenges, and the future","We survey applications of pretrained foundation models in robotics. Traditional deep learning models in robotics are trained on small datasets tailored for specific tasks, which limits their adaptability across diverse applications. In contrast, foundation models pretrained on internet-scale data appear to have superior generalization capabilities, and in some instances display an emergent ability to find zero-shot solutions to problems that are not present in the training data. Foundation models may hold the potential to enhance various components of the robot autonomy stack, from perception to decision-making and control. For example, large language models can generate code or provide common sense reasoning, while vision-language models enable open-vocabulary visual recognition. However, significant open research challenges remain, particularly around the scarcity of robot-relevant training data, safety guarantees and uncertainty quantification, and real-time execution. In this survey, we study recent papers that have used or built foundation models to solve robotics problems. We explore how foundation models contribute to improving robot capabilities in the domains of perception, decision-making, and control. We discuss the challenges hindering the adoption of foundation models in robot autonomy and provide opportunities and potential pathways for future advancements. The GitHub project corresponding to this paper can be found here: https://github.com/robotics-survey/Awesome-Robotics-Foundation-Models .","['pretrained foundation models', 'vision-language models']","The research idea centers on addressing the limitations of traditional approaches in robotics, which are typically trained on small, task-specific datasets that restrict their adaptability across diverse applications. There is a growing interest in exploring new methods that demonstrate superior generalization capabilities and the potential to solve problems beyond their initial training scope. The study recognizes significant challenges in the field, including the scarcity of relevant training data, safety concerns, and the need for reliable real-time performance. The research objective is to examine recent developments that enhance robotic capabilities in perception, decision-making, and control by leveraging advanced approaches with broader applicability. The study aims to identify the contributions of these approaches to improving robot autonomy, discuss the obstacles to their widespread adoption, and suggest opportunities and pathways for future progress in robotics."
Social Sciences,UANet: An Uncertainty-Aware Network for Building Extraction From Remote Sensing Images,"Building extraction aims to segment building pixels from remote sensing images and plays an essential role in many applications, such as city planning and urban dynamic monitoring. Over the past few years, deep learning methods with encoder–decoder architectures have achieved remarkable performance due to their powerful feature representation capability. Nevertheless, due to the varying scales and styles of buildings, conventional deep learning models always suffer from uncertain predictions and cannot accurately distinguish the complete footprints of the building from the complex distribution of ground objects, leading to a large degree of omission and commission. In this paper, we realize the importance of uncertain prediction and propose a novel and straightforward Uncertainty-Aware Network (UANet) to alleviate this problem. Specifically, we first apply a general encoder–decoder network to obtain a building extraction map with relatively high uncertainty. Second, in order to aggregate the useful information in the highest-level features, we design a Prior Information Guide Module to guide the highest-level features in learning the prior information from the conventional extraction map. Third, based on the uncertain extraction map, we introduce an Uncertainty Rank Algorithm to measure the uncertainty level of each pixel belonging to the foreground and the background. We further combine this algorithm with the proposed Uncertainty-Aware Fusion Module to facilitate level-by-level feature refinement and obtain the final refined extraction map with low uncertainty. To verify the performance of our proposed UANet, we conduct extensive experiments on three public building datasets, including the WHU building dataset, the Massachusetts building dataset, and the Inria aerial image dataset. Results demonstrate that the proposed UANet outperforms other state-of-the-art algorithms by a large margin. The source code of the proposed UANet is available at https://github.com/Henryjiepanli/Uncertainty-aware-Network.","['deep learning methods with encoder–decoder architectures', 'encoder–decoder network']","The research addresses the challenge of accurately identifying building footprints from remote sensing images, which is crucial for applications such as city planning and monitoring urban dynamics. The study highlights the difficulty in distinguishing buildings from complex ground objects due to variations in building scales and styles, leading to uncertain and incomplete predictions. The primary objective of the study is to improve the precision of building extraction by reducing uncertainty in the identification process, thereby enabling more accurate segmentation of building areas in remote sensing imagery. This aims to enhance the reliability of building data used for urban planning and related social science applications."
Social Sciences,One-Step Multi-View Clustering With Diverse Representation,"Multi-View clustering has attracted broad attention due to its capacity to utilize consistent and complementary information among views. Although tremendous progress has been made recently, most existing methods undergo high complexity, preventing them from being applied to large-scale tasks. Multi-View clustering via matrix factorization is a representative to address this issue. However, most of them map the data matrices into a fixed dimension, limiting the model's expressiveness. Moreover, a range of methods suffers from a two-step process, i.e., multimodal learning and the subsequent <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> <tex-math notation=""LaTeX"">$k$</tex-math> </inline-formula> -means, inevitably causing a suboptimal clustering result. In light of this, we propose a one-step multi-view clustering with diverse representation (OMVCDR) method, which incorporates multi-view learning and <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> <tex-math notation=""LaTeX"">$k$</tex-math> </inline-formula> -means into a unified framework. Specifically, we first project original data matrices into various latent spaces to attain comprehensive information and auto-weight them in a self-supervised manner. Then, we directly use the information matrices under diverse dimensions to obtain consensus discrete clustering labels. The unified work of representation learning and clustering boosts the quality of the final results. Furthermore, we develop an efficient optimization algorithm with proven convergence to solve the resultant problem. Comprehensive experiments on various datasets demonstrate the promising clustering performance of our proposed method. The code is publicly available at https://github.com/wanxinhang/OMVCDR.","['Multi-View clustering via matrix factorization', 'k-means', 'multi-view learning', 'representation learning']","The research idea centers on addressing the limitations of existing multi-view clustering approaches, which often face challenges such as high complexity and restricted expressiveness due to fixed-dimensional data representation. Additionally, many current methods rely on a two-step process that can lead to suboptimal clustering outcomes. The study is motivated by the need to improve the integration of information from multiple views to enhance clustering quality. The primary objective of the study is to develop a unified approach that simultaneously incorporates multi-view learning and clustering to achieve more comprehensive and accurate clustering results. This approach aims to utilize diverse representations of data to better capture information and improve the consensus on clustering labels, ultimately enhancing the effectiveness of multi-view clustering tasks."
Social Sciences,Artificial Intelligence in Point-of-Care Biosensing: Challenges and Opportunities,"The integration of artificial intelligence (AI) into point-of-care (POC) biosensing has the potential to revolutionize diagnostic methodologies by offering rapid, accurate, and accessible health assessment directly at the patient level. This review paper explores the transformative impact of AI technologies on POC biosensing, emphasizing recent computational advancements, ongoing challenges, and future prospects in the field. We provide an overview of core biosensing technologies and their use at the POC, highlighting ongoing issues and challenges that may be solved with AI. We follow with an overview of AI methodologies that can be applied to biosensing, including machine learning algorithms, neural networks, and data processing frameworks that facilitate real-time analytical decision-making. We explore the applications of AI at each stage of the biosensor development process, highlighting the diverse opportunities beyond simple data analysis procedures. We include a thorough analysis of outstanding challenges in the field of AI-assisted biosensing, focusing on the technical and ethical challenges regarding the widespread adoption of these technologies, such as data security, algorithmic bias, and regulatory compliance. Through this review, we aim to emphasize the role of AI in advancing POC biosensing and inform researchers, clinicians, and policymakers about the potential of these technologies in reshaping global healthcare landscapes.",['neural networks'],"The study addresses the transformative potential of integrating advanced technologies into point-of-care biosensing to improve diagnostic methodologies by enabling rapid, accurate, and accessible health assessments directly at the patient level. It highlights ongoing challenges and ethical concerns related to the widespread adoption of these innovations, such as data security, bias, and regulatory compliance, which impact the effectiveness and acceptance of point-of-care diagnostics. The primary aim of the study is to provide a comprehensive overview of current biosensing technologies used at the point of care, identify existing issues and challenges, and discuss future prospects that could enhance healthcare delivery. Additionally, the study seeks to inform researchers, clinicians, and policymakers about the opportunities and obstacles in advancing point-of-care biosensing to reshape global healthcare landscapes."
Social Sciences,Evaluating the persuasive influence of political microtargeting with large language models,"Recent advancements in large language models (LLMs) have raised the prospect of scalable, automated, and fine-grained political microtargeting on a scale previously unseen; however, the persuasive influence of microtargeting with LLMs remains unclear. Here, we build a custom web application capable of integrating self-reported demographic and political data into GPT-4 prompts in real-time, facilitating the live creation of unique messages tailored to persuade individual users on four political issues. We then deploy this application in a preregistered randomized control experiment ( n = 8,587) to investigate the extent to which access to individual-level data increases the persuasive influence of GPT-4. Our approach yields two key findings. First, messages generated by GPT-4 were broadly persuasive, in some cases increasing support for an issue stance by up to 12 percentage points. Second, in aggregate, the persuasive impact of microtargeted messages was not statistically different from that of non-microtargeted messages (4.83 vs. 6.20 percentage points, respectively, P = 0.226). These trends hold even when manipulating the type and number of attributes used to tailor the message. These findings suggest—contrary to widespread speculation—that the influence of current LLMs may reside not in their ability to tailor messages to individuals but rather in the persuasiveness of their generic, nontargeted messages. We release our experimental dataset, GPTarget2024 , as an empirical baseline for future research.",['GPT-4'],"The research idea centers on understanding the persuasive influence of political microtargeting at an individual level, a practice that has gained attention due to recent technological advancements enabling highly personalized messaging. Despite the potential for finely tailored political communication, it remains unclear whether such microtargeting actually enhances persuasive impact compared to more generic messaging. The study aims to investigate whether access to individual-level demographic and political information increases the effectiveness of persuasive messages on political issues. Specifically, the primary objective is to assess the extent to which personalized political messages influence individuals’ support for issue stances, and to compare the persuasive impact of microtargeted messages with that of non-microtargeted messages in a large-scale experimental setting."
Social Sciences,Crafting personalized learning paths with AI for lifelong learning: a systematic literature review,"The rapid evolution of knowledge requires constantly acquiring and updating skills, making lifelong learning crucial. Despite decades of artificial intelligence, recent advances promote new solutions to personalize learning in this context. The purpose of this article is to explore the current state of research on the development of artificial intelligence-mediated solutions for the design of personalized learning paths. To achieve this, a systematic literature review (SRL) of 78 articles published between 2019 and 2024 from the Scopus and Web or Science databases was conducted, answering seven questions grouped into three themes: characteristics of the published research, context of the research, and type of solution analyzed. This study identified that: (a) the greatest production of scientific research on the topic is developed in China, India and the United States, (b) the focus is mainly directed towards the educational context at the higher education level with areas of opportunity for application in the work context, and (c) the development of adaptive learning technologies predominates; however, there is a growing interest in the application of generative language models. This article contributes to the growing interest and literature related to personalized learning under artificial intelligence mediated solutions that will serve as a basis for academic institutions and organizations to design programs under this model.",['generative language models'],"The rapid evolution of knowledge necessitates continuous skill acquisition and updating, making lifelong learning increasingly important. This study addresses the growing need to understand how personalized learning paths can be designed to support lifelong learning effectively. The primary objective of this study is to explore the current state of research on the development of personalized learning paths, focusing on the characteristics, context, and types of solutions analyzed in recent literature. By reviewing existing research, the study aims to provide a foundation for academic institutions and organizations to design programs that support personalized learning approaches."
Social Sciences,Utilisation of Deep Learning (DL) and Neural Networks (NN) Algorithms for Energy Power Generation: A Social Network and Bibliometric Analysis (2004-2022),"The research landscape on the applications of advanced computational tools (ACTs) such as machine/deep learning and neural network algorithms for energy and power generation (EPG) was critically examined through publication trends and bibliometrics data analysis. The Elsevier Scopus database and the PRISMA methodology were employed to identify and screen the published documents, whereas the bibliometric analysis software VOSviewer was used to analyse the co-authorships, citations, and keyword occurrences. The results showed that 152 documents have been published on the topic comprising conference proceedings (58.6%) and articles (41.4%) between 2004 and 2022. Publication trends analysis revealed the number of publications increased from 1 to 31 or by 3,000% over the same period, which was ascribed to the growing scientific interest and research impact of the topic. Stakeholder analysis revealed the top authors/researchers are Anvari M, Ghaderi SF and Saberi M, whereas the most prolific affiliation and nations actively engaged in the topic are the North China Electric Power University, and China, respectively. Conversely, the top funding agency actively backing research on the topic is the National Natural Science Foundation of China (NSFC). Co-authorship analysis revealed high levels of collaboration between researching nations compared to authors and affiliations. Hotspot analysis revealed three major thematic focus areas namely; Energy Grid Forecasting, Power Generation Control, and Intelligent Energy Optimization. In conclusion, the study showed that the application of ACTs in EPG is an active, multidisciplinary, and impact area of research with potential for more impactful contributions to research and society at large.","['machine learning', 'deep learning', 'neural network algorithms']","The research idea centers on understanding the growing scientific interest and impact of advanced computational tools in the field of energy and power generation, as evidenced by increasing publication trends and collaborative efforts among researchers and institutions. The study addresses the need to critically examine the development and dissemination of knowledge within this multidisciplinary area, highlighting key contributors, thematic focus areas, and funding sources. The primary objective of the study is to systematically review and characterize the research landscape on the applications of these tools in energy and power generation by analyzing publication trends, authorship collaborations, and thematic priorities. This aims to provide insights into the current state of research and identify areas with potential for further contributions to both academia and society."
Social Sciences,Potential of Large Language Models in Health Care: Delphi Study,"Background A large language model (LLM) is a machine learning model inferred from text data that captures subtle patterns of language use in context. Modern LLMs are based on neural network architectures that incorporate transformer methods. They allow the model to relate words together through attention to multiple words in a text sequence. LLMs have been shown to be highly effective for a range of tasks in natural language processing (NLP), including classification and information extraction tasks and generative applications. Objective The aim of this adapted Delphi study was to collect researchers’ opinions on how LLMs might influence health care and on the strengths, weaknesses, opportunities, and threats of LLM use in health care. Methods We invited researchers in the fields of health informatics, nursing informatics, and medical NLP to share their opinions on LLM use in health care. We started the first round with open questions based on our strengths, weaknesses, opportunities, and threats framework. In the second and third round, the participants scored these items. Results The first, second, and third rounds had 28, 23, and 21 participants, respectively. Almost all participants (26/28, 93% in round 1 and 20/21, 95% in round 3) were affiliated with academic institutions. Agreement was reached on 103 items related to use cases, benefits, risks, reliability, adoption aspects, and the future of LLMs in health care. Participants offered several use cases, including supporting clinical tasks, documentation tasks, and medical research and education, and agreed that LLM-based systems will act as health assistants for patient education. The agreed-upon benefits included increased efficiency in data handling and extraction, improved automation of processes, improved quality of health care services and overall health outcomes, provision of personalized care, accelerated diagnosis and treatment processes, and improved interaction between patients and health care professionals. In total, 5 risks to health care in general were identified: cybersecurity breaches, the potential for patient misinformation, ethical concerns, the likelihood of biased decision-making, and the risk associated with inaccurate communication. Overconfidence in LLM-based systems was recognized as a risk to the medical profession. The 6 agreed-upon privacy risks included the use of unregulated cloud services that compromise data security, exposure of sensitive patient data, breaches of confidentiality, fraudulent use of information, vulnerabilities in data storage and communication, and inappropriate access or use of patient data. Conclusions Future research related to LLMs should not only focus on testing their possibilities for NLP-related tasks but also consider the workflows the models could contribute to and the requirements regarding quality, integration, and regulations needed for successful implementation in practice.","['large language model (LLM)', 'transformer methods']","The research idea centers on understanding how large language models might influence health care by exploring their potential benefits, risks, and overall impact on clinical and administrative tasks. The study addresses the need to gather expert opinions on the strengths, weaknesses, opportunities, and threats associated with the use of these models in health care settings. The primary objective of the study was to collect researchers’ perspectives on the influence of large language models in health care, focusing on identifying use cases, benefits, risks, reliability, adoption factors, and future implications. This was aimed at informing considerations for quality, integration, and regulatory requirements necessary for their successful implementation in health care practice."
Social Sciences,Unveiling the dynamics of AI applications: A review of reviews using scientometrics and BERTopic modeling,"In a world that has rapidly transformed through the advent of artificial intelligence (AI), our systematic review, guided by the PRISMA protocol, investigates a decade of AI research, revealing insights into its evolution and impact. Our study, examining 3,767 articles, has drawn considerable attention, as evidenced by an impressive 63,577 citations, underscoring the scholarly community's profound engagement. Our study reveals a collaborative landscape with 18,189 contributing authors, reflecting a robust network of researchers advancing AI and machine learning applications. Review categories focus on systematic reviews and bibliometric analyses, indicating an increasing emphasis on comprehensive literature synthesis and quantitative analysis. The findings also suggest an opportunity to explore emerging methodologies such as topic modeling and meta-analysis. We dissect the state of the art presented in these reviews, finding themes throughout the broad scholarly discourse through thematic clustering and BERTopic modeling. Categorization of study articles across fields of research indicates dominance in Information and Computing Sciences, followed by Biomedical and Clinical Sciences. Subject categories reveal interconnected clusters across various sectors, notably in healthcare, engineering, business intelligence, and computational technologies. Semantic analysis via BERTopic revealed nineteen clusters mapped to themes such as AI in health innovations, AI for sustainable development, AI and deep learning, AI in education, and ethical considerations. Future research directions are suggested, emphasizing the need for intersectional bias mitigation, holistic health approaches, AI's role in environmental sustainability, and the ethical deployment of generative AI.","['topic modeling', 'BERTopic modeling']","The research idea centers on understanding the evolution and impact of a rapidly transforming technological field over the past decade, highlighting the extensive scholarly engagement and collaborative efforts within this area. The study addresses the need to synthesize a vast body of literature to reveal thematic trends and the interdisciplinary nature of research across various sectors such as healthcare, business, and sustainability. The primary objective of the study is to systematically review and categorize a large collection of scholarly articles to uncover dominant themes, research clusters, and emerging areas of interest within the field. Additionally, the study aims to identify future research directions that emphasize ethical considerations, bias mitigation, holistic health approaches, and contributions to environmental sustainability."
Social Sciences,"Advancing the Sustainable Development Goals (SDGs) through artificial intelligence, machine learning, and deep learning","The use of Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) significantly has the touch of transformational potential towards bringing the Sustainable Development Goals (SDGs) to be addressed in various industries. This research investigates the new developments and applications of these technologies in advancing sustainability programs in industry-intensive domains. Industries are beginning to undergo a major change by making today with the help of AI, ML, and DL that resources can be optimized, energy efficiency can be improved, and environmental impacts can be mitigated. A number of other trends - including predictive analytics and intelligent automation, allow for smarter and more efficient production, waste minimization and circular economy practices. AI-powered solutions are also now being used in the energy sector to maximize the generation of renewable energy, optimize grid management, and aid in the transition to low carbon energy systems. This will enable industries achieve better environmental benefits and higher operational efficiencies through big data analytics and IoT. AI and ML are also crucial in smart cities, urban planning, public services that delivery efficiency and overall support the sustainability agenda. The results reinforce the importance of strong regulatory structures and interdisciplinary collaboration to optimally leverage AI, ML, and DL to the SDGs, which will be intrinsic to designing for resilience and sustainability.","['Machine Learning (ML)', 'Deep Learning (DL)']","The research idea centers on the transformational potential of emerging technologies to advance the achievement of Sustainable Development Goals (SDGs) across various industry sectors. It addresses the growing need for industries to optimize resources, improve energy efficiency, and reduce environmental impacts while supporting sustainability programs. The study highlights the broader trends that enable smarter production, waste minimization, circular economy practices, and the transition to low carbon energy systems, emphasizing the importance of sustainability in industrial and urban contexts. The research objective is to investigate the recent developments and applications of these technologies in promoting sustainability initiatives within industry-intensive domains. It aims to demonstrate how these advancements contribute to better environmental outcomes, higher operational efficiencies, and support for sustainability agendas in sectors such as energy, urban planning, and public services. Additionally, the study seeks to underscore the necessity of strong regulatory frameworks and interdisciplinary collaboration to effectively harness these innovations for resilience and sustainable development."
Social Sciences,Applications and challenges of neural networks in otolaryngology (Review),"Artificial Intelligence (AI) has become a topic of interest that is frequently debated in all research fields. The medical field is no exception, where several unanswered questions remain. When and how this field can benefit from AI support in daily routines are the most frequently asked questions. The present review aims to present the types of neural networks (NNs) available for development, discussing their advantages, disadvantages and how they can be applied practically. In addition, the present review summarizes how NNs (combined with various other features) have already been applied in studies in the ear nose throat research field, from assisting diagnosis to treatment management. Although the answer to this question regarding AI remains elusive, understanding the basics and types of applicable NNs can lead to future studies possibly using more than one type of NN. This approach may bypass the actual limitations in accuracy and relevance of information generated by AI. The proposed studies, the majority of which used convolutional NNs, obtained accuracies varying 70-98%, with a number of studies having the AI trained on a limited number of cases (<100 patients). The lack of standardization in AI protocols for research negatively affects data homogeneity and transparency of databases.","['neural networks (NNs)', 'convolutional neural networks (convolutional NNs)']","The research idea centers on the ongoing debate and unresolved questions within the medical field regarding the appropriate timing and manner in which emerging technologies can support daily clinical routines. There is a need to understand the practical applications, benefits, and limitations of these technologies in medical research and treatment management, particularly in the ear, nose, and throat specialty. The study aims to address the challenges posed by the lack of standardization and transparency in current research protocols, which affect the consistency and reliability of findings. The primary objective of the study is to review and summarize the existing types and applications of these technologies in the ear, nose, and throat research field, highlighting their advantages, disadvantages, and practical uses from diagnosis to treatment management. Additionally, the study seeks to provide a foundation for future research that may overcome current limitations in accuracy and relevance by exploring combined approaches."
Social Sciences,A Hierarchical 3D Gaussian Representation for Real-Time Rendering of Very Large Datasets,"Novel view synthesis has seen major advances in recent years, with 3D Gaussian splatting offering an excellent level of visual quality, fast training and real-time rendering. However, the resources needed for training and rendering inevitably limit the size of the captured scenes that can be represented with good visual quality. We introduce a hierarchy of 3D Gaussians that preserves visual quality for very large scenes, while offering an efficient Level-of-Detail (LOD) solution for efficient rendering of distant content with effective level selection and smooth transitions between levels. We introduce a divide-and-conquer approach that allows us to train very large scenes in independent chunks. We consolidate the chunks into a hierarchy that can be optimized to further improve visual quality of Gaussians merged into intermediate nodes. Very large captures typically have sparse coverage of the scene, presenting many challenges to the original 3D Gaussian splatting training method; we adapt and regularize training to account for these issues. We present a complete solution, that enables real-time rendering of very large scenes and can adapt to available resources thanks to our LOD method. We show results for captured scenes with up to tens of thousands of images with a simple and affordable rig, covering trajectories of up to several kilometers and lasting up to one hour.",['3D Gaussian splatting'],"The study addresses the challenge of representing and visualizing very large captured scenes with high visual quality, despite limitations in resources that typically restrict the size of scenes that can be effectively rendered. It focuses on overcoming difficulties related to sparse coverage and the complexity of managing extensive spatial data in large-scale environments. The primary aim of the study is to develop a hierarchical approach that preserves visual quality for very large scenes while enabling efficient rendering of distant content through effective level selection and smooth transitions. Additionally, the study seeks to enable the handling of very large scene captures by dividing them into manageable segments and optimizing their integration to improve overall visual quality."
Social Sciences,Beyond Discrimination: Generative AI Applications and Ethical Challenges in Forensic Psychiatry,"The advent and growing popularity of generative artificial intelligence (GenAI) holds the potential to revolutionise AI applications in forensic psychiatry and criminal justice, which traditionally relied on discriminative AI algorithms. Generative AI models mark a significant shift from the previously prevailing paradigm through their ability to generate seemingly new realistic data and analyse and integrate a vast amount of unstructured content from different data formats. This potential extends beyond reshaping conventional practices, like risk assessment, diagnostic support, and treatment and rehabilitation plans, to creating new opportunities in previously underexplored areas, such as training and education. This paper examines the transformative impact of generative artificial intelligence on AI applications in forensic psychiatry and criminal justice. First, it introduces generative AI and its prevalent models. Following this, it reviews the current applications of discriminative AI in forensic psychiatry. Subsequently, it presents a thorough exploration of the potential of generative AI to transform established practices and introduce novel applications through multimodal generative models, data generation and data augmentation. Finally, it provides a comprehensive overview of ethical and legal issues associated with deploying generative AI models, focusing on their impact on individuals as well as their broader societal implications. In conclusion, this paper aims to contribute to the ongoing discourse concerning the dynamic challenges of generative AI applications in forensic contexts, highlighting potential opportunities, risks, and challenges. It advocates for interdisciplinary collaboration and emphasises the necessity for thorough, responsible evaluations of generative AI models before widespread adoption into domains where decisions with substantial life-altering consequences are routinely made.","['generative AI models', 'multimodal generative models']","The study addresses the transformative potential of emerging technologies in forensic psychiatry and criminal justice, fields that have traditionally relied on established approaches for risk assessment, diagnostic support, and treatment planning. It highlights how new developments could reshape conventional practices and open opportunities in areas such as training and education, while also raising important ethical and legal concerns. The primary aim of the study is to examine the impact of these emerging technologies on existing applications within forensic psychiatry and criminal justice, exploring both the opportunities for innovation and the associated risks and challenges. Additionally, the study seeks to contribute to ongoing discussions by emphasizing the need for interdisciplinary collaboration and responsible evaluation before these technologies are widely adopted in contexts involving critical decisions affecting individuals’ lives."
Social Sciences,Unlocking the Potential of Artificial Intelligence in Fashion Design and E-Commerce Applications: The Case of Midjourney,"The fashion industry has shown increasing interest in applying artificial intelligence (AI), yet there is a significant gap in exploring the potential of emerging diffusion-modeling-based AI image-generation systems for fashion design and commerce. Therefore, this study aims to assess the effectiveness of Midjourney, one such AI system, in both fashion design and related commerce applications. We employed the action research approach with the Functional, Expressive, and Aesthetic (FEA) Consumer Needs Model as the theoretical framework. Our research comprised three stages: refining an initial idea into well-defined textual design concepts, facilitating concept development, and validating the preceding observations and reflections by creating a new line of hemp-based products that were evaluated by targeted consumers through an online survey. Findings reveal that this AI tool can assist fashion designers in creating both visually expressive attire and ready-to-wear products, meeting defined design criteria and consumer needs. Midjourney shows promise in streamlining the fashion design process by enhancing ideation and optimizing design details. Potential e-commercial applications of such AI systems were proposed, benefiting physical and digital fashion businesses. It is noted that, to date, the major limitations of using Midjourney encompass its restriction to only facilitating early fashion design stages and necessitating substantial involvement from designers.",['diffusion-modeling-based AI image-generation systems'],"The fashion industry is increasingly interested in innovative approaches to enhance fashion design and commerce, yet there remains a significant gap in exploring new methods for generating creative fashion concepts and products. This study addresses the need to understand how emerging tools can support designers in meeting consumer needs related to functionality, expression, and aesthetics within the fashion domain. The primary aim of the study is to assess the effectiveness of a novel approach in assisting fashion design and commerce applications by refining design concepts, facilitating development, and validating outcomes through consumer evaluation. The research seeks to determine how such approaches can aid designers in creating visually expressive and ready-to-wear products that align with defined design criteria and consumer preferences, while also exploring potential benefits for both physical and digital fashion businesses."
Social Sciences,Making Sense of Machine Learning: A Review of Interpretation Techniques and Their Applications,"Transparency in AI models is essential for promoting human–AI collaboration and ensuring regulatory compliance. However, interpreting these models is a complex process influenced by various methods and datasets. This study presents a comprehensive overview of foundational interpretation techniques, meticulously referencing the original authors and emphasizing their pivotal contributions. Recognizing the seminal work of these pioneers is imperative for contextualizing the evolutionary trajectory of interpretation in the field of AI. Furthermore, this research offers a retrospective analysis of interpretation techniques, critically evaluating their inherent strengths and limitations. We categorize these techniques into model-based, representation-based, post hoc, and hybrid methods, delving into their diverse applications. Furthermore, we analyze publication trends over time to see how the adoption of advanced computational methods within various categories of interpretation techniques has shaped the development of AI interpretability over time. This analysis highlights a notable preference shift towards data-driven approaches in the field. Moreover, we consider crucial factors such as the suitability of these techniques for generating local or global insights and their compatibility with different data types, including images, text, and tabular data. This structured categorization serves as a guide for practitioners navigating the landscape of interpretation techniques in AI. In summary, this review not only synthesizes various interpretation techniques but also acknowledges the contributions of their original authors. By emphasizing the origins of these techniques, we aim to enhance AI model explainability and underscore the importance of recognizing biases, uncertainties, and limitations inherent in the methods and datasets. This approach promotes the ethical and practical use of interpretation insights, empowering AI practitioners, researchers, and professionals to make informed decisions when selecting techniques for responsible AI implementation in real-world scenarios.","['model-based methods', 'representation-based methods', 'hybrid methods']","The research idea centers on the importance of transparency and interpretability in complex decision-making processes to promote effective collaboration and ensure adherence to regulatory standards. It addresses the challenge of understanding and contextualizing various interpretation approaches, recognizing the foundational contributions that have shaped the evolution of interpretative practices. The study highlights the need to acknowledge biases, uncertainties, and limitations inherent in these approaches to foster ethical and practical application. The primary objective of the study is to provide a comprehensive overview and critical evaluation of foundational interpretation techniques, categorizing them based on their characteristics and applications. It aims to analyze trends over time to understand shifts in preferences and suitability for different contexts, thereby guiding practitioners in making informed and responsible choices when applying interpretative methods in real-world scenarios."
Social Sciences,Artificial Intelligence to Automate Network Meta-Analyses: Four Case Studies to Evaluate the Potential Application of Large Language Models,"The emergence of artificial intelligence, capable of human-level performance on some tasks, presents an opportunity to revolutionise development of systematic reviews and network meta-analyses (NMAs). In this pilot study, we aim to assess use of a large-language model (LLM, Generative Pre-trained Transformer 4 [GPT-4]) to automatically extract data from publications, write an R script to conduct an NMA and interpret the results. We considered four case studies involving binary and time-to-event outcomes in two disease areas, for which an NMA had previously been conducted manually. For each case study, a Python script was developed that communicated with the LLM via application programming interface (API) calls. The LLM was prompted to extract relevant data from publications, to create an R script to be used to run the NMA and then to produce a small report describing the analysis. The LLM had a > 99% success rate of accurately extracting data across 20 runs for each case study and could generate R scripts that could be run end-to-end without human input. It also produced good quality reports describing the disease area, analysis conducted, results obtained and a correct interpretation of the results. This study provides a promising indication of the feasibility of using current generation LLMs to automate data extraction, code generation and NMA result interpretation, which could result in significant time savings and reduce human error. This is provided that routine technical checks are performed, as recommend for human-conducted analyses. Whilst not currently 100% consistent, LLMs are likely to improve with time.","['large-language model (LLM, Generative Pre-trained Transformer 4 [GPT-4])']","The study addresses the challenge of efficiently conducting systematic reviews and network meta-analyses, which are important for synthesizing evidence in healthcare research but are often time-consuming and prone to human error. There is a need to explore new approaches that can streamline the process of data extraction, analysis, and interpretation to improve the reliability and speed of these reviews. The primary aim of the study is to assess the feasibility of automating key steps in the development of network meta-analyses, including data extraction from publications, conducting the analysis, and interpreting the results, in order to achieve significant time savings and reduce human error while maintaining accuracy. This pilot study evaluates the potential of such automation in multiple case studies to determine its effectiveness and reliability compared to traditional manual methods."
Social Sciences,BioLORD-2023: semantic textual representations fusing large language models and clinical knowledge graph insights,"Abstract Objective In this study, we investigate the potential of large language models (LLMs) to complement biomedical knowledge graphs in the training of semantic models for the biomedical and clinical domains. Materials and Methods Drawing on the wealth of the Unified Medical Language System knowledge graph and harnessing cutting-edge LLMs, we propose a new state-of-the-art approach for obtaining high-fidelity representations of biomedical concepts and sentences, consisting of 3 steps: an improved contrastive learning phase, a novel self-distillation phase, and a weight averaging phase. Results Through rigorous evaluations of diverse downstream tasks, we demonstrate consistent and substantial improvements over the previous state of the art for semantic textual similarity (STS), biomedical concept representation (BCR), and clinically named entity linking, across 15+ datasets. Besides our new state-of-the-art biomedical model for English, we also distill and release a multilingual model compatible with 50+ languages and finetuned on 7 European languages. Discussion Many clinical pipelines can benefit from our latest models. Our new multilingual model enables a range of languages to benefit from our advancements in biomedical semantic representation learning, opening a new avenue for bioinformatics researchers around the world. As a result, we hope to see BioLORD-2023 becoming a precious tool for future biomedical applications. Conclusion In this article, we introduced BioLORD-2023, a state-of-the-art model for STS and BCR designed for the clinical domain.","['contrastive learning', 'self-distillation', 'weight averaging']","The research addresses the challenge of enhancing the representation and understanding of biomedical concepts and clinical language to improve various biomedical and clinical applications. It focuses on the need for more accurate and comprehensive semantic models that can support tasks such as semantic textual similarity, biomedical concept representation, and clinical entity linking across multiple languages. The primary aim of the study is to develop and introduce an advanced approach that improves the quality of semantic representations in the biomedical and clinical domains, thereby benefiting clinical workflows and enabling broader multilingual support for biomedical research and applications. The study seeks to provide a valuable resource that can facilitate future advancements in biomedical knowledge and clinical practice."
Social Sciences,Improving accuracy of GPT-3/4 results on biomedical data using a retrieval-augmented language model,"Large language models (LLMs) have made a significant impact on the fields of general artificial intelligence. General purpose LLMs exhibit strong logic and reasoning skills and general world knowledge but can sometimes generate misleading results when prompted on specific subject areas. LLMs trained with domain-specific knowledge can reduce the generation of misleading information (i.e. hallucinations) and enhance the precision of LLMs in specialized contexts. Training new LLMs on specific corpora however can be resource intensive. Here we explored the use of a retrieval-augmented generation (RAG) model which we tested on literature specific to a biomedical research area. OpenAI’s GPT-3.5, GPT-4, Microsoft’s Prometheus, and a custom RAG model were used to answer 19 questions pertaining to diffuse large B-cell lymphoma (DLBCL) disease biology and treatment. Eight independent reviewers assessed LLM responses based on accuracy, relevance, and readability, rating responses on a 3-point scale for each category. These scores were then used to compare LLM performance. The performance of the LLMs varied across scoring categories. On accuracy and relevance, the RAG model outperformed other models with higher scores on average and the most top scores across questions. GPT-4 was more comparable to the RAG model on relevance versus accuracy. By the same measures, GPT-4 and GPT-3.5 had the highest scores for readability of answers when compared to the other LLMs. GPT-4 and 3.5 also had more answers with hallucinations than the other LLMs, due to non-existent references and inaccurate responses to clinical questions. Our findings suggest that an oncology research-focused RAG model may outperform general-purpose LLMs in accuracy and relevance when answering subject-related questions. This framework can be tailored to Q&amp;A in other subject areas. Further research will help understand the impact of LLM architectures, RAG methodologies, and prompting techniques in answering questions across different subject areas.","['retrieval-augmented generation (RAG) model', 'OpenAI’s GPT-3.5', 'OpenAI’s GPT-4', 'Microsoft’s Prometheus']","The study addresses the challenge of generating accurate and relevant information in specialized subject areas, particularly in biomedical research, where general-purpose language tools may produce misleading or inaccurate responses. There is a need to improve the precision of information retrieval and presentation in domain-specific contexts to support research and clinical understanding. The primary aim of the study is to evaluate the effectiveness of a research-focused approach in providing accurate, relevant, and readable answers to questions about diffuse large B-cell lymphoma disease biology and treatment. The study seeks to compare the performance of this specialized approach against general-purpose tools to determine its potential advantages in addressing subject-specific inquiries."
Social Sciences,"Exploring Rich Subjective Quality Information for Image Quality
  Assessment in the Wild","Traditional in the wild image quality assessment (IQA) models are generally trained with the quality labels of mean opinion score (MOS), while missing the rich subjective quality information contained in the quality ratings, for example, the standard deviation of opinion scores (SOS) or even distribution of opinion scores (DOS). In this paper, we propose a novel IQA method named RichIQA to explore the rich subjective rating information beyond MOS to predict image quality in the wild. RichIQA is characterized by two key novel designs: (1) a three-stage image quality prediction network which exploits the powerful feature representation capability of the Convolutional vision Transformer (CvT) and mimics the short-term and long-term memory mechanisms of human brain; (2) a multi-label training strategy in which rich subjective quality information like MOS, SOS and DOS are concurrently used to train the quality prediction network. Powered by these two novel designs, RichIQA is able to predict the image quality in terms of a distribution, from which the mean image quality can be subsequently obtained. Extensive experimental results verify that the three-stage network is tailored to predict rich quality information, while the multi-label training strategy can fully exploit the potentials within subjective quality rating and enhance the prediction performance and generalizability of the network. RichIQA outperforms state-of-the-art competitors on multiple large-scale in the wild IQA databases with rich subjective rating labels. The code of RichIQA will be made publicly available on GitHub.",['Convolutional vision Transformer (CvT)'],"The research idea addresses the limitation of traditional approaches to assessing image quality in natural settings, which typically rely only on average quality ratings and overlook the richer subjective information contained in the variability and distribution of individual quality ratings. This study recognizes that subjective quality assessments encompass more nuanced information beyond mean opinion scores, such as the diversity of opinions among viewers, which has been largely ignored in previous evaluations. The primary objective of the study is to develop a method that incorporates this richer subjective rating information, including measures of variability and distribution of opinion scores, to more accurately predict perceived image quality in real-world conditions. The study aims to leverage these comprehensive subjective quality indicators concurrently to improve the understanding and prediction of image quality as experienced by diverse observers."
Social Sciences,Artificial intelligence for oral squamous cell carcinoma detection based on oral photographs: A comprehensive literature review,"Abstract Introduction Oral squamous cell carcinoma (OSCC) presents a significant global health challenge. The integration of artificial intelligence (AI) and computer vision holds promise for the early detection of OSCC through the analysis of digitized oral photographs. This literature review explores the landscape of AI‐driven OSCC automatic detection, assessing both the performance and limitations of the current state of the art. Materials and Methods An electronic search using several data base was conducted, and a systematic review performed in accordance with PRISMA guidelines (CRD42023441416). Results Several studies have demonstrated remarkable results for this task, consistently achieving sensitivity rates exceeding 85% and accuracy rates surpassing 90%, often encompassing around 1000 images. The review scrutinizes these studies, shedding light on their methodologies, including the use of recent machine learning and pattern recognition approaches coupled with different supervision strategies. However, comparing the results from different papers is challenging due to variations in the datasets used. Discussion Considering these findings, this review underscores the urgent need for more robust and reliable datasets in the field of OSCC detection. Furthermore, it highlights the potential of advanced techniques such as multi‐task learning, attention mechanisms, and ensemble learning as crucial tools in enhancing the accuracy and sensitivity of OSCC detection through oral photographs. Conclusion These insights collectively emphasize the transformative impact of AI‐driven approaches on early OSCC diagnosis, with the potential to significantly improve patient outcomes and healthcare practices.","['machine learning', 'multi-task learning', 'attention mechanisms', 'ensemble learning']","The research idea addresses the significant global health challenge posed by oral squamous cell carcinoma (OSCC) and the importance of early detection to improve patient outcomes. The study recognizes the current efforts and progress made in detecting OSCC through the analysis of oral photographs, while also acknowledging the limitations and variability in existing research due to differences in datasets. The research objective is to explore and review the current landscape of automatic OSCC detection, assessing the performance and limitations of existing studies. This review aims to highlight the need for more robust and reliable datasets and to emphasize approaches that could enhance the accuracy and sensitivity of early OSCC diagnosis, ultimately contributing to improved healthcare practices."
Social Sciences,Decision-making for solar panel selection using Sugeno-Weber triangular norm-based on q-rung orthopair fuzzy information,"Solar power is an alternative energy derived from the sun. Solar power is more environmentally friendly and sustainable than burning fossil fuels which releases harmful greenhouse gas emissions. Therefore, this study aims to evaluate a reliable solar panel based on certain characteristics by incorporating the theory of the decision-making process. To serve this goal, this study discusses a well-known aggregation model of the q-rung orthopair fuzzy set, which is a broader and flexible environment of fuzzy sets and intuitionistic fuzzy sets used to handle unpredictable information of human opinions. The key components of this article are to demonstrate some realistic operations of Sugeno–Weber triangular norms considering q-rung orthopair fuzzy information. These operations provide authentic estimated information during the decision-making process. We developed a class of new aggregation operators using the q-rung orthopair fuzzy information system, including q-rung orthopair fuzzy Sugeno–Weber power weighted average and q-rung orthopair fuzzy Sugeno–Weber power weighted geometric operators. Some realistic characteristics and special cases are also demonstrated to show the compatibility of the proposed methodologies. An innovative approach to the multi-attribute decision-making problem is utilized to resolve different real-life applications considering various criteria or attributes. To show the intensity and applicability of the proposed approaches, we explored a numerical example for efficient solar panel selection based on the proposed methodologies. Furthermore, we presented a comprehensive comparison technique to compare the findings of the existing methods with the proposed aggregation approaches. Finally, the proposed research work is summarized, and the future prospects are discussed.","['q-rung orthopair fuzzy set', 'q-rung orthopair fuzzy Sugeno–Weber power weighted average', 'q-rung orthopair fuzzy Sugeno–Weber power weighted geometric operators']","The research idea centers on the need to evaluate reliable solar panels by considering various characteristics within the decision-making process, motivated by the environmental benefits of solar power as a sustainable alternative to fossil fuels. The study addresses the challenge of handling unpredictable human opinions in selecting efficient solar panels, aiming to improve the decision-making framework in this context. The primary objective of the study is to assess and select efficient solar panels based on multiple criteria by applying a structured decision-making approach that incorporates human judgment and preferences. This objective includes demonstrating realistic operations and compatibility of the proposed decision-making methods to enhance the reliability and applicability of solar panel selection in real-life scenarios."
Social Sciences,Diagnostic Performance Comparison between Generative AI and Physicians: A Systematic Review and Meta-Analysis,"Abstract Background The rapid advancement of generative artificial intelligence (AI) has led to the wide dissemination of models with exceptional understanding and generation of human language. Their integration into healthcare has shown potential for improving medical diagnostics, yet a comprehensive diagnostic performance evaluation of generative AI models and the comparison of their diagnostic performance with that of physicians has not been extensively explored. Methods In this systematic review and meta-analysis, a comprehensive search of Medline, Scopus, Web of Science, Cochrane Central, and MedRxiv was conducted for studies published from June 2018 through December 2023, focusing on those that validate generative AI models for diagnostic tasks. The risk of bias was assessed using the Prediction Model Study Risk of Bias Assessment Tool. Meta-regression was performed to summarize the performance of the models and to compare the accuracy of the models with that of physicians. Results The search resulted in 54 studies being included in the meta-analysis. Nine generative AI models were evaluated across 17 medical specialties. The quality assessment indicated a high risk of bias in the majority of studies, primarily due to small sample sizes. The overall accuracy for generative AI models across 54 studies was 56.9% (95% confidence interval [CI]: 51.0–62.7%). The meta-analysis demonstrated that, on average, physicians exceeded the accuracy of the models (difference in accuracy: 14.4% [95% CI: 4.9–23.8%], p-value =0.004). However, both Prometheus (Bing) and GPT-4 showed slightly better performance compared to non-experts (-2.3% [95% CI: -27.0–22.4%], p-value = 0.848 and -0.32% [95% CI: -14.4–13.7%], p-value = 0.962), but slightly underperformed when compared to experts (10.9% [95% CI: -13.1–35.0%], p-value = 0.356 and 12.9% [95% CI: 0.15–25.7%], p-value = 0.048). The sub-analysis revealed significantly improved accuracy in the fields of Gynecology, Pediatrics, Orthopedic surgery, Plastic surgery, and Otolaryngology, while showing reduced accuracy for Neurology, Psychiatry, Rheumatology, and Endocrinology compared to that of General Medicine. No significant heterogeneity was observed based on the risk of bias. Conclusions Generative AI exhibits promising diagnostic capabilities, with accuracy varying significantly by model and medical specialty. Although they have not reached the reliability of expert physicians, the findings suggest that generative AI models have the potential to enhance healthcare delivery and medical education, provided they are integrated with caution and their limitations are well-understood. Key Points Question: What is the diagnostic accuracy of generative AI models and how does this accuracy compare to that of physicians? Findings: This meta-analysis found that generative AI models have a pooled accuracy of 56.9% (95% confidence interval: 51.0–62.7%). The accuracy of expert physicians exceeds that of AI in all specialties, however, some generative AI models are comparable to non-expert physicians. Meaning: The diagnostic performance of generative AI models suggests that they do not match the level of experienced physicians but that they may have potential applications in healthcare delivery and medical education.",['generative AI models'],"The research addresses the growing integration of advanced language-based technologies into healthcare, focusing on their potential to improve medical diagnostics. Despite their rapid development and widespread dissemination, there has been limited comprehensive evaluation of how these technologies perform diagnostically compared to human physicians. The study aims to systematically assess the diagnostic accuracy of these technologies across various medical specialties and to compare their performance directly with that of physicians. By doing so, the research seeks to clarify the extent to which these technologies can support healthcare delivery and medical education, highlighting areas of strength and limitations relative to expert clinical judgment."
Social Sciences,Systematic Review of Large Language Models for Patient Care: Current Applications and Challenges,"Abstract The introduction of large language models (LLMs) into clinical practice promises to improve patient education and empowerment, thereby personalizing medical care and broadening access to medical knowledge. Despite the popularity of LLMs, there is a significant gap in systematized information on their use in patient care. Therefore, this systematic review aims to synthesize current applications and limitations of LLMs in patient care using a data-driven convergent synthesis approach. We searched 5 databases for qualitative, quantitative, and mixed methods articles on LLMs in patient care published between 2022 and 2023. From 4,349 initial records, 89 studies across 29 medical specialties were included, primarily examining models based on the GPT-3.5 (53.2%, n=66 of 124 different LLMs examined per study) and GPT-4 (26.6%, n=33/124) architectures in medical question answering, followed by patient information generation, including medical text summarization or translation, and clinical documentation. Our analysis delineates two primary domains of LLM limitations: design and output. Design limitations included 6 second-order and 12 third-order codes, such as lack of medical domain optimization, data transparency, and accessibility issues, while output limitations included 9 second-order and 32 third-order codes, for example, non-reproducibility, non-comprehensiveness, incorrectness, unsafety, and bias. In conclusion, this study is the first review to systematically map LLM applications and limitations in patient care, providing a foundational framework and taxonomy for their implementation and evaluation in healthcare settings.","['GPT-3.5', 'GPT-4']","The research idea centers on the potential of large language models to enhance patient education and empowerment, thereby personalizing medical care and expanding access to medical knowledge. Despite their growing popularity, there is a notable lack of organized information regarding their practical use in patient care. The research objective is to systematically synthesize existing applications and limitations of these models in patient care by reviewing relevant studies across various medical specialties. This study aims to provide a comprehensive framework and taxonomy to guide the implementation and evaluation of these tools within healthcare settings."
Social Sciences,PathAsst: A Generative Foundation AI Assistant towards Artificial General Intelligence of Pathology,"As advances in large language models (LLMs) and multimodal techniques continue to mature, the development of general-purpose multimodal large language models (MLLMs) has surged, offering significant applications in interpreting natural images. However, the field of pathology has largely remained untapped, particularly in gathering high-quality data and designing comprehensive model frameworks. To bridge the gap in pathology MLLMs, we present PathAsst, a multimodal generative foundation AI assistant to revolutionize diagnostic and predictive analytics in pathology. The development of PathAsst involves three pivotal steps: data acquisition, CLIP model adaptation, and the training of PathAsst's multimodal generative capabilities. Firstly, we collect over 207K high-quality pathology image-text pairs from authoritative sources. Leveraging the advanced power of ChatGPT, we generate over 180K instruction-following samples. Furthermore, we devise additional instruction-following data specifically tailored for invoking eight pathology-specific sub-models we prepared, allowing the PathAsst to effectively collaborate with these models, enhancing its diagnostic ability. Secondly, by leveraging the collected data, we construct PathCLIP, a pathology-dedicated CLIP, to enhance PathAsst's capabilities in interpreting pathology images. Finally, we integrate PathCLIP with the Vicuna-13b and utilize pathology-specific instruction-tuning data to enhance the multimodal generation capacity of PathAsst and bolster its synergistic interactions with sub-models. The experimental results of PathAsst show the potential of harnessing AI-powered generative foundation model to improve pathology diagnosis and treatment processes. We open-source our dataset, as well as a comprehensive toolkit for extensive pathology data collection and preprocessing at https://github.com/superjamessyx/Generative-Foundation-AI-Assistant-for-Pathology.","['CLIP model adaptation', 'instruction-tuning']","The research idea centers on addressing the underexplored area of pathology in the context of interpreting natural images, highlighting challenges in gathering high-quality pathology data and designing comprehensive frameworks for improved diagnostic and predictive capabilities. The study recognizes a significant gap in pathology applications despite advances in related fields, emphasizing the need to enhance diagnostic processes through better data and tailored approaches. The primary objective of the study is to develop a novel pathology-focused assistant aimed at revolutionizing diagnostic and predictive analytics within pathology by collecting extensive high-quality pathology image-text data and creating specialized resources to improve interpretation and collaboration with pathology-specific sub-models. This effort seeks to improve pathology diagnosis and treatment processes by leveraging these tailored resources and making the dataset and tools openly available for further research and application."
Social Sciences,Methodological insights into ChatGPT’s screening performance in systematic reviews,"Abstract Background The screening process for systematic reviews and meta-analyses in medical research is a labor-intensive and time-consuming task. While machine learning and deep learning have been applied to facilitate this process, these methods often require training data and user annotation. This study aims to assess the efficacy of ChatGPT, a large language model based on the Generative Pretrained Transformers (GPT) architecture, in automating the screening process for systematic reviews in radiology without the need for training data. Methods A prospective simulation study was conducted between May 2nd and 24th, 2023, comparing ChatGPT’s performance in screening abstracts against that of general physicians (GPs). A total of 1198 abstracts across three subfields of radiology were evaluated. Metrics such as sensitivity, specificity, positive and negative predictive values (PPV and NPV), workload saving, and others were employed. Statistical analyses included the Kappa coefficient for inter-rater agreement, ROC curve plotting, AUC calculation, and bootstrapping for p-values and confidence intervals. Results ChatGPT completed the screening process within an hour, while GPs took an average of 7–10 days. The AI model achieved a sensitivity of 95% and an NPV of 99%, slightly outperforming the GPs’ sensitive consensus (i.e., including records if at least one person includes them). It also exhibited remarkably low false negative counts and high workload savings, ranging from 40 to 83%. However, ChatGPT had lower specificity and PPV compared to human raters. The average Kappa agreement between ChatGPT and other raters was 0.27. Conclusions ChatGPT shows promise in automating the article screening phase of systematic reviews, achieving high sensitivity and workload savings. While not entirely replacing human expertise, it could serve as an efficient first-line screening tool, particularly in reducing the burden on human resources. Further studies are needed to fine-tune its capabilities and validate its utility across different medical subfields.","['machine learning', 'deep learning', 'Generative Pretrained Transformers (GPT) architecture']","The research addresses the challenge of the labor-intensive and time-consuming nature of the screening process for systematic reviews and meta-analyses in medical research, particularly in radiology. This process requires significant human effort and resources, which can delay the synthesis of medical evidence. The study aims to evaluate the effectiveness of an automated approach in facilitating the screening of abstracts for systematic reviews without relying on extensive prior training or user annotation. The primary objective of the study is to assess the performance of this automated approach in screening abstracts compared to general physicians, focusing on metrics such as sensitivity, workload savings, and agreement with human raters, to determine its potential role in reducing the burden on human resources during systematic reviews."
Social Sciences,Machine Learning-Assisted Design of Advanced Polymeric Materials,"ConspectusPolymeric material research is encountering a new paradigm driven by machine learning (ML) and big data. The ML-assisted design has proven to be a successful approach for designing novel high-performance polymeric materials. This goal is mainly achieved through the following procedure: structure representation and database construction, establishment of a ML-based property prediction model, virtual design and high-throughput screening. The key to this approach lies in training ML models that delineate structure–property relationships based on available polymer data (e.g., structure, component, and property data), enabling the screening of promising polymers that satisfy the targeted property requirements. However, the relative scarcity of high-quality polymer data and the complex polymeric multiscale structure–property relationships pose challenges for this ML-assisted design method, such as data and modeling challenges.In this Account, we summarize the state-of-the-art advancements concerning the ML-assisted design of polymeric materials. Regarding structure representation and database construction, the digital representations of polymers are the predominant methods in cheminformatics along with some newly developed methods that integrate the polymeric multiscale structure characteristics. When establishing a ML-based property prediction model, the key is choosing and optimizing ML models to attain high-precision predictions across a vast chemical structure space. Advanced ML algorithms, such as transfer learning and multitask learning, have been utilized to address the data and modeling challenges. During the ML-assisted screening process, by defining and combining polymer genes, virtual polymer candidates are generated, and subsequently, their properties are predicted and high-throughput screened using ML property prediction models. Finally, the promising polymers identified through this approach are verified by computer simulations and experiments.We provide an overview of our recent efforts toward developing ML-assisted design approaches for discovering advanced polymeric materials and emphasize the intricate nature of polymer structural design. To well describe the multiscale structures of polymers, new structure representation methods, such as polymer fingerprint and cross-linking descriptors, were developed. Moreover, a multifidelity learning method was proposed to leverage the multisource isomerous polymer data from experiments and simulations. Additionally, graph neural networks and Bayesian optimization methods have been developed and applied for predicting polymer properties as well as designing polymer structures and compositions.Finally, we identify the current challenges and point out the development directions in this emerging field. It is highly desirable to establish new structure representation and advanced ML modeling methods for polymeric materials, particularly when constructing polymer large models based on chemical language. Through this Account, we seek to stimulate further interest and foster active collaborations for developing ML-assisted design approaches and realizing the innovation of advanced polymeric materials.","['transfer learning', 'multifidelity learning', 'graph neural networks', 'Bayesian optimization']","The research idea centers on addressing the challenges in designing novel high-performance polymeric materials, particularly due to the complexity of polymer multiscale structures and the scarcity of high-quality polymer data. This study recognizes the need for improved approaches to represent polymer structures and understand their relationships with material properties to facilitate the discovery of promising polymers that meet targeted requirements. The primary objective of the study is to summarize recent advancements in approaches for designing advanced polymeric materials, emphasizing the development of new methods for representing polymer structures and overcoming data limitations. Additionally, the study aims to highlight current challenges and encourage further research and collaboration to innovate in the design of high-performance polymers."
Social Sciences,Navigating the Power of Artificial Intelligence in Risk Management: A Comparative Analysis,"This study presents a responsive analysis of the role of artificial intelligence (AI) in risk management, contrasting traditional approaches with those augmented by AI and highlighting the challenges and opportunities that emerge. AI, intense learning methodologies such as convolutional neural networks (CNNs), have been identified as pivotal in extracting meaningful insights from image data, a form of analysis that holds significant potential in identifying and managing risks across various industries. The research methodology involves a strategic selection and processing of images for analysis and introduces three case studies that serve as benchmarks for evaluation. These case studies showcase the application of AI, in place of image processing capabilities, to identify hazards, evaluate risks, and suggest control measures. The comparative evaluation focuses on the accuracy, relevance, and practicality of the AI-generated findings alongside the system’s response time and comprehensive understanding of the context. Results reveal that AI can significantly enhance risk assessment processes, offering rapid and detailed insights. However, the study also recognises the intrinsic limitations of AI in contextual interpretation, advocating for a synergy between technological and domain-specific expertise. The conclusion underscores the transformative potential of AI in risk management, supporting continued research to further integrate AI effectively into risk assessment frameworks.",['convolutional neural networks (CNNs)'],"The study addresses the evolving role of risk management by examining how traditional approaches compare with newer methods that incorporate advanced techniques for interpreting image data to identify and manage risks across various industries. It highlights the challenges and opportunities that arise from integrating these approaches into existing risk assessment practices. The primary aim of the study is to evaluate the effectiveness of these advanced methods in identifying hazards, assessing risks, and recommending control measures through case studies, while also considering their accuracy, relevance, and practical application. The research seeks to understand how these approaches can enhance risk assessment processes and emphasizes the importance of combining technological capabilities with domain-specific expertise for improved outcomes."
Social Sciences,The Sociodemographic Biases in Machine Learning Algorithms: A Biomedical Informatics Perspective,"Artificial intelligence models represented in machine learning algorithms are promising tools for risk assessment used to guide clinical and other health care decisions. Machine learning algorithms, however, may house biases that propagate stereotypes, inequities, and discrimination that contribute to socioeconomic health care disparities. The biases include those related to some sociodemographic characteristics such as race, ethnicity, gender, age, insurance, and socioeconomic status from the use of erroneous electronic health record data. Additionally, there is concern that training data and algorithmic biases in large language models pose potential drawbacks. These biases affect the lives and livelihoods of a significant percentage of the population in the United States and globally. The social and economic consequences of the associated backlash cannot be underestimated. Here, we outline some of the sociodemographic, training data, and algorithmic biases that undermine sound health care risk assessment and medical decision-making that should be addressed in the health care system. We present a perspective and overview of these biases by gender, race, ethnicity, age, historically marginalized communities, algorithmic bias, biased evaluations, implicit bias, selection/sampling bias, socioeconomic status biases, biased data distributions, cultural biases and insurance status bias, conformation bias, information bias and anchoring biases and make recommendations to improve large language model training data, including de-biasing techniques such as counterfactual role-reversed sentences during knowledge distillation, fine-tuning, prefix attachment at training time, the use of toxicity classifiers, retrieval augmented generation and algorithmic modification to mitigate the biases moving forward.","['knowledge distillation', 'fine-tuning', 'retrieval augmented generation']","The research addresses the problem of biases related to sociodemographic characteristics such as race, ethnicity, gender, age, insurance, and socioeconomic status that contribute to health care disparities and undermine sound health care risk assessment and medical decision-making. These biases propagate stereotypes, inequities, and discrimination, affecting the lives and livelihoods of a significant portion of the population in the United States and globally, with serious social and economic consequences. The primary aim of the study is to outline and provide a perspective on the various sociodemographic and systemic biases that impact health care risk assessment and decision-making. The study seeks to highlight these issues and make recommendations to address and mitigate these biases within the health care system."
Social Sciences,Collective Constitutional AI: Aligning a Language Model with Public Input,"There is growing consensus that language model (LM) developers should not be the sole deciders of LM behavior, creating a need for methods that enable the broader public to collectively shape the behavior of LM systems that affect them. To address this need, we present Collective Constitutional AI (CCAI): a multi-stage process for sourcing and integrating public input into LMs—from identifying a target population to sourcing principles to training and evaluating a model. We demonstrate the real-world practicality of this approach by creating what is, to our knowledge, the first LM fine-tuned with collectively sourced public input and evaluating this model against a baseline model trained with established principles from a LM developer. Our quantitative evaluations demonstrate several benefits of our approach: the CCAI-trained model shows lower bias across nine social dimensions compared to the baseline model, while maintaining equivalent performance on language, math, and helpful-harmless evaluations. Qualitative comparisons of the models suggest that the models differ on the basis of their respective constitutions, e.g., when prompted with contentious topics, the CCAI-trained model tends to generate responses that reframe the matter positively instead of a refusal. These results demonstrate a promising, tractable pathway toward publicly informed development of language models.",['fine-tuning'],"The research addresses the growing concern that developers should not be the sole decision-makers in determining the behavior of language models, highlighting the need for approaches that allow the broader public to collectively influence systems that impact them. This study is motivated by the desire to create a more inclusive and representative process for shaping such systems through public input. The primary objective of the study is to develop and demonstrate a multi-stage process for sourcing and integrating public input into language models, from identifying relevant populations to incorporating their principles, and to evaluate the outcomes of this approach compared to traditional developer-driven methods. The study aims to show that involving public perspectives can reduce bias across various social dimensions while maintaining performance, thereby offering a viable pathway for publicly informed development."
Social Sciences,AI-POWERED FRAUD DETECTION IN BANKING: SAFEGUARDING FINANCIAL TRANSACTIONS,"The banking industry's metamorphosis through digitalization has unquestionably revolutionized accessibility and convenience for customers worldwide. However, this paradigm shift has ushered in a new era of challenges, most notably in the realm of cybersecurity. Conventional rule-based fraud detection strategies have struggled to keep pace with the rapid evolution of cyber threats, prompting a surge of interest in more adaptive approaches like unsupervised learning. Furthermore, the COVID-19 pandemic has exacerbated the issue of bank fraud due to the widespread transition to online platforms and the proliferation of charitable funds, which present ripe opportunities for exploitation by cybercriminals. In response to these pressing concerns, this study delves into the realm of machine learning algorithms for the analysis and identification of fraudulent banking transactions. Notably, it contributes scientific novelty by developing models specifically tailored to this purpose and implementing innovative preprocessing techniques to enhance detection accuracy. Utilizing a diverse array of algorithms, including Random Forest, K-Nearest Neighbor (KNN), Naïve Bayes, Decision Trees, and Logistic Regression, the study showcases promising results. In particular, logistic regression and decision tree models exhibit impressive accuracy and Area Under the Curve (AUC) values of approximately 0.98, 0.97 and 0.95, 0.94, respectively. Given the pervasive nature of banking fraud in our digital society, the utilization of artificial intelligence algorithms for fraud detection stands as a critical and timely endeavor, promising enhanced security and trust in the financial ecosystem.","['unsupervised learning', 'Random Forest', 'K-Nearest Neighbor (KNN)', 'Naïve Bayes', 'Decision Trees', 'Logistic Regression']","The banking industry’s transformation through digitalization has significantly improved customer accessibility and convenience but has also introduced new challenges, particularly in the area of cybersecurity. The rapid evolution of cyber threats has rendered traditional fraud detection methods less effective, while the COVID-19 pandemic has intensified the problem of bank fraud due to increased online activity and the rise of charitable fund exploitation. This study aims to address these pressing concerns by focusing on the identification and analysis of fraudulent banking transactions. Its primary objective is to develop and implement approaches specifically designed to enhance the detection of bank fraud, thereby contributing to improved security and trust within the financial sector."
Social Sciences,"A Systematic Review of Graph Neural Network in Healthcare-Based Applications: Recent Advances, Trends, and Future Directions","Graph neural network (GNN) is a formidable deep learning framework that enables the analysis and modeling of intricate relationships present in data structured as graphs. In recent years, a burgeoning interest has arisen in exploiting the latent capabilities of GNN for healthcare-based applications, capitalizing on their aptitude for modeling complex relationships and unearthing profound insights from graph-structured data. However, to the best of our knowledge, no study has systemically reviewed the GNN studies conducted in the healthcare domain. This study has furnished an all-encompassing and erudite overview of the prevailing cutting-edge research on GNN in healthcare. Through analysis and assimilation of studies, current research trends, recurrent challenges, and promising future opportunities in GNN for healthcare applications have been identified. China emerged as the leading country to conduct GNN-based studies in the healthcare domain, followed by the USA, UK, and Turkey. Among various aspects of healthcare, disease prediction and drug discovery emerge as the most prominent areas of focus for GNN application, indicating the potential of GNN for advancing diagnostic and therapeutic approaches. This study proposed research questions regarding diverse aspects of GNN in the healthcare domain and addressed them through an in-depth analysis. This study can provide practitioners and researchers with profound insights into the current landscape of GNN applications in healthcare and can guide healthcare institutes, researchers, and governments by demonstrating the ways in which GNN can contribute to the development of effective and efficient healthcare systems.",['Graph neural network (GNN)'],"The research idea centers on the increasing interest in exploring advanced approaches to understand and utilize complex relationships within healthcare data, highlighting a gap in comprehensive reviews of such studies in the healthcare domain. There is a recognized need to synthesize existing research to identify current trends, challenges, and future opportunities in applying innovative methods to healthcare problems. The primary objective of the study is to provide a thorough and scholarly overview of the latest research focused on these advanced approaches in healthcare, addressing key questions related to their application. By doing so, the study aims to offer valuable insights to practitioners, researchers, and policymakers, guiding the development of more effective and efficient healthcare systems."
Social Sciences,Pseudo-spectral angle mapping for automated pixel-level analysis of highly multiplexed tissue image data,"Abstract The rapid development of highly multiplexed microscopy systems has enabled the study of cells embedded within their native tissue, which is providing exciting insights into the spatial features of human disease [1]. However, computational methods for analyzing these high-content images are still emerging, and there is a need for more robust and generalizable tools for evaluating the cellular constituents and underlying stroma captured by high-plex imaging [2]. To address this need, we have adapted spectral angle mapping – an algorithm used widely in hyperspectral image analysis – to compress the channel dimension of high-plex immunofluorescence images. As many high-plex immunofluorescence imaging experiments probe unique sets of protein markers, existing cell and pixel classification models do not typically generalize well. Pseudospectral angle mapping (pSAM) uses reference pseudospectra – or pixel vectors – to assign each pixel in an image a similarity score to several cell class reference vectors, which are defined by each unique staining panel. Here, we demonstrate that the class maps provided by pSAM can directly provide insight into the prevalence of each class defined by reference pseudospectra. In a dataset of high-plex images of colon biopsies from patients with gut autoimmune conditions, sixteen pSAM class representation maps were combined with instance segmentation of cells to provide cell class predictions. Finally, pSAM detected a diverse set of structure and immune cells when applied to a novel dataset of kidney biopsies imaged with a 43-marker panel. In summary, pSAM provides a powerful and readily generalizable method for evaluating high-plex immunofluorescence image data. Significance Statement Understanding the cellular constituents captured by highly multiplexed tissue imaging is a major limitation affecting the usability of these novel imaging methods. Many imaging experiments have uniquely designed staining panels, reducing the generalizability of cell classification models to new datasets. We present pseudospectral angle mapping (pSAM), which can compress high-dimensional image data into class representations. We demonstrate that the class representations generated by pSAM can be used to interpret high-plex image data and guide cell classification. Importantly, we also demonstrate that pSAM can generalize to new image datasets—collected with a different staining panel in samples from different tissues—without manual image annotation, subjective intensity gating, or re-training an algorithm.",['spectral angle mapping'],"The research idea centers on the challenge of understanding the cellular constituents within highly multiplexed tissue imaging, which is crucial for gaining insights into the spatial features of human disease. Current approaches face limitations due to the unique staining panels used in many imaging experiments, which reduce the ability to generalize findings across different datasets. This creates a need for more robust and generalizable methods to evaluate the cellular and stromal components captured by these advanced imaging techniques. The study aims to address this gap by providing a means to interpret complex tissue images in a way that can be applied broadly across diverse experimental conditions. The primary objective of the study is to develop and demonstrate a method that can effectively represent and interpret high-dimensional tissue imaging data to identify and classify cellular constituents. The study seeks to show that this approach can generalize to new datasets obtained from different tissues and staining panels without requiring manual annotation or subjective adjustments, thereby enhancing the usability and applicability of multiplexed tissue imaging in biomedical research."
