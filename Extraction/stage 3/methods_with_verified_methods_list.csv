year,openalex_id,domain,title,abstract,verified_methods_list
2024,https://openalex.org/W4392173735,Biology,"A Comprehensive Survey of Continual Learning: Theory, Method and Application","To cope with real-world dynamics, an intelligent system needs to incrementally acquire, update, accumulate, and exploit knowledge throughout its lifetime. This ability, known as continual learning, provides a foundation for AI systems to develop themselves adaptively. In a general sense, continual learning is explicitly limited by catastrophic forgetting, where learning a new task usually results in a dramatic performance drop of the old tasks. Beyond this, increasingly numerous advances have emerged in recent years that largely extend the understanding and application of continual learning. The growing and widespread interest in this direction demonstrates its realistic significance as well as complexity. In this work, we present a comprehensive survey of continual learning, seeking to bridge the basic settings, theoretical foundations, representative methods, and practical applications. Based on existing theoretical and empirical results, we summarize the general objectives of continual learning as ensuring a proper stability-plasticity trade-off and an adequate intra/inter-task generalizability in the context of resource efficiency. Then we provide a state-of-the-art and elaborated taxonomy, extensively analyzing how representative strategies address continual learning, and how they are adapted to particular challenges in various applications. Through an in-depth discussion of promising directions, we believe that such a holistic perspective can greatly facilitate subsequent exploration in this field and beyond.",['continual learning']
2024,https://openalex.org/W1578086085,Biology,Genotype by Environment Interaction and Adaptation in Barley Breeding: Basic Concepts and Methods of Analysis,"Genotype by environment interaction (GE) has important consequences in barley breeding. It often complicates testing and selection of superior genotypes, reducing genetic progress in breeding programs. This drawback may be overcome by a better understanding of the genetic and environmental factors that determine GE and adaptation of genotypes. An important array of statistical techniques is nowadays available to breeders and researchers to cope with the presence of relevant GE in multi-environment trials. This paper begins with a review of recent literature on the latest barley studies on GE and adaptation, including potential biotic and abiotic causes underlying GE. Most studies reported are empirical, describing postdictively genotypic performance across environments. As an alternative, methods allowing a more analytical approach are proposed, in which genotypes and environments are characterized in terms of external variables that affect genotypic performance. These methods are applied to a real barley data set. After data description, a number of selected multiplicative models are developed, namely the additive main effects and multiplicative interaction (AMMI) model, and the factorial regression model. Finally, the implications of GE in barley breeding are discussed. As an appendix, the SAS programs are given for the models described. Key-words: genotype by environment interaction, adaptation, AMMI, factorial regression, breeding programs",['additive main effects and multiplicative interaction (AMMI) model']
2024,https://openalex.org/W4392754729,Biology,"Revolutionizing agriculture with artificial intelligence: plant disease detection methods, applications, and their limitations","Accurate and rapid plant disease detection is critical for enhancing long-term agricultural yield. Disease infection poses the most significant challenge in crop production, potentially leading to economic losses. Viruses, fungi, bacteria, and other infectious organisms can affect numerous plant parts, including roots, stems, and leaves. Traditional techniques for plant disease detection are time-consuming, require expertise, and are resource-intensive. Therefore, automated leaf disease diagnosis using artificial intelligence (AI) with Internet of Things (IoT) sensors methodologies are considered for the analysis and detection. This research examines four crop diseases: tomato, chilli, potato, and cucumber. It also highlights the most prevalent diseases and infections in these four types of vegetables, along with their symptoms. This review provides detailed predetermined steps to predict plant diseases using AI. Predetermined steps include image acquisition, preprocessing, segmentation, feature selection, and classification. Machine learning (ML) and deep understanding (DL) detection models are discussed. A comprehensive examination of various existing ML and DL-based studies to detect the disease of the following four crops is discussed, including the datasets used to evaluate these studies. We also provided the list of plant disease detection datasets. Finally, different ML and DL application problems are identified and discussed, along with future research prospects, by combining AI with IoT platforms like smart drones for field-based disease detection and monitoring. This work will help other practitioners in surveying different plant disease detection strategies and the limits of present systems.","['machine learning (ML)', 'deep learning (DL)']"
2024,https://openalex.org/W4390946589,Biology,Deep-STP: a deep learning-based approach to predict snake toxin proteins by using word embeddings,"Snake venom contains many toxic proteins that can destroy the circulatory system or nervous system of prey. Studies have found that these snake venom proteins have the potential to treat cardiovascular and nervous system diseases. Therefore, the study of snake venom protein is conducive to the development of related drugs. The research technologies based on traditional biochemistry can accurately identify these proteins, but the experimental cost is high and the time is long. Artificial intelligence technology provides a new means and strategy for large-scale screening of snake venom proteins from the perspective of computing. In this paper, we developed a sequence-based computational method to recognize snake toxin proteins. Specially, we utilized three different feature descriptors, namely g-gap , natural vector and word 2 vector, to encode snake toxin protein sequences. The analysis of variance (ANOVA), gradient-boost decision tree algorithm (GBDT) combined with incremental feature selection (IFS) were used to optimize the features, and then the optimized features were input into the deep learning model for model training. The results show that our model can achieve a prediction performance with an accuracy of 82.00% in 10-fold cross-validation. The model is further verified on independent data, and the accuracy rate reaches to 81.14%, which demonstrated that our model has excellent prediction performance and robustness.","['gradient-boost decision tree algorithm (GBDT)', 'incremental feature selection (IFS)', 'deep learning model']"
2024,https://openalex.org/W4392791588,Biology,Can large language models replace humans in systematic reviews? Evaluating <scp>GPT</scp>‐4's efficacy in screening and extracting data from peer‐reviewed and grey literature in multiple languages,"Systematic reviews are vital for guiding practice, research and policy, although they are often slow and labour-intensive. Large language models (LLMs) could speed up and automate systematic reviews, but their performance in such tasks has yet to be comprehensively evaluated against humans, and no study has tested Generative Pre-Trained Transformer (GPT)-4, the biggest LLM so far. This pre-registered study uses a ""human-out-of-the-loop"" approach to evaluate GPT-4's capability in title/abstract screening, full-text review and data extraction across various literature types and languages. Although GPT-4 had accuracy on par with human performance in some tasks, results were skewed by chance agreement and dataset imbalance. Adjusting for these caused performance scores to drop across all stages: for data extraction, performance was moderate, and for screening, it ranged from none in highly balanced literature datasets (~1:1) to moderate in those datasets where the ratio of inclusion to exclusion in studies was imbalanced (~1:3). When screening full-text literature using highly reliable prompts, GPT-4's performance was more robust, reaching ""human-like"" levels. Although our findings indicate that, currently, substantial caution should be exercised if LLMs are being used to conduct systematic reviews, they also offer preliminary evidence that, for certain review tasks delivered under specific conditions, LLMs can rival human performance.",['Generative Pre-Trained Transformer (GPT)-4']
2024,https://openalex.org/W4399777548,Biology,Feature reduction for hepatocellular carcinoma prediction using machine learning algorithms,"Abstract Hepatocellular carcinoma (HCC) is a highly prevalent form of liver cancer that necessitates accurate prediction models for early diagnosis and effective treatment. Machine learning algorithms have demonstrated promising results in various medical domains, including cancer prediction. In this study, we propose a comprehensive approach for HCC prediction by comparing the performance of different machine learning algorithms before and after applying feature reduction methods. We employ popular feature reduction techniques, such as weighting features, hidden features correlation, feature selection, and optimized selection, to extract a reduced feature subset that captures the most relevant information related to HCC. Subsequently, we apply multiple algorithms, including Naive Bayes, support vector machines (SVM), Neural Networks, Decision Tree, and K nearest neighbors (KNN), to both the original high-dimensional dataset and the reduced feature set. By comparing the predictive accuracy, precision, F Score, recall, and execution time of each algorithm, we assess the effectiveness of feature reduction in enhancing the performance of HCC prediction models. Our experimental results, obtained using a comprehensive dataset comprising clinical features of HCC patients, demonstrate that feature reduction significantly improves the performance of all examined algorithms. Notably, the reduced feature set consistently outperforms the original high-dimensional dataset in terms of prediction accuracy and execution time. After applying feature reduction techniques, the employed algorithms, namely decision trees, Naive Bayes, KNN, neural networks, and SVM achieved accuracies of 96%, 97.33%, 94.67%, 96%, and 96.00%, respectively.","['Naive Bayes', 'support vector machines (SVM)', 'Neural Networks', 'Decision Tree', 'K nearest neighbors (KNN)']"
2024,https://openalex.org/W4391019749,Biology,CIFAKE: Image Classification and Explainable Identification of AI-Generated Synthetic Images,"Recent advances in synthetic data have enabled the generation of images with such high quality that human beings cannot tell the difference between real-life photographs and Artificial Intelligence (AI) generated images. Given the critical necessity of data reliability and authentication, this article proposes to enhance our ability to recognise AI-generated images through computer vision. Initially, a synthetic dataset is generated that mirrors the ten classes of the already available CIFAR-10 dataset with latent diffusion, providing a contrasting set of images for comparison to real photographs. The model is capable of generating complex visual attributes, such as photorealistic reflections in water. The two sets of data present as a binary classification problem with regard to whether the photograph is real or generated by AI. This study then proposes the use of a Convolutional Neural Network (CNN) to classify the images into two categories; Real or Fake. Following hyperparameter tuning and the training of 36 individual network topologies, the optimal approach could correctly classify the images with 92.98% accuracy. Finally, this study implements explainable AI via Gradient Class Activation Mapping to explore which features within the images are useful for classification. Interpretation reveals interesting concepts within the image, in particular, noting that the actual entity itself does not hold useful information for classification; instead, the model focuses on small visual imperfections in the background of the images. The complete dataset engineered for this study, referred to as the CIFAKE dataset, is made publicly available to the research community for future work.","['latent diffusion', 'Convolutional Neural Network (CNN)', 'Gradient Class Activation Mapping']"
2024,https://openalex.org/W4395050972,Biology,Optimization of hepatological clinical guidelines interpretation by large language models: a retrieval augmented generation-based framework,"Abstract Large language models (LLMs) can potentially transform healthcare, particularly in providing the right information to the right provider at the right time in the hospital workflow. This study investigates the integration of LLMs into healthcare, specifically focusing on improving clinical decision support systems (CDSSs) through accurate interpretation of medical guidelines for chronic Hepatitis C Virus infection management. Utilizing OpenAI’s GPT-4 Turbo model, we developed a customized LLM framework that incorporates retrieval augmented generation (RAG) and prompt engineering. Our framework involved guideline conversion into the best-structured format that can be efficiently processed by LLMs to provide the most accurate output. An ablation study was conducted to evaluate the impact of different formatting and learning strategies on the LLM’s answer generation accuracy. The baseline GPT-4 Turbo model’s performance was compared against five experimental setups with increasing levels of complexity: inclusion of in-context guidelines, guideline reformatting, and implementation of few-shot learning. Our primary outcome was the qualitative assessment of accuracy based on expert review, while secondary outcomes included the quantitative measurement of similarity of LLM-generated responses to expert-provided answers using text-similarity scores. The results showed a significant improvement in accuracy from 43 to 99% ( p &lt; 0.001), when guidelines were provided as context in a coherent corpus of text and non-text sources were converted into text. In addition, few-shot learning did not seem to improve overall accuracy. The study highlights that structured guideline reformatting and advanced prompt engineering (data quality vs. data quantity) can enhance the efficacy of LLM integrations to CDSSs for guideline delivery.","['OpenAI’s GPT-4 Turbo model', 'retrieval augmented generation (RAG)', 'few-shot learning']"
2024,https://openalex.org/W4399885374,Biology,Survival Prediction Across Diverse Cancer Types Using Neural Networks,"Gastric cancer and Colon adenocarcinoma represent widespread and challenging malignancies with high mortality rates and complex treatment landscapes. In response to the critical need for accurate prognosis in cancer patients, the medical community has embraced the 5-year survival rate as a vital metric for estimating patient outcomes. This study introduces a pioneering approach to enhance survival prediction models for gastric and Colon adenocarcinoma patients. Leveraging advanced image analysis techniques, we sliced whole slide images (WSI) of these cancers, extracting comprehensive features to capture nuanced tumor characteristics. Subsequently, we constructed patient-level graphs, encapsulating intricate spatial relationships within tumor tissues. These graphs served as inputs for a sophisticated 4-layer graph convolutional neural network (GCN), designed to exploit the inherent connectivity of the data for comprehensive analysis and prediction. By integrating patients' total survival time and survival status, we computed C-index values for gastric cancer and Colon adenocarcinoma, yielding 0.57 and 0.64, respectively. Significantly surpassing previous convolutional neural network models, these results underscore the efficacy of our approach in accurately predicting patient survival outcomes. This research holds profound implications for both the medical and AI communities, offering insights into cancer biology and progression while advancing personalized treatment strategies. Ultimately, our study represents a significant stride in leveraging AI-driven methodologies to revolutionize cancer prognosis and improve patient outcomes on a global scale.","['graph convolutional neural network (GCN)', 'convolutional neural network']"
2024,https://openalex.org/W4400659510,Biology,Aspect-based drug review classification through a hybrid model with ant colony optimization using deep learning,"Abstract The task of aspect-level sentiment analysis is intricately designed to determine the sentiment polarity directed towards a specific target within a sentence. With the increasing availability of online reviews and the growing importance of healthcare decisions, analyzing drug reviews has become a critical task. Traditional sentiment analysis, which categorizes a whole review as positive, negative, or neutral, provides limited insights for consumers and healthcare professionals. Aspect-based sentiment analysis (ABSA) aims to overcome these limitations by identifying and evaluating the sentiment associated with specific aspects or attributes of drugs mentioned in the reviews. Various fields, including business, politics, and medicine, have been explored in the context of sentiment analysis. Automation of online user reviews allows pharmaceutical companies to assess large amounts of user feedback. This helps extract pharmacological efficacy and side effect insights. The data collected could improve pharmacovigilance. Reviewing user comments can provide valuable data that can be used to improve drug safety and efficacy monitoring procedures. This improves pharmacovigilance processes, improving pharmaceutical outcomes understanding and corporate decision-making. Therefore, we propose a pre-trained RoBERTa with a Bi-LSTM model to categorise drug reviews from online sources and pre-process the text data. Ant Colony Optimization can be used in feature selection for ABSA, helping to identify the most relevant aspects and sentiments. Further, RoBERTa is fine-tuned to perform ABSA on the dataset, enabling the system to categorize aspects and determine the associated sentiment. The outcomes reveal that the suggested framework has achieved higher accuracy (96.78%) and F1 score (98.29%) on druglib.com, and 95.02% on the drugs.com dataset, than several prior state-of-the-art methods.","['pre-trained RoBERTa', 'Bi-LSTM model', 'fine-tuned RoBERTa']"
2024,https://openalex.org/W4390494339,Biology,"A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection in Industrial Time Series: Methods, Applications, and Directions","Automating the monitoring of industrial processes has the potential to enhance efficiency and optimize quality by promptly detecting abnormal events and thus facilitating timely interventions. Deep learning, with its capacity to discern non-trivial patterns within large datasets, plays a pivotal role in this process. Standard deep learning methods are suitable to solve a specific task given a specific type of data. During training, deep learning demands large volumes of labeled data. However, due to the dynamic nature of the industrial processes and environment, it is impractical to acquire large-scale labeled data for standard deep learning training for every slightly different case anew. Deep transfer learning offers a solution to this problem. By leveraging knowledge from related tasks and accounting for variations in data distributions, the transfer learning framework solves new tasks with little or even no additional labeled data. The approach bypasses the need to retrain a model from scratch for every new setup and dramatically reduces the labeled data requirement. This survey first provides an in-depth review of deep transfer learning, examining the problem settings of transfer learning and classifying the prevailing deep transfer learning methods. Moreover, we delve into applications of deep transfer learning in the context of a broad spectrum of time series anomaly detection tasks prevalent in primary industrial domains, e.g., manufacturing process monitoring, predictive maintenance, energy management, and infrastructure facility monitoring. We discuss the challenges and limitations of deep transfer learning in industrial contexts and conclude the survey with practical directions and actionable suggestions to address the need to leverage diverse time series data for anomaly detection in an increasingly dynamic production environment.","['deep learning', 'deep transfer learning', 'transfer learning framework']"
2024,https://openalex.org/W4399326707,Biology,Enhancing precision agriculture: A comprehensive review of machine learning and AI vision applications in all-terrain vehicle for farm automation,"The automation of all-terrain vehicles (ATVs) through the integration of advanced technologies such as machine learning (ML) and artificial intelligence (AI) vision has significantly changed precision agriculture. This paper aims to analyse and develop trends to provide comprehensive knowledge of the current state of ATV-based precision agriculture and the future possibilities of ML and AI. A bibliometric analysis was conducted through network diagram with keywords taken from previous publications in the domain. This review comprehensively analyses the potential of machine learning and artificial intelligence in transforming farming operations through the automation of tasks and the deployment of all-terrain vehicles. The research extensively analyses how machine learning methods have influenced several aspects of agricultural activities, such as planting, harvesting, spraying, weeding, crop monitoring, and others. AI vision systems are being researched for their ability to enhance precise and prompt decision-making in ATV-driven agricultural automation. These technologies have been thoroughly tested to show how they can improve crop yield, reducing overall investment, and make farming more efficient. Examples include machine learning-based seeding accuracy, AI-enabled crop health monitoring, and the use of AI vision for accurate pesticide application. The assessment examines challenges such as data privacy problems and scalability constraints, along with potential advancements and future prospects in the field. This will assist researchers and practitioners in making well-informed judgments regarding farming practices that are efficient, sustainable, and technologically robust.",['machine learning']
2024,https://openalex.org/W4394579747,Biology,An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing: Algorithm Development and Validation Study,"Background Large language models (LLMs) have shown remarkable capabilities in natural language processing (NLP), especially in domains where labeled data are scarce or expensive, such as the clinical domain. However, to unlock the clinical knowledge hidden in these LLMs, we need to design effective prompts that can guide them to perform specific clinical NLP tasks without any task-specific training data. This is known as in-context learning, which is an art and science that requires understanding the strengths and weaknesses of different LLMs and prompt engineering approaches. Objective The objective of this study is to assess the effectiveness of various prompt engineering techniques, including 2 newly introduced types—heuristic and ensemble prompts, for zero-shot and few-shot clinical information extraction using pretrained language models. Methods This comprehensive experimental study evaluated different prompt types (simple prefix, simple cloze, chain of thought, anticipatory, heuristic, and ensemble) across 5 clinical NLP tasks: clinical sense disambiguation, biomedical evidence extraction, coreference resolution, medication status extraction, and medication attribute extraction. The performance of these prompts was assessed using 3 state-of-the-art language models: GPT-3.5 (OpenAI), Gemini (Google), and LLaMA-2 (Meta). The study contrasted zero-shot with few-shot prompting and explored the effectiveness of ensemble approaches. Results The study revealed that task-specific prompt tailoring is vital for the high performance of LLMs for zero-shot clinical NLP. In clinical sense disambiguation, GPT-3.5 achieved an accuracy of 0.96 with heuristic prompts and 0.94 in biomedical evidence extraction. Heuristic prompts, alongside chain of thought prompts, were highly effective across tasks. Few-shot prompting improved performance in complex scenarios, and ensemble approaches capitalized on multiple prompt strengths. GPT-3.5 consistently outperformed Gemini and LLaMA-2 across tasks and prompt types. Conclusions This study provides a rigorous evaluation of prompt engineering methodologies and introduces innovative techniques for clinical information extraction, demonstrating the potential of in-context learning in the clinical domain. These findings offer clear guidelines for future prompt-based clinical NLP research, facilitating engagement by non-NLP experts in clinical NLP advancements. To the best of our knowledge, this is one of the first works on the empirical evaluation of different prompt engineering approaches for clinical NLP in this era of generative artificial intelligence, and we hope that it will inspire and inform future research in this area.","['in-context learning', 'few-shot prompting', 'zero-shot prompting']"
2024,https://openalex.org/W4397001018,Biology,A systematic review of hyperspectral imaging in precision agriculture: Analysis of its current state and future prospects,"Hyperspectral sensor adaptability in precision agriculture to digital images is still at its nascent stage. Hyperspectral imaging (HSI) is data rich in solving agricultural problems like disease detection, weed detection, stress detection, crop monitoring, nutrient application, soil mineralogy, yield estimation, and sorting applications. With modern precision agriculture, the challenge now is to bring these applications to the field for real-time solutions, where machines are enabled to conduct analyses without expert supervision and communicate the results to users for better management of farmlands; a necessary step to gain complete autonomy in agricultural farmlands. Significant advancements in HSI technology for precision agriculture are required to fully realize its potential. As a wide-ranging collection of the status of HSI and analysis in precision agriculture is lacking, this review endeavors to provide a comprehensive overview of the recent advancements and trends of HSI in precision agriculture for real-time applications. In this study, a systematic review of 163 scientific articles published over the past twenty years (2003–2023) was conducted. Of these, 97 were selected for further analysis based on their relevance to the topic at hand. Topics include conventional data preprocessing techniques, hyperspectral data acquisition, data compression methods, and segmentation methods. The hardware implementation of field-programmable gate arrays (FPGAs) and graphics processing units (GPUs) for high-speed data processing and application of machine learning and deep learning technologies were explored. This review highlights the potential of HSI as a powerful tool for precision agriculture, particularly in real-time applications, discusses limitations, and provides insights into future research directions.","['machine learning', 'deep learning']"
2024,https://openalex.org/W4390597725,Biology,Critical review on water quality analysis using IoT and machine learning models,"Water quality and its management are the most precise concerns confronting humanity globally. This article evaluates the various sensors used for water quality monitoring and focuses on the water quality index considering the multiple physical, chemical, and biological parameters. A Review of Internet of Things (IoT) research for water quality monitoring and analysis, sensors used for water quality can help remote monitoring of the water quality parameters using various IoT-based sensors that convey the assembled estimations utilizing Low-Power Wide Area Network innovations. Overall, the IoT system was 95 % accurate in measuring pH, Turbidity, TDS, and Temperature, while the traditional method was only 85 % accurate. Also, this study reviewed the different A.I. techniques used to assess water quality, including conventional machine learning techniques, Support Vector Machines, Deep Neural Networks, and K-nearest neighbors. Compared to traditional methods, machine learning and deep learning can significantly increase the accuracy of measurements of groundwater quality. However, various variables, such as the caliber of the training data, the water quality metrics' complexity, and the monitoring frequency, will affect the accuracy. The geographical information system (GIS) is used for spatial data analysis and managing water resources. The quality of its data is also reviewed in the paper. Based on these analyses, the study has forecasted the future sensors, Geospatial Technology, and machine learning techniques for water quality monitoring and analysis.","['Support Vector Machines', 'Deep Neural Networks', 'K-nearest neighbors']"
2024,https://openalex.org/W4391332961,Biology,A novel framework for developing environmentally sustainable and cost-effective ultra-high-performance concrete (UHPC) using advanced machine learning and multi-objective optimization techniques,"This study aims to propose a novel framework for strength prediction and multi-objective optimization (MOO) of economical and environmentally sustainable ultra-high-performance concrete (UHPC) which aids in intelligent, sustainable, and resilient construction. Different tree- and boosting ensemble-based machine learning (ML) models are integrated to form an accurate and reliable prediction model for the uniaxial compressive strength of UHPC. The optimized models are integrated into a super learner model, resulting in a robust predictive model that is used as one of the objective functions in the MOO problem. A total of 19 objective functions are considered, including cost, uniaxial compressive strength, and 17 environmental impact categories that comprehensively evaluate the environmental sustainability of the UHPC mix. The resulting impacts from the mid-point indicators were calculated using the Eco-invent v3.7 Life Cycle Inventory database. The results showed that the super learner model accurately predicted the uniaxial compressive strength of UHPC. The MOO resulted in Pareto fronts, demonstrating the trade-off among the uniaxial compressive strength, cost, and environmental sustainability of the mix and a broad range of solutions that can be obtained for the 19 objectives. The study provides a useful tool for designers and decision-makers to select the optimal UHPC mixture that meets specific project requirements. Finally, for the practical application of the ML predictive model and MOO algorithm for UHPC, a graphical user interface-based software tool, FAI-OSUSCONCRET, was developed. This software tool offers fast, accurate, and intelligent predictions and multi-objective optimizations tailored to specific project requirements, thus resulting in a UHPC mixture that perfectly meets project needs.","['tree-based ensemble machine learning models', 'boosting ensemble-based machine learning models', 'super learner model']"
2024,https://openalex.org/W4391168980,Biology,Utilizing Hybrid Machine Learning and Soft Computing Techniques for Landslide Susceptibility Mapping in a Drainage Basin,"The hydrological system of thebasin of Lake Urmia is complex, deriving its supply from a network comprising 13 perennial rivers, along withnumerous small springs and direct precipitation onto the lake’s surface. Among these contributors, approximately half of the inflow is attributed to the Zarrineh River and the Simineh River. Remarkably, Lake Urmia lacks a natural outlet, with its water loss occurring solely through evaporation processes. This study employed a comprehensive methodology integrating ground surveys, remote sensing analyses, and meticulous documentation of historical landslides within the basin as primary information sources. Through this investigative approach, we preciselyidentified and geolocated a total of 512 historical landslide occurrences across the Urmia Lake drainage basin, leveraging GPS technology for precision. Thisarticle introduces a suite of hybrid machine learning predictive models, such as support-vector machine (SVM), random forest (RF), decision trees (DT), logistic regression (LR), fuzzy logic (FL), and the technique for order of preference by similarity to the ideal solution (TOPSIS). These models were strategically deployed to assess landslide susceptibility within the region. The outcomes of the landslide susceptibility assessment reveal that the main high susceptible zones for landslide occurrence are concentrated in the northwestern, northern, northeastern, and some southern and southeastern areas of the region. Moreover, when considering the implementation of predictions using different algorithms, it became evident that SVM exhibited superior performance regardingboth accuracy (0.89) and precision (0.89), followed by RF, with and accuracy of 0.83 and a precision of 0.83. However, it is noteworthy that TOPSIS yielded the lowest accuracy value among the algorithms assessed.","['support-vector machine (SVM)', 'random forest (RF)', 'decision trees (DT)', 'logistic regression (LR)']"
2024,https://openalex.org/W4391831565,Biology,Comparison of Random Forest and XGBoost Classifiers Using Integrated Optical and SAR Features for Mapping Urban Impervious Surface,"The integration of optical and SAR datasets through ensemble machine learning models shows promising results in urban remote sensing applications. The integration of multi-sensor datasets enhances the accuracy of information extraction. This research presents a comparison of two ensemble machine learning classifiers (random forest and extreme gradient boost (XGBoost)) classifiers using an integration of optical and SAR features and simple layer stacking (SLS) techniques. Therefore, Sentinel-1 (SAR) and Landsat 8 (optical) datasets were used with SAR textures and enhanced modified indices to extract features for the year 2023. The classification process utilized two machine learning algorithms, random forest and XGBoost, for urban impervious surface extraction. The study focused on three significant East Asian cities with diverse urban dynamics: Jakarta, Manila, and Seoul. This research proposed a novel index called the Normalized Blue Water Index (NBWI), which distinguishes water from other features and was utilized as an optical feature. Results showed an overall accuracy of 81% for UIS classification using XGBoost and 77% with RF while classifying land use land cover into four major classes (water, vegetation, bare soil, and urban impervious). However, the proposed framework with the XGBoost classifier outperformed the RF algorithm and Dynamic World (DW) data product and comparatively showed higher classification accuracy. Still, all three results show poor separability with bare soil class compared to ground truth data. XGBoost outperformed random forest and Dynamic World in classification accuracy, highlighting its potential use in urban remote sensing applications.","['ensemble machine learning models', 'random forest', 'extreme gradient boost (XGBoost)']"
2024,https://openalex.org/W4391037822,Biology,Estimating compressive strength of concrete containing rice husk ash using interpretable machine learning-based models,"The construction sector is a major contributor to global greenhouse gas emissions. Using recycled and waste materials in concrete is a practical solution to address environmental challenges. Currently, agricultural waste is widely used as a substitute for cement in the production of eco-friendly concrete. However, traditional methods for assessing the strength of such materials are both expensive and time-consuming. Therefore, this study uses machine learning techniques to develop prediction models for the compressive strength (CS) of rice husk ash (RHA) concrete. The ML techniques used in the present study include random forest (RF), light gradient boosting machine (LightGBM), ridge regression, and extreme gradient boosting (XGBoost). A total of 348 values of CS were collected from the experimental studies, and five characteristics of RHA concrete were taken as input variables. For the performance assessment of the models, multiple statistical metrics were used. During the training phase, the correlation coefficients (R) obtained for ridge regression, RF, XGBoost, and LightGBM were 0.943, 0.981, 0.985, and 0.996, respectively. In the testing set, these values demonstrated even higher performance, with correlation coefficients of 0.971, 0.993, 0.992, and 0.998 for ridge regression, RF, XGBoost, and LightGBM, respectively. The statistical analysis revealed that the LightGBM model outperformed other models, whereas the ridge regression model exhibited comparatively lower accuracy. SHapley Additive exPlanation (SHAP) method was employed for the interpretability of the developed model. The SHAP analysis revealed that water-to-cement is a controlling parameter in estimating the CS of RHA concrete. In conclusion, this study provides valuable guidance for builders and researchers to estimate the CS of RHA concrete. However, it is suggested that more input variables be incorporated and hybrid models utilized to further enhance the reliability and precision of the models.","['random forest (RF)', 'light gradient boosting machine (LightGBM)', 'ridge regression', 'extreme gradient boosting (XGBoost)', 'SHapley Additive exPlanation (SHAP)']"
2024,https://openalex.org/W4393012885,Biology,Improving Thyroid Disorder Diagnosis via Ensemble Stacking and Bidirectional Feature Selection,"Thyroid disorders represent a significant global health challenge with hypothyroidism and hyperthyroidism as two common conditions arising from dysfunction in the thyroid gland.Accurate and timely diagnosis of these disorders is crucial for effective treatment and patient care.This research introduces a comprehensive approach to improve the accuracy of thyroid disorder diagnosis through the integration of ensemble stacking and advanced feature selection techniques.Sequential forward feature selection, sequential backward feature elimination, and bidirectional feature elimination are investigated in this study.In ensemble learning, random forest, adaptive boosting, and bagging classifiers are employed.The effectiveness of these techniques is evaluated using two different datasets obtained from the University of California Irvine-Machine Learning Repository, both of which undergo preprocessing steps, including outlier removal, addressing missing data, data cleansing, and feature reduction.Extensive experimentation demonstrates the remarkable success of proposed ensemble stacking and bidirectional feature elimination achieving 100% and 99.86% accuracy in identifying hyperthyroidism and hypothyroidism, respectively.Beyond enhancing detection accuracy, the ensemble stacking model also demonstrated a streamlined computational complexity which is pivotal for practical medical applications.It significantly outperformed existing studies with similar objectives underscoring the viability and effectiveness of the proposed scheme.This research offers an innovative perspective and sets the platform for improved thyroid disorder diagnosis with broader implications for healthcare and patient well-being.","['ensemble stacking', 'sequential forward feature selection', 'sequential backward feature elimination', 'random forest', 'adaptive boosting', 'bagging classifiers']"
2024,https://openalex.org/W4390738897,Biology,Enhancing crop recommendation systems with explainable artificial intelligence: a study on agricultural decision-making,"Abstract Crop Recommendation Systems are invaluable tools for farmers, assisting them in making informed decisions about crop selection to optimize yields. These systems leverage a wealth of data, including soil characteristics, historical crop performance, and prevailing weather patterns, to provide personalized recommendations. In response to the growing demand for transparency and interpretability in agricultural decision-making, this study introduces XAI-CROP an innovative algorithm that harnesses eXplainable artificial intelligence (XAI) principles. The fundamental objective of XAI-CROP is to empower farmers with comprehensible insights into the recommendation process, surpassing the opaque nature of conventional machine learning models. The study rigorously compares XAI-CROP with prominent machine learning models, including Gradient Boosting (GB), Decision Tree (DT), Random Forest (RF), Gaussian Naïve Bayes (GNB), and Multimodal Naïve Bayes (MNB). Performance evaluation employs three essential metrics: Mean Squared Error (MSE), Mean Absolute Error (MAE), and R-squared (R2). The empirical results unequivocally establish the superior performance of XAI-CROP. It achieves an impressively low MSE of 0.9412, indicating highly accurate crop yield predictions. Moreover, with an MAE of 0.9874, XAI-CROP consistently maintains errors below the critical threshold of 1, reinforcing its reliability. The robust R 2 value of 0.94152 underscores XAI-CROP's ability to explain 94.15% of the data's variability, highlighting its interpretability and explanatory power.","['Gradient Boosting (GB)', 'Decision Tree (DT)', 'Random Forest (RF)', 'Gaussian Naïve Bayes (GNB)']"
2024,https://openalex.org/W4391783116,Biology,Assessing water quality of an ecologically critical urban canal incorporating machine learning approaches,"This study assessed water quality (WQ) in Tongi Canal, an ecologically critical and economically important urban canal in Bangladesh. The researchers employed the Root Mean Square Water Quality Index (RMS-WQI) model, utilizing seven WQ indicators, including temperature, dissolve oxygen, electrical conductivity, lead, cadmium, and iron to calculate the water quality index (WQI) score. The results showed that most of the water sampling locations showed poor WQ, with many indicators violating Bangladesh's environmental conservation regulations. This study employed eight machine learning algorithms, where the Gaussian process regression (GPR) model demonstrated superior performance (training RMSE = 1.77, testing RMSE = 0.0006) in predicting WQI scores. To validate the GPR model's performance, several performance measures, including the coefficient of determination (R2), the Nash-Sutcliffe efficiency (NSE), the model efficiency factor (MEF), Z statistics, and Taylor diagram analysis, were employed. The GPR model exhibited higher sensitivity (R2 = 1.0) and efficiency (NSE = 1.0, MEF = 0.0) in predicting WQ. The analysis of model uncertainty (standard uncertainty = 7.08 ± 0.9025; expanded uncertainty = 7.08 ± 1.846) indicates that the RMS-WQI model holds potential for assessing the WQ of inland waterbodies. These findings indicate that the RMS-WQI model could be an effective approach for assessing inland waters across Bangladesh. The study's results showed that most of the WQ indicators did not meet the recommended guidelines, indicating that the water in the Tongi Canal is unsafe and unsuitable for various purposes. The study's implications extend beyond the Tongi Canal and could contribute to WQ management initiatives across Bangladesh.",['Gaussian process regression (GPR)']
2024,https://openalex.org/W4392454900,Biology,Compressive strength prediction of sustainable concrete incorporating rice husk ash (RHA) using hybrid machine learning algorithms and parametric analyses,"The construction industry is making efforts to reduce the environmental impact of cement production in concrete by incorporating alternative and supplementary cementitious materials, as well as lowering carbon emissions. One such material that has gained popularity in this context is rice husk ash (RHA) due to its pozzolanic reactions. This study aims to forecast the compressive strength (CS) of RHA-based concrete (RBC) by examining the effects of several factors such as cement, RHA content, curing age, water usage, aggregate amount, and superplasticizer content. To accomplish this, the study collected and analyzed data from literature, resulting in a dataset of 1404 observations. Several machine learning (ML) models, such as light gradient boosting (LGB), extreme gradient boosting (XGB), and random forest (RF), as well as hybrid machine learning (HML) approaches like XGB-LGB and XGB-RF were employed to thoroughly analyze these parameters and assess their impact on strength. The dataset was split into training and testing groups, and statistical analyses were performed to determine the relationships between the input parameters and CS. Moreover, the performance of all the models was evaluated using various statistical evaluation criteria, including mean absolute percentage error (MAPE), coefficient of efficiency (CE), root mean square error (RMSE), and coefficient of determination (R2). The hybrid XGB-LGB model was found to have higher precision (R2 = 0.95, and RMSE = 5.255 MPa) as compared to other models. SHAP (SHapley Additive exPlanations) analysis revealed that cement, RHA, and superplasticizer had a positive effect on strength. Overall, the study's findings suggest that the hybrid XGB-LGB model with the identified input parameters can be used to accurately predict the CS of RBC. The application of such technologies in the construction sector can facilitate the rapid and low-cost identification of material qualities and the impact of input parameters.","['light gradient boosting (LGB)', 'extreme gradient boosting (XGB)', 'random forest (RF)']"
2024,https://openalex.org/W4392131696,Biology,"Assessing Chilgoza Pine (Pinus gerardiana) forest fire severity: Remote sensing analysis, correlations, and predictive modeling for enhanced management strategies","Forest fires represent a critical global threat to both humans and ecosystems. This study examines the intensity and impacts of Chilgoza (Pinus gerardiana) Pine Forest fires by using advanced remote sensing techniques comprising Normalized Burn Ratio (NBR) and Difference Normalized Burn Ratio (dNBR) analyses based on Landsat 9 datasets. The study highlights the severe effect of these fires, resulting in noteworthy losses of livestock and private properties and widespread damage to 10,156.53 acres of the Chilgoza Pine Forest. A comprehensive variable correlation analysis is conducted to gain deeper insights into the influencing factors causing forest fires. Spearman's Rank Correlation Coefficient was used to assess the association between burnt and unburnt areas and various independent factors. The analysis reveals compelling evidence of significant correlations with forest fire prevalence. This study found moderate negative (-0.532, p < 0.05) and positive (0.513, p < 0.05) correlations with elevation and Land Surface Temperature (LST), respectively, and a weak positive correlation (0.252, p < 0.05) with a Wind Speed (V). To predict forest fire susceptibility and better understand the contributing factors, three machine learning models, Random Forest (RF), XGBoost, and logistic regression, are applied to assess variable importance scores. Among the considered factors, LST is the most critical variable, with consistently high variable importance scores (100%, 96%, and 59%) across all three models. Wind Speed (V) also proved influential in all models, with variable importance scores of 78%, 83%, and 61% for RF, XGBoost, and logistic regression, respectively. Moreover, elevation significantly influences the frequency of forest fires, as evidenced by variable importance scores ranging from 26% to 100%. Comparatively, the Random Forest model outperforms XGBoost and Logistic Regression in predicting forest fire vulnerability. During the training stage, the Random Forest (RF) model achieves an impressive classification accuracy of 99.1%, followed by XGBoost with 94.5% and Logistic Regression with 85.6%. On evaluation with the validation dataset, the accuracies remain promising, with RF at 96.4%, XGBoost at 91.1%, and Logistic Regression at 84.6%. Based on the Random Forest model, the identified high-risk sites offer valuable insights for proactive fire management and prevention strategies. This study provides a robust predictive model and a comprehensive understanding of forest fire severity and impacts. Future research should consider climate change scenarios and account for human activities to enhance fire behavior predictions and risk assessment models.","['Random Forest (RF)', 'XGBoost', 'logistic regression']"
2024,https://openalex.org/W4390659289,Biology,Cognition-Driven Structural Prior for Instance-Dependent Label Transition Matrix Estimation,"The label transition matrix has emerged as a widely accepted method for mitigating label noise in machine learning. In recent years, numerous studies have centered on leveraging deep neural networks to estimate the label transition matrix for individual instances within the context of instance-dependent noise. However, these methods suffer from low search efficiency due to the large space of feasible solutions. Behind this drawback, we have explored that the real murderer lies in the invalid class transitions, that is, the actual transition probability between certain classes is zero but is estimated to have a certain value. To mask the <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">invalid class transitions</i> , we introduced a human-cognition-assisted method with structural information from human cognition. Specifically, we introduce a structured transition matrix network ( <bold xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">STMN</b> ) designed with an adversarial learning process to balance instance features and prior information from human cognition. The proposed method offers two advantages: 1) better estimation effectiveness is obtained by sparing the transition matrix and 2) better estimation accuracy is obtained with the assistance of human cognition. By exploiting these two advantages, our method parametrically estimates a sparse label transition matrix, effectively converting noisy labels into true labels. The efficiency and superiority of our proposed method are substantiated through comprehensive comparisons with state-of-the-art methods on three synthetic datasets and a real-world dataset. Our code will be available at https://github.com/WheatCao/STMN-Pytorch.","['deep neural networks', 'adversarial learning process']"
2024,https://openalex.org/W4392980686,Biology,Data-driven evolution of water quality models: An in-depth investigation of innovative outlier detection approaches-A case study of Irish Water Quality Index (IEWQI) model,"Recently, there has been a significant advancement in the water quality index (WQI) models utilizing data-driven approaches, especially those integrating machine learning and artificial intelligence (ML/AI) technology. Although, several recent studies have revealed that the data-driven model has produced inconsistent results due to the data outliers, which significantly impact model reliability and accuracy. The present study was carried out to assess the impact of data outliers on a recently developed Irish Water Quality Index (IEWQI) model, which relies on data-driven techniques. To the author's best knowledge, there has been no systematic framework for evaluating the influence of data outliers on such models. For the purposes of assessing the outlier impact of the data outliers on the water quality (WQ) model, this was the first initiative in research to introduce a comprehensive approach that combines machine learning with advanced statistical techniques. The proposed framework was implemented in Cork Harbour, Ireland, to evaluate the IEWQI model's sensitivity to outliers in input indicators to assess the water quality. In order to detect the data outlier, the study utilized two widely used ML techniques, including Isolation Forest (IF) and Kernel Density Estimation (KDE) within the dataset, for predicting WQ with and without these outliers. For validating the ML results, the study used five commonly used statistical measures. The performance metric (R2) indicates that the model performance improved slightly (R2 increased from 0.92 to 0.95) in predicting WQ after removing the data outlier from the input. But the IEWQI scores revealed that there were no statistically significant differences among the actual values, predictions with outliers, and predictions without outliers, with a 95% confidence interval at p < 0.05. The results of model uncertainty also revealed that the model contributed <1% uncertainty to the final assessment results for using both datasets (with and without outliers). In addition, all statistical measures indicated that the ML techniques provided reliable results that can be utilized for detecting outliers and their impacts on the IEWQI model. The findings of the research reveal that although the data outliers had no significant impact on the IEWQI model architecture, they had moderate impacts on the rating schemes' of the model. This finding indicated that detecting the data outliers could improve the accuracy of the IEWQI model in rating WQ as well as be helpful in mitigating the model eclipsing problem. In addition, the results of the research provide evidence of how the data outliers influenced the data-driven model in predicting WQ and reliability, particularly since the study confirmed that the IEWQI model's could be effective for accurately rating WQ despite the presence of the data outliers in the input. It could occur due to the spatio-temporal variability inherent in WQ indicators. However, the research assesses the influence of data input outliers on the IEWQI model and underscores important areas for future investigation. These areas include expanding temporal analysis using multi-year data, examining spatial outlier patterns, and evaluating detection methods. Moreover, it is essential to explore the real-world impacts of revised rating categories, involve stakeholders in outlier management, and fine-tune model parameters. Analysing model performance across varying temporal and spatial resolutions and incorporating additional environmental data can significantly enhance the accuracy of WQ assessment. Consequently, this study offers valuable insights to strengthen the IEWQI model's robustness and provides avenues for enhancing its utility in broader WQ assessment applications. Moreover, the study successfully adopted the framework for evaluating how data input outliers affect the data-driven model, such as the IEWQI model. The current study has been carried out in Cork Harbour for only a single year of WQ data. The framework should be tested across various domains for evaluating the response of the IEWQI model's in terms of the spatio-temporal resolution of the domain. Nevertheless, the study recommended that future research should be conducted to adjust or revise the IEWQI model's rating schemes and investigate the practical effects of data outliers on updated rating categories. However, the study provides potential recommendations for enhancing the IEWQI model's adaptability and reveals its effectiveness in expanding its applicability in more general WQ assessment scenarios.",['Isolation Forest (IF)']
2024,https://openalex.org/W4391235397,Biology,Real-Time Plant Disease Dataset Development and Detection of Plant Disease Using Deep Learning,"Agriculture plays a significant role in meeting food needs and providing food security for the increasingly growing global population, which has increased by 0.88% since 2022. Plant diseases can reduce food production and affect food security. Worldwide crop loss due to plant disease is estimated to be around 14.1%. The lack of proper identification of plant disease at the early stages of infection can result in inappropriate disease control measures. Therefore, the automatic identification and diagnosis of plant diseases are highly recommended. Lack of availability of large amounts of data that are not processed to a large extent is one of the main challenges in plant disease diagnosis. In the current manuscript, we developed datasets for food grains specifically for rice, wheat, and maize to address the identified challenges. The developed datasets consider the common diseases (two bacterial diseases and two fungal diseases of rice, four fungal diseases of maize, and four fungal diseases of wheat) that affect crop yields and cause damage to the whole plant. The datasets developed were applied to eight fine-tuned deep learning models with the same training hyperparameters. The experimental results based on eight fine-tuned deep learning models show that, while recognizing maize leaf diseases, the models Xception and MobileNet performed best with a testing accuracy of 0.9580 and 0.9464 respectively. Similarly, while recognizing the wheat leaf diseases, the models MobileNetV2 and MobileNet performed best with a testing accuracy of 0.9632 and 0.9628 respectively. The Xception and Inception V3 models performed best, with a testing accuracy of 0.9728 and 0.9620, respectively, for recognizing rice leaf diseases. The research also proposes a new convolutional neural network (CNN) model trained from scratch on all three food grain datasets developed. The proposed model performs well and shows a testing accuracy of 0.9704, 0.9706, and 0.9808 respectively on the maize, rice, and wheat datasets.","['fine-tuned deep learning models', 'Xception', 'MobileNet', 'MobileNetV2', 'Inception V3', 'convolutional neural network (CNN) model trained from scratch']"
2024,https://openalex.org/W4396494945,Biology,Vision–language foundation model for echocardiogram interpretation,"Abstract The development of robust artificial intelligence models for echocardiography has been limited by the availability of annotated clinical data. Here, to address this challenge and improve the performance of cardiac imaging models, we developed EchoCLIP, a vision–language foundation model for echocardiography, that learns the relationship between cardiac ultrasound images and the interpretations of expert cardiologists across a wide range of patients and indications for imaging. After training on 1,032,975 cardiac ultrasound videos and corresponding expert text, EchoCLIP performs well on a diverse range of benchmarks for cardiac image interpretation, despite not having been explicitly trained for individual interpretation tasks. EchoCLIP can assess cardiac function (mean absolute error of 7.1% when predicting left ventricular ejection fraction in an external validation dataset) and identify implanted intracardiac devices (area under the curve (AUC) of 0.84, 0.92 and 0.97 for pacemakers, percutaneous mitral valve repair and artificial aortic valves, respectively). We also developed a long-context variant (EchoCLIP-R) using a custom tokenizer based on common echocardiography concepts. EchoCLIP-R accurately identified unique patients across multiple videos (AUC of 0.86), identified clinical transitions such as heart transplants (AUC of 0.79) and cardiac surgery (AUC 0.77) and enabled robust image-to-text search (mean cross-modal retrieval rank in the top 1% of candidate text reports). These capabilities represent a substantial step toward understanding and applying foundation models in cardiovascular imaging for preliminary interpretation of echocardiographic findings.",['vision–language foundation model']
2024,https://openalex.org/W4391855187,Biology,Machine learning-assisted in-situ adaptive strategies for the control of defects and anomalies in metal additive manufacturing,"In metal additive manufacturing (AM), the material microstructure and part geometry are formed incrementally. Consequently, the resulting part could be defect- and anomaly-free if sufficient care is taken to deposit each layer under optimal process conditions. Conventional closed-loop control (CLC) engineering solutions which sought to achieve this were deterministic and rule-based, thus resulting in limited success in the stochastic environment experienced in the highly dynamic AM process. On the other hand, emerging machine learning (ML) based strategies are better suited to providing the robustness, scope, flexibility, and scalability required for process control in an uncertain environment. Offline ML models that help optimise AM process parameters before a build begins and online ML models that efficiently processed in-situ sensory data to detect and diagnose flaws in real-time (or near-real-time) have been developed. However, ML models that enable a process to take evasive or corrective actions in relation to flaws via on the fly decision-making are only emerging. These models must possess prognostic capabilities to provide context-sensitive recommendations for in-situ process control based on real-time diagnostics. In this article, we pinpoint the shortcomings in traditional CLC strategies, and provide a framework for defect and anomaly control through ML-assisted CLC in AM. We discuss flaws in terms of their causes, in-situ detectability, and controllability, and examine their management under three scenarios: avoidance, mitigation, and repair. Then, we summarise the research into ML models developed for offline optimisation and in-situ diagnosis before initiating a detailed conversation on the implementation of ML-assisted in-situ process control. We found that researchers favoured reinforcement learning approaches or inverse ML models for making rapid, situation-aware control decisions. We also observed that, to-date, the defects addressed were those that may be quantified relatively easily autonomously, and that mitigation (rather than avoidance or repair) was the aim of ML-assisted in-situ control strategies. Additionally, we highlight the various technologies that must seamlessly combine to advance the field of autonomous in-situ control so that it becomes a reality in industrial settings. Finally, we raise awareness of seldom discussed, yet highly pertinent, topics relevant to adaptive control. Our work closes a significant gap in the current AM literature by broaching wide-ranging discussions on matters relevant to in-situ adaptive control in AM.","['online ML models', 'reinforcement learning approaches']"
2024,https://openalex.org/W4392640075,Biology,Performance assessment of machine learning algorithms for mapping of land use/land cover using remote sensing data,"The rapid increase in population accelerates the rate of change of Land use/Land cover (LULC) in various parts of the world. This phenomenon caused a huge strain for natural resources. Hence, continues monitoring of LULC changes gained a significant importance for management of natural resources and assessing the climate change impacts. Recently, application of machine learning algorithms on RS (remote sensing) data for rapid and accurate mapping of LULC gained significant importance due to growing need of LULC estimation for ecosystem services, natural resource management and environmental management. Hence, it is crucial to access and compare the performance of different machine learning classifiers for accurate mapping of LULC. The primary objective of this study was to compare the performance of CART (Classification and Regression Tree), RF (Random Forest) and SVM (Support Vector Machine) for LULC estimation by processing RS data on Google Earth Engine (GEE). In total four classes of LULC (Water Bodies, Vegetation Cover, Urban Land and Barren Land) for city of Lahore were extracted using satellite images from Landsat-7, Landsat-8 and Landsat-9 for years 2008, 2015 and 2022, respectively. According to results, RF is the best performing classifier with maximum overall accuracy of 95.2% and highest Kappa coefficient value of 0.87, SVM achieved maximum accuracy of 89.8% with highest Kappa of 0.84 and CART showed maximum overall accuracy of 89.7% with Kappa value of 0.79. Results from this study can give assistance for decision makers, planners and RS experts to choose a suitable machine learning algorithm for LULC classification in an unplanned urbanized city like Lahore.","['Classification and Regression Tree (CART)', 'Random Forest (RF)', 'Support Vector Machine (SVM)']"
2024,https://openalex.org/W4390754233,Biology,Groundwater Quality Assessment and Irrigation Water Quality Index Prediction Using Machine Learning Algorithms,"The evaluation of groundwater quality is crucial for irrigation purposes; however, due to financial constraints in developing countries, such evaluations suffer from insufficient sampling frequency, hindering comprehensive assessments. Therefore, associated with machine learning approaches and the irrigation water quality index (IWQI), this research aims to evaluate the groundwater quality in Naama, a region in southwest Algeria. Hydrochemical parameters (cations, anions, pH, and EC), qualitative indices (SAR,RSC,Na%,MH,and PI), as well as geospatial representations were used to determine the groundwater’s suitability for irrigation in the study area. In addition, efficient machine learning approaches for forecasting IWQI utilizing Extreme Gradient Boosting (XGBoost), Support vector regression (SVR), and K-Nearest Neighbours (KNN) models were implemented. In this research, 166 groundwater samples were used to calculate the irrigation index. The results showed that 42.18% of them were of excellent quality, 34.34% were of very good quality, 6.63% were good quality, 9.64% were satisfactory, and 4.21% were considered unsuitable for irrigation. On the other hand, results indicate that XGBoost excels in accuracy and stability, with a low RMSE (of 2.8272 and a high R of 0.9834. SVR with only four inputs (Ca2+, Mg2+, Na+, and K) demonstrates a notable predictive capability with a low RMSE of 2.6925 and a high R of 0.98738, while KNN showcases robust performance. The distinctions between these models have important implications for making informed decisions in agricultural water management and resource allocation within the region.","['Extreme Gradient Boosting (XGBoost)', 'Support vector regression (SVR)', 'K-Nearest Neighbours (KNN)']"
2024,https://openalex.org/W4391347933,Biology,CCL-DTI: contributing the contrastive loss in drug–target interaction prediction,"Abstract Background The Drug–Target Interaction (DTI) prediction uses a drug molecule and a protein sequence as inputs to predict the binding affinity value. In recent years, deep learning-based models have gotten more attention. These methods have two modules: the feature extraction module and the task prediction module. In most deep learning-based approaches, a simple task prediction loss (i.e., categorical cross entropy for the classification task and mean squared error for the regression task) is used to learn the model. In machine learning, contrastive-based loss functions are developed to learn more discriminative feature space. In a deep learning-based model, extracting more discriminative feature space leads to performance improvement for the task prediction module. Results In this paper, we have used multimodal knowledge as input and proposed an attention-based fusion technique to combine this knowledge. Also, we investigate how utilizing contrastive loss function along the task prediction loss could help the approach to learn a more powerful model. Four contrastive loss functions are considered: (1) max-margin contrastive loss function, (2) triplet loss function, (3) Multi-class N-pair Loss Objective, and (4) NT-Xent loss function. The proposed model is evaluated using four well-known datasets: Wang et al. dataset, Luo's dataset, Davis, and KIBA datasets. Conclusions Accordingly, after reviewing the state-of-the-art methods, we developed a multimodal feature extraction network by combining protein sequences and drug molecules, along with protein–protein interaction networks and drug–drug interaction networks. The results show it performs significantly better than the comparable state-of-the-art approaches.","['contrastive loss function', 'max-margin contrastive loss function', 'triplet loss function', 'Multi-class N-pair Loss Objective', 'NT-Xent loss function']"
2024,https://openalex.org/W4391248672,Biology,Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning,"Recent development in computing power has resulted in performance improvements on holistic(none-occluded) person Re-Identification (ReID) tasks. Nevertheless, the precision of the recent research will diminish when a pedestrian is obstructed by obstacles. Within the realm of 2D space, the loss of information from obstructed objects continues to pose significant challenges in the context of person ReID. Person is a 3D non-grid object, and thus semantic representation learning in only 2D space limits the understanding of occluded person. In the present work, we propose a network based on 3D multi-view learning, allowing it to acquire geometric and shape details of an occluded pedestrian from 3D space. Simultaneously, it capitalizes on advancements in 2D-based networks to extract semantic representations from 3D multi-views. Specifically, the surface random selection strategy is proposed to convert images of 2D RGB into 3D multi-views. Using this strategy, we build four extensive 3D multi-view data collections for person ReID. After that, Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning(MV-3DSReID), is proposed for identifying the person by learning person geometry and structure representation from the groups of multi-view images. In comparison to alternative data formats (e.g., 2D RGB, 3D point cloud), multi-view images complement each other's detailed features of the 3D object by adjusting rendering viewpoints, thus facilitating a more comprehensive understanding of the person for both holistic and occluded ReID situations. Experiments on occluded and holistic ReID tasks demonstrate performance levels comparable to state-of-the-art methods, validating the effectiveness of our proposed approach in tackling challenges related to occlusion. The code is available at https://github.com/hangjiaqi1/MV-TransReID.",['3D multi-view learning']
2024,https://openalex.org/W4394822945,Biology,A Critical Review of Artificial Intelligence Based Approaches in Intrusion Detection: A Comprehensive Analysis,"Intrusion detection (ID) is critical in securing computer networks against various malicious attacks. Recent advancements in machine learning (ML), deep learning (DL), federated learning (FL), and explainable artificial intelligence (XAI) have drawn significant attention as potential approaches for ID. DL-based approaches have shown impressive performance in ID by automatically learning relevant features from data but require significant labelled data and computational resources to train complex models. ML-based approaches require fewer computational resources and labelled data, but their ability to generalize to unseen data is limited. FL is a relatively new approach that enables multiple entities to train a model collectively without exchanging their data, providing privacy and security benefits, making it an attractive option for ID. However, FL-based approaches require more communication resources and additional computation to aggregate models from different entities. XAI is critical for understanding how AI models make decisions, improving interpretability and transparency. While existing literature has explored the strengths and weaknesses of DL, ML, FL, and XAI-based approaches for ID, a significant gap exists in providing a comprehensive analysis of the specific use cases and scenarios where each approach is most suitable. This paper seeks to fill this void by delivering an in-depth review that not only highlights strengths and weaknesses but also offers guidance for selecting the appropriate approach based on the unique ID context and available resources. The selection of an appropriate approach depends on the specific use case, and this work provides insights into which method is best suited for various network sizes, data availability, privacy, and security concerns, thus aiding practitioners in making informed decisions for their ID needs.","['machine learning (ML)', 'deep learning (DL)', 'federated learning (FL)']"
2024,https://openalex.org/W4395011414,Biology,"admetSAR3.0: a comprehensive platform for exploration, prediction and optimization of chemical ADMET properties","Abstract Absorption, distribution, metabolism, excretion and toxicity (ADMET) properties play a crucial role in drug discovery and chemical safety assessment. Built on the achievements of admetSAR and its successor, admetSAR2.0, this paper introduced the new version of the series, admetSAR3.0, as a comprehensive platform for chemical ADMET assessment, including search, prediction and optimization modules. In the search module, admetSAR3.0 hosted over 370 000 high-quality experimental ADMET data for 104 652 unique compounds, and supplemented chemical structure similarity search function to facilitate read-across. In the prediction module, we introduced comprehensive ADMET endpoints and two new sections for environmental and cosmetic risk assessments, empowering admetSAR3.0 to provide prediction for 119 endpoints, more than double numbers compared to the previous version. Furthermore, the advanced multi-task graph neural network framework offered robust and reliable support for ADMET prediction. In particular, a module named ADMETopt was added to automatically optimize the ADMET properties of query molecules through transformation rules or scaffold hopping. Finally, admetSAR3.0 provides user-friendly interfaces for multiple types of input data, such as SMILES string, chemical structure and batch molecule file, and supports various output types, including digital, chart displays and file downloads. In summary, admetSAR3.0 is anticipated to be a valuable and powerful tool in drug discovery and chemical safety assessment at http://lmmd.ecust.edu.cn/admetsar3/.",['multi-task graph neural network framework']
2024,https://openalex.org/W4401163187,Biology,Monthly climate prediction using deep convolutional neural network and long short-term memory,"Climate change affects plant growth, food production, ecosystems, sustainable socio-economic development, and human health. The different artificial intelligence models are proposed to simulate climate parameters of Jinan city in China, include artificial neural network (ANN), recurrent NN (RNN), long short-term memory neural network (LSTM), deep convolutional NN (CNN), and CNN-LSTM. These models are used to forecast six climatic factors on a monthly ahead. The climate data for 72 years (1 January 1951–31 December 2022) used in this study include monthly average atmospheric temperature, extreme minimum atmospheric temperature, extreme maximum atmospheric temperature, precipitation, average relative humidity, and sunlight hours. The time series of 12 month delayed data are used as input signals to the models. The efficiency of the proposed models are examined utilizing diverse evaluation criteria namely mean absolute error, root mean square error (RMSE), and correlation coefficient (R). The modeling result inherits that the proposed hybrid CNN-LSTM model achieves a greater accuracy than other compared models. The hybrid CNN-LSTM model significantly reduces the forecasting error compared to the models for the one month time step ahead. For instance, the RMSE values of the ANN, RNN, LSTM, CNN, and CNN-LSTM models for monthly average atmospheric temperature in the forecasting stage are 2.0669, 1.4416, 1.3482, 0.8015 and 0.6292 °C, respectively. The findings of climate simulations shows the potential of CNN-LSTM models to improve climate forecasting. Climate prediction will contribute to meteorological disaster prevention and reduction, as well as flood control and drought resistance.","['artificial neural network (ANN)', 'recurrent NN (RNN)', 'long short-term memory neural network (LSTM)', 'deep convolutional NN (CNN)', 'CNN-LSTM']"
2024,https://openalex.org/W4399303474,Biology,Improving Forest Above-Ground Biomass Estimation by Integrating Individual Machine Learning Models,"The accurate estimation of forest above-ground biomass (AGB) is crucial for sustainable forest management and tracking the carbon cycle of forest ecosystem. Machine learning algorithms have been proven to have great potential in forest AGB estimation with remote sensing data. Though many studies have demonstrated that a single machine learning model can produce highly accurate estimations of forest AGB in many situations, efforts are still required to explore the possible improvement in forest AGB estimation for a specific scenario under study. This study aims to investigate the performance of novel ensemble machine learning methods for forest AGB estimation and analyzes whether these methods are affected by forest types, independent variables, and spatial autocorrelation. Four well-known machine learning models (CatBoost, LightGBM, random forest (RF), and XGBoost) were compared for forest AGB estimation in the study using eight scenarios devised on the basis of two study regions, two variable types, and two validation strategies. Subsequently, a hybrid model combining the strengths of these individual models was proposed for forest AGB estimation. The findings indicated that no individual model outperforms the others in all scenarios. The RF model demonstrates superior performance in scenarios 5, 6, and 7, while the CatBoost model shows the best performance in the remaining scenarios. Moreover, the proposed hybrid model consistently has the best performance in all scenarios in spite of some uncertainties. The ensemble strategy developed in this study for the hybrid model substantially improves estimation accuracy and exhibits greater stability, effectively addressing the challenge of model selection encountered in the forest AGB forecasting process.","['CatBoost', 'LightGBM', 'random forest (RF)', 'XGBoost', 'ensemble machine learning methods']"
2024,https://openalex.org/W4401384485,Biology,GAN based augmentation using a hybrid loss function for dermoscopy images,"Dermatology is the most appropriate field to utilize pattern recognition-based automated techniques for objective, accurate, and rapid diagnosis because diagnosis mainly relies on visual examinations of skin lesions. Recent approaches utilizing deep learning techniques have shown remarkable results in this field. However, they necessitate a substantial quantity of images and the availability of dermoscopy images is often limited. Also, even if enough images are available, their labeling requires expert knowledge and is time-consuming. To overcome these issues, an efficient augmentation approach is needed to expand training datasets from input images. Therefore, in this work, a generative adversarial network has been developed using a new hybrid loss function constructed with traditional loss functions to enhance the generation power of the architecture. Also, the effect of the proposed approach and different generative network-based augmentations, which have been used with dermoscopy images in the literature, on the classification of skin lesions has been investigated. Therefore, the main contributions of this work are: (i) introducing a new generative model for the augmentation of dermoscopy images; (ii) presenting the effect of the proposed model on the classification of the images; (iii) comparative evaluations of the effectiveness of different generative network-based augmentations in the classification of seven forms of skin lesions. The classification accuracy when the proposed augmentation is used is 93.12%, which is higher than its counterparts. Experimental results indicate the significance of augmentation techniques in the classification of skin lesions and the efficiency of the proposed structure in improving the classification accuracy.",['generative adversarial network']
2024,https://openalex.org/W4391943312,Biology,"Machine Learning and Deep Learning in Synthetic Biology: Key Architectures, Applications, and Challenges","Machine learning (ML), particularly deep learning (DL), has made rapid and substantial progress in synthetic biology in recent years. Biotechnological applications of biosystems, including pathways, enzymes, and whole cells, are being probed frequently with time. The intricacy and interconnectedness of biosystems make it challenging to design them with the desired properties. ML and DL have a synergy with synthetic biology. Synthetic biology can be employed to produce large data sets for training models (for instance, by utilizing DNA synthesis), and ML/DL models can be employed to inform design (for example, by generating new parts or advising unrivaled experiments to perform). This potential has recently been brought to light by research at the intersection of engineering biology and ML/DL through achievements like the design of novel biological components, best experimental design, automated analysis of microscopy data, protein structure prediction, and biomolecular implementations of ANNs (Artificial Neural Networks). I have divided this review into three sections. In the first section, I describe predictive potential and basics of ML along with myriad applications in synthetic biology, especially in engineering cells, activity of proteins, and metabolic pathways. In the second section, I describe fundamental DL architectures and their applications in synthetic biology. Finally, I describe different challenges causing hurdles in the progress of ML/DL and synthetic biology along with their solutions.","['machine learning (ML)', 'deep learning (DL)', 'Artificial Neural Networks (ANNs)']"
2024,https://openalex.org/W4391997375,Biology,A machine learning approach to predict the efficiency of corrosion inhibition by natural product-based organic inhibitors,"Abstract This paper presents a quantitative structure–property relationship (QSPR)-based machine learning (ML) framework designed for predicting corrosion inhibition efficiency (CIE) values in natural organic inhibitor compounds. The modeling dataset comprises 50 natural organic compounds, with 11 quantum chemical properties (QCP) serving as input features, and the target variable being the corrosion inhibition efficiency (CIE) value. To enhance the predictive accuracy of the ML model, the kernel density estimation (KDE) function is employed to generate virtual samples during the training process, with the overarching goal of refining the precision of the ML model. Three distinct models, namely random forest (RF), gradient boosting (GB), and k-nearest neighbor (KNN), are tested in the study. The results demonstrate a noteworthy enhancement in the prediction performance of the models, attributable to the incorporation of virtual samples that effectively improve the correlation between input features and target values. Consequently, the accuracy of the predicted CIE values is significantly augmented, aligning more closely with the actual CIE values. Performance improvements were evident across all models after the incorporation of virtual samples. The GB, RF, and KNN models exhibited increments in R 2 values from 0.557 to 0.996, 0.522 to 0.999, and 0.415 to 0.994, respectively, concomitant with the introduction of 500 virtual samples. Additionally, each model demonstrated a notable reduction in RMSE values, transitioning from 1.41 to 0.19, 1.27 to 0.10, and 1.22 to 0.16, respectively. While the GB model initially outperformed others before the addition of virtual samples, the performance of the model exhibited fluctuation as the number of virtual samples varied. This behavior suggests that the KDE function provides a certain level of resilience against model variations. The proposed approach contributes to the effective design and exploration of corrosion inhibitor candidates, offering a reliable and accurate predictive tool that bridges the gap between theoretical studies and experimental synthesis.","['random forest (RF)', 'gradient boosting (GB)', 'k-nearest neighbor (KNN)']"
2024,https://openalex.org/W4395037579,Biology,Assessing ChatGPT 4.0’s test performance and clinical diagnostic accuracy on USMLE STEP 2 CK and clinical case reports,"Abstract While there is data assessing the test performance of artificial intelligence (AI) chatbots, including the Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0), there is scarce data on its diagnostic accuracy of clinical cases. We assessed the large language model (LLM), ChatGPT 4.0, on its ability to answer questions from the United States Medical Licensing Exam (USMLE) Step 2, as well as its ability to generate a differential diagnosis based on corresponding clinical vignettes from published case reports. A total of 109 Step 2 Clinical Knowledge (CK) practice questions were inputted into both ChatGPT 3.5 and ChatGPT 4.0, asking ChatGPT to pick the correct answer. Compared to its previous version, ChatGPT 3.5, we found improved accuracy of ChatGPT 4.0 when answering these questions, from 47.7 to 87.2% ( p = 0.035) respectively. Utilizing the topics tested on Step 2 CK questions, we additionally found 63 corresponding published case report vignettes and asked ChatGPT 4.0 to come up with its top three differential diagnosis. ChatGPT 4.0 accurately created a shortlist of differential diagnoses in 74.6% of the 63 case reports (74.6%). We analyzed ChatGPT 4.0’s confidence in its diagnosis by asking it to rank its top three differentials from most to least likely. Out of the 47 correct diagnoses, 33 were the first (70.2%) on the differential diagnosis list, 11 were second (23.4%), and three were third (6.4%). Our study shows the continued iterative improvement in ChatGPT’s ability to answer standardized USMLE questions accurately and provides insights into ChatGPT’s clinical diagnostic accuracy.","['Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0)', 'large language model (LLM)']"
2024,https://openalex.org/W4390501772,Biology,Remote sensing based forest cover classification using machine learning,"Abstract Pakistan falls significantly below the recommended forest coverage level of 20 to 30 percent of total area, with less than 6 percent of its land under forest cover. This deficiency is primarily attributed to illicit deforestation for wood and charcoal, coupled with a failure to embrace advanced techniques for forest estimation, monitoring, and supervision. Remote sensing techniques leveraging Sentinel-2 satellite images were employed. Both single-layer stacked images and temporal layer stacked images from various dates were utilized for forest classification. The application of an artificial neural network (ANN) supervised classification algorithm yielded notable results. Using a single-layer stacked image from Sentinel-2, an impressive 91.37% training overall accuracy and 0.865 kappa coefficient were achieved, along with 93.77% testing overall accuracy and a 0.902 kappa coefficient. Furthermore, the temporal layer stacked image approach demonstrated even better results. This method yielded 98.07% overall training accuracy, 97.75% overall testing accuracy, and kappa coefficients of 0.970 and 0.965, respectively. The random forest (RF) algorithm, when applied, achieved 99.12% overall training accuracy, 92.90% testing accuracy, and kappa coefficients of 0.986 and 0.882. Notably, with the temporal layer stacked image of the Sentinel-2 satellite, the RF algorithm reached exceptional performance with 99.79% training accuracy, 96.98% validation accuracy, and kappa coefficients of 0.996 and 0.954. In terms of forest cover estimation, the ANN algorithm identified 31.07% total forest coverage in the District Abbottabad region. In comparison, the RF algorithm recorded a slightly higher 31.17% of the total forested area. This research highlights the potential of advanced remote sensing techniques and machine learning algorithms in improving forest cover assessment and monitoring strategies.","['artificial neural network (ANN) supervised classification algorithm', 'random forest (RF) algorithm']"
2024,https://openalex.org/W4390954471,Biology,Traffic Sign Detection and Recognition Using YOLO Object Detection Algorithm: A Systematic Review,"Context: YOLO (You Look Only Once) is an algorithm based on deep neural networks with real-time object detection capabilities. This state-of-the-art technology is widely available, mainly due to its speed and precision. Since its conception, YOLO has been applied to detect and recognize traffic signs, pedestrians, traffic lights, vehicles, and so on. Objective: The goal of this research is to systematically analyze the YOLO object detection algorithm, applied to traffic sign detection and recognition systems, from five relevant aspects of this technology: applications, datasets, metrics, hardware, and challenges. Method: This study performs a systematic literature review (SLR) of studies on traffic sign detection and recognition using YOLO published in the years 2016–2022. Results: The search found 115 primary studies relevant to the goal of this research. After analyzing these investigations, the following relevant results were obtained. The most common applications of YOLO in this field are vehicular security and intelligent and autonomous vehicles. The majority of the sign datasets used to train, test, and validate YOLO-based systems are publicly available, with an emphasis on datasets from Germany and China. It has also been discovered that most works present sophisticated detection, classification, and processing speed metrics for traffic sign detection and recognition systems by using the different versions of YOLO. In addition, the most popular desktop data processing hardwares are Nvidia RTX 2080 and Titan Tesla V100 and, in the case of embedded or mobile GPU platforms, Jetson Xavier NX. Finally, seven relevant challenges that these systems face when operating in real road conditions have been identified. With this in mind, research has been reclassified to address these challenges in each case. Conclusions: This SLR is the most relevant and current work in the field of technology development applied to the detection and recognition of traffic signs using YOLO. In addition, insights are provided about future work that could be conducted to improve the field.",['YOLO (You Look Only Once)']
2024,https://openalex.org/W4393306481,Biology,Reliable water quality prediction and parametric analysis using explainable AI models,"Abstract The consumption of water constitutes the physical health of most of the living species and hence management of its purity and quality is extremely essential as contaminated water has to potential to create adverse health and environmental consequences. This creates the dire necessity to measure, control and monitor the quality of water. The primary contaminant present in water is Total Dissolved Solids (TDS), which is hard to filter out. There are various substances apart from mere solids such as potassium, sodium, chlorides, lead, nitrate, cadmium, arsenic and other pollutants. The proposed work aims to provide the automation of water quality estimation through Artificial Intelligence and uses Explainable Artificial Intelligence (XAI) for the explanation of the most significant parameters contributing towards the potability of water and the estimation of the impurities. XAI has the transparency and justifiability as a white-box model since the Machine Learning (ML) model is black-box and unable to describe the reasoning behind the ML classification. The proposed work uses various ML models such as Logistic Regression, Support Vector Machine (SVM), Gaussian Naive Bayes, Decision Tree (DT) and Random Forest (RF) to classify whether the water is drinkable. The various representations of XAI such as force plot, test patch, summary plot, dependency plot and decision plot generated in SHAPELY explainer explain the significant features, prediction score, feature importance and justification behind the water quality estimation. The RF classifier is selected for the explanation and yields optimum Accuracy and F1-Score of 0.9999, with Precision and Re-call of 0.9997 and 0.998 respectively. Thus, the work is an exploratory analysis of the estimation and management of water quality with indicators associated with their significance. This work is an emerging research at present with a vision of addressing the water quality for the future as well.","['Logistic Regression', 'Support Vector Machine (SVM)', 'Gaussian Naive Bayes', 'Decision Tree (DT)', 'Random Forest (RF)']"
2024,https://openalex.org/W4399319394,Biology,Multi-task aquatic toxicity prediction model based on multi-level features fusion,"With the escalating menace of organic compounds in environmental pollution imperiling the survival of aquatic organisms, the investigation of organic compound toxicity across diverse aquatic species assumes paramount significance for environmental protection. Understanding how different species respond to these compounds helps assess the potential ecological impact of pollution on aquatic ecosystems as a whole. Compared with traditional experimental methods, deep learning methods have higher accuracy in predicting aquatic toxicity, faster data processing speed and better generalization ability. This article presents ATFPGT-multi, an advanced multi-task deep neural network prediction model for organic toxicity. The model integrates molecular fingerprints and molecule graphs to characterize molecules, enabling the simultaneous prediction of acute toxicity for the same organic compound across four distinct fish species. Furthermore, to validate the advantages of multi-task learning, we independently construct prediction models, named ATFPGT-single, for each fish species. We employ cross-validation in our experiments to assess the performance and generalization ability of ATFPGT-multi. The experimental results indicate, first, that ATFPGT-multi outperforms ATFPGT-single on four fish datasets with AUC improvements of 9.8%, 4%, 4.8%, and 8.2%, respectively, demonstrating the superiority of multi-task learning over single-task learning. Furthermore, in comparison with previous algorithms, ATFPGT-multi outperforms comparative methods, emphasizing that our approach exhibits higher accuracy and reliability in predicting aquatic toxicity. Moreover, ATFPGT-multi utilizes attention scores to identify molecular fragments associated with fish toxicity in organic molecules, as demonstrated by two organic molecule examples in the main text, demonstrating the interpretability of ATFPGT-multi. In summary, ATFPGT-multi provides important support and reference for the further development of aquatic toxicity assessment. All of codes and datasets are freely available online at https://github.com/zhaoqi106/ATFPGT-multi.","['deep learning methods', 'multi-task deep neural network prediction model', 'multi-task learning', 'single-task learning']"
2024,https://openalex.org/W4391321561,Biology,A survey on training challenges in generative adversarial networks for biomedical image analysis,"Abstract In biomedical image analysis, the applicability of deep learning methods is directly impacted by the quantity of image data available. This is due to deep learning models requiring large image datasets to provide high-level performance. Generative Adversarial Networks (GANs) have been widely utilized to address data limitations through the generation of synthetic biomedical images. GANs consist of two models. The generator, a model that learns how to produce synthetic images based on the feedback it receives. The discriminator, a model that classifies an image as synthetic or real and provides feedback to the generator. Throughout the training process, a GAN can experience several technical challenges that impede the generation of suitable synthetic imagery. First, the mode collapse problem whereby the generator either produces an identical image or produces a uniform image from distinct input features. Second, the non-convergence problem whereby the gradient descent optimizer fails to reach a Nash equilibrium. Thirdly, the vanishing gradient problem whereby unstable training behavior occurs due to the discriminator achieving optimal classification performance resulting in no meaningful feedback being provided to the generator. These problems result in the production of synthetic imagery that is blurry, unrealistic, and less diverse. To date, there has been no survey article outlining the impact of these technical challenges in the context of the biomedical imagery domain. This work presents a review and taxonomy based on solutions to the training problems of GANs in the biomedical imaging domain. This survey highlights important challenges and outlines future research directions about the training of GANs in the domain of biomedical imagery.","['deep learning', 'Generative Adversarial Networks (GANs)', 'discriminator', 'gradient descent optimizer']"
2024,https://openalex.org/W4393055891,Biology,A new intelligently optimized model reference adaptive controller using GA and WOA-based MPPT techniques for photovoltaic systems,"Recently, the integration of renewable energy sources, specifically photovoltaic (PV) systems, into power networks has grown in significance for sustainable energy generation. Researchers have investigated different control algorithms for maximum power point tracking (MPPT) to enhance the efficiency of PV systems. This article presents an innovative method to address the problem of maximum power point tracking in photovoltaic systems amidst swiftly changing weather conditions. MPPT techniques supply maximum power to the load during irradiance fluctuations and ambient temperatures. A novel optimal model reference adaptive controller is developed and designed based on the MIT rule to seek global maximum power without ripples rapidly. The suggested controller is also optimized through two popular meta-heuristic algorithms: The genetic algorithm (GA) and the whale optimization algorithm (WOA). These meta-heuristic approaches have been exploited to overcome the difficulty of selecting the adaptation gain of the MRAC controller. The reference voltage for MPPT is generated in the study through an adaptive neuro-fuzzy inference system. The suggested controller's performance is tested via MATLAB/Simulink software under varying temperature and radiation circumstances. Simulation is carried out using a Soltech 1sth-215-p module coupled to a boost converter, which powers a resistive load. Furthermore, to emphasize the recommended algorithm's performance, a comparative study was done between the optimal MRAC using GA and WOA and the conventional incremental conductance (INC) method.","['genetic algorithm (GA)', 'whale optimization algorithm (WOA)', 'adaptive neuro-fuzzy inference system']"
2024,https://openalex.org/W4399144385,Biology,Assessment of technical water quality in mining based on machine learning methods,"Introduction. Mining requires water treatment and wastewater processing, abstraction and discharge during mining increases consumption several times. Since water consumption in mining and processing is usually associated with domestic, industrial and technical needs, the need for water supply systems required for water treatment increases. Water from different sources can be used for treatment: incoming water, process and reused water, and wastewater. But the water obtained from any of the sources must meet all the norms and requirements. Water quality is determined by physical, chemical and bacteriological properties. The main directions for improving water consumption by mining enterprises are to reduce the consumption of drinking water from rivers, lakes and municipal water supply, as well as to expand the use of mine and quarry water for domestic and technical needs. Materials and methods. As training data for training the neural network, a dataset that includes water quality data obtained from fresh water sources was selected for the methods work, and using machine learning, develops a model that predicts whether the water is suitable for technical use in mines. This dataset includes 2293 values (samples) as well as 9 attributes. Correlation, neural network, and decision tree methods were used to build the models in this study. Results. Various machine learning methods (neural network and decision trees) were used to build a predictive model to assess the quality of water that would be suitable for use in the mining industry for technical purposes. With the help of the built models were processed data obtained from public sources, when analyzing which it was found that the method of decision trees was more accurate. The constructed model, for determining dependencies, thus, has high accuracy (small error). To increase the practical significance of the study, a number of transformations of the initial data set were carried out, in particular, an experiment with the division of attributes into groups of importance, in relation to the data, taking into account the subject area. The results obtained made it clear that checking only for hazardous impurities does not guarantee the suitability of water, but almost completely excludes (low significance factor) samples with impurities that do not meet the requirements, and the model can have practical significance. Allocation of the group for rapid quality determination, showed that for the express test, in an emergency situation or under time constraints, the possibility of practical use of the obtained model, has a justification, due to the small error. In general, the conducted experiments have shown that when taking into account the costs (total) for data collection, it makes sense to use models, taking into account the reduction of collected data, on the parameters (factors) of technical water. Discussion. In general, on the basis of the conducted research, we can talk about the successful application of machine learning methods in determining the suitability of technical water in the mining industry. During the experiments, the decision tree method performed particularly well, with the lowest error values. In addition, further work can be carried out to reduce the error in the models, in particular, by possibly increasing the number of attributes, as well as more fine-tuning of the applied machine learning methods. Conclusions. The authors conclude that machine learning techniques can be successfully integrated to determine the quality and suitability of process water in the mining industry in today’s world. Resume. The paper compares machine learning methods such as decision trees and neural network method. The comparative analysis of these methods and their quality of information processing is shown on the example of a set of data on water quality in the mining industry. With the help of built models were processed data obtained from open sources, when analyzing which it was found that the method of decision trees was more accurate. The constructed model for determining dependencies has high accuracy (small error). Suggestions for practical applications and future research directions. This study can form the basis for research in this or related fields to conduct further studies on the reliability and accuracy of using machine learning to predict the quality of water used in the mining industry. Continued work in the above direction may be the rationale for wider use of the above methods to improve various meaningful production performance in this or related areas.","['neural network', 'decision tree']"
2024,https://openalex.org/W4391093770,Biology,A Convolutional Neural Network approach for image-based anomaly detection in smart agriculture,"The recent technological advances and their applications to agriculture provide leverage for the new paradigm of smart agriculture. Remote sensing applications can help optimize resources, making agriculture more ecological, increasing productivity and helping farmers to anticipate events that could not otherwise be avoided. Considering that losses caused by anomalies such as diseases, weeds and pests account for 20-40 % of overall agricultural productivity, a successful research effort in this area would be a breakthrough for agriculture. In this paper, we propose a methodology with which to discover and classify anomalies in images of crops, taken from a wide range of distances, using different Convolutional Neural Network architectures. This methodology also deals with several difficulties that usually appear in this kind of problems, such as class imbalance, the insufficient and small variety of images, overtraining or lack of models generalisation. We have implemented four convolutional neural network architectures in a high-performance computing environment, and propose a methodology based on data augmentation with the addition of Gaussian noise to the images to solve the above problems. Our approach was tested using two well-established open datasets that are unalike: DeepWeeds, which provides a classification of 8 weed species native to Australia using images that were taken at a distance of 1 m, and Agriculture-Vision, which classifies 6 types of crop anomalies using multispectral satellite imagery. Our methodology attained accuracies of 98 % and 95.3% respectively, improving the state-of-the-art by several points. In order to ease reproducibility and model selection, we have provided a comparison in terms of computational time and other metrics, thus enabling the choice between architectures to be made according to the resources available. The complete code is available in an open repository in order to encourage reproducibility and promote scientific advances in sustainable agriculture.","['Convolutional Neural Network architectures', 'data augmentation with the addition of Gaussian noise']"
2024,https://openalex.org/W4391612257,Biology,Machine learning for the management of biochar yield and properties of biomass sources for sustainable energy,"Abstract Biochar is emerging as a potential solution for biomass conversion to meet the ever increasing demand for sustainable energy. Efficient management systems are needed in order to exploit fully the potential of biochar. Modern machine learning (ML) techniques, and in particular ensemble approaches and explainable AI methods, are valuable for forecasting the properties and efficiency of biochar properly. Machine‐learning‐based forecasts, optimization, and feature selection are critical for improving biomass management techniques. In this research, we explore the influences of these techniques on the accurate forecasting of biochar yield and properties for a range of biomass sources. We emphasize the importance of the interpretability of a model, as this improves human comprehension and trust in ML predictions. Sensitivity analysis is shown to be an effective technique for finding crucial biomass characteristics that influence the synthesis of biochar. Precision prognostics have far‐reaching ramifications, influencing industries such as biomass logistics, conversion technologies, and the successful use of biomass as renewable energy. These advances can make a substantial contribution to a greener future and can encourage the development of a circular biobased economy. This work emphasizes the importance of using sophisticated data‐driven methodologies such as ML in biochar synthesis, to usher in ecologically friendly energy solutions. These breakthroughs hold the key to a more sustainable and environmentally friendly future.","['ensemble approaches', 'feature selection']"
2024,https://openalex.org/W4391878291,Biology,Effective lung nodule detection using deep CNN with dual attention mechanisms,"Abstract Novel methods are required to enhance lung cancer detection, which has overtaken other cancer-related causes of death as the major cause of cancer-related mortality. Radiologists have long-standing methods for locating lung nodules in patients with lung cancer, such as computed tomography (CT) scans. Radiologists must manually review a significant amount of CT scan pictures, which makes the process time-consuming and prone to human error. Computer-aided diagnosis (CAD) systems have been created to help radiologists with their evaluations in order to overcome these difficulties. These systems make use of cutting-edge deep learning architectures. These CAD systems are designed to improve lung nodule diagnosis efficiency and accuracy. In this study, a bespoke convolutional neural network (CNN) with a dual attention mechanism was created, which was especially crafted to concentrate on the most important elements in images of lung nodules. The CNN model extracts informative features from the images, while the attention module incorporates both channel attention and spatial attention mechanisms to selectively highlight significant features. After the attention module, global average pooling is applied to summarize the spatial information. To evaluate the performance of the proposed model, extensive experiments were conducted using benchmark dataset of lung nodules. The results of these experiments demonstrated that our model surpasses recent models and achieves state-of-the-art accuracy in lung nodule detection and classification tasks.","['convolutional neural network (CNN)', 'dual attention mechanism', 'channel attention', 'spatial attention', 'global average pooling']"
2024,https://openalex.org/W4392432727,Biology,Plant disease recognition in a low data scenario using few-shot learning,"Plant disease is one of the major problems in agriculture. Diseases damage plants, reduce yields and lower the quality of the produce. Traditional approaches to detecting plant diseases are usually based on visual inspection and laboratory testing, which can be expensive and time-consuming. They require trained plant pathologists as well as specialised equipment. Several studies demonstrate that artificial intelligence (AI) methods can produce promising results. However, AI methods are generally data-hungry and require large annotated datasets, and the collection and annotation of such datasets can be a limiting factor. It often appears that only a small amount of data is available for certain disease types. Whereas the performance of typical AI methods drops significantly when they are trained with inadequate data. This paper proposes a novel few-shot learning (FSL) method to detect plant diseases and alleviate the data scarcity problem. The proposed method uses as few as five images per class in the machine learning process. Our method is based on a state-of-the-art FSL pipeline called pre-training, meta-learning, and fine-tuning (PMF), integrated with a novel feature attention (FA) module; we call the overall method PMF+FA. The FA module emphasises the discriminative parts in the image and reduces the impact of complicated backgrounds and undesired objects. We used ResNet50 and Vision Transformers (ViT) as the feature learner. Two publicly available plant disease datasets were repurposed to meet the FSL requirements. We thoroughly evaluated the proposed method on the PlantDoc dataset, which contains disease samples in field environments with complex backgrounds and unwanted objects. The PMF+FA method with ViT achieved an average accuracy of 90.12% in disease recognition. The results demonstrate that the PMF+FA pipeline consistently outperforms the baseline PMF. The results also highlight that the method using ViT generates better results than ResNet50 for diagnosing complex data. ViT and ResNet50 implementations are computationally efficient, taking 1.11 and 0.57 ms on average per image to evaluate the test set respectively. The high throughput and high-quality performance with only a small training dataset indicate that the proposed technique can be used for real-time disease detection in digital farming systems.","['few-shot learning (FSL)', 'ResNet50', 'Vision Transformers (ViT)']"
2024,https://openalex.org/W4394808249,Biology,An ensemble penalized regression method for multi-ancestry polygenic risk prediction,"Abstract Great efforts are being made to develop advanced polygenic risk scores (PRS) to improve the prediction of complex traits and diseases. However, most existing PRS are primarily trained on European ancestry populations, limiting their transferability to non-European populations. In this article, we propose a novel method for generating multi-ancestry Polygenic Risk scOres based on enSemble of PEnalized Regression models (PROSPER). PROSPER integrates genome-wide association studies (GWAS) summary statistics from diverse populations to develop ancestry-specific PRS with improved predictive power for minority populations. The method uses a combination of $${{{{{{\mathscr{L}}}}}}}_{1}$$ <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""> <mml:msub> <mml:mrow> <mml:mi>L</mml:mi> </mml:mrow> <mml:mrow> <mml:mn>1</mml:mn> </mml:mrow> </mml:msub> </mml:math> (lasso) and $${{{{{{\mathscr{L}}}}}}}_{2}$$ <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""> <mml:msub> <mml:mrow> <mml:mi>L</mml:mi> </mml:mrow> <mml:mrow> <mml:mn>2</mml:mn> </mml:mrow> </mml:msub> </mml:math> (ridge) penalty functions, a parsimonious specification of the penalty parameters across populations, and an ensemble step to combine PRS generated across different penalty parameters. We evaluate the performance of PROSPER and other existing methods on large-scale simulated and real datasets, including those from 23andMe Inc., the Global Lipids Genetics Consortium, and All of Us. Results show that PROSPER can substantially improve multi-ancestry polygenic prediction compared to alternative methods across a wide variety of genetic architectures. In real data analyses, for example, PROSPER increased out-of-sample prediction R 2 for continuous traits by an average of 70% compared to a state-of-the-art Bayesian method (PRS-CSx) in the African ancestry population. Further, PROSPER is computationally highly scalable for the analysis of large SNP contents and many diverse populations.","['lasso', 'ridge', 'ensemble']"
2024,https://openalex.org/W4399651788,Biology,Semantic segmentation of microbial alterations based on SegFormer,"Introduction Precise semantic segmentation of microbial alterations is paramount for their evaluation and treatment. This study focuses on harnessing the SegFormer segmentation model for precise semantic segmentation of strawberry diseases, aiming to improve disease detection accuracy under natural acquisition conditions. Methods Three distinct Mix Transformer encoders - MiT-B0, MiT-B3, and MiT-B5 - were thoroughly analyzed to enhance disease detection, targeting diseases such as Angular leaf spot, Anthracnose rot, Blossom blight, Gray mold, Leaf spot, Powdery mildew on fruit, and Powdery mildew on leaves. The dataset consisted of 2,450 raw images, expanded to 4,574 augmented images. The Segment Anything Model integrated into the Roboflow annotation tool facilitated efficient annotation and dataset preparation. Results The results reveal that MiT-B0 demonstrates balanced but slightly overfitting behavior, MiT-B3 adapts rapidly with consistent training and validation performance, and MiT-B5 offers efficient learning with occasional fluctuations, providing robust performance. MiT-B3 and MiT-B5 consistently outperformed MiT-B0 across disease types, with MiT-B5 achieving the most precise segmentation in general. Discussion The findings provide key insights for researchers to select the most suitable encoder for disease detection applications, propelling the field forward for further investigation. The success in strawberry disease analysis suggests potential for extending this approach to other crops and diseases, paving the way for future research and interdisciplinary collaboration.","['SegFormer segmentation model', 'Mix Transformer encoders - MiT-B0', 'Mix Transformer encoders - MiT-B3', 'Mix Transformer encoders - MiT-B5', 'Segment Anything Model']"
2024,https://openalex.org/W4390590855,Biology,A Survey of Text Classification With Transformers: How Wide? How Large? How Long? How Accurate? How Expensive? How Safe?,"Text classification is a basic task in natural language processing (NLP) with applications from sentiment analysis to question-answering with chat bots. In recent years, transformer-based models have emerged as the prevailing framework in NLP, demonstrating excellent results across many benchmarks. This paper recommends an expanded taxonomy of applications and provides a review of the performance of different models across these applications. The use of traditional research techniques plus co-citation and bibliographic coupling provides a comprehensive view of the current and past research in this area. The study begins by providing an overview of the history of transformer-based models with an emphasis on recent large language models (LLM). Next, uni-modal (text only) inputs and the emerging area of multi-modal classification are discussed to provide a comparison of current and emerging research in this area. Gaps are highlighted in the use of multi-modal text/numeric/columnar data and recommendations for future research are provided. Finally, the length of text input variables (tokens) is reviewed to explore the evolution from short-text to longer document applications. Furthermore, the accuracy on 358 datasets across 20 applications is reviewed and unexpected results emerge which show that LLMs are not always the most accurate or least expensive option. In addition to model performance, the safety implications of transformer-based models are reviewed, and a summary of issues related to ethics, bias, social implications, and copyright are explored.",['transformer-based models']
2024,https://openalex.org/W4391289138,Biology,"A stacking ANN ensemble model of ML models for stream water quality prediction of Godavari River Basin, India","The importance of water quality models has increased as their inputs are critical to the development of risk assessment framework for environmental management and monitoring of rivers. However, with the advent of a plethora of recent advances in ML algorithms better predictions are possible. This study proposes a causal and effect model by considering climatological such as temperature and precipitation along with geospatial information related to the agricultural land use factor (ALUF), the forest land use factor (FLUF), the grassland usage factor (GLUF), the shrub land use factor (SLUF), and the urban land use factor (ULUF). All these factors are included in the input data, whereas four Stream Water Quality parameters (SWQPs) such as Electrical Conductivity (EC), Biochemical Oxygen Demand (BOD), Nitrate, and Dissolved Oxygen (DO) from 2019 to 2021 are taken as outputs to predict the Godavari River Basin water quality. In the preliminary investigation, out of these four SWQPs, nitrate's coefficient of variation (CV) is high, revealing a close association with climate parameters and land use practices across the sampling stations. In the authors' earlier study, a model using a single-layer Feed-Forward Neural Network (FFNN) showed improved performance in predicting cause and effect factors linked to water quality metrics. To achieve better prediction, a stacked ANN meta-model and nine conventional machine learning (ML) models, including Extreme Gradient Boosting (XGB), Extra Trees (ET), Bagging (BG), Random Forest (RF), AdaBoost or Adaptive Boosting (ADB), Decision Tree (DT), Highest Gradient Boosting (HGB), Light Gradient Boosting Method (LGBM), and Gradient Boosting (GB), were compared in this study. According to the study's findings, Bagging and Boosting models outperformed stand-alone earlier FFNN for the same dataset and showed superior predictive capabilities in terms of accuracy in forecasting the variable of interest. For instance, during testing, the coefficient of determination (R2) of Biochemical Oxygen Demand (BOD) increased from 0.72 to 0.87. Furthermore, a stacked Artificial Neural Network (ANN) meta model that was reinforced using Extreme Gradient Boosting (XGB), Random Forest (RF), and Extra Trees (ET) as base models performed better than the individual ML models (from R2 = 0.87 to 0.91 for BOD in testing). By using this new framework, the effort for hyperparameter tuning can be minimized.","['Feed-Forward Neural Network (FFNN)', 'stacked ANN meta-model', 'Extreme Gradient Boosting (XGB)', 'Extra Trees (ET)', 'Bagging (BG)', 'Random Forest (RF)', 'AdaBoost or Adaptive Boosting (ADB)', 'Decision Tree (DT)', 'Light Gradient Boosting Method (LGBM)', 'Gradient Boosting (GB)', 'stacked Artificial Neural Network (ANN) meta model']"
2024,https://openalex.org/W4391392820,Biology,Advancements in Imaging Sensors and AI for Plant Stress Detection: A Systematic Literature Review,"Integrating imaging sensors and artificial intelligence (AI) have contributed to detecting plant stress symptoms, yet data analysis remains a key challenge. Data challenges include standardized data collection, analysis protocols, selection of imaging sensors and AI algorithms, and finally, data sharing. Here, we present a systematic literature review (SLR) scrutinizing plant imaging and AI for identifying stress responses. We performed a scoping review using specific keywords, namely abiotic and biotic stress, machine learning, plant imaging and deep learning. Next, we used programmable bots to retrieve relevant papers published since 2006. In total, 2,704 papers from 4 databases (Springer, ScienceDirect, PubMed, and Web of Science) were found, accomplished by using a second layer of keywords (e.g., hyperspectral imaging and supervised learning). To bypass the limitations of search engines, we selected OneSearch to unify keywords. We carefully reviewed 262 studies, summarizing key trends in AI algorithms and imaging sensors. We demonstrated that the increased availability of open-source imaging repositories such as PlantVillage or Kaggle has strongly contributed to a widespread shift to deep learning, requiring large datasets to train in stress symptom interpretation. Our review presents current trends in AI-applied algorithms to develop effective methods for plant stress detection using image-based phenotyping. For example, regression algorithms have seen substantial use since 2021. Ultimately, we offer an overview of the course ahead for AI and imaging technologies to predict stress responses. Altogether, this SLR highlights the potential of AI imaging in both biotic and abiotic stress detection to overcome challenges in plant data analysis.","['machine learning', 'deep learning', 'supervised learning', 'regression algorithms']"
2024,https://openalex.org/W4392783914,Biology,CAR-Toner: an AI-driven approach for CAR tonic signaling prediction and optimization,"2][3] Our previous work has elucidated that positively charged patches (PCPs) on the surface of the CAR antigenbinding domain facilitate CAR clustering, thereby triggering CAR tonic signals.To quantify these PCPs, which are indicative of CAR tonic signaling, we previously developed a bioinformatic method to determine the PCP score. 1 This calculation method starts with constructing three-dimensional (3D) homology models for CAR's single-chain variable fragments (scFvs) using the SWISS homology modeler.Subsequently, the BindUP web server is used to determine the total count of residues within the top three largest patches containing continuous positively charged residues on the surface of CAR scFv.However, this PCP score calculation method has several limitations: 1. reliance on two external servers; 2. each calculation taking a few days, significantly hindering efficiency; 3. lack of batch calculation capability; 4. no optimization strategies provided for finetuning PCP scores.Given these constraints, we aimed to develop an artificial intelligence (AI)-based PCP score calculator and optimizer to overcome these bottlenecks.Protein databases, structural biology, and advanced deep learning models are all integrated into our AI-based PCP score calculator (Fig. 1a).A comprehensive protein structure database consisting of over 170,000 entries was established by extracting 3D structural information from the Protein Data Bank (PDB) and AlphaFold predictions, followed by stringent quality control procedures.We further developed an in-house algorithm tailored for calculating PCP scores based on the obtained 3D structure information (Supplementary Information), subsequently generating a dataset comprising approximately 170,000 protein sequences along with their associated PCP scores.For model training and evaluation, 70% of the data are allocated as the training dataset, while the remaining 30% serve as the test dataset.The ESM2 model, developed by the FAIR (Meta Fundamental AI Research Protein Team), is utilized for fine-tuning tasks related to PCP prediction. 4,5SM2 is a transformer-based language model using an attention mechanism to learn interaction patterns between pairs of amino acids in the input sequence.Pre-trained on over 60 million protein sequences from the UniProt Reference Clusters (UniRef) database, ESM2 demonstrates strong adaptability to downstream protein structure-related tasks. 5The ESM2-8M model was used to fine-tune the training dataset.Following updating parameters, the ESM2 model was transformed into the PCP-AI prediction model, referred to as CAR-Tonic Signal Tuner (abbreviated as CAR-Toner; http://cartfitness.slst.shanghaitech.edu.cn/CAR-fitness/).This model encompasses three key functionalities: proficient PCP calculation for individual proteins, streamlined batch processing, and an integrated optimization strategy for refining PCP scores (Fig. 1b).","['ESM2 model', 'transformer-based language model using an attention mechanism', 'fine-tuning']"
2024,https://openalex.org/W4390708138,Biology,Accuracy of GPT-4 in histopathological image detection and classification of colorectal adenomas,"Aims To evaluate the accuracy of Chat Generative Pre-trained Transformer (ChatGPT) powered by GPT-4 in histopathological image detection and classification of colorectal adenomas using the diagnostic consensus provided by pathologists as a reference standard. Methods A study was conducted with 100 colorectal polyp photomicrographs, comprising an equal number of adenomas and non-adenomas, classified by two pathologists. These images were analysed by classic GPT-4 for 1 time in October 2023 and custom GPT-4 for 20 times in December 2023. GPT-4’s responses were compared against the reference standard through statistical measures to evaluate its proficiency in histopathological diagnosis, with the pathologists further assessing the model’s descriptive accuracy. Results GPT-4 demonstrated a median sensitivity of 74% and specificity of 36% for adenoma detection. The median accuracy of polyp classification varied, ranging from 16% for non-specific changes to 36% for tubular adenomas. Its diagnostic consistency, indicated by low kappa values ranging from 0.06 to 0.11, suggested only poor to slight agreement. All of the microscopic descriptions corresponded with their diagnoses. GPT-4 also commented about the limitations in its diagnoses (eg, slide diagnosis best done by pathologists, the inadequacy of single-image diagnostic conclusions, the need for clinical data and a higher magnification view). Conclusions GPT-4 showed high sensitivity but low specificity in detecting adenomas and varied accuracy for polyp classification. However, its diagnostic consistency was low. This artificial intelligence tool acknowledged its diagnostic limitations, emphasising the need for a pathologist’s expertise and additional clinical context.",['Chat Generative Pre-trained Transformer (ChatGPT) powered by GPT-4']
2024,https://openalex.org/W4390870882,Biology,A domain adaptation approach to damage classification with an application to bridge monitoring,"Data-driven machine-learning algorithms generally suffer from a lack of labelled health-state data, mainly those referring to damage conditions. To address such an issue, population-based structural health monitoring seeks to enrich the original dataset by transferring knowledge from a population of monitored structures. Within this context, this paper presents a transfer learning approach, based on domain adaptation, to leverage information from completely-labelled bridge structure data to accurately predict new instances of an unknown target domain. Since intrinsic structural differences may cause distribution shifts, domain adaptation attempts to minimise the distance between the domains and to learn a mapping within a shared feature space. Specifically, the methodology involves the long-term acquisition of natural frequencies from several structural scenarios. Such damage-sensitive features are then aligned via domain adaptation so that a machine-learning algorithm can effectively utilise the labelled source domain data and generalise well to the unlabelled target-domain data. The described procedure is applied to two case studies, including the Z24 and the S101 benchmark bridges and their finite element models, respectively. The results demonstrate the successful exchange of health-state labels to identify the damage class within a population of bridges equipped with SHM systems, showing potential to reduce computational efforts and to deal with scarce or poor data sets in application to bridge network monitoring.","['transfer learning', 'domain adaptation']"
2024,https://openalex.org/W4391164184,Biology,Discovering Consensus Regions for Interpretable Identification of RNA N6-Methyladenosine Modification Sites via Graph Contrastive Clustering,"As a pivotal post-transcriptional modification of RNA, N6-methyladenosine (m6A) has a substantial influence on gene expression modulation and cellular fate determination. Although a variety of computational models have been developed to accurately identify potential m6A modification sites, few of them are capable of interpreting the identification process with insights gained from consensus knowledge. To overcome this problem, we propose a deep learning model, namely M6A-DCR, by discovering consensus regions for interpretable identification of m6A modification sites. In particular, M6A-DCR first constructs an instance graph for each RNA sequence by integrating specific positions and types of nucleotides. The discovery of consensus regions is then formulated as a graph clustering problem in light of aggregating all instance graphs. After that, M6A-DCR adopts a motif-aware graph reconstruction optimization process to learn high-quality embeddings of input RNA sequences, thus achieving the identification of m6A modification sites in an end-to-end manner. Experimental results demonstrate the superior performance of M6A-DCR by comparing it with several state-of-the-art identification models. The consideration of consensus regions empowers our model to make interpretable predictions at the motif level. The analysis of cross validation through different species and tissues further verifies the consistency between the identification results of M6A-DCR and the evolutionary relationships among species","['deep learning model', 'graph clustering']"
2024,https://openalex.org/W4392356867,Biology,The SAFE procedure: a practical stopping heuristic for active learning-based screening in systematic reviews and meta-analyses,"Abstract Active learning has become an increasingly popular method for screening large amounts of data in systematic reviews and meta-analyses. The active learning process continually improves its predictions on the remaining unlabeled records, with the goal of identifying all relevant records as early as possible. However, determining the optimal point at which to stop the active learning process is a challenge. The cost of additional labeling of records by the reviewer must be balanced against the cost of erroneous exclusions. This paper introduces the SAFE procedure, a practical and conservative set of stopping heuristics that offers a clear guideline for determining when to end the active learning process in screening software like ASReview. The eclectic mix of stopping heuristics helps to minimize the risk of missing relevant papers in the screening process. The proposed stopping heuristic balances the costs of continued screening with the risk of missing relevant records, providing a practical solution for reviewers to make informed decisions on when to stop screening. Although active learning can significantly enhance the quality and efficiency of screening, this method may be more applicable to certain types of datasets and problems. Ultimately, the decision to stop the active learning process depends on careful consideration of the trade-off between the costs of additional record labeling against the potential errors of the current model for the specific dataset and context.",['active learning']
2024,https://openalex.org/W4392661577,Biology,"Machine learning models for gully erosion susceptibility assessment in the Tensift catchment, Haouz Plain, Morocco for sustainable development","Gully erosion is a widespread environmental danger, threatening global socio-economic stability and sustainable development. This study comprehensively applied seven machine learning (ML) models including SVM, KNN, RF, XGBoost, ANN, DT, and LR, and evaluated gully erosion susceptibility in the Tensift catchment and predict it within the Haouz plain, Morocco. To ensure the reliability of the findings, the study employed a robust combination of gully erosion inventory, sentinel images, and Digital Surface Model. Eighteen predictors, encompassing topographical, geomorphological, environmental, and hydrological factors, were selected after multicollinearity analyses. The gully erosion susceptibility of the study revealed that approximately 28.18% of the Tensift catchment is at a very high risk of erosion. Furthermore, 15.13% and 31.28% of the catchment are categorized as low and very low respectively. These findings extend to the Haouz plain, where 7.84% of the surface area are very highly risking erosion, while 18.25% and 55.18% are characterized as low and very low risk areas. To gauge the performance of the ML models, an array of metrics including specificity, precision, sensitivity, and accuracy were employed. The study highlights XGBoost and KNN as the most promising models, achieving AUC ROC values of 0.96 and 0.93 in the test phase. The remaining models namely RF (AUC ROC = 0.89), LR (AUC ROC = 0.80), SVM (AUC ROC = 0.81), DT (AUC ROC = 0.86), and ANN (AUC ROC = 0.78), also displayed commendable performance. The novelty of this research is its innovative approach to combat gully erosion through cutting edge ML models, offering practical solutions for watershed conservation, sustainable management, and the prevention of land degradation. These insights are invaluable for addressing the challenges posed by gully erosion within the region, and beyond its geographical boundaries and can be used for defining appropriate mitigation strategies at local to national scale.","['SVM', 'KNN', 'RF', 'XGBoost', 'ANN', 'DT', 'LR']"
2024,https://openalex.org/W4390703358,Biology,A Deep Bidirectional LSTM Model Enhanced by Transfer-Learning-Based Feature Extraction for Dynamic Human Activity Recognition,"Dynamic human activity recognition (HAR) is a domain of study that is currently receiving considerable attention within the fields of computer vision and pattern recognition. The growing need for artificial-intelligence (AI)-driven systems to evaluate human behaviour and bolster security underscores the timeliness of this research. Despite the strides made by numerous researchers in developing dynamic HAR frameworks utilizing diverse pre-trained architectures for feature extraction and classification, persisting challenges include suboptimal performance accuracy and the computational intricacies inherent in existing systems. These challenges arise due to the vast video-based datasets and the inherent similarity in the data. To address these challenges, we propose an innovative, dynamic HAR technique employing a deep-learning-based, deep bidirectional long short-term memory (Deep BiLSTM) model facilitated by a pre-trained transfer-learning-based feature-extraction approach. Our approach begins with the utilization of Convolutional Neural Network (CNN) models, specifically MobileNetV2, for extracting deep-level features from video frames. Subsequently, these features are fed into an optimized deep bidirectional long short-term memory (Deep BiLSTM) network to discern dependencies and process data, enabling optimal predictions. During the testing phase, an iterative fine-tuning procedure is introduced to update the high parameters of the trained model, ensuring adaptability to varying scenarios. The proposed model’s efficacy was rigorously evaluated using three benchmark datasets, namely UCF11, UCF Sport, and JHMDB, achieving notable accuracies of 99.20%, 93.3%, and 76.30%, respectively. This high-performance accuracy substantiates the superiority of our proposed model, signaling a promising advancement in the domain of activity recognition.","['deep bidirectional long short-term memory (Deep BiLSTM)', 'pre-trained transfer-learning-based feature-extraction approach', 'Convolutional Neural Network (CNN)', 'MobileNetV2']"
2024,https://openalex.org/W4390881001,Biology,A multimodal graph neural network framework for cancer molecular subtype classification,"Abstract Background The recent development of high-throughput sequencing has created a large collection of multi-omics data, which enables researchers to better investigate cancer molecular profiles and cancer taxonomy based on molecular subtypes. Integrating multi-omics data has been proven to be effective for building more precise classification models. Most current multi-omics integrative models use either an early fusion in the form of concatenation or late fusion with a separate feature extractor for each omic, which are mainly based on deep neural networks. Due to the nature of biological systems, graphs are a better structural representation of bio-medical data. Although few graph neural network (GNN) based multi-omics integrative methods have been proposed, they suffer from three common disadvantages. One is most of them use only one type of connection, either inter-omics or intra-omic connection; second, they only consider one kind of GNN layer, either graph convolution network (GCN) or graph attention network (GAT); and third, most of these methods have not been tested on a more complex classification task, such as cancer molecular subtypes. Results In this study, we propose a novel end-to-end multi-omics GNN framework for accurate and robust cancer subtype classification. The proposed model utilizes multi-omics data in the form of heterogeneous multi-layer graphs, which combine both inter-omics and intra-omic connections from established biological knowledge. The proposed model incorporates learned graph features and global genome features for accurate classification. We tested the proposed model on the Cancer Genome Atlas (TCGA) Pan-cancer dataset and TCGA breast invasive carcinoma (BRCA) dataset for molecular subtype and cancer subtype classification, respectively. The proposed model shows superior performance compared to four current state-of-the-art baseline models in terms of accuracy, F1 score, precision, and recall. The comparative analysis of GAT-based models and GCN-based models reveals that GAT-based models are preferred for smaller graphs with less information and GCN-based models are preferred for larger graphs with extra information.","['deep neural networks', 'graph neural network (GNN)', 'graph convolution network (GCN)', 'graph attention network (GAT)']"
2024,https://openalex.org/W4392450360,Biology,Geographically weighted machine learning for modeling spatial heterogeneity in traffic crash frequency and determinants in US,"Spatial analyses of traffic crashes have drawn much interest due to the nature of the spatial dependence and spatial heterogeneity in the crash data. This study makes the best of Geographically Weighted Random Forest (GW-RF) model to explore the local associations between crash frequency and various influencing factors in the US, including road network attributes, socio-economic characteristics, and land use factors collected from multiple data sources. Special emphasis is put on modeling the spatial heterogeneity in the effects of a factor on crash frequency in different geographical areas in a data-driven way. The GW-RF model outperforms global models (e.g. Random Forest) and conventional geographically weighted regression, demonstrating superior predictive accuracy and elucidating spatial variations. The GW-RF model reveals spatial distinctions in the effects of certain factors on crash frequency. For example, the importance of intersection density varies significantly across regions, with high significance in the southern and northeastern areas. Low-grade road density emerges as influential in specific cities. The findings highlight the significance of different factors in influencing crash frequency across zones. Road network factors, particularly intersection density, exhibit high importance universally, while socioeconomic variables demonstrate moderate effects. Interestingly, land use variables show relatively lower importance. The outcomes could help to allocate resources and implement tailored interventions to reduce the likelihood of crashes.","['Geographically Weighted Random Forest (GW-RF)', 'Random Forest']"
2024,https://openalex.org/W4399649641,Biology,An artificial intelligence-assisted microfluidic colorimetric wearable sensor system for monitoring of key tear biomarkers,"Abstract The precise, simultaneous, and rapid detection of essential biomarkers in human tears is imperative for monitoring both ocular and systemic health. The utilization of a wearable colorimetric biochemical sensor exhibits potential in achieving swift and concurrent detection of pivotal biomarkers in tears. Nevertheless, challenges arise in the collection, interpretation, and sharing of data from the colorimetric sensor, thereby restricting the practical implementation of this technology. To overcome these challenges, this research introduces an artificial intelligence-assisted wearable microfluidic colorimetric sensor system (AI-WMCS) for rapid, non-invasive, and simultaneous detection of key biomarkers in human tears, including vitamin C, H + (pH), Ca 2+ , and proteins. The sensor consists of a flexible microfluidic epidermal patch that collects tears and facilitates the colorimetric reaction, and a deep-learning neural network-based cloud server data analysis system (CSDAS) embedded in a smartphone enabling color data acquisition, interpretation, auto-correction, and display. To enhance accuracy, a well-trained multichannel convolutional recurrent neural network (CNN-GRU) corrects errors in the interpreted concentration data caused by varying pH and color temperature in different measurements. The test set determination coefficients (R 2 ) of 1D-CNN-GRU for predicting pH and 3D-CNN-GRU for predicting the other three biomarkers were as high as 0.998 and 0.994, respectively. This correction significantly improves the accuracy of the predicted concentration, enabling accurate, simultaneous, and quick detection of four critical tear biomarkers using only minute amounts of tears ( ~ 20 μL). This research demonstrates the powerful integration of a flexible microfluidic colorimetric biosensor and deep-learning algorithm, which holds immense potential to revolutionize the fields of health monitoring.","['multichannel convolutional recurrent neural network (CNN-GRU)', '1D-CNN-GRU', '3D-CNN-GRU']"
2024,https://openalex.org/W4391665000,Biology,A comprehensive review of critical analysis of biodegradable waste PCM for thermal energy storage systems using machine learning and deep learning to predict dynamic behavior,"This article explores the use of phase change materials (PCMs) derived from waste, in energy storage systems. It emphasizes the potential of these PCMs in addressing concerns related to fossil fuel usage and environmental impact. This article also highlights the aspects of these PCMs including reduced reliance on renewable resources minimized greenhouse gas emissions and waste reduction. The study also discusses approaches such as integrating nanotechnology to enhance thermal conductivity and utilizing machine learning and deep learning techniques for predicting dynamic behavior. The article provides an overall view of research on biodegradable waste-based PCMs and how they can play a promising role in achieving energy-efficient and sustainable thermal storage systems. However, specific conclusions drawn from the presented results are not explicitly outlined, leaving room, for investigation and exploration in this evolving field. Artificial neural network (ANN) predictive models for thermal energy storage devices perform differently. With a 4% adjusted mean absolute error, the Gaussian radial basis function kernel Support Vector Regression (SVR) model captured heat-related charging and discharging issues. The ANN model predicted finned tube heat and heat flux better than the numerical model. SVM models outperformed ANN and ANFIS in some datasets. Material property predictions favored gradient boosting, but Linear Regression and SVR models performed better, emphasizing application- and dataset-specific model selection. These predictive models provide insights into the complex thermal performance of building structures, aiding in the design and operation of energy-efficient systems. Biodegradable waste-based PCMs' sustainability includes carbon footprint, waste reduction, biodegradability, and circular economy alignment. Nanotechnology, machine learning, and deep learning improve thermal conductivity and prediction. Circular economy principles include waste reduction and carbon footprint reduction. Specific results-based conclusions are not stated. Presenting a comprehensive overview of current research highlights biodegradable waste-based PCMs' potential for energy-efficient and sustainable thermal storage systems.","['machine learning', 'deep learning', 'Artificial neural network (ANN)', 'Gaussian radial basis function kernel Support Vector Regression (SVR)', 'Support Vector Machine (SVM)', 'Adaptive Neuro-Fuzzy Inference System (ANFIS)', 'gradient boosting', 'Linear Regression']"
2024,https://openalex.org/W4392112102,Biology,Coupling Deep Learning and Physically Based Hydrological Models for Monthly Streamflow Predictions,"Abstract This study proposes a new hybrid model for monthly streamflow predictions by coupling a physically based distributed hydrological model with a deep learning (DL) model. Specifically, a simplified hydrological model is first developed by optimally selecting grid cells from a distributed hydrological model according to their soil moisture characteristics. It is then driven by bias corrected general circulation model (GCM) predictions to generate soil moistures for the forecasting months. Finally, model‐simulated soil moisture along with other predictors from multiple sources are used as inputs of the DL model to predict future monthly streamflows. The proposed hybrid model, using the simplified Variable Infiltration Capacity (VIC) as the hydrological model and the combination of Convolutional Neural Network and Gated Recurrent Unit (CNN‐GRU) as the DL model, is applied to predict 1‐, 3‐, and 6‐month ahead reservoir inflows for the Danjiangkou Reservoir in China. The results show that the hybrid model consistently performs better than VIC and CNN‐GRU models with great improvement in Kling‐Gupta efficiency (KGE) values for lead times up to 6 months. Additional tests indicate that hybrid models based on CNN‐GRU outperform those based on LASSO, XGBoost, CNN, and GRU models. Moreover, compared with the distributed hydrological model, the hybrid model greatly reduces the computation burden of rolling prediction. It also saves decision‐makers the time and effort of trying different combinations of predictors, which is indispensable when building DL models. Overall, the new hybrid model demonstrates great potential for monthly streamflow prediction where training data are limited.","['Convolutional Neural Network (CNN)', 'Gated Recurrent Unit (GRU)', 'CNN-GRU', 'LASSO', 'XGBoost', 'CNN', 'GRU']"
2024,https://openalex.org/W4400061043,Biology,MTMol-GPT: De novo multi-target molecular generation with transformer-based generative adversarial imitation learning,"De novo drug design is crucial in advancing drug discovery, which aims to generate new drugs with specific pharmacological properties. Recently, deep generative models have achieved inspiring progress in generating drug-like compounds. However, the models prioritize a single target drug generation for pharmacological intervention, neglecting the complicated inherent mechanisms of diseases, and influenced by multiple factors. Consequently, developing novel multi-target drugs that simultaneously target specific targets can enhance anti-tumor efficacy and address issues related to resistance mechanisms. To address this issue and inspired by Generative Pre-trained Transformers (GPT) models, we propose an upgraded GPT model with generative adversarial imitation learning for multi-target molecular generation called MTMol-GPT. The multi-target molecular generator employs a dual discriminator model using the Inverse Reinforcement Learning (IRL) method for a concurrently multi-target molecular generation. Extensive results show that MTMol-GPT generates various valid, novel, and effective multi-target molecules for various complex diseases, demonstrating robustness and generalization capability. In addition, molecular docking and pharmacophore mapping experiments demonstrate the drug-likeness properties and effectiveness of generated molecules potentially improve neuropsychiatric interventions. Furthermore, our model’s generalizability is exemplified by a case study focusing on the multi-targeted drug design for breast cancer. As a broadly applicable solution for multiple targets, MTMol-GPT provides new insight into future directions to enhance potential complex disease therapeutics by generating high-quality multi-target molecules in drug discovery.","['Generative Pre-trained Transformers (GPT)', 'generative adversarial imitation learning', 'Inverse Reinforcement Learning (IRL)']"
2024,https://openalex.org/W4401209403,Biology,AI-Driven Deep Learning Techniques in Protein Structure Prediction,"Protein structure prediction is important for understanding their function and behavior. This review study presents a comprehensive review of the computational models used in predicting protein structure. It covers the progression from established protein modeling to state-of-the-art artificial intelligence (AI) frameworks. The paper will start with a brief introduction to protein structures, protein modeling, and AI. The section on established protein modeling will discuss homology modeling, ab initio modeling, and threading. The next section is deep learning-based models. It introduces some state-of-the-art AI models, such as AlphaFold (AlphaFold, AlphaFold2, AlphaFold3), RoseTTAFold, ProteinBERT, etc. This section also discusses how AI techniques have been integrated into established frameworks like Swiss-Model, Rosetta, and I-TASSER. The model performance is compared using the rankings of CASP14 (Critical Assessment of Structure Prediction) and CASP15. CASP16 is ongoing, and its results are not included in this review. Continuous Automated Model EvaluatiOn (CAMEO) complements the biennial CASP experiment. Template modeling score (TM-score), global distance test total score (GDT_TS), and Local Distance Difference Test (lDDT) score are discussed too. This paper then acknowledges the ongoing difficulties in predicting protein structure and emphasizes the necessity of additional searches like dynamic protein behavior, conformational changes, and protein-protein interactions. In the application section, this paper introduces some applications in various fields like drug design, industry, education, and novel protein development. In summary, this paper provides a comprehensive overview of the latest advancements in established protein modeling and deep learning-based models for protein structure predictions. It emphasizes the significant advancements achieved by AI and identifies potential areas for further investigation.","['AlphaFold', 'AlphaFold2', 'RoseTTAFold', 'ProteinBERT']"
2024,https://openalex.org/W4390660035,Biology,An Empirical Study on Correlations Between Deep Neural Network Fairness and Neuron Coverage Criteria,"Recently, with the widespread use of deep neural networks (DNNs) in high-stakes decision-making systems (such as fraud detection and prison sentencing), concerns have arisen about the fairness of DNNs in terms of the potential negative impact they may have on individuals and society. Therefore, fairness testing has become an important research topic in DNN testing. At the same time, the neural network coverage criteria (such as criteria based on neuronal activation) is considered as an adequacy test for DNN white-box testing. It is implicitly assumed that improving the coverage can enhance the quality of test suites. Nevertheless, the correlation between DNN fairness (a test property) and coverage criteria (a test method) has not been adequately explored. To address this issue, we conducted a systematic empirical study on seven coverage criteria, six fairness metrics, three fairness testing techniques, and five bias mitigation methods on five DNN models and nine fairness datasets to assess the correlation between coverage criteria and DNN fairness. Our study achieved the following findings: 1) with the increase in the size of the test suite, some of the coverage and fairness metrics changed significantly, as the size of the test suite increased; 2) the statistical correlation between coverage criteria and DNN fairness is limited; and 3) after bias mitigation for improving the fairness of DNN, the change pattern in coverage criteria is different; 4) Models debiased by different bias mitigation methods have a lower correlation between coverage and fairness compared to the original models. Our findings cast doubt on the validity of coverage criteria concerning DNN fairness (i.e., increasing the coverage may even have a negative impact on the fairness of DNNs). Therefore, we warn DNN testers against blindly pursuing higher coverage of coverage criteria at the cost of test properties of DNNs (such as fairness).","['deep neural networks (DNNs)', 'bias mitigation methods']"
2024,https://openalex.org/W4391097037,Biology,An Early and Smart Detection of Corn Plant Leaf Diseases Using IoT and Deep Learning Multi-Models,"Plant leaf diseases have various causes, leading to severe disorders. The early and accurate detection and classification of these diseases are fundamental for fostering healthy crop production. In recent years, smart agricultural systems have garnered significant attention due to their capability to enhance efficiency by deploying sensor networks and Internet of Things (IoT) devices that collect and analyze environmental data. However, traditional plant disease detection methods are manual, time-consuming, and often need help handling the data's complexity and dynamism. These manual methods do not use heterogeneous data to make better decisions. Corn holds significant importance yet it faces numerous diseases that include main three diseases such as blight, common rust, and grey leaf spot. The advancement of computer technology has led to a pivotal focus on corn leaf diseases classification application based on deep learning. Convolutional Neural Networks (CNNs) have revealed remarkable achievements within Precision Agriculture (PA) due to their ability to enhance information. To this end, this work introduces a CNN-based architecture, the Multi-Model Fusion Network (MMF-Net). Its primary objective is to classify diseases within the realm of PA. MMF-Net integrates multi-contextual features using RL-block and PL-blocks 1 & 2, thus effectively combining different model streams trained on heterogeneous data. The RL-block uses spatial range to process coarse grained images to convolve the local context, while PL-block 1 extracts fine-grained global context by expanding the perceptual area of images. PL-block 2 deals with real-life environmental parameters as features. The extracted features are syndicated using multiple classifiers that ensemble three individual blocks at the decision level to improve the accuracy. After fusion, it uses adaptively the majority voting scheme to generate the final decision probability score of the base model. Multiple experiments are conducted involving the corn leaf diseases dataset and a real-life numerical dataset, generating an impressive 99.23% accuracy in the classification of corn leaf diseases. Overall, MMF-Net provides a promising and smart solution to identify plant leaf diseases in PA effectively.","['Convolutional Neural Networks (CNNs)', 'multiple classifiers ensemble']"
2024,https://openalex.org/W4392404413,Biology,Investigating the Impact of Train / Test Split Ratio on the Performance of Pre-Trained Models with Custom Datasets,"The proper allocation of data between training and testing is a critical factor influencing the performance of deep learning models, especially those built upon pre-trained architectures. Having the suitable training set size is an important factor for the classification model’s generalization performance. The main goal of this study is to find the appropriate training set size for three pre-trained networks using different custom datasets. For this aim, the study presented in this paper explores the effect of varying the train / test split ratio on the performance of three popular pre-trained models, namely MobileNetV2, ResNet50v2 and VGG19, with a focus on image classification task. In this work, three balanced datasets never seen by the models have been used, each containing 1000 images divided into two classes. The train / test split ratios used for this study are: 60-40, 70-30, 80-20 and 90-10. The focus was on the critical metrics of sensitivity, specificity and overall accuracy to evaluate the performance of the classifiers under the different ratios. Experimental results show that, the performance of the classifiers is affected by varying the training / testing split ratio for the three custom datasets. Moreover, with the three pre-trained models, using more than 70% of the dataset images for the training task gives better performance.","['MobileNetV2', 'ResNet50v2', 'VGG19']"
2024,https://openalex.org/W4393044095,Biology,"Comparative performance analysis of Boruta, SHAP, and Borutashap for disease diagnosis: A study with multiple machine learning algorithms","Interpretable machine learning models are instrumental in disease diagnosis and clinical decision-making, shedding light on relevant features. Notably, Boruta, SHAP (SHapley Additive exPlanations), and BorutaShap were employed for feature selection, each contributing to the identification of crucial features. These selected features were then utilized to train six machine learning algorithms, including LR, SVM, ETC, AdaBoost, RF, and LR, using diverse medical datasets obtained from public sources after rigorous preprocessing. The performance of each feature selection technique was evaluated across multiple ML models, assessing accuracy, precision, recall, and F1-score metrics. Among these, SHAP showcased superior performance, achieving average accuracies of 80.17%, 85.13%, 90.00%, and 99.55% across diabetes, cardiovascular, statlog, and thyroid disease datasets, respectively. Notably, the LGBM emerged as the most effective algorithm, boasting an average accuracy of 91.00% for most disease states. Moreover, SHAP enhanced the interpretability of the models, providing valuable insights into the underlying mechanisms driving disease diagnosis. This comprehensive study contributes significant insights into feature selection techniques and machine learning algorithms for disease diagnosis, benefiting researchers and practitioners in the medical field. Further exploration of feature selection methods and algorithms holds promise for advancing disease diagnosis methodologies, paving the way for more accurate and interpretable diagnostic models.","['Boruta', 'SHAP (SHapley Additive exPlanations)', 'LR', 'SVM', 'AdaBoost', 'RF', 'LGBM']"
2024,https://openalex.org/W4395479913,Biology,Machinability investigation of natural fibers reinforced polymer matrix composite under drilling: Leveraging machine learning in bioengineering applications,"The growing demand for fiber-reinforced polymer (FRP) in industrial applications has prompted the exploration of natural fiber-based composites as a viable alternative to synthetic fibers. Using jute–rattan fiber-reinforced composite offers the potential for environmentally sustainable waste material decomposition and cost reduction compared to conventional fiber materials. This article focuses on the impact of different machining constraints on surface roughness and delamination during the drilling process of the jute–rattan FRP composite. Inspired by this unexplored research area, this article emphasizes the influence of various machining constraints on surface roughness and delamination in drilling jute–rattan FRP composite. Response surface methodology designs the experiment using drill bit material, spindle speed, and feed rate as input variables to measure surface roughness and delamination factors. The technique of order of preference by similarity to the ideal solution method is used to optimize the machining parameters, and for predicting surface roughness and delamination, two machine learning-based models named random forest (RF) and support vector machine (SVM) are utilized. To evaluate the accuracy of the predicted values, the correlation coefficient (R2), mean absolute percentage error, and mean squared error were used. RF performed better in comparison with SVM, with a higher value of R2 for both testing and training datasets, which is 0.997, 0.981, and 0.985 for surface roughness, entry delamination, and exit delamination, respectively. Hence, this study presents an innovative methodology for predicting surface roughness and delamination through machine learning techniques.","['random forest (RF)', 'support vector machine (SVM)']"
2024,https://openalex.org/W4403158403,Biology,Artificial intelligence alphafold model for molecular biology and drug discovery: a machine-learning-driven informatics investigation,"AlphaFold model has reshaped biological research. However, vast unstructured data in the entire AlphaFold field requires further analysis to fully understand the current research landscape and guide future exploration. Thus, this scientometric analysis aimed to identify critical research clusters, track emerging trends, and highlight underexplored areas in this field by utilizing machine-learning-driven informatics methods. Quantitative statistical analysis reveals that the AlphaFold field is enjoying an astonishing development trend (Annual Growth Rate = 180.13%) and global collaboration (International Co-authorship = 33.33%). Unsupervised clustering algorithm, time series tracking, and global impact assessment point out that Cluster 3 (Artificial Intelligence-Powered Advancements in AlphaFold for Structural Biology) has the greatest influence (Average Citation = 48.36 ± 184.98). Additionally, regression curve and hotspot burst analysis highlight ""structure prediction"" (s = 12.40, R2 = 0.9480, p = 0.0051), ""artificial intelligence"" (s = 5.00, R2 = 0.8096, p = 0.0375), ""drug discovery"" (s = 1.90, R2 = 0.7987, p = 0.0409), and ""molecular dynamics"" (s = 2.40, R2 = 0.8000, p = 0.0405) as core hotspots driving the research frontier. More importantly, the Walktrap algorithm further reveals that ""structure prediction, artificial intelligence, molecular dynamics"" (Relevance Percentage[RP] = 100%, Development Percentage[DP] = 25.0%), ""sars-cov-2, covid-19, vaccine design"" (RP = 97.8%, DP = 37.5%), and ""homology modeling, virtual screening, membrane protein"" (RP = 89.9%, DP = 26.1%) are closely intertwined with the AlphaFold model but remain underexplored, which implies a broad exploration space. In conclusion, through the machine-learning-driven informatics methods, this scientometric analysis offers an objective and comprehensive overview of global AlphaFold research, identifying critical research clusters and hotspots while prospectively pointing out underexplored critical areas.",['unsupervised clustering algorithm']
2024,https://openalex.org/W4392499245,Biology,Exploring the role of skin temperature in thermal sensation and thermal comfort: A comprehensive review,"The role of skin temperature as a determinant of human thermal sensation and comfort has gained increasing recognition, prompting a need for a systematic review. This review examines the relationship between skin temperature and thermal sensation, synthesizing insights from 172 studies published since 2000. It uniquely focuses on the indispensable roles of local and mean skin temperatures, a perspective not comprehensively explored in previous literature. The review reveals that the most common measurement points for skin temperature are the face and hands, attributed to their higher thermal sensitivity and the practical ease of measurement. It establishes a clear linear relationship between mean skin temperature and user thermal sensation, though affected by the choice of measurement locations and number of points. A notable finding is the varying impact of local skin temperature on overall thermal sensation in changing environments, with local heating less influential than cooling. The review also uncovers significant demographic variations in thermal sensation, strongly influenced by differing skin temperatures across age groups, genders, and climatic regions. For example, elderly populations exhibit a decreased temperature sensitivity, especially towards warmth. Gender differences are also significant, with females experiencing higher skin temperatures in warmer environments and lower in colder ones. Machine learning (ML)-based methods, especially classification tree-based and support vector machine (SVM) techniques, dominate in predicting thermal sensation and comfort, leveraging skin temperature data. While ML methods are prevalent, statistical regression-based approaches offer valuable empirical insights. Thermo-physiological model-based methods provide reliable results by incorporating detailed skin temperature dynamics. The review identifies a gap in understanding how gender, age, and regional differences influence thermal comfort in diverse environments. The study recommends conducting more nuanced experiments to dissect the impact of these factors and proposes the integration of individual demographic variables into ML models to personalize thermal comfort predictions.","['support vector machine (SVM)', 'statistical regression-based approaches']"
2024,https://openalex.org/W4393380917,Biology,Motif-Aware miRNA-Disease Association Prediction via Hierarchical Attention Network,"As post-transcriptional regulators of gene expression, micro-ribonucleic acids (miRNAs) are regarded as potential biomarkers for a variety of diseases. Hence, the prediction of miRNA-disease associations (MDAs) is of great significance for an in-depth understanding of disease pathogenesis and progression. Existing prediction models are mainly concentrated on incorporating different sources of biological information to perform the MDA prediction task while failing to consider the fully potential utility of MDA network information at the motif-level. To overcome this problem, we propose a novel motif-aware MDA prediction model, namely MotifMDA, by fusing a variety of high- and low-order structural information. In particular, we first design several motifs of interest considering their ability to characterize how miRNAs are associated with diseases through different network structural patterns. Then, MotifMDA adopts a two-layer hierarchical attention to identify novel MDAs. Specifically, the first attention layer learns high-order motif preferences based on their occurrences in the given MDA network, while the second one learns the final embeddings of miRNAs and diseases through coupling high- and low-order preferences. Experimental results on two benchmark datasets have demonstrated the superior performance of MotifMDA over several state-of-the-art prediction models. This strongly indicates that accurate MDA prediction can be achieved by relying solely on MDA network information. Furthermore, our case studies indicate that the incorporation of motif-level structure information allows MotifMDA to discover novel MDAs from different perspectives. The data and codes are available at <uri xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">https://github.com/stevejobws/MotifMDA.</uri>",['two-layer hierarchical attention']
2024,https://openalex.org/W4394011823,Biology,"Artificial intelligence in lung cancer screening: Detection, classification, prediction, and prognosis","Abstract Background The exceptional capabilities of artificial intelligence (AI) in extracting image information and processing complex models have led to its recognition across various medical fields. With the continuous evolution of AI technologies based on deep learning, particularly the advent of convolutional neural networks (CNNs), AI presents an expanded horizon of applications in lung cancer screening, including lung segmentation, nodule detection, false‐positive reduction, nodule classification, and prognosis. Methodology This review initially analyzes the current status of AI technologies. It then explores the applications of AI in lung cancer screening, including lung segmentation, nodule detection, and classification, and assesses the potential of AI in enhancing the sensitivity of nodule detection and reducing false‐positive rates. Finally, it addresses the challenges and future directions of AI in lung cancer screening. Results AI holds substantial prospects in lung cancer screening. It demonstrates significant potential in improving nodule detection sensitivity, reducing false‐positive rates, and classifying nodules, while also showing value in predicting nodule growth and pathological/genetic typing. Conclusions AI offers a promising supportive approach to lung cancer screening, presenting considerable potential in enhancing nodule detection sensitivity, reducing false‐positive rates, and classifying nodules. However, the universality and interpretability of AI results need further enhancement. Future research should focus on the large‐scale validation of new deep learning‐based algorithms and multi‐center studies to improve the efficacy of AI in lung cancer screening.","['deep learning', 'convolutional neural networks (CNNs)']"
2024,https://openalex.org/W4394753955,Biology,Distributed Hydrological Modeling With Physics‐Encoded Deep Learning: A General Framework and Its Application in the Amazon,"Abstract While deep learning (DL) models exhibit superior simulation accuracy over traditional distributed hydrological models (DHMs), their main limitations lie in opacity and the absence of underlying physical mechanisms. The pursuit of synergies between DL and DHMs is an engaging research domain, yet a definitive roadmap remains elusive. In this study, a novel framework that seamlessly integrates a process‐based hydrological model encoded as a neural network (NN), an additional NN for mapping spatially distributed and physically meaningful parameters from watershed attributes, and NN‐based replacement models representing inadequately understood processes is developed. Multi‐source observations are used as training data, and the framework is fully differentiable, enabling fast parameter tuning by backpropagation. A hybrid DL model of the Amazon Basin (∼6 × 10 6 km 2 ) was established based on the framework, and HydroPy, a global‐scale DHM, was encoded as its physical backbone. Trained simultaneously with streamflow observations and Gravity Recovery and Climate Experiment satellite data, the hybrid model yielded median Nash‐Sutcliffe efficiencies of 0.83 and 0.77 for dynamic and distributed simulations of streamflow and total water storage, respectively, 41% and 35% higher than those of the original HydroPy model. Replacing the original Penman‒Monteith formulation in HydroPy with a replacement NN produces more plausible potential evapotranspiration (PET) estimates, and unravels the spatial pattern of PET in this giant basin. The NN used for parameterization was interpreted to identify the factors controlling the spatial variability in key parameters. Overall, this study lays out a feasible technical roadmap for distributed hydrological modeling in the big data era.","['deep learning (DL) models', 'neural network (NN)', 'NN-based replacement models', 'backpropagation']"
2024,https://openalex.org/W4395069357,Biology,Characterizing land use/land cover change dynamics by an enhanced random forest machine learning model: a Google Earth Engine implementation,"Abstract Land use and land cover (LULC) analysis is crucial for understanding societal development and assessing changes during the Anthropocene era. Conventional LULC mapping faces challenges in capturing changes under cloud cover and limited ground truth data. To enhance the accuracy and comprehensiveness of the descriptions of LULC changes, this investigation employed a combination of advanced techniques. Specifically, multitemporal 30 m resolution Landsat-8 satellite imagery was utilized, in addition to the cloud computing capabilities of the Google Earth Engine (GEE) platform. Additionally, the study incorporated the random forest (RF) algorithm. This study aimed to generate continuous LULC maps for 2014 and 2020 for the Shrirampur area of Maharashtra, India. A novel multiple composite RF approach based on LULC classification was utilized to generate the final LULC classification maps utilizing the RF-50 and RF-100 tree models. Both RF models utilized seven input bands (B1 to B7) as the dataset for LULC classification. By incorporating these bands, the models were able to influence the spectral information captured by each band to classify the LULC categories accurately. The inclusion of multiple bands enhanced the discrimination capabilities of the classifiers, increasing the comprehensiveness of the assessment of the LULC classes. The analysis indicated that RF-100 exhibited higher training and validation/testing accuracy for 2014 and 2020 (0.99 and 0.79/0.80, respectively). The study further revealed that agricultural land, built-up land, and water bodies have changed adequately and have undergone substantial variation among the LULC classes in the study area. Overall, this research provides novel insights into the application of machine learning (ML) models for LULC mapping and emphasizes the importance of selecting the optimal tree combination for enhancing the accuracy and reliability of LULC maps based on the GEE and different RF tree models. The present investigation further enabled the interpretation of pixel-level LULC interactions while improving image classification accuracy and suggested the best models for the classification of LULC maps through the identification of changes in LULC classes.",['random forest (RF) algorithm']
2024,https://openalex.org/W4395954533,Biology,DeepKEGG: a multi-omics data integration framework with biological insights for cancer recurrence prediction and biomarker discovery,"Abstract Deep learning-based multi-omics data integration methods have the capability to reveal the mechanisms of cancer development, discover cancer biomarkers and identify pathogenic targets. However, current methods ignore the potential correlations between samples in integrating multi-omics data. In addition, providing accurate biological explanations still poses significant challenges due to the complexity of deep learning models. Therefore, there is an urgent need for a deep learning-based multi-omics integration method to explore the potential correlations between samples and provide model interpretability. Herein, we propose a novel interpretable multi-omics data integration method (DeepKEGG) for cancer recurrence prediction and biomarker discovery. In DeepKEGG, a biological hierarchical module is designed for local connections of neuron nodes and model interpretability based on the biological relationship between genes/miRNAs and pathways. In addition, a pathway self-attention module is constructed to explore the correlation between different samples and generate the potential pathway feature representation for enhancing the prediction performance of the model. Lastly, an attribution-based feature importance calculation method is utilized to discover biomarkers related to cancer recurrence and provide a biological interpretation of the model. Experimental results demonstrate that DeepKEGG outperforms other state-of-the-art methods in 5-fold cross validation. Furthermore, case studies also indicate that DeepKEGG serves as an effective tool for biomarker discovery. The code is available at https://github.com/lanbiolab/DeepKEGG.","['deep learning-based multi-omics data integration methods', 'attribution-based feature importance calculation method']"
2024,https://openalex.org/W4400724905,Biology,Hyperspectral Image Analysis and Machine Learning Techniques for Crop Disease Detection and Identification: A Review,"Originally, the use of hyperspectral images was for military applications, but their use has been extended to precision agriculture. In particular, they are used for activities related to crop classification or disease detection, combining these hyperspectral images with machine learning techniques and algorithms. The study of hyperspectral images has a wide range of wavelengths for observation. These wavelengths allow for monitoring agricultural crops such as cereals, oilseeds, vegetables, and fruits, and other applications. In the ranges of these wavelengths, crop conditions such as maturity index and nutrient status, or the early detection of some diseases that cause losses in crops, can be studied and diagnosed. Therefore, this article proposes a technical review of the main applications of hyperspectral images in agricultural crops and perspectives and challenges that combine artificial intelligence algorithms such as machine learning and deep learning in the classification and detection of diseases of crops such as cereals, oilseeds, fruits, and vegetables. A systematic review of the scientific literature was carried out using a 10-year observation window to determine the evolution of the integration of these technological tools that support sustainable agriculture; among the findings, information on the most documented crops is highlighted, among which are some cereals and citrus fruits due to their high demand and large cultivation areas, as well as information on the main fruits and vegetables that are integrating these technologies. Also, the main artificial intelligence algorithms that are being worked on are summarized and classified, as well as the wavelength ranges for the prediction, disease detection, and analysis of other tasks of physiological characteristics used for sustainable production. This review can be useful as a reference for future research, based mainly on detection, classification, and other tasks in agricultural crops and decision making, to implement the most appropriate artificial intelligence algorithms.","['machine learning', 'deep learning']"
2024,https://openalex.org/W4403248109,Biology,Optimizing cancer classification: a hybrid RDO-XGBoost approach for feature selection and predictive insights,"The identification of relevant biomarkers from high-dimensional cancer data remains a significant challenge due to the complexity and heterogeneity inherent in various cancer types. Conventional feature selection methods often struggle to effectively navigate the vast solution space while maintaining high predictive accuracy. In response to these challenges, we introduce a novel feature selection approach that integrates Random Drift Optimization (RDO) with XGBoost, specifically designed to enhance the performance of cancer classification tasks. Our proposed framework not only improves classification accuracy but also offers valuable insights into the underlying biological mechanisms driving cancer progression. Through comprehensive experiments conducted on real-world cancer datasets, including Central Nervous System (CNS), Leukemia, Breast, and Ovarian cancers, we demonstrate the efficacy of our method in identifying a smaller subset of unique and relevant genes. This selection results in significantly improved classification efficiency and accuracy. When compared with popular classifiers such as Support Vector Machine, K-Nearest Neighbor, and Naive Bayes, our approach consistently outperforms these models in terms of both accuracy and F-measure metrics. For instance, our framework achieved an accuracy of 97.24% in the CNS dataset, 99.14% in Leukemia, 95.21% in Ovarian, and 87.62% in Breast cancer, showcasing its robustness and effectiveness across different types of cancer data. These results underline the potential of our RDO-XGBoost framework as a promising solution for feature selection in cancer data analysis, offering enhanced predictive performance and valuable biological insights.","['XGBoost', 'Support Vector Machine', 'K-Nearest Neighbor', 'Naive Bayes']"
2024,https://openalex.org/W4390604872,Biology,Cross-Domain Class Incremental Broad Network for Continuous Diagnosis of Rotating Machinery Faults Under Variable Operating Conditions,"Machine learning models have been widely successful in the field of intelligent fault diagnosis. Most of the existing machine learning models are deployed in static environments and rely on precollected datasets for offline training, which makes it impossible to update the models further once they are established. However, in the open and dynamic environment in reality, there is always incoming data in the form of streams, including new categories of data that are constantly generated over time. In addition, the operating conditions of mechanical equipment are time-varying, which results in continuous stream data that are nonindependently and homogeneously distributed. In industrial applications, the diagnosis problem of nonindependent and identically distributed continuous streaming data is referred to as the cross-domain class incremental diagnosis problem. To address the cross-domain class incremental problem, a novel cross-domain class incremental broad network (CDCIBN) is proposed. Specifically, to solve the nonindependent identically distributed problem, a novel domain-adaptation learning loss function is first designed, which enables the conventional broad network to handle the category increment task well. Then, a cross-domain class incremental learning mechanism is designed, which learns new categories while retaining the knowledge of old categories well enough without replaying old category data. The effectiveness of the proposed method is evaluated through multiple mechanical failure increment cases. Experimental analysis demonstrates that the designed CDCIBN has significant advantages in the variable working condition class incremental application.",['cross-domain class incremental learning mechanism']
2024,https://openalex.org/W4390686423,Biology,Real-life data-driven model predictive control for building energy systems comparing different machine learning models,"By considering forecasts and exploiting storage effects, model predictive control can achieve significant energy and cost savings in the building sector. However, due to the high individual modeling effort, model predictive control lacks practical applicability. For that reason, data-driven process models, approximating the system behavior based on measurements, have become increasingly popular in recent years. Still, scientific literature lacks consent about the most promising model types and efficient workflows to integrate different machine learning models into a model predictive controller. With this work, we present a workflow to provide efficient model predictive controllers based on measurement data automatically. The main idea is to translate different machine learning models into optimization syntax to enable efficient optimization with full access to gradients. We currently consider artificial neural networks, gaussian process regression, and simple linear regression process models. We use a generic model ontology to automatize the controller generation further and test the methodology on two real-life use cases. The first use case is the application of five office rooms with smart thermostat valves. The second use case is a test hall with an air handling unit and a concrete core activation. Using only two days of initial training data, we deploy controllers based on the different model types for six weeks in the offices and apply online learning to improve the models continuously. We observe only minor differences in controller performance despite the artificial neural networks showing the highest prediction accuracy. The second use case shows that the simple linear models require less controller tuning effort. Thus, for practical applications, we recommend linear regression models.","['artificial neural networks', 'gaussian process regression', 'linear regression']"
2024,https://openalex.org/W4391684052,Biology,Enhancing MPPT performance for partially shaded photovoltaic arrays through backstepping control with Genetic Algorithm-optimized gains,"As the significance and complexity of solar panel performance, particularly at their maximum power point (MPP), continue to grow, there is a demand for improved monitoring systems. The presence of variable weather conditions in Maroua, including potential partial shadowing caused by cloud cover or urban buildings, poses challenges to the efficiency of solar systems. This study introduces a new approach to tracking the Global Maximum Power Point (GMPP) in photovoltaic systems within the context of solar research conducted in Cameroon. The system utilizes Genetic Algorithm (GA) and Backstepping Controller (BSC) methodologies. The Backstepping Controller (BSC) dynamically adjusts the duty cycle of the Single Ended Primary Inductor Converter (SEPIC) to align with the reference voltage of the Genetic Algorithm (GA) in Maroua's dynamic environment. This environment, characterized by intermittent sunlight and the impact of local factors and urban shadowing, affects the production of energy. The Genetic Algorithm is employed to enhance the efficiency of BSC gains in Maroua's solar environment. This optimization technique expedites the tracking process and minimizes oscillations in the GMPP. The adaptability of the learning algorithm to specific conditions improves energy generation, even in the challenging environment of Maroua. This study introduces a novel approach to enhance the efficiency of photovoltaic systems in Maroua, Cameroon, by tailoring them to the specific solar dynamics of the region. In terms of performance, our approach surpasses the INC-BSC, P&O-BSC, GA-BSC, and PSO-BSC methodologies. In practice, the stabilization period following shadowing typically requires fewer than three iterations. Additionally, our Maximum Power Point Tracking (MPPT) technology is based on the Global Maximum Power Point (GMPP) methodology, contrasting with alternative technologies that prioritize the Local Maximum Power Point (LMPP). This differentiation is particularly relevant in areas with partial shading, such as Maroua, where the use of LMPP-based technologies can result in power losses. The proposed method demonstrates significant performance by achieving a minimum 33% reduction in power losses.",['Genetic Algorithm (GA)']
2024,https://openalex.org/W4391995887,Biology,"funspace: An R package to build, analyse and plot functional trait spaces","Abstract Aim Functional trait space analyses are pivotal to describe and compare organisms' functional diversity across the tree of life. Yet, there is no single application that streamlines the many sometimes‐troublesome steps needed to build and analyse functional trait spaces. Innovation To fill this gap, we propose funspace , an R package to easily handle bivariate and multivariate functional trait space analyses. The six functions that constitute the package can be grouped in three modules: ‘Building and exploring’, ‘Mapping’ and ‘Plotting’. The building and exploring module defines the main features of a functional trait space (e.g. functional diversity metrics) by leveraging kernel density‐based methods. The mapping module uses general additive models to map how a target variable distributes within a trait space. The plotting module provides many options for creating flexible and publication‐ready figures representing the outputs obtained from previous modules. We provide a worked example to demonstrate a complete funspace workflow. Main Conclusions funspace will provide researchers working with functional traits across the tree of life with a new tool to easily explore: (i) the main features of any functional trait space, (ii) the relationship between a functional trait space and any other biological or non‐biological factor that might contribute to shaping species' functional diversity.","['kernel density-based methods', 'general additive models']"
2024,https://openalex.org/W4392111029,Biology,GAM-MDR: probing miRNA–drug resistance using a graph autoencoder based on random path masking,"Abstract MicroRNAs (miRNAs) are found ubiquitously in biological cells and play a pivotal role in regulating the expression of numerous target genes. Therapies centered around miRNAs are emerging as a promising strategy for disease treatment, aiming to intervene in disease progression by modulating abnormal miRNA expressions. The accurate prediction of miRNA–drug resistance (MDR) is crucial for the success of miRNA therapies. Computational models based on deep learning have demonstrated exceptional performance in predicting potential MDRs. However, their effectiveness can be compromised by errors in the data acquisition process, leading to inaccurate node representations. To address this challenge, we introduce the GAM-MDR model, which combines the graph autoencoder (GAE) with random path masking techniques to precisely predict potential MDRs. The reliability and effectiveness of the GAM-MDR model are mainly reflected in two aspects. Firstly, it efficiently extracts the representations of miRNA and drug nodes in the miRNA–drug network. Secondly, our designed random path masking strategy efficiently reconstructs critical paths in the network, thereby reducing the adverse impact of noisy data. To our knowledge, this is the first time that a random path masking strategy has been integrated into a GAE to infer MDRs. Our method was subjected to multiple validations on public datasets and yielded promising results. We are optimistic that our model could offer valuable insights for miRNA therapeutic strategies and deepen the understanding of the regulatory mechanisms of miRNAs. Our data and code are publicly available at GitHub:https://github.com/ZZCrazy00/GAM-MDR.","['deep learning', 'graph autoencoder (GAE)']"
2024,https://openalex.org/W4399442306,Biology,Integrative analysis of AI-driven optimization in HIV treatment regimens,"The integration of artificial intelligence (AI) into HIV treatment regimens has revolutionized the approach to personalized care and optimization strategies. This study presents an in-depth analysis of the role of AI in transforming HIV treatment, focusing on its ability to tailor therapy to individual patient needs and enhance treatment outcomes. AI-driven optimization in HIV treatment involves the utilization of advanced algorithms and computational techniques to analyze vast amounts of patient data, including genetic information, viral load measurements, and treatment history. By harnessing the power of machine learning and predictive analytics, AI algorithms can identify patterns and trends in patient data that may not be readily apparent to human clinicians. One of the key benefits of AI-driven optimization is its ability to personalize treatment regimens based on individual patient characteristics and disease progression. By considering factors such as drug resistance profiles, comorbidities, and lifestyle factors, AI algorithms can recommend the most effective and well-tolerated treatment options for each patient, leading to improved adherence and clinical outcomes. Furthermore, AI enables continuous monitoring and adjustment of treatment regimens in real time, allowing healthcare providers to respond rapidly to changes in patient status and evolving viral dynamics. This proactive approach to HIV management can help prevent treatment failure and the development of drug resistance, ultimately leading to better long-term outcomes for patients. Despite its transformative potential, AI-driven optimization in HIV treatment is not without challenges. Ethical considerations, data privacy concerns, and the need for robust validation and regulatory oversight are all important factors that must be addressed to ensure the safe and effective implementation of AI algorithms in clinical practice. In conclusion, the integrative analysis presented in this study underscores the significant impact of AI-driven optimization on the personalization and optimization of HIV treatment regimens. By leveraging AI technologies, healthcare providers can tailor treatment approaches to individual patient needs, leading to improved outcomes and quality of life for people living with HIV. Keywords: Integrative Analysis, AI- Driven, Optimization, HIV Treatment, Regimens.",['machine learning']
2024,https://openalex.org/W4401415934,Biology,Short-Term Load Forecasting: A Comprehensive Review and Simulation Study With CNN-LSTM Hybrids Approach,"Short-term load forecasting (STLF) is vital in effectively managing the reserve requirement in modern power grids. Subsequently, it supports the grid operator in making effective and economical decisions during the power balancing operation. Therefore, this study comprehensively reviews STLF methods, including time series analysis, regression-based frameworks, artificial neural networks (ANNs), and hybrid models that employ different forecasting approaches. Detailed mathematical and graphical analyses and a comparative evaluation of these methods are provided, highlighting their advantages and disadvantages. Further, the study proposes a hybrid CNN-LSTM model comprised of Convolutional neural networks (CNN) for feature extraction of high dimensional data and Long short-term memory (LSTM) networks to boost the model's efficiency for temporal sequence prediction. This study assessed the model using a comprehensive dataset from Pakistan's NTDC national grid. The analysis revealed superior performance in short-term load prediction, achieving enhanced accuracy. For single-step forecasting, the model yielded an RMSE of 538.71, MAE of 371.97, and MAPE of 2.72. In 24-hour forecasting, it achieved an RMSE of 951.94, MAE of 656.35, and MAPE of 4.72 on the NTDC dataset. Moreover, the model has outperformed previous models in comparison using the AEP dataset, demonstrating its superiority in enhancing reserve management and balancing supply and demand in modern electricity networks.","['regression-based frameworks', 'artificial neural networks (ANNs)', 'hybrid models', 'Convolutional neural networks (CNN)', 'Long short-term memory (LSTM) networks', 'hybrid CNN-LSTM model']"
2024,https://openalex.org/W4402137675,Biology,A comprehensive review of model compression techniques in machine learning,"Abstract This paper critically examines model compression techniques within the machine learning (ML) domain, emphasizing their role in enhancing model efficiency for deployment in resource-constrained environments, such as mobile devices, edge computing, and Internet of Things (IoT) systems. By systematically exploring compression techniques and lightweight design architectures, it is provided a comprehensive understanding of their operational contexts and effectiveness. The synthesis of these strategies reveals a dynamic interplay between model performance and computational demand, highlighting the balance required for optimal application. As machine learning (ML) models grow increasingly complex and data-intensive, the demand for computational resources and memory has surged accordingly. This escalation presents significant challenges for the deployment of artificial intelligence (AI) systems in real-world applications, particularly where hardware capabilities are limited. Therefore, model compression techniques are not merely advantageous but essential for ensuring that these models can be utilized across various domains, maintaining high performance without prohibitive resource requirements. Furthermore, this review underscores the importance of model compression in sustainable artificial intelligence (AI) development. The introduction of hybrid methods, which combine multiple compression techniques, promises to deliver superior performance and efficiency. Additionally, the development of intelligent frameworks capable of selecting the most appropriate compression strategy based on specific application needs is crucial for advancing the field. The practical examples and engineering applications discussed demonstrate the real-world impact of these techniques. By optimizing the balance between model complexity and computational efficiency, model compression ensures that the advancements in AI technology remain sustainable and widely applicable. This comprehensive review thus contributes to the academic discourse and guides innovative solutions for efficient and responsible machine learning practices, paving the way for future advancements in the field. Graphical abstract","['model compression techniques', 'hybrid methods']"
2024,https://openalex.org/W4390821680,Biology,Application of deep learning to fault diagnosis of rotating machineries,"Abstract Deep learning (DL) has attained remarkable achievements in diagnosing faults for rotary machineries. Capitalizing on the formidable learning capacity of DL, it has the potential to automate human labor and augment the efficiency of fault diagnosis in rotary machinery. These advantages have engendered escalating interest over the past decade. Although recent reviews of the literature have encapsulated the utilization of DL in diagnosing faults in rotating machinery, they no longer encompass the introduction of novel methodologies and emerging directions as DL methodologies continually evolve. Moreover, in practical application, novel issues and trajectories perpetually manifest, demanding a comprehensive exegesis. To rectify this lacuna, this article amalgamates current research trends and avant-garde methodologies while systematizing the utilization of anterior DL techniques. The evolution and extant status of DL in diagnosing faults for rotary machinery were delineated, with the intent of providing orientation for prospective research. Over the bygone decade, archetypal DL theory has empowered the diagnosis of faults in rotating machinery by directly establishing the nexus between mechanical data and fault conditions. In recent years, meta learning methods aimed at solving small sample scenarios and large model transformers aimed at mining big data features have both received widespread attention and development in the field of fault diagnosis of rotating machinery equipment. Although excellent results have been achieved in these two directions, there is no review and summary article yet, so it is necessary to update the review literature in the field of fault diagnosis of rotating machinery equipment. Lastly, predicated on a survey of the literature and the current developmental landscape, the challenges and prospective orientations of DL in rotary machinery fault diagnosis are presented.","['deep learning (DL)', 'meta learning methods']"
2024,https://openalex.org/W4390970205,Biology,Empowering Cyberattack Identification in IoHT Networks With Neighborhood-Component-Based Improvised Long Short-Term Memory,"Cybersecurity has become an inevitable concern in the healthcare industry due to the rapid growth of the Internet of Health Things (IoHT). The IoHT is revolutionizing healthcare by enabling remote access to hospital equipment, real-time patient monitoring, and urgent alerts to patients and hospitals. However, the convenience of these systems also makes them vulnerable to cyberattacks, with hackers seeking to disrupt health services or extort money through ransomware attacks. Efficiently detecting multiple threats is a challenging task because IoHT generates large temporal data and system log information. In this paper, we propose time series classification models for the identification of potential cyberattacks in IoHT networks. First, we introduce Neighborhood Component Analysis (NCA) with modifications of the regularization parameter to select the vital input features. With the selected features, we propose two LSTM-based models: Directed Acyclic Graph-based Long Short-Term Memory (DAG-LSTM) and Projected Layer-based Long Short-Term Memory (PL-LSTM) for detecting cyberattacks. We evaluate the existing time series classification models (i.e., GRU, LSTM, and Bi-LSTM) and proposed models (i.e., DAG-LSTM and PL-LSTM) using real-world IoHT data. We also validate the models by applying a non-parametric statistical test, Friedman test. Our evaluation results show that the proposed DAG-LSTM achieves the highest accuracy with 99.89% training and 92.04% an average testing accuracy.","['Neighborhood Component Analysis (NCA)', 'Directed Acyclic Graph-based Long Short-Term Memory (DAG-LSTM)', 'Gated Recurrent Unit (GRU)', 'Long Short-Term Memory (LSTM)', 'Bidirectional Long Short-Term Memory (Bi-LSTM)']"
2024,https://openalex.org/W4391451930,Biology,Advancing real-time plant disease detection: A lightweight deep learning approach and novel dataset for pigeon pea crop,"Plant disease detection and early disease treatment are essential for sustainable crop production. Computer vision for crop science is overgrowing with the advancement in deep learning. Real time plant disease detection poses a challenge due to the unpredictable spread of diseases within the plant, environmental factors, and the scarcity of real field datasets. The proposed work systematically addresses these issues through three key components: (a) Collaboratively generating the novel pigeon pea image dataset from agricultural fields, in partnership with 20 Agricultural Research Centers (ARS) and governmental agencies spanning 18 Indian states. (b) The design of lightweight and high-performance models for real-time plant disease detection in resource-constrained devices. (c) The extraction of multiscale feature of plant diseases using Multi-kernel Depthwise separable Convolutions. The proposed lightweight Lite-MDC architecture uses the Multi-kernel Depthwise separable Convolutions (MDsConv). The MDsConv module captures spatial features across various scales while maintaining a lightweight design. It effectively extract multi-scale information to characterize plant diseases, accommodating their diverse scale. Proposed architectural approach significantly reduces computational complexity, employing only 2.2 million parameters, which is a 62% reduction compared to the standard VGG16 architecture. The proposed method outperforms the state-of-the-art networks such as InceptionV3, VGG16, ResNet50, DenseNet, MobileNet, MobileNetV3, NASNet, and EfficieNetB0 on the proposed pigeon pea dataset with 94.14% accuracy. Notably, the method achieves a 34 Frames Per Second (FPS) inference on an NVIDIA P100 GPU. Furthermore, its performance is validated across publicly available datasets, including the plant village dataset, Cassava, and apple leaf datasets, yielding 99.78%, 86.4%, and 97.2% accuracy, respectively. The Lite-MDC model exhibits the potential for real-time plant disease detection on resource-constrained edge devices such as Agriculture robots and drones.","['InceptionV3', 'VGG16', 'ResNet50', 'DenseNet', 'MobileNet', 'MobileNetV3', 'NASNet', 'EfficientNetB0']"
2024,https://openalex.org/W4391456824,Biology,Deep Learning-Based Mask Identification System Using ResNet Transfer Learning Architecture,"Recently, the coronavirus disease 2019 has shown excellent attention in the global community regarding health and the economy.World Health Organization (WHO) and many others advised controlling Corona Virus Disease in 2019.The limited treatment resources, medical resources, and unawareness of immunity is an essential horizon to unfold.Among all resources, wearing a mask is the primary non-pharmaceutical intervention to stop the spreading of the virus caused by Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) droplets.All countries made masks mandatory to prevent infection.For such enforcement, automatic and effective face detection systems are crucial.This study presents a face mask identification approach for static photos and real-time movies that distinguishes between images with and without masks.To contribute to society, we worked on mask detection of an individual to adhere to the rule and provide awareness to the public or organization.The paper aims to get detection accuracy using transfer learning from Residual Neural Network 50 (ResNet-50) architecture and works on detection localization.The experiment is tested with other popular pre-trained models such as Deep Convolutional Neural Networks (AlexNet), Residual Neural Networks (ResNet), and Visual Geometry Group Networks (VGG-Net) advanced architecture.The proposed system generates an accuracy of 98.4% when modeled using Residual Neural Network 50 (ResNet-50).Also, the precision and recall values are proved as better when compared to the existing models.This outstanding work also can be used in video surveillance applications.","['transfer learning', 'Residual Neural Network 50 (ResNet-50)', 'Deep Convolutional Neural Networks (AlexNet)', 'Residual Neural Networks (ResNet)', 'Visual Geometry Group Networks (VGG-Net)']"
2024,https://openalex.org/W4391509831,Biology,A hyperspectral deep learning attention model for predicting lettuce chlorophyll content,"Abstract Background The phenotypic traits of leaves are the direct reflection of the agronomic traits in the growth process of leafy vegetables, which plays a vital role in the selection of high-quality leafy vegetable varieties. The current image-based phenotypic traits extraction research mainly focuses on the morphological and structural traits of plants or leaves, and there are few studies on the phenotypes of physiological traits of leaves. The current research has developed a deep learning model aimed at predicting the total chlorophyll of greenhouse lettuce directly from the full spectrum of hyperspectral images. Results A CNN-based one-dimensional deep learning model with spectral attention module was utilized for the estimate of the total chlorophyll of greenhouse lettuce from the full spectrum of hyperspectral images. Experimental results demonstrate that the deep neural network with spectral attention module outperformed the existing standard approaches, including partial least squares regression (PLSR) and random forest (RF), with an average R 2 of 0.746 and an average RMSE of 2.018. Conclusions This study unveils the capability of leveraging deep attention networks and hyperspectral imaging for estimating lettuce chlorophyll levels. This approach offers a convenient, non-destructive, and effective estimation method for the automatic monitoring and production management of leafy vegetables.","['CNN-based one-dimensional deep learning model with spectral attention module', 'partial least squares regression (PLSR)', 'random forest (RF)']"
2024,https://openalex.org/W2986574354,Biology,African Journal of Environmental Science and Technology,"The aim of the present study is to test ESA's Sentinel-2 (S2) satellites (S2A and S2B) for an efficient quantification of land cover (LC) and forest compositions in a tropical environment southwest of Mount Kenya.Furthermore, outcome of the research is used to validate ESA's S2 prototype LC 20 m map of Africa that was produced in 2016.A decision tree that is based on significant altitudinal ranges was used to discriminate four natural tree compositions that occur within the investigation area.In addition, the classification process was supported by Google Earth images, and land use (LU) data that were provided by the local Kenyan Forest Service (KFS).Final classification products include four LC classes and five subclasses of forest (four natural forest subclasses plus one non-natural forest class).Results of the Jeffries-Matusita (JM) distance test show significant differences in spectral separability between all classes.Furthermore, the study identifies spectral signatures and significant wavelengths for a classification of all LC classes and forest subclasses where wavelengths of SWIR and the rededge domain show highest importance for the discrimination of tree compositions.Finally, considerable differences can be seen between the utilized multi-temporal classification set (total of 39 bands from three acquisition dates) and ESA's S2 prototype LC 20 m map of Africa 2016.A visual comparison of ESA's prototype map within the investigation area indicates an overrepresentation of tree cover areas (as confirmed in previous studies) and also an underrepresentation of water.",['decision tree']
2024,https://openalex.org/W4392173735,Biology,"A Comprehensive Survey of Continual Learning: Theory, Method and Application","To cope with real-world dynamics, an intelligent system needs to incrementally acquire, update, accumulate, and exploit knowledge throughout its lifetime. This ability, known as continual learning, provides a foundation for AI systems to develop themselves adaptively. In a general sense, continual learning is explicitly limited by catastrophic forgetting, where learning a new task usually results in a dramatic performance drop of the old tasks. Beyond this, increasingly numerous advances have emerged in recent years that largely extend the understanding and application of continual learning. The growing and widespread interest in this direction demonstrates its realistic significance as well as complexity. In this work, we present a comprehensive survey of continual learning, seeking to bridge the basic settings, theoretical foundations, representative methods, and practical applications. Based on existing theoretical and empirical results, we summarize the general objectives of continual learning as ensuring a proper stability-plasticity trade-off and an adequate intra/inter-task generalizability in the context of resource efficiency. Then we provide a state-of-the-art and elaborated taxonomy, extensively analyzing how representative strategies address continual learning, and how they are adapted to particular challenges in various applications. Through an in-depth discussion of promising directions, we believe that such a holistic perspective can greatly facilitate subsequent exploration in this field and beyond.",['continual learning']
2024,https://openalex.org/W4390919701,Biology,Chatbots and Large Language Models in Radiology: A Practical Primer for Clinical and Research Applications,"Although chatbots have existed for decades, the emergence of transformer-based large language models (LLMs) has captivated the world through the most recent wave of artificial intelligence chatbots, including ChatGPT. Transformers are a type of neural network architecture that enables better contextual understanding of language and efficient training on massive amounts of unlabeled data, such as unstructured text from the internet. As LLMs have increased in size, their improved performance and emergent abilities have revolutionized natural language processing. Since language is integral to human thought, applications based on LLMs have transformative potential in many industries. In fact, LLM-based chatbots have demonstrated human-level performance on many professional benchmarks, including in radiology. LLMs offer numerous clinical and research applications in radiology, several of which have been explored in the literature with encouraging results. Multimodal LLMs can simultaneously interpret text and images to generate reports, closely mimicking current diagnostic pathways in radiology. Thus, from requisition to report, LLMs have the opportunity to positively impact nearly every step of the radiology journey. Yet, these impressive models are not without limitations. This article reviews the limitations of LLMs and mitigation strategies, as well as potential uses of LLMs, including multimodal models. Also reviewed are existing LLM-based applications that can enhance efficiency in supervised settings.","['transformer-based large language models (LLMs)', 'Transformers', 'Multimodal LLMs']"
2024,https://openalex.org/W9567271,Biology,Fingerprint Based Gender Classification,"Male-female classification from a fingerprint is an important step in forensic science, anthropological and medical studies to reduce the efforts required for searching a person.The aim of this research is to establish a relationship between gender and the fingerprint using some special features such as ridge density, ridge thickness to valley thickness ratio (RTVTR) and ridge width.showed that male-female classification can be done correctly up to 88.5% based on white lines count, RTVTR & ridge count using Neural Network as Classifier.We have used RTVTR, ridge width and ridge density for classification and SVM as classifier.We have found male-female can be correctly classified up to 91%.Gender classification plays an active role in several applications such as biometrics, criminology, surveillance, human computer interaction, commercial profiling.Though biometric traits such as face, gait, iris and hand shape are used for gender classification in the past, majority of the work is based on face as it contains more prominent features than others.In this paper we have analyzed fingerprints for gender classification with a hope that it has great potential for future research.We have employed a three convolutional layer CNN with rectified linear and activation functions on NIST database which contains a set of 4000 images and achieved 99% accuracy.Performance of the proposed system demonstrated that fingerprints contains vital features to discriminate gender of a person.Humans have distinctive and unique traits which can be used to distinguish them thus, acting as a form of identification.Biometrics identify people by measuring some aspect of individual's anatomy or physiology such as hand geometry or fingerprint which consists of a pattern of interleaved ridges and valleys.The year 2015 election in Nigeria was greeted by some petitions including under-aged voters.The need for an age and gender detector system is a major concern for organizations at all levels where integrity of information cannot be compromised.This work developed a system that determines human age-range and gender using fingerprint analysis trained with Back Propagation Neural Network (for gender classification) and DWT+PCA (for age classification).A total of 280 fingerprint samples of people with various age and gender were collected.140 of these samples were used for training the system""s Database; 70 males and 70 females respectively.This was done for age groups 1-10, 11-20, 21-30, 31-40, 41-50, 51-60 and 61-70 accordingly.In order to determine the gender of an individual, the Ridge Thickness Valley Thickness Ratio (RTVTR) of the person was put into consideration.Result showed 80.00 % classification accuracy for females and 72.86 % for males while 115 subjects out of 140 (82.14%)were correctly classified in age.","['Neural Network', 'SVM', 'CNN', 'Back Propagation Neural Network']"
2024,https://openalex.org/W4392714200,Biology,Genomic selection in plant breeding: Key factors shaping two decades of progress,"Genomic selection, the application of genomic prediction (GP) models to select candidate individuals, has significantly advanced in the past two decades, effectively accelerating genetic gains in plant breeding.This article provides a holistic overview of key factors that have influenced GP in plant breeding during this period.We delved into the pivotal roles of training population size and genetic diversity, and their relationship with the breeding population, in determining GP accuracy.Special emphasis was placed on optimizing training population size.We explored its benefits and the associated diminishing returns beyond an optimum size.This was done while considering the balance between resource allocation and maximizing prediction accuracy through current optimization algorithms.The density and distribution of single-nucleotide polymorphisms, level of linkage disequilibrium, genetic complexity, trait heritability, statistical machine-learning methods, and non-additive effects are the other vital factors.Using wheat, maize, and potato as examples, we summarize the effect of these factors on the accuracy of GP for various traits.The search for high accuracy in GP-theoretically reaching one when using the Pearson's correlation as a metric-is an active research area as yet far from optimal for various traits.We hypothesize that with ultra-high sizes of genotypic and phenotypic datasets, effective training population optimization methods and support from other omics approaches (transcriptomics, metabolomics and proteomics) coupled with deep-learning algorithms could overcome the boundaries of current limitations to achieve the highest possible prediction accuracy, making genomic selection an effective tool in plant breeding.",['statistical machine-learning methods']
2024,https://openalex.org/W4392754729,Biology,"Revolutionizing agriculture with artificial intelligence: plant disease detection methods, applications, and their limitations","Accurate and rapid plant disease detection is critical for enhancing long-term agricultural yield. Disease infection poses the most significant challenge in crop production, potentially leading to economic losses. Viruses, fungi, bacteria, and other infectious organisms can affect numerous plant parts, including roots, stems, and leaves. Traditional techniques for plant disease detection are time-consuming, require expertise, and are resource-intensive. Therefore, automated leaf disease diagnosis using artificial intelligence (AI) with Internet of Things (IoT) sensors methodologies are considered for the analysis and detection. This research examines four crop diseases: tomato, chilli, potato, and cucumber. It also highlights the most prevalent diseases and infections in these four types of vegetables, along with their symptoms. This review provides detailed predetermined steps to predict plant diseases using AI. Predetermined steps include image acquisition, preprocessing, segmentation, feature selection, and classification. Machine learning (ML) and deep understanding (DL) detection models are discussed. A comprehensive examination of various existing ML and DL-based studies to detect the disease of the following four crops is discussed, including the datasets used to evaluate these studies. We also provided the list of plant disease detection datasets. Finally, different ML and DL application problems are identified and discussed, along with future research prospects, by combining AI with IoT platforms like smart drones for field-based disease detection and monitoring. This work will help other practitioners in surveying different plant disease detection strategies and the limits of present systems.","['machine learning (ML)', 'deep learning (DL)']"
2024,https://openalex.org/W4390946589,Biology,Deep-STP: a deep learning-based approach to predict snake toxin proteins by using word embeddings,"Snake venom contains many toxic proteins that can destroy the circulatory system or nervous system of prey. Studies have found that these snake venom proteins have the potential to treat cardiovascular and nervous system diseases. Therefore, the study of snake venom protein is conducive to the development of related drugs. The research technologies based on traditional biochemistry can accurately identify these proteins, but the experimental cost is high and the time is long. Artificial intelligence technology provides a new means and strategy for large-scale screening of snake venom proteins from the perspective of computing. In this paper, we developed a sequence-based computational method to recognize snake toxin proteins. Specially, we utilized three different feature descriptors, namely g-gap , natural vector and word 2 vector, to encode snake toxin protein sequences. The analysis of variance (ANOVA), gradient-boost decision tree algorithm (GBDT) combined with incremental feature selection (IFS) were used to optimize the features, and then the optimized features were input into the deep learning model for model training. The results show that our model can achieve a prediction performance with an accuracy of 82.00% in 10-fold cross-validation. The model is further verified on independent data, and the accuracy rate reaches to 81.14%, which demonstrated that our model has excellent prediction performance and robustness.","['gradient-boost decision tree algorithm (GBDT)', 'incremental feature selection (IFS)', 'deep learning model']"
2024,https://openalex.org/W4392791588,Biology,Can large language models replace humans in systematic reviews? Evaluating <scp>GPT</scp>‐4's efficacy in screening and extracting data from peer‐reviewed and grey literature in multiple languages,"Systematic reviews are vital for guiding practice, research and policy, although they are often slow and labour-intensive. Large language models (LLMs) could speed up and automate systematic reviews, but their performance in such tasks has yet to be comprehensively evaluated against humans, and no study has tested Generative Pre-Trained Transformer (GPT)-4, the biggest LLM so far. This pre-registered study uses a ""human-out-of-the-loop"" approach to evaluate GPT-4's capability in title/abstract screening, full-text review and data extraction across various literature types and languages. Although GPT-4 had accuracy on par with human performance in some tasks, results were skewed by chance agreement and dataset imbalance. Adjusting for these caused performance scores to drop across all stages: for data extraction, performance was moderate, and for screening, it ranged from none in highly balanced literature datasets (~1:1) to moderate in those datasets where the ratio of inclusion to exclusion in studies was imbalanced (~1:3). When screening full-text literature using highly reliable prompts, GPT-4's performance was more robust, reaching ""human-like"" levels. Although our findings indicate that, currently, substantial caution should be exercised if LLMs are being used to conduct systematic reviews, they also offer preliminary evidence that, for certain review tasks delivered under specific conditions, LLMs can rival human performance.",['Generative Pre-Trained Transformer (GPT)-4']
2024,https://openalex.org/W4390782971,Biology,MemBrain v2: an end-to-end tool for the analysis of membranes in cryo-electron tomography,"A bstract MemBrain v2 is a deep learning-enabled program aimed at the efficient analysis of membranes in cryo-electron tomography (cryo-ET). The final v2 release of MemBrain will comprise three main modules: 1) MemBrain-seg, which provides automated membrane segmentation, 2) MemBrain-pick, which provides automated picking of particles along segmented membranes, and 3) MemBrain-stats, which provides quantitative statistics of particle distributions and membrane morphometrics. This initial version of the manuscript is focused on the beta release of MemBrain-seg, which combines iterative training with diverse data and specialized Fourier-based data augmentations. These augmentations are specifically designed to enhance the tool’s adaptability to a variety of tomographic data and address common challenges in cryo-ET analysis. A key feature of MemBrain-seg is the implementation of the Surface-Dice loss function, which improves the network’s focus on membrane connectivity and allows for the effective incorporation of manual annotations from different sources. This function is beneficial in handling the variability inherent in membrane structures and annotations. Our ongoing collaboration with the cryo-ET community plays an important role in continually improving MemBrain v2 with a wide array of training data. This collaborative approach ensures that MemBrain v2 remains attuned to the field’s needs, enhancing its robustness and generalizability across different types of tomographic data. The current version of MemBrain-seg is available at https://github.com/teamtomo/membrain-seg , and the predecessor of MemBrain-pick (also called MemBrain v1) is deposited at https://github.com/CellArchLab/MemBrain . This preprint will be updated concomitantly with the code until the three integrated modules of MemBrain v2 are complete.","['deep learning', 'Surface-Dice loss function']"
2024,https://openalex.org/W4395055639,Biology,Foundation Models for Generalist Geospatial Artificial Intelligence,"Much of the progress in the development of highly adaptable and reusable artificial intelligence (AI) models is expected to have a profound impact on Earth science and remote sensing. Foundation models are pre-trained on large unlabeled datasets through self-supervision, and then fine-tuned for various downstream tasks with small labeled datasets. There is an increasing interest within the scientific community to investigate how to effectively build generalist AI models that exploit multi-sensor data in Earth observation applications. This paper introduces a first-of-its-kind framework for efficient pre-training and fine-tuning of foundational models on extensive geospatial data. We have utilized this framework to create Prithvi, a transformer-based geospatial foundational model pre-trained on more than 1 TB of multispectral satellite imagery from the Harmonized Landsat Sentinel-2 (HLS) dataset. Our study demonstrates the efficacy of our framework in successfully fine-tuning Prithvi to a range of Earth observation applications not previously analyzed by foundation models. Applications for which results are presented in this paper include multi-temporal cloud gap imputation, flood mapping, wildfire scar segmentation, and multi-temporal crop segmentation. We assessed the effect of Prithvi's pre-trained weights on downstream tasks and compared learning curves for (1) fine-tuning the entire model, (2) fine-tuning solely the decoder for the downstream task, and (3) training the model without utilizing Prithvi's pre-trained weights. Our experiments showed that the pre-trained model accelerates the fine-tuning process compared to leveraging randomly initialized weights. In addition, pre-trained Prithvi compared well against the state-of-the-art on downstream tasks; e.g., the model outperformed a conditional GAN model in multi-temporal cloud imputation by up to 5pp (or 5.7%) in the structural similarity index. Further, given the cost and time required for collecting labeled training data, we gradually reduced the quantity of available labeled data for refining the model to evaluate data efficiency. We found that labeled training data can be decreased substantially without affecting the model's accuracy. The pre-trained 100 million parameter model and corresponding fine-tuning workflows have been released publicly as open source contributions to the global Earth sciences community through Hugging Face","['foundation models', 'self-supervision', 'fine-tuning', 'transformer-based model', 'conditional GAN model']"
2024,https://openalex.org/W4404856766,Biology,Face mask identification with enhanced cuckoo optimization and deep learning-based faster regional neural network,"Abstract A mask identification and social distance monitoring system using Unmanned Aerial Vehicles (UAV) in the outdoors has been proposed for a health establishment. The above approach performed surveillance of the surrounding area using cameras installed in UAVs and internet of things technologies, and the captured images seem useful for tracking the entire environment. However, innate images from unmanned aerial vehicles show an adaptable visual effect in an uncontrolled environment, making face-mask detection and recognition harder. The UAV picture first had to be converted to grayscale, then its contrast was amplified. Image contrast was improved using Optimum Wavelet-Based Masking and the Enhanced Cuckoo Methodology (ECM). According to the contrast-enhanced image, Gabor-Transform (GT) and Stroke Width Transform (SWT) methods are used to derive attributes that help categorise mask-wearers and non-mask-wearers. Using the retrieved attributes, a Weighted Naive Bayes Classification (WNBC) detected masks in the images. Additionally, a deep neural network-based, the faster Region-Based Convolutional Neural Networks (R-CNN) algorithm combined with Adaptive Galactic Swarm Optimization (AGSO) is being used to identify appropriate and incorrect face mask wear in images, as well as to monitor social distancing among individuals in crowded areas. When the system recognises unmasked individuals, it sends their information to the doctor and the nearby police station. One unmanned aerial vehicle’s automated system alert people via speakers, ensuring social spacing. The problem involves a large percentage of appropriate and incorrect face mask wear using data from GitHub and Kaggle, including a training repository of 16,000 images and a testing data set of 12,751 images. To enhance the performance of the model’s learning, the methodology of 10-fold cross-validation will be used. Precision, recall, F1-score, and speed are then measured to determine the efficacy of the suggested approach.","['Weighted Naive Bayes Classification (WNBC)', 'faster Region-Based Convolutional Neural Networks (R-CNN)']"
2024,https://openalex.org/W4399777548,Biology,Feature reduction for hepatocellular carcinoma prediction using machine learning algorithms,"Abstract Hepatocellular carcinoma (HCC) is a highly prevalent form of liver cancer that necessitates accurate prediction models for early diagnosis and effective treatment. Machine learning algorithms have demonstrated promising results in various medical domains, including cancer prediction. In this study, we propose a comprehensive approach for HCC prediction by comparing the performance of different machine learning algorithms before and after applying feature reduction methods. We employ popular feature reduction techniques, such as weighting features, hidden features correlation, feature selection, and optimized selection, to extract a reduced feature subset that captures the most relevant information related to HCC. Subsequently, we apply multiple algorithms, including Naive Bayes, support vector machines (SVM), Neural Networks, Decision Tree, and K nearest neighbors (KNN), to both the original high-dimensional dataset and the reduced feature set. By comparing the predictive accuracy, precision, F Score, recall, and execution time of each algorithm, we assess the effectiveness of feature reduction in enhancing the performance of HCC prediction models. Our experimental results, obtained using a comprehensive dataset comprising clinical features of HCC patients, demonstrate that feature reduction significantly improves the performance of all examined algorithms. Notably, the reduced feature set consistently outperforms the original high-dimensional dataset in terms of prediction accuracy and execution time. After applying feature reduction techniques, the employed algorithms, namely decision trees, Naive Bayes, KNN, neural networks, and SVM achieved accuracies of 96%, 97.33%, 94.67%, 96%, and 96.00%, respectively.","['Naive Bayes', 'support vector machines (SVM)', 'Neural Networks', 'Decision Tree', 'K nearest neighbors (KNN)']"
2024,https://openalex.org/W4392303127,Biology,Recent advancements and challenges of NLP-based sentiment analysis: A state-of-the-art review,"Sentiment analysis is a method within natural language processing that evaluates and identifies the emotional tone or mood conveyed in textual data. Scrutinizing words and phrases categorizes them into positive, negative, or neutral sentiments. The significance of sentiment analysis lies in its capacity to derive valuable insights from extensive textual data, empowering businesses to grasp customer sentiments, make informed choices, and enhance their offerings. For the further advancement of sentiment analysis, gaining a deep understanding of its algorithms, applications, current performance, and challenges is imperative. Therefore, in this extensive survey, we began exploring the vast array of application domains for sentiment analysis, scrutinizing them within the context of existing research. We then delved into prevalent pre-processing techniques, datasets, and evaluation metrics to enhance comprehension. We also explored Machine Learning, Deep Learning, Large Language Models and Pre-trained models in sentiment analysis, providing insights into their advantages and drawbacks. Subsequently, we precisely reviewed the experimental results and limitations of recent state-of-the-art articles. Finally, we discussed the diverse challenges encountered in sentiment analysis and proposed future research directions to mitigate these concerns. This extensive review provides a complete understanding of sentiment analysis, covering its models, application domains, results analysis, challenges, and research directions.","['Machine Learning', 'Deep Learning']"
2024,https://openalex.org/W4393072087,Biology,FI-NPI: Exploring Optimal Control in Parallel Platform Systems,"Typically, the current and speed loop closure of servo motor of the parallel platform is accomplished with incremental PI regulation. The control method has strong robustness, but the parameter tuning process is cumbersome, and it is difficult to achieve the optimal control state. In order to further optimize the performance, this paper proposes a double-loop control structure based on fuzzy integral and neuron proportional integral (FI-NPI). The structure makes full use of the control advantages of the fuzzy controller and integrator to improve the performance of speed closed-loop control. And through the feedforward branch, the speed error is used as the teacher signal for neuron supervised learning, which improves the effect of current closed-loop control. Through comparative simulation experiments, this paper verifies that the FI-NPI controller has a faster dynamic response speed than the traditional PI controller. Finally, in this paper, the FI-NPI controller is implemented in C language in the servo-driven lower computer, and the speed closed-loop test of the BLDC motor is carried out. The experimental results show that the FI-NPI double-loop controller is better than the traditional double-PI controller in performance indicators such as convergence rate and RMSE, which confirms that the FI-NPI double-loop controller is more suitable for BLDC servo control.",['fuzzy integral']
2024,https://openalex.org/W4391019749,Biology,CIFAKE: Image Classification and Explainable Identification of AI-Generated Synthetic Images,"Recent advances in synthetic data have enabled the generation of images with such high quality that human beings cannot tell the difference between real-life photographs and Artificial Intelligence (AI) generated images. Given the critical necessity of data reliability and authentication, this article proposes to enhance our ability to recognise AI-generated images through computer vision. Initially, a synthetic dataset is generated that mirrors the ten classes of the already available CIFAR-10 dataset with latent diffusion, providing a contrasting set of images for comparison to real photographs. The model is capable of generating complex visual attributes, such as photorealistic reflections in water. The two sets of data present as a binary classification problem with regard to whether the photograph is real or generated by AI. This study then proposes the use of a Convolutional Neural Network (CNN) to classify the images into two categories; Real or Fake. Following hyperparameter tuning and the training of 36 individual network topologies, the optimal approach could correctly classify the images with 92.98% accuracy. Finally, this study implements explainable AI via Gradient Class Activation Mapping to explore which features within the images are useful for classification. Interpretation reveals interesting concepts within the image, in particular, noting that the actual entity itself does not hold useful information for classification; instead, the model focuses on small visual imperfections in the background of the images. The complete dataset engineered for this study, referred to as the CIFAKE dataset, is made publicly available to the research community for future work.","['latent diffusion', 'Convolutional Neural Network (CNN)', 'Gradient Class Activation Mapping']"
2024,https://openalex.org/W4395050972,Biology,Optimization of hepatological clinical guidelines interpretation by large language models: a retrieval augmented generation-based framework,"Abstract Large language models (LLMs) can potentially transform healthcare, particularly in providing the right information to the right provider at the right time in the hospital workflow. This study investigates the integration of LLMs into healthcare, specifically focusing on improving clinical decision support systems (CDSSs) through accurate interpretation of medical guidelines for chronic Hepatitis C Virus infection management. Utilizing OpenAI’s GPT-4 Turbo model, we developed a customized LLM framework that incorporates retrieval augmented generation (RAG) and prompt engineering. Our framework involved guideline conversion into the best-structured format that can be efficiently processed by LLMs to provide the most accurate output. An ablation study was conducted to evaluate the impact of different formatting and learning strategies on the LLM’s answer generation accuracy. The baseline GPT-4 Turbo model’s performance was compared against five experimental setups with increasing levels of complexity: inclusion of in-context guidelines, guideline reformatting, and implementation of few-shot learning. Our primary outcome was the qualitative assessment of accuracy based on expert review, while secondary outcomes included the quantitative measurement of similarity of LLM-generated responses to expert-provided answers using text-similarity scores. The results showed a significant improvement in accuracy from 43 to 99% ( p &lt; 0.001), when guidelines were provided as context in a coherent corpus of text and non-text sources were converted into text. In addition, few-shot learning did not seem to improve overall accuracy. The study highlights that structured guideline reformatting and advanced prompt engineering (data quality vs. data quantity) can enhance the efficacy of LLM integrations to CDSSs for guideline delivery.","['OpenAI’s GPT-4 Turbo model', 'retrieval augmented generation (RAG)', 'few-shot learning']"
2024,https://openalex.org/W4399885374,Biology,Survival Prediction Across Diverse Cancer Types Using Neural Networks,"Gastric cancer and Colon adenocarcinoma represent widespread and challenging malignancies with high mortality rates and complex treatment landscapes. In response to the critical need for accurate prognosis in cancer patients, the medical community has embraced the 5-year survival rate as a vital metric for estimating patient outcomes. This study introduces a pioneering approach to enhance survival prediction models for gastric and Colon adenocarcinoma patients. Leveraging advanced image analysis techniques, we sliced whole slide images (WSI) of these cancers, extracting comprehensive features to capture nuanced tumor characteristics. Subsequently, we constructed patient-level graphs, encapsulating intricate spatial relationships within tumor tissues. These graphs served as inputs for a sophisticated 4-layer graph convolutional neural network (GCN), designed to exploit the inherent connectivity of the data for comprehensive analysis and prediction. By integrating patients' total survival time and survival status, we computed C-index values for gastric cancer and Colon adenocarcinoma, yielding 0.57 and 0.64, respectively. Significantly surpassing previous convolutional neural network models, these results underscore the efficacy of our approach in accurately predicting patient survival outcomes. This research holds profound implications for both the medical and AI communities, offering insights into cancer biology and progression while advancing personalized treatment strategies. Ultimately, our study represents a significant stride in leveraging AI-driven methodologies to revolutionize cancer prognosis and improve patient outcomes on a global scale.","['graph convolutional neural network (GCN)', 'convolutional neural network']"
2024,https://openalex.org/W4391216149,Biology,"Benchmarking Micro-Action Recognition: Dataset, Methods, and Applications","Micro-action is an imperceptible non-verbal behaviour characterised by low-intensity movement. It offers insights into the feelings and intentions of individuals and is important for human-oriented applications such as emotion recognition and psychological assessment. However, the identification, differentiation, and understanding of micro-actions pose challenges due to the imperceptible and inaccessible nature of these subtle human behaviors in everyday life. In this study, we innovatively collect a new micro-action dataset designated as Micro-action-52 (MA-52), and propose a benchmark named micro-action network (MANet) for micro-action recognition (MAR) task. Uniquely, MA-52 provides the whole-body perspective including gestures, upper- and lower-limb movements, attempting to reveal comprehensive micro-action cues. In detail, MA-52 contains 52 micro-action categories along with seven body part labels, and encompasses a full array of realistic and natural micro-actions, accounting for 205 participants and 22,422 video instances collated from the psychological interviews. Based on the proposed dataset, we assess MANet and other nine prevalent action recognition methods. MANet incorporates squeeze-and-excitation (SE) and temporal shift module (TSM) into the ResNet architecture for modeling the spatiotemporal characteristics of micro-actions. Then a joint-embedding loss is designed for semantic matching between video and action labels; the loss is used to better distinguish between visually similar yet distinct micro-action categories. The extended application in emotion recognition has demonstrated one of the important values of our proposed dataset and method. In the future, further exploration of human behaviour, emotion, and psychological assessment will be conducted in depth. The dataset and source code are released at https://github.com/VUT-HFUT/Micro-Action.","['squeeze-and-excitation (SE)', 'temporal shift module (TSM)', 'ResNet architecture', 'joint-embedding loss']"
2024,https://openalex.org/W4400659510,Biology,Aspect-based drug review classification through a hybrid model with ant colony optimization using deep learning,"Abstract The task of aspect-level sentiment analysis is intricately designed to determine the sentiment polarity directed towards a specific target within a sentence. With the increasing availability of online reviews and the growing importance of healthcare decisions, analyzing drug reviews has become a critical task. Traditional sentiment analysis, which categorizes a whole review as positive, negative, or neutral, provides limited insights for consumers and healthcare professionals. Aspect-based sentiment analysis (ABSA) aims to overcome these limitations by identifying and evaluating the sentiment associated with specific aspects or attributes of drugs mentioned in the reviews. Various fields, including business, politics, and medicine, have been explored in the context of sentiment analysis. Automation of online user reviews allows pharmaceutical companies to assess large amounts of user feedback. This helps extract pharmacological efficacy and side effect insights. The data collected could improve pharmacovigilance. Reviewing user comments can provide valuable data that can be used to improve drug safety and efficacy monitoring procedures. This improves pharmacovigilance processes, improving pharmaceutical outcomes understanding and corporate decision-making. Therefore, we propose a pre-trained RoBERTa with a Bi-LSTM model to categorise drug reviews from online sources and pre-process the text data. Ant Colony Optimization can be used in feature selection for ABSA, helping to identify the most relevant aspects and sentiments. Further, RoBERTa is fine-tuned to perform ABSA on the dataset, enabling the system to categorize aspects and determine the associated sentiment. The outcomes reveal that the suggested framework has achieved higher accuracy (96.78%) and F1 score (98.29%) on druglib.com, and 95.02% on the drugs.com dataset, than several prior state-of-the-art methods.","['pre-trained RoBERTa', 'Bi-LSTM model', 'fine-tuned RoBERTa']"
2024,https://openalex.org/W4390494339,Biology,"A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection in Industrial Time Series: Methods, Applications, and Directions","Automating the monitoring of industrial processes has the potential to enhance efficiency and optimize quality by promptly detecting abnormal events and thus facilitating timely interventions. Deep learning, with its capacity to discern non-trivial patterns within large datasets, plays a pivotal role in this process. Standard deep learning methods are suitable to solve a specific task given a specific type of data. During training, deep learning demands large volumes of labeled data. However, due to the dynamic nature of the industrial processes and environment, it is impractical to acquire large-scale labeled data for standard deep learning training for every slightly different case anew. Deep transfer learning offers a solution to this problem. By leveraging knowledge from related tasks and accounting for variations in data distributions, the transfer learning framework solves new tasks with little or even no additional labeled data. The approach bypasses the need to retrain a model from scratch for every new setup and dramatically reduces the labeled data requirement. This survey first provides an in-depth review of deep transfer learning, examining the problem settings of transfer learning and classifying the prevailing deep transfer learning methods. Moreover, we delve into applications of deep transfer learning in the context of a broad spectrum of time series anomaly detection tasks prevalent in primary industrial domains, e.g., manufacturing process monitoring, predictive maintenance, energy management, and infrastructure facility monitoring. We discuss the challenges and limitations of deep transfer learning in industrial contexts and conclude the survey with practical directions and actionable suggestions to address the need to leverage diverse time series data for anomaly detection in an increasingly dynamic production environment.","['deep learning', 'deep transfer learning', 'transfer learning framework']"
2024,https://openalex.org/W4399326707,Biology,Enhancing precision agriculture: A comprehensive review of machine learning and AI vision applications in all-terrain vehicle for farm automation,"The automation of all-terrain vehicles (ATVs) through the integration of advanced technologies such as machine learning (ML) and artificial intelligence (AI) vision has significantly changed precision agriculture. This paper aims to analyse and develop trends to provide comprehensive knowledge of the current state of ATV-based precision agriculture and the future possibilities of ML and AI. A bibliometric analysis was conducted through network diagram with keywords taken from previous publications in the domain. This review comprehensively analyses the potential of machine learning and artificial intelligence in transforming farming operations through the automation of tasks and the deployment of all-terrain vehicles. The research extensively analyses how machine learning methods have influenced several aspects of agricultural activities, such as planting, harvesting, spraying, weeding, crop monitoring, and others. AI vision systems are being researched for their ability to enhance precise and prompt decision-making in ATV-driven agricultural automation. These technologies have been thoroughly tested to show how they can improve crop yield, reducing overall investment, and make farming more efficient. Examples include machine learning-based seeding accuracy, AI-enabled crop health monitoring, and the use of AI vision for accurate pesticide application. The assessment examines challenges such as data privacy problems and scalability constraints, along with potential advancements and future prospects in the field. This will assist researchers and practitioners in making well-informed judgments regarding farming practices that are efficient, sustainable, and technologically robust.",['machine learning']
2024,https://openalex.org/W4394579747,Biology,An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing: Algorithm Development and Validation Study,"Background Large language models (LLMs) have shown remarkable capabilities in natural language processing (NLP), especially in domains where labeled data are scarce or expensive, such as the clinical domain. However, to unlock the clinical knowledge hidden in these LLMs, we need to design effective prompts that can guide them to perform specific clinical NLP tasks without any task-specific training data. This is known as in-context learning, which is an art and science that requires understanding the strengths and weaknesses of different LLMs and prompt engineering approaches. Objective The objective of this study is to assess the effectiveness of various prompt engineering techniques, including 2 newly introduced types—heuristic and ensemble prompts, for zero-shot and few-shot clinical information extraction using pretrained language models. Methods This comprehensive experimental study evaluated different prompt types (simple prefix, simple cloze, chain of thought, anticipatory, heuristic, and ensemble) across 5 clinical NLP tasks: clinical sense disambiguation, biomedical evidence extraction, coreference resolution, medication status extraction, and medication attribute extraction. The performance of these prompts was assessed using 3 state-of-the-art language models: GPT-3.5 (OpenAI), Gemini (Google), and LLaMA-2 (Meta). The study contrasted zero-shot with few-shot prompting and explored the effectiveness of ensemble approaches. Results The study revealed that task-specific prompt tailoring is vital for the high performance of LLMs for zero-shot clinical NLP. In clinical sense disambiguation, GPT-3.5 achieved an accuracy of 0.96 with heuristic prompts and 0.94 in biomedical evidence extraction. Heuristic prompts, alongside chain of thought prompts, were highly effective across tasks. Few-shot prompting improved performance in complex scenarios, and ensemble approaches capitalized on multiple prompt strengths. GPT-3.5 consistently outperformed Gemini and LLaMA-2 across tasks and prompt types. Conclusions This study provides a rigorous evaluation of prompt engineering methodologies and introduces innovative techniques for clinical information extraction, demonstrating the potential of in-context learning in the clinical domain. These findings offer clear guidelines for future prompt-based clinical NLP research, facilitating engagement by non-NLP experts in clinical NLP advancements. To the best of our knowledge, this is one of the first works on the empirical evaluation of different prompt engineering approaches for clinical NLP in this era of generative artificial intelligence, and we hope that it will inspire and inform future research in this area.","['in-context learning', 'ensemble approaches', 'zero-shot prompting', 'few-shot prompting']"
2024,https://openalex.org/W4397001018,Biology,A systematic review of hyperspectral imaging in precision agriculture: Analysis of its current state and future prospects,"Hyperspectral sensor adaptability in precision agriculture to digital images is still at its nascent stage. Hyperspectral imaging (HSI) is data rich in solving agricultural problems like disease detection, weed detection, stress detection, crop monitoring, nutrient application, soil mineralogy, yield estimation, and sorting applications. With modern precision agriculture, the challenge now is to bring these applications to the field for real-time solutions, where machines are enabled to conduct analyses without expert supervision and communicate the results to users for better management of farmlands; a necessary step to gain complete autonomy in agricultural farmlands. Significant advancements in HSI technology for precision agriculture are required to fully realize its potential. As a wide-ranging collection of the status of HSI and analysis in precision agriculture is lacking, this review endeavors to provide a comprehensive overview of the recent advancements and trends of HSI in precision agriculture for real-time applications. In this study, a systematic review of 163 scientific articles published over the past twenty years (2003–2023) was conducted. Of these, 97 were selected for further analysis based on their relevance to the topic at hand. Topics include conventional data preprocessing techniques, hyperspectral data acquisition, data compression methods, and segmentation methods. The hardware implementation of field-programmable gate arrays (FPGAs) and graphics processing units (GPUs) for high-speed data processing and application of machine learning and deep learning technologies were explored. This review highlights the potential of HSI as a powerful tool for precision agriculture, particularly in real-time applications, discusses limitations, and provides insights into future research directions.","['machine learning', 'deep learning']"
2024,https://openalex.org/W4390597725,Biology,Critical review on water quality analysis using IoT and machine learning models,"Water quality and its management are the most precise concerns confronting humanity globally. This article evaluates the various sensors used for water quality monitoring and focuses on the water quality index considering the multiple physical, chemical, and biological parameters. A Review of Internet of Things (IoT) research for water quality monitoring and analysis, sensors used for water quality can help remote monitoring of the water quality parameters using various IoT-based sensors that convey the assembled estimations utilizing Low-Power Wide Area Network innovations. Overall, the IoT system was 95 % accurate in measuring pH, Turbidity, TDS, and Temperature, while the traditional method was only 85 % accurate. Also, this study reviewed the different A.I. techniques used to assess water quality, including conventional machine learning techniques, Support Vector Machines, Deep Neural Networks, and K-nearest neighbors. Compared to traditional methods, machine learning and deep learning can significantly increase the accuracy of measurements of groundwater quality. However, various variables, such as the caliber of the training data, the water quality metrics' complexity, and the monitoring frequency, will affect the accuracy. The geographical information system (GIS) is used for spatial data analysis and managing water resources. The quality of its data is also reviewed in the paper. Based on these analyses, the study has forecasted the future sensors, Geospatial Technology, and machine learning techniques for water quality monitoring and analysis.","['Support Vector Machines', 'Deep Neural Networks', 'K-nearest neighbors']"
2024,https://openalex.org/W4390604402,Biology,A novel and dynamic land use/cover change research framework based on an improved PLUS model and a fuzzy multiobjective programming model,"Spatial reconstruction and scenario simulation of historical processes and future trends of land use/cover change (LUCC) can help to reveal the historical background of land conversion and the spatial distribution of future land. Moreover, there is a close relationship between the spatiotemporal dynamics of land use/cover and changes in different ecosystem services (ESs). Using this relationship to simulate future land use scenarios is important. In this study, an LUCC dynamic analysis framework (LSTM-PLUS-FMOP) was constructed based on a deep learning time series forecasting model (LSTM), a parallelized urban land use simulation (PLUS) model and a fuzzy multiobjective programming (FMOP) model. The PLUS model was used to analyze the driving mechanism of land expansion and explore the land conversion pattern. In addition, three land conversion scenarios were established: natural land expansion (NLE), economic development priority (EDP) and regional sustainable development (RSD). The FMOP model and the relationship between LUCC and ES were used to perform a spatial simulation of land conversion. The uncertainty parameters in the model were treated by intuitionistic fuzzy numbers (IFSs). This study applied the constructed framework to the Yellow River Basin of Shaanxi Province (YRB-SX). The results showed that (1) from 2000 to 2020, the cropland area of the YRB-SX continuously decreased by 12.67 × 104 ha, while the built-up area continuously increased by 28.25 × 104 ha. The net reduction in woodland and grassland area was 13.90 × 104 ha. (2) The relative error range of land prediction using the LSTM model was 0.0003– 0.0042. This model had better accuracy than the Markov chain prediction model. (3) The cropland area decreased by 0.26% (NLE), 0.85% (EDP) and 1.68% (RSD) under the three scenarios. The built-up area increased by 25.01%, 32.76% and 14.72%, respectively. The RSD scenario followed the principles of ecological protection and spatial constraints, which mitigated the degradation of the ecosystem to some extent. This coupled simulation framework will help to obtain land allocation schemes that meet the requirements of ecological protection and provide solutions for rational land management.",['LSTM']
2024,https://openalex.org/W4391168980,Biology,Utilizing Hybrid Machine Learning and Soft Computing Techniques for Landslide Susceptibility Mapping in a Drainage Basin,"The hydrological system of thebasin of Lake Urmia is complex, deriving its supply from a network comprising 13 perennial rivers, along withnumerous small springs and direct precipitation onto the lake’s surface. Among these contributors, approximately half of the inflow is attributed to the Zarrineh River and the Simineh River. Remarkably, Lake Urmia lacks a natural outlet, with its water loss occurring solely through evaporation processes. This study employed a comprehensive methodology integrating ground surveys, remote sensing analyses, and meticulous documentation of historical landslides within the basin as primary information sources. Through this investigative approach, we preciselyidentified and geolocated a total of 512 historical landslide occurrences across the Urmia Lake drainage basin, leveraging GPS technology for precision. Thisarticle introduces a suite of hybrid machine learning predictive models, such as support-vector machine (SVM), random forest (RF), decision trees (DT), logistic regression (LR), fuzzy logic (FL), and the technique for order of preference by similarity to the ideal solution (TOPSIS). These models were strategically deployed to assess landslide susceptibility within the region. The outcomes of the landslide susceptibility assessment reveal that the main high susceptible zones for landslide occurrence are concentrated in the northwestern, northern, northeastern, and some southern and southeastern areas of the region. Moreover, when considering the implementation of predictions using different algorithms, it became evident that SVM exhibited superior performance regardingboth accuracy (0.89) and precision (0.89), followed by RF, with and accuracy of 0.83 and a precision of 0.83. However, it is noteworthy that TOPSIS yielded the lowest accuracy value among the algorithms assessed.","['support-vector machine (SVM)', 'random forest (RF)', 'decision trees (DT)', 'logistic regression (LR)']"
2024,https://openalex.org/W4391831565,Biology,Comparison of Random Forest and XGBoost Classifiers Using Integrated Optical and SAR Features for Mapping Urban Impervious Surface,"The integration of optical and SAR datasets through ensemble machine learning models shows promising results in urban remote sensing applications. The integration of multi-sensor datasets enhances the accuracy of information extraction. This research presents a comparison of two ensemble machine learning classifiers (random forest and extreme gradient boost (XGBoost)) classifiers using an integration of optical and SAR features and simple layer stacking (SLS) techniques. Therefore, Sentinel-1 (SAR) and Landsat 8 (optical) datasets were used with SAR textures and enhanced modified indices to extract features for the year 2023. The classification process utilized two machine learning algorithms, random forest and XGBoost, for urban impervious surface extraction. The study focused on three significant East Asian cities with diverse urban dynamics: Jakarta, Manila, and Seoul. This research proposed a novel index called the Normalized Blue Water Index (NBWI), which distinguishes water from other features and was utilized as an optical feature. Results showed an overall accuracy of 81% for UIS classification using XGBoost and 77% with RF while classifying land use land cover into four major classes (water, vegetation, bare soil, and urban impervious). However, the proposed framework with the XGBoost classifier outperformed the RF algorithm and Dynamic World (DW) data product and comparatively showed higher classification accuracy. Still, all three results show poor separability with bare soil class compared to ground truth data. XGBoost outperformed random forest and Dynamic World in classification accuracy, highlighting its potential use in urban remote sensing applications.","['ensemble machine learning models', 'random forest', 'extreme gradient boost (XGBoost)']"
2024,https://openalex.org/W4390669592,Biology,Enhancing plasticity in optoelectronic artificial synapses: A pathway to efficient neuromorphic computing,"The continuous growth in artificial intelligence and high-performance computing has necessitated the development of efficient optoelectronic artificial synapses crucial for neuromorphic computing (NC). Ga2O3 is an emerging wide-bandgap semiconductor with high deep ultraviolet absorption, tunable persistent photoconductivity, and excellent stability toward electric fields, making it a promising component for optoelectronic artificial synapses. Currently reported Ga2O3 optoelectronic artificial synapses often suffer from complex fabrication processes and potential room for improvement due to plasticity. To address the issue of low device plasticity and practical application scenarios, we present an amorphous Ga2O3 (α-GaOx) flexible optoelectronic artificial synapse. This synapse modulates light stimulus signals using electron/oxygen vacancies and optical stimulation and operates as a visual storage device for information processing. We investigate the improvement of the optoelectronic synapses' plasticity by controlling the number of oxygen vacancies via a plasma treatment method and demonstrate its effective application in a three-layer backpropagation neural network for handwritten digit classification. Under the same stimulus conditions, the synaptic weight of samples treated with Ar plasma exhibits a higher rate of change, with the current levels increasing by 2–3 orders of magnitude, achieving greater plasticity. The improved optoelectronic synapses achieved an accuracy of 93.34%/94%, demonstrating their potential as efficient computing solutions and insights for future applications in NC chips.",['backpropagation neural network']
2024,https://openalex.org/W4393201659,Biology,Garlic Origin Traceability and Identification Based on Fusion of Multi-Source Heterogeneous Spectral Information,"The chemical composition and nutritional content of garlic are greatly impacted by its production location, leading to distinct flavor profiles and functional properties among garlic varieties from diverse origins. Consequently, these variations determine the preference and acceptance among diverse consumer groups. In this study, purple-skinned garlic samples were collected from five regions in China: Yunnan, Shandong, Henan, Anhui, and Jiangsu Provinces. Mid-infrared spectroscopy and ultraviolet spectroscopy were utilized to analyze the components of garlic cells. Three preprocessing methods, including Multiple Scattering Correction (MSC), Savitzky–Golay Smoothing (SG Smoothing), and Standard Normalized Variate (SNV), were applied to reduce the background noise of spectroscopy data. Following variable feature extraction by Genetic Algorithm (GA), a variety of machine learning algorithms, including XGboost, Support Vector Classification (SVC), Random Forest (RF), and Artificial Neural Network (ANN), were used according to the fusion of spectral data to obtain the best processing results. The results showed that the best-performing model for ultraviolet spectroscopy data was SNV-GA-ANN, with an accuracy of 99.73%. The best-performing model for mid-infrared spectroscopy data was SNV-GA-RF, with an accuracy of 97.34%. After the fusion of ultraviolet and mid-infrared spectroscopy data, the SNV-GA-SVC, SNV-GA-RF, SNV-GA-ANN, and SNV-GA-XGboost models achieved 100% accuracy in both training and test sets. Although there were some differences in the accuracy of the four models under different preprocessing methods, the fusion of ultraviolet and mid-infrared spectroscopy data yielded the best outcomes, with an accuracy of 100%. Overall, the combination of ultraviolet and mid-infrared spectroscopy data fusion and chemometrics established in this study provides a theoretical foundation for identifying the origin of garlic, as well as that of other agricultural products.","['Genetic Algorithm (GA)', 'XGboost', 'Support Vector Classification (SVC)', 'Random Forest (RF)', 'Artificial Neural Network (ANN)']"
2024,https://openalex.org/W4391037822,Biology,Estimating compressive strength of concrete containing rice husk ash using interpretable machine learning-based models,"The construction sector is a major contributor to global greenhouse gas emissions. Using recycled and waste materials in concrete is a practical solution to address environmental challenges. Currently, agricultural waste is widely used as a substitute for cement in the production of eco-friendly concrete. However, traditional methods for assessing the strength of such materials are both expensive and time-consuming. Therefore, this study uses machine learning techniques to develop prediction models for the compressive strength (CS) of rice husk ash (RHA) concrete. The ML techniques used in the present study include random forest (RF), light gradient boosting machine (LightGBM), ridge regression, and extreme gradient boosting (XGBoost). A total of 348 values of CS were collected from the experimental studies, and five characteristics of RHA concrete were taken as input variables. For the performance assessment of the models, multiple statistical metrics were used. During the training phase, the correlation coefficients (R) obtained for ridge regression, RF, XGBoost, and LightGBM were 0.943, 0.981, 0.985, and 0.996, respectively. In the testing set, these values demonstrated even higher performance, with correlation coefficients of 0.971, 0.993, 0.992, and 0.998 for ridge regression, RF, XGBoost, and LightGBM, respectively. The statistical analysis revealed that the LightGBM model outperformed other models, whereas the ridge regression model exhibited comparatively lower accuracy. SHapley Additive exPlanation (SHAP) method was employed for the interpretability of the developed model. The SHAP analysis revealed that water-to-cement is a controlling parameter in estimating the CS of RHA concrete. In conclusion, this study provides valuable guidance for builders and researchers to estimate the CS of RHA concrete. However, it is suggested that more input variables be incorporated and hybrid models utilized to further enhance the reliability and precision of the models.","['random forest (RF)', 'light gradient boosting machine (LightGBM)', 'ridge regression', 'extreme gradient boosting (XGBoost)', 'SHapley Additive exPlanation (SHAP)']"
2024,https://openalex.org/W4393012885,Biology,Improving Thyroid Disorder Diagnosis via Ensemble Stacking and Bidirectional Feature Selection,"Thyroid disorders represent a significant global health challenge with hypothyroidism and hyperthyroidism as two common conditions arising from dysfunction in the thyroid gland.Accurate and timely diagnosis of these disorders is crucial for effective treatment and patient care.This research introduces a comprehensive approach to improve the accuracy of thyroid disorder diagnosis through the integration of ensemble stacking and advanced feature selection techniques.Sequential forward feature selection, sequential backward feature elimination, and bidirectional feature elimination are investigated in this study.In ensemble learning, random forest, adaptive boosting, and bagging classifiers are employed.The effectiveness of these techniques is evaluated using two different datasets obtained from the University of California Irvine-Machine Learning Repository, both of which undergo preprocessing steps, including outlier removal, addressing missing data, data cleansing, and feature reduction.Extensive experimentation demonstrates the remarkable success of proposed ensemble stacking and bidirectional feature elimination achieving 100% and 99.86% accuracy in identifying hyperthyroidism and hypothyroidism, respectively.Beyond enhancing detection accuracy, the ensemble stacking model also demonstrated a streamlined computational complexity which is pivotal for practical medical applications.It significantly outperformed existing studies with similar objectives underscoring the viability and effectiveness of the proposed scheme.This research offers an innovative perspective and sets the platform for improved thyroid disorder diagnosis with broader implications for healthcare and patient well-being.","['ensemble stacking', 'sequential forward feature selection', 'sequential backward feature elimination', 'random forest', 'adaptive boosting', 'bagging classifiers']"
2024,https://openalex.org/W4391558635,Biology,Large Language Models are Few-Shot Summarizers: Multi-Intent Comment Generation via In-Context Learning,"Code comment generation aims at generating natural language descriptions for a code snippet to facilitate developers' program comprehension activities. Despite being studied for a long time, a bottleneck for existing approaches is that given a code snippet, they can only generate one comment while developers usually need to know information from diverse perspectives such as what is the functionality of this code snippet and how to use it. To tackle this limitation, this study empirically investigates the feasibility of utilizing large language models (LLMs) to generate comments that can fulfill developers' diverse intents. Our intuition is based on the facts that (1) the code and its pairwise comment are used during the pre-training process of LLMs to build the semantic connection between the natural language and programming language, and (2) comments in the real-world projects, which are collected for the pre-training, usually contain different developers' intents. We thus postulate that the LLMs can already understand the code from different perspectives after the pre-training. Indeed, experiments on two large-scale datasets demonstrate the rationale of our insights: by adopting the in-context learning paradigm and giving adequate prompts to the LLM (e.g., providing it with ten or more examples), the LLM can significantly outperform a state-of-the-art supervised learning approach on generating comments with multiple intents. Results also show that customized strategies for constructing the prompts and post-processing strategies for reranking the results can both boost the LLM's performances, which shed light on future research directions for using LLMs to achieve comment generation.","['in-context learning paradigm', 'supervised learning approach']"
2024,https://openalex.org/W4390738897,Biology,Enhancing crop recommendation systems with explainable artificial intelligence: a study on agricultural decision-making,"Abstract Crop Recommendation Systems are invaluable tools for farmers, assisting them in making informed decisions about crop selection to optimize yields. These systems leverage a wealth of data, including soil characteristics, historical crop performance, and prevailing weather patterns, to provide personalized recommendations. In response to the growing demand for transparency and interpretability in agricultural decision-making, this study introduces XAI-CROP an innovative algorithm that harnesses eXplainable artificial intelligence (XAI) principles. The fundamental objective of XAI-CROP is to empower farmers with comprehensible insights into the recommendation process, surpassing the opaque nature of conventional machine learning models. The study rigorously compares XAI-CROP with prominent machine learning models, including Gradient Boosting (GB), Decision Tree (DT), Random Forest (RF), Gaussian Naïve Bayes (GNB), and Multimodal Naïve Bayes (MNB). Performance evaluation employs three essential metrics: Mean Squared Error (MSE), Mean Absolute Error (MAE), and R-squared (R2). The empirical results unequivocally establish the superior performance of XAI-CROP. It achieves an impressively low MSE of 0.9412, indicating highly accurate crop yield predictions. Moreover, with an MAE of 0.9874, XAI-CROP consistently maintains errors below the critical threshold of 1, reinforcing its reliability. The robust R 2 value of 0.94152 underscores XAI-CROP's ability to explain 94.15% of the data's variability, highlighting its interpretability and explanatory power.","['Gradient Boosting (GB)', 'Decision Tree (DT)', 'Random Forest (RF)', 'Gaussian Naïve Bayes (GNB)']"
2024,https://openalex.org/W4391177783,Biology,"Making food systems more resilient to food safety risks by including artificial intelligence, big data, and internet of things into food safety early warning and emerging risk identification tools","Abstract To enhance the resilience of food systems to food safety risks, it is vitally important for national authorities and international organizations to be able to identify emerging food safety risks and to provide early warning signals in a timely manner. This review provides an overview of existing and experimental applications of artificial intelligence (AI), big data, and internet of things as part of early warning and emerging risk identification tools and methods in the food safety domain. There is an ongoing rapid development of systems fed by numerous, real‐time, and diverse data with the aim of early warning and identification of emerging food safety risks. The suitability of big data and AI to support such systems is illustrated by two cases in which climate change drives the emergence of risks, namely, harmful algal blooms affecting seafood and fungal growth and mycotoxin formation in crops. Automation and machine learning are crucial for the development of future real‐time food safety risk early warning systems. Although these developments increase the feasibility and effectiveness of prospective early warning and emerging risk identification tools, their implementation may prove challenging, particularly for low‐ and middle‐income countries due to low connectivity and data availability. It is advocated to overcome these challenges by improving the capability and capacity of national authorities, as well as by enhancing their collaboration with the private sector and international organizations.",['machine learning']
2024,https://openalex.org/W4391783116,Biology,Assessing water quality of an ecologically critical urban canal incorporating machine learning approaches,"This study assessed water quality (WQ) in Tongi Canal, an ecologically critical and economically important urban canal in Bangladesh. The researchers employed the Root Mean Square Water Quality Index (RMS-WQI) model, utilizing seven WQ indicators, including temperature, dissolve oxygen, electrical conductivity, lead, cadmium, and iron to calculate the water quality index (WQI) score. The results showed that most of the water sampling locations showed poor WQ, with many indicators violating Bangladesh's environmental conservation regulations. This study employed eight machine learning algorithms, where the Gaussian process regression (GPR) model demonstrated superior performance (training RMSE = 1.77, testing RMSE = 0.0006) in predicting WQI scores. To validate the GPR model's performance, several performance measures, including the coefficient of determination (R2), the Nash-Sutcliffe efficiency (NSE), the model efficiency factor (MEF), Z statistics, and Taylor diagram analysis, were employed. The GPR model exhibited higher sensitivity (R2 = 1.0) and efficiency (NSE = 1.0, MEF = 0.0) in predicting WQ. The analysis of model uncertainty (standard uncertainty = 7.08 ± 0.9025; expanded uncertainty = 7.08 ± 1.846) indicates that the RMS-WQI model holds potential for assessing the WQ of inland waterbodies. These findings indicate that the RMS-WQI model could be an effective approach for assessing inland waters across Bangladesh. The study's results showed that most of the WQ indicators did not meet the recommended guidelines, indicating that the water in the Tongi Canal is unsafe and unsuitable for various purposes. The study's implications extend beyond the Tongi Canal and could contribute to WQ management initiatives across Bangladesh.",['Gaussian process regression (GPR)']
2024,https://openalex.org/W4400748541,Biology,Comparing YOLOv8 and Mask R-CNN for instance segmentation in complex orchard environments,"Instance segmentation, an important image processing operation for automation in agriculture, is used to precisely delineate individual objects of interest within images, which provides foundational information for various automated or robotic tasks such as selective harvesting and precision pruning. This study compares the one-stage YOLOv8 and the two-stage Mask R-CNN machine learning models for instance segmentation under varying orchard conditions across two datasets. Dataset 1, collected in dormant season, includes images of dormant apple trees, which were used to train multi-object segmentation models delineating tree branches and trunks. Dataset 2, collected in the early growing season, includes images of apple tree canopies with green foliage and immature (green) apples (also called fruitlet), which were used to train single-object segmentation models delineating only immature green apples. The results showed that YOLOv8 performed better than Mask R-CNN, achieving good precision and near-perfect recall across both datasets at a confidence threshold of 0.5. Specifically, for Dataset 1, YOLOv8 achieved a precision of 0.90 and a recall of 0.95 for all classes. In comparison, Mask R-CNN demonstrated a precision of 0.81 and a recall of 0.81 for the same dataset. With Dataset 2, YOLOv8 achieved a precision of 0.93 and a recall of 0.97. Mask R-CNN, in this single-class scenario, achieved a precision of 0.85 and a recall of 0.88. Additionally, the inference times for YOLOv8 were 10.9 ms for multi-class segmentation (Dataset 1) and 7.8 ms for single-class segmentation (Dataset 2), compared to 15.6 ms and 12.8 ms achieved by Mask R-CNN's, respectively. These findings show YOLOv8's superior accuracy and efficiency in machine learning applications compared to two-stage models, specifically Mask-R-CNN, which suggests its suitability in developing smart and automated orchard operations, particularly when real-time applications are necessary in such cases as robotic harvesting and robotic immature green fruit thinning.","['YOLOv8', 'Mask R-CNN']"
2024,https://openalex.org/W4390659289,Biology,Cognition-Driven Structural Prior for Instance-Dependent Label Transition Matrix Estimation,"The label transition matrix has emerged as a widely accepted method for mitigating label noise in machine learning. In recent years, numerous studies have centered on leveraging deep neural networks to estimate the label transition matrix for individual instances within the context of instance-dependent noise. However, these methods suffer from low search efficiency due to the large space of feasible solutions. Behind this drawback, we have explored that the real murderer lies in the invalid class transitions, that is, the actual transition probability between certain classes is zero but is estimated to have a certain value. To mask the <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">invalid class transitions</i> , we introduced a human-cognition-assisted method with structural information from human cognition. Specifically, we introduce a structured transition matrix network ( <bold xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">STMN</b> ) designed with an adversarial learning process to balance instance features and prior information from human cognition. The proposed method offers two advantages: 1) better estimation effectiveness is obtained by sparing the transition matrix and 2) better estimation accuracy is obtained with the assistance of human cognition. By exploiting these two advantages, our method parametrically estimates a sparse label transition matrix, effectively converting noisy labels into true labels. The efficiency and superiority of our proposed method are substantiated through comprehensive comparisons with state-of-the-art methods on three synthetic datasets and a real-world dataset. Our code will be available at https://github.com/WheatCao/STMN-Pytorch.","['deep neural networks', 'adversarial learning process']"
2024,https://openalex.org/W4392980686,Biology,Data-driven evolution of water quality models: An in-depth investigation of innovative outlier detection approaches-A case study of Irish Water Quality Index (IEWQI) model,"Recently, there has been a significant advancement in the water quality index (WQI) models utilizing data-driven approaches, especially those integrating machine learning and artificial intelligence (ML/AI) technology. Although, several recent studies have revealed that the data-driven model has produced inconsistent results due to the data outliers, which significantly impact model reliability and accuracy. The present study was carried out to assess the impact of data outliers on a recently developed Irish Water Quality Index (IEWQI) model, which relies on data-driven techniques. To the author's best knowledge, there has been no systematic framework for evaluating the influence of data outliers on such models. For the purposes of assessing the outlier impact of the data outliers on the water quality (WQ) model, this was the first initiative in research to introduce a comprehensive approach that combines machine learning with advanced statistical techniques. The proposed framework was implemented in Cork Harbour, Ireland, to evaluate the IEWQI model's sensitivity to outliers in input indicators to assess the water quality. In order to detect the data outlier, the study utilized two widely used ML techniques, including Isolation Forest (IF) and Kernel Density Estimation (KDE) within the dataset, for predicting WQ with and without these outliers. For validating the ML results, the study used five commonly used statistical measures. The performance metric (R2) indicates that the model performance improved slightly (R2 increased from 0.92 to 0.95) in predicting WQ after removing the data outlier from the input. But the IEWQI scores revealed that there were no statistically significant differences among the actual values, predictions with outliers, and predictions without outliers, with a 95% confidence interval at p < 0.05. The results of model uncertainty also revealed that the model contributed <1% uncertainty to the final assessment results for using both datasets (with and without outliers). In addition, all statistical measures indicated that the ML techniques provided reliable results that can be utilized for detecting outliers and their impacts on the IEWQI model. The findings of the research reveal that although the data outliers had no significant impact on the IEWQI model architecture, they had moderate impacts on the rating schemes' of the model. This finding indicated that detecting the data outliers could improve the accuracy of the IEWQI model in rating WQ as well as be helpful in mitigating the model eclipsing problem. In addition, the results of the research provide evidence of how the data outliers influenced the data-driven model in predicting WQ and reliability, particularly since the study confirmed that the IEWQI model's could be effective for accurately rating WQ despite the presence of the data outliers in the input. It could occur due to the spatio-temporal variability inherent in WQ indicators. However, the research assesses the influence of data input outliers on the IEWQI model and underscores important areas for future investigation. These areas include expanding temporal analysis using multi-year data, examining spatial outlier patterns, and evaluating detection methods. Moreover, it is essential to explore the real-world impacts of revised rating categories, involve stakeholders in outlier management, and fine-tune model parameters. Analysing model performance across varying temporal and spatial resolutions and incorporating additional environmental data can significantly enhance the accuracy of WQ assessment. Consequently, this study offers valuable insights to strengthen the IEWQI model's robustness and provides avenues for enhancing its utility in broader WQ assessment applications. Moreover, the study successfully adopted the framework for evaluating how data input outliers affect the data-driven model, such as the IEWQI model. The current study has been carried out in Cork Harbour for only a single year of WQ data. The framework should be tested across various domains for evaluating the response of the IEWQI model's in terms of the spatio-temporal resolution of the domain. Nevertheless, the study recommended that future research should be conducted to adjust or revise the IEWQI model's rating schemes and investigate the practical effects of data outliers on updated rating categories. However, the study provides potential recommendations for enhancing the IEWQI model's adaptability and reveals its effectiveness in expanding its applicability in more general WQ assessment scenarios.",['Isolation Forest (IF)']
2024,https://openalex.org/W4396707011,Biology,DeepAVP-TPPred: identification of antiviral peptides using transformed image-based localized descriptors and binary tree growth algorithm,"Abstract Motivation Despite the extensive manufacturing of antiviral drugs and vaccination, viral infections continue to be a major human ailment. Antiviral peptides (AVPs) have emerged as potential candidates in the pursuit of novel antiviral drugs. These peptides show vigorous antiviral activity against a diverse range of viruses by targeting different phases of the viral life cycle. Therefore, the accurate prediction of AVPs is an essential yet challenging task. Lately, many machine learning-based approaches have developed for this purpose; however, their limited capabilities in terms of feature engineering, accuracy, and generalization make these methods restricted. Results In the present study, we aim to develop an efficient machine learning-based approach for the identification of AVPs, referred to as DeepAVP-TPPred, to address the aforementioned problems. First, we extract two new transformed feature sets using our designed image-based feature extraction algorithms and integrate them with an evolutionary information-based feature. Next, these feature sets were optimized using a novel feature selection approach called binary tree growth Algorithm. Finally, the optimal feature space from the training dataset was fed to the deep neural network to build the final classification model. The proposed model DeepAVP-TPPred was tested using stringent 5-fold cross-validation and two independent dataset testing methods, which achieved the maximum performance and showed enhanced efficiency over existing predictors in terms of both accuracy and generalization capabilities. Availability and implementation https://github.com/MateeullahKhan/DeepAVP-TPPred.",['deep neural network']
2024,https://openalex.org/W4391235397,Biology,Real-Time Plant Disease Dataset Development and Detection of Plant Disease Using Deep Learning,"Agriculture plays a significant role in meeting food needs and providing food security for the increasingly growing global population, which has increased by 0.88% since 2022. Plant diseases can reduce food production and affect food security. Worldwide crop loss due to plant disease is estimated to be around 14.1%. The lack of proper identification of plant disease at the early stages of infection can result in inappropriate disease control measures. Therefore, the automatic identification and diagnosis of plant diseases are highly recommended. Lack of availability of large amounts of data that are not processed to a large extent is one of the main challenges in plant disease diagnosis. In the current manuscript, we developed datasets for food grains specifically for rice, wheat, and maize to address the identified challenges. The developed datasets consider the common diseases (two bacterial diseases and two fungal diseases of rice, four fungal diseases of maize, and four fungal diseases of wheat) that affect crop yields and cause damage to the whole plant. The datasets developed were applied to eight fine-tuned deep learning models with the same training hyperparameters. The experimental results based on eight fine-tuned deep learning models show that, while recognizing maize leaf diseases, the models Xception and MobileNet performed best with a testing accuracy of 0.9580 and 0.9464 respectively. Similarly, while recognizing the wheat leaf diseases, the models MobileNetV2 and MobileNet performed best with a testing accuracy of 0.9632 and 0.9628 respectively. The Xception and Inception V3 models performed best, with a testing accuracy of 0.9728 and 0.9620, respectively, for recognizing rice leaf diseases. The research also proposes a new convolutional neural network (CNN) model trained from scratch on all three food grain datasets developed. The proposed model performs well and shows a testing accuracy of 0.9704, 0.9706, and 0.9808 respectively on the maize, rice, and wheat datasets.","['fine-tuned deep learning models', 'Xception', 'MobileNet', 'MobileNetV2', 'Inception V3', 'convolutional neural network (CNN) model trained from scratch']"
2024,https://openalex.org/W4396494945,Biology,Vision–language foundation model for echocardiogram interpretation,"Abstract The development of robust artificial intelligence models for echocardiography has been limited by the availability of annotated clinical data. Here, to address this challenge and improve the performance of cardiac imaging models, we developed EchoCLIP, a vision–language foundation model for echocardiography, that learns the relationship between cardiac ultrasound images and the interpretations of expert cardiologists across a wide range of patients and indications for imaging. After training on 1,032,975 cardiac ultrasound videos and corresponding expert text, EchoCLIP performs well on a diverse range of benchmarks for cardiac image interpretation, despite not having been explicitly trained for individual interpretation tasks. EchoCLIP can assess cardiac function (mean absolute error of 7.1% when predicting left ventricular ejection fraction in an external validation dataset) and identify implanted intracardiac devices (area under the curve (AUC) of 0.84, 0.92 and 0.97 for pacemakers, percutaneous mitral valve repair and artificial aortic valves, respectively). We also developed a long-context variant (EchoCLIP-R) using a custom tokenizer based on common echocardiography concepts. EchoCLIP-R accurately identified unique patients across multiple videos (AUC of 0.86), identified clinical transitions such as heart transplants (AUC of 0.79) and cardiac surgery (AUC 0.77) and enabled robust image-to-text search (mean cross-modal retrieval rank in the top 1% of candidate text reports). These capabilities represent a substantial step toward understanding and applying foundation models in cardiovascular imaging for preliminary interpretation of echocardiographic findings.",['vision–language foundation model']
2024,https://openalex.org/W4391089359,Biology,Groundwater level prediction using an improved SVR model integrated with hybrid particle swarm optimization and firefly algorithm,"The demand for water resources has increased due to rapid increase of metropolitan areas brought on by growth in population and industrialisation. In addition, the groundwater recharge is being afftected by shifting land use pattern caused by urban development. Using precise and trustworthy estimates of groundwater level is vital for the sustainable groundwater resources management in the face of changing climatic circumstances. In this context, machine learning (ML) methods offer a new and promising approach for accurately forecasting long-term changes in the groundwater level (GWL) without computational effort of developing a comprehensive flow model. In order to simulate GWL, five data-driven (DD) models, including the hybridization of support vector regression (SVR) with two optimisation algorithms i.e., firefly algorithm and particle swarm optimisation (FFAPSO), SVR-FFA, SVR-PSO, SVR and Multilayer perception (MLP), have been examined in the present study. Spatial clustering was utilised to choose four observation wells within Cuttack district in order to study and assess the water levels. Six scenarios were created by incorporating numerous variables, such as GWL in the previous months, evapotranspiration, temperature, precipitation, and river discharge. The goal was to identify the variables that were most efficient in predicting GWL. The SVR-FFAPSO model performs best in GWL forecasting for Khuntuni station, according to the quantitative analysis with correlation coefficient (R) = 0.9978, Nash–Sutcliffe efficiency (NSE) = 0.9933, mean absolute error (MAE) = 0.00025 (m), root mean squared error (RMSE) = 0.00775 (m) during the training phase. It is advised that groundwater monitoring network and data collecting system are strengthen in India for ensuring effective modelling of long-term management of groundwater resources.","['support vector regression (SVR)', 'firefly algorithm', 'SVR-PSO']"
2024,https://openalex.org/W4391145008,Biology,Assessing ChatGPT’s Mastery of Bloom’s Taxonomy Using Psychosomatic Medicine Exam Questions: Mixed-Methods Study,"Background Large language models such as GPT-4 (Generative Pre-trained Transformer 4) are being increasingly used in medicine and medical education. However, these models are prone to “hallucinations” (ie, outputs that seem convincing while being factually incorrect). It is currently unknown how these errors by large language models relate to the different cognitive levels defined in Bloom’s taxonomy. Objective This study aims to explore how GPT-4 performs in terms of Bloom’s taxonomy using psychosomatic medicine exam questions. Methods We used a large data set of psychosomatic medicine multiple-choice questions (N=307) with real-world results derived from medical school exams. GPT-4 answered the multiple-choice questions using 2 distinct prompt versions: detailed and short. The answers were analyzed using a quantitative approach and a qualitative approach. Focusing on incorrectly answered questions, we categorized reasoning errors according to the hierarchical framework of Bloom’s taxonomy. Results GPT-4’s performance in answering exam questions yielded a high success rate: 93% (284/307) for the detailed prompt and 91% (278/307) for the short prompt. Questions answered correctly by GPT-4 had a statistically significant higher difficulty than questions answered incorrectly (P=.002 for the detailed prompt and P&lt;.001 for the short prompt). Independent of the prompt, GPT-4’s lowest exam performance was 78.9% (15/19), thereby always surpassing the “pass” threshold. Our qualitative analysis of incorrect answers, based on Bloom’s taxonomy, showed that errors were primarily in the “remember” (29/68) and “understand” (23/68) cognitive levels; specific issues arose in recalling details, understanding conceptual relationships, and adhering to standardized guidelines. Conclusions GPT-4 demonstrated a remarkable success rate when confronted with psychosomatic medicine multiple-choice exam questions, aligning with previous findings. When evaluated through Bloom’s taxonomy, our data revealed that GPT-4 occasionally ignored specific facts (remember), provided illogical reasoning (understand), or failed to apply concepts to a new situation (apply). These errors, which were confidently presented, could be attributed to inherent model biases and the tendency to generate outputs that maximize likelihood.",['GPT-4 (Generative Pre-trained Transformer 4)']
2024,https://openalex.org/W4391855187,Biology,Machine learning-assisted in-situ adaptive strategies for the control of defects and anomalies in metal additive manufacturing,"In metal additive manufacturing (AM), the material microstructure and part geometry are formed incrementally. Consequently, the resulting part could be defect- and anomaly-free if sufficient care is taken to deposit each layer under optimal process conditions. Conventional closed-loop control (CLC) engineering solutions which sought to achieve this were deterministic and rule-based, thus resulting in limited success in the stochastic environment experienced in the highly dynamic AM process. On the other hand, emerging machine learning (ML) based strategies are better suited to providing the robustness, scope, flexibility, and scalability required for process control in an uncertain environment. Offline ML models that help optimise AM process parameters before a build begins and online ML models that efficiently processed in-situ sensory data to detect and diagnose flaws in real-time (or near-real-time) have been developed. However, ML models that enable a process to take evasive or corrective actions in relation to flaws via on the fly decision-making are only emerging. These models must possess prognostic capabilities to provide context-sensitive recommendations for in-situ process control based on real-time diagnostics. In this article, we pinpoint the shortcomings in traditional CLC strategies, and provide a framework for defect and anomaly control through ML-assisted CLC in AM. We discuss flaws in terms of their causes, in-situ detectability, and controllability, and examine their management under three scenarios: avoidance, mitigation, and repair. Then, we summarise the research into ML models developed for offline optimisation and in-situ diagnosis before initiating a detailed conversation on the implementation of ML-assisted in-situ process control. We found that researchers favoured reinforcement learning approaches or inverse ML models for making rapid, situation-aware control decisions. We also observed that, to-date, the defects addressed were those that may be quantified relatively easily autonomously, and that mitigation (rather than avoidance or repair) was the aim of ML-assisted in-situ control strategies. Additionally, we highlight the various technologies that must seamlessly combine to advance the field of autonomous in-situ control so that it becomes a reality in industrial settings. Finally, we raise awareness of seldom discussed, yet highly pertinent, topics relevant to adaptive control. Our work closes a significant gap in the current AM literature by broaching wide-ranging discussions on matters relevant to in-situ adaptive control in AM.","['online ML models', 'reinforcement learning approaches']"
2024,https://openalex.org/W4392640075,Biology,Performance assessment of machine learning algorithms for mapping of land use/land cover using remote sensing data,"The rapid increase in population accelerates the rate of change of Land use/Land cover (LULC) in various parts of the world. This phenomenon caused a huge strain for natural resources. Hence, continues monitoring of LULC changes gained a significant importance for management of natural resources and assessing the climate change impacts. Recently, application of machine learning algorithms on RS (remote sensing) data for rapid and accurate mapping of LULC gained significant importance due to growing need of LULC estimation for ecosystem services, natural resource management and environmental management. Hence, it is crucial to access and compare the performance of different machine learning classifiers for accurate mapping of LULC. The primary objective of this study was to compare the performance of CART (Classification and Regression Tree), RF (Random Forest) and SVM (Support Vector Machine) for LULC estimation by processing RS data on Google Earth Engine (GEE). In total four classes of LULC (Water Bodies, Vegetation Cover, Urban Land and Barren Land) for city of Lahore were extracted using satellite images from Landsat-7, Landsat-8 and Landsat-9 for years 2008, 2015 and 2022, respectively. According to results, RF is the best performing classifier with maximum overall accuracy of 95.2% and highest Kappa coefficient value of 0.87, SVM achieved maximum accuracy of 89.8% with highest Kappa of 0.84 and CART showed maximum overall accuracy of 89.7% with Kappa value of 0.79. Results from this study can give assistance for decision makers, planners and RS experts to choose a suitable machine learning algorithm for LULC classification in an unplanned urbanized city like Lahore.","['Classification and Regression Tree (CART)', 'Random Forest (RF)', 'Support Vector Machine (SVM)']"
2024,https://openalex.org/W4390480832,Biology,Joint Optimization Risk Factor and Energy Consumption in IoT Networks With TinyML-Enabled Internet of UAVs,"The high mobility of Internet of Unmanned Aerial Vehicles (IUAVs) has attracted attention in the field of data collection. With the rapid development of the Internet of Things (IoT), more and more data are generated by IoT networks. IUAV-aided IoT networks can efficiently collect data in specific areas, which is of great significance in disaster relief. In the data collection task, it is necessary to plan the flight trajectory for the data collector—IUAV, so that the IUAV can collect data efficiently. However, existing research basically only considers the efficiency of data collection by IUAVs, but rarely considers the safety of IUAVs during flight. Therefore, this paper proposes an IUAV trajectory planning algorithm that integrates energy efficiency and safety using local search to address the issues mentioned above. At the same time, a Tiny Machine Learning (TinyML) algorithm is designed to assist the IUAV in making real-time decisions during flight. First, we build a general mathematical model that describes the risk in a particular region. Then consider guiding the IUAV to a safer trajectory by introducing virtual nodes in the flight trajectory. Furthermore, we designed a local search algorithm for the three tasks of IUAV access sequence, IoT Networks cluster heads selection and virtual nodes selection, and solved them through iterative optimization. We also consider the unreachable situation of the virtual nodes and use TinyML technology to help the IUAV adjust the position of the virtual nodes in real time in case of an emergency.In the end, an IUAV trajectory is obtained that can efficiently collect IoT networks' data and fly safely. We have conducted a large number of simulation experiments to demonstrate the efficiency of the proposed algorithm compared to the baseline algorithm.",['Tiny Machine Learning (TinyML)']
2024,https://openalex.org/W4390754233,Biology,Groundwater Quality Assessment and Irrigation Water Quality Index Prediction Using Machine Learning Algorithms,"The evaluation of groundwater quality is crucial for irrigation purposes; however, due to financial constraints in developing countries, such evaluations suffer from insufficient sampling frequency, hindering comprehensive assessments. Therefore, associated with machine learning approaches and the irrigation water quality index (IWQI), this research aims to evaluate the groundwater quality in Naama, a region in southwest Algeria. Hydrochemical parameters (cations, anions, pH, and EC), qualitative indices (SAR,RSC,Na%,MH,and PI), as well as geospatial representations were used to determine the groundwater’s suitability for irrigation in the study area. In addition, efficient machine learning approaches for forecasting IWQI utilizing Extreme Gradient Boosting (XGBoost), Support vector regression (SVR), and K-Nearest Neighbours (KNN) models were implemented. In this research, 166 groundwater samples were used to calculate the irrigation index. The results showed that 42.18% of them were of excellent quality, 34.34% were of very good quality, 6.63% were good quality, 9.64% were satisfactory, and 4.21% were considered unsuitable for irrigation. On the other hand, results indicate that XGBoost excels in accuracy and stability, with a low RMSE (of 2.8272 and a high R of 0.9834. SVR with only four inputs (Ca2+, Mg2+, Na+, and K) demonstrates a notable predictive capability with a low RMSE of 2.6925 and a high R of 0.98738, while KNN showcases robust performance. The distinctions between these models have important implications for making informed decisions in agricultural water management and resource allocation within the region.","['Extreme Gradient Boosting (XGBoost)', 'Support Vector Regression (SVR)', 'K-Nearest Neighbours (KNN)']"
2024,https://openalex.org/W4391347933,Biology,CCL-DTI: contributing the contrastive loss in drug–target interaction prediction,"Abstract Background The Drug–Target Interaction (DTI) prediction uses a drug molecule and a protein sequence as inputs to predict the binding affinity value. In recent years, deep learning-based models have gotten more attention. These methods have two modules: the feature extraction module and the task prediction module. In most deep learning-based approaches, a simple task prediction loss (i.e., categorical cross entropy for the classification task and mean squared error for the regression task) is used to learn the model. In machine learning, contrastive-based loss functions are developed to learn more discriminative feature space. In a deep learning-based model, extracting more discriminative feature space leads to performance improvement for the task prediction module. Results In this paper, we have used multimodal knowledge as input and proposed an attention-based fusion technique to combine this knowledge. Also, we investigate how utilizing contrastive loss function along the task prediction loss could help the approach to learn a more powerful model. Four contrastive loss functions are considered: (1) max-margin contrastive loss function, (2) triplet loss function, (3) Multi-class N-pair Loss Objective, and (4) NT-Xent loss function. The proposed model is evaluated using four well-known datasets: Wang et al. dataset, Luo's dataset, Davis, and KIBA datasets. Conclusions Accordingly, after reviewing the state-of-the-art methods, we developed a multimodal feature extraction network by combining protein sequences and drug molecules, along with protein–protein interaction networks and drug–drug interaction networks. The results show it performs significantly better than the comparable state-of-the-art approaches.","['contrastive loss function', 'max-margin contrastive loss function', 'triplet loss function', 'Multi-class N-pair Loss Objective', 'NT-Xent loss function']"
2024,https://openalex.org/W4391248672,Biology,Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning,"Recent development in computing power has resulted in performance improvements on holistic(none-occluded) person Re-Identification (ReID) tasks. Nevertheless, the precision of the recent research will diminish when a pedestrian is obstructed by obstacles. Within the realm of 2D space, the loss of information from obstructed objects continues to pose significant challenges in the context of person ReID. Person is a 3D non-grid object, and thus semantic representation learning in only 2D space limits the understanding of occluded person. In the present work, we propose a network based on 3D multi-view learning, allowing it to acquire geometric and shape details of an occluded pedestrian from 3D space. Simultaneously, it capitalizes on advancements in 2D-based networks to extract semantic representations from 3D multi-views. Specifically, the surface random selection strategy is proposed to convert images of 2D RGB into 3D multi-views. Using this strategy, we build four extensive 3D multi-view data collections for person ReID. After that, Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning(MV-3DSReID), is proposed for identifying the person by learning person geometry and structure representation from the groups of multi-view images. In comparison to alternative data formats (e.g., 2D RGB, 3D point cloud), multi-view images complement each other's detailed features of the 3D object by adjusting rendering viewpoints, thus facilitating a more comprehensive understanding of the person for both holistic and occluded ReID situations. Experiments on occluded and holistic ReID tasks demonstrate performance levels comparable to state-of-the-art methods, validating the effectiveness of our proposed approach in tackling challenges related to occlusion. The code is available at https://github.com/hangjiaqi1/MV-TransReID.",['3D multi-view learning']
2024,https://openalex.org/W4394685122,Biology,Sequence Training and Data Shuffling to Enhance the Accuracy of Recurrent Neural Network Based Battery Voltage Models,"&lt;div class=""section abstract""&gt;&lt;div class=""htmlview paragraph""&gt;Battery terminal voltage modelling is crucial for various applications, including electric vehicles, renewable energy systems, and portable electronics. Terminal voltage models are used to determine how a battery will respond under load and can be used to calculate run-time, power capability, and heat generation and as a component of state estimation approaches, such as for state of charge. Previous studies have shown better voltage modelling accuracy for long short-term memory (LSTM) recurrent neural networks than other traditional methods (e.g., equivalent circuit and electrochemical models). This study presents two new approaches – sequence training and data shuffling – to improve LSTM battery voltage models further, making them an even better candidate for the high-accuracy modelling of lithium-ion batteries. Because the LSTM memory captures information from past time steps, it must typically be trained using one series of continuous data. Instead, the proposed sequence training approach feeds a fixed window of prior data (e.g., 100 seconds) into the LSTM at each time step to initialize the memory states properly and then only uses the output at the current time step. With this method, the LSTM just requires the prior data window to be continuous, thereby allowing the handling of discontinuities. This also means that during the training process, the data can be shuffled randomly, enabling mini-batches to speed up the training significantly. When these approaches were applied, LSTM voltage estimation error was reduced by 22%, from 28.5 mV to 22.3 mV RMS error over four drive cycles and temperatures from -20 to 25°C.&lt;/div&gt;&lt;/div&gt;","['long short-term memory (LSTM) recurrent neural networks', 'sequence training']"
2024,https://openalex.org/W4401844424,Biology,AlphaFold predictions of fold-switched conformations are driven by structure memorization,"Abstract Recent work suggests that AlphaFold (AF)–a deep learning-based model that can accurately infer protein structure from sequence–may discern important features of folded protein energy landscapes, defined by the diversity and frequency of different conformations in the folded state. Here, we test the limits of its predictive power on fold-switching proteins, which assume two structures with regions of distinct secondary and/or tertiary structure. We find that (1) AF is a weak predictor of fold switching and (2) some of its successes result from memorization of training-set structures rather than learned protein energetics. Combining &gt;280,000 models from several implementations of AF2 and AF3, a 35% success rate was achieved for fold switchers likely in AF’s training sets. AF2’s confidence metrics selected against models consistent with experimentally determined fold-switching structures and failed to discriminate between low and high energy conformations. Further, AF captured only one out of seven experimentally confirmed fold switchers outside of its training sets despite extensive sampling of an additional ~280,000 models. Several observations indicate that AF2 has memorized structural information during training, and AF3 misassigns coevolutionary restraints. These limitations constrain the scope of successful predictions, highlighting the need for physically based methods that readily predict multiple protein conformations.","['AlphaFold (AF)', 'AF2']"
2024,https://openalex.org/W4391482136,Biology,A comprehensive analysis of the emerging modern trends in research on photovoltaic systems and desalination in the era of artificial intelligence and machine learning,"Integration of photovoltaic (PV) systems, desalination technologies, and Artificial Intelligence (AI) combined with Machine Learning (ML) has introduced a new era of remarkable research and innovation. This review article thoroughly examines the recent advancements in the field, focusing on the interplay between PV systems and water desalination within the framework of AI and ML applications, along with it analyses current research to identify significant patterns, obstacles, and prospects in this interdisciplinary field. Furthermore, review examines the incorporation of AI and ML methods in improving the performance of PV systems. This includes raising their efficiency, implementing predictive maintenance strategies, and enabling real-time monitoring. It also explores the transformative influence of intelligent algorithms on desalination techniques, specifically addressing concerns pertaining to energy usage, scalability, and environmental sustainability. This article provides a thorough analysis of the current literature, identifying areas where research is lacking and suggesting potential future avenues for investigation. These advancements have resulted in increased efficiency, decreased expenses, and improved sustainability of PV system. By utilizing artificial intelligence technologies, freshwater productivity can increase by 10 % and efficiency. This review offers significant and informative perspectives for researchers, engineers, and policymakers involved in renewable energy and water technology. It sheds light on the latest advancements in photovoltaic systems and desalination, which are facilitated by AI and ML. The review aims to guide towards a more sustainable and technologically advanced future.",['Machine Learning (ML)']
2024,https://openalex.org/W4394822945,Biology,A Critical Review of Artificial Intelligence Based Approaches in Intrusion Detection: A Comprehensive Analysis,"Intrusion detection (ID) is critical in securing computer networks against various malicious attacks. Recent advancements in machine learning (ML), deep learning (DL), federated learning (FL), and explainable artificial intelligence (XAI) have drawn significant attention as potential approaches for ID. DL-based approaches have shown impressive performance in ID by automatically learning relevant features from data but require significant labelled data and computational resources to train complex models. ML-based approaches require fewer computational resources and labelled data, but their ability to generalize to unseen data is limited. FL is a relatively new approach that enables multiple entities to train a model collectively without exchanging their data, providing privacy and security benefits, making it an attractive option for ID. However, FL-based approaches require more communication resources and additional computation to aggregate models from different entities. XAI is critical for understanding how AI models make decisions, improving interpretability and transparency. While existing literature has explored the strengths and weaknesses of DL, ML, FL, and XAI-based approaches for ID, a significant gap exists in providing a comprehensive analysis of the specific use cases and scenarios where each approach is most suitable. This paper seeks to fill this void by delivering an in-depth review that not only highlights strengths and weaknesses but also offers guidance for selecting the appropriate approach based on the unique ID context and available resources. The selection of an appropriate approach depends on the specific use case, and this work provides insights into which method is best suited for various network sizes, data availability, privacy, and security concerns, thus aiding practitioners in making informed decisions for their ID needs.","['machine learning (ML)', 'deep learning (DL)', 'federated learning (FL)']"
2024,https://openalex.org/W4399052867,Biology,Generative artificial intelligence in manufacturing: opportunities for actualizing Industry 5.0 sustainability goals,"Purpose This study offers practical insights into how generative artificial intelligence (AI) can enhance responsible manufacturing within the context of Industry 5.0. It explores how manufacturers can strategically maximize the potential benefits of generative AI through a synergistic approach. Design/methodology/approach The study developed a strategic roadmap by employing a mixed qualitative-quantitative research method involving case studies, interviews and interpretive structural modeling (ISM). This roadmap visualizes and elucidates the mechanisms through which generative AI can contribute to advancing the sustainability goals of Industry 5.0. Findings Generative AI has demonstrated the capability to promote various sustainability objectives within Industry 5.0 through ten distinct functions. These multifaceted functions address multiple facets of manufacturing, ranging from providing data-driven production insights to enhancing the resilience of manufacturing operations. Practical implications While each identified generative AI function independently contributes to responsible manufacturing under Industry 5.0, leveraging them individually is a viable strategy. However, they synergistically enhance each other when systematically employed in a specific order. Manufacturers are advised to strategically leverage these functions, drawing on their complementarities to maximize their benefits. Originality/value This study pioneers by providing early practical insights into how generative AI enhances the sustainability performance of manufacturers within the Industry 5.0 framework. The proposed strategic roadmap suggests prioritization orders, guiding manufacturers in decision-making processes regarding where and for what purpose to integrate generative AI.",['generative artificial intelligence (generative AI)']
2024,https://openalex.org/W4399802093,Biology,Fractional order PID controller for load frequency control in a deregulated hybrid power system using Aquila Optimization,"This paper presents an innovative approach for automatic generation control for power system under a deregulated setting. The main objective of this work is to optimally tune the parameters of the fractional-order controller using the newly developed Aquila Optimizer (AO) to enhance system performance. A test system comprising a thermal power plant, a hydroelectric system, a gas turbine-based power plant, and wind energy sources is examined under deregulated environment. The study emphasizes the minimization of frequency variations, tie line deviations, and area control errors during diverse operational shifts. The proposed control strategy explores the response of generators in a hybrid deregulated power system, emphasizing the critical role of properly tuned Fractional Order Proportional-Integral-Derivative (FOPID) controllers in ensuring system stability. The potential and effectiveness of the proposed algorithm are compared with particle swarm optimization (PSO) and whale optimization algorithm (WOA) based controller performance for the same test system. The objective function for optimization is set as the minimization of the integral time and absolute error (ITAE) performance index. Furthermore, the efficacy of the proposed technique is compared with the Unified Power Flow Controller (UPFC) and its superiority is validated. Performance evaluation of the hybrid power system is conducted under Poolco agreement, bilateral agreement, and varying operating conditions. Comparative assessments reveal the superiority of the AO-driven FOPID over other techniques, demonstrating improved system metrics, including frequencies across different areas, tie-line power variations, and generator outputs.","['Aquila Optimizer (AO)', 'whale optimization algorithm (WOA)']"
2024,https://openalex.org/W4399857583,Biology,Integrating artificial intelligence to assess emotions in learning environments: a systematic literature review,"Introduction Artificial Intelligence (AI) is transforming multiple sectors within our society, including education. In this context, emotions play a fundamental role in the teaching-learning process given that they influence academic performance, motivation, information retention, and student well-being. Thus, the integration of AI in emotional assessment within educational environments offers several advantages that can transform how we understand and address the socio-emotional development of students. However, there remains a lack of comprehensive approach that systematizes advancements, challenges, and opportunities in this field. Aim This systematic literature review aims to explore how artificial intelligence (AI) is used to evaluate emotions within educational settings. We provide a comprehensive overview of the current state of research, focusing on advancements, challenges, and opportunities in the domain of AI-driven emotional assessment within educational settings. Method The review involved a search across the following academic databases: Pubmed, Web of Science, PsycINFO and Scopus. Forty-one articles were selected that meet the established inclusion criteria. These articles were analyzed to extract key insights related to the integration of AI and emotional assessment within educational environments. Results The findings reveal a variety of AI-driven approaches that were developed to capture and analyze students’ emotional states during learning activities. The findings are summarized in four fundamental topics: (1) emotion recognition in education, (2) technology integration and learning outcomes, (3) special education and assistive technology, (4) affective computing. Among the key AI techniques employed are machine learning and facial recognition, which are used to assess emotions. These approaches demonstrate promising potential in enhancing pedagogical strategies and creating adaptive learning environments that cater to individual emotional needs. The review identified emerging factors that, while important, require further investigation to understand their relationships and implications fully. These elements could significantly enhance the use of AI in assessing emotions within educational settings. Specifically, we are referring to: (1) federated learning, (2) convolutional neural network (CNN), (3) recurrent neural network (RNN), (4) facial expression databases, and (5) ethics in the development of intelligent systems. Conclusion This systematic literature review showcases the significance of AI in revolutionizing educational practices through emotion assessment. While advancements are evident, challenges related to accuracy, privacy, and cross-cultural validity were also identified. The synthesis of existing research highlights the need for further research into refining AI models for emotion recognition and emphasizes the importance of ethical considerations in implementing AI technologies within educational contexts.","['machine learning', 'federated learning', 'convolutional neural network (CNN)', 'recurrent neural network (RNN)']"
2024,https://openalex.org/W4401163187,Biology,Monthly climate prediction using deep convolutional neural network and long short-term memory,"Climate change affects plant growth, food production, ecosystems, sustainable socio-economic development, and human health. The different artificial intelligence models are proposed to simulate climate parameters of Jinan city in China, include artificial neural network (ANN), recurrent NN (RNN), long short-term memory neural network (LSTM), deep convolutional NN (CNN), and CNN-LSTM. These models are used to forecast six climatic factors on a monthly ahead. The climate data for 72 years (1 January 1951–31 December 2022) used in this study include monthly average atmospheric temperature, extreme minimum atmospheric temperature, extreme maximum atmospheric temperature, precipitation, average relative humidity, and sunlight hours. The time series of 12 month delayed data are used as input signals to the models. The efficiency of the proposed models are examined utilizing diverse evaluation criteria namely mean absolute error, root mean square error (RMSE), and correlation coefficient (R). The modeling result inherits that the proposed hybrid CNN-LSTM model achieves a greater accuracy than other compared models. The hybrid CNN-LSTM model significantly reduces the forecasting error compared to the models for the one month time step ahead. For instance, the RMSE values of the ANN, RNN, LSTM, CNN, and CNN-LSTM models for monthly average atmospheric temperature in the forecasting stage are 2.0669, 1.4416, 1.3482, 0.8015 and 0.6292 °C, respectively. The findings of climate simulations shows the potential of CNN-LSTM models to improve climate forecasting. Climate prediction will contribute to meteorological disaster prevention and reduction, as well as flood control and drought resistance.","['artificial neural network (ANN)', 'recurrent NN (RNN)', 'long short-term memory neural network (LSTM)', 'deep convolutional NN (CNN)', 'CNN-LSTM']"
2024,https://openalex.org/W4390940873,Biology,Pattern recognition in the nucleation kinetics of non-equilibrium self-assembly,"Abstract Inspired by biology’s most sophisticated computer, the brain, neural networks constitute a profound reformulation of computational principles 1–3 . Analogous high-dimensional, highly interconnected computational architectures also arise within information-processing molecular systems inside living cells, such as signal transduction cascades and genetic regulatory networks 4–7 . Might collective modes analogous to neural computation be found more broadly in other physical and chemical processes, even those that ostensibly play non-information-processing roles? Here we examine nucleation during self-assembly of multicomponent structures, showing that high-dimensional patterns of concentrations can be discriminated and classified in a manner similar to neural network computation. Specifically, we design a set of 917 DNA tiles that can self-assemble in three alternative ways such that competitive nucleation depends sensitively on the extent of colocalization of high-concentration tiles within the three structures. The system was trained in silico to classify a set of 18 grayscale 30 × 30 pixel images into three categories. Experimentally, fluorescence and atomic force microscopy measurements during and after a 150 hour anneal established that all trained images were correctly classified, whereas a test set of image variations probed the robustness of the results. Although slow compared to previous biochemical neural networks, our approach is compact, robust and scalable. Our findings suggest that ubiquitous physical phenomena, such as nucleation, may hold powerful information-processing capabilities when they occur within high-dimensional multicomponent systems.",['neural networks']
2024,https://openalex.org/W4391341367,Biology,Automated Tool Support for Glaucoma Identification With Explainability Using Fundus Images,"Glaucoma is a progressive eye condition that causes irreversible vision loss due to damage to the optic nerve. Recent developments in deep learning and the accessibility of computing resources have provided tool support for automated glaucoma diagnosis. Despite deep learning's advances in disease diagnosis using medical images, generic convolutional neural networks are still not widely used in medical practices due to the limited trustworthiness of these models. Although deep learning-based glaucoma classification has gained popularity in recent years, only a few of them have addressed the explainability and interpretability of the models, which increases confidence in using such applications. This study presents state-of-the-art deep learning techniques to segment and classify fundus images to predict glaucoma conditions and applies visualization techniques to explain the results to ease understandability. Our predictions are based on U-Net with attention mechanisms with ResNet50 for the segmentation process and a modified Inception V3 architecture for the classification. Attention U-Net with modified ResNet50 backbone obtained 99.58% and 98.05% accuracies for optic disc segmentation and optic cup segmentation, respectively for the RIM-ONE dataset. Additionally, we generate heatmaps that highlight the regions that impacted the glaucoma diagnosis using both Gradient-weighted Class Activation Mapping (Grad-CAM) and Grad-CAM++. Our model that classifies the segmented images achieves accuracy, sensitivity, and specificity values of 98.97%, 99.42%, and 95.59%, respectively, with the RIM-ONE dataset. This model can be used as a support tool for automated glaucoma identification using fundus images.","['U-Net with attention mechanisms', 'ResNet50', 'modified Inception V3 architecture', 'Attention U-Net with modified ResNet50 backbone', 'Gradient-weighted Class Activation Mapping (Grad-CAM)', 'Grad-CAM++']"
2024,https://openalex.org/W4391610180,Biology,"Generative artificial intelligence in drug discovery: basic framework, recent advances, challenges, and opportunities","There are two main ways to discover or design small drug molecules. The first involves fine-tuning existing molecules or commercially successful drugs through quantitative structure-activity relationships and virtual screening. The second approach involves generating new molecules through de novo drug design or inverse quantitative structure-activity relationship. Both methods aim to get a drug molecule with the best pharmacokinetic and pharmacodynamic profiles. However, bringing a new drug to market is an expensive and time-consuming endeavor, with the average cost being estimated at around $2.5 billion. One of the biggest challenges is screening the vast number of potential drug candidates to find one that is both safe and effective. The development of artificial intelligence in recent years has been phenomenal, ushering in a revolution in many fields. The field of pharmaceutical sciences has also significantly benefited from multiple applications of artificial intelligence, especially drug discovery projects. Artificial intelligence models are finding use in molecular property prediction, molecule generation, virtual screening, synthesis planning, repurposing, among others. Lately, generative artificial intelligence has gained popularity across domains for its ability to generate entirely new data, such as images, sentences, audios, videos, novel chemical molecules, etc. Generative artificial intelligence has also delivered promising results in drug discovery and development. This review article delves into the fundamentals and framework of various generative artificial intelligence models in the context of drug discovery via de novo drug design approach. Various basic and advanced models have been discussed, along with their recent applications. The review also explores recent examples and advances in the generative artificial intelligence approach, as well as the challenges and ongoing efforts to fully harness the potential of generative artificial intelligence in generating novel drug molecules in a faster and more affordable manner. Some clinical-level assets generated form generative artificial intelligence have also been discussed in this review to show the ever-increasing application of artificial intelligence in drug discovery through commercial partnerships.",['inverse quantitative structure-activity relationship']
2024,https://openalex.org/W4391923223,Biology,Improved random forest algorithms for increasing the accuracy of forest aboveground biomass estimation using Sentinel-2 imagery,"A simpler, unbiased, and comprehensive random forest (RF) model is needed to improve the accuracy of aboveground biomass (AGB) estimation. In this study, data were obtained from 128 sample plots of Pinus yunnanensis forest located in Chuxiong prefecture, Yunnan province, China. Sentinel-2 imagery data were applied to extract the important predictors of forest AGB, which were screened using the Boruta algorithm. We compared the fitting performance of two modified random forest models − regularized random forest (RRF) and quantile random forest (QRF) − with the random forest model. Moreover, we combined the smallest mean error of each quantile model as the best QRF (QRFb). The result showed: (1) Window sizes of 3 × 3 pixels and 5 × 5 pixels demonstrated greater sensitivity and suitability for estimating AGB than the 7 × 7 pixels window size. Enhanced vegetation indices derived from Red Edge 1 (B5) and Near-Infrared bands (B8A) were strongly correlated with AGB, indicating the heightened sensitivity of B5 and B8A bands to biomass and their potential in AGB estimation. (2) The RRF model outperformed both the standard RF and QRF in fitting performance, with an R2 of 0.56 and RMSE 57.14 Mg/ha. (3) The QRFb model exhibited the highest R2 of 0.88 and lowest RMSE of 29.56 Mg/ha, significantly reducing overestimation and underestimation issues. The modified RF regression supplies new insights into improving forest AGB estimation, which will be helpful for future research addressing carbon cycling.","['random forest (RF)', 'Boruta algorithm', 'regularized random forest (RRF)', 'quantile random forest (QRF)']"
2024,https://openalex.org/W4401384485,Biology,GAN based augmentation using a hybrid loss function for dermoscopy images,"Dermatology is the most appropriate field to utilize pattern recognition-based automated techniques for objective, accurate, and rapid diagnosis because diagnosis mainly relies on visual examinations of skin lesions. Recent approaches utilizing deep learning techniques have shown remarkable results in this field. However, they necessitate a substantial quantity of images and the availability of dermoscopy images is often limited. Also, even if enough images are available, their labeling requires expert knowledge and is time-consuming. To overcome these issues, an efficient augmentation approach is needed to expand training datasets from input images. Therefore, in this work, a generative adversarial network has been developed using a new hybrid loss function constructed with traditional loss functions to enhance the generation power of the architecture. Also, the effect of the proposed approach and different generative network-based augmentations, which have been used with dermoscopy images in the literature, on the classification of skin lesions has been investigated. Therefore, the main contributions of this work are: (i) introducing a new generative model for the augmentation of dermoscopy images; (ii) presenting the effect of the proposed model on the classification of the images; (iii) comparative evaluations of the effectiveness of different generative network-based augmentations in the classification of seven forms of skin lesions. The classification accuracy when the proposed augmentation is used is 93.12%, which is higher than its counterparts. Experimental results indicate the significance of augmentation techniques in the classification of skin lesions and the efficiency of the proposed structure in improving the classification accuracy.",['generative adversarial network']
2024,https://openalex.org/W4391317367,Biology,Automated localization of mandibular landmarks in the construction of mandibular median sagittal plane,"Abstract Objective To use deep learning to segment the mandible and identify three-dimensional (3D) anatomical landmarks from cone-beam computed tomography (CBCT) images, the planes constructed from the mandibular midline landmarks were compared and analyzed to find the best mandibular midsagittal plane (MMSP). Methods A total of 400 participants were randomly divided into a training group ( n = 360) and a validation group ( n = 40). Normal individuals were used as the test group ( n = 50). The PointRend deep learning mechanism segmented the mandible from CBCT images and accurately identified 27 anatomic landmarks via PoseNet. 3D coordinates of 5 central landmarks and 2 pairs of side landmarks were obtained for the test group. Every 35 combinations of 3 midline landmarks were screened using the template mapping technique. The asymmetry index (AI) was calculated for each of the 35 mirror planes. The template mapping technique plane was used as the reference plane; the top four planes with the smallest AIs were compared through distance, volume difference, and similarity index to find the plane with the fewest errors. Results The mandible was segmented automatically in 10 ± 1.5 s with a 0.98 Dice similarity coefficient. The mean landmark localization error for the 27 landmarks was 1.04 ± 0.28 mm. MMSP should use the plane made by B (supramentale), Gn (gnathion), and F (mandibular foramen). The average AI grade was 1.6 (min–max: 0.59–3.61). There was no significant difference in distance or volume ( P &gt; 0.05); however, the similarity index was significantly different ( P &lt; 0.01). Conclusion Deep learning can automatically segment the mandible, identify anatomic landmarks, and address medicinal demands in people without mandibular deformities. The most accurate MMSP was the B-Gn-F plane.","['PointRend deep learning mechanism', 'PoseNet']"
2024,https://openalex.org/W4391515422,Biology,Predicting transient wind loads on tall buildings in three-dimensional spatial coordinates using machine learning,"Machine learning (ML) as a subset of artificial intelligence (AI), has gained significant attention in wind engineering applications over the past decade. Wind load predictions for tall buildings using ML studies presented in literature have always been limited to static pressure measurements or time history measurements without considering the spatial coordinates system. To design wind-sensitive tall buildings, ML models must be capable of estimating transient wind flow quantities along with its spatial distribution. Thus, in this study, for the first time, the authors used ML to model the transient wind pressure on a tall building using a three-dimensional (3D) spatial coordinates system. A series of Boundary Layer Wind Tunnel tests were performed to obtain the transient pressure readings on building surfaces, which were used to validate the Computational Fluid Dynamics (CFD) models. Turbulence was modelled using large eddy simulations and the data obtained through CFD simulations were utilised to generate the ML models. The popular Extreme Gradient Boosting (XGBoost) model was selected as the ML model due to its capability of efficient data handling. The trained XGBoost model accurately predicted the transient wind pressure throughout the flow time. The XGBoost model has captured the extreme values well, closely following the flow patterns. In addition, special flow features like flow separation, reattachment, and steep pressure gradients have been well captured over the corresponding surfaces. Therefore, this study showcases the ability to use ML to predict pressures on tall buildings, capturing all key flow features time-efficiently.",['Extreme Gradient Boosting (XGBoost)']
2024,https://openalex.org/W4391943312,Biology,"Machine Learning and Deep Learning in Synthetic Biology: Key Architectures, Applications, and Challenges","Machine learning (ML), particularly deep learning (DL), has made rapid and substantial progress in synthetic biology in recent years. Biotechnological applications of biosystems, including pathways, enzymes, and whole cells, are being probed frequently with time. The intricacy and interconnectedness of biosystems make it challenging to design them with the desired properties. ML and DL have a synergy with synthetic biology. Synthetic biology can be employed to produce large data sets for training models (for instance, by utilizing DNA synthesis), and ML/DL models can be employed to inform design (for example, by generating new parts or advising unrivaled experiments to perform). This potential has recently been brought to light by research at the intersection of engineering biology and ML/DL through achievements like the design of novel biological components, best experimental design, automated analysis of microscopy data, protein structure prediction, and biomolecular implementations of ANNs (Artificial Neural Networks). I have divided this review into three sections. In the first section, I describe predictive potential and basics of ML along with myriad applications in synthetic biology, especially in engineering cells, activity of proteins, and metabolic pathways. In the second section, I describe fundamental DL architectures and their applications in synthetic biology. Finally, I describe different challenges causing hurdles in the progress of ML/DL and synthetic biology along with their solutions.","['machine learning (ML)', 'deep learning (DL)', 'Artificial Neural Networks (ANNs)']"
2024,https://openalex.org/W4391997375,Biology,A machine learning approach to predict the efficiency of corrosion inhibition by natural product-based organic inhibitors,"Abstract This paper presents a quantitative structure–property relationship (QSPR)-based machine learning (ML) framework designed for predicting corrosion inhibition efficiency (CIE) values in natural organic inhibitor compounds. The modeling dataset comprises 50 natural organic compounds, with 11 quantum chemical properties (QCP) serving as input features, and the target variable being the corrosion inhibition efficiency (CIE) value. To enhance the predictive accuracy of the ML model, the kernel density estimation (KDE) function is employed to generate virtual samples during the training process, with the overarching goal of refining the precision of the ML model. Three distinct models, namely random forest (RF), gradient boosting (GB), and k-nearest neighbor (KNN), are tested in the study. The results demonstrate a noteworthy enhancement in the prediction performance of the models, attributable to the incorporation of virtual samples that effectively improve the correlation between input features and target values. Consequently, the accuracy of the predicted CIE values is significantly augmented, aligning more closely with the actual CIE values. Performance improvements were evident across all models after the incorporation of virtual samples. The GB, RF, and KNN models exhibited increments in R 2 values from 0.557 to 0.996, 0.522 to 0.999, and 0.415 to 0.994, respectively, concomitant with the introduction of 500 virtual samples. Additionally, each model demonstrated a notable reduction in RMSE values, transitioning from 1.41 to 0.19, 1.27 to 0.10, and 1.22 to 0.16, respectively. While the GB model initially outperformed others before the addition of virtual samples, the performance of the model exhibited fluctuation as the number of virtual samples varied. This behavior suggests that the KDE function provides a certain level of resilience against model variations. The proposed approach contributes to the effective design and exploration of corrosion inhibitor candidates, offering a reliable and accurate predictive tool that bridges the gap between theoretical studies and experimental synthesis.","['random forest (RF)', 'gradient boosting (GB)', 'k-nearest neighbor (KNN)']"
2024,https://openalex.org/W4395037579,Biology,Assessing ChatGPT 4.0’s test performance and clinical diagnostic accuracy on USMLE STEP 2 CK and clinical case reports,"Abstract While there is data assessing the test performance of artificial intelligence (AI) chatbots, including the Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0), there is scarce data on its diagnostic accuracy of clinical cases. We assessed the large language model (LLM), ChatGPT 4.0, on its ability to answer questions from the United States Medical Licensing Exam (USMLE) Step 2, as well as its ability to generate a differential diagnosis based on corresponding clinical vignettes from published case reports. A total of 109 Step 2 Clinical Knowledge (CK) practice questions were inputted into both ChatGPT 3.5 and ChatGPT 4.0, asking ChatGPT to pick the correct answer. Compared to its previous version, ChatGPT 3.5, we found improved accuracy of ChatGPT 4.0 when answering these questions, from 47.7 to 87.2% ( p = 0.035) respectively. Utilizing the topics tested on Step 2 CK questions, we additionally found 63 corresponding published case report vignettes and asked ChatGPT 4.0 to come up with its top three differential diagnosis. ChatGPT 4.0 accurately created a shortlist of differential diagnoses in 74.6% of the 63 case reports (74.6%). We analyzed ChatGPT 4.0’s confidence in its diagnosis by asking it to rank its top three differentials from most to least likely. Out of the 47 correct diagnoses, 33 were the first (70.2%) on the differential diagnosis list, 11 were second (23.4%), and three were third (6.4%). Our study shows the continued iterative improvement in ChatGPT’s ability to answer standardized USMLE questions accurately and provides insights into ChatGPT’s clinical diagnostic accuracy.","['Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0)', 'large language model (LLM)']"
2024,https://openalex.org/W4390501772,Biology,Remote sensing based forest cover classification using machine learning,"Abstract Pakistan falls significantly below the recommended forest coverage level of 20 to 30 percent of total area, with less than 6 percent of its land under forest cover. This deficiency is primarily attributed to illicit deforestation for wood and charcoal, coupled with a failure to embrace advanced techniques for forest estimation, monitoring, and supervision. Remote sensing techniques leveraging Sentinel-2 satellite images were employed. Both single-layer stacked images and temporal layer stacked images from various dates were utilized for forest classification. The application of an artificial neural network (ANN) supervised classification algorithm yielded notable results. Using a single-layer stacked image from Sentinel-2, an impressive 91.37% training overall accuracy and 0.865 kappa coefficient were achieved, along with 93.77% testing overall accuracy and a 0.902 kappa coefficient. Furthermore, the temporal layer stacked image approach demonstrated even better results. This method yielded 98.07% overall training accuracy, 97.75% overall testing accuracy, and kappa coefficients of 0.970 and 0.965, respectively. The random forest (RF) algorithm, when applied, achieved 99.12% overall training accuracy, 92.90% testing accuracy, and kappa coefficients of 0.986 and 0.882. Notably, with the temporal layer stacked image of the Sentinel-2 satellite, the RF algorithm reached exceptional performance with 99.79% training accuracy, 96.98% validation accuracy, and kappa coefficients of 0.996 and 0.954. In terms of forest cover estimation, the ANN algorithm identified 31.07% total forest coverage in the District Abbottabad region. In comparison, the RF algorithm recorded a slightly higher 31.17% of the total forested area. This research highlights the potential of advanced remote sensing techniques and machine learning algorithms in improving forest cover assessment and monitoring strategies.","['artificial neural network (ANN) supervised classification algorithm', 'random forest (RF) algorithm']"
2024,https://openalex.org/W4390660406,Biology,Improving River Routing Using a Differentiable Muskingum‐Cunge Model and Physics‐Informed Machine Learning,"Abstract Recently, rainfall‐runoff simulations in small headwater basins have been improved by methodological advances such as deep neural networks (NNs) and hybrid physics‐NN models—particularly, a genre called differentiable modeling that intermingles NNs with physics to learn relationships between variables. However, hydrologic routing simulations, necessary for simulating floods in stem rivers downstream of large heterogeneous basins, had not yet benefited from these advances and it was unclear if the routing process could be improved via coupled NNs. We present a novel differentiable routing method ( δ MC‐Juniata‐hydroDL2) that mimics the classical Muskingum‐Cunge routing model over a river network but embeds an NN to infer parameterizations for Manning's roughness ( n ) and channel geometries from raw reach‐scale attributes like catchment areas and sinuosity. The NN was trained solely on downstream hydrographs. Synthetic experiments show that while the channel geometry parameter was unidentifiable, n can be identified with moderate precision. With real‐world data, the trained differentiable routing model produced more accurate long‐term routing results for both the training gage and untrained inner gages for larger subbasins (&gt;2,000 km 2 ) than either a machine learning model assuming homogeneity, or simply using the sum of runoff from subbasins. The n parameterization trained on short periods gave high performance in other periods, despite significant errors in runoff inputs. The learned n pattern was consistent with literature expectations, demonstrating the framework's potential for knowledge discovery, but the absolute values can vary depending on training periods. The trained n parameterization can be coupled with traditional models to improve national‐scale hydrologic flood simulations.","['deep neural networks (NNs)', 'hybrid physics‐NN models', 'differentiable modeling']"
2024,https://openalex.org/W4390954471,Biology,Traffic Sign Detection and Recognition Using YOLO Object Detection Algorithm: A Systematic Review,"Context: YOLO (You Look Only Once) is an algorithm based on deep neural networks with real-time object detection capabilities. This state-of-the-art technology is widely available, mainly due to its speed and precision. Since its conception, YOLO has been applied to detect and recognize traffic signs, pedestrians, traffic lights, vehicles, and so on. Objective: The goal of this research is to systematically analyze the YOLO object detection algorithm, applied to traffic sign detection and recognition systems, from five relevant aspects of this technology: applications, datasets, metrics, hardware, and challenges. Method: This study performs a systematic literature review (SLR) of studies on traffic sign detection and recognition using YOLO published in the years 2016–2022. Results: The search found 115 primary studies relevant to the goal of this research. After analyzing these investigations, the following relevant results were obtained. The most common applications of YOLO in this field are vehicular security and intelligent and autonomous vehicles. The majority of the sign datasets used to train, test, and validate YOLO-based systems are publicly available, with an emphasis on datasets from Germany and China. It has also been discovered that most works present sophisticated detection, classification, and processing speed metrics for traffic sign detection and recognition systems by using the different versions of YOLO. In addition, the most popular desktop data processing hardwares are Nvidia RTX 2080 and Titan Tesla V100 and, in the case of embedded or mobile GPU platforms, Jetson Xavier NX. Finally, seven relevant challenges that these systems face when operating in real road conditions have been identified. With this in mind, research has been reclassified to address these challenges in each case. Conclusions: This SLR is the most relevant and current work in the field of technology development applied to the detection and recognition of traffic signs using YOLO. In addition, insights are provided about future work that could be conducted to improve the field.",['YOLO (You Only Look Once)']
2024,https://openalex.org/W4392015292,Biology,Avoiding fusion plasma tearing instability with deep reinforcement learning,"Abstract For stable and efficient fusion energy production using a tokamak reactor, it is essential to maintain a high-pressure hydrogenic plasma without plasma disruption. Therefore, it is necessary to actively control the tokamak based on the observed plasma state, to manoeuvre high-pressure plasma while avoiding tearing instability, the leading cause of disruptions. This presents an obstacle-avoidance problem for which artificial intelligence based on reinforcement learning has recently shown remarkable performance 1–4 . However, the obstacle here, the tearing instability, is difficult to forecast and is highly prone to terminating plasma operations, especially in the ITER baseline scenario. Previously, we developed a multimodal dynamic model that estimates the likelihood of future tearing instability based on signals from multiple diagnostics and actuators 5 . Here we harness this dynamic model as a training environment for reinforcement-learning artificial intelligence, facilitating automated instability prevention. We demonstrate artificial intelligence control to lower the possibility of disruptive tearing instabilities in DIII-D 6 , the largest magnetic fusion facility in the United States. The controller maintained the tearing likelihood under a given threshold, even under relatively unfavourable conditions of low safety factor and low torque. In particular, it allowed the plasma to actively track the stable path within the time-varying operational space while maintaining H-mode performance, which was challenging with traditional preprogrammed control. This controller paves the path to developing stable high-performance operational scenarios for future use in ITER.",['reinforcement learning']
2024,https://openalex.org/W4393094733,Biology,Advancing entity recognition in biomedicine via instruction tuning of large language models,"Abstract Motivation Large Language Models (LLMs) have the potential to revolutionize the field of Natural Language Processing, excelling not only in text generation and reasoning tasks but also in their ability for zero/few-shot learning, swiftly adapting to new tasks with minimal fine-tuning. LLMs have also demonstrated great promise in biomedical and healthcare applications. However, when it comes to Named Entity Recognition (NER), particularly within the biomedical domain, LLMs fall short of the effectiveness exhibited by fine-tuned domain-specific models. One key reason is that NER is typically conceptualized as a sequence labeling task, whereas LLMs are optimized for text generation and reasoning tasks. Results We developed an instruction-based learning paradigm that transforms biomedical NER from a sequence labeling task into a generation task. This paradigm is end-to-end and streamlines the training and evaluation process by automatically repurposing pre-existing biomedical NER datasets. We further developed BioNER-LLaMA using the proposed paradigm with LLaMA-7B as the foundational LLM. We conducted extensive testing on BioNER-LLaMA across three widely recognized biomedical NER datasets, consisting of entities related to diseases, chemicals, and genes. The results revealed that BioNER-LLaMA consistently achieved higher F1-scores ranging from 5% to 30% compared to the few-shot learning capabilities of GPT-4 on datasets with different biomedical entities. We show that a general-domain LLM can match the performance of rigorously fine-tuned PubMedBERT models and PMC-LLaMA, biomedical-specific language model. Our findings underscore the potential of our proposed paradigm in developing general-domain LLMs that can rival SOTA performances in multi-task, multi-domain scenarios in biomedical and health applications. Availability and implementation Datasets and other resources are available at https://github.com/BIDS-Xu-Lab/BioNER-LLaMA.","['few-shot learning', 'LLaMA-7B', 'GPT-4 few-shot learning', 'PubMedBERT fine-tuning']"
2024,https://openalex.org/W4393306481,Biology,Reliable water quality prediction and parametric analysis using explainable AI models,"Abstract The consumption of water constitutes the physical health of most of the living species and hence management of its purity and quality is extremely essential as contaminated water has to potential to create adverse health and environmental consequences. This creates the dire necessity to measure, control and monitor the quality of water. The primary contaminant present in water is Total Dissolved Solids (TDS), which is hard to filter out. There are various substances apart from mere solids such as potassium, sodium, chlorides, lead, nitrate, cadmium, arsenic and other pollutants. The proposed work aims to provide the automation of water quality estimation through Artificial Intelligence and uses Explainable Artificial Intelligence (XAI) for the explanation of the most significant parameters contributing towards the potability of water and the estimation of the impurities. XAI has the transparency and justifiability as a white-box model since the Machine Learning (ML) model is black-box and unable to describe the reasoning behind the ML classification. The proposed work uses various ML models such as Logistic Regression, Support Vector Machine (SVM), Gaussian Naive Bayes, Decision Tree (DT) and Random Forest (RF) to classify whether the water is drinkable. The various representations of XAI such as force plot, test patch, summary plot, dependency plot and decision plot generated in SHAPELY explainer explain the significant features, prediction score, feature importance and justification behind the water quality estimation. The RF classifier is selected for the explanation and yields optimum Accuracy and F1-Score of 0.9999, with Precision and Re-call of 0.9997 and 0.998 respectively. Thus, the work is an exploratory analysis of the estimation and management of water quality with indicators associated with their significance. This work is an emerging research at present with a vision of addressing the water quality for the future as well.","['Logistic Regression', 'Support Vector Machine (SVM)', 'Gaussian Naive Bayes', 'Decision Tree (DT)', 'Random Forest (RF)']"
2024,https://openalex.org/W4399319394,Biology,Multi-task aquatic toxicity prediction model based on multi-level features fusion,"With the escalating menace of organic compounds in environmental pollution imperiling the survival of aquatic organisms, the investigation of organic compound toxicity across diverse aquatic species assumes paramount significance for environmental protection. Understanding how different species respond to these compounds helps assess the potential ecological impact of pollution on aquatic ecosystems as a whole. Compared with traditional experimental methods, deep learning methods have higher accuracy in predicting aquatic toxicity, faster data processing speed and better generalization ability. This article presents ATFPGT-multi, an advanced multi-task deep neural network prediction model for organic toxicity. The model integrates molecular fingerprints and molecule graphs to characterize molecules, enabling the simultaneous prediction of acute toxicity for the same organic compound across four distinct fish species. Furthermore, to validate the advantages of multi-task learning, we independently construct prediction models, named ATFPGT-single, for each fish species. We employ cross-validation in our experiments to assess the performance and generalization ability of ATFPGT-multi. The experimental results indicate, first, that ATFPGT-multi outperforms ATFPGT-single on four fish datasets with AUC improvements of 9.8%, 4%, 4.8%, and 8.2%, respectively, demonstrating the superiority of multi-task learning over single-task learning. Furthermore, in comparison with previous algorithms, ATFPGT-multi outperforms comparative methods, emphasizing that our approach exhibits higher accuracy and reliability in predicting aquatic toxicity. Moreover, ATFPGT-multi utilizes attention scores to identify molecular fragments associated with fish toxicity in organic molecules, as demonstrated by two organic molecule examples in the main text, demonstrating the interpretability of ATFPGT-multi. In summary, ATFPGT-multi provides important support and reference for the further development of aquatic toxicity assessment. All of codes and datasets are freely available online at https://github.com/zhaoqi106/ATFPGT-multi.","['deep learning methods', 'multi-task deep neural network prediction model', 'multi-task learning', 'single-task learning']"
2024,https://openalex.org/W4391321561,Biology,A survey on training challenges in generative adversarial networks for biomedical image analysis,"Abstract In biomedical image analysis, the applicability of deep learning methods is directly impacted by the quantity of image data available. This is due to deep learning models requiring large image datasets to provide high-level performance. Generative Adversarial Networks (GANs) have been widely utilized to address data limitations through the generation of synthetic biomedical images. GANs consist of two models. The generator, a model that learns how to produce synthetic images based on the feedback it receives. The discriminator, a model that classifies an image as synthetic or real and provides feedback to the generator. Throughout the training process, a GAN can experience several technical challenges that impede the generation of suitable synthetic imagery. First, the mode collapse problem whereby the generator either produces an identical image or produces a uniform image from distinct input features. Second, the non-convergence problem whereby the gradient descent optimizer fails to reach a Nash equilibrium. Thirdly, the vanishing gradient problem whereby unstable training behavior occurs due to the discriminator achieving optimal classification performance resulting in no meaningful feedback being provided to the generator. These problems result in the production of synthetic imagery that is blurry, unrealistic, and less diverse. To date, there has been no survey article outlining the impact of these technical challenges in the context of the biomedical imagery domain. This work presents a review and taxonomy based on solutions to the training problems of GANs in the biomedical imaging domain. This survey highlights important challenges and outlines future research directions about the training of GANs in the domain of biomedical imagery.","['deep learning', 'Generative Adversarial Networks (GANs)', 'discriminator', 'gradient descent optimizer']"
2024,https://openalex.org/W4392791588,Psychology,Can large language models replace humans in systematic reviews? Evaluating <scp>GPT</scp>‐4's efficacy in screening and extracting data from peer‐reviewed and grey literature in multiple languages,"Systematic reviews are vital for guiding practice, research and policy, although they are often slow and labour-intensive. Large language models (LLMs) could speed up and automate systematic reviews, but their performance in such tasks has yet to be comprehensively evaluated against humans, and no study has tested Generative Pre-Trained Transformer (GPT)-4, the biggest LLM so far. This pre-registered study uses a ""human-out-of-the-loop"" approach to evaluate GPT-4's capability in title/abstract screening, full-text review and data extraction across various literature types and languages. Although GPT-4 had accuracy on par with human performance in some tasks, results were skewed by chance agreement and dataset imbalance. Adjusting for these caused performance scores to drop across all stages: for data extraction, performance was moderate, and for screening, it ranged from none in highly balanced literature datasets (~1:1) to moderate in those datasets where the ratio of inclusion to exclusion in studies was imbalanced (~1:3). When screening full-text literature using highly reliable prompts, GPT-4's performance was more robust, reaching ""human-like"" levels. Although our findings indicate that, currently, substantial caution should be exercised if LLMs are being used to conduct systematic reviews, they also offer preliminary evidence that, for certain review tasks delivered under specific conditions, LLMs can rival human performance.",['Generative Pre-Trained Transformer (GPT)-4']
2024,https://openalex.org/W4394884079,Psychology,TRANSFORMING FINTECH FRAUD DETECTION WITH ADVANCED ARTIFICIAL INTELLIGENCE ALGORITHMS,"The rapid evolution of financial technology (fintech) platforms has exponentially increased the volume and sophistication of financial transactions, concurrently elevating the risk and complexity of fraudulent activities. This necessitates a paradigm shift in fraud detection methodologies towards more agile, accurate, and predictive solutions. This paper presents a comprehensive study on the transformative potential of advanced Artificial Intelligence (AI) algorithms in enhancing fintech fraud detection mechanisms. By leveraging cutting-edge AI techniques including deep learning, machine learning, and natural language processing, this research aims to develop a robust fraud detection framework capable of identifying, analyzing, and preventing fraudulent transactions in real-time.&#x0D; Our methodology encompasses the deployment of several AI algorithms on extensive datasets comprising genuine and fraudulent financial transactions. Through a comparative analysis, we identify the most effective algorithms in terms of accuracy, efficiency, and scalability. Key findings reveal that deep learning models, particularly those employing neural networks, outperform traditional machine learning models in detecting complex and nuanced fraudulent activities. Furthermore, the integration of natural language processing enables the extraction and analysis of unstructured data, significantly enhancing the detection capabilities.&#x0D; Conclusively, this paper underscores the critical role of advanced AI algorithms in revolutionizing fintech fraud detection. It highlights the superior performance of AI-based models over conventional methods, offering fintech platforms a more dynamic and predictive approach to fraud prevention. This research not only contributes to the academic discourse on financial security but also provides practical insights for fintech companies striving to safeguard their operations against fraud.&#x0D; Keywords: Artificial Intelligence, Fintech, Fraud Detection, Ethical Ai, Regulatory Compliance, Data Privacy, Algorithmic Bias, Predictive Analytics, Blockchain Technology, Quantum Computing, Interdisciplinary Collaboration, Innovation, Transparency, Accountability, Continuous Learning, Ethical Principles, Real-Time Processing, Financial Sector.","['deep learning', 'machine learning', 'neural networks']"
2024,https://openalex.org/W4392202731,Psychology,Applying large language models and chain-of-thought for automatic scoring,"This study investigates the application of large language models (LLMs), specifically GPT-3.5 and GPT-4, with Chain-of-Though (CoT) in the automatic scoring of student-written responses to science assessments. We focused on overcoming the challenges of accessibility, technical complexity, and lack of explainability that have previously limited the use of artificial intelligence-based automatic scoring tools among researchers and educators. With a testing dataset comprising six assessment tasks (three binomial and three trinomial) with 1650 student responses, we employed six prompt engineering strategies to automatically score student responses. The six strategies combined zero-shot or few-shot learning with CoT, either alone or alongside item stem and scoring rubrics, developed based on a novel approach, WRVRT (prompt writing, reviewing, validating, revising, and testing). Results indicated that few-shot (acc = 0.67) outperformed zero-shot learning (acc = 0.60), with 12.6% increase. CoT, when used without item stem and scoring rubrics, did not significantly affect scoring accuracy (acc = 0.60). However, CoT prompting paired with contextual item stems and rubrics proved to be a significant contributor to scoring accuracy (13.44% increase for zero-shot; 3.7% increase for few-shot). We found a more balanced accuracy across different proficiency categories when CoT was used with a scoring rubric, highlighting the importance of domain-specific reasoning in enhancing the effectiveness of LLMs in scoring tasks. We also found that GPT-4 demonstrated superior performance over GPT -3.5 in various scoring tasks when combined with the single-call greedy sampling or ensemble voting nucleus sampling strategy, showing 8.64% difference. Particularly, the single-call greedy sampling strategy with GPT-4 outperformed other approaches. This study also demonstrates the potential of LLMs in facilitating explainable and interpretable automatic scoring, emphasizing that CoT enhances accuracy and transparency, particularly when used with item stem and scoring rubrics.","['GPT-3.5', 'GPT-4', 'Chain-of-Thought (CoT)', 'zero-shot learning', 'few-shot learning']"
2024,https://openalex.org/W4391103530,Psychology,Transformative Breast Cancer Diagnosis using CNNs with Optimized ReduceLROnPlateau and Early Stopping Enhancements,"Abstract Breast cancer stands as a paramount public health concern worldwide, underscoring an imperative necessity within the research sphere for precision-driven and efficacious methodologies facilitating accurate detection. The existing diagnostic approaches in breast cancer often suffer from limitations in accuracy and efficiency, leading to delayed detection and subsequent challenges in personalized treatment planning. The primary focus of this research is to overcome these shortcomings by harnessing the power of advanced deep learning techniques, thereby revolutionizing the precision and reliability of breast cancer classification. This research addresses the critical need for improved breast cancer diagnostics by introducing a novel Convolutional Neural Network (CNN) model integrated with an Early Stopping callback and ReduceLROnPlateau callback. By enhancing the precision and reliability of breast cancer classification, the study aims to overcome the limitations of existing diagnostic methods, ultimately leading to better patient outcomes and reduced mortality rates. The comprehensive methodology includes diverse datasets, meticulous image preprocessing, robust model training, and validation strategies, emphasizing the model's adaptability and reliability in varied clinical contexts. The findings showcase the CNN model's exceptional performance, achieving a 95.2% accuracy rate in distinguishing cancerous and non-cancerous breast tissue in the integrated dataset, thereby demonstrating its potential for enhancing clinical decision-making and fostering the development of AI-driven diagnostic solutions.","['Convolutional Neural Network (CNN)', 'Early Stopping callback']"
2024,https://openalex.org/W4402780379,Psychology,Investigating Spatial Effects through Machine Learning and Leveraging Explainable AI for Child Malnutrition in Pakistan,"While socioeconomic gradients in regional health inequalities are firmly established, the synergistic interactions between socioeconomic deprivation and climate vulnerability within convenient proximity and neighbourhood locations with health disparities remain poorly explored and thus require deep understanding within a regional context. Furthermore, disregarding the importance of spatial spillover effects and nonlinear effects of covariates on childhood stunting are inevitable in dealing with an enduring issue of regional health inequalities. The present study aims to investigate the spatial inequalities in childhood stunting at the district level in Pakistan and validate the importance of spatial lag in predicting childhood stunting. Furthermore, it examines the presence of any nonlinear relationships among the selected independent features with childhood stunting. The study utilized data related to socioeconomic features from MICS 2017–2018 and climatic data from Integrated Contextual Analysis. A multi-model approach was employed to address the research questions, which included Ordinary Least Squares Regression (OLS), various Spatial Models, Machine Learning Algorithms and Explainable Artificial Intelligence methods. Firstly, OLS was used to analyse and test the linear relationships among selected variables. Secondly, Spatial Durbin Error Model (SDEM) was used to detect and capture the impact of spatial spillover on childhood stunting. Third, XGBoost and Random Forest machine learning algorithms were employed to examine and validate the importance of the spatial lag component. Finally, EXAI methods such as SHapley were utilized to identify potential nonlinear relationships. The study found a clear pattern of spatial clustering and geographical disparities in childhood stunting, with multidimensional poverty, high climate vulnerability and early marriage worsening childhood stunting. In contrast, low climate vulnerability, high exposure to mass media and high women’s literacy were found to reduce childhood stunting. The use of machine learning algorithms, specifically XGBoost and Random Forest, highlighted the significant role played by the average value in the neighbourhood in predicting childhood stunting in nearby districts, confirming that the spatial spillover effect is not bounded by geographical boundaries. Furthermore, EXAI methods such as partial dependency plot reveal the existence of a nonlinear relationship between multidimensional poverty and childhood stunting. The study’s findings provide valuable insights into the spatial distribution of childhood stunting in Pakistan, emphasizing the importance of considering spatial effects in predicting childhood stunting. Individual and household-level factors such as exposure to mass media and women’s literacy have shown positive implications for childhood stunting. It further provides a justification for the usage of EXAI methods to draw better insights and propose customised intervention policies accordingly.","['XGBoost', 'Random Forest', 'partial dependency plot']"
2024,https://openalex.org/W4390659289,Psychology,Cognition-Driven Structural Prior for Instance-Dependent Label Transition Matrix Estimation,"The label transition matrix has emerged as a widely accepted method for mitigating label noise in machine learning. In recent years, numerous studies have centered on leveraging deep neural networks to estimate the label transition matrix for individual instances within the context of instance-dependent noise. However, these methods suffer from low search efficiency due to the large space of feasible solutions. Behind this drawback, we have explored that the real murderer lies in the invalid class transitions, that is, the actual transition probability between certain classes is zero but is estimated to have a certain value. To mask the <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">invalid class transitions</i> , we introduced a human-cognition-assisted method with structural information from human cognition. Specifically, we introduce a structured transition matrix network ( <bold xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">STMN</b> ) designed with an adversarial learning process to balance instance features and prior information from human cognition. The proposed method offers two advantages: 1) better estimation effectiveness is obtained by sparing the transition matrix and 2) better estimation accuracy is obtained with the assistance of human cognition. By exploiting these two advantages, our method parametrically estimates a sparse label transition matrix, effectively converting noisy labels into true labels. The efficiency and superiority of our proposed method are substantiated through comprehensive comparisons with state-of-the-art methods on three synthetic datasets and a real-world dataset. Our code will be available at https://github.com/WheatCao/STMN-Pytorch.","['deep neural networks', 'adversarial learning process']"
2024,https://openalex.org/W4391107516,Psychology,Multiple Classification of Brain MRI Autism Spectrum Disorder by Age and Gender Using Deep Learning,"Abstract The fact that the rapid and definitive diagnosis of autism cannot be made today and that autism cannot be treated provides an impetus to look into novel technological solutions. To contribute to the resolution of this problem through multiple classifications by considering age and gender factors, in this study, two quadruple and one octal classifications were performed using a deep learning (DL) approach. Gender in one of the four classifications and age groups in the other were considered. In the octal classification, classes were created considering gender and age groups. In addition to the diagnosis of ASD (Autism Spectrum Disorders), another goal of this study is to find out the contribution of gender and age factors to the diagnosis of ASD by making multiple classifications based on age and gender for the first time. Brain structural MRI (sMRI) scans of participators with ASD and TD (Typical Development) were pre-processed in the system originally designed for this purpose. Using the Canny Edge Detection (CED) algorithm, the sMRI image data was cropped in the data pre-processing stage, and the data set was enlarged five times with the data augmentation (DA) techniques. The most optimal convolutional neural network (CNN) models were developed using the grid search optimization (GSO) algorism. The proposed DL prediction system was tested with the five-fold cross-validation technique. Three CNN models were designed to be used in the system. The first of these models is the quadruple classification model created by taking gender into account (model 1), the second is the quadruple classification model created by taking into account age (model 2), and the third is the eightfold classification model created by taking into account both gender and age (model 3). ). The accuracy rates obtained for all three designed models are 80.94, 85.42 and 67.94, respectively. These obtained accuracy rates were compared with pre-trained models by using the transfer learning approach. As a result, it was revealed that age and gender factors were effective in the diagnosis of ASD with the system developed for ASD multiple classifications, and higher accuracy rates were achieved compared to pre-trained models.","['convolutional neural network (CNN) models', 'transfer learning approach']"
2024,https://openalex.org/W4400461591,Psychology,Counterfactual Explanations and Algorithmic Recourses for Machine Learning: A Review,"Machine learning plays a role in many deployed decision systems, often in ways that are difficult or impossible to understand by human stakeholders. Explaining, in a human-understandable way, the relationship between the input and output of machine learning models is essential to the development of trustworthy machine learning based systems. A burgeoning body of research seeks to define the goals and methods of explainability in machine learning. In this article, we seek to review and categorize research on counterfactual explanations , a specific class of explanation that provides a link between what could have happened had input to a model been changed in a particular way. Modern approaches to counterfactual explainability in machine learning draw connections to the established legal doctrine in many countries, making them appealing to fielded systems in high-impact areas such as finance and healthcare. Thus, we design a rubric with desirable properties of counterfactual explanation algorithms and comprehensively evaluate all currently proposed algorithms against that rubric. Our rubric provides easy comparison and comprehension of the advantages and disadvantages of different approaches and serves as an introduction to major research themes in this field. We also identify gaps and discuss promising research directions in the space of counterfactual explainability.","['counterfactual explanations', 'counterfactual explanation algorithms']"
2024,https://openalex.org/W4391531220,Psychology,An Explainable AI Paradigm for Alzheimer’s Diagnosis Using Deep Transfer Learning,"Alzheimer’s disease (AD) is a progressive neurodegenerative disorder that affects millions of individuals worldwide, causing severe cognitive decline and memory impairment. The early and accurate diagnosis of AD is crucial for effective intervention and disease management. In recent years, deep learning techniques have shown promising results in medical image analysis, including AD diagnosis from neuroimaging data. However, the lack of interpretability in deep learning models hinders their adoption in clinical settings, where explainability is essential for gaining trust and acceptance from healthcare professionals. In this study, we propose an explainable AI (XAI)-based approach for the diagnosis of Alzheimer’s disease, leveraging the power of deep transfer learning and ensemble modeling. The proposed framework aims to enhance the interpretability of deep learning models by incorporating XAI techniques, allowing clinicians to understand the decision-making process and providing valuable insights into disease diagnosis. By leveraging popular pre-trained convolutional neural networks (CNNs) such as VGG16, VGG19, DenseNet169, and DenseNet201, we conducted extensive experiments to evaluate their individual performances on a comprehensive dataset. The proposed ensembles, Ensemble-1 (VGG16 and VGG19) and Ensemble-2 (DenseNet169 and DenseNet201), demonstrated superior accuracy, precision, recall, and F1 scores compared to individual models, reaching up to 95%. In order to enhance interpretability and transparency in Alzheimer’s diagnosis, we introduced a novel model achieving an impressive accuracy of 96%. This model incorporates explainable AI techniques, including saliency maps and grad-CAM (gradient-weighted class activation mapping). The integration of these techniques not only contributes to the model’s exceptional accuracy but also provides clinicians and researchers with visual insights into the neural regions influencing the diagnosis. Our findings showcase the potential of combining deep transfer learning with explainable AI in the realm of Alzheimer’s disease diagnosis, paving the way for more interpretable and clinically relevant AI models in healthcare.","['deep learning', 'explainable AI (XAI)', 'deep transfer learning', 'ensemble modeling', 'pre-trained convolutional neural networks (CNNs)', 'VGG16', 'VGG19', 'DenseNet169', 'DenseNet201', 'saliency maps', 'grad-CAM (gradient-weighted class activation mapping)']"
2024,https://openalex.org/W4402827393,Psychology,Larger and more instructable language models become less reliable,"Abstract The prevailing methods to make large language models more powerful and amenable have been based on continuous scaling up (that is, increasing their size, data volume and computational resources 1 ) and bespoke shaping up (including post-filtering 2,3 , fine tuning or use of human feedback 4,5 ). However, larger and more instructable large language models may have become less reliable. By studying the relationship between difficulty concordance, task avoidance and prompting stability of several language model families, here we show that easy instances for human participants are also easy for the models, but scaled-up, shaped-up models do not secure areas of low difficulty in which either the model does not err or human supervision can spot the errors. We also find that early models often avoid user questions but scaled-up, shaped-up models tend to give an apparently sensible yet wrong answer much more often, including errors on difficult questions that human supervisors frequently overlook. Moreover, we observe that stability to different natural phrasings of the same question is improved by scaling-up and shaping-up interventions, but pockets of variability persist across difficulty levels. These findings highlight the need for a fundamental shift in the design and development of general-purpose artificial intelligence, particularly in high-stakes areas for which a predictable distribution of errors is paramount.","['post-filtering', 'fine tuning', 'use of human feedback']"
2024,https://openalex.org/W4391126287,Psychology,Evaluating the ChatGPT family of models for biomedical reasoning and classification,"Abstract Objective Large language models (LLMs) have shown impressive ability in biomedical question-answering, but have not been adequately investigated for more specific biomedical applications. This study investigates ChatGPT family of models (GPT-3.5, GPT-4) in biomedical tasks beyond question-answering. Materials and Methods We evaluated model performance with 11 122 samples for two fundamental tasks in the biomedical domain—classification (n = 8676) and reasoning (n = 2446). The first task involves classifying health advice in scientific literature, while the second task is detecting causal relations in biomedical literature. We used 20% of the dataset for prompt development, including zero- and few-shot settings with and without chain-of-thought (CoT). We then evaluated the best prompts from each setting on the remaining dataset, comparing them to models using simple features (BoW with logistic regression) and fine-tuned BioBERT models. Results Fine-tuning BioBERT produced the best classification (F1: 0.800-0.902) and reasoning (F1: 0.851) results. Among LLM approaches, few-shot CoT achieved the best classification (F1: 0.671-0.770) and reasoning (F1: 0.682) results, comparable to the BoW model (F1: 0.602-0.753 and 0.675 for classification and reasoning, respectively). It took 78 h to obtain the best LLM results, compared to 0.078 and 0.008 h for the top-performing BioBERT and BoW models, respectively. Discussion The simple BoW model performed similarly to the most complex LLM prompting. Prompt engineering required significant investment. Conclusion Despite the excitement around viral ChatGPT, fine-tuning for two fundamental biomedical natural language processing tasks remained the best strategy.","['ChatGPT family of models (GPT-3.5, GPT-4)', 'zero-shot prompting', 'few-shot prompting', 'chain-of-thought (CoT) prompting', 'Bag of Words (BoW) with logistic regression', 'fine-tuned BioBERT models']"
2024,https://openalex.org/W4392285688,Psychology,Machine Learning and Digital Biomarkers Can Detect Early Stages of Neurodegenerative Diseases,"Neurodegenerative diseases (NDs) such as Alzheimer’s Disease (AD) and Parkinson’s Disease (PD) are devastating conditions that can develop without noticeable symptoms, causing irreversible damage to neurons before any signs become clinically evident. NDs are a major cause of disability and mortality worldwide. Currently, there are no cures or treatments to halt their progression. Therefore, the development of early detection methods is urgently needed to delay neuronal loss as soon as possible. Despite advancements in Medtech, the early diagnosis of NDs remains a challenge at the intersection of medical, IT, and regulatory fields. Thus, this review explores “digital biomarkers” (tools designed for remote neurocognitive data collection and AI analysis) as a potential solution. The review summarizes that recent studies combining AI with digital biomarkers suggest the possibility of identifying pre-symptomatic indicators of NDs. For instance, research utilizing convolutional neural networks for eye tracking has achieved significant diagnostic accuracies. ROC-AUC scores reached up to 0.88, indicating high model performance in differentiating between PD patients and healthy controls. Similarly, advancements in facial expression analysis through tools have demonstrated significant potential in detecting emotional changes in ND patients, with some models reaching an accuracy of 0.89 and a precision of 0.85. This review follows a structured approach to article selection, starting with a comprehensive database search and culminating in a rigorous quality assessment and meaning for NDs of the different methods. The process is visualized in 10 tables with 54 parameters describing different approaches and their consequences for understanding various mechanisms in ND changes. However, these methods also face challenges related to data accuracy and privacy concerns. To address these issues, this review proposes strategies that emphasize the need for rigorous validation and rapid integration into clinical practice. Such integration could transform ND diagnostics, making early detection tools more cost-effective and globally accessible. In conclusion, this review underscores the urgent need to incorporate validated digital health tools into mainstream medical practice. This integration could indicate a new era in the early diagnosis of neurodegenerative diseases, potentially altering the trajectory of these conditions for millions worldwide. Thus, by highlighting specific and statistically significant findings, this review demonstrates the current progress in this field and the potential impact of these advancements on the global management of NDs.",['convolutional neural networks']
2024,https://openalex.org/W4390987311,Psychology,Reliability of ChatGPT for performing triage task in the emergency department using the Korean Triage and Acuity Scale,"Background Artificial intelligence (AI) technology can enable more efficient decision-making in healthcare settings. There is a growing interest in improving the speed and accuracy of AI systems in providing responses for given tasks in healthcare settings. Objective This study aimed to assess the reliability of ChatGPT in determining emergency department (ED) triage accuracy using the Korean Triage and Acuity Scale (KTAS). Methods Two hundred and two virtual patient cases were built. The gold standard triage classification for each case was established by an experienced ED physician. Three other human raters (ED paramedics) were involved and rated the virtual cases individually. The virtual cases were also rated by two different versions of the chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0). Inter-rater reliability was examined using Fleiss’ kappa and intra-class correlation coefficient (ICC). Results The kappa values for the agreement between the four human raters and ChatGPTs were .523 (version 4.0) and .320 (version 3.5). Of the five levels, the performance was poor when rating patients at levels 1 and 5, as well as case scenarios with additional text descriptions. There were differences in the accuracy of the different versions of GPTs. The ICC between version 3.5 and the gold standard was .520, and that between version 4.0 and the gold standard was .802. Conclusions A substantial level of inter-rater reliability was revealed when GPTs were used as KTAS raters. The current study showed the potential of using GPT in emergency healthcare settings. Considering the shortage of experienced manpower, this AI method may help improve triaging accuracy.","['chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0)']"
2024,https://openalex.org/W4391573023,Psychology,Deep Reinforcement Learning Unleashing the Power of AI in Decision-Making,"Deep Reinforcement Learning (DRL) has emerged as a transformative paradigm in the field of artificial intelligence (AI), offering unprecedented capabilities in decision-making across diverse domains. This article explores the profound impact of DRL on enhancing the decision-making capabilities of AI systems, elucidating its underlying principles, applications, and implications.DRL represents a fusion of deep learning and reinforcement learning, enabling machines to learn complex behaviors and make decisions by interacting with their environment. The utilization of neural networks allows DRL algorithms to handle high-dimensional input spaces, making it well-suited for tasks that involve intricate decision-making processes.One of the key strengths of DRL lies in its ability to address problems with sparse and delayed rewards, common challenges in traditional reinforcement learning. Through a process of trial and error, DRL algorithms can learn optimal decision strategies by navigating through a vast decision space, adapting to dynamic environments, and maximizing cumulative rewards over time.The applications of DRL span various domains, including robotics, finance, healthcare, gaming, and autonomous systems. In robotics, DRL facilitates the development of intelligent agents capable of autonomously navigating complex environments, performing intricate tasks, and adapting to unforeseen circumstances. In finance, DRL is leveraged for portfolio optimization, algorithmic trading, and risk management, demonstrating its potential to revolutionize traditional financial strategies.","['Deep Reinforcement Learning (DRL)', 'deep learning', 'reinforcement learning']"
2024,https://openalex.org/W4396712983,Psychology,3WC-GBNRS++: A novel three-way classifier with granular-ball neighborhood rough sets based on uncertainty,"Three-way decision with neighborhood rough sets (3WDNRS) is adept at addressing uncertain problems involving continuous data by configuring the neighborhood radius. However, on one hand, the inputs of 3WDNRS are individual neighborhood granules, which reduce the decision efficiency and generality; on other hand, the thresholds of 3WDNRS require prior knowledge to be approximately set in advance, making it difficult to apply in cases where such knowledge is unavailable. To address these issues, we introduce granular-ball computing (GBC) into 3WDNRS from the perspective of uncertainty. Firstly, we propose an enhanced granular-ball generation method based on DBSCAN called DBGBC. Subsequently, we present an improved granular-ball neighborhood rough sets model (GBNRS++) by combining DBGBC with a quality index. Furthermore, we construct a three-way classifier with granular-ball neighborhood rough sets (3WC-GBNRS++) based on the principle of minimum fuzziness loss. This approach provides an objective and efficient way to determine the thresholds. To further enhance classification accuracy, we design an adaptive granular-ball neighborhood within the subsequent classification process of 3WC-GBNRS++. Finally, experimental results demonstrate that, 3WC-GBNRS++ almost outperformed other comparison methods in terms of effectiveness and robustness, including 4 state-of-the-art granular-balls-based classifiers and 5 classical machine learning classifiers on 12 public benchmark datasets. Moreover, we discuss the limitations of our work and the outlook for future research.","['three-way decision with neighborhood rough sets (3WDNRS)', 'DBSCAN']"
2024,https://openalex.org/W4396723505,Psychology,MentaLLaMA: Interpretable Mental Health Analysis on Social Media with Large Language Models,"As an integral part of people's daily lives, social media is becoming a rich source for automatic mental health analysis.As traditional discriminative methods bear poor generalization ability and low interpretability, the recent large language models (LLMs) have been explored for interpretable mental health analysis on social media, which aims to provide detailed explanations along with predictions in zero-shot or few-shot settings.The results show that LLMs still achieve unsatisfactory classification performance in a zero-shot/few-shot manner, which further significantly affects the quality of the generated explanations.Domain-specific finetuning is an effective solution, but faces two critical challenges: 1) lack of high-quality training data.2) no open-source foundation LLMs.To alleviate these problems, we formally model interpretable mental health analysis as a text generation task, and build the first multi-task and multi-source interpretable mental health instruction (IMHI) dataset with 105K data samples to support LLM instruction tuning and evaluation.The raw social media data are collected from 10 existing sources covering 8 mental health analysis tasks.We prompt ChatGPT with expert-designed few-shot prompts to obtain explanations.To ensure the reliability of the explanations, we perform strict automatic and human evaluations on the correctness, consistency, and quality of generated data.Based on the IMHI dataset and LLaMA2 foundation models, we train MentaLLaMA, the first open-source instruction-following LLM series for interpretable mental health analysis on social media.We evaluate Men-taLLaMA and other advanced methods on the IMHI benchmark, the first holistic evaluation benchmark for interpretable mental health analysis.The results show that MentaLLaMA approaches state-of-the-art discriminative methods in correctness and generates human-level explanations.MentaLLaMA models also show strong generalizability to unseen tasks.The project is available at https://github.com/SteveKGYang/MentaLLaMA.","['zero-shot learning', 'few-shot learning', 'domain-specific finetuning', 'instruction tuning']"
2024,https://openalex.org/W4397026358,Psychology,Automated Classification of Cognitive Visual Objects Using Multivariate Swarm Sparse Decomposition From Multichannel EEG-MEG Signals,"In visual object decoding, magnetoencephalogram (MEG) and electroencephalogram (EEG) activation patterns demonstrate the utmost discriminative cognitive analysis due to their multivariate oscillatory nature. However, high noise in the recorded EEG-MEG signals and subject-specific variability make it extremely difficult to classify subject's cognitive responses to different visual stimuli. The proposed method is a multivariate extension of the swarm sparse decomposition method (MSSDM) for multivariate pattern analysis of EEG-MEG-based visual activation signals. In comparison, it is an advanced technique for decomposing nonstationary multicomponent signals into a finite number of channel-aligned oscillatory components that significantly enhance visual activation-related sub-bands. The MSSDM method adopts multivariate swarm filtering and sparse spectrum to automatically deliver optimal frequency bands in channel-specific sparse spectrums, resulting in improved filter banks. By combining the advantages of the multivariate SSDM and Riemann's correlation-assisted fusion feature (RCFF), the MSSDM-RCFF algorithm is investigated to improve the visual object recognition ability of EEG-MEG signals. We have also proposed time–frequency representation based on MSSDM to analyze discriminative cognitive patterns of different visual object classes from multichannel EEG-MEG signals. A proposed MSSDM is evaluated on multivariate synthetic signals and multivariate EEG-MEG signals using five classifiers. The proposed fusion feature and linear discriminant analysis classifier-based framework outperformed all existing state-of-the-art methods used for visual object detection and achieved the highest accuracy of 86.42% using tenfold cross-validation on EEG-MEG multichannel signals.","['sparse spectrum', 'linear discriminant analysis classifier']"
2024,https://openalex.org/W4391345489,Psychology,CLARUS: An interactive explainable AI platform for manual counterfactuals in graph neural networks,"Lack of trust in artificial intelligence (AI) models in medicine is still the key blockage for the use of AI in clinical decision support systems (CDSS). Although AI models are already performing excellently in systems medicine, their black-box nature entails that patient-specific decisions are incomprehensible for the physician. Explainable AI (XAI) algorithms aim to ""explain"" to a human domain expert, which input features influenced a specific recommendation. However, in the clinical domain, these explanations must lead to some degree of causal understanding by a clinician. We developed the CLARUS platform, aiming to promote human understanding of graph neural network (GNN) predictions. CLARUS enables the visualisation of patient-specific networks, as well as, relevance values for genes and interactions, computed by XAI methods, such as GNNExplainer. This enables domain experts to gain deeper insights into the network and more importantly, the expert can interactively alter the patient-specific network based on the acquired understanding and initiate re-prediction or retraining. This interactivity allows us to ask manual counterfactual questions and analyse the effects on the GNN prediction. We present the first interactive XAI platform prototype, CLARUS, that allows not only the evaluation of specific human counterfactual questions based on user-defined alterations of patient networks and a re-prediction of the clinical outcome but also a retraining of the entire GNN after changing the underlying graph structures. The platform is currently hosted by the GWDG on https://rshiny.gwdg.de/apps/clarus/.","['graph neural network (GNN)', 'GNNExplainer']"
2024,https://openalex.org/W4400981456,Psychology,Multimodal data integration for oncology in the era of deep neural networks: a review,"Cancer research encompasses data across various scales, modalities, and resolutions, from screening and diagnostic imaging to digitized histopathology slides to various types of molecular data and clinical records. The integration of these diverse data types for personalized cancer care and predictive modeling holds the promise of enhancing the accuracy and reliability of cancer screening, diagnosis, and treatment. Traditional analytical methods, which often focus on isolated or unimodal information, fall short of capturing the complex and heterogeneous nature of cancer data. The advent of deep neural networks has spurred the development of sophisticated multimodal data fusion techniques capable of extracting and synthesizing information from disparate sources. Among these, Graph Neural Networks (GNNs) and Transformers have emerged as powerful tools for multimodal learning, demonstrating significant success. This review presents the foundational principles of multimodal learning including oncology data modalities, taxonomy of multimodal learning, and fusion strategies. We delve into the recent advancements in GNNs and Transformers for the fusion of multimodal data in oncology, spotlighting key studies and their pivotal findings. We discuss the unique challenges of multimodal learning, such as data heterogeneity and integration complexities, alongside the opportunities it presents for a more nuanced and comprehensive understanding of cancer. Finally, we present some of the latest comprehensive multimodal pan-cancer data sources. By surveying the landscape of multimodal data integration in oncology, our goal is to underline the transformative potential of multimodal GNNs and Transformers. Through technological advancements and the methodological innovations presented in this review, we aim to chart a course for future research in this promising field. This review may be the first that highlights the current state of multimodal modeling applications in cancer using GNNs and transformers, presents comprehensive multimodal oncology data sources, and sets the stage for multimodal evolution, encouraging further exploration and development in personalized cancer care.","['deep neural networks', 'Graph Neural Networks (GNNs)', 'Transformers']"
2024,https://openalex.org/W4391774550,Psychology,Role of machine learning and deep learning techniques in EEG-based BCI emotion recognition system: a review,"Abstract Emotion is a subjective psychophysiological reaction coming from external stimuli which impacts every aspect of our daily lives. Due to the continuing development of non-invasive and portable sensor technologies, such as brain-computer interfaces (BCI), intellectuals from several fields have been interested in emotion recognition techniques. Human emotions can be recognised using a variety of behavioural cues, including gestures and body language, voice, and physiological markers. The first three, however, might be ineffective because people sometimes conceal their genuine emotions either intentionally or unknowingly. More precise and objective emotion recognition can be accomplished using physiological signals. Among other physiological signals, Electroencephalogram (EEG) is more responsive and sensitive to variation in affective states. Various EEG-based emotion recognition methods have recently been introduced. This study reviews EEG-based BCIs for emotion identification and gives an outline of the progress made in this field. A summary of the datasets and techniques utilised to evoke human emotions and various emotion models is also given. We discuss several EEG feature extractions, feature selection/reduction, machine learning, and deep learning algorithms in accordance with standard emotional identification process. We provide an overview of the human brain's EEG rhythms, which are closely related to emotional states. We also go over a number of EEG-based emotion identification research and compare numerous machine learning and deep learning techniques. In conclusion, this study highlights the applications, challenges and potential areas for future research in identification and classification of human emotional states.",['feature selection/reduction']
2024,https://openalex.org/W4401434014,Psychology,Crafting personalized learning paths with AI for lifelong learning: a systematic literature review,"The rapid evolution of knowledge requires constantly acquiring and updating skills, making lifelong learning crucial. Despite decades of artificial intelligence, recent advances promote new solutions to personalize learning in this context. The purpose of this article is to explore the current state of research on the development of artificial intelligence-mediated solutions for the design of personalized learning paths. To achieve this, a systematic literature review (SRL) of 78 articles published between 2019 and 2024 from the Scopus and Web or Science databases was conducted, answering seven questions grouped into three themes: characteristics of the published research, context of the research, and type of solution analyzed. This study identified that: (a) the greatest production of scientific research on the topic is developed in China, India and the United States, (b) the focus is mainly directed towards the educational context at the higher education level with areas of opportunity for application in the work context, and (c) the development of adaptive learning technologies predominates; however, there is a growing interest in the application of generative language models. This article contributes to the growing interest and literature related to personalized learning under artificial intelligence mediated solutions that will serve as a basis for academic institutions and organizations to design programs under this model.",['generative language models']
2024,https://openalex.org/W4390777660,Psychology,Unlocking the Potential of XAI for Improved Alzheimer’s Disease Detection and Classification Using a ViT-GRU Model,"Alzheimer's Disease (AD) is a significant cause of dementia worldwide, and its progression from mild to severe affects an individual's ability to perform daily activities independently. The accurate and early diagnosis of AD is crucial for effective clinical intervention. However, interpreting AD from medical images can be challenging, even for experienced radiologists. Therefore, there is a need for an automatic diagnosis of AD, and researchers have investigated the potential of utilizing Artificial Intelligence (AI) techniques, particularly deep learning models, to address this challenge. This study proposes a framework that combines a Vision Transformer (ViT) and a Gated Recurrent Unit (GRU) to detect AD characteristics from Magnetic Resonance Imaging (MRI) images accurately and reliably. The ViT identifies crucial features from the input image, and the GRU establishes clear correlations between these features. The proposed model overcomes the class imbalance issue in the MRI image dataset and achieves superior accuracy and performance compared to existing methods. The model was trained on the Alzheimer's MRI Preprocessed Dataset obtained from Kaggle, achieving notable accuracies of 99.53% for 4-class and 99.69% for binary classification. It also demonstrated a high accuracy of 99.26% for 3-class on the AD Neuroimaging Initiative (ADNI) Baseline Database. These results were validated through a thorough 10-fold cross-validation process. Furthermore, Explainable AI (XAI) techniques were incorporated to make the model interpretable and explainable. This allows clinicians to understand the model's decision-making process and gain insights into the underlying factors driving the AD diagnosis.","['Vision Transformer (ViT)', 'Gated Recurrent Unit (GRU)']"
2024,https://openalex.org/W4391325398,Psychology,A fast and robust method for detecting trend turning points in InSAR displacement time series,"Ground deformation monitoring is a crucial task in geohazard management to ensure the safety of lives and infrastructure. Persistent scatterer interferometric synthetic aperture radar (PS-InSAR) is an advanced technique for measuring small displacements on the Earth's surface. Estimated PS-InSAR time series acquired by Sentinel-1 satellites provide a great opportunity for effective monitoring of ground deformation in recent years. However, challenges arise when processing these time series due to their non-uniform sampling, noise from atmosphere and preprocessing issues including phase unwrapping and others. Therefore, estimating the location and direction of trend turning in such time series, as an indicator of ground deformation, is not an easy task. In this work, a sequential turning point detection method (STPD) is proposed and compared with other change point detection methods. Using a large set of simulated time series with various noise types, it is shown that STPD outperforms other methods in terms of overall accuracy and root mean square error for location and direction of trend turnings. As a case study, STPD is applied to detect turning points within PS-InSAR time series for the province of Frosinone in Italy and classified using topography and land cover/use. In addition, an area susceptible to landslides is selected to estimate the starting dates of potential slow-moving landslides. It is also shown that the turning points in the local precipitation time series have a high correlation with the ones in the PS-InSAR time series, indicating that precipitation is a major triggering factor of the displacements in the area. The STPD can rapidly and effectively detect locations and directions of trend turnings and is freely available online in both MATLAB and python.",['change point detection methods']
2024,https://openalex.org/W4391810207,Psychology,Machine Learning–Based Prediction of Suicidality in Adolescents With Allergic Rhinitis: Derivation and Validation in 2 Independent Nationwide Cohorts,"Background Given the additional risk of suicide-related behaviors in adolescents with allergic rhinitis (AR), it is important to use the growing field of machine learning (ML) to evaluate this risk. Objective This study aims to evaluate the validity and usefulness of an ML model for predicting suicide risk in patients with AR. Methods We used data from 2 independent survey studies, Korea Youth Risk Behavior Web-based Survey (KYRBS; n=299,468) for the original data set and Korea National Health and Nutrition Examination Survey (KNHANES; n=833) for the external validation data set, to predict suicide risks of AR in adolescents aged 13 to 18 years, with 3.45% (10,341/299,468) and 1.4% (12/833) of the patients attempting suicide in the KYRBS and KNHANES studies, respectively. The outcome of interest was the suicide attempt risks. We selected various ML-based models with hyperparameter tuning in the discovery and performed an area under the receiver operating characteristic curve (AUROC) analysis in the train, test, and external validation data. Results The study data set included 299,468 (KYRBS; original data set) and 833 (KNHANES; external validation data set) patients with AR recruited between 2005 and 2022. The best-performing ML model was the random forest model with a mean AUROC of 84.12% (95% CI 83.98%-84.27%) in the original data set. Applying this result to the external validation data set revealed the best performance among the models, with an AUROC of 89.87% (sensitivity 83.33%, specificity 82.58%, accuracy 82.59%, and balanced accuracy 82.96%). While looking at feature importance, the 5 most important features in predicting suicide attempts in adolescent patients with AR are depression, stress status, academic achievement, age, and alcohol consumption. Conclusions This study emphasizes the potential of ML models in predicting suicide risks in patients with AR, encouraging further application of these models in other conditions to enhance adolescent health and decrease suicide rates.",['random forest']
2024,https://openalex.org/W4393222196,Psychology,Finding the Right XAI Method—A Guide for the Evaluation and Ranking of Explainable AI Methods in Climate Science,"Abstract Explainable artificial intelligence (XAI) methods shed light on the predictions of machine learning algorithms. Several different approaches exist and have already been applied in climate science. However, usually missing ground truth explanations complicate their evaluation and comparison, subsequently impeding the choice of the XAI method. Therefore, in this work, we introduce XAI evaluation in the climate context and discuss different desired explanation properties, namely, robustness, faithfulness, randomization, complexity, and localization. To this end, we chose previous work as a case study where the decade of annual-mean temperature maps is predicted. After training both a multilayer perceptron (MLP) and a convolutional neural network (CNN), multiple XAI methods are applied and their skill scores in reference to a random uniform explanation are calculated for each property. Independent of the network, we find that XAI methods such as Integrated Gradients, layerwise relevance propagation, and input times gradients exhibit considerable robustness, faithfulness, and complexity while sacrificing randomization performance. Sensitivity methods, gradient, SmoothGrad, NoiseGrad, and FusionGrad, match the robustness skill but sacrifice faithfulness and complexity for the randomization skill. We find architecture-dependent performance differences regarding robustness, complexity, and localization skills of different XAI methods, highlighting the necessity for research task-specific evaluation. Overall, our work offers an overview of different evaluation properties in the climate science context and shows how to compare and benchmark different explanation methods, assessing their suitability based on strengths and weaknesses, for the specific research problem at hand. By that, we aim to support climate researchers in the selection of a suitable XAI method. Significance Statement Explainable artificial intelligence (XAI) helps to understand the reasoning behind the prediction of a neural network. XAI methods have been applied in climate science to validate networks and provide new insight into physical processes. However, the increasing number of XAI methods can overwhelm practitioners, making it difficult to choose an explanation method. Since XAI methods’ results can vary, uninformed choices might cause misleading conclusions about the network decision. In this work, we introduce XAI evaluation to compare and assess the performance of explanation methods based on five desirable properties. We demonstrate that XAI evaluation reveals the strengths and weaknesses of different XAI methods. Thus, our work provides climate researchers with the tools to compare, analyze, and subsequently choose explanation methods.","['multilayer perceptron (MLP)', 'convolutional neural network (CNN)', 'Integrated Gradients', 'layerwise relevance propagation', 'SmoothGrad']"
2024,https://openalex.org/W4390660035,Psychology,An Empirical Study on Correlations Between Deep Neural Network Fairness and Neuron Coverage Criteria,"Recently, with the widespread use of deep neural networks (DNNs) in high-stakes decision-making systems (such as fraud detection and prison sentencing), concerns have arisen about the fairness of DNNs in terms of the potential negative impact they may have on individuals and society. Therefore, fairness testing has become an important research topic in DNN testing. At the same time, the neural network coverage criteria (such as criteria based on neuronal activation) is considered as an adequacy test for DNN white-box testing. It is implicitly assumed that improving the coverage can enhance the quality of test suites. Nevertheless, the correlation between DNN fairness (a test property) and coverage criteria (a test method) has not been adequately explored. To address this issue, we conducted a systematic empirical study on seven coverage criteria, six fairness metrics, three fairness testing techniques, and five bias mitigation methods on five DNN models and nine fairness datasets to assess the correlation between coverage criteria and DNN fairness. Our study achieved the following findings: 1) with the increase in the size of the test suite, some of the coverage and fairness metrics changed significantly, as the size of the test suite increased; 2) the statistical correlation between coverage criteria and DNN fairness is limited; and 3) after bias mitigation for improving the fairness of DNN, the change pattern in coverage criteria is different; 4) Models debiased by different bias mitigation methods have a lower correlation between coverage and fairness compared to the original models. Our findings cast doubt on the validity of coverage criteria concerning DNN fairness (i.e., increasing the coverage may even have a negative impact on the fairness of DNNs). Therefore, we warn DNN testers against blindly pursuing higher coverage of coverage criteria at the cost of test properties of DNNs (such as fairness).","['deep neural networks (DNNs)', 'bias mitigation methods']"
2024,https://openalex.org/W4391174596,Psychology,Generative Large Language Models for Detection of Speech Recognition Errors in Radiology Reports,"This study evaluated the ability of generative large language models (LLMs) to detect speech recognition errors in radiology reports. A dataset of 3233 CT and MRI reports was assessed by radiologists for speech recognition errors. Errors were categorized as clinically significant or not clinically significant. Performances of five generative LLMs—GPT-3.5-turbo, GPT-4, text-davinci-003, Llama-v2–70B-chat, and Bard—were compared in detecting these errors, using manual error detection as the reference standard. Prompt engineering was used to optimize model performance. GPT-4 demonstrated high accuracy in detecting clinically significant errors (precision, 76.9%; recall, 100%; F1 score, 86.9%) and not clinically significant errors (precision, 93.9%; recall, 94.7%; F1 score, 94.3%). Text-davinci-003 achieved F1 scores of 72% and 46.6% for clinically significant and not clinically significant errors, respectively. GPT-3.5-turbo obtained 59.1% and 32.2% F1 scores, while Llama-v2–70B-chat scored 72.8% and 47.7%. Bard showed the lowest accuracy, with F1 scores of 47.5% and 20.9%. GPT-4 effectively identified challenging errors of nonsense phrases and internally inconsistent statements. Longer reports, resident dictation, and overnight shifts were associated with higher error rates. In conclusion, advanced generative LLMs show potential for automatic detection of speech recognition errors in radiology reports. Keywords: CT, Large Language Model, Machine Learning, MRI, Natural Language Processing, Radiology Reports, Speech, Unsupervised Learning Supplemental material is available for this article. © RSNA, 2024","['generative large language models (LLMs)', 'GPT-3.5-turbo', 'GPT-4', 'text-davinci-003', 'Llama-v2–70B-chat']"
2024,https://openalex.org/W4391641063,Psychology,Predictors for estimating subcortical EEG responses to continuous speech,"Perception of sounds and speech involves structures in the auditory brainstem that rapidly process ongoing auditory stimuli. The role of these structures in speech processing can be investigated by measuring their electrical activity using scalp-mounted electrodes. However, typical analysis methods involve averaging neural responses to many short repetitive stimuli that bear little relevance to daily listening environments. Recently, subcortical responses to more ecologically relevant continuous speech were detected using linear encoding models. These methods estimate the temporal response function (TRF), which is a regression model that minimises the error between the measured neural signal and a predictor derived from the stimulus. Using predictors that model the highly non-linear peripheral auditory system may improve linear TRF estimation accuracy and peak detection. Here, we compare predictors from both simple and complex peripheral auditory models for estimating brainstem TRFs on electroencephalography (EEG) data from 24 participants listening to continuous speech. We also investigate the data length required for estimating subcortical TRFs, and find that around 12 minutes of data is sufficient for clear wave V peaks (&gt;3 dB SNR) to be seen in nearly all participants. Interestingly, predictors derived from simple filterbank-based models of the peripheral auditory system yield TRF wave V peak SNRs that are not significantly different from those estimated using a complex model of the auditory nerve, provided that the nonlinear effects of adaptation in the auditory system are appropriately modelled. Crucially, computing predictors from these simpler models is more than 50 times faster compared to the complex model. This work paves the way for efficient modelling and detection of subcortical processing of continuous speech, which may lead to improved diagnosis metrics for hearing impairment and assistive hearing technology.","['linear encoding models', 'temporal response function (TRF)', 'regression model']"
2024,https://openalex.org/W4400770903,Psychology,"A Survey of Imitation Learning: Algorithms, Recent Developments, and Challenges","In recent years, the development of robotics and artificial intelligence (AI) systems has been nothing short of remarkable. As these systems continue to evolve, they are being utilized in increasingly complex and unstructured environments, such as autonomous driving, aerial robotics, and natural language processing. As a consequence, programming their behaviors manually or defining their behavior through the reward functions as done in reinforcement learning (RL) has become exceedingly difficult. This is because such environments require a high degree of flexibility and adaptability, making it challenging to specify an optimal set of rules or reward signals that can account for all the possible situations. In such environments, learning from an expert's behavior through imitation is often more appealing. This is where imitation learning (IL) comes into play -a process where desired behavior is learned by imitating an expert's behavior, which is provided through demonstrations.This article aims to provide an introduction to IL and an overview of its underlying assumptions and approaches. It also offers a detailed description of recent advances and emerging areas of research in the field. Additionally, this article discusses how researchers have addressed common challenges associated with IL and provides potential directions for future research. Overall, the goal of this article is to provide a comprehensive guide to the growing field of IL in robotics and AI.","['reinforcement learning (RL)', 'imitation learning (IL)']"
2024,https://openalex.org/W4392499245,Psychology,Exploring the role of skin temperature in thermal sensation and thermal comfort: A comprehensive review,"The role of skin temperature as a determinant of human thermal sensation and comfort has gained increasing recognition, prompting a need for a systematic review. This review examines the relationship between skin temperature and thermal sensation, synthesizing insights from 172 studies published since 2000. It uniquely focuses on the indispensable roles of local and mean skin temperatures, a perspective not comprehensively explored in previous literature. The review reveals that the most common measurement points for skin temperature are the face and hands, attributed to their higher thermal sensitivity and the practical ease of measurement. It establishes a clear linear relationship between mean skin temperature and user thermal sensation, though affected by the choice of measurement locations and number of points. A notable finding is the varying impact of local skin temperature on overall thermal sensation in changing environments, with local heating less influential than cooling. The review also uncovers significant demographic variations in thermal sensation, strongly influenced by differing skin temperatures across age groups, genders, and climatic regions. For example, elderly populations exhibit a decreased temperature sensitivity, especially towards warmth. Gender differences are also significant, with females experiencing higher skin temperatures in warmer environments and lower in colder ones. Machine learning (ML)-based methods, especially classification tree-based and support vector machine (SVM) techniques, dominate in predicting thermal sensation and comfort, leveraging skin temperature data. While ML methods are prevalent, statistical regression-based approaches offer valuable empirical insights. Thermo-physiological model-based methods provide reliable results by incorporating detailed skin temperature dynamics. The review identifies a gap in understanding how gender, age, and regional differences influence thermal comfort in diverse environments. The study recommends conducting more nuanced experiments to dissect the impact of these factors and proposes the integration of individual demographic variables into ML models to personalize thermal comfort predictions.","['support vector machine (SVM)', 'statistical regression-based approaches']"
2024,https://openalex.org/W4399154552,Psychology,Seeking in Ride-on-Demand Service: A Reinforcement Learning Model With Dynamic Price Prediction,"Recent years witness the increasing popularity of ride-on-demand (RoD) services such as Uber and Didi. Compared with traditional taxi, RoD service is more ""data-driven"" and adopts dynamic pricing to manipulate the supply and demand in real time. Dynamic price could be viewed as an accurate and quantitative indicator of the supply and demand, and could provide clues to drivers, passengers, and the service providers, possibly reshaping the ways in which some problems are solved. In this paper, we focus on the seeking route recommendation problem that aims at increasing driver revenue by recommending highly profitable seeking routes to drivers of vacant cars with the help of dynamic prices. We first justify our motivation by showing the importance of route recommendation and answering why it is necessary to consider dynamic prices, based on the analysis of real service data. We then design a dynamic price prediction model to generate the dynamic prices at any given time and location based on multi-source urban data. After that, a reinforcement learning model is adopted to perform seeking route recommendation based on predicted dynamic prices. We conduct extensive experiments in different spatio-temporal combinations and make comparisons with multiple baselines. Results first show that our dynamic price prediction model achieves an accuracy ranging from 83.82% to 90.67% under different settings. It also proves that considering the real-time predicted dynamic prices significantly increases driver revenue by, for example, 12% and 47.5% during weekday evening rush hours, than merely using the average prices or completely ignoring dynamic prices.",['reinforcement learning model']
2024,https://openalex.org/W4391715895,Psychology,Deciphering Digital Social Dynamics: A Comparative Study of Logistic Regression and Random Forest in Predicting E-Commerce Customer Behavior,"This study compares Logistic Regression and Random Forest in predicting e-commerce customer churn. Utilizing the E-commerce Customer dataset, it navigates the complexities of customer interactions and behaviors, offering a rich context for analysis. The methodology focuses on meticulous data preprocessing to ensure data integrity, setting the stage for applying and evaluating Logistic Regression and Random Forest. Both models were assessed using accuracy, precision, recall, F1-Score, and AUC-ROC. Logistic Regression showed an accuracy of 90%, precision of 91% for class 0 and 82% for class 1, recall of 98% for class 0 and 50% for class 1, F1-Score of 94% for class 0 and 62% for class 1, and AUC-ROC of 0.88. Random Forest, with its ability to handle complex patterns, demonstrated higher overall performance with an accuracy of 95%, precision of 95% for class 0 and 93% for class 1, recall of 99% for class 0 and 74% for class 1, F1-Score of 97% for class 0 and 82% for class 1, and an AUC-ROC of 0.97. This comparative analysis offers insights into each model's strengths and suitability for predicting customer churn. The findings contribute to a deeper understanding of machine learning applications in e-commerce, guiding stakeholders in enhancing customer retention strategies. This research provides a foundation for further exploration into the digital social dynamics that shape customer behavior in the evolving digital marketplace.","['Logistic Regression', 'Random Forest']"
2024,https://openalex.org/W4396622079,Psychology,The power of Deep Learning techniques for predicting student performance in Virtual Learning Environments: A systematic literature review,"With the advances in Artificial Intelligence (AI) and the increasing volume of online educational data, Deep Learning techniques have played a critical role in predicting student performance. Recent developments have assisted instructors in determining the strengths and weaknesses of student achievement. This understanding will benefit from adopting the necessary interventions to assist students in improving their performance, helping at-risk of failure students, and preventing dropout rates. The review analyzed 46 studies between 2019 and 2023 that apply one or more Deep Learning (DL) techniques, either single or in combination with Machine Learning (ML) or Ensemble Learning techniques. Moreover, the review utilized datasets from public Massive Open Online Courses (MOOCs), private Learning Management Systems (LMSs), and other platforms. Four categories were used to group the features: demographic, previous academic performance, current academic performance, and learning behavior/activity features. The analysis revealed that the DNNs and CNN-LSTM models were the most common techniques. Moreover, the studies that used DL techniques, such as CNNs, DNNs, and LSTMs, performed well by achieving high prediction accuracy above 90%; other studies achieved accuracy ranging (60 to 90)%. For datasets used within the reviewed studies, even though 44% of the studies used LMSs datasets, Open University Learning Analytics Dataset (OULAD) was the most used dataset from MOOCs. The analysis of grouped features shows that among the various categories examined, learning behavior and activity features stand out as the most significant predictors, suggesting that students engagement with their learning environment through their overall participation offers crucial insights into their success. The educational prediction findings hopefully serve as a strong foundation for administrators and instructors to observe student performance and provide a suitable educational adaptation that can meet their needs to protect them from failure and prevent their dropout.","['Ensemble Learning techniques', 'DNNs', 'CNN-LSTM models', 'CNNs', 'DNNs', 'LSTMs']"
2024,https://openalex.org/W4399442306,Psychology,Integrative analysis of AI-driven optimization in HIV treatment regimens,"The integration of artificial intelligence (AI) into HIV treatment regimens has revolutionized the approach to personalized care and optimization strategies. This study presents an in-depth analysis of the role of AI in transforming HIV treatment, focusing on its ability to tailor therapy to individual patient needs and enhance treatment outcomes. AI-driven optimization in HIV treatment involves the utilization of advanced algorithms and computational techniques to analyze vast amounts of patient data, including genetic information, viral load measurements, and treatment history. By harnessing the power of machine learning and predictive analytics, AI algorithms can identify patterns and trends in patient data that may not be readily apparent to human clinicians. One of the key benefits of AI-driven optimization is its ability to personalize treatment regimens based on individual patient characteristics and disease progression. By considering factors such as drug resistance profiles, comorbidities, and lifestyle factors, AI algorithms can recommend the most effective and well-tolerated treatment options for each patient, leading to improved adherence and clinical outcomes. Furthermore, AI enables continuous monitoring and adjustment of treatment regimens in real time, allowing healthcare providers to respond rapidly to changes in patient status and evolving viral dynamics. This proactive approach to HIV management can help prevent treatment failure and the development of drug resistance, ultimately leading to better long-term outcomes for patients. Despite its transformative potential, AI-driven optimization in HIV treatment is not without challenges. Ethical considerations, data privacy concerns, and the need for robust validation and regulatory oversight are all important factors that must be addressed to ensure the safe and effective implementation of AI algorithms in clinical practice. In conclusion, the integrative analysis presented in this study underscores the significant impact of AI-driven optimization on the personalization and optimization of HIV treatment regimens. By leveraging AI technologies, healthcare providers can tailor treatment approaches to individual patient needs, leading to improved outcomes and quality of life for people living with HIV. Keywords: Integrative Analysis, AI- Driven, Optimization, HIV Treatment, Regimens.",['machine learning']
2024,https://openalex.org/W4390506438,Psychology,Artificial intelligence for oral squamous cell carcinoma detection based on oral photographs: A comprehensive literature review,"Abstract Introduction Oral squamous cell carcinoma (OSCC) presents a significant global health challenge. The integration of artificial intelligence (AI) and computer vision holds promise for the early detection of OSCC through the analysis of digitized oral photographs. This literature review explores the landscape of AI‐driven OSCC automatic detection, assessing both the performance and limitations of the current state of the art. Materials and Methods An electronic search using several data base was conducted, and a systematic review performed in accordance with PRISMA guidelines (CRD42023441416). Results Several studies have demonstrated remarkable results for this task, consistently achieving sensitivity rates exceeding 85% and accuracy rates surpassing 90%, often encompassing around 1000 images. The review scrutinizes these studies, shedding light on their methodologies, including the use of recent machine learning and pattern recognition approaches coupled with different supervision strategies. However, comparing the results from different papers is challenging due to variations in the datasets used. Discussion Considering these findings, this review underscores the urgent need for more robust and reliable datasets in the field of OSCC detection. Furthermore, it highlights the potential of advanced techniques such as multi‐task learning, attention mechanisms, and ensemble learning as crucial tools in enhancing the accuracy and sensitivity of OSCC detection through oral photographs. Conclusion These insights collectively emphasize the transformative impact of AI‐driven approaches on early OSCC diagnosis, with the potential to significantly improve patient outcomes and healthcare practices.","['machine learning', 'multi-task learning', 'attention mechanisms', 'ensemble learning']"
2024,https://openalex.org/W4390665001,Psychology,A deep learning model for brain age prediction using minimally preprocessed T1w images as input,"Introduction In the last few years, several models trying to calculate the biological brain age have been proposed based on structural magnetic resonance imaging scans (T1-weighted MRIs, T1w) using multivariate methods and machine learning. We developed and validated a convolutional neural network (CNN)-based biological brain age prediction model that uses one T1w MRI preprocessing step when applying the model to external datasets to simplify implementation and increase accessibility in research settings. Our model only requires rigid image registration to the MNI space, which is an advantage compared to previous methods that require more preprocessing steps, such as feature extraction. Methods We used a multicohort dataset of cognitively healthy individuals (age range = 32.0–95.7 years) comprising 17,296 MRIs for training and evaluation. We compared our model using hold-out (CNN1) and cross-validation (CNN2–4) approaches. To verify generalisability, we used two external datasets with different populations and MRI scan characteristics to evaluate the model. To demonstrate its usability, we included the external dataset’s images in the cross-validation training (CNN3). To ensure that our model used only the brain signal on the image, we also predicted brain age using skull-stripped images (CNN4). Results: The trained models achieved a mean absolute error of 2.99, 2.67, 2.67, and 3.08 years for CNN1–4, respectively. The model’s performance in the external dataset was in the typical range of mean absolute error (MAE) found in the literature for testing sets. Adding the external dataset to the training set (CNN3), overall, MAE is unaffected, but individual cohort MAE improves (5.63–2.25 years). Salience maps of predictions reveal that periventricular, temporal, and insular regions are the most important for age prediction. Discussion We provide indicators for using biological (predicted) brain age as a metric for age correction in neuroimaging studies as an alternative to the traditional chronological age. In conclusion, using different approaches, our CNN-based model showed good performance using one T1w brain MRI preprocessing step. The proposed CNN model is made publicly available for the research community to be easily implemented and used to study ageing and age-related disorders.","['machine learning', 'convolutional neural network (CNN)', 'hold-out approach']"
2024,https://openalex.org/W4391035240,Psychology,Detection of epileptic seizure in EEG signals using machine learning and deep learning techniques,"Abstract Around 50 million individuals worldwide suffer from epilepsy, a chronic, non-communicable brain disorder. Several screening methods, including electroencephalography, have been proposed to identify epileptic episodes. EEG data, which are frequently utilised to enhance epilepsy analysis, offer essential information on the electrical processes of the brain. Prior to the emergence of deep learning (DL), feature extraction was accomplished by standard machine learning techniques. As a result, they were only as good as the people who made the features by hand. But with DL, both feature extraction and classification are fully automated. These methods have significantly advanced several fields of medicine, including the diagnosis of epilepsy. In this paper, the works focused on automated epileptic seizure detection using ML and DL techniques are presented as well as their comparative analysis is done. The UCI-Epileptic Seizure Recognition dataset is used for training and validation. Some of the conventional ML and DL algorithms are used with a proposed model which uses long short-term memory (LSTM) to find the best approach. Post that comparative analysis is performed on these algorithms to find the best approach for epileptic seizure detection. As a result, the proposed model LSTM gives a validation accuracy of 97% giving the most appropriate and precise result as compared to other mentioned algorithms used in this study.","['machine learning', 'deep learning', 'long short-term memory (LSTM)']"
2024,https://openalex.org/W4391164242,Psychology,Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models,"Suicidal ideation detection is a vital research area that holds great potential for improving mental health support systems. However, the sensitivity surrounding suicide-related data poses challenges in accessing large-scale, annotated datasets necessary for training effective machine learning models. To address this limitation, we introduce an innovative strategy that leverages the capabilities of generative AI models, such as ChatGPT, Flan-T5, and Llama, to create synthetic data for suicidal ideation detection. Our data generation approach is grounded in social factors extracted from psychology literature and aims to ensure coverage of essential information related to suicidal ideation. In our study, we benchmarked against state-of-the-art NLP classification models, specifically, those centered around the BERT family structures. When trained on the real-world dataset, UMD, these conventional models tend to yield F1-scores ranging from 0.75 to 0.87. Our synthetic data-driven method, informed by social factors, offers consistent F1-scores of 0.82 for both models, suggesting that the richness of topics in synthetic data can bridge the performance gap across different model complexities. Most impressively, when we combined a mere 30% of the UMD dataset with our synthetic data, we witnessed a substantial increase in performance, achieving an F1-score of 0.88 on the UMD test set. Such results underscore the cost-effectiveness and potential of our approach in confronting major challenges in the field, such as data scarcity and the quest for diversity in data representation.","['generative AI models', 'Flan-T5', 'Llama']"
2024,https://openalex.org/W4392138877,Psychology,Prevalence and risk factors analysis of postpartum depression at early stage using hybrid deep learning model,"Postpartum Depression Disorder (PPDD) is a prevalent mental health condition and results in severe depression and suicide attempts in the social community. Prompt actions are crucial in tackling PPDD, which requires a quick recognition and accurate analysis of the probability factors associated with this condition. This concern requires attention. The primary aim of our research is to investigate the feasibility of anticipating an individual's mental state by categorizing individuals with depression from those without depression using a dataset consisting of text along with audio recordings from patients diagnosed with PPDD. This research proposes a hybrid PPDD framework that combines Improved Bi-directional Long Short-Term Memory (IBi-LSTM) with Transfer Learning (TL) based on two Convolutional Neural Network (CNN) architectures, respectively CNN-text and CNN audio. In the proposed model, the CNN section efficiently utilizes TL to obtain crucial knowledge from text and audio characteristics, whereas the improved Bi-LSTM module combines written material and sound data to obtain intricate chronological interpersonal relationships. The proposed model incorporates an attention technique to augment the effectiveness of the Bi-LSTM scheme. An experimental analysis is conducted on the PPDD online textual and speech audio dataset collected from UCI. It includes textual features such as age, women's health tracks, medical histories, demographic information, daily life metrics, psychological evaluations, and 'speech records' of PPDD patients. Data pre-processing is applied to maintain the data integrity and achieve reliable model performance. The proposed model demonstrates a great performance in better precision, recall, accuracy, and F1-score over existing deep learning models, including VGG-16, Base-CNN, and CNN-LSTM. These metrics indicate the model's ability to differentiate among women at risk of PPDD vs. non-PPDD. In addition, the feature importance analysis demonstrates that specific risk factors substantially impact the prediction of PPDD. The findings of this research establish a basis for improved precision and promptness in assessing the risk of PPDD, which may ultimately result in earlier implementation of interventions and the establishment of support networks for women who are susceptible to PPDD.","['Transfer Learning (TL)', 'Convolutional Neural Network (CNN)', 'Attention technique', 'VGG-16', 'CNN-LSTM']"
2024,https://openalex.org/W4399363436,Psychology,Collective Constitutional AI: Aligning a Language Model with Public Input,"There is growing consensus that language model (LM) developers should not be the sole deciders of LM behavior, creating a need for methods that enable the broader public to collectively shape the behavior of LM systems that affect them. To address this need, we present Collective Constitutional AI (CCAI): a multi-stage process for sourcing and integrating public input into LMs—from identifying a target population to sourcing principles to training and evaluating a model. We demonstrate the real-world practicality of this approach by creating what is, to our knowledge, the first LM fine-tuned with collectively sourced public input and evaluating this model against a baseline model trained with established principles from a LM developer. Our quantitative evaluations demonstrate several benefits of our approach: the CCAI-trained model shows lower bias across nine social dimensions compared to the baseline model, while maintaining equivalent performance on language, math, and helpful-harmless evaluations. Qualitative comparisons of the models suggest that the models differ on the basis of their respective constitutions, e.g., when prompted with contentious topics, the CCAI-trained model tends to generate responses that reframe the matter positively instead of a refusal. These results demonstrate a promising, tractable pathway toward publicly informed development of language models.",['fine-tuning']
2024,https://openalex.org/W3186881383,Psychology,Graph Autoencoders for Embedding Learning in Brain Networks and Major Depressive Disorder Identification,"Brain functional connectivity (FC) networks inferred from functional magnetic resonance imaging (fMRI) have shown altered or aberrant brain functional connectome in various neuropsychiatric disorders. Recent application of deep neural networks to connectome-based classification mostly relies on traditional convolutional neural networks (CNNs) using input FCs on a regular Euclidean grid to learn spatial maps of brain networks neglecting the topological information of the brain networks, leading to potentially sub-optimal performance in brain disorder identification. We propose a novel graph deep learning framework that leverages non-Euclidean information inherent in the graph structure for classifying brain networks in major depressive disorder (MDD). We introduce a novel graph autoencoder (GAE) architecture, built upon graph convolutional networks (GCNs), to embed the topological structure and node content of large fMRI networks into low-dimensional representations. For constructing the brain networks, we employ the Ledoit-Wolf (LDW) shrinkage method to efficiently estimate high-dimensional FC metrics from fMRI data. We explore both supervised and unsupervised techniques for graph embedding learning. The resulting embeddings serve as feature inputs for a deep fully-connected neural network (FCNN) to distinguish MDD from healthy controls (HCs). Evaluating our model on resting-state fMRI MDD dataset, we observe that the GAE-FCNN outperforms several state-of-the-art methods for brain connectome classification, achieving the highest accuracy when using LDW-FC edges as node features. The graph embeddings of fMRI FC networks also reveal significant group differences between MDD and HCs. Our framework demonstrates the feasibility of learning graph embeddings from brain networks, providing valuable discriminative information for diagnosing brain disorders.","['deep neural networks', 'convolutional neural networks (CNNs)', 'graph autoencoder (GAE)', 'graph convolutional networks (GCNs)', 'supervised techniques for graph embedding learning', 'unsupervised techniques for graph embedding learning', 'deep fully-connected neural network (FCNN)']"
2024,https://openalex.org/W4391655051,Psychology,Do large language models show decision heuristics similar to humans? A case study using GPT-3.5.,"A Large Language Model (LLM) is an artificial intelligence system trained on vast amounts of natural language data, enabling it to generate human-like responses to written or spoken language input. Generative Pre-Trained Transformer (GPT)-3.5 is an example of an LLM that supports a conversational agent called ChatGPT. In this work, we used a series of novel prompts to determine whether ChatGPT shows heuristics and other context-sensitive responses. We also tested the same prompts on human participants. Across four studies, we found that ChatGPT was influenced by random anchors in making estimates (anchoring, Study 1); it judged the likelihood of two events occurring together to be higher than the likelihood of either event occurring alone, and it was influenced by anecdotal information (representativeness and availability heuristic, Study 2); it found an item to be more efficacious when its features were presented positively rather than negatively-even though both presentations contained statistically equivalent information (framing effect, Study 3); and it valued an owned item more than a newly found item even though the two items were objectively identical (endowment effect, Study 4). In each study, human participants showed similar effects. Heuristics and context-sensitive responses in humans are thought to be driven by cognitive and affective processes such as loss aversion and effort reduction. The fact that an LLM-which lacks these processes-also shows such responses invites consideration of the possibility that language is sufficiently rich to carry these effects and may play a role in generating these effects in humans. (PsycInfo Database Record (c) 2024 APA, all rights reserved).",['Generative Pre-Trained Transformer (GPT)-3.5']
2024,https://openalex.org/W4392542342,Psychology,Detecting ChatGPT-Generated Code Submissions in a CS1 Course Using Machine Learning Models,"The emergence of publicly accessible large language models (LLMs) such as ChatGPT poses unprecedented risks of new types of plagiarism and cheating where students use LLMs to solve exercises for them. Detecting this behavior will be a necessary component in introductory computer science (CS1) courses, and educators should be well-equipped with detection tools when the need arises. However, ChatGPT generates code non-deterministically, and thus, traditional similarity detectors might not suffice to detect AI-created code. In this work, we explore the affordances of Machine Learning (ML) models for the detection task. We used an openly available dataset of student programs for CS1 assignments and had ChatGPT generate code for the same assignments, and then evaluated the performance of both traditional machine learning models and Abstract Syntax Tree-based (AST-based) deep learning models in detecting ChatGPT code from student code submissions. Our results suggest that both traditional machine learning models and AST-based deep learning models are effective in identifying ChatGPT-generated code with accuracy above 90%. Since the deployment of such models requires ML knowledge and resources that are not always accessible to instructors, we also explore the patterns detected by deep learning models that indicate possible ChatGPT code signatures, which instructors could possibly use to detect LLM-based cheating manually. We also explore whether explicitly asking ChatGPT to impersonate a novice programmer affects the code produced. We further discuss the potential applications of our proposed models for enhancing introductory computer science instruction.",['Abstract Syntax Tree-based (AST-based) deep learning models']
2024,https://openalex.org/W4393078946,Psychology,Enhancing End-to-End Multi-Task Dialogue Systems: A Study on Intrinsic Motivation Reinforcement Learning Algorithms for Improved Training and Adaptability,"End-to-end multi-task dialogue systems are usually designed with separate modules for the dialogue pipeline. Among these, the policy module is essential for deciding what to do in response to user input. This policy is trained by reinforcement learning algorithms by taking advantage of an environment in which an agent receives feedback in the form of a reward signal. The current dialogue systems, however, only provide meagre and simplistic rewards. Investigating intrinsic motivation reinforcement learning algorithms is the goal of this study. Through this, the agent can quickly accelerate training and improve its capacity to judge the quality of its actions by teaching it an internal incentive system. In particular, we adapt techniques for random network distillation and curiosity-driven reinforcement learning to measure the frequency of state visits and encourage exploration by using semantic similarity between utterances. Experimental results on MultiWOZ, a heterogeneous dataset, show that intrinsic motivation-based debate systems outperform policies that depend on extrinsic incentives. By adopting random network distillation, for example, which is trained using semantic similarity between user-system dialogues, an astounding average success rate of 73% is achieved. This is a significant improvement over the baseline Proximal Policy optimization (PPO), which has an average success rate of 60%. In addition, performance indicators such as booking rates and completion rates show a 10% rise over the baseline. Furthermore, these intrinsic incentive models help improve the system's policy's resilience in an increasing amount of domains. This implies that they could be useful in scaling up to settings that cover a wider range of domains.","['reinforcement learning algorithms', 'intrinsic motivation reinforcement learning algorithms', 'random network distillation', 'curiosity-driven reinforcement learning', 'Proximal Policy Optimization (PPO)']"
2024,https://openalex.org/W4394633221,Psychology,An efficient Parkinson's disease detection framework: Leveraging time-frequency representation and AlexNet convolutional neural network,"Parkinson's disease (PD) is a progressive neurodegenerative disorder affecting the quality of life of over 10 million individuals worldwide. Early diagnosis is crucial for timely intervention and better patient outcomes. Electroencephalogram (EEG) signals are commonly used for early PD diagnosis due to their potential in monitoring disease progression. But traditional EEG-based methods lack exploration of brain regions that provide essential information about PD, and their performance falls short for real-time applications. To address these limitations, this study proposes a novel approach using a Time-Frequency Representation (TFR) based AlexNet Convolutional Neural Network (CNN) model to explore EEG channel-based analysis and identify critical brain regions efficiently diagnosing PD from EEG data. The Wavelet Scattering Transform (WST) is employed to capture distinct temporal and spectral characteristics, while AlexNet CNN is utilized to detect complex spatial patterns at different scales, accurately identifying intricate EEG patterns associated with PD. The experiment results on two real-time EEG PD datasets: San Diego dataset and the Iowa dataset demonstrate that frontal and central brain regions, including AF4 and AFz electrodes, contribute significantly to providing more representative features compared to other regions for PD detection. The proposed architecture achieves an impressive accuracy of 99.84% for the San Diego dataset and 95.79% for the Iowa dataset, outperforming existing EEG-based PD detection methods. The findings of this research will assist to create an essential technology for efficient PD diagnosis, enhancing patient care and quality of life.","['Wavelet Scattering Transform (WST)', 'AlexNet CNN']"
2024,https://openalex.org/W4391023547,Psychology,Multimodal diagnosis model of Alzheimer’s disease based on improved Transformer,"Abstract Purpose Recent technological advancements in data acquisition tools allowed neuroscientists to acquire different modality data to diagnosis Alzheimer’s disease (AD). However, how to fuse these enormous amount different modality data to improve recognizing rate and find significance brain regions is still challenging. Methods The algorithm used multimodal medical images [structural magnetic resonance imaging (sMRI) and positron emission tomography (PET)] as experimental data. Deep feature representations of sMRI and PET images are extracted by 3D convolution neural network (3DCNN). An improved Transformer is then used to progressively learn global correlation information among features. Finally, the information from different modalities is fused for identification. A model-based visualization method is used to explain the decisions of the model and identify brain regions related to AD. Results The model attained a noteworthy classification accuracy of 98.1% for Alzheimer’s disease (AD) using the Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset. Upon examining the visualization results, distinct brain regions associated with AD diagnosis were observed across different image modalities. Notably, the left parahippocampal region emerged consistently as a prominent and significant brain area. Conclusions A large number of comparative experiments have been carried out for the model, and the experimental results verify the reliability of the model. In addition, the model adopts a visualization analysis method based on the characteristics of the model, which improves the interpretability of the model. Some disease-related brain regions were found in the visualization results, which provides reliable information for AD clinical research.",['3D convolution neural network (3DCNN)']
2024,https://openalex.org/W4392190113,Psychology,Factors influencing academic performance and dropout rates in higher education,"The aim of this study was to identify and evaluate the most frequently used research methods and factors influencing academic performance, based on a pool of 95 studies, published after 2012. We considered only peer-reviewed papers containing 78 empirical and 17 meta-analytic studies. Our theoretical background lies in the different approaches of the terms 'university dropout' and 'academic performance'. After the systematic analysis we ascertained the most commonly used methods are Educational Data Mining (EDM) algorithms (decision tree, logistic regression and neural networks) and Structural Equation Modelling (SEM). The strength of the predictive power depends on the dataset, however Support Vector Machines, Multilayer Perceptron, Naïve Bayes algorithm were found to be the most precise in prediction. Regarding factors influencing academic performance we derived our results based on 600,000 university students. Considering the data from meta-analyses and systematic reviews, reaching up to 900 studies, we found grade point average (GPA), obtained credits (ECTS) and gender to be the most consistent and decisive predictors of academic performance. Nevertheless, GPA and ECTS (as output variables) are mediated by student factors (intrinsic motivation, self-regulated learning strategies, self-efficacy, prior education) and throughput factors (work, finances, academic engagement). We had contradictory results on age and family background.","['decision tree', 'logistic regression', 'neural networks', 'Support Vector Machines', 'Multilayer Perceptron', 'Naïve Bayes algorithm']"
2024,https://openalex.org/W4392891497,Psychology,Learners’ continuance intention in multimodal language learning education: An innovative multiple linear regression model,"Confronted with the unprecedented COVID-19 pandemic, millions of learners have received, are receiving, or will receive multimodal language learning education. This study aims to explore the relationships between various factors influencing learners' continuance intention by proposing an innovative multiple linear regression model in multimodal language learning education. Participants were randomly recruited (N = 334) in China who had received multimodal language learning education by combining Massive Open Online Courses, Rain Classroom, and WeChat. The research instrument, a comprehensive questionnaire, was sent through the online system named Questionnaire Star developed by technical experts. A multiple linear regression analysis was adopted to test the proposed hypotheses and fit the research model. This study confirms the relationships between the Technology Acceptance Model-inclusive constructs such as perceived ease of use, perceived usefulness, attitudes toward multimodal language learning education, and continuance intention of participating in multimodal language learning education. The Technology Acceptance Model is also associated with other constructs, e.g. Task-technology fit, Individual-technology fit, Openness, and Reputation of multimodal language learning educational institutes, and personal investment in multimodal language learning education. However, personal investment neither directly nor indirectly predicts continuance intention. Educators and designers could make every effort to improve multimodal language learning education to enhance personal investment and foster its association with continuance intention of learners.",['multiple linear regression']
2024,https://openalex.org/W4390618032,Psychology,An interpretable model based on graph learning for diagnosis of Parkinson’s disease with voice-related EEG,"Abstract Parkinson’s disease (PD) exhibits significant clinical heterogeneity, presenting challenges in the identification of reliable electroencephalogram (EEG) biomarkers. Machine learning techniques have been integrated with resting-state EEG for PD diagnosis, but their practicality is constrained by the interpretable features and the stochastic nature of resting-state EEG. The present study proposes a novel and interpretable deep learning model, graph signal processing-graph convolutional networks (GSP-GCNs), using event-related EEG data obtained from a specific task involving vocal pitch regulation for PD diagnosis. By incorporating both local and global information from single-hop and multi-hop networks, our proposed GSP-GCNs models achieved an averaged classification accuracy of 90.2%, exhibiting a significant improvement of 9.5% over other deep learning models. Moreover, the interpretability analysis revealed discriminative distributions of large-scale EEG networks and topographic map of microstate MS5 learned by our models, primarily located in the left ventral premotor cortex, superior temporal gyrus, and Broca’s area that are implicated in PD-related speech disorders, reflecting our GSP-GCN models’ ability to provide interpretable insights identifying distinctive EEG biomarkers from large-scale networks. These findings demonstrate the potential of interpretable deep learning models coupled with voice-related EEG signals for distinguishing PD patients from healthy controls with accuracy and elucidating the underlying neurobiological mechanisms.",['graph signal processing-graph convolutional networks (GSP-GCNs)']
2024,https://openalex.org/W4390812034,Psychology,The Utility of AI in Writing a Scientific Review Article on the Impacts of COVID-19 on Musculoskeletal Health,"Abstract Purpose of Review There were two primary purposes to our reviews. First, to provide an update to the scientific community about the impacts of COVID-19 on musculoskeletal health. Second, was to determine the value of using a large language model, ChatGPT 4.0, in the process of writing a scientific review article. To accomplish these objectives, we originally set out to write three review articles on the topic using different methods to produce the initial drafts of the review articles. The first review article was written in the traditional manner by humans, the second was to be written exclusively using ChatGPT (AI-only or AIO), and the third approach was to input the outline and references selected by humans from approach 1 into ChatGPT, using the AI to assist in completing the writing (AI-assisted or AIA). All review articles were extensively fact-checked and edited by all co-authors leading to the final drafts of the manuscripts, which were significantly different from the initial drafts. Recent Findings Unfortunately, during this process, it became clear that approach 2 was not feasible for a very recent topic like COVID-19 as at the time, ChatGPT 4.0 had a cutoff date of September 2021 and all articles published after this date had to be provided to ChatGPT, making approaches 2 and 3 virtually identical. Therefore, only two approaches and two review articles were written (human and AI-assisted). Here we found that the human-only approach took less time to complete than the AI-assisted approach. This was largely due to the number of hours required to fact-check and edit the AI-assisted manuscript. Of note, the AI-assisted approach resulted in inaccurate attributions of references (about 20%) and had a higher similarity index suggesting an increased risk of plagiarism. Summary The main aim of this project was to determine whether the use of AI could improve the process of writing a scientific review article. Based on our experience, with the current state of technology, it would not be advised to solely use AI to write a scientific review article, especially on a recent topic.","['large language model, ChatGPT 4.0']"
2024,https://openalex.org/W4390881691,Psychology,"Uncertainty Reduction in Flood Susceptibility Mapping Using Random Forest and eXtreme Gradient Boosting Algorithms in Two Tropical Desert Cities, Shibam and Marib, Yemen","Flooding is a natural disaster that coexists with human beings and causes severe loss of life and property worldwide. Although numerous studies for flood susceptibility modelling have been introduced, a notable gap has been the overlooked or reduced consideration of the uncertainty in the accuracy of the produced maps. Challenges such as limited data, uncertainty due to confidence bounds, and the overfitting problem are critical areas for improving accurate models. We focus on the uncertainty in susceptibility mapping, mainly when there is a significant variation in the predictive relevance of the predictor factors. It is also noted that the receiver operating characteristic (ROC) curve may not accurately depict the sensitivity of the resulting susceptibility map to overfitting. Therefore, reducing the overfitting problem was targeted to increase accuracy and improve processing time in flood prediction. This study created a spatial repository to test the models, containing data from historical flooding and twelve topographic and geo-environmental flood conditioning variables. Then, we applied random forest (RF) and extreme gradient boosting (XGB) algorithms to map flood susceptibility, incorporating a variable drop-off in the empirical loop function. The results showed that the drop-off loop function was a crucial method to resolve the model uncertainty associated with the conditioning factors of the susceptibility modelling and methods. The results showed that approximately 8.42% to 9.89% of Marib City and 9.93% to 15.69% of Shibam City areas were highly vulnerable to floods. Furthermore, this study significantly contributes to worldwide endeavors focused on reducing the hazards linked to natural disasters. The approaches used in this study can offer valuable insights and strategies for reducing natural disaster risks, particularly in Yemen.","['random forest (RF)', 'extreme gradient boosting (XGB)']"
2024,https://openalex.org/W4390959437,Psychology,Machine learning model (RG-DMML) and ensemble algorithm for prediction of students’ retention and graduation in education,"Automated prediction of students' retention and graduation in education using advanced analytical methods such as artificial intelligence (AI), has recently attracted the attention of educators, both in theory and in practice. Whereas invaluable insights and theories for measuring and testing the topic have been proposed, most of the existing methods do not technically highlight the non-trivial factors behind the renowned challenges and attrition. To this effect, by making use of two categories of data collected in a higher education setting about students (i) retention (n = 52262) and (ii) graduation (n = 53639); this study proposes a machine learning model - RG-DMML (retention and graduation data mining and machine learning) and ensemble algorithm for prediction of students' retention and graduation status in education. This was done by training and testing key features that are technically deemed suitable for measuring the constructs (retention and graduation), such as (i) the Average grade of the previous high school, and (ii) the Entry/admission score. The proposed model (RG-DMML) is designed based on the cross industry standard process for data mining (CRISP-DM) methodology, implemented using supervised machine learning technique such as K-Nearest Neighbor (KNN), and validated using the k-fold cross-validation method. The results show that the executed model and algorithm based on the Bagging method and 10-fold cross-validation are efficient and effective for predicting the student's retention and graduation status, with Precision (retention = 0.909, graduation = 0.822), Recall (retention = 1.000, graduation = 0.957), Accuracy (retention = 0.909, graduation = 0.817), F1-Score (retention = 0.952, graduation = 0.885) showing significant high accuracy levels or performance rate, and low Error-rate (retention = 0.090, graduation = 0.182), respectively. In addition, by considering the individual features selected through the Wrapper method in predicting the outputs, the proposed model proved more effective for predicting the students' retention status in comparison to the graduation data. The implications of the models' output and factors that impact the effective prediction or identification of at-risk students, e.g., for timely intervention, counselling, decision-making, and sustainable educational practice are empirically discussed in the study.","['ensemble algorithm', 'supervised machine learning technique', 'K-Nearest Neighbor (KNN)', 'Wrapper method']"
2024,https://openalex.org/W4391649643,Psychology,Diagnosis of Alzheimer's disease via optimized lightweight convolution-attention and structural MRI,"Alzheimer's disease (AD) poses a substantial public health challenge, demanding accurate screening and diagnosis. Identifying AD in its early stages, including mild cognitive impairment (MCI) and healthy control (HC), is crucial given the global aging population. Structural magnetic resonance imaging (sMRI) is essential for understanding the brain's structural changes due to atrophy. While current deep learning networks overlook voxel long-term dependencies, vision transformers (ViT) excel at recognizing such dependencies in images, making them valuable in AD diagnosis. Our proposed method integrates convolution-attention mechanisms in transformer-based classifiers for AD brain datasets, enhancing performance without excessive computing resources. Replacing multi-head attention with lightweight multi-head self-attention (LMHSA), employing inverted residual (IRU) blocks, and introducing local feed-forward networks (LFFN) yields exceptional results. Training on AD datasets with a gradient-centralized optimizer and Adam achieves an impressive accuracy rate of 94.31% for multi-class classification, rising to 95.37% for binary classification (AD vs. HC) and 92.15% for HC vs. MCI. These outcomes surpass existing AD diagnosis approaches, showcasing the model's efficacy. Identifying key brain regions aids future clinical solutions for AD and neurodegenerative diseases. However, this study focused exclusively on the AD Neuroimaging Initiative (ADNI) cohort, emphasizing the need for a more robust, generalizable approach incorporating diverse databases beyond ADNI in future research.","['vision transformers (ViT)', 'convolution-attention mechanisms in transformer-based classifiers', 'lightweight multi-head self-attention (LMHSA)', 'Adam']"
2024,https://openalex.org/W4392955615,Psychology,Variation in social media sensitivity across people and contexts,"Abstract Social media impacts people’s wellbeing in different ways, but relatively little is known about why this is the case. Here we introduce the construct of “social media sensitivity” to understand how social media and wellbeing associations differ across people and the contexts in which these platforms are used. In a month-long large-scale intensive longitudinal study (total n = 1632; total number of observations = 120,599), we examined for whom and under which circumstances social media was associated with positive and negative changes in social and affective wellbeing. Applying a combination of frequentist and Bayesian multilevel models, we found a small negative average association between social media use AND subsequent wellbeing, but the associations were heterogenous across people. People with psychologically vulnerable dispositions (e.g., those who were depressed, lonely, not satisfied with life) tended to experience heightened negative social media sensitivity in comparison to people who were not psychologically vulnerable. People also experienced heightened negative social media sensitivity when in certain types of places (e.g., in social places, in nature) and while around certain types of people (e.g., around family members, close ties), as compared to using social media in other contexts. Our results suggest that an understanding of the effects of social media on wellbeing should account for the psychological dispositions of social media users, and the physical and social contexts surrounding their use. We discuss theoretical and practical implications of social media sensitivity for scholars, policymakers, and those in the technology industry.",['Bayesian multilevel models']
2024,https://openalex.org/W4398130977,Psychology,Imagined Speech-EEG Detection Using Multivariate Swarm Sparse Decomposition-Based Joint Time-Frequency Analysis for Intuitive BCI,"In brain-computer interface (BCI) applications, imagined speech (IMS) decoding based on electroencephalography (EEG) has established a new neuro-paradigm that offers an intuitive communication tool for physically impaired patients.However, existing IMS-EEG-based BCI systems have introduced difficulties in feasible deployment due to nonstationary EEG signals, suboptimal feature extraction, and constrained multi-class scalability.To address these challenges, we have presented a novel approach using the multivariate swarm-sparse decomposition method (MSSDM) for joint time-frequency (JTF) analysis and further developed a feasible end-to-end framework from multichannel IMS-EEG signals for imagined speech detection.MSSDM employs improved multivariate swarm filtering and sparse spectrum techniques to design optimal filter banks for extracting an ensemble of channel-aligned oscillatory components (CAOCs), significantly enhancing IMS activation-related sub-bands.To enhance channelaligned information, multivariate JTF images have been constructed using joint instantaneous frequency and instantaneous amplitude across channels from the obtained CAOCs.Further, JTFbased deep features (JTFDF) were computed using different pretrained neural networks and mapped most discriminant features using two well-known feature correlation techniques: Canonical correlation analysis and Hellinger distance-based correlation.The proposed method has been tested on the 5-class BCI Competition DB and 6-class Coretto DB IMS datasets.The experimental findings on cross-subject reveal that the novel JTFDF feature-based classification model, MSSDM-SqueezeNet-JTFDF, achieved the highest classification performance against all other existing state-of-theart methods in imagined speech recognition.","['sparse spectrum techniques', 'pretrained neural networks', 'Canonical correlation analysis']"
2024,https://openalex.org/W4390953182,Psychology,ERTNet: an interpretable transformer-based framework for EEG emotion recognition,"Background Emotion recognition using EEG signals enables clinicians to assess patients’ emotional states with precision and immediacy. However, the complexity of EEG signal data poses challenges for traditional recognition methods. Deep learning techniques effectively capture the nuanced emotional cues within these signals by leveraging extensive data. Nonetheless, most deep learning techniques lack interpretability while maintaining accuracy. Methods We developed an interpretable end-to-end EEG emotion recognition framework rooted in the hybrid CNN and transformer architecture. Specifically, temporal convolution isolates salient information from EEG signals while filtering out potential high-frequency noise. Spatial convolution discerns the topological connections between channels. Subsequently, the transformer module processes the feature maps to integrate high-level spatiotemporal features, enabling the identification of the prevailing emotional state. Results Experiments’ results demonstrated that our model excels in diverse emotion classification, achieving an accuracy of 74.23% ± 2.59% on the dimensional model (DEAP) and 67.17% ± 1.70% on the discrete model (SEED-V). These results surpass the performances of both CNN and LSTM-based counterparts. Through interpretive analysis, we ascertained that the beta and gamma bands in the EEG signals exert the most significant impact on emotion recognition performance. Notably, our model can independently tailor a Gaussian-like convolution kernel, effectively filtering high-frequency noise from the input EEG data. Discussion Given its robust performance and interpretative capabilities, our proposed framework is a promising tool for EEG-driven emotion brain-computer interface.","['hybrid CNN and transformer architecture', 'temporal convolution', 'spatial convolution', 'transformer module', 'CNN', 'LSTM']"
2024,https://openalex.org/W4393218816,Psychology,A study on smart home use intention of elderly consumers based on technology acceptance models,"Purpose Smart home devices have great potential to improve the quality of life and independence of older people, positively impacting their health, safety, and comfort. However, Chinese research in this field is still in its early stages. Therefore, more comprehensive and in-depth studies are needed to comprehend the various aspects influencing the acceptance and use of smart homes by older users. Patients and methods This study adopted the Technology Acceptance Model (TAM) and included perceived usefulness, perceived ease of use, usage intention, intergenerational technology support, perceived value, and perceived risk as extension variables to delve deeper into the behavioral intentions of older users in smart home services. The study used a convenience sampling method to randomly distribute 236 questionnaires among older adults over the age of 60 in the school’s community and neighboring urban communities who have experience in smart home use and who can complete human-computer interactions either independently or with the help of others, mainly focusing on the four sections: user characteristics, family situation, experience of use, and usage intention. The study used structural equation modeling (SEM) and factor analysis to analyze the completion of questionnaires. Finally, we conducted a validation analysis of the rationality and scientificity of the model and derived the six dimensions of the model of the influencing factors on the use of smart home products by the elderly and the weight sizes of their corresponding 13 influencing factors. Results The results show that perceived usefulness and perceived ease of use have a positive effect on users’ intention to use smart homes. Perceived ease of use has a positive effect on the perceived usefulness of smart homes. In addition, intergenerational technology support, perceived value, and perceived risk impact users’ perceived usefulness and perceived ease of use of the smart home. Conclusion This research aims to describe the factors influencing older users’ willingness to use smart homes. The findings are not only significant for the elderly in China but also of broad value to other regions and countries facing similar demographic challenges. The development of smart homes not only involves the elderly but is also closely related to all segments of society. The government should increase policy support and guide more social forces to participate in the development of the smart home industry. Service providers and designers should fully understand the demand situation and user experience of target users to develop easy-to-use smart home solutions. At the same time, smart homes, as intelligent products for the elderly, need to focus not only on the basic needs of the elderly such as material life and home safety, but also on the spiritual needs of elderly users. Children or caregivers should always pay attention to the psychological state of the elderly and actively guide them to use smart homes to help them realize their self-worth. We look forward to more research focusing on this area in the future and further exploring the specific issues and solutions involved.",['factor analysis']
2024,https://openalex.org/W4400726844,Psychology,Enhancing Brain Tumor Classification by a Comprehensive Study on Transfer Learning Techniques and Model Efficiency Using MRI Datasets,"Brain tumors, a significant health concern, are a leading cause of mortality globally, with an annual projected increase of 5% by the World Health Organization. This work aims to comprehensively analyze the performance of transfer learning methods in identifying the types of brain tumors, with a particular emphasis on the necessity of prompt identification. The study demonstrates how useful it is to use pre-trained models, including models VGG-16, VGG-19, Inception-v3, ResNet-50, DenseNet, and MobileNet—on MRI datasets and used to obtain a precise classification. Using these methods model accuracy and efficiency have been enhanced. The research aims to contribute to improved treatment planning and patient outcomes by implementing optimal methodologies for precise and automated brain tumor analysis, evaluation framework encompasses vital metrics such as confusion matrices, ROC curves, and the achieved Area Under the Curve (AUC) for each approach. The comprehensive methodology outlined in this paper serves as a systematic guide for the implementation and evaluation of brain tumor classification models utilizing deep learning techniques. The integration of visual representations, code snippets, and performance metrics significantly enhances the clarity and understanding of the proposed approach. Among our proposed algorithms, VGG-16 attains the highest accuracy at 97% and consumes only 22% of time as compared to our previous proposed methodology.","['transfer learning', 'VGG-16', 'VGG-19', 'Inception-v3', 'ResNet-50', 'DenseNet', 'MobileNet']"
2024,https://openalex.org/W4390771316,Psychology,Building typology classification using convolutional neural networks utilizing multiple ground-level image process for city-scale rapid seismic vulnerability assessment,"Several studies have focused on generating seismic vulnerability maps for earthquake-prone areas, particularly in Indonesia. Building typologies are a key factor in determining vulnerability to earthquakes. However, conducting large-scale field surveys to determine the spatial distribution of building typologies in a city is uneconomical. This paper explores the use of a convolutional neural network (CNN) to automatically detect building typologies from diverse regions in Indonesia, utilizing both conventional and automated building image acquisition processes. In this study, datasets from three distinct image acquisition methods are trained with four unique CNN architectures to identify the best-performing model to classify building typologies. The sample size effect on CNN performance is also investigated. The results showed that randomly sampled Google Street View (GSV) images are the most effective dataset for the CNN model, achieving an f1-score of 84.33%. Among the network architectures tested, MobileNet demonstrated superior performance on the majority of evaluated datasets. As the sample size increases by about 350% in the dataset, there is a positive correlation with up to 2.3% f1-score improvement. Using the best-performing CNN model, two building vulnerability models were employed to assess the spatial distribution of building damage in the urban area of Bandung, considering a hypothetical scenario of an M7 earthquake. Incorporating local construction data, one of the generated maps estimated that approximately 55% of buildings in Bandung would experience moderate to severe structural damage. This study showcases the potential of CNN models in automating regional seismic assessments and providing valuable insights for comprehensive seismic mitigation strategies.","['convolutional neural network (CNN)', 'CNN architectures', 'MobileNet']"
2024,https://openalex.org/W4390817372,Psychology,Brain structure ages—A new biomarker for multi‐disease classification,"Age is an important variable to describe the expected brain's anatomy status across the normal aging trajectory. The deviation from that normative aging trajectory may provide some insights into neurological diseases. In neuroimaging, predicted brain age is widely used to analyze different diseases. However, using only the brain age gap information (i.e., the difference between the chronological age and the estimated age) can be not enough informative for disease classification problems. In this paper, we propose to extend the notion of global brain age by estimating brain structure ages using structural magnetic resonance imaging. To this end, an ensemble of deep learning models is first used to estimate a 3D aging map (i.e., voxel-wise age estimation). Then, a 3D segmentation mask is used to obtain the final brain structure ages. This biomarker can be used in several situations. First, it enables to accurately estimate the brain age for the purpose of anomaly detection at the population level. In this situation, our approach outperforms several state-of-the-art methods. Second, brain structure ages can be used to compute the deviation from the normal aging process of each brain structure. This feature can be used in a multi-disease classification task for an accurate differential diagnosis at the subject level. Finally, the brain structure age deviations of individuals can be visualized, providing some insights about brain abnormality and helping clinicians in real medical contexts.",['ensemble of deep learning models']
2024,https://openalex.org/W4391350390,Psychology,"Machine learning in physical activity, sedentary, and sleep behavior research","Abstract The nature of human movement and non-movement behaviors is complex and multifaceted, making their study complicated and challenging. Thanks to the availability of wearable activity monitors, we can now monitor the full spectrum of physical activity, sedentary, and sleep behaviors better than ever before—whether the subjects are elite athletes, children, adults, or individuals with pre-existing medical conditions. The increasing volume of generated data, combined with the inherent complexities of human movement and non-movement behaviors, necessitates the development of new data analysis methods for the research of physical activity, sedentary, and sleep behaviors. The characteristics of machine learning (ML) methods, including their ability to deal with complicated data, make them suitable for such analysis and thus can be an alternative tool to deal with data of this nature. ML can potentially be an excellent tool for solving many traditional problems related to the research of physical activity, sedentary, and sleep behaviors such as activity recognition, posture detection, profile analysis, and correlates research. However, despite this potential, ML has not yet been widely utilized for analyzing and studying these behaviors. In this review, we aim to introduce experts in physical activity, sedentary behavior, and sleep research—individuals who may possess limited familiarity with ML—to the potential applications of these techniques for analyzing their data. We begin by explaining the underlying principles of the ML modeling pipeline, highlighting the challenges and issues that need to be considered when applying ML. We then present the types of ML: supervised and unsupervised learning, and introduce a few ML algorithms frequently used in supervised and unsupervised learning. Finally, we highlight three research areas where ML methodologies have already been used in physical activity, sedentary behavior, and sleep behavior research, emphasizing their successes and challenges. This paper serves as a resource for ML in physical activity, sedentary, and sleep behavior research, offering guidance and resources to facilitate its utilization.","['supervised learning', 'unsupervised learning']"
2024,https://openalex.org/W4391509840,Psychology,A dynamic Bayesian optimized active recommender system for curiosity-driven partially Human-in-the-loop automated experiments,"Abstract Optimization of experimental materials synthesis and characterization through active learning methods has been growing over the last decade, with examples ranging from measurements of diffraction on combinatorial alloys at synchrotrons, to searches through chemical space with automated synthesis robots for perovskites. In virtually all cases, the target property of interest for optimization is defined a priori with the ability to shift the trajectory of the optimization based on human-identified findings during the experiment is lacking. Thus, to highlight the best of both human operators and AI-driven experiments, here we present the development of a human–AI collaborated experimental workflow, via a Bayesian optimized active recommender system (BOARS), to shape targets on the fly with human real-time feedback. Here, the human guidance overpowers AI at early iteration when prior knowledge (uncertainty) is minimal (higher), while the AI overpowers the human during later iterations to accelerate the process with the human-assessed goal. We showcase examples of this framework applied to pre-acquired piezoresponse force spectroscopy of a ferroelectric thin film, and in real-time on an atomic force microscope, with human assessment to find symmetric hysteresis loops. It is found that such features appear more affected by subsurface defects than the local domain structure. This work shows the utility of human–AI approaches for curiosity driven exploration of systems across experimental domains.",['active learning']
2024,https://openalex.org/W4391930362,Psychology,Designing AI for mental health diagnosis: challenges from sub-Saharan African value-laden judgements on mental health disorders,"Recently clinicians have become more reliant on technologies such as artificial intelligence (AI) and machine learning (ML) for effective and accurate diagnosis and prognosis of diseases, especially mental health disorders. These remarks, however, apply primarily to Europe, the USA, China and other technologically developed nations. Africa is yet to leverage the potential applications of AI and ML within the medical space. Sub-Saharan African countries are currently disadvantaged economically and infrastructure-wise. Yet precisely, these circumstances create significant opportunities for the deployment of medical AI, which has already been deployed in some places in the continent. However, while AI and ML have come with enormous promises in Africa, there are still challenges when it comes to successfully applying AI and ML designed elsewhere within the African context, especially in diagnosing mental health disorders. We argue, in this paper, that there ought not to be a homogeneous/generic design of AI and ML used in diagnosing mental health disorders. Our claim is grounded on the premise that mental health disorders cannot be diagnosed solely on 'factual evidence' but on both factual evidence and value-laden judgements of what constitutes mental health disorders in sub-Saharan Africa. For ML to play a successful role in diagnosing mental health disorders in sub-Saharan African medical spaces, with a precise focus on South Africa, we allude that it ought to understand what sub-Saharan Africans consider as mental health disorders, that is, the value-laden judgements of some conditions.",['machine learning (ML)']
2024,https://openalex.org/W4392130768,Psychology,EEG-based brain-computer interface methods with the aim of rehabilitating advanced stage ALS patients,"Amyotrophic Lateral Sclerosis (ALS) is a neurodegenerative disease that leads to progressive muscle weakness and paralysis, ultimately resulting in the loss of ability to communicate and control the environment. EEG-based Brain-Computer Interface (BCI) methods have shown promise in providing communication and control with the aim of rehabilitating ALS patients. In particular, P300-based BCI has been widely studied and used for ALS rehabilitation. Other EEG-based BCI methods, such as Motor Imagery (MI) based BCI and Hybrid BCI, have also shown promise in ALS rehabilitation. Nonetheless, EEG-based BCI methods hold great potential for improvement. This review article introduces and reviews FFT, WPD, CSP, CSSP, CSP, and GC feature extraction methods. The Common Spatial Pattern (CSP) is an efficient and common technique for extracting data properties used in BCI systems. In addition, Linear Discriminant Analysis (LDA), Support Vector Machine (SVM), Neural Networks (NN), and Deep Learning (DL) classification methods were introduced and reviewed. SVM is the most appropriate classifier due to its insensitivity to the curse of dimensionality. Also, DL is used in the design of BCI systems and is a good choice for BCI systems based on motor imagery with big datasets. Despite the progress made in the field, there are still challenges to overcome, such as improving the accuracy and reliability of EEG signal detection and developing more intuitive and user-friendly interfaces By using BCI, disabled patients can communicate with their caregivers and control their environment using various devices, including wheelchairs, and robotic arms.","['Linear Discriminant Analysis (LDA)', 'Support Vector Machine (SVM)', 'Neural Networks (NN)', 'Deep Learning (DL)']"
2024,https://openalex.org/W4392262143,Psychology,Brain Tumor Detection for Efficient Adaptation and Superior Diagnostic Precision by Utilizing MBConv-Finetuned-B0 and Advanced Deep Learning,"In the rapidly evolving landscape of medical imaging, our proposed work presents an innovative and efficient approach to brain tumor detection through advanced deep learning methodologies.Central to our methodology is the strategic utilization of pre-trained weights from the formidable MBConv-Finetuned-B0 model, initially honed on the expansive ImageNet dataset, providing a foundation rich in general visual knowledge.Our subsequent fine-tuning process targets specific layers relevant to brain tumor detection, introducing two distinct convolutional layers, MBConv 6, 55, and MBConv 6, 30, meticulously added to the MBConv-Finetuned-B0 base model.These layers are intricately designed to extract and refine features specific to brain tumors, ensuring a nuanced understanding of pathology and enhancing the model's discrimination and accuracy.The flexibility of our methodology is exemplified by the thoughtful consideration of two fine-tuning options: one that adjusts all layers of the model and another that selectively fine-tunes only the proposed layers.We conduct a detailed comparative analysis, including homogeneity and median feature values, placing our work in direct comparison with established techniques such as Ensemble Transfer Learning and Quantum Variational Classifier (ETL & QVC), Ultra-Light Deep Learning (ULDL) Model, Deep Convolutional Neural Network (DCNN), and Deep Learning and Image Processing (DLIP).The results showcase the model's proficiency, achieving an accuracy of 94%, precision of 84%, recall of 92%, F1 score of 88%, and an AUC-ROC of 96%.Notably, our model demonstrates superior performance in terms of homogeneity (vE Homogeneity: 0.93, vN Homogeneity: 0.91, Enhancement Homogeneity: 0.97) and median feature values (Median vE Feature Value: 0.82, Median vN Feature Value: 0.87, Median Enhancement Feature Value: 0.80), providing a comprehensive understanding of its effectiveness in capturing subtle nuances in brain tumor images.","['fine-tuning', 'Quantum Variational Classifier (QVC)', 'Deep Convolutional Neural Network (DCNN)']"
2024,https://openalex.org/W4394997844,Psychology,Revisiting drug–protein interaction prediction: a novel global–local perspective,"Abstract Motivation Accurate inference of potential drug–protein interactions (DPIs) aids in understanding drug mechanisms and developing novel treatments. Existing deep learning models, however, struggle with accurate node representation in DPI prediction, limiting their performance. Results We propose a new computational framework that integrates global and local features of nodes in the drug–protein bipartite graph for efficient DPI inference. Initially, we employ pre-trained models to acquire fundamental knowledge of drugs and proteins and to determine their initial features. Subsequently, the MinHash and HyperLogLog algorithms are utilized to estimate the similarity and set cardinality between drug and protein subgraphs, serving as their local features. Then, an energy-constrained diffusion mechanism is integrated into the transformer architecture, capturing interdependencies between nodes in the drug–protein bipartite graph and extracting their global features. Finally, we fuse the local and global features of nodes and employ multilayer perceptrons to predict the likelihood of potential DPIs. A comprehensive and precise node representation guarantees efficient prediction of unknown DPIs by the model. Various experiments validate the accuracy and reliability of our model, with molecular docking results revealing its capability to identify potential DPIs not present in existing databases. This approach is expected to offer valuable insights for furthering drug repurposing and personalized medicine research. Availability and implementation Our code and data are accessible at: https://github.com/ZZCrazy00/DPI.","['transformer architecture', 'multilayer perceptrons']"
2024,https://openalex.org/W4399563755,Psychology,Exploring the frontier: Transformer-based models in EEG signal analysis for brain-computer interfaces,"This review systematically explores the application of transformer-based models in EEG signal processing and brain-computer interface (BCI) development, with a distinct focus on ensuring methodological rigour and adhering to empirical validations within the existing literature. By examining various transformer architectures, such as the Temporal Spatial Transformer Network (TSTN) and EEG Conformer, this review delineates their capabilities in mitigating challenges intrinsic to EEG data, such as noise and artifacts, and their subsequent implications on decoding and classification accuracies across disparate mental tasks. The analytical scope extends to a meticulous examination of attention mechanisms within transformer models, delineating their role in illuminating critical temporal and spatial EEG features and facilitating interpretability in model decision-making processes. The discourse additionally encapsulates emerging works that substantiate the efficacy of transformer models in noise reduction of EEG signals and diversifying applications beyond the conventional motor imagery paradigm. Furthermore, this review elucidates evident gaps and propounds exploratory avenues in the applications of pre-trained transformers in EEG analysis and the potential expansion into real-time and multi-task BCI applications. Collectively, this review distils extant knowledge, navigates through the empirical findings, and puts forward a structured synthesis, thereby serving as a conduit for informed future research endeavours in transformer-enhanced, EEG-based BCI systems.","['transformer-based models', 'attention mechanisms within transformer models']"
2024,https://openalex.org/W4390725372,Psychology,A Novel EEG-Based Parkinson’s Disease Detection Model Using Multiscale Convolutional Prototype Networks,"Objective and accurate detection of Parkinson's disease (PD) is crucial for timely intervention and treatment. Electroencephalography (EEG) has been proven to characterize PD by measuring brain activity. In recent years, deep learning methods have gained great attention in automated PD detection, but their performance is limited by insufficient data samples. In this article, we propose a novel PD automated detection model named the multiscale convolutional prototype network (MCPNet), which integrates and improves upon multiscale convolutional neural networks (CNNs) and prototype learning. On the one hand, it employs multiscale CNNs to extract brain features from different scales, enhancing feature diversity and utilization. On the other hand, a prototype calibration strategy is introduced to mitigate the effect of data noise on prototype generation, improving the generalization performance of model. Multiple within-dataset and cross-dataset experiments on three different datasets demonstrate the effectiveness of our model in PD detection. The leave-one-subject-out (LOSO) results of within-dataset experiments show that MCPNet achieves an accuracy of 92.5%, a sensitivity of 93.1%, a specificity of 91.9%, and an AUC of 92.4% in cross-subject classification between PD patients and healthy controls. In the cross-dataset classification, the performance of MCPNet is somewhat weakened due to dataset variations. However, this weakening is partially compensated by introducing the prototype calibration strategy. With the introduction of the calibration strategy, the accuracy of cross-dataset classification increases to 90.2%, a 4.0% improvement compared to when it is not used. These results indicate that the proposed model may be a promising tool for automated PD diagnosis.","['multiscale convolutional neural networks (CNNs)', 'prototype learning']"
2024,https://openalex.org/W4391407181,Psychology,DiffMDD: A Diffusion-Based Deep Learning Framework for MDD Diagnosis Using EEG,"Major Depression Disorder (MDD) is a common yet destructive mental disorder that affects millions of people worldwide. Making early and accurate diagnosis of it is very meaningful. Recently, EEG, a non-invasive technique of recording spontaneous electrical activity of brains, has been widely used for MDD diagnosis. However, there are still some challenges in data quality and data size of EEG: (1) A large amount of noise is inevitable during EEG collection, making it difficult to extract discriminative features from raw EEG; (2) It is difficult to recruit a large number of subjects to collect sufficient and diverse data for model training. Both of the challenges cause the overfitting problem, especially for deep learning methods. In this paper, we propose DiffMDD, a diffusion-based deep learning framework for MDD diagnosis using EEG. Specifically, we extract more noise-irrelevant features to improve the model's robustness by designing the Forward Diffusion Noisy Training Module. Then we increase the size and diversity of data to help the model learn more generalized features by designing the Reverse Diffusion Data Augmentation Module. Finally, we re-train the classifier on the augmented dataset for MDD diagnosis. We conducted comprehensive experiments to test the overall performance and each module's effectiveness. The framework was validated on two public MDD diagnosis datasets, achieving the state-of-the-art performance.",['diffusion-based deep learning framework']
2024,https://openalex.org/W4391468027,Psychology,Predicting University Student Graduation Using Academic Performance and Machine Learning: A Systematic Literature Review,"Predicting university student graduation is a beneficial tool for both students and institutions. With the help of this predictive capacity, students may make well-informed decisions about their academic and career paths, and institutions can proactively identify students who may not graduate and offer tailored support to ensure their success. The use of machine learning for predicting university student graduation has drawn more attention in recent years. Large datasets of student academic performance data can be used to train machine learning algorithms to identify patterns that are applicable in predicting future outcomes. In accordance with some studies, this approach predicts student graduation with an accuracy rate as high as 90%. Many SLRs have been conducted in this field, but there are still limitations, including not discussing the predictive models and algorithms used, a lack of coverage of the machine learning algorithms applied, small database coverage, keyword selection that does not cover all synonyms relevant to the investigation, and less specific data collection transparency. By delving into the limitations of existing SLRs on this topic, this research not only enhances the understanding of machine learning applications in forecasting student graduation but also fills a crucial gap in the literature. The inclusion of weaknesses in current SLRs provides a foundation for justifying the need for this study, emphasizing the necessity of a more nuanced and comprehensive review to advance the field and guide future research efforts in smart learning environments. This research conducts a thorough systematic review of the existing literature on machine learning-based student graduation prediction models from 70 journal articles from 2018 through 2023 that are pertinent. This review includes the various machine learning algorithms that have been implemented, the various academic performance data that was obtained from students, and the effectiveness of the models that have been developed. It also discusses the difficulties and potential advantages of utilizing machine learning to predict student graduation. The review indicates that the most common approach employed is the prediction of students' academic performance, which relies on data obtained from the Learning Management System and Student Information System. The primary data utilized for prediction purposes consists Student retention and time of academic and behavioral information. Among the various algorithms employed, Support Vector Machine and Random Forest are the most commonly utilized. This study makes a significant contribution to the advancement of learner modules within the smart learning environment.","['Support Vector Machine', 'Random Forest']"
2024,https://openalex.org/W4391625720,Psychology,Combining artificial and human intelligence to manage cross-cultural knowledge in humanitarian logistics: a Yin–Yang dialectic systems view of knowledge creation,"Purpose Aiming to resolve cross-cultural paradoxes in combining artificial intelligence (AI) with human intelligence (HI) for international humanitarian logistics, this paper aims to adopt an unorthodox Yin–Yang dialectic approach to address how AI–HI interactions can be interpreted as a sophisticated cross-cultural knowledge creation (KC) system that enables more effective decision-making for providing humanitarian relief across borders. Design/methodology/approach This paper is conceptual and pragmatic in nature, whereas its structure design follows the requirements of a real impact study. Findings Based on experimental information and logical reasoning, the authors first identify three critical cross-cultural challenges in AI–HI collaboration: paradoxes of building a cross-cultural KC system, paradoxes of integrative AI and HI in moral judgement and paradoxes of processing moral-related information with emotions in AI–HI collaboration. Then applying the Yin–Yang dialectic to interpret Klir’s epistemological frame (1993), the authors propose an unconventional stratified system of cross-cultural KC for understanding integrative AI–HI decision-making for humanitarian logistics across cultures. Practical implications This paper aids not only in deeply understanding complex issues stemming from human emotions and cultural cognitions in the context of cross-border humanitarian logistics, but also equips culturally-diverse stakeholders to effectively navigate these challenges and their potential ramifications. It enhances the decision-making process and optimizes the synergy between AI and HI for cross-cultural humanitarian logistics. Originality/value The originality lies in the use of a cognitive methodology of the Yin–Yang dialectic to metaphorize the dynamic genesis of integrative AI-HI KC for international humanitarian logistics. Based on system science and knowledge management, this paper applies game theory, multi-objective optimization and Markov decision process to operationalize the conceptual framework in the context of cross-cultural humanitarian logistics.",['Markov decision process']
2024,https://openalex.org/W4390919701,Psychology,Chatbots and Large Language Models in Radiology: A Practical Primer for Clinical and Research Applications,"Although chatbots have existed for decades, the emergence of transformer-based large language models (LLMs) has captivated the world through the most recent wave of artificial intelligence chatbots, including ChatGPT. Transformers are a type of neural network architecture that enables better contextual understanding of language and efficient training on massive amounts of unlabeled data, such as unstructured text from the internet. As LLMs have increased in size, their improved performance and emergent abilities have revolutionized natural language processing. Since language is integral to human thought, applications based on LLMs have transformative potential in many industries. In fact, LLM-based chatbots have demonstrated human-level performance on many professional benchmarks, including in radiology. LLMs offer numerous clinical and research applications in radiology, several of which have been explored in the literature with encouraging results. Multimodal LLMs can simultaneously interpret text and images to generate reports, closely mimicking current diagnostic pathways in radiology. Thus, from requisition to report, LLMs have the opportunity to positively impact nearly every step of the radiology journey. Yet, these impressive models are not without limitations. This article reviews the limitations of LLMs and mitigation strategies, as well as potential uses of LLMs, including multimodal models. Also reviewed are existing LLM-based applications that can enhance efficiency in supervised settings.","['transformer-based large language models (LLMs)', 'Transformers', 'Multimodal LLMs']"
2024,https://openalex.org/W4399803256,Psychology,Detecting hallucinations in large language models using semantic entropy,"Abstract Large language model (LLM) systems, such as ChatGPT 1 or Gemini 2 , can show impressive reasoning and question-answering capabilities but often ‘hallucinate’ false outputs and unsubstantiated answers 3,4 . Answering unreliably or without the necessary information prevents adoption in diverse fields, with problems including fabrication of legal precedents 5 or untrue facts in news articles 6 and even posing a risk to human life in medical domains such as radiology 7 . Encouraging truthfulness through supervision or reinforcement has been only partially successful 8 . Researchers need a general method for detecting hallucinations in LLMs that works even with new and unseen questions to which humans might not know the answer. Here we develop new methods grounded in statistics, proposing entropy-based uncertainty estimators for LLMs to detect a subset of hallucinations—confabulations—which are arbitrary and incorrect generations. Our method addresses the fact that one idea can be expressed in many ways by computing uncertainty at the level of meaning rather than specific sequences of words. Our method works across datasets and tasks without a priori knowledge of the task, requires no task-specific data and robustly generalizes to new tasks not seen before. By detecting when a prompt is likely to produce a confabulation, our method helps users understand when they must take extra care with LLMs and opens up new possibilities for using LLMs that are otherwise prevented by their unreliability.",['entropy-based uncertainty estimators']
2024,https://openalex.org/W4392639864,Psychology,Comparing the quality of human and ChatGPT feedback of students’ writing,"Offering students formative feedback on their writing is an effective way to facilitate writing development. Recent advances in AI (i.e., ChatGPT) may function as an automated writing evaluation tool, increasing the amount of feedback students receive and diminishing the burden on teachers to provide frequent feedback to large classes. We examined the ability of generative AI (ChatGPT) to provide formative feedback. We compared the quality of human and AI feedback by scoring the feedback each provided on secondary student essays. We scored the degree to which feedback (a) was criteria-based, (b) provided clear directions for improvement, (c) was accurate, (d) prioritized essential features, and (e) used a supportive tone. 200 pieces of human-generated formative feedback and 200 pieces of AI-generated formative feedback for the same essays. We examined whether ChatGPT and human feedback differed in quality for the whole sample, for compositions that differed in overall quality, and for native English speakers and English learners by comparing descriptive statistics and effect sizes. Human raters were better at providing high-quality feedback to students in all categories other than criteria-based. AI and humans showed differences in feedback quality based on essay quality. Feedback did not vary by language status for humans or AI. Well-trained evaluators provided higher quality feedback than ChatGPT. Considering the ease of generating feedback through ChatGPT and its overall quality, generative AI may still be useful in some contexts, particularly in formative early drafts or instances where a well-trained educator is unavailable.",['generative AI (ChatGPT)']
2024,https://openalex.org/W4393252719,Psychology,Application of generative artificial intelligence (GenAI) in language teaching and learning: A scoping literature review,"This scoping literature review examines the application of Generative Artificial Intelligence (GenAI), a disruptive technology, in language teaching and learning. Since its launch in November 2022, GenAI has captured global attention with OpenAI's ChatGPT, powered by the generative pre-trained transformer-3 (GPT-3) large-language model. The emergence of GenAI holds immense implications across various domains, including language education. This review aims to provide an overview of the current state of research and identify research gaps and future directions in this emerging field. The review follows the PRISMA-ScR guidelines and includes eligible publications published between 2017 and July 2023. Four electronic databases were searched and 41 of the 224 initial papers were eventually selected for review. The findings reveal key terms related to GenAI in language education, the most researched language study and education levels, areas of research, attitudes towards GenAI, and the potential benefits and challenges of GenAI application. The review highlights several research gaps, including the need for more empirical studies to assess the effectiveness and impact of GenAI tools, discussion of ethical considerations, targeted interventions for specific language skills, and stakeholder engagement in responsible integration. Educators are encouraged to incorporate GenAI tools into their teaching practices while remaining vigilant about potential risks. Continuous professional development for educators is crucial to ensure informed decision-making and effective integration of GenAI tools. This scoping review contributes to the existing knowledge on the use of GenAI in language education and informs future research and practice in this disruptive and rapidly evolving field.",['generative pre-trained transformer-3 (GPT-3)']
2024,https://openalex.org/W4392791588,Psychology,Can large language models replace humans in systematic reviews? Evaluating <scp>GPT</scp>‐4's efficacy in screening and extracting data from peer‐reviewed and grey literature in multiple languages,"Systematic reviews are vital for guiding practice, research and policy, although they are often slow and labour-intensive. Large language models (LLMs) could speed up and automate systematic reviews, but their performance in such tasks has yet to be comprehensively evaluated against humans, and no study has tested Generative Pre-Trained Transformer (GPT)-4, the biggest LLM so far. This pre-registered study uses a ""human-out-of-the-loop"" approach to evaluate GPT-4's capability in title/abstract screening, full-text review and data extraction across various literature types and languages. Although GPT-4 had accuracy on par with human performance in some tasks, results were skewed by chance agreement and dataset imbalance. Adjusting for these caused performance scores to drop across all stages: for data extraction, performance was moderate, and for screening, it ranged from none in highly balanced literature datasets (~1:1) to moderate in those datasets where the ratio of inclusion to exclusion in studies was imbalanced (~1:3). When screening full-text literature using highly reliable prompts, GPT-4's performance was more robust, reaching ""human-like"" levels. Although our findings indicate that, currently, substantial caution should be exercised if LLMs are being used to conduct systematic reviews, they also offer preliminary evidence that, for certain review tasks delivered under specific conditions, LLMs can rival human performance.",['Generative Pre-Trained Transformer (GPT)-4']
2024,https://openalex.org/W4391473908,Psychology,Exploring AI-mediated informal digital learning of English (AI-IDLE): a mixed-method investigation of Chinese EFL learners’ AI adoption and experiences,"Recent advancements in natural language processing and large language models have ushered language learning into the age of artificial intelligence (AI). Recognizing the affordances of generative AI tools, this paper aims to examine the degree to which L2 learners accepted and leveraged large language model platforms (e.g. ChatGPT, Bing Chat) for the informal digital learning of English (IDLE) purposes. Employing an explanatory sequential mixed-method design, this study draws on the technology acceptance model (TAM) and collects data via an adapted TAM questionnaire and an interview guide. A total of 867 Chinese EFL (English as a foreign language) learners answered the online survey, while 20 attended the post-survey interviews. Drawing on a validated structural model that elucidates the inter-factor relationships of perceived ease of use, perceived usefulness, intention to use, and actual use, the quantitative analysis provides statistical accounts for EFL learners' adoption of Generative Pre-trained Transformer (GPT) technologies. The qualitative findings, derived from the interview data, reveal three key themes: (1) how perceived usefulness of chatbots for IDLE emerges from hands-on experimentation with these tools; (2) how intention to use increases as learners negotiate chatbot affordances and constraints; and (3) how actual use of chatbots for IDLE involves using these tools as tutors or conversation partners. Connections between quantitative and qualitative findings enhance our understanding of how EFL learners negotiate the affordances and constraints of highly capable AI technologies to participate in creative IDLE practices. By understanding these practices, this study draws attention to the attitudes and practices that constitute AI literacies, ultimately offering implications for future classroom practices and research.",['Generative Pre-trained Transformer (GPT)']
2024,https://openalex.org/W4394884079,Psychology,TRANSFORMING FINTECH FRAUD DETECTION WITH ADVANCED ARTIFICIAL INTELLIGENCE ALGORITHMS,"The rapid evolution of financial technology (fintech) platforms has exponentially increased the volume and sophistication of financial transactions, concurrently elevating the risk and complexity of fraudulent activities. This necessitates a paradigm shift in fraud detection methodologies towards more agile, accurate, and predictive solutions. This paper presents a comprehensive study on the transformative potential of advanced Artificial Intelligence (AI) algorithms in enhancing fintech fraud detection mechanisms. By leveraging cutting-edge AI techniques including deep learning, machine learning, and natural language processing, this research aims to develop a robust fraud detection framework capable of identifying, analyzing, and preventing fraudulent transactions in real-time.&#x0D; Our methodology encompasses the deployment of several AI algorithms on extensive datasets comprising genuine and fraudulent financial transactions. Through a comparative analysis, we identify the most effective algorithms in terms of accuracy, efficiency, and scalability. Key findings reveal that deep learning models, particularly those employing neural networks, outperform traditional machine learning models in detecting complex and nuanced fraudulent activities. Furthermore, the integration of natural language processing enables the extraction and analysis of unstructured data, significantly enhancing the detection capabilities.&#x0D; Conclusively, this paper underscores the critical role of advanced AI algorithms in revolutionizing fintech fraud detection. It highlights the superior performance of AI-based models over conventional methods, offering fintech platforms a more dynamic and predictive approach to fraud prevention. This research not only contributes to the academic discourse on financial security but also provides practical insights for fintech companies striving to safeguard their operations against fraud.&#x0D; Keywords: Artificial Intelligence, Fintech, Fraud Detection, Ethical Ai, Regulatory Compliance, Data Privacy, Algorithmic Bias, Predictive Analytics, Blockchain Technology, Quantum Computing, Interdisciplinary Collaboration, Innovation, Transparency, Accountability, Continuous Learning, Ethical Principles, Real-Time Processing, Financial Sector.","['deep learning', 'machine learning', 'neural networks']"
2024,https://openalex.org/W4392503764,Psychology,Mental-LLM,"Advances in large language models (LLMs) have empowered a variety of applications. However, there is still a significant gap in research when it comes to understanding and enhancing the capabilities of LLMs in the field of mental health. In this work, we present a comprehensive evaluation of multiple LLMs on various mental health prediction tasks via online text data, including Alpaca, Alpaca-LoRA, FLAN-T5, GPT-3.5, and GPT-4. We conduct a broad range of experiments, covering zero-shot prompting, few-shot prompting, and instruction fine-tuning. The results indicate a promising yet limited performance of LLMs with zero-shot and few-shot prompt designs for mental health tasks. More importantly, our experiments show that instruction finetuning can significantly boost the performance of LLMs for all tasks simultaneously. Our best-finetuned models, Mental-Alpaca and Mental-FLAN-T5, outperform the best prompt design of GPT-3.5 (25 and 15 times bigger) by 10.9% on balanced accuracy and the best of GPT-4 (250 and 150 times bigger) by 4.8%. They further perform on par with the state-of-the-art task-specific language model. We also conduct an exploratory case study on LLMs' capability on mental health reasoning tasks, illustrating the promising capability of certain models such as GPT-4. We summarize our findings into a set of action guidelines for potential methods to enhance LLMs' capability for mental health tasks. Meanwhile, we also emphasize the important limitations before achieving deployability in real-world mental health settings, such as known racial and gender bias. We highlight the important ethical risks accompanying this line of research.","['zero-shot prompting', 'few-shot prompting', 'instruction fine-tuning']"
2024,https://openalex.org/W4392239564,Psychology,Human-AI collaboration patterns in AI-assisted academic writing,"Artificial Intelligence (AI) has increasingly influenced higher education, notably in academic writing where AI-powered assisting tools offer both opportunities and challenges. Recently, the rapid growth of generative AI (GAI) has brought its impacts into sharper focus, yet the dynamics of its utilisation in academic writing remain largely unexplored. This paper focuses on examining the nature of human-AI interactions in academic writing, specifically investigating the strategies doctoral students employ when collaborating with a GAI-powered assisting tool. This study involves 626 recorded activities on how ten doctoral students interact with GAI-powered assisting tool during academic writing. AI-driven learning analytics approach was adopted for three layered analyses: (1) data pre-processing and analysis with quantitative content analysis, (2) sequence analysis with Hidden Markov Model (HMM) and hierarchical sequence clustering, and (3) pattern analysis with process mining. Findings indicate that doctoral students engaging in iterative, highly interactive processes with the GAI-powered assisting tool generally achieve better performance in the writing task. In contrast, those who use GAI merely as a supplementary information source, maintaining a linear writing approach, tend to get lower writing performance. This study points to the need for further investigations into human-AI collaboration in learning in higher education, with implications for tailored educational strategies and solutions.",['Hidden Markov Model (HMM)']
2024,https://openalex.org/W4392303127,Psychology,Recent advancements and challenges of NLP-based sentiment analysis: A state-of-the-art review,"Sentiment analysis is a method within natural language processing that evaluates and identifies the emotional tone or mood conveyed in textual data. Scrutinizing words and phrases categorizes them into positive, negative, or neutral sentiments. The significance of sentiment analysis lies in its capacity to derive valuable insights from extensive textual data, empowering businesses to grasp customer sentiments, make informed choices, and enhance their offerings. For the further advancement of sentiment analysis, gaining a deep understanding of its algorithms, applications, current performance, and challenges is imperative. Therefore, in this extensive survey, we began exploring the vast array of application domains for sentiment analysis, scrutinizing them within the context of existing research. We then delved into prevalent pre-processing techniques, datasets, and evaluation metrics to enhance comprehension. We also explored Machine Learning, Deep Learning, Large Language Models and Pre-trained models in sentiment analysis, providing insights into their advantages and drawbacks. Subsequently, we precisely reviewed the experimental results and limitations of recent state-of-the-art articles. Finally, we discussed the diverse challenges encountered in sentiment analysis and proposed future research directions to mitigate these concerns. This extensive review provides a complete understanding of sentiment analysis, covering its models, application domains, results analysis, challenges, and research directions.","['Machine Learning', 'Deep Learning']"
2024,https://openalex.org/W4390638955,Psychology,Artificial intelligence (AI) learning tools in K-12 education: A scoping review,"Abstract Artificial intelligence (AI) literacy is a global strategic objective in education. However, little is known about how AI should be taught. In this paper, 46 studies in academic conferences and journals are reviewed to investigate pedagogical strategies, learning tools, assessment methods in AI literacy education in K-12 contexts, and students’ learning outcomes. The investigation reveals that the promotion of AI literacy education has seen significant progress in the past two decades. This highlights that intelligent agents, including Google’s Teachable Machine, Learning ML, and Machine Learning for Kids, are age-appropriate tools for AI literacy education in K-12 contexts. Kindergarten students can benefit from learning tools such as PopBots, while software devices, such as Scratch and Python, which help to develop the computational thinking of AI algorithms, can be introduced to both primary and secondary schools. The research shows that project-based, human–computer collaborative learning and play- and game-based approaches, with constructivist methodologies, have been applied frequently in AI literacy education. Cognitive, affective, and behavioral learning outcomes, course satisfaction and soft skills acquisition have been reported. The paper informs educators of appropriate learning tools, pedagogical strategies, assessment methodologies in AI literacy education, and students’ learning outcomes. Research implications and future research directions within the K-12 context are also discussed.",['Teachable Machine']
2024,https://openalex.org/W4392251648,Psychology,A Comprehensive Survey on Source-Free Domain Adaptation,"Over the past decade, domain adaptation has become a widely studied branch of transfer learning which aims to improve performance on target domains by leveraging knowledge from the source domain. Conventional domain adaptation methods often assume access to both source and target domain data simultaneously, which may not be feasible in real-world scenarios due to privacy and confidentiality concerns. As a result, the research of Source-Free Domain Adaptation (SFDA) has drawn growing attention in recent years, which only utilizes the source-trained model and unlabeled target data to adapt to the target domain. Despite the rapid explosion of SFDA work, there has been no timely and comprehensive survey in the field. To fill this gap, we provide a comprehensive survey of recent advances in SFDA and organize them into a unified categorization scheme based on the framework of transfer learning. Instead of presenting each approach independently, we modularize several components of each method to more clearly illustrate their relationships and mechanisms in light of the composite properties of each method. Furthermore, we compare the results of more than 30 representative SFDA methods on three popular classification benchmarks, namely Office-31, Office-home, and VisDA, to explore the effectiveness of various technical routes and the combination effects among them. Additionally, we briefly introduce the applications of SFDA and related fields. Drawing on our analysis of the challenges confronting SFDA, we offer some insights into future research directions and potential settings.","['domain adaptation', 'transfer learning', 'Source-Free Domain Adaptation (SFDA)']"
2024,https://openalex.org/W4394009485,Psychology,AI-Driven Clinical Decision Support Systems: An Ongoing Pursuit of Potential,"Clinical Decision Support Systems (CDSS) are essential tools in contemporary healthcare, enhancing clinicians' decisions and patient outcomes. The integration of artificial intelligence (AI) is now revolutionizing CDSS even further. This review delves into AI technologies transforming CDSS, their applications in healthcare decision-making, associated challenges, and the potential trajectory toward fully realizing AI-CDSS's potential. The review begins by laying the groundwork with a definition of CDSS and its function within the healthcare field. It then highlights the increasingly significant role that AI is playing in enhancing CDSS effectiveness and efficiency, underlining its evolving prominence in shaping healthcare practices. It examines the integration of AI technologies into CDSS, including machine learning algorithms like neural networks and decision trees, natural language processing, and deep learning. It also addresses the challenges associated with AI integration, such as interpretability and bias. We then shift to AI applications within CDSS, with real-life examples of AI-driven diagnostics, personalized treatment recommendations, risk prediction, early intervention, and AI-assisted clinical documentation. The review emphasizes user-centered design in AI-CDSS integration, addressing usability, trust, workflow, and ethical and legal considerations. It acknowledges prevailing obstacles and suggests strategies for successful AI-CDSS adoption, highlighting the need for workflow alignment and interdisciplinary collaboration. The review concludes by summarizing key findings, underscoring AI's transformative potential in CDSS, and advocating for continued research and innovation. It emphasizes the need for collaborative efforts to realize a future where AI-powered CDSS optimizes healthcare delivery and improves patient outcomes.","['neural networks', 'decision trees', 'deep learning']"
2024,https://openalex.org/W4390667862,Psychology,Integration of Generative AI Techniques and Applications in Student Behavior and Cognitive Achievement in Arab Higher Education,"The integration of Artificial Intelligence (AI) in higher education has the power to revolutionize the learning experience by fostering engagement, personalization, efficiency, and innovation. AI offers a wide range of exciting possibilities where AI-powered tools enable students to receive tailored feedback and guidance, enabling them to learn at their own pace and excel academically. This research aims to investigate the effects of generative AI techniques and applications on students' cognitive achievement through student behavior. Data was collected through surveys in three Arab countries including Oman, Jordan and Yemen. 768 students from these Arab country's universities were participated in completing surveys randomly. Structure Equation Modeling SEM-PLS was adopted to analysis data. Results reveal that generative AI techniques and applications have positive and significant effects on students' cognitive achievement in Arab higher education institutions. Results also reveal that student behavior enhances the relationship among AI techniques, applications and cognitive achievement. These results highlight the crucial role of AI applications among students in higher education while the integration of this emerging technology is still at the first stage, students' interaction with and utility of these applications show high satisfactory level of their impact on students' behavior and cognitive achievement. This research contributes to literature of generative AI applications giving evidence from Arab region and filling the gap regarding usage of these applications in higher education.",['generative AI techniques']
2024,https://openalex.org/W4398203672,Psychology,Hallucination Rates and Reference Accuracy of ChatGPT and Bard for Systematic Reviews: Comparative Analysis,"Background Large language models (LLMs) have raised both interest and concern in the academic community. They offer the potential for automating literature search and synthesis for systematic reviews but raise concerns regarding their reliability, as the tendency to generate unsupported (hallucinated) content persist. Objective The aim of the study is to assess the performance of LLMs such as ChatGPT and Bard (subsequently rebranded Gemini) to produce references in the context of scientific writing. Methods The performance of ChatGPT and Bard in replicating the results of human-conducted systematic reviews was assessed. Using systematic reviews pertaining to shoulder rotator cuff pathology, these LLMs were tested by providing the same inclusion criteria and comparing the results with original systematic review references, serving as gold standards. The study used 3 key performance metrics: recall, precision, and F1-score, alongside the hallucination rate. Papers were considered “hallucinated” if any 2 of the following information were wrong: title, first author, or year of publication. Results In total, 11 systematic reviews across 4 fields yielded 33 prompts to LLMs (3 LLMs×11 reviews), with 471 references analyzed. Precision rates for GPT-3.5, GPT-4, and Bard were 9.4% (13/139), 13.4% (16/119), and 0% (0/104) respectively (P&lt;.001). Recall rates were 11.9% (13/109) for GPT-3.5 and 13.7% (15/109) for GPT-4, with Bard failing to retrieve any relevant papers (P&lt;.001). Hallucination rates stood at 39.6% (55/139) for GPT-3.5, 28.6% (34/119) for GPT-4, and 91.4% (95/104) for Bard (P&lt;.001). Further analysis of nonhallucinated papers retrieved by GPT models revealed significant differences in identifying various criteria, such as randomized studies, participant criteria, and intervention criteria. The study also noted the geographical and open-access biases in the papers retrieved by the LLMs. Conclusions Given their current performance, it is not recommended for LLMs to be deployed as the primary or exclusive tool for conducting systematic reviews. Any references generated by such models warrant thorough validation by researchers. The high occurrence of hallucinations in LLMs highlights the necessity for refining their training and functionality before confidently using them for rigorous academic purposes.","['GPT-3.5', 'GPT-4']"
2024,https://openalex.org/W4392119583,Psychology,Object detection and tracking in Precision Farming: a systematic review,"Object Detection and Tracking have gained importance in recent years because of the great advances in image and video analysis techniques and the accurate results these technologies are producing. Moreover, they have successfully been applied to multiple fields, including the agricultural domain since they offer real-time monitoring of the status of the crops and animals while counting how many are present within a field/barn. This review aims to review the current literature on Object Detection and Tracking within the field of Precision Farming. For that, over 300 research articles were explored, from which 150 articles from the last five years were systematically reviewed and analysed regarding the algorithms they implemented, the domain they belong to, the difficulties they faced, and which limitations should be tackled in the future. Lastly, it examines potential issues that this approach might have, for instance, the lack of open-source datasets with labelled data. The findings of this study indicate that Object Detection and Tracking are critical techniques to enhance Precision Farming and pave the way for robotization for the agricultural sector since they provide accurate results and insights on crop and animal management, and optimize resource allocation. Future work should focus on the optimal acquisition of the datasets prior to Object Detection and Tracking, along with the consideration of the biophysical environment of the farming scenarios.",['Object Detection']
2024,https://openalex.org/W4392202731,Psychology,Applying large language models and chain-of-thought for automatic scoring,"This study investigates the application of large language models (LLMs), specifically GPT-3.5 and GPT-4, with Chain-of-Though (CoT) in the automatic scoring of student-written responses to science assessments. We focused on overcoming the challenges of accessibility, technical complexity, and lack of explainability that have previously limited the use of artificial intelligence-based automatic scoring tools among researchers and educators. With a testing dataset comprising six assessment tasks (three binomial and three trinomial) with 1650 student responses, we employed six prompt engineering strategies to automatically score student responses. The six strategies combined zero-shot or few-shot learning with CoT, either alone or alongside item stem and scoring rubrics, developed based on a novel approach, WRVRT (prompt writing, reviewing, validating, revising, and testing). Results indicated that few-shot (acc = 0.67) outperformed zero-shot learning (acc = 0.60), with 12.6% increase. CoT, when used without item stem and scoring rubrics, did not significantly affect scoring accuracy (acc = 0.60). However, CoT prompting paired with contextual item stems and rubrics proved to be a significant contributor to scoring accuracy (13.44% increase for zero-shot; 3.7% increase for few-shot). We found a more balanced accuracy across different proficiency categories when CoT was used with a scoring rubric, highlighting the importance of domain-specific reasoning in enhancing the effectiveness of LLMs in scoring tasks. We also found that GPT-4 demonstrated superior performance over GPT -3.5 in various scoring tasks when combined with the single-call greedy sampling or ensemble voting nucleus sampling strategy, showing 8.64% difference. Particularly, the single-call greedy sampling strategy with GPT-4 outperformed other approaches. This study also demonstrates the potential of LLMs in facilitating explainable and interpretable automatic scoring, emphasizing that CoT enhances accuracy and transparency, particularly when used with item stem and scoring rubrics.","['GPT-3.5', 'GPT-4', 'Chain-of-Thought (CoT)', 'zero-shot learning', 'few-shot learning']"
2024,https://openalex.org/W4391103530,Psychology,Transformative Breast Cancer Diagnosis using CNNs with Optimized ReduceLROnPlateau and Early Stopping Enhancements,"Abstract Breast cancer stands as a paramount public health concern worldwide, underscoring an imperative necessity within the research sphere for precision-driven and efficacious methodologies facilitating accurate detection. The existing diagnostic approaches in breast cancer often suffer from limitations in accuracy and efficiency, leading to delayed detection and subsequent challenges in personalized treatment planning. The primary focus of this research is to overcome these shortcomings by harnessing the power of advanced deep learning techniques, thereby revolutionizing the precision and reliability of breast cancer classification. This research addresses the critical need for improved breast cancer diagnostics by introducing a novel Convolutional Neural Network (CNN) model integrated with an Early Stopping callback and ReduceLROnPlateau callback. By enhancing the precision and reliability of breast cancer classification, the study aims to overcome the limitations of existing diagnostic methods, ultimately leading to better patient outcomes and reduced mortality rates. The comprehensive methodology includes diverse datasets, meticulous image preprocessing, robust model training, and validation strategies, emphasizing the model's adaptability and reliability in varied clinical contexts. The findings showcase the CNN model's exceptional performance, achieving a 95.2% accuracy rate in distinguishing cancerous and non-cancerous breast tissue in the integrated dataset, thereby demonstrating its potential for enhancing clinical decision-making and fostering the development of AI-driven diagnostic solutions.","['Convolutional Neural Network (CNN)', 'Early Stopping callback']"
2024,https://openalex.org/W4393160204,Psychology,Detecting and Preventing Hallucinations in Large Vision Language Models,"Instruction tuned Large Vision Language Models (LVLMs) have significantly advanced in generalizing across a diverse set of multi-modal tasks, especially for Visual Question Answering (VQA). However, generating detailed responses that are visually grounded is still a challenging task for these models. We find that even the current state-of-the-art LVLMs (InstructBLIP) still contain a staggering 30 percent of the hallucinatory text in the form of non-existent objects, unfaithful descriptions, and inaccurate relationships. To address this, we introduce M-HalDetect, a Multimodal Hallucination Detection Dataset that can be used to train and benchmark models for hallucination detection and prevention. M-HalDetect consists of 16k fine-grained annotations on VQA examples, making it the first comprehensive multi-modal hallucination detection dataset for detailed image descriptions. Unlike previous work that only consider object hallucination, we additionally annotate both entity descriptions and relationships that are unfaithful. To demonstrate the potential of this dataset for hallucination prevention, we optimize InstructBLIP through our novel Fine-grained Direct Preference Optimization (FDPO). We also train fine-grained multi-modal reward models from InstructBLIP and evaluate their effectiveness with best-of-n rejection sampling (RS). We perform human evaluation on both FDPO and rejection sampling, and find that they reduce hallucination rates in InstructBLIP by 41% and 55% respectively. We also find that our reward model generalizes to other multi-modal models, reducing hallucinations in LLaVA and mPLUG-OWL by 15% and 57% respectively, and has strong correlation with human evaluated accuracy scores. The dataset is available at https://github.com/hendryx-scale/mhal-detect.",['Instruction tuned Large Vision Language Models (LVLMs)']
2024,https://openalex.org/W4392462461,Psychology,Sentiment Analysis in the Age of Generative AI,"Abstract In the rapidly advancing age of Generative AI, Large Language Models (LLMs) such as ChatGPT stand at the forefront of disrupting marketing practice and research. This paper presents a comprehensive exploration of LLMs’ proficiency in sentiment analysis, a core task in marketing research for understanding consumer emotions, opinions, and perceptions. We benchmark the performance of three state-of-the-art LLMs, i.e., GPT-3.5, GPT-4, and Llama 2, against established, high-performing transfer learning models. Despite their zero-shot nature, our research reveals that LLMs can not only compete with but in some cases also surpass traditional transfer learning methods in terms of sentiment classification accuracy. We investigate the influence of textual data characteristics and analytical procedures on classification accuracy, shedding light on how data origin, text complexity, and prompting techniques impact LLM performance. We find that linguistic features such as the presence of lengthy, content-laden words improve classification performance, while other features such as single-sentence reviews and less structured social media text documents reduce performance. Further, we explore the explainability of sentiment classifications generated by LLMs. The findings indicate that LLMs, especially Llama 2, offer remarkable classification explanations, highlighting their advanced human-like reasoning capabilities. Collectively, this paper enriches the current understanding of sentiment analysis, providing valuable insights and guidance for the selection of suitable methods by marketing researchers and practitioners in the age of Generative AI.","['GPT-3.5', 'GPT-4', 'Llama 2', 'transfer learning models']"
2024,https://openalex.org/W4393154152,Psychology,NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models,"Trained with an unprecedented scale of data, large language models (LLMs) like ChatGPT and GPT-4 exhibit the emergence of significant reasoning abilities from model scaling. Such a trend underscored the potential of training LLMs with unlimited language data, advancing the development of a universal embodied agent. In this work, we introduce the NavGPT, a purely LLM-based instruction-following navigation agent, to reveal the reasoning capability of GPT models in complex embodied scenes by performing zero-shot sequential action prediction for vision-and-language navigation (VLN). At each step, NavGPT takes the textual descriptions of visual observations, navigation history, and future explorable directions as inputs to reason the agent's current status, and makes the decision to approach the target. Through comprehensive experiments, we demonstrate NavGPT can explicitly perform high-level planning for navigation, including decomposing instruction into sub-goals, integrating commonsense knowledge relevant to navigation task resolution, identifying landmarks from observed scenes, tracking navigation progress, and adapting to exceptions with plan adjustment. Furthermore, we show that LLMs is capable of generating high-quality navigational instructions from observations and actions along a path, as well as drawing accurate top-down metric trajectory given the agent's navigation history. Despite the performance of using NavGPT to zero-shot R2R tasks still falling short of trained models, we suggest adapting multi-modality inputs for LLMs to use as visual navigation agents and applying the explicit reasoning of LLMs to benefit learning-based models. Code is available at: https://github.com/GengzeZhou/NavGPT.","['GPT-4', 'zero-shot sequential action prediction']"
2024,https://openalex.org/W4402780379,Psychology,Investigating Spatial Effects through Machine Learning and Leveraging Explainable AI for Child Malnutrition in Pakistan,"While socioeconomic gradients in regional health inequalities are firmly established, the synergistic interactions between socioeconomic deprivation and climate vulnerability within convenient proximity and neighbourhood locations with health disparities remain poorly explored and thus require deep understanding within a regional context. Furthermore, disregarding the importance of spatial spillover effects and nonlinear effects of covariates on childhood stunting are inevitable in dealing with an enduring issue of regional health inequalities. The present study aims to investigate the spatial inequalities in childhood stunting at the district level in Pakistan and validate the importance of spatial lag in predicting childhood stunting. Furthermore, it examines the presence of any nonlinear relationships among the selected independent features with childhood stunting. The study utilized data related to socioeconomic features from MICS 2017–2018 and climatic data from Integrated Contextual Analysis. A multi-model approach was employed to address the research questions, which included Ordinary Least Squares Regression (OLS), various Spatial Models, Machine Learning Algorithms and Explainable Artificial Intelligence methods. Firstly, OLS was used to analyse and test the linear relationships among selected variables. Secondly, Spatial Durbin Error Model (SDEM) was used to detect and capture the impact of spatial spillover on childhood stunting. Third, XGBoost and Random Forest machine learning algorithms were employed to examine and validate the importance of the spatial lag component. Finally, EXAI methods such as SHapley were utilized to identify potential nonlinear relationships. The study found a clear pattern of spatial clustering and geographical disparities in childhood stunting, with multidimensional poverty, high climate vulnerability and early marriage worsening childhood stunting. In contrast, low climate vulnerability, high exposure to mass media and high women’s literacy were found to reduce childhood stunting. The use of machine learning algorithms, specifically XGBoost and Random Forest, highlighted the significant role played by the average value in the neighbourhood in predicting childhood stunting in nearby districts, confirming that the spatial spillover effect is not bounded by geographical boundaries. Furthermore, EXAI methods such as partial dependency plot reveal the existence of a nonlinear relationship between multidimensional poverty and childhood stunting. The study’s findings provide valuable insights into the spatial distribution of childhood stunting in Pakistan, emphasizing the importance of considering spatial effects in predicting childhood stunting. Individual and household-level factors such as exposure to mass media and women’s literacy have shown positive implications for childhood stunting. It further provides a justification for the usage of EXAI methods to draw better insights and propose customised intervention policies accordingly.","['XGBoost', 'Random Forest', 'partial dependency plot']"
2024,https://openalex.org/W4390659289,Psychology,Cognition-Driven Structural Prior for Instance-Dependent Label Transition Matrix Estimation,"The label transition matrix has emerged as a widely accepted method for mitigating label noise in machine learning. In recent years, numerous studies have centered on leveraging deep neural networks to estimate the label transition matrix for individual instances within the context of instance-dependent noise. However, these methods suffer from low search efficiency due to the large space of feasible solutions. Behind this drawback, we have explored that the real murderer lies in the invalid class transitions, that is, the actual transition probability between certain classes is zero but is estimated to have a certain value. To mask the <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">invalid class transitions</i> , we introduced a human-cognition-assisted method with structural information from human cognition. Specifically, we introduce a structured transition matrix network ( <bold xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">STMN</b> ) designed with an adversarial learning process to balance instance features and prior information from human cognition. The proposed method offers two advantages: 1) better estimation effectiveness is obtained by sparing the transition matrix and 2) better estimation accuracy is obtained with the assistance of human cognition. By exploiting these two advantages, our method parametrically estimates a sparse label transition matrix, effectively converting noisy labels into true labels. The efficiency and superiority of our proposed method are substantiated through comprehensive comparisons with state-of-the-art methods on three synthetic datasets and a real-world dataset. Our code will be available at https://github.com/WheatCao/STMN-Pytorch.","['deep neural networks', 'adversarial learning process']"
2024,https://openalex.org/W4391044499,Psychology,Artificial intelligence (AI)—it’s the end of the tox as we know it (and I feel fine)*,"The rapid progress of AI impacts diverse scientific disciplines, including toxicology, and has the potential to transform chemical safety evaluation. Toxicology has evolved from an empirical science focused on observing apical outcomes of chemical exposure, to a data-rich field ripe for AI integration. The volume, variety and velocity of toxicological data from legacy studies, literature, high-throughput assays, sensor technologies and omics approaches create opportunities but also complexities that AI can help address. In particular, machine learning is well suited to handle and integrate large, heterogeneous datasets that are both structured and unstructured-a key challenge in modern toxicology. AI methods like deep neural networks, large language models, and natural language processing have successfully predicted toxicity endpoints, analyzed high-throughput data, extracted facts from literature, and generated synthetic data. Beyond automating data capture, analysis, and prediction, AI techniques show promise for accelerating quantitative risk assessment by providing probabilistic outputs to capture uncertainties. AI also enables explanation methods to unravel mechanisms and increase trust in modeled predictions. However, issues like model interpretability, data biases, and transparency currently limit regulatory endorsement of AI. Multidisciplinary collaboration is needed to ensure development of interpretable, robust, and human-centered AI systems. Rather than just automating human tasks at scale, transformative AI can catalyze innovation in how evidence is gathered, data are generated, hypotheses are formed and tested, and tasks are performed to usher new paradigms in chemical safety assessment. Used judiciously, AI has immense potential to advance toxicology into a more predictive, mechanism-based, and evidence-integrated scientific discipline to better safeguard human and environmental wellbeing across diverse populations.","['machine learning', 'deep neural networks']"
2024,https://openalex.org/W4391107516,Psychology,Multiple Classification of Brain MRI Autism Spectrum Disorder by Age and Gender Using Deep Learning,"Abstract The fact that the rapid and definitive diagnosis of autism cannot be made today and that autism cannot be treated provides an impetus to look into novel technological solutions. To contribute to the resolution of this problem through multiple classifications by considering age and gender factors, in this study, two quadruple and one octal classifications were performed using a deep learning (DL) approach. Gender in one of the four classifications and age groups in the other were considered. In the octal classification, classes were created considering gender and age groups. In addition to the diagnosis of ASD (Autism Spectrum Disorders), another goal of this study is to find out the contribution of gender and age factors to the diagnosis of ASD by making multiple classifications based on age and gender for the first time. Brain structural MRI (sMRI) scans of participators with ASD and TD (Typical Development) were pre-processed in the system originally designed for this purpose. Using the Canny Edge Detection (CED) algorithm, the sMRI image data was cropped in the data pre-processing stage, and the data set was enlarged five times with the data augmentation (DA) techniques. The most optimal convolutional neural network (CNN) models were developed using the grid search optimization (GSO) algorism. The proposed DL prediction system was tested with the five-fold cross-validation technique. Three CNN models were designed to be used in the system. The first of these models is the quadruple classification model created by taking gender into account (model 1), the second is the quadruple classification model created by taking into account age (model 2), and the third is the eightfold classification model created by taking into account both gender and age (model 3). ). The accuracy rates obtained for all three designed models are 80.94, 85.42 and 67.94, respectively. These obtained accuracy rates were compared with pre-trained models by using the transfer learning approach. As a result, it was revealed that age and gender factors were effective in the diagnosis of ASD with the system developed for ASD multiple classifications, and higher accuracy rates were achieved compared to pre-trained models.","['convolutional neural network (CNN) models', 'transfer learning approach']"
2024,https://openalex.org/W4400461591,Psychology,Counterfactual Explanations and Algorithmic Recourses for Machine Learning: A Review,"Machine learning plays a role in many deployed decision systems, often in ways that are difficult or impossible to understand by human stakeholders. Explaining, in a human-understandable way, the relationship between the input and output of machine learning models is essential to the development of trustworthy machine learning based systems. A burgeoning body of research seeks to define the goals and methods of explainability in machine learning. In this article, we seek to review and categorize research on counterfactual explanations , a specific class of explanation that provides a link between what could have happened had input to a model been changed in a particular way. Modern approaches to counterfactual explainability in machine learning draw connections to the established legal doctrine in many countries, making them appealing to fielded systems in high-impact areas such as finance and healthcare. Thus, we design a rubric with desirable properties of counterfactual explanation algorithms and comprehensively evaluate all currently proposed algorithms against that rubric. Our rubric provides easy comparison and comprehension of the advantages and disadvantages of different approaches and serves as an introduction to major research themes in this field. We also identify gaps and discuss promising research directions in the space of counterfactual explainability.","['counterfactual explanations', 'counterfactual explanation algorithms']"
2024,https://openalex.org/W4401533174,Psychology,The Crowdless Future? Generative AI and Creative Problem-Solving,"The rapid advances in generative artificial intelligence (AI) open up attractive opportunities for creative problem-solving through human-guided AI partnerships. To explore this potential, we initiated a crowdsourcing challenge focused on sustainable, circular economy business ideas generated by the human crowd (HC) and collaborative human-AI efforts using two alternative forms of solution search. The challenge attracted 125 global solvers from various industries, and we used strategic prompt engineering to generate the human-AI solutions. We recruited 300 external human evaluators to judge a randomized selection of 13 out of 234 solutions, totaling 3,900 evaluator-solution pairs. Our results indicate that while human crowd solutions exhibited higher novelty—both on average and for highly novel outcomes—human-AI solutions demonstrated superior strategic viability, financial and environmental value, and overall quality. Notably, human-AI solutions cocreated through differentiated search, where human-guided prompts instructed the large language model to sequentially generate outputs distinct from previous iterations, outperformed solutions generated through independent search. By incorporating “AI in the loop” into human-centered creative problem-solving, our study demonstrates a scalable, cost-effective approach to augment the early innovation phases and lays the groundwork for investigating how integrating human-AI solution search processes can drive more impactful innovations. Funding: This work was supported by Harvard Business School (Division of Research and Faculty Development) and the Laboratory for Innovation Science at Harvard (LISH) at the Digital Data and Design (D 3 ) Institute at Harvard. Supplemental Material: The online appendix is available at https://doi.org/10.1287/orsc.2023.18430 .",['large language model']
2024,https://openalex.org/W4391145008,Psychology,Assessing ChatGPT’s Mastery of Bloom’s Taxonomy Using Psychosomatic Medicine Exam Questions: Mixed-Methods Study,"Background Large language models such as GPT-4 (Generative Pre-trained Transformer 4) are being increasingly used in medicine and medical education. However, these models are prone to “hallucinations” (ie, outputs that seem convincing while being factually incorrect). It is currently unknown how these errors by large language models relate to the different cognitive levels defined in Bloom’s taxonomy. Objective This study aims to explore how GPT-4 performs in terms of Bloom’s taxonomy using psychosomatic medicine exam questions. Methods We used a large data set of psychosomatic medicine multiple-choice questions (N=307) with real-world results derived from medical school exams. GPT-4 answered the multiple-choice questions using 2 distinct prompt versions: detailed and short. The answers were analyzed using a quantitative approach and a qualitative approach. Focusing on incorrectly answered questions, we categorized reasoning errors according to the hierarchical framework of Bloom’s taxonomy. Results GPT-4’s performance in answering exam questions yielded a high success rate: 93% (284/307) for the detailed prompt and 91% (278/307) for the short prompt. Questions answered correctly by GPT-4 had a statistically significant higher difficulty than questions answered incorrectly (P=.002 for the detailed prompt and P&lt;.001 for the short prompt). Independent of the prompt, GPT-4’s lowest exam performance was 78.9% (15/19), thereby always surpassing the “pass” threshold. Our qualitative analysis of incorrect answers, based on Bloom’s taxonomy, showed that errors were primarily in the “remember” (29/68) and “understand” (23/68) cognitive levels; specific issues arose in recalling details, understanding conceptual relationships, and adhering to standardized guidelines. Conclusions GPT-4 demonstrated a remarkable success rate when confronted with psychosomatic medicine multiple-choice exam questions, aligning with previous findings. When evaluated through Bloom’s taxonomy, our data revealed that GPT-4 occasionally ignored specific facts (remember), provided illogical reasoning (understand), or failed to apply concepts to a new situation (apply). These errors, which were confidently presented, could be attributed to inherent model biases and the tendency to generate outputs that maximize likelihood.",['GPT-4 (Generative Pre-trained Transformer 4)']
2024,https://openalex.org/W4391531220,Psychology,An Explainable AI Paradigm for Alzheimer’s Diagnosis Using Deep Transfer Learning,"Alzheimer’s disease (AD) is a progressive neurodegenerative disorder that affects millions of individuals worldwide, causing severe cognitive decline and memory impairment. The early and accurate diagnosis of AD is crucial for effective intervention and disease management. In recent years, deep learning techniques have shown promising results in medical image analysis, including AD diagnosis from neuroimaging data. However, the lack of interpretability in deep learning models hinders their adoption in clinical settings, where explainability is essential for gaining trust and acceptance from healthcare professionals. In this study, we propose an explainable AI (XAI)-based approach for the diagnosis of Alzheimer’s disease, leveraging the power of deep transfer learning and ensemble modeling. The proposed framework aims to enhance the interpretability of deep learning models by incorporating XAI techniques, allowing clinicians to understand the decision-making process and providing valuable insights into disease diagnosis. By leveraging popular pre-trained convolutional neural networks (CNNs) such as VGG16, VGG19, DenseNet169, and DenseNet201, we conducted extensive experiments to evaluate their individual performances on a comprehensive dataset. The proposed ensembles, Ensemble-1 (VGG16 and VGG19) and Ensemble-2 (DenseNet169 and DenseNet201), demonstrated superior accuracy, precision, recall, and F1 scores compared to individual models, reaching up to 95%. In order to enhance interpretability and transparency in Alzheimer’s diagnosis, we introduced a novel model achieving an impressive accuracy of 96%. This model incorporates explainable AI techniques, including saliency maps and grad-CAM (gradient-weighted class activation mapping). The integration of these techniques not only contributes to the model’s exceptional accuracy but also provides clinicians and researchers with visual insights into the neural regions influencing the diagnosis. Our findings showcase the potential of combining deep transfer learning with explainable AI in the realm of Alzheimer’s disease diagnosis, paving the way for more interpretable and clinically relevant AI models in healthcare.","['deep learning', 'explainable AI (XAI)', 'deep transfer learning', 'ensemble modeling', 'pre-trained convolutional neural networks (CNNs)', 'VGG16', 'VGG19', 'DenseNet169', 'DenseNet201', 'saliency maps', 'grad-CAM (gradient-weighted class activation mapping)']"
2024,https://openalex.org/W4393091384,Psychology,REVIEWING THE TRANSFORMATIONAL IMPACT OF EDGE COMPUTING ON REAL-TIME DATA PROCESSING AND ANALYTICS,"Edge computing has emerged as a pivotal paradigm shift in the realm of data processing and analytics, revolutionizing the way organizations handle real-time data. This review presents a comprehensive review of the transformational impact of edge computing on real-time data processing and analytics. Firstly, the review delves into the fundamental concepts of edge computing, elucidating its architectural framework and highlighting its distinct advantages over traditional cloud-centric approaches. By distributing computational resources closer to data sources, edge computing mitigates latency issues and enhances responsiveness, thereby enabling real-time data processing at the edge. Furthermore, this review explores how edge computing facilitates the seamless integration of analytics capabilities into edge devices, empowering organizations to derive actionable insights at the source of data generation. Leveraging advanced analytics algorithms, such as machine learning and artificial intelligence, edge computing enables autonomous decision-making and predictive analytics in real time, fostering innovation across diverse industry verticals. Moreover, the review examines the transformative implications of edge computing on various sectors, including healthcare, manufacturing, transportation, and smart cities. By enabling localized data processing and analytics, edge computing enhances operational efficiency, ensures data privacy and security, and unlocks new opportunities for business optimization and value creation. This review underscores the profound impact of edge computing on real-time data processing and analytics, revolutionizing the way organizations harness data to drive informed decision-making and gain competitive advantage in today's dynamic business landscape. As edge computing continues to evolve, its transformative potential is poised to redefine the future of data-driven innovation and digital transformation.&#x0D; Keywords: Edge, Computing, Analytics, Data, Impact, Review.",['machine learning']
2024,https://openalex.org/W4391399751,Psychology,"Human-in-the-Loop Reinforcement Learning: A Survey and Position on Requirements, Challenges, and Opportunities","Artificial intelligence (AI) and especially reinforcement learning (RL) have the potential to enable agents to learn and perform tasks autonomously with superhuman performance. However, we consider RL as fundamentally a Human-in-the-Loop (HITL) paradigm, even when an agent eventually performs its task autonomously. In cases where the reward function is challenging or impossible to define, HITL approaches are considered particularly advantageous. The application of Reinforcement Learning from Human Feedback (RLHF) in systems such as ChatGPT demonstrates the effectiveness of optimizing for user experience and integrating their feedback into the training loop. In HITL RL, human input is integrated during the agent’s learning process, allowing iterative updates and fine-tuning based on human feedback, thus enhancing the agent’s performance. Since the human is an essential part of this process, we argue that human-centric approaches are the key to successful RL, a fact that has not been adequately considered in the existing literature. This paper aims to inform readers about current explainability methods in HITL RL. It also shows how the application of explainable AI (xAI) and specific improvements to existing explainability approaches can enable a better human-agent interaction in HITL RL for all types of users, whether for lay people, domain experts, or machine learning specialists. Accounting for the workflow in HITL RL and based on software and machine learning methodologies, this article identifies four phases for human involvement for creating HITL RL systems: (1) Agent Development, (2) Agent Learning, (3) Agent Evaluation, and (4) Agent Deployment. We highlight human involvement, explanation requirements, new challenges, and goals for each phase. We furthermore identify low-risk, high-return opportunities for explainability research in HITL RL and present long-term research goals to advance the field. Finally, we propose a vision of human-robot collaboration that allows both parties to reach their full potential and cooperate effectively.","['reinforcement learning (RL)', 'Reinforcement Learning from Human Feedback (RLHF)', 'explainable AI (xAI)']"
2024,https://openalex.org/W4401844424,Psychology,AlphaFold predictions of fold-switched conformations are driven by structure memorization,"Abstract Recent work suggests that AlphaFold (AF)–a deep learning-based model that can accurately infer protein structure from sequence–may discern important features of folded protein energy landscapes, defined by the diversity and frequency of different conformations in the folded state. Here, we test the limits of its predictive power on fold-switching proteins, which assume two structures with regions of distinct secondary and/or tertiary structure. We find that (1) AF is a weak predictor of fold switching and (2) some of its successes result from memorization of training-set structures rather than learned protein energetics. Combining &gt;280,000 models from several implementations of AF2 and AF3, a 35% success rate was achieved for fold switchers likely in AF’s training sets. AF2’s confidence metrics selected against models consistent with experimentally determined fold-switching structures and failed to discriminate between low and high energy conformations. Further, AF captured only one out of seven experimentally confirmed fold switchers outside of its training sets despite extensive sampling of an additional ~280,000 models. Several observations indicate that AF2 has memorized structural information during training, and AF3 misassigns coevolutionary restraints. These limitations constrain the scope of successful predictions, highlighting the need for physically based methods that readily predict multiple protein conformations.","['AlphaFold (AF)', 'AF2']"
2024,https://openalex.org/W4402827393,Psychology,Larger and more instructable language models become less reliable,"Abstract The prevailing methods to make large language models more powerful and amenable have been based on continuous scaling up (that is, increasing their size, data volume and computational resources 1 ) and bespoke shaping up (including post-filtering 2,3 , fine tuning or use of human feedback 4,5 ). However, larger and more instructable large language models may have become less reliable. By studying the relationship between difficulty concordance, task avoidance and prompting stability of several language model families, here we show that easy instances for human participants are also easy for the models, but scaled-up, shaped-up models do not secure areas of low difficulty in which either the model does not err or human supervision can spot the errors. We also find that early models often avoid user questions but scaled-up, shaped-up models tend to give an apparently sensible yet wrong answer much more often, including errors on difficult questions that human supervisors frequently overlook. Moreover, we observe that stability to different natural phrasings of the same question is improved by scaling-up and shaping-up interventions, but pockets of variability persist across difficulty levels. These findings highlight the need for a fundamental shift in the design and development of general-purpose artificial intelligence, particularly in high-stakes areas for which a predictable distribution of errors is paramount.","['post-filtering', 'fine tuning', 'use of human feedback']"
2024,https://openalex.org/W4390975281,Psychology,Semantic and Instance Segmentation in Coastal Urban Spatial Perception: A Multi-Task Learning Framework with an Attention Mechanism,"With the continuous acceleration of urbanization, urban planning and design require more in-depth research and development. Street view images can express rich urban features and guide residents’ emotions toward a city, thereby providing the most intuitive reflection of their perception of the city’s spatial quality. However, current researchers mainly conduct research on urban spatial quality through subjective experiential judgment, which includes problems such as a high cost and a low judgment accuracy. In response to these problems, this study proposes a multi-task learning urban spatial attribute perception model that integrates an attention mechanism. Via this model, the existing attributes of urban street scenes are analyzed. Then, the model is improved by introducing semantic segmentation and instance segmentation to identify and match the qualities of the urban space. The experimental results show that the multi-task learning urban spatial attribute perception model with an integrated attention mechanism has prediction accuracies of 79.54%, 78.62%, 79.68%, 77.42%, 78.45%, and 76.98% for the urban spatial attributes of beauty, boredom, depression, liveliness, safety, and richness, respectively. The accuracy of the multi-task learning urban spatial scene feature image segmentation model with an integrated attention mechanism is 95.4, 94.8, 96.2, 92.1, and 96.7 for roads, walls, sky, vehicles, and buildings, respectively. The multi-task learning urban spatial scene feature image segmentation model with an integrated attention mechanism has a higher recognition accuracy for urban spatial buildings than other models. These research results indicate the model’s effectiveness in matching urban spatial quality with public perception.","['multi-task learning', 'attention mechanism', 'semantic segmentation', 'instance segmentation']"
2024,https://openalex.org/W4391126287,Psychology,Evaluating the ChatGPT family of models for biomedical reasoning and classification,"Abstract Objective Large language models (LLMs) have shown impressive ability in biomedical question-answering, but have not been adequately investigated for more specific biomedical applications. This study investigates ChatGPT family of models (GPT-3.5, GPT-4) in biomedical tasks beyond question-answering. Materials and Methods We evaluated model performance with 11 122 samples for two fundamental tasks in the biomedical domain—classification (n = 8676) and reasoning (n = 2446). The first task involves classifying health advice in scientific literature, while the second task is detecting causal relations in biomedical literature. We used 20% of the dataset for prompt development, including zero- and few-shot settings with and without chain-of-thought (CoT). We then evaluated the best prompts from each setting on the remaining dataset, comparing them to models using simple features (BoW with logistic regression) and fine-tuned BioBERT models. Results Fine-tuning BioBERT produced the best classification (F1: 0.800-0.902) and reasoning (F1: 0.851) results. Among LLM approaches, few-shot CoT achieved the best classification (F1: 0.671-0.770) and reasoning (F1: 0.682) results, comparable to the BoW model (F1: 0.602-0.753 and 0.675 for classification and reasoning, respectively). It took 78 h to obtain the best LLM results, compared to 0.078 and 0.008 h for the top-performing BioBERT and BoW models, respectively. Discussion The simple BoW model performed similarly to the most complex LLM prompting. Prompt engineering required significant investment. Conclusion Despite the excitement around viral ChatGPT, fine-tuning for two fundamental biomedical natural language processing tasks remained the best strategy.","['ChatGPT family of models (GPT-3.5, GPT-4)', 'zero-shot prompting', 'few-shot prompting', 'chain-of-thought (CoT) prompting', 'Bag of Words (BoW) with logistic regression', 'fine-tuned BioBERT']"
2024,https://openalex.org/W4391574742,Psychology,Optimum tuned mass damper inerter under near-fault pulse-like ground motions of buildings including soil-structure interaction,"This study investigates the effectiveness of the tuned mass damper inerter (TMDI) in mitigating building response, considering the soil structure interaction (SSI). Three types of models are examined: single degree of freedom (SDOF), low-rise multi-degree of freedom (MDOF), and high-rise MDOF. Additionally, the natural period of the SDOF model is varied to explore the TMDI's efficacy across different ranges. Frequency and time domain analysis are conducted under pulse-like ground motions. The H2 and genetic algorithm (GA) are used to optimize the parameters of the TMDI. In this optimization method the transfer function for displacement response is minimized. In time domain analysis we used Newmark's integration method to solve the equation of motion for all the cases considered. It is found that the optimized TMDI proves highly effective in mitigating the displacement response of the buildings, accounting for SSI. Notably, its efficiency is more pronounced when pulse period aligns closely with the buildings' natural period. In addition, a notable pattern emerges, wherein the TMDI excels in mitigating response for buildings experiencing large motion, thereby enhancing safety under severe conditions. These findings offer valuable insights into the application and optimization of the TMDI to enhance seismic performance in various buildings, while considering complex interaction with the soil.",['genetic algorithm (GA)']
2024,https://openalex.org/W4392285688,Psychology,Machine Learning and Digital Biomarkers Can Detect Early Stages of Neurodegenerative Diseases,"Neurodegenerative diseases (NDs) such as Alzheimer’s Disease (AD) and Parkinson’s Disease (PD) are devastating conditions that can develop without noticeable symptoms, causing irreversible damage to neurons before any signs become clinically evident. NDs are a major cause of disability and mortality worldwide. Currently, there are no cures or treatments to halt their progression. Therefore, the development of early detection methods is urgently needed to delay neuronal loss as soon as possible. Despite advancements in Medtech, the early diagnosis of NDs remains a challenge at the intersection of medical, IT, and regulatory fields. Thus, this review explores “digital biomarkers” (tools designed for remote neurocognitive data collection and AI analysis) as a potential solution. The review summarizes that recent studies combining AI with digital biomarkers suggest the possibility of identifying pre-symptomatic indicators of NDs. For instance, research utilizing convolutional neural networks for eye tracking has achieved significant diagnostic accuracies. ROC-AUC scores reached up to 0.88, indicating high model performance in differentiating between PD patients and healthy controls. Similarly, advancements in facial expression analysis through tools have demonstrated significant potential in detecting emotional changes in ND patients, with some models reaching an accuracy of 0.89 and a precision of 0.85. This review follows a structured approach to article selection, starting with a comprehensive database search and culminating in a rigorous quality assessment and meaning for NDs of the different methods. The process is visualized in 10 tables with 54 parameters describing different approaches and their consequences for understanding various mechanisms in ND changes. However, these methods also face challenges related to data accuracy and privacy concerns. To address these issues, this review proposes strategies that emphasize the need for rigorous validation and rapid integration into clinical practice. Such integration could transform ND diagnostics, making early detection tools more cost-effective and globally accessible. In conclusion, this review underscores the urgent need to incorporate validated digital health tools into mainstream medical practice. This integration could indicate a new era in the early diagnosis of neurodegenerative diseases, potentially altering the trajectory of these conditions for millions worldwide. Thus, by highlighting specific and statistically significant findings, this review demonstrates the current progress in this field and the potential impact of these advancements on the global management of NDs.",['convolutional neural networks']
2024,https://openalex.org/W4392404912,Psychology,The Impact of Artificial Intelligence on Students' Learning Experience,"The integration of artificial intelligence (AI) in education has the potential to revolutionize the learning experience for students. This abstract provides an overview of the impact of AI on students' learning experience, highlighting its benefits and potential challenges.AI technologies such as machine learning, natural language processing, and data analytics have been increasingly adopted in educational settings. These technologies enable personalized and adaptive learning experiences, providing students with tailored content and feedback based on their individual needs and learning styles. AI-powered educational platforms can analyze vast amounts of data to identify patterns and offer personalized recommendations, thereby enhancing students' engagement and motivation.One of the significant benefits of AI in education is its ability to provide immediate and constructive feedback to students. Automated grading systems powered by AI algorithms can assess and provide feedback on assignments, quizzes, and exams promptly, allowing students to understand their strengths and weaknesses in real-time. This timely feedback facilitates self-reflection and enables students to make necessary improvements, leading to enhanced learning outcomes.Furthermore, AI can support collaborative learning environments. Intelligent tutoring systems and virtual learning assistants can facilitate group discussions, provide guidance, and foster collaboration among students. These AI-powered tools can promote active participation, critical thinking, and problem-solving skills, creating a dynamic learning environment that mirrors real-world scenarios.However, the integration of AI in education also poses challenges that need to be addressed. Privacy and ethical concerns arise when dealing with student data, as AI relies on collecting and analyzing personal information to provide personalized experiences. Safeguarding student data privacy and ensuring ethical use of AI technologies are essential considerations for educators and policymakers.Additionally, there is a potential risk of over-reliance on AI technologies, leading to a passive learning experience for students. Balancing the use of AI with human instruction and guidance is crucial to maintain meaningful interactions and promote deeper understanding.",['machine learning']
2024,https://openalex.org/W4399857583,Psychology,Integrating artificial intelligence to assess emotions in learning environments: a systematic literature review,"Introduction Artificial Intelligence (AI) is transforming multiple sectors within our society, including education. In this context, emotions play a fundamental role in the teaching-learning process given that they influence academic performance, motivation, information retention, and student well-being. Thus, the integration of AI in emotional assessment within educational environments offers several advantages that can transform how we understand and address the socio-emotional development of students. However, there remains a lack of comprehensive approach that systematizes advancements, challenges, and opportunities in this field. Aim This systematic literature review aims to explore how artificial intelligence (AI) is used to evaluate emotions within educational settings. We provide a comprehensive overview of the current state of research, focusing on advancements, challenges, and opportunities in the domain of AI-driven emotional assessment within educational settings. Method The review involved a search across the following academic databases: Pubmed, Web of Science, PsycINFO and Scopus. Forty-one articles were selected that meet the established inclusion criteria. These articles were analyzed to extract key insights related to the integration of AI and emotional assessment within educational environments. Results The findings reveal a variety of AI-driven approaches that were developed to capture and analyze students’ emotional states during learning activities. The findings are summarized in four fundamental topics: (1) emotion recognition in education, (2) technology integration and learning outcomes, (3) special education and assistive technology, (4) affective computing. Among the key AI techniques employed are machine learning and facial recognition, which are used to assess emotions. These approaches demonstrate promising potential in enhancing pedagogical strategies and creating adaptive learning environments that cater to individual emotional needs. The review identified emerging factors that, while important, require further investigation to understand their relationships and implications fully. These elements could significantly enhance the use of AI in assessing emotions within educational settings. Specifically, we are referring to: (1) federated learning, (2) convolutional neural network (CNN), (3) recurrent neural network (RNN), (4) facial expression databases, and (5) ethics in the development of intelligent systems. Conclusion This systematic literature review showcases the significance of AI in revolutionizing educational practices through emotion assessment. While advancements are evident, challenges related to accuracy, privacy, and cross-cultural validity were also identified. The synthesis of existing research highlights the need for further research into refining AI models for emotion recognition and emphasizes the importance of ethical considerations in implementing AI technologies within educational contexts.","['machine learning', 'federated learning', 'convolutional neural network (CNN)', 'recurrent neural network (RNN)']"
2024,https://openalex.org/W4390490725,Psychology,Evaluating LLM-generated Worked Examples in an Introductory Programming Course,"Worked examples, which illustrate the process for solving a problem step-by-step, are a well-established pedagogical technique that has been widely studied in computing classrooms. However, creating high-quality worked examples is very time-intensive for educators, and thus learners tend not to have access to a broad range of such examples. The recent emergence of powerful large language models (LLMs), which appear capable of generating high-quality human-like content, may offer a solution. Separate strands of recent work have shown that LLMs can accurately generate code suitable for a novice audience, and that they can generate high-quality explanations of code. Therefore, LLMs may be well suited to creating a broad range of worked examples, overcoming the bottleneck of manual effort that is currently required. In this work, we present a novel tool, 'WorkedGen', which uses an LLM to generate interactive worked examples. We evaluate this tool with both an expert assessment of the content, and a user study involving students in a first-year Python programming course (n = ~400). We find that prompt chaining and one-shot learning are useful strategies for optimising the output of an LLM when producing worked examples. Our expert analysis suggests that LLMs generate clear explanations, and our classroom deployment revealed that students find the LLM-generated worked examples useful for their learning. We propose several avenues for future work, including investigating WorkedGen's value in a range of programming languages, and with more complex questions suitable for more advanced courses.","['prompt chaining', 'one-shot learning']"
2024,https://openalex.org/W4393250851,Psychology,Evaluating the subjective perceptions of streetscapes using street-view images,"Developing a model to evaluate urban streetscapes based on subjective perceptions is important for quantitative understanding. However, previous studies have only considered limited types of subjective perceptions, neglecting the relationships between them. Further, accurately measuring subjective perception with low computational costs for large-scale urban regions at high spatial resolutions has been difficult. We present a deep-learning-based multilabel classification model that can measure 22 subjective perceptions scores from street-view images. This model uses the results of a web questionnaire survey encompassing 22 subjective perceptions, with 8.8 million responses. Our model demonstrates high accuracy (0.80–0.91) in measuring subjective perception scores from street-view images and achieves low computational cost by training on 22 subjective perception relationships. The 22 subjective perceptions were analyzed using PCA and k-means analysis. By categorizing the 22 subjective perceptions into a two-dimensional space visualized and grouped into distinct groups—positive, negative, calm, and lively—we unearthed vital insights into the intricate nuances of human perception. In addition, the study used semantic segmentation to extract landscape elements from street-view images and applied ℓ1-regularized sparse modeling to identify the landscape elements structurally correlating with each subjective perception class. The analysis revealed that only seven out of nineteen landscape elements significantly correlated with subjective impressions, and these effects varied by class. Notably, sky coverage positively influences positive subjective perceptions, such as attractiveness and calmness, but negatively affects lively impressions. The proposed model can be used to map the overall image of a city and identify landscape design issues in community development design.","['PCA', 'k-means analysis', 'semantic segmentation', 'ℓ1-regularized sparse modeling']"
2024,https://openalex.org/W4396908686,Psychology,Firefighter Skill Advancement through IoT-Enabled Virtual Reality and CNN-Based Training,"To maintain the safety and efficacy of firefighters in various circumstances, modern firefighting necessitates constantly improving skills and training techniques. Utilizing the Internet of Things (IoT), virtual reality (VR), and convolutional neural networks (CNN), this paper details a novel method for training firefighters. The proposed system collects real-time data on ambient variables, equipment state, and firefighter biometrics via integrating IoT sensors into firefighting equipment and training settings. Using this information, it can develop lifelike VR training simulations of difficult and potentially dangerous scenarios. To make the training settings more realistic and malleable, CNN-based algorithms are used to assess the data. The capacity to simulate a wide variety of firefighting situations, customize training difficulty depending on individual and team performance, and provide instant feedback and performance metrics to trainees are all major benefits of this method. The method also allows teachers to check in and evaluate their learners remotely, improving instruction quality. An IoT-enabled VR and CNN-based training technique has shown promising preliminary results in pilot trials, suggesting it might greatly enhance firefighter competence, situational awareness, and decision-making ability. Because of this, it has the potential to completely alter the way firefighters are informed and prepared for the ever-changing dangers users may encounter on the job.",['convolutional neural networks (CNN)']
2024,https://openalex.org/W4404134492,Psychology,Bias in medical AI: Implications for clinical decision-making,"Biases in medical artificial intelligence (AI) arise and compound throughout the AI lifecycle. These biases can have significant clinical consequences, especially in applications that involve clinical decision-making. Left unaddressed, biased medical AI can lead to substandard clinical decisions and the perpetuation and exacerbation of longstanding healthcare disparities. We discuss potential biases that can arise at different stages in the AI development pipeline and how they can affect AI algorithms and clinical decision-making. Bias can occur in data features and labels, model development and evaluation, deployment, and publication. Insufficient sample sizes for certain patient groups can result in suboptimal performance, algorithm underestimation, and clinically unmeaningful predictions. Missing patient findings can also produce biased model behavior, including capturable but nonrandomly missing data, such as diagnosis codes, and data that is not usually or not easily captured, such as social determinants of health. Expertly annotated labels used to train supervised learning models may reflect implicit cognitive biases or substandard care practices. Overreliance on performance metrics during model development may obscure bias and diminish a model's clinical utility. When applied to data outside the training cohort, model performance can deteriorate from previous validation and can do so differentially across subgroups. How end users interact with deployed solutions can introduce bias. Finally, where models are developed and published, and by whom, impacts the trajectories and priorities of future medical AI development. Solutions to mitigate bias must be implemented with care, which include the collection of large and diverse data sets, statistical debiasing methods, thorough model evaluation, emphasis on model interpretability, and standardized bias reporting and transparency requirements. Prior to real-world implementation in clinical settings, rigorous validation through clinical trials is critical to demonstrate unbiased application. Addressing biases across model development stages is crucial for ensuring all patients benefit equitably from the future of medical AI.","['supervised learning', 'statistical debiasing methods']"
2024,https://openalex.org/W4391753792,Psychology,Flood Detection with SAR: A Review of Techniques and Datasets,"Floods are among the most severe and impacting natural disasters. Their occurrence rate and intensity have been significantly increasing worldwide in the last years due to climate change and urbanization, bringing unprecedented effects on human lives and activities. Hence, providing a prompt response to flooding events is of crucial relevance for humanitarian, social and economic reasons. Satellite remote sensing using synthetic aperture radar (SAR) offers a great deal of support in facing flood events and mitigating their effects on a global scale. As opposed to multi-spectral sensors, SAR offers important advantages, as it enables Earth’s surface imaging regardless of weather and sunlight illumination conditions. In the last decade, the increasing availability of SAR data, even at no cost, thanks to the efforts of international and national space agencies, has been deeply stimulating research activities in every Earth observation field, including flood mapping and monitoring, where advanced processing paradigms, e.g., fuzzy logic, machine learning, data fusion, have been applied, demonstrating their superiority with respect to traditional classification strategies. However, a fair assessment of the performance and reliability of flood mapping techniques is of key importance for an efficient disasters response and, hence, should be addressed carefully and on a quantitative basis trough synthetic quality metrics and high-quality reference data. To this end, the recent development of open SAR datasets specifically covering flood events with related ground-truth reference data can support thorough and objective validation as well as reproducibility of results. Notwithstanding, SAR-based flood monitoring still suffers from severe limitations, especially in vegetated and urban areas, where complex scattering mechanisms can impair an accurate extraction of water regions. All such aspects, including classification methodologies, SAR datasets, validation strategies, challenges and future perspectives for SAR-based flood mapping are described and discussed.",['machine learning']
2024,https://openalex.org/W4390753190,Psychology,Investigating the impact of motion in the scanner on brain age predictions,"Abstract Brain Age Gap (BAG) is defined as the difference between the brain’s predicted age and the chronological age of an individual. Magnetic resonance imaging (MRI)-based BAG can quantify acceleration of brain aging, and is used to infer brain health as aging and disease interact. Motion in the scanner is a common occurrence that can affect the acquired MRI data and act as a major confound in the derived models. As such, age-related changes in head motion may impact the observed age-related differences. However, the relationship between head motion and BAG as estimated by structural MRI has not been systematically examined. The aim of this study is to assess the impact of motion on voxel-based morphometry (VBM) based BAG. Data were obtained from two sources: i) T1-weighted (T1w) MRIs from the Cambridge Centre for Ageing and Neuroscience (CamCAN) were used to train the brain age prediction model, and ii) T1w MRIs from the Movement-related artifacts (MR-ART) dataset were used to assess the impact of motion on BAG. MR-ART includes one motion-free and two motion-affected (one low and one high) 3D T1w MRIs. We also visually rated the motion levels of the MR-ART MRIs from 0 to 5, with 0 meaning no motion and 5 high motion levels. All images were pre-processed through a standard VBM pipeline. GM density across cortical and subcortical regions were then used to train the brain age prediction model and assess the relationship between BAG and MRI motion. Principal component analysis was used to perform dimension reduction and extract the VBM-based features. BAG was estimated by regressing out the portion of delta age explained by chronological age. Linear mixed-effects models were used to investigate the relationship between BAG and motion session as well as motion severity, including participant IDs as random effects. We repeated the same analysis using cortical thickness based on FreeSurfer 7.4.1 and to compare the results for volumetric versus surface-based measures of brain morphometry. In contrast with the session with no induced motion, predicted delta age was significantly higher for high motion sessions 2.35 years (t = 5.17, p &amp;lt; 0.0001), with marginal effect for low motion sessions 0.95 years (t = 2.11, p = 0.035) for VBM analysis as well as 3.46 years (t = 11.45, p &amp;lt; 0.0001) for high motion and 2.28 years (t = 7.54, p &amp;lt; 0.0001) for low motion based on cortical thickness. In addition, delta age was significantly associated with motion severity as evaluated by visual rating 0.45 years per rating level (t = 4.59, p &amp;lt; 0.0001) for VBM analysis and 0.83 years per motion level (t = 12.89, p &amp;lt; 0.0001) for cortical thickness analysis. Motion in the scanner can significantly impact brain age estimates, and needs to be accounted for as a confound, particularly when studying populations that are known to have higher levels of motion in the scanner. These results have significant implications for brain age studies in aging and neurodegeneration. Based on these findings, we recommend assessment and inclusion of visual motion ratings in such studies. In cases that the visual rating proves prohibitive, we recommend the inclusion of normalized Euler number from FreeSurfer as defined in the manuscript as a covariate in the models.","['principal component analysis', 'regression']"
2024,https://openalex.org/W4390987311,Psychology,Reliability of ChatGPT for performing triage task in the emergency department using the Korean Triage and Acuity Scale,"Background Artificial intelligence (AI) technology can enable more efficient decision-making in healthcare settings. There is a growing interest in improving the speed and accuracy of AI systems in providing responses for given tasks in healthcare settings. Objective This study aimed to assess the reliability of ChatGPT in determining emergency department (ED) triage accuracy using the Korean Triage and Acuity Scale (KTAS). Methods Two hundred and two virtual patient cases were built. The gold standard triage classification for each case was established by an experienced ED physician. Three other human raters (ED paramedics) were involved and rated the virtual cases individually. The virtual cases were also rated by two different versions of the chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0). Inter-rater reliability was examined using Fleiss’ kappa and intra-class correlation coefficient (ICC). Results The kappa values for the agreement between the four human raters and ChatGPTs were .523 (version 4.0) and .320 (version 3.5). Of the five levels, the performance was poor when rating patients at levels 1 and 5, as well as case scenarios with additional text descriptions. There were differences in the accuracy of the different versions of GPTs. The ICC between version 3.5 and the gold standard was .520, and that between version 4.0 and the gold standard was .802. Conclusions A substantial level of inter-rater reliability was revealed when GPTs were used as KTAS raters. The current study showed the potential of using GPT in emergency healthcare settings. Considering the shortage of experienced manpower, this AI method may help improve triaging accuracy.","['chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0)']"
2024,https://openalex.org/W4391573023,Psychology,Deep Reinforcement Learning Unleashing the Power of AI in Decision-Making,"Deep Reinforcement Learning (DRL) has emerged as a transformative paradigm in the field of artificial intelligence (AI), offering unprecedented capabilities in decision-making across diverse domains. This article explores the profound impact of DRL on enhancing the decision-making capabilities of AI systems, elucidating its underlying principles, applications, and implications.DRL represents a fusion of deep learning and reinforcement learning, enabling machines to learn complex behaviors and make decisions by interacting with their environment. The utilization of neural networks allows DRL algorithms to handle high-dimensional input spaces, making it well-suited for tasks that involve intricate decision-making processes.One of the key strengths of DRL lies in its ability to address problems with sparse and delayed rewards, common challenges in traditional reinforcement learning. Through a process of trial and error, DRL algorithms can learn optimal decision strategies by navigating through a vast decision space, adapting to dynamic environments, and maximizing cumulative rewards over time.The applications of DRL span various domains, including robotics, finance, healthcare, gaming, and autonomous systems. In robotics, DRL facilitates the development of intelligent agents capable of autonomously navigating complex environments, performing intricate tasks, and adapting to unforeseen circumstances. In finance, DRL is leveraged for portfolio optimization, algorithmic trading, and risk management, demonstrating its potential to revolutionize traditional financial strategies.","['Deep Reinforcement Learning (DRL)', 'deep learning', 'reinforcement learning']"
2024,https://openalex.org/W4396712983,Psychology,3WC-GBNRS++: A novel three-way classifier with granular-ball neighborhood rough sets based on uncertainty,"Three-way decision with neighborhood rough sets (3WDNRS) is adept at addressing uncertain problems involving continuous data by configuring the neighborhood radius. However, on one hand, the inputs of 3WDNRS are individual neighborhood granules, which reduce the decision efficiency and generality; on other hand, the thresholds of 3WDNRS require prior knowledge to be approximately set in advance, making it difficult to apply in cases where such knowledge is unavailable. To address these issues, we introduce granular-ball computing (GBC) into 3WDNRS from the perspective of uncertainty. Firstly, we propose an enhanced granular-ball generation method based on DBSCAN called DBGBC. Subsequently, we present an improved granular-ball neighborhood rough sets model (GBNRS++) by combining DBGBC with a quality index. Furthermore, we construct a three-way classifier with granular-ball neighborhood rough sets (3WC-GBNRS++) based on the principle of minimum fuzziness loss. This approach provides an objective and efficient way to determine the thresholds. To further enhance classification accuracy, we design an adaptive granular-ball neighborhood within the subsequent classification process of 3WC-GBNRS++. Finally, experimental results demonstrate that, 3WC-GBNRS++ almost outperformed other comparison methods in terms of effectiveness and robustness, including 4 state-of-the-art granular-balls-based classifiers and 5 classical machine learning classifiers on 12 public benchmark datasets. Moreover, we discuss the limitations of our work and the outlook for future research.","['three-way decision with neighborhood rough sets (3WDNRS)', 'DBSCAN']"
2024,https://openalex.org/W4396723505,Psychology,MentaLLaMA: Interpretable Mental Health Analysis on Social Media with Large Language Models,"As an integral part of people's daily lives, social media is becoming a rich source for automatic mental health analysis.As traditional discriminative methods bear poor generalization ability and low interpretability, the recent large language models (LLMs) have been explored for interpretable mental health analysis on social media, which aims to provide detailed explanations along with predictions in zero-shot or few-shot settings.The results show that LLMs still achieve unsatisfactory classification performance in a zero-shot/few-shot manner, which further significantly affects the quality of the generated explanations.Domain-specific finetuning is an effective solution, but faces two critical challenges: 1) lack of high-quality training data.2) no open-source foundation LLMs.To alleviate these problems, we formally model interpretable mental health analysis as a text generation task, and build the first multi-task and multi-source interpretable mental health instruction (IMHI) dataset with 105K data samples to support LLM instruction tuning and evaluation.The raw social media data are collected from 10 existing sources covering 8 mental health analysis tasks.We prompt ChatGPT with expert-designed few-shot prompts to obtain explanations.To ensure the reliability of the explanations, we perform strict automatic and human evaluations on the correctness, consistency, and quality of generated data.Based on the IMHI dataset and LLaMA2 foundation models, we train MentaLLaMA, the first open-source instruction-following LLM series for interpretable mental health analysis on social media.We evaluate Men-taLLaMA and other advanced methods on the IMHI benchmark, the first holistic evaluation benchmark for interpretable mental health analysis.The results show that MentaLLaMA approaches state-of-the-art discriminative methods in correctness and generates human-level explanations.MentaLLaMA models also show strong generalizability to unseen tasks.The project is available at https://github.com/SteveKGYang/MentaLLaMA.","['zero-shot learning', 'few-shot learning', 'domain-specific finetuning', 'instruction tuning']"
2024,https://openalex.org/W4390577959,Psychology,MixFormer: End-to-End Tracking With Iterative Mixed Attention,"Visual object tracking often employs a multi-stage pipeline of feature extraction, target information integration, and bounding box estimation. To simplify this pipeline and unify the process of feature extraction and target information integration, in this paper, we present a compact tracking framework, termed as MixFormer, built upon transformers. Our core design is to utilize the flexibility of attention operations, and we propose a Mixed Attention Module (MAM) for simultaneous feature extraction and target information integration. This synchronous modeling scheme allows us to extract target-specific discriminative features and perform extensive communication between target and search area. Based on MAM, we build our MixFormer trackers simply by stacking multiple MAMs and placing a localization head on top. Specifically, we instantiate two types of MixFormer trackers, a hierarchical tracker MixCvT, and a non-hierarchical simple tracker MixViT. For these two trackers, we investigate a series of pre-training methods and uncover the different behaviors between supervised pre-training and self-supervised pre-training in our MixFormer trackers. We also extend the masked autoencoder pre-training to our MixFormer trackers and design the new competitive TrackMAE pre-training technique. Finally, to handle multiple target templates during online tracking, we devise an asymmetric attention scheme in MAM to reduce computational cost, and propose an effective score prediction module to select high-quality templates. Our MixFormer trackers set a new state-of-the-art performance on seven tracking benchmarks, including LaSOT, TrackingNet, VOT2020, GOT-10 k, OTB100, TOTB and UAV123. In particular, our MixViT-L achieves AUC scores of 73.3% on LaSOT, 86.1% on TrackingNet and 82.8% on TOTB.","['transformers', 'MixFormer trackers', 'supervised pre-training', 'self-supervised pre-training', 'masked autoencoder pre-training']"
2024,https://openalex.org/W4392816828,Psychology,Role of Artificial Intelligence in Higher Education- An Empirical Investigation,"The importance of artificial intelligence (AI) is growing in all economic sectors and thus also in higher education. In recent years, there have been significant developments in this concept of ""Artificial Intelligence in Education (AIED)"". The purpose of this study was to find out how the concept of artificial intelligence can be applied to teaching and learning in higher education and the implications of the use of artificial intelligence in higher education. The impact of the development of technologies on learning is often studied on the methods and scope of learning and teaching. Artificial intelligence enables higher education services to become easily accessible with extraordinary speed, not only in the classroom but also outside the classroom. This report seeks to explore how AI will become an integral part of universities and seeks to examine its immediate and future impact on various aspects of higher education. The challenges of implementing AI in these institutes were also explored. As artificial intelligence (AI) research in education increases, many researchers in the field believe that the role of teachers, schools and leaders in education will change. In this regard, the aim of this study is to investigate which are the possible scenarios for the arrival of artificial intelligence in education and what impact it can have on the future of schools. In this research, it confirmed that artificial intelligence has been widely adopted and used in various forms in education, especially educational institutions. Artificial intelligence was initially implemented in the form of computers and computer-related technologies, moving to web-based and web-based intelligent educational systems, and finally with the use of embedded computing systems and other technologies such as humanoid robots and web-based chatbots teachers &amp; tasks and assignments independently or with tutors. With these platforms, teachers could perform various administrative tasks such as grading and Work more effectively and efficiently and achieve higher quality in your learning activities. On the other hand, because the systems use machine learning and adaptability, the curriculum and content are adapted which improved uptake and retention, which improved the student experience and the overall quality of education.",['machine learning']
2024,https://openalex.org/W4397026358,Psychology,Automated Classification of Cognitive Visual Objects Using Multivariate Swarm Sparse Decomposition From Multichannel EEG-MEG Signals,"In visual object decoding, magnetoencephalogram (MEG) and electroencephalogram (EEG) activation patterns demonstrate the utmost discriminative cognitive analysis due to their multivariate oscillatory nature. However, high noise in the recorded EEG-MEG signals and subject-specific variability make it extremely difficult to classify subject's cognitive responses to different visual stimuli. The proposed method is a multivariate extension of the swarm sparse decomposition method (MSSDM) for multivariate pattern analysis of EEG-MEG-based visual activation signals. In comparison, it is an advanced technique for decomposing nonstationary multicomponent signals into a finite number of channel-aligned oscillatory components that significantly enhance visual activation-related sub-bands. The MSSDM method adopts multivariate swarm filtering and sparse spectrum to automatically deliver optimal frequency bands in channel-specific sparse spectrums, resulting in improved filter banks. By combining the advantages of the multivariate SSDM and Riemann's correlation-assisted fusion feature (RCFF), the MSSDM-RCFF algorithm is investigated to improve the visual object recognition ability of EEG-MEG signals. We have also proposed time–frequency representation based on MSSDM to analyze discriminative cognitive patterns of different visual object classes from multichannel EEG-MEG signals. A proposed MSSDM is evaluated on multivariate synthetic signals and multivariate EEG-MEG signals using five classifiers. The proposed fusion feature and linear discriminant analysis classifier-based framework outperformed all existing state-of-the-art methods used for visual object detection and achieved the highest accuracy of 86.42% using tenfold cross-validation on EEG-MEG multichannel signals.","['sparse spectrum', 'linear discriminant analysis classifier']"
2024,https://openalex.org/W4403619648,Psychology,Enhancing black-box models: Advances in explainable artificial intelligence for ethical decision-making,"Transparency, trust, and accountability are among the issues raised by artificial intelligence's (AI) growing reliance on black-box models, especially in high-stakes industries like healthcare, finance, and criminal justice. These models, which are frequently distinguished by their intricacy and opacity, are capable of producing extremely accurate forecasts, but users and decision-makers are still unable to fully understand how they operate. In response to this challenge, the field of Explainable AI (XAI) has emerged with the goal of demystifying these models by offering insights into their decision-making processes. Our ability to interpret model behavior has greatly improved with recent developments in XAI techniques, such as SHAP (Shapley Additive Explanations), LIME (Local Interpretable Model-agnostic Explanations), and counterfactual explanations. These instruments make it easier to recognize bias, promote trust, and guarantee adherence to moral principles and laws like the GDPR and the AI Act. Modern XAI techniques are reviewed in this research along with how they are used in moral decision-making. It looks at how explainability can improve fairness, reduce the risks of AI bias and discrimination, and assist well-informed decision-making in a variety of industries. It also examines the trade-offs between performance and interpretability of models, as well as the growing trends toward user-centric explainability techniques. In order to ensure responsible AI development and deployment, XAI's role in fostering accountability and transparency will become increasingly important as AI becomes more integrated into critical systems.","['SHAP (Shapley Additive Explanations)', 'LIME (Local Interpretable Model-agnostic Explanations)', 'counterfactual explanations']"
2024,https://openalex.org/W4390562274,Psychology,Active inference as a theory of sentient behavior,"This review paper offers an overview of the history and future of active inference—a unifying perspective on action and perception. Active inference is based upon the idea that sentient behavior depends upon our brains' implicit use of internal models to predict, infer, and direct action. Our focus is upon the conceptual roots and development of this theory of (basic) sentience and does not follow a rigid chronological narrative. We trace the evolution from Helmholtzian ideas on unconscious inference, through to a contemporary understanding of action and perception. In doing so, we touch upon related perspectives, the neural underpinnings of active inference, and the opportunities for future development. Key steps in this development include the formulation of predictive coding models and related theories of neuronal message passing, the use of sequential models for planning and policy optimization, and the importance of hierarchical (temporally) deep internal (i.e., generative or world) models. Active inference has been used to account for aspects of anatomy and neurophysiology, to offer theories of psychopathology in terms of aberrant precision control, and to unify extant psychological theories. We anticipate further development in all these areas and note the exciting early work applying active inference beyond neuroscience. This suggests a future not just in biology, but in robotics, machine learning, and artificial intelligence.","['active inference', 'predictive coding models', 'sequential models for planning and policy optimization']"
2024,https://openalex.org/W4391345489,Psychology,CLARUS: An interactive explainable AI platform for manual counterfactuals in graph neural networks,"Lack of trust in artificial intelligence (AI) models in medicine is still the key blockage for the use of AI in clinical decision support systems (CDSS). Although AI models are already performing excellently in systems medicine, their black-box nature entails that patient-specific decisions are incomprehensible for the physician. Explainable AI (XAI) algorithms aim to ""explain"" to a human domain expert, which input features influenced a specific recommendation. However, in the clinical domain, these explanations must lead to some degree of causal understanding by a clinician. We developed the CLARUS platform, aiming to promote human understanding of graph neural network (GNN) predictions. CLARUS enables the visualisation of patient-specific networks, as well as, relevance values for genes and interactions, computed by XAI methods, such as GNNExplainer. This enables domain experts to gain deeper insights into the network and more importantly, the expert can interactively alter the patient-specific network based on the acquired understanding and initiate re-prediction or retraining. This interactivity allows us to ask manual counterfactual questions and analyse the effects on the GNN prediction. We present the first interactive XAI platform prototype, CLARUS, that allows not only the evaluation of specific human counterfactual questions based on user-defined alterations of patient networks and a re-prediction of the clinical outcome but also a retraining of the entire GNN after changing the underlying graph structures. The platform is currently hosted by the GWDG on https://rshiny.gwdg.de/apps/clarus/.","['graph neural network (GNN)', 'GNNExplainer']"
2024,https://openalex.org/W4393157467,Psychology,Visual Adversarial Examples Jailbreak Aligned Large Language Models,"Warning: this paper contains data, prompts, and model outputs that are offensive in nature. Recently, there has been a surge of interest in integrating vision into Large Language Models (LLMs), exemplified by Visual Language Models (VLMs) such as Flamingo and GPT-4. This paper sheds light on the security and safety implications of this trend. First, we underscore that the continuous and high-dimensional nature of the visual input makes it a weak link against adversarial attacks, representing an expanded attack surface of vision-integrated LLMs. Second, we highlight that the versatility of LLMs also presents visual attackers with a wider array of achievable adversarial objectives, extending the implications of security failures beyond mere misclassification. As an illustration, we present a case study in which we exploit visual adversarial examples to circumvent the safety guardrail of aligned LLMs with integrated vision. Intriguingly, we discover that a single visual adversarial example can universally jailbreak an aligned LLM, compelling it to heed a wide range of harmful instructions (that it otherwise would not) and generate harmful content that transcends the narrow scope of a `few-shot' derogatory corpus initially employed to optimize the adversarial example. Our study underscores the escalating adversarial risks associated with the pursuit of multimodality. Our findings also connect the long-studied adversarial vulnerabilities of neural networks to the nascent field of AI alignment. The presented attack suggests a fundamental adversarial challenge for AI alignment, especially in light of the emerging trend toward multimodality in frontier foundation models.","['Visual Language Models (VLMs)', 'Flamingo', 'GPT-4']"
2024,https://openalex.org/W4400981456,Psychology,Multimodal data integration for oncology in the era of deep neural networks: a review,"Cancer research encompasses data across various scales, modalities, and resolutions, from screening and diagnostic imaging to digitized histopathology slides to various types of molecular data and clinical records. The integration of these diverse data types for personalized cancer care and predictive modeling holds the promise of enhancing the accuracy and reliability of cancer screening, diagnosis, and treatment. Traditional analytical methods, which often focus on isolated or unimodal information, fall short of capturing the complex and heterogeneous nature of cancer data. The advent of deep neural networks has spurred the development of sophisticated multimodal data fusion techniques capable of extracting and synthesizing information from disparate sources. Among these, Graph Neural Networks (GNNs) and Transformers have emerged as powerful tools for multimodal learning, demonstrating significant success. This review presents the foundational principles of multimodal learning including oncology data modalities, taxonomy of multimodal learning, and fusion strategies. We delve into the recent advancements in GNNs and Transformers for the fusion of multimodal data in oncology, spotlighting key studies and their pivotal findings. We discuss the unique challenges of multimodal learning, such as data heterogeneity and integration complexities, alongside the opportunities it presents for a more nuanced and comprehensive understanding of cancer. Finally, we present some of the latest comprehensive multimodal pan-cancer data sources. By surveying the landscape of multimodal data integration in oncology, our goal is to underline the transformative potential of multimodal GNNs and Transformers. Through technological advancements and the methodological innovations presented in this review, we aim to chart a course for future research in this promising field. This review may be the first that highlights the current state of multimodal modeling applications in cancer using GNNs and transformers, presents comprehensive multimodal oncology data sources, and sets the stage for multimodal evolution, encouraging further exploration and development in personalized cancer care.","['deep neural networks', 'Graph Neural Networks (GNNs)', 'Transformers']"
2024,https://openalex.org/W4391774550,Psychology,Role of machine learning and deep learning techniques in EEG-based BCI emotion recognition system: a review,"Abstract Emotion is a subjective psychophysiological reaction coming from external stimuli which impacts every aspect of our daily lives. Due to the continuing development of non-invasive and portable sensor technologies, such as brain-computer interfaces (BCI), intellectuals from several fields have been interested in emotion recognition techniques. Human emotions can be recognised using a variety of behavioural cues, including gestures and body language, voice, and physiological markers. The first three, however, might be ineffective because people sometimes conceal their genuine emotions either intentionally or unknowingly. More precise and objective emotion recognition can be accomplished using physiological signals. Among other physiological signals, Electroencephalogram (EEG) is more responsive and sensitive to variation in affective states. Various EEG-based emotion recognition methods have recently been introduced. This study reviews EEG-based BCIs for emotion identification and gives an outline of the progress made in this field. A summary of the datasets and techniques utilised to evoke human emotions and various emotion models is also given. We discuss several EEG feature extractions, feature selection/reduction, machine learning, and deep learning algorithms in accordance with standard emotional identification process. We provide an overview of the human brain's EEG rhythms, which are closely related to emotional states. We also go over a number of EEG-based emotion identification research and compare numerous machine learning and deep learning techniques. In conclusion, this study highlights the applications, challenges and potential areas for future research in identification and classification of human emotional states.",['feature selection/reduction']
2024,https://openalex.org/W4393971547,Psychology,A self-attention-based CNN-Bi-LSTM model for accurate state-of-charge estimation of lithium-ion batteries,"In the quest for clean and efficient energy solutions, lithium-ion batteries have emerged at the forefront of technological innovation. Accurate state-of-charge (SOC) estimation across a broad temperature range is essential for extending battery longevity, and enduring effective management of overcharge and over-discharge conditions. However, prevailing challenges persist in achieving precise SOC estimates and generalizing across a wide temperature range, particularly at lower temperatures. Our comparative analysis reveals that, while a single-layer bidirectional LSTM model with a self-attention mechanism achieves remarkable SOC estimation accuracy at room temperature, the intricacies of SOC estimation at lower temperatures necessitate the incorporation of more hidden layers and more complex network architecture to capture intricate features influencing battery dynamics. Hence, we propose a deep learning model, based on convolutional neural networks integrating bidirectional long short-term memory and self-attention mechanism (CNN-Bi-LSTM-AM), specifically designed to tackle the challenges of achieving accurate SOC estimations across a wide temperature range. The proposed model demonstrates proficiency in capturing both spatial and temporal dependencies critical for lithium-ion battery SOC estimation. Furthermore, the integration of a self-attention mechanism enhances the model's adeptness to discern pertinent features and patterns within the dataset, thereby improving its overall performance and robustness, even in sub-room temperature environments.","['single-layer bidirectional LSTM model with a self-attention mechanism', 'deep learning model based on convolutional neural networks integrating bidirectional long short-term memory and self-attention mechanism (CNN-Bi-LSTM-AM)']"
2024,https://openalex.org/W4399054302,Psychology,Artificial Intelligence in Point-of-Care Biosensing: Challenges and Opportunities,"The integration of artificial intelligence (AI) into point-of-care (POC) biosensing has the potential to revolutionize diagnostic methodologies by offering rapid, accurate, and accessible health assessment directly at the patient level. This review paper explores the transformative impact of AI technologies on POC biosensing, emphasizing recent computational advancements, ongoing challenges, and future prospects in the field. We provide an overview of core biosensing technologies and their use at the POC, highlighting ongoing issues and challenges that may be solved with AI. We follow with an overview of AI methodologies that can be applied to biosensing, including machine learning algorithms, neural networks, and data processing frameworks that facilitate real-time analytical decision-making. We explore the applications of AI at each stage of the biosensor development process, highlighting the diverse opportunities beyond simple data analysis procedures. We include a thorough analysis of outstanding challenges in the field of AI-assisted biosensing, focusing on the technical and ethical challenges regarding the widespread adoption of these technologies, such as data security, algorithmic bias, and regulatory compliance. Through this review, we aim to emphasize the role of AI in advancing POC biosensing and inform researchers, clinicians, and policymakers about the potential of these technologies in reshaping global healthcare landscapes.",['neural networks']
2024,https://openalex.org/W4399426804,Psychology,Evaluating the persuasive influence of political microtargeting with large language models,"Recent advancements in large language models (LLMs) have raised the prospect of scalable, automated, and fine-grained political microtargeting on a scale previously unseen; however, the persuasive influence of microtargeting with LLMs remains unclear. Here, we build a custom web application capable of integrating self-reported demographic and political data into GPT-4 prompts in real-time, facilitating the live creation of unique messages tailored to persuade individual users on four political issues. We then deploy this application in a preregistered randomized control experiment ( n = 8,587) to investigate the extent to which access to individual-level data increases the persuasive influence of GPT-4. Our approach yields two key findings. First, messages generated by GPT-4 were broadly persuasive, in some cases increasing support for an issue stance by up to 12 percentage points. Second, in aggregate, the persuasive impact of microtargeted messages was not statistically different from that of non-microtargeted messages (4.83 vs. 6.20 percentage points, respectively, P = 0.226). These trends hold even when manipulating the type and number of attributes used to tailor the message. These findings suggest—contrary to widespread speculation—that the influence of current LLMs may reside not in their ability to tailor messages to individuals but rather in the persuasiveness of their generic, nontargeted messages. We release our experimental dataset, GPTarget2024 , as an empirical baseline for future research.",['GPT-4']
2024,https://openalex.org/W4390506881,Medicine,Discovering biomarkers associated and predicting cardiovascular disease with high accuracy using a novel nexus of machine learning techniques for precision medicine,"Abstract Personalized interventions are deemed vital given the intricate characteristics, advancement, inherent genetic composition, and diversity of cardiovascular diseases (CVDs). The appropriate utilization of artificial intelligence (AI) and machine learning (ML) methodologies can yield novel understandings of CVDs, enabling improved personalized treatments through predictive analysis and deep phenotyping. In this study, we proposed and employed a novel approach combining traditional statistics and a nexus of cutting-edge AI/ML techniques to identify significant biomarkers for our predictive engine by analyzing the complete transcriptome of CVD patients. After robust gene expression data pre-processing, we utilized three statistical tests (Pearson correlation, Chi-square test, and ANOVA) to assess the differences in transcriptomic expression and clinical characteristics between healthy individuals and CVD patients. Next, the recursive feature elimination classifier assigned rankings to transcriptomic features based on their relation to the case–control variable. The top ten percent of commonly observed significant biomarkers were evaluated using four unique ML classifiers (Random Forest, Support Vector Machine, Xtreme Gradient Boosting Decision Trees, and k-Nearest Neighbors). After optimizing hyperparameters, the ensembled models, which were implemented using a soft voting classifier, accurately differentiated between patients and healthy individuals. We have uncovered 18 transcriptomic biomarkers that are highly significant in the CVD population that were used to predict disease with up to 96% accuracy. Additionally, we cross-validated our results with clinical records collected from patients in our cohort. The identified biomarkers served as potential indicators for early detection of CVDs. With its successful implementation, our newly developed predictive engine provides a valuable framework for identifying patients with CVDs based on their biomarker profiles.","['Random Forest', 'Support Vector Machine', 'Xtreme Gradient Boosting Decision Trees', 'k-Nearest Neighbors', 'soft voting classifier']"
2024,https://openalex.org/W4391292768,Medicine,Improving large language models for clinical named entity recognition via prompt engineering,"Abstract Importance The study highlights the potential of large language models, specifically GPT-3.5 and GPT-4, in processing complex clinical data and extracting meaningful information with minimal training data. By developing and refining prompt-based strategies, we can significantly enhance the models’ performance, making them viable tools for clinical NER tasks and possibly reducing the reliance on extensive annotated datasets. Objectives This study quantifies the capabilities of GPT-3.5 and GPT-4 for clinical named entity recognition (NER) tasks and proposes task-specific prompts to improve their performance. Materials and Methods We evaluated these models on 2 clinical NER tasks: (1) to extract medical problems, treatments, and tests from clinical notes in the MTSamples corpus, following the 2010 i2b2 concept extraction shared task, and (2) to identify nervous system disorder-related adverse events from safety reports in the vaccine adverse event reporting system (VAERS). To improve the GPT models' performance, we developed a clinical task-specific prompt framework that includes (1) baseline prompts with task description and format specification, (2) annotation guideline-based prompts, (3) error analysis-based instructions, and (4) annotated samples for few-shot learning. We assessed each prompt's effectiveness and compared the models to BioClinicalBERT. Results Using baseline prompts, GPT-3.5 and GPT-4 achieved relaxed F1 scores of 0.634, 0.804 for MTSamples and 0.301, 0.593 for VAERS. Additional prompt components consistently improved model performance. When all 4 components were used, GPT-3.5 and GPT-4 achieved relaxed F1 socres of 0.794, 0.861 for MTSamples and 0.676, 0.736 for VAERS, demonstrating the effectiveness of our prompt framework. Although these results trail BioClinicalBERT (F1 of 0.901 for the MTSamples dataset and 0.802 for the VAERS), it is very promising considering few training samples are needed. Discussion The study’s findings suggest a promising direction in leveraging LLMs for clinical NER tasks. However, while the performance of GPT models improved with task-specific prompts, there's a need for further development and refinement. LLMs like GPT-4 show potential in achieving close performance to state-of-the-art models like BioClinicalBERT, but they still require careful prompt engineering and understanding of task-specific knowledge. The study also underscores the importance of evaluation schemas that accurately reflect the capabilities and performance of LLMs in clinical settings. Conclusion While direct application of GPT models to clinical NER tasks falls short of optimal performance, our task-specific prompt framework, incorporating medical knowledge and training samples, significantly enhances GPT models' feasibility for potential clinical applications.","['large language models (GPT-3.5)', 'large language models (GPT-4)', 'prompt-based strategies', 'few-shot learning', 'BioClinicalBERT']"
2024,https://openalex.org/W4392754729,Medicine,"Revolutionizing agriculture with artificial intelligence: plant disease detection methods, applications, and their limitations","Accurate and rapid plant disease detection is critical for enhancing long-term agricultural yield. Disease infection poses the most significant challenge in crop production, potentially leading to economic losses. Viruses, fungi, bacteria, and other infectious organisms can affect numerous plant parts, including roots, stems, and leaves. Traditional techniques for plant disease detection are time-consuming, require expertise, and are resource-intensive. Therefore, automated leaf disease diagnosis using artificial intelligence (AI) with Internet of Things (IoT) sensors methodologies are considered for the analysis and detection. This research examines four crop diseases: tomato, chilli, potato, and cucumber. It also highlights the most prevalent diseases and infections in these four types of vegetables, along with their symptoms. This review provides detailed predetermined steps to predict plant diseases using AI. Predetermined steps include image acquisition, preprocessing, segmentation, feature selection, and classification. Machine learning (ML) and deep understanding (DL) detection models are discussed. A comprehensive examination of various existing ML and DL-based studies to detect the disease of the following four crops is discussed, including the datasets used to evaluate these studies. We also provided the list of plant disease detection datasets. Finally, different ML and DL application problems are identified and discussed, along with future research prospects, by combining AI with IoT platforms like smart drones for field-based disease detection and monitoring. This work will help other practitioners in surveying different plant disease detection strategies and the limits of present systems.","['machine learning (ML)', 'deep learning (DL)']"
2024,https://openalex.org/W4392791588,Medicine,Can large language models replace humans in systematic reviews? Evaluating <scp>GPT</scp>‐4's efficacy in screening and extracting data from peer‐reviewed and grey literature in multiple languages,"Systematic reviews are vital for guiding practice, research and policy, although they are often slow and labour-intensive. Large language models (LLMs) could speed up and automate systematic reviews, but their performance in such tasks has yet to be comprehensively evaluated against humans, and no study has tested Generative Pre-Trained Transformer (GPT)-4, the biggest LLM so far. This pre-registered study uses a ""human-out-of-the-loop"" approach to evaluate GPT-4's capability in title/abstract screening, full-text review and data extraction across various literature types and languages. Although GPT-4 had accuracy on par with human performance in some tasks, results were skewed by chance agreement and dataset imbalance. Adjusting for these caused performance scores to drop across all stages: for data extraction, performance was moderate, and for screening, it ranged from none in highly balanced literature datasets (~1:1) to moderate in those datasets where the ratio of inclusion to exclusion in studies was imbalanced (~1:3). When screening full-text literature using highly reliable prompts, GPT-4's performance was more robust, reaching ""human-like"" levels. Although our findings indicate that, currently, substantial caution should be exercised if LLMs are being used to conduct systematic reviews, they also offer preliminary evidence that, for certain review tasks delivered under specific conditions, LLMs can rival human performance.",['Generative Pre-Trained Transformer (GPT)-4']
2024,https://openalex.org/W4395050972,Medicine,Optimization of hepatological clinical guidelines interpretation by large language models: a retrieval augmented generation-based framework,"Abstract Large language models (LLMs) can potentially transform healthcare, particularly in providing the right information to the right provider at the right time in the hospital workflow. This study investigates the integration of LLMs into healthcare, specifically focusing on improving clinical decision support systems (CDSSs) through accurate interpretation of medical guidelines for chronic Hepatitis C Virus infection management. Utilizing OpenAI’s GPT-4 Turbo model, we developed a customized LLM framework that incorporates retrieval augmented generation (RAG) and prompt engineering. Our framework involved guideline conversion into the best-structured format that can be efficiently processed by LLMs to provide the most accurate output. An ablation study was conducted to evaluate the impact of different formatting and learning strategies on the LLM’s answer generation accuracy. The baseline GPT-4 Turbo model’s performance was compared against five experimental setups with increasing levels of complexity: inclusion of in-context guidelines, guideline reformatting, and implementation of few-shot learning. Our primary outcome was the qualitative assessment of accuracy based on expert review, while secondary outcomes included the quantitative measurement of similarity of LLM-generated responses to expert-provided answers using text-similarity scores. The results showed a significant improvement in accuracy from 43 to 99% ( p &lt; 0.001), when guidelines were provided as context in a coherent corpus of text and non-text sources were converted into text. In addition, few-shot learning did not seem to improve overall accuracy. The study highlights that structured guideline reformatting and advanced prompt engineering (data quality vs. data quantity) can enhance the efficacy of LLM integrations to CDSSs for guideline delivery.","['OpenAI’s GPT-4 Turbo model', 'retrieval augmented generation (RAG)', 'few-shot learning']"
2024,https://openalex.org/W4393247259,Medicine,Employing deep learning and transfer learning for accurate brain tumor detection,"Abstract Artificial intelligence-powered deep learning methods are being used to diagnose brain tumors with high accuracy, owing to their ability to process large amounts of data. Magnetic resonance imaging stands as the gold standard for brain tumor diagnosis using machine vision, surpassing computed tomography, ultrasound, and X-ray imaging in its effectiveness. Despite this, brain tumor diagnosis remains a challenging endeavour due to the intricate structure of the brain. This study delves into the potential of deep transfer learning architectures to elevate the accuracy of brain tumor diagnosis. Transfer learning is a machine learning technique that allows us to repurpose pre-trained models on new tasks. This can be particularly useful for medical imaging tasks, where labelled data is often scarce. Four distinct transfer learning architectures were assessed in this study: ResNet152, VGG19, DenseNet169, and MobileNetv3. The models were trained and validated on a dataset from benchmark database: Kaggle. Five-fold cross validation was adopted for training and testing. To enhance the balance of the dataset and improve the performance of the models, image enhancement techniques were applied to the data for the four categories: pituitary, normal, meningioma, and glioma. MobileNetv3 achieved the highest accuracy of 99.75%, significantly outperforming other existing methods. This demonstrates the potential of deep transfer learning architectures to revolutionize the field of brain tumor diagnosis.","['deep learning', 'deep transfer learning', 'transfer learning', 'ResNet152', 'VGG19', 'DenseNet169', 'MobileNetv3']"
2024,https://openalex.org/W4391103530,Medicine,Transformative Breast Cancer Diagnosis using CNNs with Optimized ReduceLROnPlateau and Early Stopping Enhancements,"Abstract Breast cancer stands as a paramount public health concern worldwide, underscoring an imperative necessity within the research sphere for precision-driven and efficacious methodologies facilitating accurate detection. The existing diagnostic approaches in breast cancer often suffer from limitations in accuracy and efficiency, leading to delayed detection and subsequent challenges in personalized treatment planning. The primary focus of this research is to overcome these shortcomings by harnessing the power of advanced deep learning techniques, thereby revolutionizing the precision and reliability of breast cancer classification. This research addresses the critical need for improved breast cancer diagnostics by introducing a novel Convolutional Neural Network (CNN) model integrated with an Early Stopping callback and ReduceLROnPlateau callback. By enhancing the precision and reliability of breast cancer classification, the study aims to overcome the limitations of existing diagnostic methods, ultimately leading to better patient outcomes and reduced mortality rates. The comprehensive methodology includes diverse datasets, meticulous image preprocessing, robust model training, and validation strategies, emphasizing the model's adaptability and reliability in varied clinical contexts. The findings showcase the CNN model's exceptional performance, achieving a 95.2% accuracy rate in distinguishing cancerous and non-cancerous breast tissue in the integrated dataset, thereby demonstrating its potential for enhancing clinical decision-making and fostering the development of AI-driven diagnostic solutions.","['Convolutional Neural Network (CNN)', 'Early Stopping callback']"
2024,https://openalex.org/W4402780379,Medicine,Investigating Spatial Effects through Machine Learning and Leveraging Explainable AI for Child Malnutrition in Pakistan,"While socioeconomic gradients in regional health inequalities are firmly established, the synergistic interactions between socioeconomic deprivation and climate vulnerability within convenient proximity and neighbourhood locations with health disparities remain poorly explored and thus require deep understanding within a regional context. Furthermore, disregarding the importance of spatial spillover effects and nonlinear effects of covariates on childhood stunting are inevitable in dealing with an enduring issue of regional health inequalities. The present study aims to investigate the spatial inequalities in childhood stunting at the district level in Pakistan and validate the importance of spatial lag in predicting childhood stunting. Furthermore, it examines the presence of any nonlinear relationships among the selected independent features with childhood stunting. The study utilized data related to socioeconomic features from MICS 2017–2018 and climatic data from Integrated Contextual Analysis. A multi-model approach was employed to address the research questions, which included Ordinary Least Squares Regression (OLS), various Spatial Models, Machine Learning Algorithms and Explainable Artificial Intelligence methods. Firstly, OLS was used to analyse and test the linear relationships among selected variables. Secondly, Spatial Durbin Error Model (SDEM) was used to detect and capture the impact of spatial spillover on childhood stunting. Third, XGBoost and Random Forest machine learning algorithms were employed to examine and validate the importance of the spatial lag component. Finally, EXAI methods such as SHapley were utilized to identify potential nonlinear relationships. The study found a clear pattern of spatial clustering and geographical disparities in childhood stunting, with multidimensional poverty, high climate vulnerability and early marriage worsening childhood stunting. In contrast, low climate vulnerability, high exposure to mass media and high women’s literacy were found to reduce childhood stunting. The use of machine learning algorithms, specifically XGBoost and Random Forest, highlighted the significant role played by the average value in the neighbourhood in predicting childhood stunting in nearby districts, confirming that the spatial spillover effect is not bounded by geographical boundaries. Furthermore, EXAI methods such as partial dependency plot reveal the existence of a nonlinear relationship between multidimensional poverty and childhood stunting. The study’s findings provide valuable insights into the spatial distribution of childhood stunting in Pakistan, emphasizing the importance of considering spatial effects in predicting childhood stunting. Individual and household-level factors such as exposure to mass media and women’s literacy have shown positive implications for childhood stunting. It further provides a justification for the usage of EXAI methods to draw better insights and propose customised intervention policies accordingly.","['XGBoost', 'Random Forest', 'partial dependency plot']"
2024,https://openalex.org/W4393119757,Medicine,Unmasking bias in artificial intelligence: a systematic review of bias detection and mitigation strategies in electronic health record-based models,"Abstract Objectives Leveraging artificial intelligence (AI) in conjunction with electronic health records (EHRs) holds transformative potential to improve healthcare. However, addressing bias in AI, which risks worsening healthcare disparities, cannot be overlooked. This study reviews methods to handle various biases in AI models developed using EHR data. Materials and Methods We conducted a systematic review following the Preferred Reporting Items for Systematic Reviews and Meta-analyses guidelines, analyzing articles from PubMed, Web of Science, and IEEE published between January 01, 2010 and December 17, 2023. The review identified key biases, outlined strategies for detecting and mitigating bias throughout the AI model development, and analyzed metrics for bias assessment. Results Of the 450 articles retrieved, 20 met our criteria, revealing 6 major bias types: algorithmic, confounding, implicit, measurement, selection, and temporal. The AI models were primarily developed for predictive tasks, yet none have been deployed in real-world healthcare settings. Five studies concentrated on the detection of implicit and algorithmic biases employing fairness metrics like statistical parity, equal opportunity, and predictive equity. Fifteen studies proposed strategies for mitigating biases, especially targeting implicit and selection biases. These strategies, evaluated through both performance and fairness metrics, predominantly involved data collection and preprocessing techniques like resampling and reweighting. Discussion This review highlights evolving strategies to mitigate bias in EHR-based AI models, emphasizing the urgent need for both standardized and detailed reporting of the methodologies and systematic real-world testing and evaluation. Such measures are essential for gauging models’ practical impact and fostering ethical AI that ensures fairness and equity in healthcare.","['resampling', 'reweighting']"
2024,https://openalex.org/W4391235397,Medicine,Real-Time Plant Disease Dataset Development and Detection of Plant Disease Using Deep Learning,"Agriculture plays a significant role in meeting food needs and providing food security for the increasingly growing global population, which has increased by 0.88% since 2022. Plant diseases can reduce food production and affect food security. Worldwide crop loss due to plant disease is estimated to be around 14.1%. The lack of proper identification of plant disease at the early stages of infection can result in inappropriate disease control measures. Therefore, the automatic identification and diagnosis of plant diseases are highly recommended. Lack of availability of large amounts of data that are not processed to a large extent is one of the main challenges in plant disease diagnosis. In the current manuscript, we developed datasets for food grains specifically for rice, wheat, and maize to address the identified challenges. The developed datasets consider the common diseases (two bacterial diseases and two fungal diseases of rice, four fungal diseases of maize, and four fungal diseases of wheat) that affect crop yields and cause damage to the whole plant. The datasets developed were applied to eight fine-tuned deep learning models with the same training hyperparameters. The experimental results based on eight fine-tuned deep learning models show that, while recognizing maize leaf diseases, the models Xception and MobileNet performed best with a testing accuracy of 0.9580 and 0.9464 respectively. Similarly, while recognizing the wheat leaf diseases, the models MobileNetV2 and MobileNet performed best with a testing accuracy of 0.9632 and 0.9628 respectively. The Xception and Inception V3 models performed best, with a testing accuracy of 0.9728 and 0.9620, respectively, for recognizing rice leaf diseases. The research also proposes a new convolutional neural network (CNN) model trained from scratch on all three food grain datasets developed. The proposed model performs well and shows a testing accuracy of 0.9704, 0.9706, and 0.9808 respectively on the maize, rice, and wheat datasets.","['fine-tuned deep learning models', 'Xception', 'MobileNet', 'MobileNetV2', 'Inception V3', 'convolutional neural network (CNN) model trained from scratch']"
2024,https://openalex.org/W4396494945,Medicine,Vision–language foundation model for echocardiogram interpretation,"Abstract The development of robust artificial intelligence models for echocardiography has been limited by the availability of annotated clinical data. Here, to address this challenge and improve the performance of cardiac imaging models, we developed EchoCLIP, a vision–language foundation model for echocardiography, that learns the relationship between cardiac ultrasound images and the interpretations of expert cardiologists across a wide range of patients and indications for imaging. After training on 1,032,975 cardiac ultrasound videos and corresponding expert text, EchoCLIP performs well on a diverse range of benchmarks for cardiac image interpretation, despite not having been explicitly trained for individual interpretation tasks. EchoCLIP can assess cardiac function (mean absolute error of 7.1% when predicting left ventricular ejection fraction in an external validation dataset) and identify implanted intracardiac devices (area under the curve (AUC) of 0.84, 0.92 and 0.97 for pacemakers, percutaneous mitral valve repair and artificial aortic valves, respectively). We also developed a long-context variant (EchoCLIP-R) using a custom tokenizer based on common echocardiography concepts. EchoCLIP-R accurately identified unique patients across multiple videos (AUC of 0.86), identified clinical transitions such as heart transplants (AUC of 0.79) and cardiac surgery (AUC 0.77) and enabled robust image-to-text search (mean cross-modal retrieval rank in the top 1% of candidate text reports). These capabilities represent a substantial step toward understanding and applying foundation models in cardiovascular imaging for preliminary interpretation of echocardiographic findings.",['vision–language foundation model']
2024,https://openalex.org/W4391320803,Medicine,Oral squamous cell carcinoma detection using EfficientNet on histopathological images,"Introduction Oral Squamous Cell Carcinoma (OSCC) poses a significant challenge in oncology due to the absence of precise diagnostic tools, leading to delays in identifying the condition. Current diagnostic methods for OSCC have limitations in accuracy and efficiency, highlighting the need for more reliable approaches. This study aims to explore the discriminative potential of histopathological images of oral epithelium and OSCC. By utilizing a database containing 1224 images from 230 patients, captured at varying magnifications and publicly available, a customized deep learning model based on EfficientNetB3 was developed. The model’s objective was to differentiate between normal epithelium and OSCC tissues by employing advanced techniques such as data augmentation, regularization, and optimization. Methods The research utilized a histopathological imaging database for Oral Cancer analysis, incorporating 1224 images from 230 patients. These images, taken at various magnifications, formed the basis for training a specialized deep learning model built upon the EfficientNetB3 architecture. The model underwent training to distinguish between normal epithelium and OSCC tissues, employing sophisticated methodologies including data augmentation, regularization techniques, and optimization strategies. Results The customized deep learning model achieved significant success, showcasing a remarkable 99% accuracy when tested on the dataset. This high accuracy underscores the model’s efficacy in effectively discerning between normal epithelium and OSCC tissues. Furthermore, the model exhibited impressive precision, recall, and F1-score metrics, reinforcing its potential as a robust diagnostic tool for OSCC. Discussion This research demonstrates the promising potential of employing deep learning models to address the diagnostic challenges associated with OSCC. The model’s ability to achieve a 99% accuracy rate on the test dataset signifies a considerable leap forward in earlier and more accurate detection of OSCC. Leveraging advanced techniques in machine learning, such as data augmentation and optimization, has shown promising results in improving patient outcomes through timely and precise identification of OSCC.",['deep learning model based on EfficientNetB3']
2024,https://openalex.org/W4400993192,Medicine,Damage identification of steel bridge based on data augmentation and adaptive optimization neural network,"With the advancement of deep learning, data-driven structural damage identification (SDI) has shown considerable development. However, collecting vibration signals related to structural damage poses certain challenges, which can undermine the accuracy of the identification results produced by data-driven SDI methods in scenarios where data is scarce. This paper introduces an innovative approach to bridge SDI in a few-shot context by integrating an adaptive simulated annealing particle swarm optimization-convolutional neural network (ASAPSO-CNN) as the foundational framework, augmented by data enhancement techniques. Firstly, three specific types of noise are introduced to augment the source signals used for training. Subsequently, the source signals and augmented signals are recombined to construct a four-dimensional matrix as the input to the CNN, while defining the damage feature vector as the output. Secondly, a CNN is constructed to establish the mapping relationship between the input and output. Then, an adaptive fitness function is proposed that simultaneously considers the accuracy of SDI, model complexity, and training efficiency. The ASAPSO is employed to adaptively optimize the hyperparameters of the CNN. The proposed method is validated on an experimental model of a three-span continuous beam. It is compared with four other data-driven methods, demonstrating good effectiveness and robustness of SDI under cases of scarce data. Finally, the effectiveness of this SDI method is validated in a real-world case of a steel truss bridge.",['convolutional neural network (CNN)']
2024,https://openalex.org/W4390588437,Medicine,Enhancing heart disease prediction using a self-attention-based transformer model,"Abstract Cardiovascular diseases (CVDs) continue to be the leading cause of more than 17 million mortalities worldwide. The early detection of heart failure with high accuracy is crucial for clinical trials and therapy. Patients will be categorized into various types of heart disease based on characteristics like blood pressure, cholesterol levels, heart rate, and other characteristics. With the use of an automatic system, we can provide early diagnoses for those who are prone to heart failure by analyzing their characteristics. In this work, we deploy a novel self-attention-based transformer model, that combines self-attention mechanisms and transformer networks to predict CVD risk. The self-attention layers capture contextual information and generate representations that effectively model complex patterns in the data. Self-attention mechanisms provide interpretability by giving each component of the input sequence a certain amount of attention weight. This includes adjusting the input and output layers, incorporating more layers, and modifying the attention processes to collect relevant information. This also makes it possible for physicians to comprehend which features of the data contributed to the model's predictions. The proposed model is tested on the Cleveland dataset, a benchmark dataset of the University of California Irvine (UCI) machine learning (ML) repository. Comparing the proposed model to several baseline approaches, we achieved the highest accuracy of 96.51%. Furthermore, the outcomes of our experiments demonstrate that the prediction rate of our model is higher than that of other cutting-edge approaches used for heart disease prediction.","['self-attention-based transformer model', 'self-attention mechanisms', 'transformer networks']"
2024,https://openalex.org/W4400937555,Medicine,The diagnostic and triage accuracy of the GPT-3 artificial intelligence model: an observational study,"BackgroundArtificial intelligence (AI) applications in health care have been effective in many areas of medicine, but they are often trained for a single task using labelled data, making deployment and generalisability challenging. How well a general-purpose AI language model performs diagnosis and triage relative to physicians and laypeople is not well understood.MethodsWe compared the predictive accuracy of Generative Pre-trained Transformer 3 (GPT-3)'s diagnostic and triage ability for 48 validated synthetic case vignettes (<50 words; sixth-grade reading level or below) of both common (eg, viral illness) and severe (eg, heart attack) conditions to a nationally representative sample of 5000 lay people from the USA who could use the internet to find the correct options and 21 practising physicians at Harvard Medical School. There were 12 vignettes for each of four triage categories: emergent, within one day, within 1 week, and self-care. The correct diagnosis and triage category (ie, ground truth) for each vignette was determined by two general internists at Harvard Medical School. For each vignette, human respondents and GPT-3 were prompted to list diagnoses in order of likelihood, and the vignette was marked as correct if the ground-truth diagnosis was in the top three of the listed diagnoses. For triage accuracy, we examined whether the human respondents' and GPT-3's selected triage was exactly correct according to the four triage categories, or matched a dichotomised triage variable (emergent or within 1 day vs within 1 week or self-care). We estimated GPT-3's diagnostic and triage confidence on a given vignette using a modified bootstrap resampling procedure, and examined how well calibrated GPT-3's confidence was by computing calibration curves and Brier scores. We also performed subgroup analysis by case acuity, and an error analysis for triage advice to characterise how its advice might affect patients using this tool to decide if they should seek medical care immediately.FindingsAmong all cases, GPT-3 replied with the correct diagnosis in its top three for 88% (42/48, 95% CI 75–94) of cases, compared with 54% (2700/5000, 53–55) for lay individuals (p<0.0001) and 96% (637/666, 94–97) for physicians (p=0·012). GPT-3 triaged 70% correct (34/48, 57–82) versus 74% (3706/5000, 73–75; p=0.60) for lay individuals and 91% (608/666, 89–93%; p<0.0001) for physicians. As measured by the Brier score, GPT-3 confidence in its top prediction was reasonably well calibrated for diagnosis (Brier score=0·18) and triage (Brier score=0·22). We observed an inverse relationship between case acuity and GPT-3 accuracy (p<0·0001) with a fitted trend line of –8·33% decrease in accuracy for every level of increase in case acuity. For triage error analysis, GPT-3 deprioritised truly emergent cases in seven instances.InterpretationA general-purpose AI language model without any content-specific training could perform diagnosis at levels close to, but below, physicians and better than lay individuals. We found that GPT-3's performance was inferior to physicians for triage, sometimes by a large margin, and its performance was closer to that of lay individuals. Although the diagnostic performance of GPT-3 was comparable to physicians, it was significantly better than a typical person using a search engine.FundingThe National Heart, Lung, and Blood Institute.",['Generative Pre-trained Transformer 3 (GPT-3)']
2024,https://openalex.org/W4392285688,Medicine,Machine Learning and Digital Biomarkers Can Detect Early Stages of Neurodegenerative Diseases,"Neurodegenerative diseases (NDs) such as Alzheimer’s Disease (AD) and Parkinson’s Disease (PD) are devastating conditions that can develop without noticeable symptoms, causing irreversible damage to neurons before any signs become clinically evident. NDs are a major cause of disability and mortality worldwide. Currently, there are no cures or treatments to halt their progression. Therefore, the development of early detection methods is urgently needed to delay neuronal loss as soon as possible. Despite advancements in Medtech, the early diagnosis of NDs remains a challenge at the intersection of medical, IT, and regulatory fields. Thus, this review explores “digital biomarkers” (tools designed for remote neurocognitive data collection and AI analysis) as a potential solution. The review summarizes that recent studies combining AI with digital biomarkers suggest the possibility of identifying pre-symptomatic indicators of NDs. For instance, research utilizing convolutional neural networks for eye tracking has achieved significant diagnostic accuracies. ROC-AUC scores reached up to 0.88, indicating high model performance in differentiating between PD patients and healthy controls. Similarly, advancements in facial expression analysis through tools have demonstrated significant potential in detecting emotional changes in ND patients, with some models reaching an accuracy of 0.89 and a precision of 0.85. This review follows a structured approach to article selection, starting with a comprehensive database search and culminating in a rigorous quality assessment and meaning for NDs of the different methods. The process is visualized in 10 tables with 54 parameters describing different approaches and their consequences for understanding various mechanisms in ND changes. However, these methods also face challenges related to data accuracy and privacy concerns. To address these issues, this review proposes strategies that emphasize the need for rigorous validation and rapid integration into clinical practice. Such integration could transform ND diagnostics, making early detection tools more cost-effective and globally accessible. In conclusion, this review underscores the urgent need to incorporate validated digital health tools into mainstream medical practice. This integration could indicate a new era in the early diagnosis of neurodegenerative diseases, potentially altering the trajectory of these conditions for millions worldwide. Thus, by highlighting specific and statistically significant findings, this review demonstrates the current progress in this field and the potential impact of these advancements on the global management of NDs.",['convolutional neural networks']
2024,https://openalex.org/W4390607226,Medicine,RanMerFormer: Randomized vision transformer with token merging for brain tumor classification,"Brains are the control center of the nervous system in human bodies, and brain tumor is one of the most deadly diseases. Currently, magnetic resonance imaging (MRI) is the most effective way to brain tumors early detection in clinical diagnoses due to its superior imaging quality for soft tissues. Manual analysis of brain MRI is error-prone which depends on empirical experience and the fatigue state of the radiologists to a large extent. Computer-aided diagnosis (CAD) systems are becoming more and more impactful because they can provide accurate prediction results based on medical images with advanced techniques from computer vision. Therefore, a novel CAD method for brain tumor classification named RanMerFormer is presented in this paper. A pre-trained vision transformer is used as the backbone model. Then, a merging mechanism is proposed to remove the redundant tokens in the vision transformer, which improves computing efficiency substantially. Finally, a randomized vector functional-link serves as the head in the proposed RanMerFormer, which can be trained swiftly. All the simulation results are obtained from two public benchmark datasets, which reveal that the proposed RanMerFormer can achieve state-of-the-art performance for brain tumor classification. The trained RanMerFormer can be applied in real-world scenarios to assist in brain tumor diagnosis.","['vision transformer', 'randomized vector functional-link']"
2024,https://openalex.org/W4391023920,Medicine,A hybrid deep CNN model for brain tumor image multi-classification,"Abstract The current approach to diagnosing and classifying brain tumors relies on the histological evaluation of biopsy samples, which is invasive, time-consuming, and susceptible to manual errors. These limitations underscore the pressing need for a fully automated, deep-learning-based multi-classification system for brain malignancies. This article aims to leverage a deep convolutional neural network (CNN) to enhance early detection and presents three distinct CNN models designed for different types of classification tasks. The first CNN model achieves an impressive detection accuracy of 99.53% for brain tumors. The second CNN model, with an accuracy of 93.81%, proficiently categorizes brain tumors into five distinct types: normal, glioma, meningioma, pituitary, and metastatic. Furthermore, the third CNN model demonstrates an accuracy of 98.56% in accurately classifying brain tumors into their different grades. To ensure optimal performance, a grid search optimization approach is employed to automatically fine-tune all the relevant hyperparameters of the CNN models. The utilization of large, publicly accessible clinical datasets results in robust and reliable classification outcomes. This article conducts a comprehensive comparison of the proposed models against classical models, such as AlexNet, DenseNet121, ResNet-101, VGG-19, and GoogleNet, reaffirming the superiority of the deep CNN-based approach in advancing the field of brain tumor classification and early detection.","['deep convolutional neural network (CNN)', 'AlexNet', 'DenseNet121', 'ResNet-101', 'VGG-19', 'GoogleNet']"
2024,https://openalex.org/W4390706643,Medicine,Present and Future Innovations in AI and Cardiac MRI,"Cardiac MRI is used to diagnose and treat patients with a multitude of cardiovascular diseases. Despite the growth of clinical cardiac MRI, complicated image prescriptions and long acquisition protocols limit the specialty and restrain its impact on the practice of medicine. Artificial intelligence (AI)-the ability to mimic human intelligence in learning and performing tasks-will impact nearly all aspects of MRI. Deep learning (DL) primarily uses an artificial neural network to learn a specific task from example data sets. Self-driving scanners are increasingly available, where AI automatically controls cardiac image prescriptions. These scanners offer faster image collection with higher spatial and temporal resolution, eliminating the need for cardiac triggering or breath holding. In the future, fully automated inline image analysis will most likely provide all contour drawings and initial measurements to the reader. Advanced analysis using radiomic or DL features may provide new insights and information not typically extracted in the current analysis workflow. AI may further help integrate these features with clinical, genetic, wearable-device, and ""omics"" data to improve patient outcomes. This article presents an overview of AI and its application in cardiac MRI, including in image acquisition, reconstruction, and processing, and opportunities for more personalized cardiovascular care through extraction of novel imaging markers.","['Deep learning (DL)', 'artificial neural network']"
2024,https://openalex.org/W4391508432,Medicine,Artificial intelligence-driven virtual rehabilitation for people living in the community: A scoping review,"Abstract Virtual Rehabilitation (VRehab) is a promising approach to improving the physical and mental functioning of patients living in the community. The use of VRehab technology results in the generation of multi-modal datasets collected through various devices. This presents opportunities for the development of Artificial Intelligence (AI) techniques in VRehab, namely the measurement, detection, and prediction of various patients’ health outcomes. The objective of this scoping review was to explore the applications and effectiveness of incorporating AI into home-based VRehab programs. PubMed/MEDLINE, Embase, IEEE Xplore, Web of Science databases, and Google Scholar were searched from inception until June 2023 for studies that applied AI for the delivery of VRehab programs to the homes of adult patients. After screening 2172 unique titles and abstracts and 51 full-text studies, 13 studies were included in the review. A variety of AI algorithms were applied to analyze data collected from various sensors and make inferences about patients’ health outcomes, most involving evaluating patients’ exercise quality and providing feedback to patients. The AI algorithms used in the studies were mostly fuzzy rule-based methods, template matching, and deep neural networks. Despite the growing body of literature on the use of AI in VRehab, very few studies have examined its use in patients’ homes. Current research suggests that integrating AI with home-based VRehab can lead to improved rehabilitation outcomes for patients. However, further research is required to fully assess the effectiveness of various forms of AI-driven home-based VRehab, taking into account its unique challenges and using standardized metrics.","['fuzzy rule-based methods', 'deep neural networks']"
2024,https://openalex.org/W4395037579,Medicine,Assessing ChatGPT 4.0’s test performance and clinical diagnostic accuracy on USMLE STEP 2 CK and clinical case reports,"Abstract While there is data assessing the test performance of artificial intelligence (AI) chatbots, including the Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0), there is scarce data on its diagnostic accuracy of clinical cases. We assessed the large language model (LLM), ChatGPT 4.0, on its ability to answer questions from the United States Medical Licensing Exam (USMLE) Step 2, as well as its ability to generate a differential diagnosis based on corresponding clinical vignettes from published case reports. A total of 109 Step 2 Clinical Knowledge (CK) practice questions were inputted into both ChatGPT 3.5 and ChatGPT 4.0, asking ChatGPT to pick the correct answer. Compared to its previous version, ChatGPT 3.5, we found improved accuracy of ChatGPT 4.0 when answering these questions, from 47.7 to 87.2% ( p = 0.035) respectively. Utilizing the topics tested on Step 2 CK questions, we additionally found 63 corresponding published case report vignettes and asked ChatGPT 4.0 to come up with its top three differential diagnosis. ChatGPT 4.0 accurately created a shortlist of differential diagnoses in 74.6% of the 63 case reports (74.6%). We analyzed ChatGPT 4.0’s confidence in its diagnosis by asking it to rank its top three differentials from most to least likely. Out of the 47 correct diagnoses, 33 were the first (70.2%) on the differential diagnosis list, 11 were second (23.4%), and three were third (6.4%). Our study shows the continued iterative improvement in ChatGPT’s ability to answer standardized USMLE questions accurately and provides insights into ChatGPT’s clinical diagnostic accuracy.","['Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0)', 'large language model (LLM)']"
2024,https://openalex.org/W4402521185,Medicine,Advanced Ensemble Machine Learning Techniques for Optimizing Diabetes Mellitus Prognostication: A Detailed Examination of Hospital Data,"Diabetes is a chronic disease that affects millions of people worldwide. Early diagnosis and effective management are crucial for reducing its complications. Diabetes is the fourth-highest cause of mortality due to its association with various comorbidities, including heart disease, nerve damage, blood vessel damage, and blindness. The potential of machine learning algorithms in predicting Diabetes and related conditions is significant, and mining diabetes data is an efficient method for extracting new insights.The primary objective of this study is to develop an enhanced ensemble model to predict Diabetes with improved accuracy by leveraging various machine learning algorithms.This study tested several popular machine learning algorithms commonly used in diabetes prediction, including Naive Bayes (NB), Generalized Linear Model (GLM), Logistic Regression (LR), Fast Large Margin (FLM), Deep Learning (DL), Decision Tree (DT), Random Forest (RF), Gradient Boosted Trees (GBT), and Support Vector Machine (SVM). The performance of these algorithms was compared, and two different ensemble techniques—stacking and voting—were used to build a more accurate predictive model.The top three algorithms based on accuracy were Deep Learning, Naive Bayes, and Gradient Boosted Trees. The machine learning algorithms revealed that individuals with Diabetes are significantly affected by the number of chronic conditions they have, as well as their gender and age. The ensemble models, particularly the stacking method, provided higher accuracy than individual algorithms. The stacking ensemble model achieved a slightly better accuracy of 99.94% compared to 99.34% for the voting method.Building an ensemble model significantly increased the accuracy of predicting Diabetes and related conditions. The stacking ensemble model, in particular, demonstrated superior performance, highlighting the importance of combining multiple machine learning approaches to enhance predictive accuracy","['Naive Bayes (NB)', 'Logistic Regression (LR)', 'Deep Learning (DL)', 'Decision Tree (DT)', 'Random Forest (RF)', 'Gradient Boosted Trees (GBT)', 'Support Vector Machine (SVM)', 'stacking ensemble', 'voting ensemble']"
2024,https://openalex.org/W4390987311,Medicine,Reliability of ChatGPT for performing triage task in the emergency department using the Korean Triage and Acuity Scale,"Background Artificial intelligence (AI) technology can enable more efficient decision-making in healthcare settings. There is a growing interest in improving the speed and accuracy of AI systems in providing responses for given tasks in healthcare settings. Objective This study aimed to assess the reliability of ChatGPT in determining emergency department (ED) triage accuracy using the Korean Triage and Acuity Scale (KTAS). Methods Two hundred and two virtual patient cases were built. The gold standard triage classification for each case was established by an experienced ED physician. Three other human raters (ED paramedics) were involved and rated the virtual cases individually. The virtual cases were also rated by two different versions of the chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0). Inter-rater reliability was examined using Fleiss’ kappa and intra-class correlation coefficient (ICC). Results The kappa values for the agreement between the four human raters and ChatGPTs were .523 (version 4.0) and .320 (version 3.5). Of the five levels, the performance was poor when rating patients at levels 1 and 5, as well as case scenarios with additional text descriptions. There were differences in the accuracy of the different versions of GPTs. The ICC between version 3.5 and the gold standard was .520, and that between version 4.0 and the gold standard was .802. Conclusions A substantial level of inter-rater reliability was revealed when GPTs were used as KTAS raters. The current study showed the potential of using GPT in emergency healthcare settings. Considering the shortage of experienced manpower, this AI method may help improve triaging accuracy.","['chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0)']"
2024,https://openalex.org/W4391145465,Medicine,Assessing generalisability of deep learning-based polyp detection and segmentation methods through a computer vision challenge,"Abstract Polyps are well-known cancer precursors identified by colonoscopy. However, variability in their size, appearance, and location makes the detection of polyps challenging. Moreover, colonoscopy surveillance and removal of polyps are highly operator-dependent procedures and occur in a highly complex organ topology. There exists a high missed detection rate and incomplete removal of colonic polyps. To assist in clinical procedures and reduce missed rates, automated methods for detecting and segmenting polyps using machine learning have been achieved in past years. However, the major drawback in most of these methods is their ability to generalise to out-of-sample unseen datasets from different centres, populations, modalities, and acquisition systems. To test this hypothesis rigorously, we, together with expert gastroenterologists, curated a multi-centre and multi-population dataset acquired from six different colonoscopy systems and challenged the computational expert teams to develop robust automated detection and segmentation methods in a crowd-sourcing Endoscopic computer vision challenge. This work put forward rigorous generalisability tests and assesses the usability of devised deep learning methods in dynamic and actual clinical colonoscopy procedures. We analyse the results of four top performing teams for the detection task and five top performing teams for the segmentation task. Our analyses demonstrate that the top-ranking teams concentrated mainly on accuracy over the real-time performance required for clinical applicability. We further dissect the devised methods and provide an experiment-based hypothesis that reveals the need for improved generalisability to tackle diversity present in multi-centre datasets and routine clinical procedures.","['machine learning', 'deep learning']"
2024,https://openalex.org/W4391878291,Medicine,Effective lung nodule detection using deep CNN with dual attention mechanisms,"Abstract Novel methods are required to enhance lung cancer detection, which has overtaken other cancer-related causes of death as the major cause of cancer-related mortality. Radiologists have long-standing methods for locating lung nodules in patients with lung cancer, such as computed tomography (CT) scans. Radiologists must manually review a significant amount of CT scan pictures, which makes the process time-consuming and prone to human error. Computer-aided diagnosis (CAD) systems have been created to help radiologists with their evaluations in order to overcome these difficulties. These systems make use of cutting-edge deep learning architectures. These CAD systems are designed to improve lung nodule diagnosis efficiency and accuracy. In this study, a bespoke convolutional neural network (CNN) with a dual attention mechanism was created, which was especially crafted to concentrate on the most important elements in images of lung nodules. The CNN model extracts informative features from the images, while the attention module incorporates both channel attention and spatial attention mechanisms to selectively highlight significant features. After the attention module, global average pooling is applied to summarize the spatial information. To evaluate the performance of the proposed model, extensive experiments were conducted using benchmark dataset of lung nodules. The results of these experiments demonstrated that our model surpasses recent models and achieves state-of-the-art accuracy in lung nodule detection and classification tasks.","['convolutional neural network (CNN)', 'dual attention mechanism', 'channel attention', 'spatial attention', 'global average pooling']"
2024,https://openalex.org/W4392004069,Medicine,A precise model for skin cancer diagnosis using hybrid U-Net and improved MobileNet-V3 with hyperparameters optimization,"Abstract Skin cancer is a frequently occurring and possibly deadly disease that necessitates prompt and precise diagnosis in order to ensure efficacious treatment. This paper introduces an innovative approach for accurately identifying skin cancer by utilizing Convolution Neural Network architecture and optimizing hyperparameters. The proposed approach aims to increase the precision and efficacy of skin cancer recognition and consequently enhance patients' experiences. This investigation aims to tackle various significant challenges in skin cancer recognition, encompassing feature extraction, model architecture design, and optimizing hyperparameters. The proposed model utilizes advanced deep-learning methodologies to extract complex features and patterns from skin cancer images. We enhance the learning procedure of deep learning by integrating Standard U-Net and Improved MobileNet-V3 with optimization techniques, allowing the model to differentiate malignant and benign skin cancers. Also substituted the crossed-entropy loss function of the Mobilenet-v3 mathematical framework with a bias loss function to enhance the accuracy. The model's squeeze and excitation component was replaced with the practical channel attention component to achieve parameter reduction. Integrating cross-layer connections among Mobile modules has been proposed to leverage synthetic features effectively. The dilated convolutions were incorporated into the model to enhance the receptive field. The optimization of hyperparameters is of utmost importance in improving the efficiency of deep learning models. To fine-tune the model's hyperparameter, we employ sophisticated optimization methods such as the Bayesian optimization method using pre-trained CNN architecture MobileNet-V3. The proposed model is compared with existing models, i.e., MobileNet, VGG-16, MobileNet-V2, Resnet-152v2 and VGG-19 on the “HAM-10000 Melanoma Skin Cancer dataset"". The empirical findings illustrate that the proposed optimized hybrid MobileNet-V3 model outperforms existing skin cancer detection and segmentation techniques based on high precision of 97.84%, sensitivity of 96.35%, accuracy of 98.86% and specificity of 97.32%. The enhanced performance of this research resulted in timelier and more precise diagnoses, potentially contributing to life-saving outcomes and mitigating healthcare expenditures.","['Standard U-Net', 'Improved MobileNet-V3', 'dilated convolutions', 'Bayesian optimization method', 'pre-trained CNN architecture MobileNet-V3']"
2024,https://openalex.org/W4391718168,Medicine,A comparative study of explainable ensemble learning and logistic regression for predicting in-hospital mortality in the emergency department,"Abstract This study addresses the challenges associated with emergency department (ED) overcrowding and emphasizes the need for efficient risk stratification tools to identify high-risk patients for early intervention. While several scoring systems, often based on logistic regression (LR) models, have been proposed to indicate patient illness severity, this study aims to compare the predictive performance of ensemble learning (EL) models with LR for in-hospital mortality in the ED. A cross-sectional single-center study was conducted at the ED of Imam Reza Hospital in northeast Iran from March 2016 to March 2017. The study included adult patients with one to three levels of emergency severity index. EL models using Bagging, AdaBoost, random forests (RF), Stacking and extreme gradient boosting (XGB) algorithms, along with an LR model, were constructed. The training and validation visits from the ED were randomly divided into 80% and 20%, respectively. After training the proposed models using tenfold cross-validation, their predictive performance was evaluated. Model performance was compared using the Brier score (BS), The area under the receiver operating characteristics curve (AUROC), The area and precision–recall curve (AUCPR), Hosmer–Lemeshow (H–L) goodness-of-fit test, precision, sensitivity, accuracy, F1-score, and Matthews correlation coefficient (MCC). The study included 2025 unique patients admitted to the hospital’s ED, with a total percentage of hospital deaths at approximately 19%. In the training group and the validation group, 274 of 1476 (18.6%) and 152 of 728 (20.8%) patients died during hospitalization, respectively. According to the evaluation of the presented framework, EL models, particularly Bagging, predicted in-hospital mortality with the highest AUROC (0.839, CI (0.802–0.875)) and AUCPR = 0.64 comparable in terms of discrimination power with LR (AUROC (0.826, CI (0.787–0.864)) and AUCPR = 0.61). XGB achieved the highest precision (0.83), sensitivity (0.831), accuracy (0.842), F1-score (0.833), and the highest MCC (0.48). Additionally, the most accurate models in the unbalanced dataset belonged to RF with the lowest BS (0.128). Although all studied models overestimate mortality risk and have insufficient calibration ( P &gt; 0.05), stacking demonstrated relatively good agreement between predicted and actual mortality. EL models are not superior to LR in predicting in-hospital mortality in the ED. Both EL and LR models can be considered as screening tools to identify patients at risk of mortality.","['logistic regression (LR)', 'ensemble learning (EL)', 'Bagging', 'AdaBoost', 'random forests (RF)', 'Stacking', 'extreme gradient boosting (XGB)']"
2024,https://openalex.org/W4400981456,Medicine,Multimodal data integration for oncology in the era of deep neural networks: a review,"Cancer research encompasses data across various scales, modalities, and resolutions, from screening and diagnostic imaging to digitized histopathology slides to various types of molecular data and clinical records. The integration of these diverse data types for personalized cancer care and predictive modeling holds the promise of enhancing the accuracy and reliability of cancer screening, diagnosis, and treatment. Traditional analytical methods, which often focus on isolated or unimodal information, fall short of capturing the complex and heterogeneous nature of cancer data. The advent of deep neural networks has spurred the development of sophisticated multimodal data fusion techniques capable of extracting and synthesizing information from disparate sources. Among these, Graph Neural Networks (GNNs) and Transformers have emerged as powerful tools for multimodal learning, demonstrating significant success. This review presents the foundational principles of multimodal learning including oncology data modalities, taxonomy of multimodal learning, and fusion strategies. We delve into the recent advancements in GNNs and Transformers for the fusion of multimodal data in oncology, spotlighting key studies and their pivotal findings. We discuss the unique challenges of multimodal learning, such as data heterogeneity and integration complexities, alongside the opportunities it presents for a more nuanced and comprehensive understanding of cancer. Finally, we present some of the latest comprehensive multimodal pan-cancer data sources. By surveying the landscape of multimodal data integration in oncology, our goal is to underline the transformative potential of multimodal GNNs and Transformers. Through technological advancements and the methodological innovations presented in this review, we aim to chart a course for future research in this promising field. This review may be the first that highlights the current state of multimodal modeling applications in cancer using GNNs and transformers, presents comprehensive multimodal oncology data sources, and sets the stage for multimodal evolution, encouraging further exploration and development in personalized cancer care.","['deep neural networks', 'Graph Neural Networks (GNNs)', 'Transformers']"
2024,https://openalex.org/W4390708138,Medicine,Accuracy of GPT-4 in histopathological image detection and classification of colorectal adenomas,"Aims To evaluate the accuracy of Chat Generative Pre-trained Transformer (ChatGPT) powered by GPT-4 in histopathological image detection and classification of colorectal adenomas using the diagnostic consensus provided by pathologists as a reference standard. Methods A study was conducted with 100 colorectal polyp photomicrographs, comprising an equal number of adenomas and non-adenomas, classified by two pathologists. These images were analysed by classic GPT-4 for 1 time in October 2023 and custom GPT-4 for 20 times in December 2023. GPT-4’s responses were compared against the reference standard through statistical measures to evaluate its proficiency in histopathological diagnosis, with the pathologists further assessing the model’s descriptive accuracy. Results GPT-4 demonstrated a median sensitivity of 74% and specificity of 36% for adenoma detection. The median accuracy of polyp classification varied, ranging from 16% for non-specific changes to 36% for tubular adenomas. Its diagnostic consistency, indicated by low kappa values ranging from 0.06 to 0.11, suggested only poor to slight agreement. All of the microscopic descriptions corresponded with their diagnoses. GPT-4 also commented about the limitations in its diagnoses (eg, slide diagnosis best done by pathologists, the inadequacy of single-image diagnostic conclusions, the need for clinical data and a higher magnification view). Conclusions GPT-4 showed high sensitivity but low specificity in detecting adenomas and varied accuracy for polyp classification. However, its diagnostic consistency was low. This artificial intelligence tool acknowledged its diagnostic limitations, emphasising the need for a pathologist’s expertise and additional clinical context.",['Chat Generative Pre-trained Transformer (ChatGPT) powered by GPT-4']
2024,https://openalex.org/W4390870882,Medicine,A domain adaptation approach to damage classification with an application to bridge monitoring,"Data-driven machine-learning algorithms generally suffer from a lack of labelled health-state data, mainly those referring to damage conditions. To address such an issue, population-based structural health monitoring seeks to enrich the original dataset by transferring knowledge from a population of monitored structures. Within this context, this paper presents a transfer learning approach, based on domain adaptation, to leverage information from completely-labelled bridge structure data to accurately predict new instances of an unknown target domain. Since intrinsic structural differences may cause distribution shifts, domain adaptation attempts to minimise the distance between the domains and to learn a mapping within a shared feature space. Specifically, the methodology involves the long-term acquisition of natural frequencies from several structural scenarios. Such damage-sensitive features are then aligned via domain adaptation so that a machine-learning algorithm can effectively utilise the labelled source domain data and generalise well to the unlabelled target-domain data. The described procedure is applied to two case studies, including the Z24 and the S101 benchmark bridges and their finite element models, respectively. The results demonstrate the successful exchange of health-state labels to identify the damage class within a population of bridges equipped with SHM systems, showing potential to reduce computational efforts and to deal with scarce or poor data sets in application to bridge network monitoring.","['transfer learning', 'domain adaptation']"
2024,https://openalex.org/W4392200867,Medicine,Revolutionizing core muscle analysis in female sexual dysfunction based on machine learning,"Abstract The purpose of this study is to investigate the role of core muscles in female sexual dysfunction (FSD) and develop comprehensive rehabilitation programs to address this issue. We aim to answer the following research questions: what are the roles of core muscles in FSD, and how can machine and deep learning models accurately predict changes in core muscles during FSD? FSD is a common condition that affects women of all ages, characterized by symptoms such as decreased libido, difficulty achieving orgasm, and pain during intercourse. We conducted a comprehensive analysis of changes in core muscles during FSD using machine and deep learning. We evaluated the performance of multiple models, including multi-layer perceptron (MLP), long short-term memory (LSTM), convolutional neural network (CNN), recurrent neural network (RNN), ElasticNetCV, random forest regressor, SVR, and Bagging regressor. The models were evaluated based on mean squared error (MSE), mean absolute error (MAE), and R-squared (R 2 ) score. Our results show that CNN and random forest regressor are the most accurate models for predicting changes in core muscles during FSD. CNN achieved the lowest MSE (0.002) and the highest R 2 score (0.988), while random forest regressor also performed well with an MSE of 0.0021 and an R 2 score of 0.9905. Our study demonstrates that machine and deep learning models can accurately predict changes in core muscles during FSD. The neglected core muscles play a significant role in FSD, highlighting the need for comprehensive rehabilitation programs that address these muscles. By developing these programs, we can improve the quality of life for women with FSD and help them achieve optimal sexual health.","['multi-layer perceptron (MLP)', 'long short-term memory (LSTM)', 'convolutional neural network (CNN)', 'recurrent neural network (RNN)', 'ElasticNetCV', 'random forest regressor', 'SVR', 'Bagging regressor']"
2024,https://openalex.org/W4392356867,Medicine,The SAFE procedure: a practical stopping heuristic for active learning-based screening in systematic reviews and meta-analyses,"Abstract Active learning has become an increasingly popular method for screening large amounts of data in systematic reviews and meta-analyses. The active learning process continually improves its predictions on the remaining unlabeled records, with the goal of identifying all relevant records as early as possible. However, determining the optimal point at which to stop the active learning process is a challenge. The cost of additional labeling of records by the reviewer must be balanced against the cost of erroneous exclusions. This paper introduces the SAFE procedure, a practical and conservative set of stopping heuristics that offers a clear guideline for determining when to end the active learning process in screening software like ASReview. The eclectic mix of stopping heuristics helps to minimize the risk of missing relevant papers in the screening process. The proposed stopping heuristic balances the costs of continued screening with the risk of missing relevant records, providing a practical solution for reviewers to make informed decisions on when to stop screening. Although active learning can significantly enhance the quality and efficiency of screening, this method may be more applicable to certain types of datasets and problems. Ultimately, the decision to stop the active learning process depends on careful consideration of the trade-off between the costs of additional record labeling against the potential errors of the current model for the specific dataset and context.",['active learning']
2024,https://openalex.org/W4403545332,Medicine,Evaluating AI and Machine Learning Models in Breast Cancer Detection: A Review of Convolutional Neural Networks (CNN) and Global Research Trends,"Numerous studies have highlighted the significance of artificial intelligence (AI) in breast cancer diagnosis. However, systematic reviews of AI applications in this field often lack cohesion, with each study adopting a unique approach. The aim of this study is to provide a detailed examination of AI's role in breast cancer diagnosis through citation analysis, helping to categorize the key areas that attract academic attention. It also includes a thematic analysis to identify the specific research topics within each category. A total of 30,200 studies related to breast cancer and AI, published between 2015 and 2024, were sourced from databases such as IEEE, Scopus, PubMed, Springer, and Google Scholar. After applying inclusion and exclusion criteria, 32 relevant studies were identified. Most of these studies utilized classification models for breast cancer prediction, with high accuracy being the most commonly reported performance metric. Convolutional Neural Networks (CNN) emerged as the preferred model in many studies. The findings indicate that both the quantity and quality of AI-based algorithms in breast cancer diagnosis are increases in the given years. AI is increasingly seen as a complement to healthcare sector and clinical expertise, with the target of enhancing the accessibility and affordability of quality healthcare worldwide.",['Convolutional Neural Networks (CNN)']
2024,https://openalex.org/W4390777660,Medicine,Unlocking the Potential of XAI for Improved Alzheimer’s Disease Detection and Classification Using a ViT-GRU Model,"Alzheimer's Disease (AD) is a significant cause of dementia worldwide, and its progression from mild to severe affects an individual's ability to perform daily activities independently. The accurate and early diagnosis of AD is crucial for effective clinical intervention. However, interpreting AD from medical images can be challenging, even for experienced radiologists. Therefore, there is a need for an automatic diagnosis of AD, and researchers have investigated the potential of utilizing Artificial Intelligence (AI) techniques, particularly deep learning models, to address this challenge. This study proposes a framework that combines a Vision Transformer (ViT) and a Gated Recurrent Unit (GRU) to detect AD characteristics from Magnetic Resonance Imaging (MRI) images accurately and reliably. The ViT identifies crucial features from the input image, and the GRU establishes clear correlations between these features. The proposed model overcomes the class imbalance issue in the MRI image dataset and achieves superior accuracy and performance compared to existing methods. The model was trained on the Alzheimer's MRI Preprocessed Dataset obtained from Kaggle, achieving notable accuracies of 99.53% for 4-class and 99.69% for binary classification. It also demonstrated a high accuracy of 99.26% for 3-class on the AD Neuroimaging Initiative (ADNI) Baseline Database. These results were validated through a thorough 10-fold cross-validation process. Furthermore, Explainable AI (XAI) techniques were incorporated to make the model interpretable and explainable. This allows clinicians to understand the model's decision-making process and gain insights into the underlying factors driving the AD diagnosis.","['Vision Transformer (ViT)', 'Gated Recurrent Unit (GRU)']"
2024,https://openalex.org/W4391166899,Medicine,"Prediction of atmospheric PM2.5 level by machine learning techniques in Isfahan, Iran","Abstract With increasing levels of air pollution, air quality prediction has attracted more attention. Mathematical models are being developed by researchers to achieve precise predictions. Monitoring and prediction of atmospheric PM 2.5 levels, as a predominant pollutant, is essential in emission mitigation programs. In this study, meteorological datasets from 9 years in Isfahan city, a large metropolis of Iran, were applied to predict the PM 2.5 levels, using four machine learning algorithms including Artificial Neural |Networks (ANNs), K-Nearest-Neighbors (KNN), Support Vector |Machines (SVMs) and ensembles of classification trees Random Forest (RF). The data from 7 air quality monitoring stations located in Isfahan City were taken into consideration. The Confusion Matrix and Cross-Entropy Loss were used to analyze the performance of classification models. Several parameters, including sensitivity, specificity, accuracy, F1 score, precision, and the area under the curve (AUC), are computed to assess model performance. Finally, by introducing the predicted data for 2020 into ArcGIS software and using the IDW (Inverse Distance Weighting) method, interpolation was conducted for the area of Isfahan city and the pollution map was illustrated for each month of the year. The results showed that, based on the accuracy percentage, the ANN model has a better performance (90.1%) in predicting PM 2.5 grades compared to the other models for the applied meteorological dataset, followed by RF (86.1%), SVM (84.6%) and KNN (82.2%) models, respectively. Therefore, ANN modelling provides a feasible procedure for the managerial planning of air pollution control.","['Artificial Neural Networks (ANNs)', 'K-Nearest-Neighbors (KNN)', 'Support Vector Machines (SVMs)', 'Random Forest (RF)']"
2024,https://openalex.org/W4391810207,Medicine,Machine Learning–Based Prediction of Suicidality in Adolescents With Allergic Rhinitis: Derivation and Validation in 2 Independent Nationwide Cohorts,"Background Given the additional risk of suicide-related behaviors in adolescents with allergic rhinitis (AR), it is important to use the growing field of machine learning (ML) to evaluate this risk. Objective This study aims to evaluate the validity and usefulness of an ML model for predicting suicide risk in patients with AR. Methods We used data from 2 independent survey studies, Korea Youth Risk Behavior Web-based Survey (KYRBS; n=299,468) for the original data set and Korea National Health and Nutrition Examination Survey (KNHANES; n=833) for the external validation data set, to predict suicide risks of AR in adolescents aged 13 to 18 years, with 3.45% (10,341/299,468) and 1.4% (12/833) of the patients attempting suicide in the KYRBS and KNHANES studies, respectively. The outcome of interest was the suicide attempt risks. We selected various ML-based models with hyperparameter tuning in the discovery and performed an area under the receiver operating characteristic curve (AUROC) analysis in the train, test, and external validation data. Results The study data set included 299,468 (KYRBS; original data set) and 833 (KNHANES; external validation data set) patients with AR recruited between 2005 and 2022. The best-performing ML model was the random forest model with a mean AUROC of 84.12% (95% CI 83.98%-84.27%) in the original data set. Applying this result to the external validation data set revealed the best performance among the models, with an AUROC of 89.87% (sensitivity 83.33%, specificity 82.58%, accuracy 82.59%, and balanced accuracy 82.96%). While looking at feature importance, the 5 most important features in predicting suicide attempts in adolescent patients with AR are depression, stress status, academic achievement, age, and alcohol consumption. Conclusions This study emphasizes the potential of ML models in predicting suicide risks in patients with AR, encouraging further application of these models in other conditions to enhance adolescent health and decrease suicide rates.",['random forest']
2024,https://openalex.org/W4392450360,Medicine,Geographically weighted machine learning for modeling spatial heterogeneity in traffic crash frequency and determinants in US,"Spatial analyses of traffic crashes have drawn much interest due to the nature of the spatial dependence and spatial heterogeneity in the crash data. This study makes the best of Geographically Weighted Random Forest (GW-RF) model to explore the local associations between crash frequency and various influencing factors in the US, including road network attributes, socio-economic characteristics, and land use factors collected from multiple data sources. Special emphasis is put on modeling the spatial heterogeneity in the effects of a factor on crash frequency in different geographical areas in a data-driven way. The GW-RF model outperforms global models (e.g. Random Forest) and conventional geographically weighted regression, demonstrating superior predictive accuracy and elucidating spatial variations. The GW-RF model reveals spatial distinctions in the effects of certain factors on crash frequency. For example, the importance of intersection density varies significantly across regions, with high significance in the southern and northeastern areas. Low-grade road density emerges as influential in specific cities. The findings highlight the significance of different factors in influencing crash frequency across zones. Road network factors, particularly intersection density, exhibit high importance universally, while socioeconomic variables demonstrate moderate effects. Interestingly, land use variables show relatively lower importance. The outcomes could help to allocate resources and implement tailored interventions to reduce the likelihood of crashes.","['Geographically Weighted Random Forest (GW-RF)', 'Random Forest']"
2024,https://openalex.org/W4393405326,Medicine,"Developing Deep LSTMs With Later Temporal Attention for Predicting COVID-19 Severity, Clinical Outcome, and Antibody Level by Screening Serological Indicators Over Time","Objective: The clinical course of COVID-19, as well as the immunological reaction, is notable for its extreme variability. Identifying the main associated factors might help understand the disease progression and physiological status of COVID-19 patients. The dynamic changes of the antibody against Spike protein are crucial for understanding the immune response. This work explores a temporal attention (TA) mechanism of deep learning to predict COVID-19 disease severity, clinical outcomes, and Spike antibody levels by screening serological indicators over time. Methods: We use feature selection techniques to filter feature subsets that are highly correlated with the target. The specific deep Long Short-Term Memory (LSTM) models are employed to capture the dynamic changes of disease severity, clinical outcome, and Spike antibody level. We also propose deep LSTMs with a TA mechanism to emphasize the later blood test records because later records often attract more attention from doctors. Results: Risk factors highly correlated with COVID-19 are revealed. LSTM achieves the highest classification accuracy for disease severity prediction. Temporal Attention Long Short-Term Memory (TA-LSTM) achieves the best performance for clinical outcome prediction. For Spike antibody level prediction, LSTM achieves the best permanence. Conclusion: The experimental results demonstrate the effectiveness of the proposed models. The proposed models can provide a computer-aided medical diagnostics system by simply using time series of serological indicators.","['deep Long Short-Term Memory (LSTM) models', 'deep LSTMs with a temporal attention (TA) mechanism', 'Temporal Attention Long Short-Term Memory (TA-LSTM)']"
2024,https://openalex.org/W4401537518,Medicine,A New Brain Network Construction Paradigm for Brain Disorder via Diffusion-Based Graph Contrastive Learning,"Brain network analysis plays an increasingly important role in studying brain function and the exploring of disease mechanisms. However, existing brain network construction tools have some limitations, including dependency on empirical users, weak consistency in repeated experiments and time-consuming processes. In this work, a diffusion-based brain network pipeline, DGCL is designed for end-to-end construction of brain networks. Initially, the brain region-aware module (BRAM) precisely determines the spatial locations of brain regions by the diffusion process, avoiding subjective parameter selection. Subsequently, DGCL employs graph contrastive learning to optimize brain connections by eliminating individual differences in redundant connections unrelated to diseases, thereby enhancing the consistency of brain networks within the same group. Finally, the node-graph contrastive loss and classification loss jointly constrain the learning process of the model to obtain the reconstructed brain network, which is then used to analyze important brain connections. Validation on two datasets, ADNI and ABIDE, demonstrates that DGCL surpasses traditional methods and other deep learning models in predicting disease development stages. Significantly, the proposed model improves the efficiency and generalization of brain network construction. In summary, the proposed DGCL can be served as a universal brain network construction scheme, which can effectively identify important brain connections through generative paradigms and has the potential to provide disease interpretability support for neuroscience research.","['diffusion process', 'graph contrastive learning']"
2024,https://openalex.org/W4390819402,Medicine,Development and Validation of a Machine Learning Model to Predict Weekly Risk of Hypoglycemia in Patients with Type 1 Diabetes Based on Continuous Glucose Monitoring,"Aim: The aim of this study was to develop and validate a prediction model based on CGM data to identify a week-to-week risk profile of excessive hypoglycemia. Methods: We analyzed, trained, and internally tested two prediction models using CGM data from 205 type 1 diabetes patients with long-term CGM monitoring. A binary classification approach (XGBoost) combined with feature engineering deployed on the CGM signals was utilized to predict excessive hypoglycemia risk defined by two targets (TBR > 4% and the upper TBR 90th percentile limit) of time below range (TBR) the following week. The models were validated in two independent cohorts with a total of 253 additional patients. Results: A total of 61,470 weeks of CGM data were included in the analysis. The XGBoost models had a ROC-AUC of 0.83-0.87 (95% confidence interval [CI]; 0.83-0.88) in the test dataset. The external validation showed ROC-AUCs of 0.81-0.90. The most discriminative features included the low blood glucose index (LBGI), the glycemic risk assessment diabetes equation (GRADE), hypoglycemia, the TBR, waveform length, the CV and mean glucose during the previous week. This highlights that the pattern of hypoglycemia combined with glucose variability during the past week contains information on the risk of future hypoglycemia. Conclusion: Prediction models based on real-world CGM data can be used to predict the risk of hypoglycemia in the forthcoming week. The models showed good performance in both the internal and external validation cohorts.",['XGBoost']
2024,https://openalex.org/W4391437034,Medicine,A methodical exploration of imaging modalities from dataset to detection through machine learning paradigms in prominent lung disease diagnosis: a review,"Abstract Background Lung diseases, both infectious and non-infectious, are the most prevalent cause of mortality overall in the world. Medical research has identified pneumonia, lung cancer, and Corona Virus Disease 2019 (COVID-19) as prominent lung diseases prioritized over others. Imaging modalities, including X-rays, computer tomography (CT) scans, magnetic resonance imaging (MRIs), positron emission tomography (PET) scans, and others, are primarily employed in medical assessments because they provide computed data that can be utilized as input datasets for computer-assisted diagnostic systems. Imaging datasets are used to develop and evaluate machine learning (ML) methods to analyze and predict prominent lung diseases. Objective This review analyzes ML paradigms, imaging modalities' utilization, and recent developments for prominent lung diseases. Furthermore, the research also explores various datasets available publically that are being used for prominent lung diseases. Methods The well-known databases of academic studies that have been subjected to peer review, namely ScienceDirect, arXiv, IEEE Xplore, MDPI, and many more, were used for the search of relevant articles. Applied keywords and combinations used to search procedures with primary considerations for review, such as pneumonia, lung cancer, COVID-19, various imaging modalities, ML, convolutional neural networks (CNNs), transfer learning, and ensemble learning. Results This research finding indicates that X-ray datasets are preferred for detecting pneumonia, while CT scan datasets are predominantly favored for detecting lung cancer. Furthermore, in COVID-19 detection, X-ray datasets are prioritized over CT scan datasets. The analysis reveals that X-rays and CT scans have surpassed all other imaging techniques. It has been observed that using CNNs yields a high degree of accuracy and practicability in identifying prominent lung diseases. Transfer learning and ensemble learning are complementary techniques to CNNs to facilitate analysis. Furthermore, accuracy is the most favored metric for assessment.","['machine learning (ML)', 'convolutional neural networks (CNNs)', 'transfer learning', 'ensemble learning']"
2024,https://openalex.org/W4392056032,Medicine,A novel fusion framework of deep bottleneck residual convolutional neural network for breast cancer classification from mammogram images,"With over 2.1 million new cases of breast cancer diagnosed annually, the incidence and mortality rate of this disease pose severe global health issues for women. Identifying the disease’s influence is the only practical way to lessen it immediately. Numerous research works have developed automated methods using different medical imaging to identify BC. Still, the precision of each strategy differs based on the available resources, the issue’s nature, and the dataset being used. We proposed a novel deep bottleneck convolutional neural network with a quantum optimization algorithm for breast cancer classification and diagnosis from mammogram images. Two novel deep architectures named three-residual blocks bottleneck and four-residual blocks bottle have been proposed with parallel and single paths. Bayesian Optimization (BO) has been employed to initialize hyperparameter values and train the architectures on the selected dataset. Deep features are extracted from the global average pool layer of both models. After that, a kernel-based canonical correlation analysis and entropy technique is proposed for the extracted deep features fusion. The fused feature set is further refined using an optimization technique named quantum generalized normal distribution optimization. The selected features are finally classified using several neural network classifiers, such as bi-layered and wide-neural networks. The experimental process was conducted on a publicly available mammogram imaging dataset named INbreast, and a maximum accuracy of 96.5% was obtained. Moreover, for the proposed method, the sensitivity rate is 96.45, the precision rate is 96.5, the F1 score value is 96.64, the MCC value is 92.97%, and the Kappa value is 92.97%, respectively. The proposed architectures are further utilized for the diagnosis process of infected regions. In addition, a detailed comparison has been conducted with a few recent techniques showing the proposed framework’s higher accuracy and precision rate.","['deep bottleneck convolutional neural network', 'three-residual blocks bottleneck architecture', 'Bayesian Optimization (BO)', 'kernel-based canonical correlation analysis', 'bi-layered neural network classifier', 'wide-neural network classifier']"
2024,https://openalex.org/W4392139441,Medicine,Artificial intelligence for radiographic imaging detection of caries lesions: a systematic review,"Abstract Background The aim of this systematic review is to evaluate the diagnostic performance of Artificial Intelligence (AI) models designed for the detection of caries lesion (CL). Materials and methods An electronic literature search was conducted on PubMed, Web of Science, SCOPUS, LILACS and Embase databases for retrospective, prospective and cross-sectional studies published until January 2023, using the following keywords: artificial intelligence (AI), machine learning (ML), deep learning (DL), artificial neural networks (ANN), convolutional neural networks (CNN), deep convolutional neural networks (DCNN), radiology, detection, diagnosis and dental caries (DC). The quality assessment was performed using the guidelines of QUADAS-2. Results Twenty articles that met the selection criteria were evaluated. Five studies were performed on periapical radiographs, nine on bitewings, and six on orthopantomography. The number of imaging examinations included ranged from 15 to 2900. Four studies investigated ANN models, fifteen CNN models, and two DCNN models. Twelve were retrospective studies, six cross-sectional and two prospective. The following diagnostic performance was achieved in detecting CL: sensitivity from 0.44 to 0.86, specificity from 0.85 to 0.98, precision from 0.50 to 0.94, PPV (Positive Predictive Value) 0.86, NPV (Negative Predictive Value) 0.95, accuracy from 0.73 to 0.98, area under the curve (AUC) from 0.84 to 0.98, intersection over union of 0.3–0.4 and 0.78, Dice coefficient 0.66 and 0.88, F1-score from 0.64 to 0.92. According to the QUADAS-2 evaluation, most studies exhibited a low risk of bias. Conclusion AI-based models have demonstrated good diagnostic performance, potentially being an important aid in CL detection. Some limitations of these studies are related to the size and heterogeneity of the datasets. Future studies need to rely on comparable, large, and clinically meaningful datasets. Protocol PROSPERO identifier: CRD42023470708","['Artificial Neural Networks (ANN)', 'Convolutional Neural Networks (CNN)', 'Deep Convolutional Neural Networks (DCNN)']"
2024,https://openalex.org/W4391174596,Medicine,Generative Large Language Models for Detection of Speech Recognition Errors in Radiology Reports,"This study evaluated the ability of generative large language models (LLMs) to detect speech recognition errors in radiology reports. A dataset of 3233 CT and MRI reports was assessed by radiologists for speech recognition errors. Errors were categorized as clinically significant or not clinically significant. Performances of five generative LLMs—GPT-3.5-turbo, GPT-4, text-davinci-003, Llama-v2–70B-chat, and Bard—were compared in detecting these errors, using manual error detection as the reference standard. Prompt engineering was used to optimize model performance. GPT-4 demonstrated high accuracy in detecting clinically significant errors (precision, 76.9%; recall, 100%; F1 score, 86.9%) and not clinically significant errors (precision, 93.9%; recall, 94.7%; F1 score, 94.3%). Text-davinci-003 achieved F1 scores of 72% and 46.6% for clinically significant and not clinically significant errors, respectively. GPT-3.5-turbo obtained 59.1% and 32.2% F1 scores, while Llama-v2–70B-chat scored 72.8% and 47.7%. Bard showed the lowest accuracy, with F1 scores of 47.5% and 20.9%. GPT-4 effectively identified challenging errors of nonsense phrases and internally inconsistent statements. Longer reports, resident dictation, and overnight shifts were associated with higher error rates. In conclusion, advanced generative LLMs show potential for automatic detection of speech recognition errors in radiology reports. Keywords: CT, Large Language Model, Machine Learning, MRI, Natural Language Processing, Radiology Reports, Speech, Unsupervised Learning Supplemental material is available for this article. © RSNA, 2024","['generative large language models (LLMs)', 'GPT-3.5-turbo', 'GPT-4', 'text-davinci-003', 'Llama-v2–70B-chat', 'unsupervised learning']"
2024,https://openalex.org/W4391480252,Medicine,Performance of convolutional neural networks for the classification of brain tumors using magnetic resonance imaging,"Brain tumors are a diverse group of neoplasms that are challenging to detect and classify due to their varying characteristics. Deep learning techniques have proven to be effective in tumor classification. However, there is a lack of studies that compare these techniques using a common methodology. This work aims to analyze the performance of convolutional neural networks in the classification of brain tumors. We propose a network consisting of a few convolutional layers, batch normalization, and max-pooling. Then, we explore recent deep architectures, such as VGG, ResNet, EfficientNet, or ConvNeXt. The study relies on two magnetic resonance imaging datasets with over 3000 images of three types of tumors –gliomas, meningiomas, and pituitary tumors–, as well as images without tumors. We determine the optimal hyperparameters of the networks using the training and validation sets. The training and test sets are used to assess the performance of the models from different perspectives, including training from scratch, data augmentation, transfer learning, and fine-tuning. The experiments are performed using the TensorFlow and Keras libraries in Python. We compare the accuracy of the models and analyze their complexity based on the capacity of the networks, their training times, and image throughput. Several networks achieve high accuracy rates on both datasets, with the best model achieving 98.7% accuracy, which is on par with state-of-the-art methods. The average precision for each type of tumor is 94.3% for gliomas, 93.8% for meningiomas, 97.9% for pituitary tumors, and 95.3% for images without tumors. VGG is the largest model with over 171 million parameters, whereas MobileNet and EfficientNetB0 are the smallest ones with 3.2 and 5.9 million parameters, respectively. These two neural networks are also the fastest to train with 23.7 and 25.4 seconds per epoch, respectively. On the other hand, ConvNext is the slowest model with 58.2 seconds per epoch. Our custom model obtained the highest image throughput with 234.37 images per second, followed by MobileNet with 226 images per second. ConvNext obtained the smallest throughput with 97.35 images per second. ResNet, MobileNet, and EfficientNet are the most accurate networks, with MobileNet and EfficientNet demonstrating superior performance in terms of complexity. Most models achieve the best accuracy using transfer learning followed by a fine-tuning step. However, data augmentation does not contribute to increasing the accuracy of the models in general.","['convolutional neural networks', 'batch normalization', 'max-pooling', 'VGG', 'ResNet', 'EfficientNet', 'ConvNeXt', 'transfer learning', 'fine-tuning']"
2024,https://openalex.org/W4391641063,Medicine,Predictors for estimating subcortical EEG responses to continuous speech,"Perception of sounds and speech involves structures in the auditory brainstem that rapidly process ongoing auditory stimuli. The role of these structures in speech processing can be investigated by measuring their electrical activity using scalp-mounted electrodes. However, typical analysis methods involve averaging neural responses to many short repetitive stimuli that bear little relevance to daily listening environments. Recently, subcortical responses to more ecologically relevant continuous speech were detected using linear encoding models. These methods estimate the temporal response function (TRF), which is a regression model that minimises the error between the measured neural signal and a predictor derived from the stimulus. Using predictors that model the highly non-linear peripheral auditory system may improve linear TRF estimation accuracy and peak detection. Here, we compare predictors from both simple and complex peripheral auditory models for estimating brainstem TRFs on electroencephalography (EEG) data from 24 participants listening to continuous speech. We also investigate the data length required for estimating subcortical TRFs, and find that around 12 minutes of data is sufficient for clear wave V peaks (&gt;3 dB SNR) to be seen in nearly all participants. Interestingly, predictors derived from simple filterbank-based models of the peripheral auditory system yield TRF wave V peak SNRs that are not significantly different from those estimated using a complex model of the auditory nerve, provided that the nonlinear effects of adaptation in the auditory system are appropriately modelled. Crucially, computing predictors from these simpler models is more than 50 times faster compared to the complex model. This work paves the way for efficient modelling and detection of subcortical processing of continuous speech, which may lead to improved diagnosis metrics for hearing impairment and assistive hearing technology.","['linear encoding models', 'temporal response function (TRF)', 'regression model']"
2024,https://openalex.org/W4393044095,Medicine,"Comparative performance analysis of Boruta, SHAP, and Borutashap for disease diagnosis: A study with multiple machine learning algorithms","Interpretable machine learning models are instrumental in disease diagnosis and clinical decision-making, shedding light on relevant features. Notably, Boruta, SHAP (SHapley Additive exPlanations), and BorutaShap were employed for feature selection, each contributing to the identification of crucial features. These selected features were then utilized to train six machine learning algorithms, including LR, SVM, ETC, AdaBoost, RF, and LR, using diverse medical datasets obtained from public sources after rigorous preprocessing. The performance of each feature selection technique was evaluated across multiple ML models, assessing accuracy, precision, recall, and F1-score metrics. Among these, SHAP showcased superior performance, achieving average accuracies of 80.17%, 85.13%, 90.00%, and 99.55% across diabetes, cardiovascular, statlog, and thyroid disease datasets, respectively. Notably, the LGBM emerged as the most effective algorithm, boasting an average accuracy of 91.00% for most disease states. Moreover, SHAP enhanced the interpretability of the models, providing valuable insights into the underlying mechanisms driving disease diagnosis. This comprehensive study contributes significant insights into feature selection techniques and machine learning algorithms for disease diagnosis, benefiting researchers and practitioners in the medical field. Further exploration of feature selection methods and algorithms holds promise for advancing disease diagnosis methodologies, paving the way for more accurate and interpretable diagnostic models.","['Boruta', 'SHAP (SHapley Additive exPlanations)', 'LR', 'SVM', 'AdaBoost', 'RF', 'LGBM']"
2024,https://openalex.org/W4394975332,Medicine,Distilling large language models for matching patients to clinical trials,"Abstract Objective The objective of this study is to systematically examine the efficacy of both proprietary (GPT-3.5, GPT-4) and open-source large language models (LLMs) (LLAMA 7B, 13B, 70B) in the context of matching patients to clinical trials in healthcare. Materials and methods The study employs a multifaceted evaluation framework, incorporating extensive automated and human-centric assessments along with a detailed error analysis for each model, and assesses LLMs’ capabilities in analyzing patient eligibility against clinical trial’s inclusion and exclusion criteria. To improve the adaptability of open-source LLMs, a specialized synthetic dataset was created using GPT-4, facilitating effective fine-tuning under constrained data conditions. Results The findings indicate that open-source LLMs, when fine-tuned on this limited and synthetic dataset, achieve performance parity with their proprietary counterparts, such as GPT-3.5. Discussion This study highlights the recent success of LLMs in the high-stakes domain of healthcare, specifically in patient-trial matching. The research demonstrates the potential of open-source models to match the performance of proprietary models when fine-tuned appropriately, addressing challenges like cost, privacy, and reproducibility concerns associated with closed-source proprietary LLMs. Conclusion The study underscores the opportunity for open-source LLMs in patient-trial matching. To encourage further research and applications in this field, the annotated evaluation dataset and the fine-tuned LLM, Trial-LLAMA, are released for public use.","['GPT-3.5', 'GPT-4', 'LLAMA 7B', 'LLAMA 13B', 'LLAMA 70B', 'fine-tuning']"
2024,https://openalex.org/W4390547705,Medicine,Impact of random oversampling and random undersampling on the performance of prediction models developed using observational health data,"Abstract Background There is currently no consensus on the impact of class imbalance methods on the performance of clinical prediction models. We aimed to empirically investigate the impact of random oversampling and random undersampling, two commonly used class imbalance methods, on the internal and external validation performance of prediction models developed using observational health data. Methods We developed and externally validated prediction models for various outcomes of interest within a target population of people with pharmaceutically treated depression across four large observational health databases. We used three different classifiers (lasso logistic regression, random forest, XGBoost) and varied the target imbalance ratio. We evaluated the impact on model performance in terms of discrimination and calibration. Discrimination was assessed using the area under the receiver operating characteristic curve (AUROC) and calibration was assessed using calibration plots. Results We developed and externally validated a total of 1,566 prediction models. On internal and external validation, random oversampling and random undersampling generally did not result in higher AUROCs. Moreover, we found overestimated risks, although this miscalibration could largely be corrected by recalibrating the models towards the imbalance ratios in the original dataset. Conclusions Overall, we found that random oversampling or random undersampling generally does not improve the internal and external validation performance of prediction models developed in large observational health databases. Based on our findings, we do not recommend applying random oversampling or random undersampling when developing prediction models in large observational health databases.","['random undersampling', 'lasso logistic regression', 'random forest', 'XGBoost']"
2024,https://openalex.org/W4390579686,Medicine,Auto-detection of the coronavirus disease by using deep convolutional neural networks and X-ray photographs,"Abstract The most widely used method for detecting Coronavirus Disease 2019 (COVID-19) is real-time polymerase chain reaction. However, this method has several drawbacks, including high cost, lengthy turnaround time for results, and the potential for false-negative results due to limited sensitivity. To address these issues, additional technologies such as computed tomography (CT) or X-rays have been employed for diagnosing the disease. Chest X-rays are more commonly used than CT scans due to the widespread availability of X-ray machines, lower ionizing radiation, and lower cost of equipment. COVID-19 presents certain radiological biomarkers that can be observed through chest X-rays, making it necessary for radiologists to manually search for these biomarkers. However, this process is time-consuming and prone to errors. Therefore, there is a critical need to develop an automated system for evaluating chest X-rays. Deep learning techniques can be employed to expedite this process. In this study, a deep learning-based method called Custom Convolutional Neural Network (Custom-CNN) is proposed for identifying COVID-19 infection in chest X-rays. The Custom-CNN model consists of eight weighted layers and utilizes strategies like dropout and batch normalization to enhance performance and reduce overfitting. The proposed approach achieved a classification accuracy of 98.19% and aims to accurately classify COVID-19, normal, and pneumonia samples.","['Deep learning', 'dropout', 'batch normalization']"
2024,https://openalex.org/W4391480223,Medicine,GAN-based generation of realistic 3D volumetric data: A systematic review and taxonomy,"With the massive proliferation of data-driven algorithms, such as deep learning-based approaches, the availability of high-quality data is of great interest. Volumetric data is very important in medicine, as it ranges from disease diagnoses to therapy monitoring. When the dataset is sufficient, models can be trained to help doctors with these tasks. Unfortunately, there are scenarios where large amounts of data is unavailable. For example, rare diseases and privacy issues can lead to restricted data availability. In non-medical fields, the high cost of obtaining enough high-quality data can also be a concern. A solution to these problems can be the generation of realistic synthetic data using Generative Adversarial Networks (GANs). The existence of these mechanisms is a good asset, especially in healthcare, as the data must be of good quality, realistic, and without privacy issues. Therefore, most of the publications on volumetric GANs are within the medical domain. In this review, we provide a summary of works that generate realistic volumetric synthetic data using GANs. We therefore outline GAN-based methods in these areas with common architectures, loss functions and evaluation metrics, including their advantages and disadvantages. We present a novel taxonomy, evaluations, challenges, and research opportunities to provide a holistic overview of the current state of volumetric GANs.","['Generative Adversarial Networks (GANs)', 'GAN-based methods']"
2024,https://openalex.org/W4392302759,Medicine,Molecular structural modeling and physical characteristics of anti-breast cancer drugs via some novel topological descriptors and regression models,"Research is continuously being pursued to treat cancer patients and prevent the disease by developing new medicines. However, experimental drug design and development is a costly, time-consuming, and challenging process. Alternatively, computational and mathematical techniques play an important role in optimally achieving this goal. Among these mathematical techniques, topological indices (TIs) have many applications in the drugs used for the treatment of breast cancer. TIs can be utilized to forecast the effectiveness of drugs by providing molecular structure information and related properties of the drugs. In addition, these can assist in the design and discovery of new drugs by providing insights into the structure-property/structure-activity relationships. In this article, a Quantitative Structure Property Relationship (QSPR) analysis is carried out using some novel degree-based molecular descriptors and regression models to predict various properties (such as boiling point, melting point, enthalpy, flashpoint, molar refraction, molar volume, and polarizability) of 14 drugs used for the breast cancer treatment. The molecular structures of these drugs are topologically modeled through vertex and edge partitioning techniques of graph theory, and then linear regression models are developed to correlate the computed values with the experimental properties of the drugs to investigate the performance of TIs in predicting these properties. The results confirmed the potential of the considered topological indices as a tool for drug discovery and design in the field of breast cancer treatment.","['regression models', 'linear regression models']"
2024,https://openalex.org/W4392499245,Medicine,Exploring the role of skin temperature in thermal sensation and thermal comfort: A comprehensive review,"The role of skin temperature as a determinant of human thermal sensation and comfort has gained increasing recognition, prompting a need for a systematic review. This review examines the relationship between skin temperature and thermal sensation, synthesizing insights from 172 studies published since 2000. It uniquely focuses on the indispensable roles of local and mean skin temperatures, a perspective not comprehensively explored in previous literature. The review reveals that the most common measurement points for skin temperature are the face and hands, attributed to their higher thermal sensitivity and the practical ease of measurement. It establishes a clear linear relationship between mean skin temperature and user thermal sensation, though affected by the choice of measurement locations and number of points. A notable finding is the varying impact of local skin temperature on overall thermal sensation in changing environments, with local heating less influential than cooling. The review also uncovers significant demographic variations in thermal sensation, strongly influenced by differing skin temperatures across age groups, genders, and climatic regions. For example, elderly populations exhibit a decreased temperature sensitivity, especially towards warmth. Gender differences are also significant, with females experiencing higher skin temperatures in warmer environments and lower in colder ones. Machine learning (ML)-based methods, especially classification tree-based and support vector machine (SVM) techniques, dominate in predicting thermal sensation and comfort, leveraging skin temperature data. While ML methods are prevalent, statistical regression-based approaches offer valuable empirical insights. Thermo-physiological model-based methods provide reliable results by incorporating detailed skin temperature dynamics. The review identifies a gap in understanding how gender, age, and regional differences influence thermal comfort in diverse environments. The study recommends conducting more nuanced experiments to dissect the impact of these factors and proposes the integration of individual demographic variables into ML models to personalize thermal comfort predictions.","['support vector machine (SVM)', 'statistical regression-based approaches']"
2024,https://openalex.org/W4394011823,Medicine,"Artificial intelligence in lung cancer screening: Detection, classification, prediction, and prognosis","Abstract Background The exceptional capabilities of artificial intelligence (AI) in extracting image information and processing complex models have led to its recognition across various medical fields. With the continuous evolution of AI technologies based on deep learning, particularly the advent of convolutional neural networks (CNNs), AI presents an expanded horizon of applications in lung cancer screening, including lung segmentation, nodule detection, false‐positive reduction, nodule classification, and prognosis. Methodology This review initially analyzes the current status of AI technologies. It then explores the applications of AI in lung cancer screening, including lung segmentation, nodule detection, and classification, and assesses the potential of AI in enhancing the sensitivity of nodule detection and reducing false‐positive rates. Finally, it addresses the challenges and future directions of AI in lung cancer screening. Results AI holds substantial prospects in lung cancer screening. It demonstrates significant potential in improving nodule detection sensitivity, reducing false‐positive rates, and classifying nodules, while also showing value in predicting nodule growth and pathological/genetic typing. Conclusions AI offers a promising supportive approach to lung cancer screening, presenting considerable potential in enhancing nodule detection sensitivity, reducing false‐positive rates, and classifying nodules. However, the universality and interpretability of AI results need further enhancement. Future research should focus on the large‐scale validation of new deep learning‐based algorithms and multi‐center studies to improve the efficacy of AI in lung cancer screening.","['deep learning', 'convolutional neural networks (CNNs)']"
2024,https://openalex.org/W4398141531,Medicine,Enhancing EfficientNetv2 with global and efficient channel attention mechanisms for accurate MRI-Based brain tumor classification,"Abstract The early and accurate diagnosis of brain tumors is critical for effective treatment planning, with Magnetic Resonance Imaging (MRI) serving as a key tool in the non-invasive examination of such conditions. Despite the advancements in Computer-Aided Diagnosis (CADx) systems powered by deep learning, the challenge of accurately classifying brain tumors from MRI scans persists due to the high variability of tumor appearances and the subtlety of early-stage manifestations. This work introduces a novel adaptation of the EfficientNetv2 architecture, enhanced with Global Attention Mechanism (GAM) and Efficient Channel Attention (ECA), aimed at overcoming these hurdles. This enhancement not only amplifies the model’s ability to focus on salient features within complex MRI images but also significantly improves the classification accuracy of brain tumors. Our approach distinguishes itself by meticulously integrating attention mechanisms that systematically enhance feature extraction, thereby achieving superior performance in detecting a broad spectrum of brain tumors. Demonstrated through extensive experiments on a large public dataset, our model achieves an exceptional high-test accuracy of 99.76%, setting a new benchmark in MRI-based brain tumor classification. Moreover, the incorporation of Grad-CAM visualization techniques sheds light on the model’s decision-making process, offering transparent and interpretable insights that are invaluable for clinical assessment. By addressing the limitations inherent in previous models, this study not only advances the field of medical imaging analysis but also highlights the pivotal role of attention mechanisms in enhancing the interpretability and accuracy of deep learning models for brain tumor diagnosis. This research sets the stage for advanced CADx systems, enhancing patient care and treatment outcomes.","['EfficientNetv2 architecture', 'Global Attention Mechanism (GAM)', 'Efficient Channel Attention (ECA)']"
2024,https://openalex.org/W4399128365,Medicine,Automated model discovery for human cardiac tissue: Discovering the best model and parameters,"For more than half a century, scientists have developed mathematical models to understand the behavior of the human heart. Today, we have dozens of heart tissue models to choose from, but selecting the best model is limited to expert professionals, prone to user bias, and vulnerable to human error. Here we take the human out of the loop and automate the process of model discovery. Towards this goal, we establish a novel incompressible orthotropic constitutive neural network to simultaneously discover both, model and parameters, that best explain human cardiac tissue. Notably, our network features 32 individual terms, 8 isotropic and 24 anisotropic, and fully autonomously selects the best model, out of more than 4 billion possible combinations of terms. We demonstrate that we can successfully train the network with triaxial shear and biaxial extension tests and systematically sparsify the parameter vector with L1-regularization. Strikingly, we robustly discover a four-term model that features a quadratic term in the second invariant I2, and exponential quadratic terms in the fourth and eighth invariants I4f, I4n, and I8fs. Importantly, our discovered model is interpretable by design and has parameters with well-defined physical units. We show that it outperforms popular existing myocardium models and generalizes well, from homogeneous laboratory tests to heterogeneous whole heart simulations. This is made possible by a new universal material subroutine that directly takes the discovered network weights as input. Automating the process of model discovery has the potential to democratize cardiac modeling, broaden participation in scientific discovery, and accelerate the development of innovative treatments for cardiovascular disease. Our source code, data, and examples are available at https://github.com/LivingMatterLab/CANN.",['L1-regularization']
2024,https://openalex.org/W4391068733,Medicine,Improving diabetes disease patients classification using stacking ensemble method with PIMA and local healthcare data,"Diabetes mellitus, a chronic metabolic disorder, continues to be a major public health issue around the world. It is estimated that one in every two diabetics is undiagnosed. Early diagnosis and management of diabetes can also prevent or delay the onset of complications. With the help of a variety of machine learning and deep learning models, stacking algorithms, and other techniques, our study's goal is to detect diseases early. In this study, we propose two stacking-based models for diabetes disease classification using a combination of the PIMA Indian diabetes dataset, simulated data, and additional data collected from a local healthcare facility. We use both the classical and deep neural network stacking ensemble methods to combine the predictions of multiple classification models and improve classification accuracy and robustness. In the evaluation protocol, we used both the train-test and cross-validation (CV) techniques to validate our proposed model. The highest accuracy is obtained by stacking ensemble with three NN architectures, resulting in an accuracy of 95.50 %, precision of 94 %, recall of 97 %, and f1-score of 96 % using 5-fold CV on simulation study. The stacked accuracy obtained from ML algorithms for the Pima Indian Diabetes dataset is 75.03 % using the train-test split protocol, while the accuracy obtained from the CV protocol is 77.10 % on the stacked model. The range of performance scores that outperformed the CV protocol 2.23 %–12 %. Our proposed method achieves a high accuracy range from 92 % to 95 %, precision, recall, and F1-score ranges from 88 % to 96 % using classical and deep neural network (NN)-based stacking method on the primary dataset. The proposed dataset and ensemble method could be useful in the early detection and treatment of diabetes, as well as in the advancement of machine learning and data analysis techniques in the healthcare industry.","['stacking algorithms', 'stacking-based models', 'classical stacking ensemble methods', 'deep neural network stacking ensemble methods']"
2024,https://openalex.org/W4391598337,Medicine,Federated Learning for Decentralized Artificial Intelligence in Melanoma Diagnostics,"Importance The development of artificial intelligence (AI)–based melanoma classifiers typically calls for large, centralized datasets, requiring hospitals to give away their patient data, which raises serious privacy concerns. To address this concern, decentralized federated learning has been proposed, where classifier development is distributed across hospitals. Objective To investigate whether a more privacy-preserving federated learning approach can achieve comparable diagnostic performance to a classical centralized (ie, single-model) and ensemble learning approach for AI-based melanoma diagnostics. Design, Setting, and Participants This multicentric, single-arm diagnostic study developed a federated model for melanoma-nevus classification using histopathological whole-slide images prospectively acquired at 6 German university hospitals between April 2021 and February 2023 and benchmarked it using both a holdout and an external test dataset. Data analysis was performed from February to April 2023. Exposures All whole-slide images were retrospectively analyzed by an AI-based classifier without influencing routine clinical care. Main Outcomes and Measures The area under the receiver operating characteristic curve (AUROC) served as the primary end point for evaluating the diagnostic performance. Secondary end points included balanced accuracy, sensitivity, and specificity. Results The study included 1025 whole-slide images of clinically melanoma-suspicious skin lesions from 923 patients, consisting of 388 histopathologically confirmed invasive melanomas and 637 nevi. The median (range) age at diagnosis was 58 (18-95) years for the training set, 57 (18-93) years for the holdout test dataset, and 61 (18-95) years for the external test dataset; the median (range) Breslow thickness was 0.70 (0.10-34.00) mm, 0.70 (0.20-14.40) mm, and 0.80 (0.30-20.00) mm, respectively. The federated approach (0.8579; 95% CI, 0.7693-0.9299) performed significantly worse than the classical centralized approach (0.9024; 95% CI, 0.8379-0.9565) in terms of AUROC on a holdout test dataset (pairwise Wilcoxon signed-rank, P &amp;amp;lt; .001) but performed significantly better (0.9126; 95% CI, 0.8810-0.9412) than the classical centralized approach (0.9045; 95% CI, 0.8701-0.9331) on an external test dataset (pairwise Wilcoxon signed-rank, P &amp;amp;lt; .001). Notably, the federated approach performed significantly worse than the ensemble approach on both the holdout (0.8867; 95% CI, 0.8103-0.9481) and external test dataset (0.9227; 95% CI, 0.8941-0.9479). Conclusions and Relevance The findings of this diagnostic study suggest that federated learning is a viable approach for the binary classification of invasive melanomas and nevi on a clinically representative distributed dataset. Federated learning can improve privacy protection in AI-based melanoma diagnostics while simultaneously promoting collaboration across institutions and countries. Moreover, it may have the potential to be extended to other image classification tasks in digital cancer histopathology and beyond.","['federated learning', 'ensemble learning approach']"
2024,https://openalex.org/W4391692539,Medicine,Exploration of Interpretability Techniques for Deep COVID-19 Classification Using Chest X-ray Images,"The outbreak of COVID-19 has shocked the entire world with its fairly rapid spread, and has challenged different sectors. One of the most effective ways to limit its spread is the early and accurate diagnosing of infected patients. Medical imaging, such as X-ray and computed tomography (CT), combined with the potential of artificial intelligence (AI), plays an essential role in supporting medical personnel in the diagnosis process. Thus, in this article, five different deep learning models (ResNet18, ResNet34, InceptionV3, InceptionResNetV2, and DenseNet161) and their ensemble, using majority voting, have been used to classify COVID-19, pneumoniæ and healthy subjects using chest X-ray images. Multilabel classification was performed to predict multiple pathologies for each patient, if present. Firstly, the interpretability of each of the networks was thoroughly studied using local interpretability methods—occlusion, saliency, input X gradient, guided backpropagation, integrated gradients, and DeepLIFT—and using a global technique—neuron activation profiles. The mean micro F1 score of the models for COVID-19 classifications ranged from 0.66 to 0.875, and was 0.89 for the ensemble of the network models. The qualitative results showed that the ResNets were the most interpretable models. This research demonstrates the importance of using interpretability methods to compare different models before making a decision regarding the best performing model.","['ResNet18', 'ResNet34', 'InceptionV3', 'InceptionResNetV2', 'DenseNet161', 'ensemble using majority voting', 'saliency', 'input X gradient', 'guided backpropagation', 'integrated gradients', 'DeepLIFT']"
2024,https://openalex.org/W4393131920,Medicine,Diabetic foot ulcers segmentation challenge report: Benchmark and analysis,"Monitoring the healing progress of diabetic foot ulcers is a challenging process. Accurate segmentation of foot ulcers can help podiatrists to quantitatively measure the size of wound regions to assist prediction of healing status. The main challenge in this field is the lack of publicly available manual delineation, which can be time consuming and laborious. Recently, methods based on deep learning have shown excellent results in automatic segmentation of medical images, however, they require large-scale datasets for training, and there is limited consensus on which methods perform the best. The 2022 Diabetic Foot Ulcers segmentation challenge was held in conjunction with the 2022 International Conference on Medical Image Computing and Computer Assisted Intervention, which sought to address these issues and stimulate progress in this research domain. A training set of 2000 images exhibiting diabetic foot ulcers was released with corresponding segmentation ground truth masks. Of the 72 (approved) requests from 47 countries, 26 teams used this data to develop fully automated systems to predict the true segmentation masks on a test set of 2000 images, with the corresponding ground truth segmentation masks kept private. Predictions from participating teams were scored and ranked according to their average Dice similarity coefficient of the ground truth masks and prediction masks. The winning team achieved a Dice of 0.7287 for diabetic foot ulcer segmentation. This challenge has now entered a live leaderboard stage where it serves as a challenging benchmark for diabetic foot ulcer segmentation.",['deep learning']
2024,https://openalex.org/W4396679651,Medicine,Predictive Modelling of Critical Vital Signs in ICU Patients by Machine Learning: An Early Warning System for Improved Patient Outcomes,"Accurate monitoring of vital signs in an ICU is integral to understanding overall physical well-being for patients. Our research endeavor employed machine learning techniques to construct a predictive classification model utilizing continuous ICU vital sign measurements. The primary aim was to develop an early warning system capable of forecasting whether vital indicators would reach critical values within one hour; our ultimate aim was to enable healthcare professionals, including nurses and doctors, to intervene proactively, preventing emergency situations which could result in organ dysfunction or mortality. Our comprehensive dataset comprises vital sign measurements, lab test results, procedures, and medications from over 50,000 patients collected via rigorous preprocessing procedures like data cleansing, bias correction, feature extraction and selection to produce an insightful dataset with distinguishing attributes. After selecting an algorithmic set that included Decision Trees (DT), Support Vector Machines (SVM), Recurrent Neural Networks (RNN), and Long Short-Term Memory (LSTM), to predict critical vital signs in ICU patients one hour in advance - such as Heart Rate, SpO2, Mean Artery Pressure (MAP), Respiratory Rate (RR), and Systolic Blood Pressure (SBP). Our models included Heart Rate prediction as well as respiratory Rate/RR predictions/SBP estimation models. The results of the study demonstrated the efficacy and accuracy of machine learning methods designed to anticipate imminent changes to vital signs. Utilizing such predictive models, healthcare providers can increase their capacity to address potential complications before they occur, ultimately leading to improved patient outcomes in challenging settings.","['Decision Trees (DT)', 'Support Vector Machines (SVM)', 'Recurrent Neural Networks (RNN)', 'Long Short-Term Memory (LSTM)']"
2024,https://openalex.org/W4396834505,Medicine,Enhancing cervical cancer detection and robust classification through a fusion of deep learning models,"Abstract Cervical cancer, the second most prevalent cancer affecting women, arises from abnormal cell growth in the cervix, a crucial anatomical structure within the uterus. The significance of early detection cannot be overstated, prompting the use of various screening methods such as Pap smears, colposcopy, and Human Papillomavirus (HPV) testing to identify potential risks and initiate timely intervention. These screening procedures encompass visual inspections, Pap smears, colposcopies, biopsies, and HPV-DNA testing, each demanding the specialized knowledge and skills of experienced physicians and pathologists due to the inherently subjective nature of cancer diagnosis. In response to the imperative for efficient and intelligent screening, this article introduces a groundbreaking methodology that leverages pre-trained deep neural network models, including Alexnet, Resnet-101, Resnet-152, and InceptionV3, for feature extraction. The fine-tuning of these models is accompanied by the integration of diverse machine learning algorithms, with ResNet152 showcasing exceptional performance, achieving an impressive accuracy rate of 98.08%. It is noteworthy that the SIPaKMeD dataset, publicly accessible and utilized in this study, contributes to the transparency and reproducibility of our findings. The proposed hybrid methodology combines aspects of DL and ML for cervical cancer classification. Most intricate and complicated features from images can be extracted through DL. Further various ML algorithms can be implemented on extracted features. This innovative approach not only holds promise for significantly improving cervical cancer detection but also underscores the transformative potential of intelligent automation within the realm of medical diagnostics, paving the way for more accurate and timely interventions.","['Alexnet', 'Resnet-101', 'Resnet-152', 'InceptionV3', 'deep neural network models', 'fine-tuning']"
2024,https://openalex.org/W4399258783,Medicine,A review of uncertainty quantification in medical image analysis: Probabilistic and non-probabilistic methods,"The comprehensive integration of machine learning healthcare models within clinical practice remains suboptimal, notwithstanding the proliferation of high-performing solutions reported in the literature. A predominant factor hindering widespread adoption pertains to an insufficiency of evidence affirming the reliability of the aforementioned models. Recently, uncertainty quantification methods have been proposed as a potential solution to quantify the reliability of machine learning models and thus increase the interpretability and acceptability of the results. In this review, we offer a comprehensive overview of the prevailing methods proposed to quantify the uncertainty inherent in machine learning models developed for various medical image tasks. Contrary to earlier reviews that exclusively focused on probabilistic methods, this review also explores non-probabilistic approaches, thereby furnishing a more holistic survey of research pertaining to uncertainty quantification for machine learning models. Analysis of medical images with the summary and discussion on medical applications and the corresponding uncertainty evaluation protocols are presented, which focus on the specific challenges of uncertainty in medical image analysis. We also highlight some potential future research work at the end. Generally, this review aims to allow researchers from both clinical and technical backgrounds to gain a quick and yet in-depth understanding of the research in uncertainty quantification for medical image analysis machine learning models.","['probabilistic methods', 'non-probabilistic approaches']"
2024,https://openalex.org/W4399442306,Medicine,Integrative analysis of AI-driven optimization in HIV treatment regimens,"The integration of artificial intelligence (AI) into HIV treatment regimens has revolutionized the approach to personalized care and optimization strategies. This study presents an in-depth analysis of the role of AI in transforming HIV treatment, focusing on its ability to tailor therapy to individual patient needs and enhance treatment outcomes. AI-driven optimization in HIV treatment involves the utilization of advanced algorithms and computational techniques to analyze vast amounts of patient data, including genetic information, viral load measurements, and treatment history. By harnessing the power of machine learning and predictive analytics, AI algorithms can identify patterns and trends in patient data that may not be readily apparent to human clinicians. One of the key benefits of AI-driven optimization is its ability to personalize treatment regimens based on individual patient characteristics and disease progression. By considering factors such as drug resistance profiles, comorbidities, and lifestyle factors, AI algorithms can recommend the most effective and well-tolerated treatment options for each patient, leading to improved adherence and clinical outcomes. Furthermore, AI enables continuous monitoring and adjustment of treatment regimens in real time, allowing healthcare providers to respond rapidly to changes in patient status and evolving viral dynamics. This proactive approach to HIV management can help prevent treatment failure and the development of drug resistance, ultimately leading to better long-term outcomes for patients. Despite its transformative potential, AI-driven optimization in HIV treatment is not without challenges. Ethical considerations, data privacy concerns, and the need for robust validation and regulatory oversight are all important factors that must be addressed to ensure the safe and effective implementation of AI algorithms in clinical practice. In conclusion, the integrative analysis presented in this study underscores the significant impact of AI-driven optimization on the personalization and optimization of HIV treatment regimens. By leveraging AI technologies, healthcare providers can tailor treatment approaches to individual patient needs, leading to improved outcomes and quality of life for people living with HIV. Keywords: Integrative Analysis, AI- Driven, Optimization, HIV Treatment, Regimens.",['machine learning']
2024,https://openalex.org/W4390506438,Medicine,Artificial intelligence for oral squamous cell carcinoma detection based on oral photographs: A comprehensive literature review,"Abstract Introduction Oral squamous cell carcinoma (OSCC) presents a significant global health challenge. The integration of artificial intelligence (AI) and computer vision holds promise for the early detection of OSCC through the analysis of digitized oral photographs. This literature review explores the landscape of AI‐driven OSCC automatic detection, assessing both the performance and limitations of the current state of the art. Materials and Methods An electronic search using several data base was conducted, and a systematic review performed in accordance with PRISMA guidelines (CRD42023441416). Results Several studies have demonstrated remarkable results for this task, consistently achieving sensitivity rates exceeding 85% and accuracy rates surpassing 90%, often encompassing around 1000 images. The review scrutinizes these studies, shedding light on their methodologies, including the use of recent machine learning and pattern recognition approaches coupled with different supervision strategies. However, comparing the results from different papers is challenging due to variations in the datasets used. Discussion Considering these findings, this review underscores the urgent need for more robust and reliable datasets in the field of OSCC detection. Furthermore, it highlights the potential of advanced techniques such as multi‐task learning, attention mechanisms, and ensemble learning as crucial tools in enhancing the accuracy and sensitivity of OSCC detection through oral photographs. Conclusion These insights collectively emphasize the transformative impact of AI‐driven approaches on early OSCC diagnosis, with the potential to significantly improve patient outcomes and healthcare practices.","['machine learning', 'multi-task learning', 'attention mechanisms', 'ensemble learning']"
2024,https://openalex.org/W4391096835,Medicine,Diagnostic Performance Comparison between Generative AI and Physicians: A Systematic Review and Meta-Analysis,"Abstract Background The rapid advancement of generative artificial intelligence (AI) has led to the wide dissemination of models with exceptional understanding and generation of human language. Their integration into healthcare has shown potential for improving medical diagnostics, yet a comprehensive diagnostic performance evaluation of generative AI models and the comparison of their diagnostic performance with that of physicians has not been extensively explored. Methods In this systematic review and meta-analysis, a comprehensive search of Medline, Scopus, Web of Science, Cochrane Central, and MedRxiv was conducted for studies published from June 2018 through December 2023, focusing on those that validate generative AI models for diagnostic tasks. The risk of bias was assessed using the Prediction Model Study Risk of Bias Assessment Tool. Meta-regression was performed to summarize the performance of the models and to compare the accuracy of the models with that of physicians. Results The search resulted in 54 studies being included in the meta-analysis. Nine generative AI models were evaluated across 17 medical specialties. The quality assessment indicated a high risk of bias in the majority of studies, primarily due to small sample sizes. The overall accuracy for generative AI models across 54 studies was 56.9% (95% confidence interval [CI]: 51.0–62.7%). The meta-analysis demonstrated that, on average, physicians exceeded the accuracy of the models (difference in accuracy: 14.4% [95% CI: 4.9–23.8%], p-value =0.004). However, both Prometheus (Bing) and GPT-4 showed slightly better performance compared to non-experts (-2.3% [95% CI: -27.0–22.4%], p-value = 0.848 and -0.32% [95% CI: -14.4–13.7%], p-value = 0.962), but slightly underperformed when compared to experts (10.9% [95% CI: -13.1–35.0%], p-value = 0.356 and 12.9% [95% CI: 0.15–25.7%], p-value = 0.048). The sub-analysis revealed significantly improved accuracy in the fields of Gynecology, Pediatrics, Orthopedic surgery, Plastic surgery, and Otolaryngology, while showing reduced accuracy for Neurology, Psychiatry, Rheumatology, and Endocrinology compared to that of General Medicine. No significant heterogeneity was observed based on the risk of bias. Conclusions Generative AI exhibits promising diagnostic capabilities, with accuracy varying significantly by model and medical specialty. Although they have not reached the reliability of expert physicians, the findings suggest that generative AI models have the potential to enhance healthcare delivery and medical education, provided they are integrated with caution and their limitations are well-understood. Key Points Question: What is the diagnostic accuracy of generative AI models and how does this accuracy compare to that of physicians? Findings: This meta-analysis found that generative AI models have a pooled accuracy of 56.9% (95% confidence interval: 51.0–62.7%). The accuracy of expert physicians exceeds that of AI in all specialties, however, some generative AI models are comparable to non-expert physicians. Meaning: The diagnostic performance of generative AI models suggests that they do not match the level of experienced physicians but that they may have potential applications in healthcare delivery and medical education.",['generative AI models']
2024,https://openalex.org/W4391113105,Medicine,A systematic review of artificial intelligence techniques for oral cancer detection,"Oral cancer is a form of cancer that develops in the tissue of an oral cavity. Detection at an early stage is necessary to prevent the mortality rate in cancer patients. Artificial intelligence (AI) techniques play a significant role in assisting with diagnosing oral cancer. The AI techniques provide better detection accuracy and help automate oral cancer detection. The study shows that AI has a wide range of algorithms and provides outcomes in the most precise manner possible. We provide an overview of different input types and apply an appropriate algorithm to detect oral cancer. We aim to provide an overview of various AI techniques that can be used to automate oral cancer detection and to analyze these techniques to improve the efficiency and accuracy of oral cancer screening. We provide a summary of various methods available for oral cancer detection. We cover different input image formats, their processing, and the need for segmentation and feature extraction. We further include a list of other conventional strategies. We focus on various AI techniques for detecting oral cancer, including deep learning, machine learning, fuzzy computing, data mining, and genetic algorithms, and evaluates their benefits and drawbacks. The larger part of the articles focused on deep learning (37%) methods, followed by machine learning (32%), genetic algorithms (12%), data mining techniques (10%), and fuzzy computing (9%) for oral cancer detection.","['deep learning', 'machine learning', 'genetic algorithms']"
2024,https://openalex.org/W4391164242,Medicine,Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models,"Suicidal ideation detection is a vital research area that holds great potential for improving mental health support systems. However, the sensitivity surrounding suicide-related data poses challenges in accessing large-scale, annotated datasets necessary for training effective machine learning models. To address this limitation, we introduce an innovative strategy that leverages the capabilities of generative AI models, such as ChatGPT, Flan-T5, and Llama, to create synthetic data for suicidal ideation detection. Our data generation approach is grounded in social factors extracted from psychology literature and aims to ensure coverage of essential information related to suicidal ideation. In our study, we benchmarked against state-of-the-art NLP classification models, specifically, those centered around the BERT family structures. When trained on the real-world dataset, UMD, these conventional models tend to yield F1-scores ranging from 0.75 to 0.87. Our synthetic data-driven method, informed by social factors, offers consistent F1-scores of 0.82 for both models, suggesting that the richness of topics in synthetic data can bridge the performance gap across different model complexities. Most impressively, when we combined a mere 30% of the UMD dataset with our synthetic data, we witnessed a substantial increase in performance, achieving an F1-score of 0.88 on the UMD test set. Such results underscore the cost-effectiveness and potential of our approach in confronting major challenges in the field, such as data scarcity and the quest for diversity in data representation.","['generative AI models', 'Flan-T5', 'Llama']"
2024,https://openalex.org/W4391613588,Medicine,Artificial intelligence framework for heart disease classification from audio signals,"Abstract As cardiovascular disorders are prevalent, there is a growing demand for reliable and precise diagnostic methods within this domain. Audio signal-based heart disease detection is a promising area of research that leverages sound signals generated by the heart to identify and diagnose cardiovascular disorders. Machine learning (ML) and deep learning (DL) techniques are pivotal in classifying and identifying heart disease from audio signals. This study investigates ML and DL techniques to detect heart disease by analyzing noisy sound signals. This study employed two subsets of datasets from the PASCAL CHALLENGE having real heart audios. The research process and visually depict signals using spectrograms and Mel-Frequency Cepstral Coefficients (MFCCs). We employ data augmentation to improve the model’s performance by introducing synthetic noise to the heart sound signals. In addition, a feature ensembler is developed to integrate various audio feature extraction techniques. Several machine learning and deep learning classifiers are utilized for heart disease detection. Among the numerous models studied and previous study findings, the multilayer perceptron model performed best, with an accuracy rate of 95.65%. This study demonstrates the potential of this methodology in accurately detecting heart disease from sound signals. These findings present promising opportunities for enhancing medical diagnosis and patient care.","['machine learning (ML)', 'deep learning (DL)', 'multilayer perceptron model']"
2024,https://openalex.org/W4391820319,Medicine,Investigation on explainable machine learning models to predict chronic kidney diseases,"Chronic kidney disease (CKD) is a major worldwide health problem, affecting a large proportion of the world's population and leading to higher morbidity and death rates. The early stages of CKD sometimes present without visible symptoms, causing patients to be unaware. Early detection and treatments are critical in reducing complications and improving the overall quality of life for people afflicted. In this work, we investigate the use of an explainable artificial intelligence (XAI)-based strategy, leveraging clinical characteristics, to predict CKD. This study collected clinical data from 491 patients, comprising 56 with CKD and 435 without CKD, encompassing clinical, laboratory, and demographic variables. To develop the predictive model, five machine learning (ML) methods, namely logistic regression (LR), random forest (RF), decision tree (DT), Naïve Bayes (NB), and extreme gradient boosting (XGBoost), were employed. The optimal model was selected based on accuracy and area under the curve (AUC). Additionally, the SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable Model-agnostic Explanations) algorithms were utilized to demonstrate the influence of the features on the optimal model. Among the five models developed, the XGBoost model achieved the best performance with an AUC of 0.9689 and an accuracy of 93.29%. The analysis of feature importance revealed that creatinine, glycosylated hemoglobin type A1C (HgbA1C), and age were the three most influential features in the XGBoost model. The SHAP force analysis further illustrated the model's visualization of individualized CKD predictions. For further insights into individual predictions, we also utilized the LIME algorithm. This study presents an interpretable ML-based approach for the early prediction of CKD. The SHAP and LIME methods enhance the interpretability of ML models and help clinicians better understand the rationale behind the predicted outcomes more effectively.","['logistic regression (LR)', 'random forest (RF)', 'decision tree (DT)', 'Naïve Bayes (NB)', 'extreme gradient boosting (XGBoost)', 'SHAP (SHapley Additive exPlanations)', 'LIME (Local Interpretable Model-agnostic Explanations)']"
2024,https://openalex.org/W4392058879,Medicine,Prostate cancer grading framework based on deep transfer learning and Aquila optimizer,"Abstract Prostate cancer is the one of the most dominant cancer among males. It represents one of the leading cancer death causes worldwide. Due to the current evolution of artificial intelligence in medical imaging, deep learning has been successfully applied in diseases diagnosis. However, most of the recent studies in prostate cancer classification suffers from either low accuracy or lack of data. Therefore, the present work introduces a hybrid framework for early and accurate classification and segmentation of prostate cancer using deep learning. The proposed framework consists of two stages, namely classification stage and segmentation stage. In the classification stage, 8 pretrained convolutional neural networks were fine-tuned using Aquila optimizer and used to classify patients of prostate cancer from normal ones. If the patient is diagnosed with prostate cancer, segmenting the cancerous spot from the overall image using U-Net can help in accurate diagnosis, and here comes the importance of the segmentation stage. The proposed framework is trained on 3 different datasets in order to generalize the framework. The best reported classification accuracies of the proposed framework are 88.91% using MobileNet for the “ISUP Grade-wise Prostate Cancer” dataset and 100% using MobileNet and ResNet152 for the “Transverse Plane Prostate Dataset” dataset with precisions 89.22% and 100%, respectively. U-Net model gives an average segmentation accuracy and AUC of 98.46% and 0.9778, respectively, using the “PANDA: Resized Train Data (512 × 512)” dataset. The results give an indicator of the acceptable performance of the proposed framework.","['pretrained convolutional neural networks', 'MobileNet', 'ResNet152', 'U-Net']"
2024,https://openalex.org/W4393222088,Medicine,Methodological insights into ChatGPT’s screening performance in systematic reviews,"Abstract Background The screening process for systematic reviews and meta-analyses in medical research is a labor-intensive and time-consuming task. While machine learning and deep learning have been applied to facilitate this process, these methods often require training data and user annotation. This study aims to assess the efficacy of ChatGPT, a large language model based on the Generative Pretrained Transformers (GPT) architecture, in automating the screening process for systematic reviews in radiology without the need for training data. Methods A prospective simulation study was conducted between May 2nd and 24th, 2023, comparing ChatGPT’s performance in screening abstracts against that of general physicians (GPs). A total of 1198 abstracts across three subfields of radiology were evaluated. Metrics such as sensitivity, specificity, positive and negative predictive values (PPV and NPV), workload saving, and others were employed. Statistical analyses included the Kappa coefficient for inter-rater agreement, ROC curve plotting, AUC calculation, and bootstrapping for p-values and confidence intervals. Results ChatGPT completed the screening process within an hour, while GPs took an average of 7–10 days. The AI model achieved a sensitivity of 95% and an NPV of 99%, slightly outperforming the GPs’ sensitive consensus (i.e., including records if at least one person includes them). It also exhibited remarkably low false negative counts and high workload savings, ranging from 40 to 83%. However, ChatGPT had lower specificity and PPV compared to human raters. The average Kappa agreement between ChatGPT and other raters was 0.27. Conclusions ChatGPT shows promise in automating the article screening phase of systematic reviews, achieving high sensitivity and workload savings. While not entirely replacing human expertise, it could serve as an efficient first-line screening tool, particularly in reducing the burden on human resources. Further studies are needed to fine-tune its capabilities and validate its utility across different medical subfields.","['machine learning', 'deep learning', 'Generative Pretrained Transformers (GPT) architecture']"
2024,https://openalex.org/W4393991916,Medicine,Advancing Ligand Docking through Deep Learning: Challenges and Prospects in Virtual Screening,"ConspectusMolecular docking, also termed ligand docking (LD), is a pivotal element of structure-based virtual screening (SBVS) used to predict the binding conformations and affinities of protein–ligand complexes. Traditional LD methodologies rely on a search and scoring framework, utilizing heuristic algorithms to explore binding conformations and scoring functions to evaluate binding strengths. However, to meet the efficiency demands of SBVS, these algorithms and functions are often simplified, prioritizing speed over accuracy.The emergence of deep learning (DL) has exerted a profound impact on diverse fields, ranging from natural language processing to computer vision and drug discovery. DeepMind's AlphaFold2 has impressively exhibited its ability to accurately predict protein structures solely from amino acid sequences, highlighting the remarkable potential of DL in conformation prediction. This groundbreaking advancement circumvents the traditional search-scoring frameworks in LD, enhancing both accuracy and processing speed and thereby catalyzing a broader adoption of DL algorithms in binding pose prediction. Nevertheless, a consensus on certain aspects remains elusive.In this Account, we delineate the current status of employing DL to augment LD within the VS paradigm, highlighting our contributions to this domain. Furthermore, we discuss the challenges and future prospects, drawing insights from our scholarly investigations. Initially, we present an overview of VS and LD, followed by an introduction to DL paradigms, which deviate significantly from traditional search-scoring frameworks. Subsequently, we delve into the challenges associated with the development of DL-based LD (DLLD), encompassing evaluation metrics, application scenarios, and physical plausibility of the predicted conformations. In the evaluation of LD algorithms, it is essential to recognize the multifaceted nature of the metrics. While the accuracy of binding pose prediction, often measured by the success rate, is a pivotal aspect, the scoring/screening power and computational speed of these algorithms are equally important given the pivotal role of LD tools in VS. Regarding application scenarios, early methods focused on blind docking, where the binding site is unknown. However, recent studies suggest a shift toward identifying binding sites rather than solely predicting binding poses within these models. In contrast, LD with a known pocket in VS has been shown to be more practical. Physical plausibility poses another significant challenge. Although DLLD models often achieve higher success rates compared to traditional methods, they may generate poses with implausible local structures, such as incorrect bond angles or lengths, which are disadvantageous for postprocessing tasks like visualization. Finally, we discuss the future perspectives for DLLD, emphasizing the need to improve generalization ability, strike a balance between speed and accuracy, account for protein conformation flexibility, and enhance physical plausibility. Additionally, we delve into the comparison between generative and regression algorithms in this context, exploring their respective strengths and potential.","['deep learning (DL)', ""DeepMind's AlphaFold2"", 'regression algorithms']"
2024,https://openalex.org/W4398169659,Medicine,The Sociodemographic Biases in Machine Learning Algorithms: A Biomedical Informatics Perspective,"Artificial intelligence models represented in machine learning algorithms are promising tools for risk assessment used to guide clinical and other health care decisions. Machine learning algorithms, however, may house biases that propagate stereotypes, inequities, and discrimination that contribute to socioeconomic health care disparities. The biases include those related to some sociodemographic characteristics such as race, ethnicity, gender, age, insurance, and socioeconomic status from the use of erroneous electronic health record data. Additionally, there is concern that training data and algorithmic biases in large language models pose potential drawbacks. These biases affect the lives and livelihoods of a significant percentage of the population in the United States and globally. The social and economic consequences of the associated backlash cannot be underestimated. Here, we outline some of the sociodemographic, training data, and algorithmic biases that undermine sound health care risk assessment and medical decision-making that should be addressed in the health care system. We present a perspective and overview of these biases by gender, race, ethnicity, age, historically marginalized communities, algorithmic bias, biased evaluations, implicit bias, selection/sampling bias, socioeconomic status biases, biased data distributions, cultural biases and insurance status bias, conformation bias, information bias and anchoring biases and make recommendations to improve large language model training data, including de-biasing techniques such as counterfactual role-reversed sentences during knowledge distillation, fine-tuning, prefix attachment at training time, the use of toxicity classifiers, retrieval augmented generation and algorithmic modification to mitigate the biases moving forward.","['knowledge distillation', 'fine-tuning', 'retrieval augmented generation']"
2024,https://openalex.org/W4399715357,Medicine,AI-POWERED FRAUD DETECTION IN BANKING: SAFEGUARDING FINANCIAL TRANSACTIONS,"The banking industry's metamorphosis through digitalization has unquestionably revolutionized accessibility and convenience for customers worldwide. However, this paradigm shift has ushered in a new era of challenges, most notably in the realm of cybersecurity. Conventional rule-based fraud detection strategies have struggled to keep pace with the rapid evolution of cyber threats, prompting a surge of interest in more adaptive approaches like unsupervised learning. Furthermore, the COVID-19 pandemic has exacerbated the issue of bank fraud due to the widespread transition to online platforms and the proliferation of charitable funds, which present ripe opportunities for exploitation by cybercriminals. In response to these pressing concerns, this study delves into the realm of machine learning algorithms for the analysis and identification of fraudulent banking transactions. Notably, it contributes scientific novelty by developing models specifically tailored to this purpose and implementing innovative preprocessing techniques to enhance detection accuracy. Utilizing a diverse array of algorithms, including Random Forest, K-Nearest Neighbor (KNN), Naïve Bayes, Decision Trees, and Logistic Regression, the study showcases promising results. In particular, logistic regression and decision tree models exhibit impressive accuracy and Area Under the Curve (AUC) values of approximately 0.98, 0.97 and 0.95, 0.94, respectively. Given the pervasive nature of banking fraud in our digital society, the utilization of artificial intelligence algorithms for fraud detection stands as a critical and timely endeavor, promising enhanced security and trust in the financial ecosystem.","['unsupervised learning', 'Random Forest', 'K-Nearest Neighbor (KNN)', 'Naïve Bayes', 'Decision Trees', 'Logistic Regression']"
2024,https://openalex.org/W4391042406,Medicine,"A comparative analysis of machine learning techniques for aboveground biomass estimation: A case study of the Western Ghats, India","Accurate assessment of aboveground biomass (AGB) in tropical forests, particularly within a biodiversity hotspot, is vital for sustainable resource management and the preservation of ecosystems. However, estimating AGB in tropical forests is complex due to the diverse and intricate nature of vegetation, necessitating the integration of data from multiple sources. To tackle this challenge, our study utilized seven machine learning algorithms to analyze various combination of multisource datasets. We developed seven models/scenarios that incorporated Sentinel-1, Sentinel-2 as well as environmental factors such as topography, soil and climate to identify key variables for accurate estimation of AGB. For optimal performance, hyperparameters of the algorithms were fine-tuned through 10-fold cross-validation and their accuracy were assessed using the testing dataset. We found that the integrated model of satellite datasets, topography, climate, and soil variables exhibited the highest accuracy, where ensemble stacking, that combined multiple MLAs, proved to be reliable and best suited for predicting AGB (mean absolute error-3.97 Mg 0.1 ha−1, root mean square error-5.67 Mg 0.1 ha−1, and coefficient of determination - 0.82). Notably, the top predictor variables included Sentinel-2 bands (near infrared and green), soil properties (pH and soil organic carbon), and topography (elevation). The study emphasizes the significance of incorporating environmental variables (specifically topography and soil properties) along with Sentinel datasets to improve the accuracy of AGB estimation. This approach has the potential for broader applications, specifically in regions where vegetation productivity is governed by diverse environmental conditions.",['ensemble stacking']
2024,https://openalex.org/W4391166814,Medicine,Identifying top ten predictors of type 2 diabetes through machine learning analysis of UK Biobank data,"Abstract The study aimed to identify the most predictive factors for the development of type 2 diabetes. Using an XGboost classification model, we projected type 2 diabetes incidence over a 10-year horizon. We deliberately minimized the selection of baseline factors to fully exploit the rich dataset from the UK Biobank. The predictive value of features was assessed using shap values, with model performance evaluated via Receiver Operating Characteristic Area Under the Curve, sensitivity, and specificity. Data from the UK Biobank, encompassing a vast population with comprehensive demographic and health data, was employed. The study enrolled 450,000 participants aged 40–69, excluding those with pre-existing diabetes. Among 448,277 participants, 12,148 developed type 2 diabetes within a decade. HbA1c emerged as the foremost predictor, followed by BMI, waist circumference, blood glucose, family history of diabetes, gamma-glutamyl transferase, waist-hip ratio, HDL cholesterol, age, and urate. Our XGboost model achieved a Receiver Operating Characteristic Area Under the Curve of 0.9 for 10-year type 2 diabetes prediction, with a reduced 10-feature model achieving 0.88. Easily measurable biological factors surpassed traditional risk factors like diet, physical activity, and socioeconomic status in predicting type 2 diabetes. Furthermore, high prediction accuracy could be maintained using just the top 10 biological factors, with additional ones offering marginal improvements. These findings underscore the significance of biological markers in type 2 diabetes prediction.","['XGboost classification model', 'shap values']"
2024,https://openalex.org/W4391305160,Medicine,Protocol for metadata and image collection at diabetic foot ulcer clinics: enabling research in wound analytics and deep learning,"Abstract Background The escalating impact of diabetes and its complications, including diabetic foot ulcers (DFUs), presents global challenges in quality of life, economics, and resources, affecting around half a billion people. DFU healing is hindered by hyperglycemia-related issues and diverse diabetes-related physiological changes, necessitating ongoing personalized care. Artificial intelligence and clinical research strive to address these challenges by facilitating early detection and efficient treatments despite resource constraints. This study establishes a standardized framework for DFU data collection, introducing a dedicated case report form, a comprehensive dataset named Zivot with patient population clinical feature breakdowns and a baseline for DFU detection using this dataset and a UNet architecture. Results Following this protocol, we created the Zivot dataset consisting of 269 patients with active DFUs, and about 3700 RGB images and corresponding thermal and depth maps for the DFUs. The effectiveness of collecting a consistent and clean dataset was demonstrated using a bounding box prediction deep learning network that was constructed with EfficientNet as the feature extractor and UNet architecture. The network was trained on the Zivot dataset, and the evaluation metrics showed promising values of 0.79 and 0.86 for F1-score and mAP segmentation metrics. Conclusions This work and the Zivot database offer a foundation for further exploration of holistic and multimodal approaches to DFU research.","['UNet architecture', 'EfficientNet']"
2024,https://openalex.org/W4392693790,Medicine,BINDTI: A bi-directional Intention network for drug-target interaction identification based on attention mechanisms,"The identification of drug-target interactions (DTIs) is an essential step in drug discovery. In vitro experimental methods are expensive, laborious, and time-consuming. Deep learning has witnessed promising progress in DTI prediction. However, how to precisely represent drug and protein features is a major challenge for DTI prediction. Here, we developed an end-to-end DTI identification framework called BINDTI based on bi-directional Intention network. First, drug features are encoded with graph convolutional networks based on its 2D molecular graph obtained by its SMILES string. Next, protein features are encoded based on its amino acid sequence through a mixed model called ACmix, which integrates self-attention mechanism and convolution. Third, drug and target features are fused through bi-directional Intention network, which combines Intention and multi-head attention. Finally, unknown drug-target (DT) pairs are classified through multilayer perceptron based on the fused DT features. The results demonstrate that BINDTI greatly outperformed four baseline methods (i.e., CPI-GNN, TransfomerCPI, MolTrans, and IIFDTI) on the BindingDB, BioSNAP, DrugBank, and Human datasets. More importantly, it was more appropriate to predict new DTIs than the four baseline methods on imbalanced datasets. Ablation experimental results elucidated that both bi-directional Intention and ACmix could greatly advance DTI prediction. The fused feature visualization and case studies manifested that the predicted results by BINDTI were basically consistent with the true ones. We anticipate that the proposed BINDTI framework can find new low-cost drug candidates, improve drugs' virtual screening, and further facilitate drug repositioning as well as drug discovery. BINDTI is publicly available at <uri xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">https://github.com/plhhnu/BINDTI</uri> .","['graph convolutional networks', 'self-attention mechanism', 'convolution', 'multi-head attention', 'multilayer perceptron']"
2024,https://openalex.org/W4400006942,Medicine,Prediction of Alzheimer's disease progression within 6 years using speech: A novel approach leveraging language models,"Abstract INTRODUCTION Identification of individuals with mild cognitive impairment (MCI) who are at risk of developing Alzheimer's disease (AD) is crucial for early intervention and selection of clinical trials. METHODS We applied natural language processing techniques along with machine learning methods to develop a method for automated prediction of progression to AD within 6 years using speech. The study design was evaluated on the neuropsychological test interviews of n = 166 participants from the Framingham Heart Study, comprising 90 progressive MCI and 76 stable MCI cases. RESULTS Our best models, which used features generated from speech data, as well as age, sex, and education level, achieved an accuracy of 78.5% and a sensitivity of 81.1% to predict MCI‐to‐AD progression within 6 years. DISCUSSION The proposed method offers a fully automated procedure, providing an opportunity to develop an inexpensive, broadly accessible, and easy‐to‐administer screening tool for MCI‐to‐AD progression prediction, facilitating development of remote assessment. Highlights Voice recordings from neuropsychological exams coupled with basic demographics can lead to strong predictive models of progression to dementia from mild cognitive impairment. The study leveraged AI methods for speech recognition and processed the resulting text using language models. The developed AI‐powered pipeline can lead to fully automated assessment that could enable remote and cost‐effective screening and prognosis for Alzehimer's disease.",['machine learning']
2024,https://openalex.org/W4390884647,Medicine,Detecting COVID-19 in chest CT images based on several pre-trained models,"Abstract This paper explores the use of chest CT scans for early detection of COVID-19 and improved patient outcomes. The proposed method employs advanced techniques, including binary cross-entropy, transfer learning, and deep convolutional neural networks, to achieve accurate results. The COVIDx dataset, which contains 104,009 chest CT images from 1,489 patients, is used for a comprehensive analysis of the virus. A sample of 13,413 images from this dataset is categorised into two groups: 7,395 CT scans of individuals with confirmed COVID-19 and 6,018 images of normal cases. The study presents pre-trained transfer learning models such as ResNet (50), VGG (19), VGG (16), and Inception V3 to enhance the DCNN for classifying the input CT images. The binary cross-entropy metric is used to compare COVID-19 cases with normal cases based on predicted probabilities for each class. Stochastic Gradient Descent and Adam optimizers are employed to address overfitting issues. The study shows that the proposed pre-trained transfer learning models achieve accuracies of 99.07%, 98.70%, 98.55%, and 96.23%, respectively, in the validation set using the Adam optimizer. Therefore, the proposed work demonstrates the effectiveness of pre-trained transfer learning models in enhancing the accuracy of DCNNs for image classification. Furthermore, this paper provides valuable insights for the development of more accurate and efficient diagnostic tools for COVID-19.","['transfer learning', 'deep convolutional neural networks', 'pre-trained transfer learning models', 'ResNet (50)', 'VGG (19)', 'VGG (16)', 'Inception V3', 'Stochastic Gradient Descent optimizer', 'Adam optimizer']"
2024,https://openalex.org/W4391892547,Medicine,A Novel Early Detection and Prevention of Coronary Heart Disease Framework Using Hybrid Deep Learning Model and Neural Fuzzy Inference System,"Diabetes is the ""mother of all diseases"" as it affects multiple organs of body of an individual in some way. Its timely detection and management are critically important. Otherwise, the long run, it can cause several complications in a diabetic. Heart disease is one of the major complications of diabetes.This work proposed an Optimal Scrutiny Boosted Graph Convolutional LSTM (O-SBGC-LSTM), SBGC-LSTM enhanced by Eurygaster Optimization Algorithm (EOA) to tune hyperparameters for early prevention and detection of diabetes disease. This work proposed an Optimal Scrutiny Boosted Graph Convolutional LSTM (O-SBGC-LSTM), SBGC-LSTM enhanced by Eurygaster Optimization Algorithm (EOA) to tune hyperparameters for early prevention and detection of diabetes disease. This method not only captures discriminative features in spatial configuration and temporal dynamics but also explore the co-occurrence relationship between spatial and temporal domains. This method also presents a temporal hierarchical architecture to increase temporal receptive fields of top SBGC-LSTM layer, which boosts the ability to learn high-level semantic representation and significantly reduces computation cost. The performance of O-SBGC-LSTM was found overall to be satisfactory, reaching >98% accuracy in most studies. In comparison with classic machine learning approaches, proposed hybrid DL was found to achieve better performance in almost all studies that reported such comparison outcomes. Furthermore, prevention is better than cure. Additionally, employed fuzzy based inference techniques to enhance the prevention procedure using suggestion table.",['fuzzy based inference techniques']
2024,https://openalex.org/W4392195911,Medicine,<scp>CerviFormer</scp>: A pap smear‐based cervical cancer classification method using cross‐attention and latent transformer,"Abstract Cervical cancer is one of the primary causes of death in women. It should be diagnosed early and treated according to the best medical advice, similar to other diseases, to ensure that its effects are as minimal as possible. Pap smear images are one of the most constructive ways for identifying this type of cancer. This study proposes a cross‐attention‐based Transfomer approach for the reliable classification of cervical cancer in pap smear images. In this study, we propose the CerviFormer‐a model that depends on the Transformers and thereby requires minimal architectural assumptions about the size of the input data. The model uses a cross‐attention technique to repeatedly consolidate the input data into a compact latent Transformer module, which enables it to manage very large‐scale inputs. We evaluated our model on two publicly available pap smear datasets. For 3‐state classification on the Sipakmed data, the model achieved an accuracy of 96.67%. For 2‐state classification on the Herlev data, the model achieved an accuracy of 94.57%. Experimental results on two publicly accessible datasets demonstrate that the proposed method achieves competitive results when compared to contemporary approaches. The proposed method brings forth a comprehensive classification model to detect cervical cancer in pap smear images. This may aid medical professionals in providing better cervical cancer treatment, consequently, enhancing the overall effectiveness of the entire testing process.","['cross-attention-based Transformer', 'Transformers']"
2024,https://openalex.org/W4392915169,Medicine,Unified deep learning models for enhanced lung cancer prediction with ResNet-50–101 and EfficientNet-B3 using DICOM images,"Abstract Significant advancements in machine learning algorithms have the potential to aid in the early detection and prevention of cancer, a devastating disease. However, traditional research methods face obstacles, and the amount of cancer-related information is rapidly expanding. The authors have developed a helpful support system using three distinct deep-learning models, ResNet-50, EfficientNet-B3, and ResNet-101, along with transfer learning, to predict lung cancer, thereby contributing to health and reducing the mortality rate associated with this condition. This offer aims to address the issue effectively. Using a dataset of 1,000 DICOM lung cancer images from the LIDC-IDRI repository, each image is classified into four different categories. Although deep learning is still making progress in its ability to analyze and understand cancer data, this research marks a significant step forward in the fight against cancer, promoting better health outcomes and potentially lowering the mortality rate. The Fusion Model, like all other models, achieved 100% precision in classifying Squamous Cells. The Fusion Model and ResNet-50 achieved a precision of 90%, closely followed by EfficientNet-B3 and ResNet-101 with slightly lower precision. To prevent overfitting and improve data collection and planning, the authors implemented a data extension strategy. The relationship between acquiring knowledge and reaching specific scores was also connected to advancing and addressing the issue of imprecise accuracy, ultimately contributing to advancements in health and a reduction in the mortality rate associated with lung cancer.","['ResNet-50', 'EfficientNet-B3', 'ResNet-101', 'transfer learning']"
2024,https://openalex.org/W4390490875,Medicine,More Robots are Coming: Large Multimodal Models (ChatGPT) can Solve Visually Diverse Images of Parsons Problems,"Large language models are reshaping computing education. Based on recent research, these models explain code better than students, answer multiple choice questions at or above the class average, and generate code that can pass automated tests in introductory courses. In response to these capabilities, instructors have quickly adjusted their courses and assessment methods to align with shifting learning goals and the increased risk of academic integrity issues. While some scholars have advocated for the integration of visual problems as a safeguard against the capabilities of language models, new multimodal models now have vision and language capabilities that may allow them to analyze and solve visual problems. In this paper, we compare the large multimodal model (LMMs) GPT-4V with Bard, an LLM that uses Google Lens for text recognition. We find that LMMs, which have learned both pixel features (from images) and text features (from prompts) in the same embedding space, performed substantially better than Bard which uses a piecemeal approach. With a specific focus on Parsons problems presented across diverse visual representations, our results show that GPT-4V solved 96.7% these visual problems, struggling minimally with a single Parsons problem. Conversely, Bard performed poorly by only solving 69.2% of problems, struggling with common issues like hallucinations and refusals. These findings suggest that merely transitioning to visual programming problems might not be a panacea to issues of academic integrity in the generative AI era.",['large multimodal models (LMMs)']
2024,https://openalex.org/W4390812034,Medicine,The Utility of AI in Writing a Scientific Review Article on the Impacts of COVID-19 on Musculoskeletal Health,"Abstract Purpose of Review There were two primary purposes to our reviews. First, to provide an update to the scientific community about the impacts of COVID-19 on musculoskeletal health. Second, was to determine the value of using a large language model, ChatGPT 4.0, in the process of writing a scientific review article. To accomplish these objectives, we originally set out to write three review articles on the topic using different methods to produce the initial drafts of the review articles. The first review article was written in the traditional manner by humans, the second was to be written exclusively using ChatGPT (AI-only or AIO), and the third approach was to input the outline and references selected by humans from approach 1 into ChatGPT, using the AI to assist in completing the writing (AI-assisted or AIA). All review articles were extensively fact-checked and edited by all co-authors leading to the final drafts of the manuscripts, which were significantly different from the initial drafts. Recent Findings Unfortunately, during this process, it became clear that approach 2 was not feasible for a very recent topic like COVID-19 as at the time, ChatGPT 4.0 had a cutoff date of September 2021 and all articles published after this date had to be provided to ChatGPT, making approaches 2 and 3 virtually identical. Therefore, only two approaches and two review articles were written (human and AI-assisted). Here we found that the human-only approach took less time to complete than the AI-assisted approach. This was largely due to the number of hours required to fact-check and edit the AI-assisted manuscript. Of note, the AI-assisted approach resulted in inaccurate attributions of references (about 20%) and had a higher similarity index suggesting an increased risk of plagiarism. Summary The main aim of this project was to determine whether the use of AI could improve the process of writing a scientific review article. Based on our experience, with the current state of technology, it would not be advised to solely use AI to write a scientific review article, especially on a recent topic.","['large language model, ChatGPT 4.0']"
2024,https://openalex.org/W4390959437,Medicine,Machine learning model (RG-DMML) and ensemble algorithm for prediction of students’ retention and graduation in education,"Automated prediction of students' retention and graduation in education using advanced analytical methods such as artificial intelligence (AI), has recently attracted the attention of educators, both in theory and in practice. Whereas invaluable insights and theories for measuring and testing the topic have been proposed, most of the existing methods do not technically highlight the non-trivial factors behind the renowned challenges and attrition. To this effect, by making use of two categories of data collected in a higher education setting about students (i) retention (n = 52262) and (ii) graduation (n = 53639); this study proposes a machine learning model - RG-DMML (retention and graduation data mining and machine learning) and ensemble algorithm for prediction of students' retention and graduation status in education. This was done by training and testing key features that are technically deemed suitable for measuring the constructs (retention and graduation), such as (i) the Average grade of the previous high school, and (ii) the Entry/admission score. The proposed model (RG-DMML) is designed based on the cross industry standard process for data mining (CRISP-DM) methodology, implemented using supervised machine learning technique such as K-Nearest Neighbor (KNN), and validated using the k-fold cross-validation method. The results show that the executed model and algorithm based on the Bagging method and 10-fold cross-validation are efficient and effective for predicting the student's retention and graduation status, with Precision (retention = 0.909, graduation = 0.822), Recall (retention = 1.000, graduation = 0.957), Accuracy (retention = 0.909, graduation = 0.817), F1-Score (retention = 0.952, graduation = 0.885) showing significant high accuracy levels or performance rate, and low Error-rate (retention = 0.090, graduation = 0.182), respectively. In addition, by considering the individual features selected through the Wrapper method in predicting the outputs, the proposed model proved more effective for predicting the students' retention status in comparison to the graduation data. The implications of the models' output and factors that impact the effective prediction or identification of at-risk students, e.g., for timely intervention, counselling, decision-making, and sustainable educational practice are empirically discussed in the study.","['ensemble algorithm', 'supervised machine learning technique', 'K-Nearest Neighbor (KNN)', 'Wrapper method']"
2024,https://openalex.org/W4391542772,Medicine,Deep learning algorithm-based multimodal MRI radiomics and pathomics data improve prediction of bone metastases in primary prostate cancer,"Abstract Purpose Bone metastasis is a significant contributor to morbidity and mortality in advanced prostate cancer, and early diagnosis is challenging due to its insidious onset. The use of machine learning to obtain prognostic information from pathological images has been highlighted. However, there is a limited understanding of the potential of early prediction of bone metastasis through the feature combination method from various sources. This study presents a method of integrating multimodal data to enhance the feasibility of early diagnosis of bone metastasis in prostate cancer. Methods and materials Overall, 211 patients diagnosed with prostate cancer (PCa) at Gansu Provincial Hospital between January 2017 and February 2023 were included in this study. The patients were randomized (8:2) into a training group ( n = 169) and a validation group ( n = 42). The region of interest (ROI) were segmented from the three magnetic resonance imaging (MRI) sequences (T2WI, DWI, and ADC), and pathological features were extracted from tissue sections (hematoxylin and eosin [H&amp;E] staining, 10 × 20). A deep learning (DL) model using ResNet 50 was employed to extract deep transfer learning (DTL) features. The least absolute shrinkage and selection operator (LASSO) regression method was utilized for feature selection, feature construction, and reducing feature dimensions. Different machine learning classifiers were used to build predictive models. The performance of the models was evaluated using receiver operating characteristic curves. The net clinical benefit was assessed using decision curve analysis (DCA). The goodness of fit was evaluated using calibration curves. A joint model nomogram was eventually developed by combining clinically independent risk factors. Results The best prediction models based on DTL and pathomics features showed area under the curve (AUC) values of 0.89 (95% confidence interval [CI], 0.799–0.989) and 0.85 (95% CI, 0.714–0.989), respectively. The AUC for the best prediction model based on radiomics features and combining radiomics features, DTL features, and pathomics features were 0.86 (95% CI, 0.735–0.979) and 0.93 (95% CI, 0.854–1.000), respectively. Based on DCA and calibration curves, the model demonstrated good net clinical benefit and fit. Conclusion Multimodal radiomics and pathomics serve as valuable predictors of the risk of bone metastases in patients with primary PCa.","['deep learning (DL) model using ResNet 50', 'deep transfer learning (DTL) features', 'least absolute shrinkage and selection operator (LASSO) regression method']"
2024,https://openalex.org/W4391814741,Medicine,Explainable hybrid vision transformers and convolutional network for multimodal glioma segmentation in brain MRI,"Abstract Accurate localization of gliomas, the most common malignant primary brain cancer, and its different sub-region from multimodal magnetic resonance imaging (MRI) volumes are highly important for interventional procedures. Recently, deep learning models have been applied widely to assist automatic lesion segmentation tasks for neurosurgical interventions. However, these models are often complex and represented as “black box” models which limit their applicability in clinical practice. This article introduces new hybrid vision Transformers and convolutional neural networks for accurate and robust glioma segmentation in Brain MRI scans. Our proposed method, TransXAI, provides surgeon-understandable heatmaps to make the neural networks transparent. TransXAI employs a post-hoc explanation technique that provides visual interpretation after the brain tumor localization is made without any network architecture modifications or accuracy tradeoffs. Our experimental findings showed that TransXAI achieves competitive performance in extracting both local and global contexts in addition to generating explainable saliency maps to help understand the prediction of the deep network. Further, visualization maps are obtained to realize the flow of information in the internal layers of the encoder-decoder network and understand the contribution of MRI modalities in the final prediction. The explainability process could provide medical professionals with additional information about the tumor segmentation results and therefore aid in understanding how the deep learning model is capable of processing MRI data successfully. Thus, it enables the physicians’ trust in such deep learning systems towards applying them clinically. To facilitate TransXAI model development and results reproducibility, we will share the source code and the pre-trained models after acceptance at https://github.com/razeineldin/TransXAI .","['vision Transformers', 'convolutional neural networks', 'post-hoc explanation technique', 'encoder-decoder network']"
2024,https://openalex.org/W4392391366,Medicine,Prediction of Effectiveness and Toxicities of Immune Checkpoint Inhibitors Using Real-World Patient Data,"PURPOSE Although immune checkpoint inhibitors (ICIs) have improved outcomes in certain patients with cancer, they can also cause life-threatening immunotoxicities. Predicting immunotoxicity risks alongside response could provide a personalized risk-benefit profile, inform therapeutic decision making, and improve clinical trial cohort selection. We aimed to build a machine learning (ML) framework using routine electronic health record (EHR) data to predict hepatitis, colitis, pneumonitis, and 1-year overall survival. METHODS Real-world EHR data of more than 2,200 patients treated with ICI through December 31, 2018, were used to develop predictive models. Using a prediction time point of ICI initiation, a 1-year prediction time window was applied to create binary labels for the four outcomes for each patient. Feature engineering involved aggregating laboratory measurements over appropriate time windows (60-365 days). Patients were randomly partitioned into training (80%) and test (20%) sets. Random forest classifiers were developed using a rigorous model development framework. RESULTS The patient cohort had a median age of 63 years and was 61.8% male. Patients predominantly had melanoma (37.8%), lung cancer (27.3%), or genitourinary cancer (16.4%). They were treated with PD-1 (60.4%), PD-L1 (9.0%), and CTLA-4 (19.7%) ICIs. Our models demonstrate reasonably strong performance, with AUCs of 0.739, 0.729, 0.755, and 0.752 for the pneumonitis, hepatitis, colitis, and 1-year overall survival models, respectively. Each model relies on an outcome-specific feature set, though some features are shared among models. CONCLUSION To our knowledge, this is the first ML solution that assesses individual ICI risk-benefit profiles based predominantly on routine structured EHR data. As such, use of our ML solution will not require additional data collection or documentation in the clinic.",['random forest classifiers']
2024,https://openalex.org/W4392694180,Medicine,NSGA-II-DL: Metaheuristic Optimal Feature Selection With Deep Learning Framework for HER2 Classification in Breast Cancer,"Immunohistochemistry (IHC) slides are graded for breast cancer based on visual markers and morphological characteristics of stained membrane regions. The usage of whole slide images (WSIs) from histology in digital pathology algorithms for computer-assisted evaluations has increased recently. Human epidermal growth factor receptor 2 (HER2)-stained microscopic images are challenging, time-consuming, and error-prone to evaluate manually. This is due to different staining, overlapped regions, and huge, non-homogeneous slides. Additionally, the classification of HER2 images by the selection of fundamental features must be used to capture the difficult elements of the images, such as the irregular cell structure and the coloring of the tissue of the cells. To solve the above problems, a transfer learning model-based, trainable metaheuristic method for choosing the best features is suggested in this paper. Moreover, the suggested model is efficient in reducing model complexity and computational costs as well as avoiding overfitting. The four main components of the proposed cascaded design are: (a) converting WSIs to tiled images and enhancing contrast with fast local Laplacian filtering (FlLpF); (b) extracting features with a ResNet50 CNN technique based on transfer learning; (c) selecting the most informative features with the help of a non-dominated sorting genetic algorithm (NSGA-II) optimizer; and (d) using a support vector machine (SVM) to classify HER2 scores. Results from the HER2SC and HER2GAN datasets show that the suggested model is superior to other methods already in use, with 94.4% accuracy, 93.71% precision, 98.07% specificity, 93.83% sensitivity, and a 93.71% F1-score for the HER2SC dataset being achieved.","['transfer learning', 'ResNet50 CNN', 'non-dominated sorting genetic algorithm (NSGA-II)', 'support vector machine (SVM)']"
2024,https://openalex.org/W4392926377,Medicine,Generalizability of machine learning in predicting antimicrobial resistance in E. coli: a multi-country case study in Africa,"Abstract Background Antimicrobial resistance (AMR) remains a significant global health threat particularly impacting low- and middle-income countries (LMICs). These regions often grapple with limited healthcare resources and access to advanced diagnostic tools. Consequently, there is a pressing need for innovative approaches that can enhance AMR surveillance and management. Machine learning (ML) though underutilized in these settings, presents a promising avenue. This study leverages ML models trained on whole-genome sequencing data from England, where such data is more readily available, to predict AMR in E . coli , targeting key antibiotics such as ciprofloxacin, ampicillin, and cefotaxime. A crucial part of our work involved the validation of these models using an independent dataset from Africa, specifically from Uganda, Nigeria, and Tanzania, to ascertain their applicability and effectiveness in LMICs. Results Model performance varied across antibiotics. The Support Vector Machine excelled in predicting ciprofloxacin resistance (87% accuracy, F1 Score: 0.57), Light Gradient Boosting Machine for cefotaxime (92% accuracy, F1 Score: 0.42), and Gradient Boosting for ampicillin (58% accuracy, F1 Score: 0.66). In validation with data from Africa, Logistic Regression showed high accuracy for ampicillin (94%, F1 Score: 0.97), while Random Forest and Light Gradient Boosting Machine were effective for ciprofloxacin (50% accuracy, F1 Score: 0.56) and cefotaxime (45% accuracy, F1 Score:0.54), respectively. Key mutations associated with AMR were identified for these antibiotics. Conclusion As the threat of AMR continues to rise, the successful application of these models, particularly on genomic datasets from LMICs, signals a promising avenue for improving AMR prediction to support large AMR surveillance programs. This work thus not only expands our current understanding of the genetic underpinnings of AMR but also provides a robust methodological framework that can guide future research and applications in the fight against AMR.","['Support Vector Machine', 'Light Gradient Boosting Machine', 'Gradient Boosting', 'Logistic Regression', 'Random Forest']"
2024,https://openalex.org/W4393260925,Medicine,Accurate and interpretable drug-drug interaction prediction enabled by knowledge subgraph learning,"Abstract Background Discovering potential drug-drug interactions (DDIs) is a long-standing challenge in clinical treatments and drug developments. Recently, deep learning techniques have been developed for DDI prediction. However, they generally require a huge number of samples, while known DDIs are rare. Methods In this work, we present KnowDDI, a graph neural network-based method that addresses the above challenge. KnowDDI enhances drug representations by adaptively leveraging rich neighborhood information from large biomedical knowledge graphs. Then, it learns a knowledge subgraph for each drug-pair to interpret the predicted DDI, where each of the edges is associated with a connection strength indicating the importance of a known DDI or resembling strength between a drug-pair whose connection is unknown. Thus, the lack of DDIs is implicitly compensated by the enriched drug representations and propagated drug similarities. Results Here we show the evaluation results of KnowDDI on two benchmark DDI datasets. Results show that KnowDDI obtains the state-of-the-art prediction performance with better interpretability. We also find that KnowDDI suffers less than existing works given a sparser knowledge graph. This indicates that the propagated drug similarities play a more important role in compensating for the lack of DDIs when the drug representations are less enriched. Conclusions KnowDDI nicely combines the efficiency of deep learning techniques and the rich prior knowledge in biomedical knowledge graphs. As an original open-source tool, KnowDDI can help detect possible interactions in a broad range of relevant interaction prediction tasks, such as protein-protein interactions, drug-target interactions and disease-gene interactions, eventually promoting the development of biomedicine and healthcare.",['graph neural network-based method']
2024,https://openalex.org/W4393276564,Medicine,Artificial intelligence–based assessment of built environment from Google Street View and coronary artery disease prevalence,"Abstract Background and Aims Built environment plays an important role in the development of cardiovascular disease. Tools to evaluate the built environment using machine vision and informatic approaches have been limited. This study aimed to investigate the association between machine vision–based built environment and prevalence of cardiometabolic disease in US cities. Methods This cross-sectional study used features extracted from Google Street View (GSV) images to measure the built environment and link them with prevalence of coronary heart disease (CHD). Convolutional neural networks, linear mixed-effects models, and activation maps were utilized to predict health outcomes and identify feature associations with CHD at the census tract level. The study obtained 0.53 million GSV images covering 789 census tracts in seven US cities (Cleveland, OH; Fremont, CA; Kansas City, MO; Detroit, MI; Bellevue, WA; Brownsville, TX; and Denver, CO). Results Built environment features extracted from GSV using deep learning predicted 63% of the census tract variation in CHD prevalence. The addition of GSV features improved a model that only included census tract-level age, sex, race, income, and education or composite indices of social determinant of health. Activation maps from the features revealed a set of neighbourhood features represented by buildings and roads associated with CHD prevalence. Conclusions In this cross-sectional study, the prevalence of CHD was associated with built environment factors derived from GSV through deep learning analysis, independent of census tract demographics. Machine vision–enabled assessment of the built environment could potentially offer a more precise approach to identify at-risk neighbourhoods, thereby providing an efficient avenue to address and reduce cardiovascular health disparities in urban environments.","['convolutional neural networks', 'activation maps']"
2024,https://openalex.org/W4394693547,Medicine,Urban morphology clustering analysis to identify heat-prone neighbourhoods in cities,"Exposure to heat is a major health concern to urban populations. Cities aim to reduce outdoor thermal stress by adapting the built environment, but the spatial heterogeneity within cities makes it difficult to establish universal mitigation strategies. We present a methodology that identifies the hottest neighbourhoods in a city and links them to underlying patterns in urban form and function, to derive heat mitigation measures for individual neighbourhoods according to their characteristics, mitigation potential, and average surface temperature. The method applies k-means clustering and is applicable to any city using available datasets on surface cover and building morphology, as well as globally available satellite measurements of surface temperatures. Here, we present a heat-mitigation analysis for the city of Zurich. The clustering differentiates seven neighbourhood types, including two types of residential areas, modern neighbourhoods with high-rise buildings, historical districts, and industrial zones. The hottest temperatures are in neighbourhoods with extensive impervious ground cover such as railway tracks and airport parking. Surface temperatures strongly correlate with impervious surface cover and vegetation cover for all neighbourhoods, with building cover only for non-industrial built neighbourhoods, and with sky-view factor for all neighbourhoods except those with large vegetation cover. Historical, modern, and industrial neighbourhoods are particular heat-prone, and increasing vegetation for evaporative cooling is a suggested mitigation strategy for all. Modern and industrial areas could benefit from shading through increase of tree cover, while historical centres may adapt vertical greening as suitable heat mitigation strategy.",['k-means clustering']
2024,https://openalex.org/W4394767609,Medicine,Cardiac Arrhythmia Classification Using Advanced Deep Learning Techniques on Digitized ECG Datasets,"ECG classification or heartbeat classification is an extremely valuable tool in cardiology. Deep learning-based techniques for the analysis of ECG signals assist human experts in the timely diagnosis of cardiac diseases and help save precious lives. This research aims at digitizing a dataset of images of ECG records into time series signals and then applying deep learning (DL) techniques on the digitized dataset. State-of-the-art DL techniques are proposed for the classification of the ECG signals into different cardiac classes. Multiple DL models, including a convolutional neural network (CNN), a long short-term memory (LSTM) network, and a self-supervised learning (SSL)-based model using autoencoders are explored and compared in this study. The models are trained on the dataset generated from ECG plots of patients from various healthcare institutes in Pakistan. First, the ECG images are digitized, segmenting the lead II heartbeats, and then the digitized signals are passed to the proposed deep learning models for classification. Among the different DL models used in this study, the proposed CNN model achieves the highest accuracy of ∼92%. The proposed model is highly accurate and provides fast inference for real-time and direct monitoring of ECG signals that are captured from the electrodes (sensors) placed on different parts of the body. Using the digitized form of ECG signals instead of images for the classification of cardiac arrhythmia allows cardiologists to utilize DL models directly on ECG signals from an ECG machine for the real-time and accurate monitoring of ECGs.","['convolutional neural network (CNN)', 'long short-term memory (LSTM) network', 'self-supervised learning (SSL)-based model using autoencoders']"
2024,https://openalex.org/W4400429759,Medicine,Deep learning for lungs cancer detection: a review,"Abstract Although lung cancer has been recognized to be the deadliest type of cancer, a good prognosis and efficient treatment depend on early detection. Medical practitioners’ burden is reduced by deep learning techniques, especially Deep Convolutional Neural Networks (DCNN), which are essential in automating the diagnosis and classification of diseases. In this study, we use a variety of medical imaging modalities, including X-rays, WSI, CT scans, and MRI, to thoroughly investigate the use of deep learning techniques in the field of lung cancer diagnosis and classification. This study conducts a comprehensive Systematic Literature Review (SLR) using deep learning techniques for lung cancer research, providing a comprehensive overview of the methodology, cutting-edge developments, quality assessments, and customized deep learning approaches. It presents data from reputable journals and concentrates on the years 2015–2024. Deep learning techniques solve the difficulty of manually identifying and selecting abstract features from lung cancer images. This study includes a wide range of deep learning methods for classifying lung cancer but focuses especially on the most popular method, the Convolutional Neural Network (CNN). CNN can achieve maximum accuracy because of its multi-layer structure, automatic learning of weights, and capacity to communicate local weights. Various algorithms are shown with performance measures like precision, accuracy, specificity, sensitivity, and AUC; CNN consistently shows the greatest accuracy. The findings highlight the important contributions of DCNN in improving lung cancer detection and classification, making them an invaluable resource for researchers looking to gain a greater knowledge of deep learning’s function in medical applications.","['Deep Convolutional Neural Networks (DCNN)', 'Convolutional Neural Network (CNN)']"
2024,https://openalex.org/W4390483004,Medicine,Population-Specific Glucose Prediction in Diabetes Care With Transformer-Based Deep Learning on the Edge,"Leveraging continuous glucose monitoring (CGM) systems, real-time blood glucose (BG) forecasting is essential for proactive interventions, playing a crucial role in enhancing the management of type 1 diabetes (T1D) and type 2 diabetes (T2D). However, developing a model generalized to a population and subsequently embedding it within a microchip of a wearable device presents significant technical challenges. Furthermore, the domain of BG prediction in T2D remains under-explored in the literature. In light of this, we propose a population-specific BG prediction model, leveraging the capabilities of the temporal fusion Transformer (TFT) to adjust predictions based on personal demographic data. Then the trained model is embedded within a system-on-chip, integral to our low-power and low-cost customized wearable device. This device seamlessly communicates with CGM systems through Bluetooth and provides timely BG predictions using edge computing. When evaluated on two publicly available clinical datasets with a total of 124 participants with T1D or T2D, the embedded TFT model consistently demonstrated superior performance, achieving the lowest prediction errors when compared with a range of machine learning baseline methods. Executing the TFT model on our wearable device requires minimal memory and power consumption, enabling continuous decision support for more than 51 days on a single Li-Poly battery charge. These findings demonstrate the significant potential of the proposed TFT model and wearable device in enhancing the quality of life for people with diabetes and effectively addressing real-world challenges.",['temporal fusion Transformer (TFT)']
2024,https://openalex.org/W4390506124,Medicine,Machine learning models for predicting preeclampsia: a systematic review,"Abstract Background This systematic review provides an overview of machine learning (ML) approaches for predicting preeclampsia. Method This review adhered to the Preferred Reporting Items for Systematic Reviews and Meta-Analyzes (PRISMA) guidelines. We searched the Cochrane Central Register, PubMed, EMBASE, ProQuest, Scopus, and Google Scholar up to February 2023. Search terms were limited to “preeclampsia” AND “artificial intelligence” OR “machine learning” OR “deep learning.” All studies that used ML-based analysis for predicting preeclampsia in pregnant women were considered. Non-English articles and those that are unrelated to the topic were excluded. The PROBAST was used to assess the risk of bias and applicability of each included study. Results The search strategy yielded 128 citations; after duplicates were removed and title and abstract screening was completed, 18 full-text articles were evaluated for eligibility. Four studies were included in this review. Two studies were at low risk of bias, and two had low to moderate risk. All of the study designs included were retrospective cohort studies. Nine distinct models were chosen as ML models from the four studies. Maternal characteristics, medical history, medication intake, obstetrical history, and laboratory and ultrasound findings obtained during prenatal care visits were candidate predictors to train the ML model. Elastic net, stochastic gradient boosting, extreme gradient boosting, and Random forest were among the best models to predict preeclampsia. All four studies used metrics such as the area under the curve, true positive rate, negative positive rate, accuracy, precision, recall, and F1 score. The AUC of ML models varied from 0.860 to 0.973 in four studies. Conclusion The results of studies yielded high prediction performance of ML models for preeclampsia risk from routine early pregnancy information.","['Elastic net', 'stochastic gradient boosting', 'extreme gradient boosting', 'Random forest']"
2024,https://openalex.org/W4390563519,Medicine,Association between dietary antioxidant intakes and chronic respiratory diseases in adults,"BackgroundChronic respiratory diseases (CRDs) pose a significant global health burden. Antioxidant-rich diets have been associated with improved lung health, but the specific relationship with CRDs remains unclear.MethodsThis study examined the relationship between dietary antioxidant intakes and CRDs using data from the 2001–2018 National Health and Nutrition Examination Survey (NHANES). Information on dietary antioxidant intakes, including vitamins A, C, and E, zinc, selenium, and carotenoid, were collected from the 2 24-h recall interviews to calculate composite dietary antioxidant index (CDAI). CRDs were determined based on self-reported physician diagnoses. To examine the relationship between CDAI and CRDs, multivariate logistic regression was used. To study potential non-linear correlations within these associations, restricted cubic spline (RCS) regression was performed.ResultsThe study involved 40 557 individuals. The median CDAI was −0.09 (−2.05, 2.25). We discovered those who were in the fourth quartile of CDAI scores had a 19% lower prevalence than those in the first quartile (OR = 0.81 [0.72–0.91], Ptrend < 0.01) after adjusting for all relevant covariates. The fourth quartile of CDAI was linked with a lower prevalence of emphysema (OR = 0.57 [0.40–0.81], Ptrend < 0.01) and chronic bronchitis (OR = 0.74 [0.62–0.88], Ptrend < 0.01). RCS regression showed that CDAI was non-linearly related to the prevalence of CRDs, with inflection points of 3.20 (P for non-linearity <0.01). The stratified analysis did not identify variables that significantly affected the results.ConclusionHigher dietary antioxidant intakes were related with a lower prevalence of CRDs (particularly emphysema and chronic bronchitis) in general adults.",['multivariate logistic regression']
2024,https://openalex.org/W4392915224,Medicine,"An Extensive Investigation into the Use of Machine Learning Tools and Deep Neural Networks for the Recognition of Skin Cancer: Challenges, Future Directions, and a Comprehensive Review","Skin cancer poses a serious risk to one’s health and can only be effectively treated with early detection. Early identification is critical since skin cancer has a higher fatality rate, and it expands gradually to different areas of the body. The rapid growth of automated diagnosis frameworks has led to the combination of diverse machine learning, deep learning, and computer vision algorithms for detecting clinical samples and atypical skin lesion specimens. Automated methods for recognizing skin cancer that use deep learning techniques are discussed in this article: convolutional neural networks, and, in general, artificial neural networks. The recognition of symmetries is a key point in dealing with the skin cancer image datasets; hence, in developing the appropriate architecture of neural networks, as it can improve the performance and release capacities of the network. The current study emphasizes the need for an automated method to identify skin lesions to reduce the amount of time and effort required for the diagnostic process, as well as the novel aspect of using algorithms based on deep learning for skin lesion detection. The analysis concludes with underlying research directions for the future, which will assist in better addressing the difficulties encountered in human skin cancer recognition. By highlighting the drawbacks and advantages of prior techniques, the authors hope to establish a standard for future analysis in the domain of human skin lesion diagnostics.","['convolutional neural networks', 'artificial neural networks']"
2024,https://openalex.org/W4395076002,Medicine,DenRAM: neuromorphic dendritic architecture with RRAM for efficient temporal processing with delays,"An increasing number of studies are highlighting the importance of spatial dendritic branching in pyramidal neurons in the neocortex for supporting non-linear computation through localized synaptic integration. In particular, dendritic branches play a key role in temporal signal processing and feature detection. This is accomplished thanks to coincidence detection (CD) mechanisms enabled by the presence of synaptic delays that align temporally disparate inputs for effective integration. Computational studies on spiking neural networks further highlight the significance of delays for achieving spatio-temporal pattern recognition with pure feed-forward neural networks, without the need of resorting to recurrent architectures. In this work, we present ""DenRAM"", the first realization of a feed-forward spiking neural network with dendritic compartments, implemented using analog electronic circuits integrated into a 130 nm technology node and coupled with Resistive Random Access Memory (RRAM) technology. DenRAM's dendritic circuits use RRAM devices to implement both delays and synaptic weights in the network. By configuring the RRAM devices to reproduce bio-realistic timescales, and by exploiting their heterogeneity we experimentally demonstrate DenRAM's ability to replicate synaptic delay profiles, and to efficiently implement CD for spatio-temporal pattern recognition. To validate the architecture, we conduct comprehensive system-level simulations on two representative temporal benchmarks, demonstrating DenRAM's resilience to analog hardware noise, and its superior accuracy compared to recurrent architectures with an equivalent number of parameters. DenRAM not only brings rich temporal processing capabilities to neuromorphic architectures, but also reduces the memory footprint of edge devices, warrants high accuracy on temporal benchmarks, and represents a significant step-forward in low-power real-time signal processing technologies.",['feed-forward spiking neural network']
2024,https://openalex.org/W4396622164,Medicine,Colon and lung cancer classification from multi-modal images using resilient and efficient neural network architectures,"Automatic classification of colon and lung cancer images is crucial for early detection and accurate diagnostics. However, there is room for improvement to enhance accuracy, ensuring better diagnostic precision. This study introduces two novel dense architectures (D1 and D2) and emphasizes their effectiveness in classifying colon and lung cancer from diverse images. It also highlights their resilience, efficiency, and superior performance across multiple datasets. These architectures were tested on various types of datasets, including NCT-CRC-HE-100K (set of 100,000 non-overlapping image patches from hematoxylin and eosin (H&E) stained histological images of human colorectal cancer (CRC) and normal tissue), CRC-VAL-HE-7K (set of 7180 image patches from N=50 patients with colorectal adenocarcinoma, no overlap with patients in NCT-CRC-HE-100K), LC25000 (Lung and Colon Cancer Histopathological Image), and IQ-OTHNCCD (Iraq-Oncology Teaching Hospital/National Center for Cancer Diseases), showcasing their effectiveness in classifying colon and lung cancers from histopathological and Computed Tomography (CT) scan images. This underscores the multi-modal image classification capability of the proposed models. Moreover, the study addresses imbalanced datasets, particularly in CRC-VAL-HE-7K and IQ-OTHNCCD, with a specific focus on model resilience and robustness. To assess overall performance, the study conducted experiments in different scenarios. The D1 model achieved an impressive 99.80% accuracy on the NCT-CRC-HE-100K dataset, with a Jaccard Index (J) of 0.8371, a Matthew's Correlation Coefficient (MCC) of 0.9073, a Cohen's Kappa (Kp) of 0.9057, and a Critical Success Index (CSI) of 0.8213. When subjected to 10-fold cross-validation on LC25000, the D1 model averaged (avg) 99.96% accuracy (avg J, MCC, Kp, and CSI of 0.9993, 0.9987, 0.9853, and 0.9990), surpassing recent reported performances. Furthermore, the ensemble of D1 and D2 reached 93% accuracy (J, MCC, Kp, and CSI of 0.7556, 0.8839, 0.8796, and 0.7140) on the IQ-OTHNCCD dataset, exceeding recent benchmarks and aligning with other reported results. Efficiency evaluations were conducted in various scenarios. For instance, training on only 10% of LC25000 resulted in high accuracy rates of 99.19% (J, MCC, Kp, and CSI of 0.9840, 0.9898, 0.9898, and 0.9837) (D1) and 99.30% (J, MCC, Kp, and CSI of 0.9863, 0.9913, 0.9913, and 0.9861) (D2). In NCT-CRC-HE-100K, D2 achieved an impressive 99.53% accuracy (J, MCC, Kp, and CSI of 0.9906, 0.9946, 0.9946, and 0.9906) with training on only 30% of the dataset and testing on the remaining 70%. When tested on CRC-VAL-HE-7K, D1 and D2 achieved 95% accuracy (J, MCC, Kp, and CSI of 0.8845, 0.9455, 0.9452, and 0.8745) and 96% accuracy (J, MCC, Kp, and CSI of 0.8926, 0.9504, 0.9503, and 0.8798), respectively, outperforming previously reported results and aligning closely with others. Lastly, training D2 on just 10% of NCT-CRC-HE-100K and testing on CRC-VAL-HE-7K resulted in significant outperformance of InceptionV3, Xception, and DenseNet201 benchmarks, achieving an accuracy rate of 82.98% (J, MCC, Kp, and CSI of 0.7227, 0.8095, 0.8081, and 0.6671). Finally, using explainable AI algorithms such as Grad-CAM, Grad-CAM++, Score-CAM, and Faster Score-CAM, along with their emphasized versions, we visualized the features from the last layer of DenseNet201 for histopathological as well as CT-scan image samples. The proposed dense models, with their multi-modality, robustness, and efficiency in cancer image classification, hold the promise of significant advancements in medical diagnostics. They have the potential to revolutionize early cancer detection and improve healthcare accessibility worldwide.","['InceptionV3', 'Xception', 'DenseNet201', 'Grad-CAM', 'Grad-CAM++', 'Score-CAM', 'Faster Score-CAM']"
2024,https://openalex.org/W4399322162,Medicine,Integration of deep learning and habitat radiomics for predicting the response to immunotherapy in NSCLC patients,"Abstract Background The non-invasive biomarkers for predicting immunotherapy response are urgently needed to prevent both premature cessation of treatment and ineffective extension. This study aimed to construct a non-invasive model for predicting immunotherapy response, based on the integration of deep learning and habitat radiomics in patients with advanced non-small cell lung cancer (NSCLC). Methods Independent patient cohorts from three medical centers were enrolled for training ( n = 164) and test ( n = 82). Habitat imaging radiomics features were derived from sub-regions clustered from individual’s tumor by K-means method. The deep learning features were extracted based on 3D ResNet algorithm. Pearson correlation coefficient, T test and least absolute shrinkage and selection operator regression were used to select features. Support vector machine was applied to implement deep learning and habitat radiomics, respectively. Then, a combination model was developed integrating both sources of data. Results The combination model obtained a strong well-performance, achieving area under receiver operating characteristics curve of 0.865 (95% CI 0.772–0.931). The model significantly discerned high and low-risk patients, and exhibited a significant benefit in the clinical use. Conclusion The integration of deep-leaning and habitat radiomics contributed to predicting response to immunotherapy in patients with NSCLC. The developed integration model may be used as potential tool for individual immunotherapy management.","['K-means', '3D ResNet algorithm', 'least absolute shrinkage and selection operator regression', 'Support vector machine']"
2024,https://openalex.org/W4399986067,Medicine,Comparing machine learning algorithms to predict vegetation fire detections in Pakistan,"Abstract Vegetation fires have major impacts on the ecosystem and present a significant threat to human life. Vegetation fires consists of forest fires, cropland fires, and other vegetation fires in this study. Currently, there is a limited amount of research on the long-term prediction of vegetation fires in Pakistan. The exact effect of every factor on the frequency of vegetation fires remains unclear when using standard analysis. This research utilized the high proficiency of machine learning algorithms to combine data from several sources, including the MODIS Global Fire Atlas dataset, topographic, climatic conditions, and different vegetation types acquired between 2001 and 2022. We tested many algorithms and ultimately chose four models for formal data processing. Their selection was based on their performance metrics, such as accuracy, computational efficiency, and preliminary test results. The model’s logistic regression, a random forest, a support vector machine, and an eXtreme Gradient Boosting were used to identify and select the nine key factors of forest and cropland fires and, in the case of other vegetation, seven key factors that cause a fire in Pakistan. The findings indicated that the vegetation fire prediction models achieved prediction accuracies ranging from 78.7 to 87.5% for forest fires, 70.4 to 84.0% for cropland fires, and 66.6 to 83.1% for other vegetation. Additionally, the area under the curve (AUC) values ranged from 83.6 to 93.4% in forest fires, 72.6 to 90.6% in cropland fires, and 74.2 to 90.7% in other vegetation. The random forest model had the highest accuracy rate of 87.5% in forest fires, 84.0% in cropland fires, and 83.1% in other vegetation and also the highest AUC value of 93.4% in forest fires, 90.6% in cropland fires, and 90.7% in other vegetation, proving to be the most optimal performance model. The models provided predictive insights into specific conditions and regional susceptibilities to fire occurrences, adding significant value beyond the initial MODIS detection data. The maps generated to analyze Pakistan’s vegetation fire risk showed the geographical distribution of areas with high, moderate, and low vegetation fire risks, highlighting predictive risk assessments rather than historical fire detections.","['logistic regression', 'random forest', 'support vector machine', 'eXtreme Gradient Boosting']"
2024,https://openalex.org/W4400335482,Medicine,Enhancing ECG-based heart age: impact of acquisition parameters and generalization strategies for varying signal morphologies and corruptions,"Electrocardiogram (ECG) is a non-invasive approach to capture the overall electrical activity produced by the contraction and relaxation of the cardiac muscles. It has been established in the literature that the difference between ECG-derived age and chronological age represents a general measure of cardiovascular health. Elevated ECG-derived age strongly correlates with cardiovascular conditions (e.g., atherosclerotic cardiovascular disease). However, the neural networks for ECG age estimation are yet to be thoroughly evaluated from the perspective of ECG acquisition parameters. Additionally, deep learning systems for ECG analysis encounter challenges in generalizing across diverse ECG morphologies in various ethnic groups and are susceptible to errors with signals that exhibit random or systematic distortions To address these challenges, we perform a comprehensive empirical study to determine the threshold for the sampling rate and duration of ECG signals while considering their impact on the computational cost of the neural networks. To tackle the concern of ECG waveform variability in different populations, we evaluate the feasibility of utilizing pre-trained and fine-tuned networks to estimate ECG age in different ethnic groups. Additionally, we empirically demonstrate that finetuning is an environmentally sustainable way to train neural networks, and it significantly decreases the ECG instances required (by more than <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML"" id=""IM1""><mml:mn>100</mml:mn><mml:mo>×</mml:mo></mml:math> ) for attaining performance similar to the networks trained from random weight initialization on a complete dataset. Finally, we systematically evaluate augmentation schemes for ECG signals in the context of age estimation and introduce a random cropping scheme that provides best-in-class performance while using shorter-duration ECG signals. The results also show that random cropping enables the networks to perform well with systematic and random ECG signal corruptions.","['neural networks', 'fine-tuned networks', 'finetuning']"
2024,https://openalex.org/W4400896445,Medicine,Recent deep learning-based brain tumor segmentation models using multi-modality magnetic resonance imaging: a prospective survey,"Radiologists encounter significant challenges when segmenting and determining brain tumors in patients because this information assists in treatment planning. The utilization of artificial intelligence (AI), especially deep learning (DL), has emerged as a useful tool in healthcare, aiding radiologists in their diagnostic processes. This empowers radiologists to understand the biology of tumors better and provide personalized care to patients with brain tumors. The segmentation of brain tumors using multi-modal magnetic resonance imaging (MRI) images has received considerable attention. In this survey, we first discuss multi-modal and available magnetic resonance imaging modalities and their properties. Subsequently, we discuss the most recent DL-based models for brain tumor segmentation using multi-modal MRI. We divide this section into three parts based on the architecture: the first is for models that use the backbone of convolutional neural networks (CNN), the second is for vision transformer-based models, and the third is for hybrid models that use both convolutional neural networks and transformer in the architecture. In addition, in-depth statistical analysis is performed of the recent publication, frequently used datasets, and evaluation metrics for segmentation tasks. Finally, open research challenges are identified and suggested promising future directions for brain tumor segmentation to improve diagnostic accuracy and treatment outcomes for patients with brain tumors. This aligns with public health goals to use health technologies for better healthcare delivery and population health management.","['deep learning (DL)', 'convolutional neural networks (CNN)', 'vision transformer-based models', 'hybrid models that use both convolutional neural networks and transformer']"
2024,https://openalex.org/W4403343918,Medicine,A comprehensive investigation of multimodal deep learning fusion strategies for breast cancer classification,"In breast cancer research, diverse data types and formats, such as radiological images, clinical records, histological data, and expression analysis, are employed. Given the intricate nature of natural phenomena, relying on the features of a single modality is seldom sufficient for comprehensive analysis. Therefore, it is possible to guarantee medical relevance and achieve improved clinical outcomes by combining several modalities. The presen study carefully maps and reviews 47 primary articles from six well-known digital libraries that were published between 2018 and 2023 for breast cancer classification based on multimodal deep learning fusion (MDLF) techniques. This systematic literature review encompasses various aspects, including the medical modalities combined, the datasets utilized in these studies, the techniques, models, and architectures used in MDLF and it also discusses the advantages and limitations of each approach. The analysis of selected papers has revealed a compelling trend: the emergence of new modalities and combinations that were previously unexplored in the context of breast cancer classification. This exploration has not only expanded the scope of predictive models but also introduced fresh perspectives for addressing diverse targets, ranging from screening to diagnosis and prognosis. The practical advantages of MDLF are evident in its ability to enhance the predictive capabilities of machine learning models, resulting in improved accuracy across diverse applications. The prevalence of deep learning models underscores their success in autonomously discerning complex patterns, offering a substantial departure from traditional machine learning approaches. Furthermore, the paper explores the challenges and future directions in this field, including the need for larger datasets, the use of ensemble learning methods, and the interpretation of multimodal models.",['ensemble learning methods']
2024,https://openalex.org/W4390662926,Medicine,Artificial intelligence performance in detecting lymphoma from medical imaging: a systematic review and meta-analysis,"Abstract Background Accurate diagnosis and early treatment are essential in the fight against lymphatic cancer. The application of artificial intelligence (AI) in the field of medical imaging shows great potential, but the diagnostic accuracy of lymphoma is unclear. This study was done to systematically review and meta-analyse researches concerning the diagnostic performance of AI in detecting lymphoma using medical imaging for the first time. Methods Searches were conducted in Medline, Embase, IEEE and Cochrane up to December 2023. Data extraction and assessment of the included study quality were independently conducted by two investigators. Studies that reported the diagnostic performance of an AI model/s for the early detection of lymphoma using medical imaging were included in the systemic review. We extracted the binary diagnostic accuracy data to obtain the outcomes of interest: sensitivity (SE), specificity (SP), and Area Under the Curve (AUC). The study was registered with the PROSPERO, CRD42022383386. Results Thirty studies were included in the systematic review, sixteen of which were meta-analyzed with a pooled sensitivity of 87% (95%CI 83–91%), specificity of 94% (92–96%), and AUC of 97% (95–98%). Satisfactory diagnostic performance was observed in subgroup analyses based on algorithms types (machine learning versus deep learning, and whether transfer learning was applied), sample size (≤ 200 or &gt; 200), clinicians versus AI models and geographical distribution of institutions (Asia versus non-Asia). Conclusions Even if possible overestimation and further studies with a better standards for application of AI algorithms in lymphoma detection are needed, we suggest the AI may be useful in lymphoma diagnosis.","['machine learning', 'deep learning', 'transfer learning']"
2024,https://openalex.org/W4390906064,Medicine,A critical moment in machine learning in medicine: on reproducible and interpretable learning,"Over the past two decades, advances in computational power and data availability combined with increased accessibility to pre-trained models have led to an exponential rise in machine learning (ML) publications. While ML may have the potential to transform healthcare, this sharp increase in ML research output without focus on methodological rigor and standard reporting guidelines has fueled a reproducibility crisis. In addition, the rapidly growing complexity of these models compromises their interpretability, which currently impedes their successful and widespread clinical adoption. In medicine, where failure of such models may have severe implications for patients' health, the high requirements for accuracy, robustness, and interpretability confront ML researchers with a unique set of challenges. In this review, we discuss the semantics of reproducibility and interpretability, as well as related issues and challenges, and outline possible solutions to counteracting the ""black box"". To foster reproducibility, standard reporting guidelines need to be further developed and data or code sharing encouraged. Editors and reviewers may equally play a critical role by establishing high methodological standards and thus preventing the dissemination of low-quality ML publications. To foster interpretable learning, the use of simpler models more suitable for medical data can inform the clinician how results are generated based on input data. Model-agnostic explanation tools, sensitivity analysis, and hidden layer representations constitute further promising approaches to increase interpretability. Balancing model performance and interpretability are important to ensure clinical applicability. We have now reached a critical moment for ML in medicine, where addressing these issues and implementing appropriate solutions will be vital for the future evolution of the field.",['model-agnostic explanation tools']
2024,https://openalex.org/W4391127198,Medicine,Risk predictions of surgical wound complications based on a machine learning algorithm: A systematic review,"Abstract Surgical wounds may arise due to harm inflicted upon soft tissue during surgical intervention, and many complications and injuries may accompany them. These complications can lead to prolonged hospitalization and poorer clinical outcomes. Also, Machine learning (ML) is a Section of artificial intelligence (AI) that has emerged in medical care and is increasingly used for diagnosis, complications, prognosis and recurrence prediction. This study aims to investigate surgical wound risk predictions and management using a ML algorithm by R programming language analysis. The systematic review, following PRISMA guidelines, spanned electronic databases using search terms like ‘machine learning’, ‘surgical’ and ‘wound’. Inclusion criteria covered experimental studies from 1990 to the present on ML's application in surgical wound evaluation. Exclusion criteria included studies lacking full text, focusing on ML in all surgeries, neglecting wound assessment and duplications. Two authors rigorously assessed titles, abstracts and full texts, excluding reviews and guidelines. Ultimately, relevant articles were then analysed. The present study identified nine articles employing ML for surgical wound management. The analysis encompassed various surgical procedures, including Cardiothoracic, Caesarean total abdominal colectomy, Burn plastic surgery, facial plastic surgery, laparotomy, minimal invasive surgery, hernia repair and unspecified surgeries. ML was skillful in evaluating surgical site infections (SSI) in seven studies, while two extended its use to burn‐grade diagnosis and wound classification. Support Vector Machine (SVM) and Convolutional Neural Network (CNN) were the most utilized algorithms. ANN achieved a 96% accuracy in facial plastic surgery wound management. CNN demonstrated commendable accuracies in various surgeries, and SVM exhibited high accuracy in multiple surgeries and burn plastic surgery. In sum, these findings underscore ML's potential for significant improvements in postoperative management and the development of enhanced care techniques, particularly in surgical wound management.","['Support Vector Machine (SVM)', 'Convolutional Neural Network (CNN)', 'Artificial Neural Network (ANN)']"
2024,https://openalex.org/W4391187635,Medicine,Prediction models for postoperative delirium in elderly patients with machine-learning algorithms and SHapley Additive exPlanations,"Abstract Postoperative delirium (POD) is a common and severe complication in elderly patients with hip fractures. Identifying high-risk patients with POD can help improve the outcome of patients with hip fractures. We conducted a retrospective study on elderly patients (≥65 years of age) who underwent orthopedic surgery with hip fracture between January 2014 and August 2019. Conventional logistic regression and five machine-learning algorithms were used to construct prediction models of POD. A nomogram for POD prediction was built with the logistic regression method. The area under the receiver operating characteristic curve (AUC-ROC), accuracy, sensitivity, and precision were calculated to evaluate different models. Feature importance of individuals was interpreted using Shapley Additive Explanations (SHAP). About 797 patients were enrolled in the study, with the incidence of POD at 9.28% (74/797). The age, renal insufficiency, chronic obstructive pulmonary disease (COPD), use of antipsychotics, lactate dehydrogenase (LDH), and C-reactive protein are used to build a nomogram for POD with an AUC of 0.71. The AUCs of five machine-learning models are 0.81 (Random Forest), 0.80 (GBM), 0.68 (AdaBoost), 0.77 (XGBoost), and 0.70 (SVM). The sensitivities of the six models range from 68.8% (logistic regression and SVM) to 91.9% (Random Forest). The precisions of the six machine-learning models range from 18.3% (logistic regression) to 67.8% (SVM). Six prediction models of POD in patients with hip fractures were constructed using logistic regression and five machine-learning algorithms. The application of machine-learning algorithms could provide convenient POD risk stratification to benefit elderly hip fracture patients.","['logistic regression', 'Random Forest', 'GBM', 'AdaBoost', 'XGBoost', 'SVM']"
2024,https://openalex.org/W4391277876,Medicine,Predicting mechanical properties of self-healing concrete with Trichoderma Reesei Fungus using machine learning,"Trichoderma Reesei is a mesophilic and filamentous fungus. It is an anamorph of the fungus Hypocrea jecorina, in addition, T. reesei can secrete large amounts of cellulolytic enzymes and form dextrose PDA (potato dextrose agar) and potato injection. After the preparation of fungi, it is added to the cracked samples. The experimental samples were 150 mm3 cubic compression and 70 mm x 30 mm x 15 mm cracks on the surface of each cube. Different fungi water extracts were used with 0, 50.5, 6.37, and 8.42 liters of water per ml. The results show that the addition of 8.42 (ml) of the mushroom extract with one liter of water has the maximum compressive strength with more than 18.99 MPa for 28 days, 16.7 for 14 days, and 14.5 for 7 days. In this study, linear regression, lasso regression, and rigid regression have been used to predict compressive strength, also the cooperation between mushroom juice per milliliter and compressive strength has been predicted. To find the accuracy, Correlation Coefficient (R2), Mean Absolute Errors (MAE), and Root Mean Square Error have been used. The results of machine learning show that the results of linear regression and rigid regression R2 were more than 0.98. In addition, the relationship compressive strength prediction results showed that R2 for fungi broth with one liter of water was 5.05 mL was more than 0.98. Finally, this study shows that the fungus Trichoderma reesei is an effective agent for curing concrete and improving the compressive strength of concrete.","['linear regression', 'lasso regression']"
2024,https://openalex.org/W4391670546,Medicine,Random forest regression for prediction of Covid-19 daily cases and deaths in Turkey,"During pandemic periods, there is an intense flow of patients to hospitals. Depending on the disease, many patients may require hospitalization. In some cases, these patients must be taken to intensive care units and emergency interventions must be performed. However, finding a sufficient number of hospital beds or intensive care units during pandemic periods poses a big problem. In these periods, fast and effective planning is more important than ever. Another problem experienced during pandemic periods is the burial of the dead in case the number of deaths increases. This is also a situation that requires due planning. We can learn some lessons from Covid 19 pandemic and be prepared for the future ones. In this paper, statistical properties of the daily cases and daily deaths in Turkey, which is one of the most affected countries by the pandemic in the World, are studied. It is found that the characteristics are nonstationary. Then, random forest regression is applied to predict Covid-19 daily cases and deaths. In addition, seven other machine learning models, namely bagging, AdaBoost, gradient boosting, XGBoost, decision tree, LSTM and ARIMA regressors are built for comparison. The performance of the models are measured using accuracy, coefficient of variation, root-mean-square score and relative error metrics. When random forest regressors are employed, test data related to daily cases are predicted with an accuracy of 92.30% and with an r2 score of 0.9893. Besides, daily deaths are predicted with an accuracy of 91.39% and with an r2 score of 0.9834. The closest rival in predictions is the bagging regressor. Nevertheless, the results provided by this algoritm changed in different runs and this fact is shown in the study, as well. Comparisons are based on test data. Comparisons with the earlier works are also provided.","['random forest regression', 'bagging', 'AdaBoost', 'gradient boosting', 'XGBoost', 'decision tree', 'LSTM']"
2024,https://openalex.org/W4392386754,Medicine,A Comparative Analysis of Machine Learning Algorithms for Breast Cancer Detection and Identification of Key Predictive Features,"Cancer, a disease with numerous subtypes, poses a deadly threat to human life, with the potential for successful clinical treatment heavily reliant on early detection and appropriate treatment planning.The classification of cancer patients into either low or high-risk subgroups is critical.Consequently, various research teams spanning the biomedical and bioinformatics fields have explored the use of Machine Learning (ML) technology in this crucial domain.The impressive capability of ML algorithms to discern significant features in complex datasets underscores their value.In the current study, we propose a framework to detect breast cancer (through benign and malignant categorization) utilizing advanced ML techniques with high accuracy.This framework deploys the Wisconsin Breast Cancer (Diagnostic) dataset.Five supervised ML techniques, namely Decision Tree, Random Forest (RF), Support Vector Machine (SVM), Extreme Gradient Boosting (XGBoost), and Artificial Neural Network (ANN), are trained for classification purposes.Out of 569 samples, 70% are allocated for training while the other 30% for testing.A comprehensive evaluation of ML techniques is performed using an array of metrics: precision, recall, specificity, F1 score, classification accuracy, ROC Curve, training time, and feature utilization.Additionally, feature importance is computed for each classifier.The results reveal that the SVM has the maximum accuracy as 97.66%, with an F1-score of 0.98 for benign and 0.97 for malignant classifications.Conversely, the decision tree registers the minimum performance (94.55%) with an F1-score of 0.95 for benign and 0.91 for malignant classes.Accuracy scores for RF, XGBoost, and ANN stand at 95.32%, 95.91%, and 97.07%, with corresponding F1-scores of 0.96, 0.97, and 0.98 for benign and 0.94, 0.95, and 0.96 for malignant respectively.Interestingly, RF and XGBoost exhibited near-equivalent similarly with respect of accuracy measurements.In the context of the area over the ROC curve, SVM outperformed the other ML classifiers and also reported the shortest training time.Conversely, the ANN reported the longest training time.","['Decision Tree', 'Random Forest (RF)', 'Support Vector Machine (SVM)', 'Extreme Gradient Boosting (XGBoost)', 'Artificial Neural Network (ANN)']"
2024,https://openalex.org/W4392471890,Medicine,An interpretable machine learning system for colorectal cancer diagnosis from pathology slides,"Abstract Considering the profound transformation affecting pathology practice, we aimed to develop a scalable artificial intelligence (AI) system to diagnose colorectal cancer from whole-slide images (WSI). For this, we propose a deep learning (DL) system that learns from weak labels, a sampling strategy that reduces the number of training samples by a factor of six without compromising performance, an approach to leverage a small subset of fully annotated samples, and a prototype with explainable predictions, active learning features and parallelisation. Noting some problems in the literature, this study is conducted with one of the largest WSI colorectal samples dataset with approximately 10,500 WSIs. Of these samples, 900 are testing samples. Furthermore, the robustness of the proposed method is assessed with two additional external datasets (TCGA and PAIP) and a dataset of samples collected directly from the proposed prototype. Our proposed method predicts, for the patch-based tiles, a class based on the severity of the dysplasia and uses that information to classify the whole slide. It is trained with an interpretable mixed-supervision scheme to leverage the domain knowledge introduced by pathologists through spatial annotations. The mixed-supervision scheme allowed for an intelligent sampling strategy effectively evaluated in several different scenarios without compromising the performance. On the internal dataset, the method shows an accuracy of 93.44% and a sensitivity between positive (low-grade and high-grade dysplasia) and non-neoplastic samples of 0.996. On the external test samples varied with TCGA being the most challenging dataset with an overall accuracy of 84.91% and a sensitivity of 0.996.",['deep learning (DL) system that learns from weak labels']
2024,https://openalex.org/W4392520481,Medicine,Predicting sepsis in-hospital mortality with machine learning: a multi-center study using clinical and inflammatory biomarkers,"Abstract Background This study aimed to develop and validate an interpretable machine-learning model that utilizes clinical features and inflammatory biomarkers to predict the risk of in-hospital mortality in critically ill patients suffering from sepsis. Methods We enrolled all patients diagnosed with sepsis in the Medical Information Mart for Intensive Care IV (MIMIC-IV, v.2.0), eICU Collaborative Research Care (eICU-CRD 2.0), and the Amsterdam University Medical Centers databases (AmsterdamUMCdb 1.0.2). LASSO regression was employed for feature selection. Seven machine-learning methods were applied to develop prognostic models. The optimal model was chosen based on its accuracy, F1 score and area under curve (AUC) in the validation cohort. Moreover, we utilized the SHapley Additive exPlanations (SHAP) method to elucidate the effects of the features attributed to the model and analyze how individual features affect the model’s output. Finally, Spearman correlation analysis examined the associations among continuous predictor variables. Restricted cubic splines (RCS) explored potential non-linear relationships between continuous risk factors and in-hospital mortality. Results 3535 patients with sepsis were eligible for participation in this study. The median age of the participants was 66 years (IQR, 55–77 years), and 56% were male. After selection, 12 of the 45 clinical parameters collected on the first day after ICU admission remained associated with prognosis and were used to develop machine-learning models. Among seven constructed models, the eXtreme Gradient Boosting (XGBoost) model achieved the best performance, with an AUC of 0.94 and an F1 score of 0.937 in the validation cohort. Feature importance analysis revealed that Age, AST, invasive ventilation treatment, and serum urea nitrogen (BUN) were the top four features of the XGBoost model with the most significant impact. Inflammatory biomarkers may have prognostic value. Furthermore, SHAP force analysis illustrated how the constructed model visualized the prediction of the model. Conclusions This study demonstrated the potential of machine-learning approaches for early prediction of outcomes in patients with sepsis. The SHAP method could improve the interoperability of machine-learning models and help clinicians better understand the reasoning behind the outcome.","['LASSO regression', 'eXtreme Gradient Boosting (XGBoost)', 'SHapley Additive exPlanations (SHAP)']"
2024,https://openalex.org/W4393137838,Medicine,Structural health monitoring on offshore jacket platforms using a novel ensemble deep learning model,"Monitoring health condition of offshore jacket platforms is crucial to prevent unexpected structural damages, where a prevailing challenge involves translating available feature information into structural damage patterns. Although the artificial neural network (ANN) models are popular in addressing this challenge, they often fail to capture the temporal correlations between the feature information and the damage patterns, which reduce their capability for discovering the laws governing the structural damage detection. To bridge this research gap, this study proposes a novel ensemble deep learning model to enhance the temporal feature extraction to improve the damage pattern identification. In this approach, a one-dimensional Convolutional Neural Network (CNN) extracts the spatiotemporal features from the structural vibration measurements. Simultaneously, a SENet attention mechanism is introduced to select the most informatic features. Subsequently, a bidirectional long short-term memory network (BiLSTM) is employed to learn the mapping between the extracted features and the structural damage patterns. Furthermore, the particle swarm optimization (PSO) algorithm is used to optimize the BiLSTM hyperparameters to enhance its stability and reliability. Both simulations and experiments are carried out to collect the vibration responses of the offshore jacket structure in different damage scenarios. The analysis results demonstrate that the proposed method produces remarkable improvement with respect to the accuracy and robustness in identifying the structural damages when compared with the ANNs. The overall detection accuracy of the proposed CNN-BiLSTM-Attention ensemble model is beyond 95%, which provides strong applicability to practical structural health monitoring of offshore platforms.","['artificial neural network (ANN)', 'ensemble deep learning model', 'one-dimensional Convolutional Neural Network (CNN)', 'SENet attention mechanism', 'bidirectional long short-term memory network (BiLSTM)', 'particle swarm optimization (PSO) algorithm']"
2024,https://openalex.org/W4393218816,Medicine,A study on smart home use intention of elderly consumers based on technology acceptance models,"Purpose Smart home devices have great potential to improve the quality of life and independence of older people, positively impacting their health, safety, and comfort. However, Chinese research in this field is still in its early stages. Therefore, more comprehensive and in-depth studies are needed to comprehend the various aspects influencing the acceptance and use of smart homes by older users. Patients and methods This study adopted the Technology Acceptance Model (TAM) and included perceived usefulness, perceived ease of use, usage intention, intergenerational technology support, perceived value, and perceived risk as extension variables to delve deeper into the behavioral intentions of older users in smart home services. The study used a convenience sampling method to randomly distribute 236 questionnaires among older adults over the age of 60 in the school’s community and neighboring urban communities who have experience in smart home use and who can complete human-computer interactions either independently or with the help of others, mainly focusing on the four sections: user characteristics, family situation, experience of use, and usage intention. The study used structural equation modeling (SEM) and factor analysis to analyze the completion of questionnaires. Finally, we conducted a validation analysis of the rationality and scientificity of the model and derived the six dimensions of the model of the influencing factors on the use of smart home products by the elderly and the weight sizes of their corresponding 13 influencing factors. Results The results show that perceived usefulness and perceived ease of use have a positive effect on users’ intention to use smart homes. Perceived ease of use has a positive effect on the perceived usefulness of smart homes. In addition, intergenerational technology support, perceived value, and perceived risk impact users’ perceived usefulness and perceived ease of use of the smart home. Conclusion This research aims to describe the factors influencing older users’ willingness to use smart homes. The findings are not only significant for the elderly in China but also of broad value to other regions and countries facing similar demographic challenges. The development of smart homes not only involves the elderly but is also closely related to all segments of society. The government should increase policy support and guide more social forces to participate in the development of the smart home industry. Service providers and designers should fully understand the demand situation and user experience of target users to develop easy-to-use smart home solutions. At the same time, smart homes, as intelligent products for the elderly, need to focus not only on the basic needs of the elderly such as material life and home safety, but also on the spiritual needs of elderly users. Children or caregivers should always pay attention to the psychological state of the elderly and actively guide them to use smart homes to help them realize their self-worth. We look forward to more research focusing on this area in the future and further exploring the specific issues and solutions involved.",['factor analysis']
2024,https://openalex.org/W4393281695,Medicine,An ensemble classification approach for cervical cancer prediction using behavioral risk factors,"Cervical cancer is a significant public health concern among females worldwide. Despite being preventable, it remains a leading cause of mortality. Early detection is crucial for successful treatment and improved survival rates. This study proposes an ensemble Machine Learning (ML) classifier for efficient and accurate identification of cervical cancer using medical data. The proposed methodology involves preparing two datasets using effective preprocessing techniques, extracting essential features using the scikit-learn package, and developing an ensemble classifier based on Random Forest, Support Vector Machine, Gaussian Naïve Bayes, and Decision Tree classifier traits. Comparison with other state-of-the-art algorithms using several ML techniques, including support vector machine, decision tree, random forest, Naïve Bayes, logistic regression, CatBoost, and AdaBoost, demonstrates that the proposed ensemble classifier outperforms them significantly, achieving accuracies of 98.06% and 95.45% for Dataset 1 and Dataset 2, respectively. The proposed ensemble classifier outperforms current state-of-the-art algorithms by 1.50% and 6.67% for Dataset 1 and Dataset 2, respectively, highlighting its superior performance compared to existing methods. The study also utilizes a five-fold cross-validation technique to analyze the benefits and drawbacks of the proposed methodology for predicting cervical cancer using medical data. The Receiver Operating Characteristic (ROC) curves with corresponding Area Under the Curve (AUC) values are 0.95 for Dataset 1 and 0.97 for Dataset 2, indicating the overall performance of the classifiers in distinguishing between the classes. Additionally, we employed SHapley Additive exPlanations (SHAP) as an Explainable Artificial Intelligence (XAI) technique to visualize the classifier's performance, providing insights into the important features contributing to cervical cancer identification. The results demonstrate that the proposed ensemble classifier can efficiently and accurately identify cervical cancer and potentially improve cervical cancer diagnosis and treatment.","['ensemble Machine Learning (ML) classifier', 'Random Forest', 'Support Vector Machine', 'Gaussian Naïve Bayes', 'Decision Tree classifier', 'support vector machine', 'decision tree', 'random forest', 'Naïve Bayes', 'logistic regression', 'CatBoost', 'AdaBoost', 'SHapley Additive exPlanations (SHAP)']"
2024,https://openalex.org/W4393864192,Medicine,Comprehensive evaluation and performance analysis of machine learning in heart disease prediction,"Heart disease is a leading cause of mortality on a global scale. Accurately predicting cardiovascular disease poses a significant challenge within clinical data analysis. The present study introduces a prediction model that utilizes various combinations of information and employs multiple established classification approaches. The proposed technique combines the genetic algorithm (GA) and the recursive feature elimination method (RFEM) to select relevant features, thus enhancing the model's robustness. Techniques like the under sampling clustering oversampling method (USCOM) address the issue of data imbalance, thereby improving the model's predictive capabilities. The classification challenge employs a multilayer deep convolutional neural network (MLDCNN), trained using the adaptive elephant herd optimization method (AEHOM). The proposed machine learning-based heart disease prediction method (ML-HDPM) demonstrates outstanding performance across various crucial evaluation parameters, as indicated by its comprehensive assessment. During the training process, the ML-HDPM model exhibits a high level of performance, achieving an accuracy rate of 95.5% and a precision rate of 94.8%. The system's sensitivity (recall) performs with a high accuracy rate of 96.2%, while the F-score highlights its well-balanced performance, measuring 91.5%. It is worth noting that the specificity of ML-HDPM is recorded at a remarkable 89.7%. The findings underscore the potential of ML-HDPM to transform the prediction of heart disease and aid healthcare practitioners in providing precise diagnoses, exerting a substantial influence on patient care outcomes.","['genetic algorithm (GA)', 'multilayer deep convolutional neural network (MLDCNN)']"
2024,https://openalex.org/W4396557972,Medicine,Enhancing breast cancer segmentation and classification: An Ensemble Deep Convolutional Neural Network and U-net approach on ultrasound images,"Breast cancer is a condition where the irregular growth of breast cells occurs uncontrollably, leading to the formation of tumors. It poses a significant threat to women's lives globally, emphasizing the need for enhanced methods of detecting and categorizing the disease. In this work, we propose an Ensemble Deep Convolutional Neural Network (EDCNN) model that exhibits superior accuracy compared to several transfer learning models and the Vision Transformer model. Our EDCNN model integrates the strengths of the MobileNet and Xception models to improve its performance in breast cancer detection and classification. We employ various preprocessing techniques, including image resizing, data normalization, and data augmentation, to prepare the data for analysis. By following these measures, the formatting is optimized, and the model's capacity to make generalizations is improved. We trained and evaluated our proposed EDCNN model using ultrasound images, a widely available modality for breast cancer imaging. The outcomes of our experiments illustrate that the EDCNN model attains an exceptional accuracy of 87.82% on Dataset 1 and 85.69% on Dataset 2, surpassing the performance of several well-known transfer learning models and the Vision Transformer model. Furthermore, an AUC value of 0.91 on Dataset 1 highlights the robustness and effectiveness of our proposed model. Moreover, we highlight the incorporation of the Grad-CAM Explainable Artificial Intelligence (XAI) technique to improve the interpretability and transparency of our proposed model. Additionally, we performed image segmentation using the U-Net segmentation technique on the input ultrasound images. This segmentation process allowed for the identification and isolation of specific regions of interest, facilitating a more comprehensive analysis of breast cancer characteristics. In conclusion, the study presents a creative approach to detecting and categorizing breast cancer, demonstrating the superior performance of the EDCNN model compared to well-established transfer learning models. Through advanced deep learning techniques and image segmentation, this study contributes to improving diagnosis and treatment outcomes in breast cancer.","['MobileNet', 'Xception', 'transfer learning models', 'Vision Transformer model', 'Grad-CAM Explainable Artificial Intelligence (XAI) technique', 'U-Net segmentation technique']"
2024,https://openalex.org/W4396894907,Medicine,Employing machine learning for enhanced abdominal fat prediction in cavitation post-treatment,"This study investigates the application of cavitation in non-invasive abdominal fat reduction and body contouring, a topic of considerable interest in the medical and aesthetic fields. We explore the potential of cavitation to alter abdominal fat composition and delve into the optimization of fat prediction models using advanced hyperparameter optimization techniques, Hyperopt and Optuna. Our objective is to enhance the predictive accuracy of abdominal fat dynamics post-cavitation treatment. Employing a robust dataset with abdominal fat measurements and cavitation treatment parameters, we evaluate the efficacy of our approach through regression analysis. The performance of Hyperopt and Optuna regression models is assessed using metrics such as mean squared error, mean absolute error, and R-squared score. Our results reveal that both models exhibit strong predictive capabilities, with R-squared scores reaching 94.12% and 94.11% for post-treatment visceral fat, and 71.15% and 70.48% for post-treatment subcutaneous fat predictions, respectively. Additionally, we investigate feature selection techniques to pinpoint critical predictors within the fat prediction models. Techniques including F-value selection, mutual information, recursive feature elimination with logistic regression and random forests, variance thresholding, and feature importance evaluation are utilized. The analysis identifies key features such as BMI, waist circumference, and pretreatment fat levels as significant predictors of post-treatment fat outcomes. Our findings underscore the effectiveness of hyperparameter optimization in refining fat prediction models and offer valuable insights for the advancement of non-invasive fat reduction methods. This research holds important implications for both the scientific community and clinical practitioners, paving the way for improved treatment strategies in the realm of body contouring.","['mutual information', 'recursive feature elimination with logistic regression', 'recursive feature elimination with random forests', 'variance thresholding']"
2024,https://openalex.org/W4397044870,Medicine,Advancements in Predictive Microbiology: Integrating New Technologies for Efficient Food Safety Models,"Predictive microbiology is a rapidly evolving field that has gained significant interest over the years due to its diverse application in food safety. Predictive models are widely used in food microbiology to estimate the growth of microorganisms in food products. These models represent the dynamic interactions between intrinsic and extrinsic food factors as mathematical equations and then apply these data to predict shelf life, spoilage, and microbial risk assessment. Due to their ability to predict the microbial risk, these tools are also integrated into hazard analysis critical control point (HACCP) protocols. However, like most new technologies, several limitations have been linked to their use. Predictive models have been found incapable of modeling the intricate microbial interactions in food colonized by different bacteria populations under dynamic environmental conditions. To address this issue, researchers are integrating several new technologies into predictive models to improve efficiency and accuracy. Increasingly, newer technologies such as whole genome sequencing (WGS), metagenomics, artificial intelligence, and machine learning are being rapidly adopted into newer-generation models. This has facilitated the development of devices based on robotics, the Internet of Things, and time-temperature indicators that are being incorporated into food processing both domestically and industrially globally. This study reviewed current research on predictive models, limitations, challenges, and newer technologies being integrated into developing more efficient models. Machine learning algorithms commonly employed in predictive modeling are discussed with emphasis on their application in research and industry and their advantages over traditional models.",['machine learning']
2024,https://openalex.org/W4399708678,Medicine,Detection of Parkinson disease using multiclass machine learning approach,"Parkinson's Disease (PD) is a prevalent neurological condition characterized by motor and cognitive impairments, typically manifesting around the age of 50 and presenting symptoms such as gait difficulties and speech impairments. Although a cure remains elusive, symptom management through medication is possible. Timely detection is pivotal for effective disease management. In this study, we leverage Machine Learning (ML) and Deep Learning (DL) techniques, specifically K-Nearest Neighbor (KNN) and Feed-forward Neural Network (FNN) models, to differentiate between individuals with PD and healthy individuals based on voice signal characteristics. Our dataset, sourced from the University of California at Irvine (UCI), comprises 195 voice recordings collected from 31 patients. To optimize model performance, we employ various strategies including Synthetic Minority Over-sampling Technique (SMOTE) for addressing class imbalance, Feature Selection to identify the most relevant features, and hyperparameter tuning using RandomizedSearchCV. Our experimentation reveals that the FNN and KSVM models, trained on an 80-20 split of the dataset for training and testing respectively, yield the most promising results. The FNN model achieves an impressive overall accuracy of 99.11%, with 98.78% recall, 99.96% precision, and a 99.23% f1-score. Similarly, the KSVM model demonstrates strong performance with an overall accuracy of 95.89%, recall of 96.88%, precision of 98.71%, and an f1-score of 97.62%. Overall, our study showcases the efficacy of ML and DL techniques in accurately identifying PD from voice signals, underscoring the potential for these approaches to contribute significantly to early diagnosis and intervention strategies for Parkinson's Disease.","['K-Nearest Neighbor (KNN)', 'Feed-forward Neural Network (FNN)', 'Feature Selection', 'RandomizedSearchCV', 'KSVM']"
2024,https://openalex.org/W4400528496,Medicine,Deep learning empowered breast cancer diagnosis: Advancements in detection and classification,"Recent advancements in AI, driven by big data technologies, have reshaped various industries, with a strong focus on data-driven approaches. This has resulted in remarkable progress in fields like computer vision, e-commerce, cybersecurity, and healthcare, primarily fueled by the integration of machine learning and deep learning models. Notably, the intersection of oncology and computer science has given rise to Computer-Aided Diagnosis (CAD) systems, offering vital tools to aid medical professionals in tumor detection, classification, recurrence tracking, and prognosis prediction. Breast cancer, a significant global health concern, is particularly prevalent in Asia due to diverse factors like lifestyle, genetics, environmental exposures, and healthcare accessibility. Early detection through mammography screening is critical, but the accuracy of mammograms can vary due to factors like breast composition and tumor characteristics, leading to potential misdiagnoses. To address this, an innovative CAD system leveraging deep learning and computer vision techniques was introduced. This system enhances breast cancer diagnosis by independently identifying and categorizing breast lesions, segmenting mass lesions, and classifying them based on pathology. Thorough validation using the Curated Breast Imaging Subset of Digital Database for Screening Mammography (CBIS-DDSM) demonstrated the CAD system’s exceptional performance, with a 99% success rate in detecting and classifying breast masses. While the accuracy of detection is 98.5%, when segmenting breast masses into separate groups for examination, the method’s performance was approximately 95.39%. Upon completing all the analysis, the system’s classification phase yielded an overall accuracy of 99.16% for classification. The potential for this integrated framework to outperform current deep learning techniques is proposed, despite potential challenges related to the high number of trainable parameters. Ultimately, this recommended framework offers valuable support to researchers and physicians in breast cancer diagnosis by harnessing cutting-edge AI and image processing technologies, extending recent advances in deep learning to the medical domain.",['deep learning']
2024,https://openalex.org/W4390817372,Medicine,Brain structure ages—A new biomarker for multi‐disease classification,"Age is an important variable to describe the expected brain's anatomy status across the normal aging trajectory. The deviation from that normative aging trajectory may provide some insights into neurological diseases. In neuroimaging, predicted brain age is widely used to analyze different diseases. However, using only the brain age gap information (i.e., the difference between the chronological age and the estimated age) can be not enough informative for disease classification problems. In this paper, we propose to extend the notion of global brain age by estimating brain structure ages using structural magnetic resonance imaging. To this end, an ensemble of deep learning models is first used to estimate a 3D aging map (i.e., voxel-wise age estimation). Then, a 3D segmentation mask is used to obtain the final brain structure ages. This biomarker can be used in several situations. First, it enables to accurately estimate the brain age for the purpose of anomaly detection at the population level. In this situation, our approach outperforms several state-of-the-art methods. Second, brain structure ages can be used to compute the deviation from the normal aging process of each brain structure. This feature can be used in a multi-disease classification task for an accurate differential diagnosis at the subject level. Finally, the brain structure age deviations of individuals can be visualized, providing some insights about brain abnormality and helping clinicians in real medical contexts.",['ensemble of deep learning models']
2024,https://openalex.org/W4391097175,Medicine,Toward Improving Breast Cancer Classification Using an Adaptive Voting Ensemble Learning Algorithm,"Over the past decade, breast cancer has been the most common type of cancer in women. Different methods were proposed for breast cancer detection. These methods mainly classify and categorize malignant and Benign tumors. Machine learning is a practical approach for breast cancer classification. Data mining and classification are effective methods to predict and categorize breast cancer. The optimum classification for detecting Breast Cancer (BC) is ensemble-based. The ensemble approach involves using multiple ways to find the best possible solution. This study used the Wisconsin Breast Cancer Diagnostic (WBCD) dataset. We created a voting ensemble classifier that combines four different machine learning models: Extra Trees Classifier (ETC), Light Gradient Boosting Machine (LightGBM), Ridge Classifier (RC), and Linear Discriminant Analysis (LDA). The proposed ELRL-E approach achieved an accuracy of 97.6%, a precision of 96.4%, a recall of 100%, and an F1 score of 98.1%. Various output evaluations are used to evaluate the performance and efficiency of the proposed model and other classifiers. Overall, the recommended strategy performed better. Results are directly compared with the individual classifier and different recognized state-of-the-art classifiers. The primary objective of this study is to identify the most influential ensemble machine learning classifier for breast cancer detection and diagnosis in terms of accuracy and AUC score.","['Machine learning', 'ensemble-based classification', 'voting ensemble classifier', 'Extra Trees Classifier (ETC)', 'Light Gradient Boosting Machine (LightGBM)', 'Ridge Classifier (RC)', 'Linear Discriminant Analysis (LDA)']"
2024,https://openalex.org/W4391324248,Medicine,"The Prediction of Clinical Mastitis in Dairy Cows Based on Milk Yield, Rumination Time, and Milk Electrical Conductivity Using Machine Learning Algorithms","In commercial dairy farms, mastitis is associated with increased antimicrobial use and associated resistance, which may affect milk production. This study aimed to develop sensor-based prediction models for naturally occurring clinical bovine mastitis using nine machine learning algorithms with data from 447 mastitic and 2146 healthy cows obtained from five commercial farms in Northeast China. The variables were related to daily activity, rumination time, and daily milk yield of cows, as well as milk electrical conductivity. Both Z-standardized and non-standardized datasets pertaining to four specific stages of lactation were used to train and test prediction models. For all four subgroups, the Z-standardized dataset yielded better results than those of the non-standardized one, with the multilayer artificial neural net algorithm showing the best performance. Variables of importance had a similar rank in this algorithm, indicating the consistency of these variables as predictors for bovine mastitis in commercial farms with similar automatic systems. Moreover, the peak milk yield (PMY) of mastitic cows was significantly higher than that of healthy cows (p &lt; 0.005), indicating that high-yielding cattle are more prone to mastitis. Our results show that machine learning algorithms are effective tools for predicting mastitis in dairy cows for immediate intervention and management in commercial farms.",['multilayer artificial neural net algorithm']
2024,https://openalex.org/W4391350390,Medicine,"Machine learning in physical activity, sedentary, and sleep behavior research","Abstract The nature of human movement and non-movement behaviors is complex and multifaceted, making their study complicated and challenging. Thanks to the availability of wearable activity monitors, we can now monitor the full spectrum of physical activity, sedentary, and sleep behaviors better than ever before—whether the subjects are elite athletes, children, adults, or individuals with pre-existing medical conditions. The increasing volume of generated data, combined with the inherent complexities of human movement and non-movement behaviors, necessitates the development of new data analysis methods for the research of physical activity, sedentary, and sleep behaviors. The characteristics of machine learning (ML) methods, including their ability to deal with complicated data, make them suitable for such analysis and thus can be an alternative tool to deal with data of this nature. ML can potentially be an excellent tool for solving many traditional problems related to the research of physical activity, sedentary, and sleep behaviors such as activity recognition, posture detection, profile analysis, and correlates research. However, despite this potential, ML has not yet been widely utilized for analyzing and studying these behaviors. In this review, we aim to introduce experts in physical activity, sedentary behavior, and sleep research—individuals who may possess limited familiarity with ML—to the potential applications of these techniques for analyzing their data. We begin by explaining the underlying principles of the ML modeling pipeline, highlighting the challenges and issues that need to be considered when applying ML. We then present the types of ML: supervised and unsupervised learning, and introduce a few ML algorithms frequently used in supervised and unsupervised learning. Finally, we highlight three research areas where ML methodologies have already been used in physical activity, sedentary behavior, and sleep behavior research, emphasizing their successes and challenges. This paper serves as a resource for ML in physical activity, sedentary, and sleep behavior research, offering guidance and resources to facilitate its utilization.","['machine learning (ML)', 'supervised learning', 'unsupervised learning']"
2024,https://openalex.org/W4391593760,Medicine,Enhanced Jaya Optimization Algorithm with Deep Learning Assisted Oral Cancer Diagnosis on IoT Healthcare Systems,"Recently, healthcare systems integrate the power of deep learning (DL) models with the connectivity and data processing capabilities of the Internet of Things (IoT) to enhance the early recognition and diagnosis of disease. Oral cancer diagnosis comprises the detection of cancerous or pre-cancerous abrasions in the oral cavity. Timely identification is essential for successful treatment and enhanced prognosis. Here is an overview of the key aspects of oral cancer diagnosis. One potential benefit of utilizing DL for oral cancer detection is that it analyses huge counts of data fast and accurately, and it could not need clear programming of the rules for recognizing abnormalities. This can create the procedure of detecting oral cancer more effective and efficient. Thus, the study presents an Enhanced Jaya Optimization Algorithm with Deep Learning Based Oral Cancer Classification (EJOADL-OCC) method. The presented EJOADL-OCC method aims to classify and detect the existence of oral cancer accurately and effectively. To accomplish this, the presented EJOADL-OCC method initially exploits median filtering for the noise elimination. Next, the feature vector generation process is performed by the residual network (ResNetv2) model with EJOA as a hyperparameter optimizer. For accurate classification of oral cancer, a continuously restricted Boltzmann machine with a deep belief network (CRBM-DBN) model. The simulated validation of the EJOADL-OCC algorithm is tested by the series of simulations and the outcome demonstrates its supremacy over present DL approaches.","['Deep Learning (DL)', 'Residual Network (ResNetv2)']"
2024,https://openalex.org/W4390506881,Medicine,Discovering biomarkers associated and predicting cardiovascular disease with high accuracy using a novel nexus of machine learning techniques for precision medicine,"Abstract Personalized interventions are deemed vital given the intricate characteristics, advancement, inherent genetic composition, and diversity of cardiovascular diseases (CVDs). The appropriate utilization of artificial intelligence (AI) and machine learning (ML) methodologies can yield novel understandings of CVDs, enabling improved personalized treatments through predictive analysis and deep phenotyping. In this study, we proposed and employed a novel approach combining traditional statistics and a nexus of cutting-edge AI/ML techniques to identify significant biomarkers for our predictive engine by analyzing the complete transcriptome of CVD patients. After robust gene expression data pre-processing, we utilized three statistical tests (Pearson correlation, Chi-square test, and ANOVA) to assess the differences in transcriptomic expression and clinical characteristics between healthy individuals and CVD patients. Next, the recursive feature elimination classifier assigned rankings to transcriptomic features based on their relation to the case–control variable. The top ten percent of commonly observed significant biomarkers were evaluated using four unique ML classifiers (Random Forest, Support Vector Machine, Xtreme Gradient Boosting Decision Trees, and k-Nearest Neighbors). After optimizing hyperparameters, the ensembled models, which were implemented using a soft voting classifier, accurately differentiated between patients and healthy individuals. We have uncovered 18 transcriptomic biomarkers that are highly significant in the CVD population that were used to predict disease with up to 96% accuracy. Additionally, we cross-validated our results with clinical records collected from patients in our cohort. The identified biomarkers served as potential indicators for early detection of CVDs. With its successful implementation, our newly developed predictive engine provides a valuable framework for identifying patients with CVDs based on their biomarker profiles.","['Random Forest', 'Support Vector Machine', 'Xtreme Gradient Boosting Decision Trees', 'k-Nearest Neighbors', 'soft voting classifier']"
2024,https://openalex.org/W4390919701,Medicine,Chatbots and Large Language Models in Radiology: A Practical Primer for Clinical and Research Applications,"Although chatbots have existed for decades, the emergence of transformer-based large language models (LLMs) has captivated the world through the most recent wave of artificial intelligence chatbots, including ChatGPT. Transformers are a type of neural network architecture that enables better contextual understanding of language and efficient training on massive amounts of unlabeled data, such as unstructured text from the internet. As LLMs have increased in size, their improved performance and emergent abilities have revolutionized natural language processing. Since language is integral to human thought, applications based on LLMs have transformative potential in many industries. In fact, LLM-based chatbots have demonstrated human-level performance on many professional benchmarks, including in radiology. LLMs offer numerous clinical and research applications in radiology, several of which have been explored in the literature with encouraging results. Multimodal LLMs can simultaneously interpret text and images to generate reports, closely mimicking current diagnostic pathways in radiology. Thus, from requisition to report, LLMs have the opportunity to positively impact nearly every step of the radiology journey. Yet, these impressive models are not without limitations. This article reviews the limitations of LLMs and mitigation strategies, as well as potential uses of LLMs, including multimodal models. Also reviewed are existing LLM-based applications that can enhance efficiency in supervised settings.","['transformer-based large language models (LLMs)', 'Transformers', 'Multimodal LLMs']"
2024,https://openalex.org/W4391292768,Medicine,Improving large language models for clinical named entity recognition via prompt engineering,"Abstract Importance The study highlights the potential of large language models, specifically GPT-3.5 and GPT-4, in processing complex clinical data and extracting meaningful information with minimal training data. By developing and refining prompt-based strategies, we can significantly enhance the models’ performance, making them viable tools for clinical NER tasks and possibly reducing the reliance on extensive annotated datasets. Objectives This study quantifies the capabilities of GPT-3.5 and GPT-4 for clinical named entity recognition (NER) tasks and proposes task-specific prompts to improve their performance. Materials and Methods We evaluated these models on 2 clinical NER tasks: (1) to extract medical problems, treatments, and tests from clinical notes in the MTSamples corpus, following the 2010 i2b2 concept extraction shared task, and (2) to identify nervous system disorder-related adverse events from safety reports in the vaccine adverse event reporting system (VAERS). To improve the GPT models' performance, we developed a clinical task-specific prompt framework that includes (1) baseline prompts with task description and format specification, (2) annotation guideline-based prompts, (3) error analysis-based instructions, and (4) annotated samples for few-shot learning. We assessed each prompt's effectiveness and compared the models to BioClinicalBERT. Results Using baseline prompts, GPT-3.5 and GPT-4 achieved relaxed F1 scores of 0.634, 0.804 for MTSamples and 0.301, 0.593 for VAERS. Additional prompt components consistently improved model performance. When all 4 components were used, GPT-3.5 and GPT-4 achieved relaxed F1 socres of 0.794, 0.861 for MTSamples and 0.676, 0.736 for VAERS, demonstrating the effectiveness of our prompt framework. Although these results trail BioClinicalBERT (F1 of 0.901 for the MTSamples dataset and 0.802 for the VAERS), it is very promising considering few training samples are needed. Discussion The study’s findings suggest a promising direction in leveraging LLMs for clinical NER tasks. However, while the performance of GPT models improved with task-specific prompts, there's a need for further development and refinement. LLMs like GPT-4 show potential in achieving close performance to state-of-the-art models like BioClinicalBERT, but they still require careful prompt engineering and understanding of task-specific knowledge. The study also underscores the importance of evaluation schemas that accurately reflect the capabilities and performance of LLMs in clinical settings. Conclusion While direct application of GPT models to clinical NER tasks falls short of optimal performance, our task-specific prompt framework, incorporating medical knowledge and training samples, significantly enhances GPT models' feasibility for potential clinical applications.","['GPT-3.5', 'GPT-4', 'prompt-based strategies', 'few-shot learning', 'BioClinicalBERT']"
2024,https://openalex.org/W4390940921,Medicine,Solving olympiad geometry without human demonstrations,"Abstract Proving mathematical theorems at the olympiad level represents a notable milestone in human-level automated reasoning 1–4 , owing to their reputed difficulty among the world’s best talents in pre-university mathematics. Current machine-learning approaches, however, are not applicable to most mathematical domains owing to the high cost of translating human proofs into machine-verifiable format. The problem is even worse for geometry because of its unique translation challenges 1,5 , resulting in severe scarcity of training data. We propose AlphaGeometry, a theorem prover for Euclidean plane geometry that sidesteps the need for human demonstrations by synthesizing millions of theorems and proofs across different levels of complexity. AlphaGeometry is a neuro-symbolic system that uses a neural language model, trained from scratch on our large-scale synthetic data, to guide a symbolic deduction engine through infinite branching points in challenging problems. On a test set of 30 latest olympiad-level problems, AlphaGeometry solves 25, outperforming the previous best method that only solves ten problems and approaching the performance of an average International Mathematical Olympiad (IMO) gold medallist. Notably, AlphaGeometry produces human-readable proofs, solves all geometry problems in the IMO 2000 and 2015 under human expert evaluation and discovers a generalized version of a translated IMO theorem in 2004.","['neural language model', 'neuro-symbolic system']"
2024,https://openalex.org/W4391577343,Medicine,The Image Biomarker Standardization Initiative: Standardized Convolutional Filters for Reproducible Radiomics and Enhanced Clinical Insights,"Filters are commonly used to enhance specific structures and patterns in images, such as vessels or peritumoral regions, to enable clinical insights beyond the visible image using radiomics. However, their lack of standardization restricts reproducibility and clinical translation of radiomics decision support tools. In this special report, teams of researchers who developed radiomics software participated in a three-phase study (September 2020 to December 2022) to establish a standardized set of filters. The first two phases focused on finding reference filtered images and reference feature values for commonly used convolutional filters: mean, Laplacian of Gaussian, Laws and Gabor kernels, separable and nonseparable wavelets (including decomposed forms), and Riesz transformations. In the first phase, 15 teams used digital phantoms to establish 33 reference filtered images of 36 filter configurations. In phase 2, 11 teams used a chest CT image to derive reference values for 323 of 396 features computed from filtered images using 22 filter and image processing configurations. Reference filtered images and feature values for Riesz transformations were not established. Reproducibility of standardized convolutional filters was validated on a public data set of multimodal imaging (CT, fluorodeoxyglucose PET, and T1-weighted MRI) in 51 patients with soft-tissue sarcoma. At validation, reproducibility of 486 features computed from filtered images using nine configurations × three imaging modalities was assessed using the lower bounds of 95% CIs of intraclass correlation coefficients. Out of 486 features, 458 were found to be reproducible across nine teams with lower bounds of 95% CIs of intraclass correlation coefficients greater than 0.75. In conclusion, eight filter types were standardized with reference filtered images and reference feature values for verifying and calibrating radiomics software packages. A web-based tool is available for compliance checking. © RSNA, 2024 Supplemental material is available for this article. See also the editorial by Huisman and D'Antonoli in this issue.",['nonseparable wavelets']
2024,https://openalex.org/W4392754729,Medicine,"Revolutionizing agriculture with artificial intelligence: plant disease detection methods, applications, and their limitations","Accurate and rapid plant disease detection is critical for enhancing long-term agricultural yield. Disease infection poses the most significant challenge in crop production, potentially leading to economic losses. Viruses, fungi, bacteria, and other infectious organisms can affect numerous plant parts, including roots, stems, and leaves. Traditional techniques for plant disease detection are time-consuming, require expertise, and are resource-intensive. Therefore, automated leaf disease diagnosis using artificial intelligence (AI) with Internet of Things (IoT) sensors methodologies are considered for the analysis and detection. This research examines four crop diseases: tomato, chilli, potato, and cucumber. It also highlights the most prevalent diseases and infections in these four types of vegetables, along with their symptoms. This review provides detailed predetermined steps to predict plant diseases using AI. Predetermined steps include image acquisition, preprocessing, segmentation, feature selection, and classification. Machine learning (ML) and deep understanding (DL) detection models are discussed. A comprehensive examination of various existing ML and DL-based studies to detect the disease of the following four crops is discussed, including the datasets used to evaluate these studies. We also provided the list of plant disease detection datasets. Finally, different ML and DL application problems are identified and discussed, along with future research prospects, by combining AI with IoT platforms like smart drones for field-based disease detection and monitoring. This work will help other practitioners in surveying different plant disease detection strategies and the limits of present systems.","['feature selection', 'machine learning (ML)', 'deep learning (DL)']"
2024,https://openalex.org/W4392791588,Medicine,Can large language models replace humans in systematic reviews? Evaluating <scp>GPT</scp>‐4's efficacy in screening and extracting data from peer‐reviewed and grey literature in multiple languages,"Systematic reviews are vital for guiding practice, research and policy, although they are often slow and labour-intensive. Large language models (LLMs) could speed up and automate systematic reviews, but their performance in such tasks has yet to be comprehensively evaluated against humans, and no study has tested Generative Pre-Trained Transformer (GPT)-4, the biggest LLM so far. This pre-registered study uses a ""human-out-of-the-loop"" approach to evaluate GPT-4's capability in title/abstract screening, full-text review and data extraction across various literature types and languages. Although GPT-4 had accuracy on par with human performance in some tasks, results were skewed by chance agreement and dataset imbalance. Adjusting for these caused performance scores to drop across all stages: for data extraction, performance was moderate, and for screening, it ranged from none in highly balanced literature datasets (~1:1) to moderate in those datasets where the ratio of inclusion to exclusion in studies was imbalanced (~1:3). When screening full-text literature using highly reliable prompts, GPT-4's performance was more robust, reaching ""human-like"" levels. Although our findings indicate that, currently, substantial caution should be exercised if LLMs are being used to conduct systematic reviews, they also offer preliminary evidence that, for certain review tasks delivered under specific conditions, LLMs can rival human performance.",['Generative Pre-Trained Transformer (GPT)-4']
2024,https://openalex.org/W4390496023,Medicine,Improved Support Vector Machine based on CNN-SVD for vision-threatening diabetic retinopathy detection and classification,"The integration of artificial intelligence (AI) in diagnosing diabetic retinopathy, a major contributor to global vision impairment, is becoming increasingly pronounced. Notably, the detection of vision-threatening diabetic retinopathy (VTDR) has been significantly fortified through automated techniques. Traditionally, the reliance on manual analysis of retinal images, albeit slow and error-prone, constituted the conventional approach. Addressing this, our study introduces a novel methodology that amplifies the robustness and precision of the detection process. This is complemented by the groundbreaking Hierarchical Block Attention (HBA) and HBA-U-Net architecture, which notably propel attention mechanisms in image segmentation. This innovative model refines image processing without imposing excessive computational demands by honing in on individual pixel intricacies, spatial relationships, and channel-specific attention. Building upon this innovation, our proposed method employs a multi-stage strategy encompassing data pre-processing, feature extraction via a hybrid CNN-SVD model, and classification employing an amalgamation of Improved Support Vector Machine-Radial Basis Function (ISVM-RBF), DT, and KNN techniques. Rigorously tested on the IDRiD dataset classified into five severity tiers, the hybrid model yields remarkable performance, achieving a 99.18% accuracy, 98.15% sensitivity, and 100% specificity in VTDR detection, thus surpassing existing methods. These results underscore a more potent avenue for diagnosing and addressing this crucial ocular condition while underscoring AI's transformative potential in medical care, particularly in ophthalmology.","['hybrid CNN-SVD model', 'DT', 'KNN']"
2024,https://openalex.org/W4399885365,Medicine,Convolutional neural network classification of cancer cytopathology images: taking breast cancer as an example,"Breast cancer is a relatively common cancer among gynecological cancers. Its diagnosis often relies on the pathology of cells in the lesion. The pathological diagnosis of breast cancer not only requires professionals and time, but also sometimes involves subjective judgment. To address the challenges of dependence on pathologists expertise and the time-consuming nature of achieving accurate breast pathological image classification, this paper introduces an approach utilizing convolutional neural networks (CNNs) for the rapid categorization of pathological images, aiming to enhance the efficiency of breast pathological image detection. And the approach enables the rapid and automatic classification of pathological images into benign and malignant groups. The methodology involves utilizing a convolutional neural network (CNN) model leveraging the Inceptionv3 architecture and transfer learning algorithm for extracting features from pathological images. Utilizing a neural network with fully connected layers and employing the SoftMax function for image classification. Additionally, the concept of image partitioning is introduced to handle high-resolution images. To achieve the ultimate classification outcome, the classification probabilities of each image block are aggregated using three algorithms: summation, product, and maximum. Experimental validation was conducted on the BreaKHis public dataset, resulting in accuracy rates surpassing 0.92 across all four magnification coefficients (40X, 100X, 200X, and 400X). It demonstrates that the proposed method effectively enhances the accuracy in classifying pathological images of breast cancer.","['convolutional neural networks (CNNs)', 'Inceptionv3 architecture', 'transfer learning algorithm', 'neural network with fully connected layers']"
2024,https://openalex.org/W4395050972,Medicine,Optimization of hepatological clinical guidelines interpretation by large language models: a retrieval augmented generation-based framework,"Abstract Large language models (LLMs) can potentially transform healthcare, particularly in providing the right information to the right provider at the right time in the hospital workflow. This study investigates the integration of LLMs into healthcare, specifically focusing on improving clinical decision support systems (CDSSs) through accurate interpretation of medical guidelines for chronic Hepatitis C Virus infection management. Utilizing OpenAI’s GPT-4 Turbo model, we developed a customized LLM framework that incorporates retrieval augmented generation (RAG) and prompt engineering. Our framework involved guideline conversion into the best-structured format that can be efficiently processed by LLMs to provide the most accurate output. An ablation study was conducted to evaluate the impact of different formatting and learning strategies on the LLM’s answer generation accuracy. The baseline GPT-4 Turbo model’s performance was compared against five experimental setups with increasing levels of complexity: inclusion of in-context guidelines, guideline reformatting, and implementation of few-shot learning. Our primary outcome was the qualitative assessment of accuracy based on expert review, while secondary outcomes included the quantitative measurement of similarity of LLM-generated responses to expert-provided answers using text-similarity scores. The results showed a significant improvement in accuracy from 43 to 99% ( p &lt; 0.001), when guidelines were provided as context in a coherent corpus of text and non-text sources were converted into text. In addition, few-shot learning did not seem to improve overall accuracy. The study highlights that structured guideline reformatting and advanced prompt engineering (data quality vs. data quantity) can enhance the efficacy of LLM integrations to CDSSs for guideline delivery.","['OpenAI’s GPT-4 Turbo model', 'retrieval augmented generation (RAG)', 'few-shot learning']"
2024,https://openalex.org/W4393247259,Medicine,Employing deep learning and transfer learning for accurate brain tumor detection,"Abstract Artificial intelligence-powered deep learning methods are being used to diagnose brain tumors with high accuracy, owing to their ability to process large amounts of data. Magnetic resonance imaging stands as the gold standard for brain tumor diagnosis using machine vision, surpassing computed tomography, ultrasound, and X-ray imaging in its effectiveness. Despite this, brain tumor diagnosis remains a challenging endeavour due to the intricate structure of the brain. This study delves into the potential of deep transfer learning architectures to elevate the accuracy of brain tumor diagnosis. Transfer learning is a machine learning technique that allows us to repurpose pre-trained models on new tasks. This can be particularly useful for medical imaging tasks, where labelled data is often scarce. Four distinct transfer learning architectures were assessed in this study: ResNet152, VGG19, DenseNet169, and MobileNetv3. The models were trained and validated on a dataset from benchmark database: Kaggle. Five-fold cross validation was adopted for training and testing. To enhance the balance of the dataset and improve the performance of the models, image enhancement techniques were applied to the data for the four categories: pituitary, normal, meningioma, and glioma. MobileNetv3 achieved the highest accuracy of 99.75%, significantly outperforming other existing methods. This demonstrates the potential of deep transfer learning architectures to revolutionize the field of brain tumor diagnosis.","['deep learning', 'deep transfer learning architectures', 'transfer learning', 'ResNet152', 'VGG19', 'DenseNet169', 'MobileNetv3']"
2024,https://openalex.org/W4390880481,Medicine,Liquid-metal-based three-dimensional microelectrode arrays integrated with implantable ultrathin retinal prosthesis for vision restoration,"Abstract Electronic retinal prostheses for stimulating retinal neurons are promising for vision restoration. However, the rigid electrodes of conventional retinal implants can inflict damage on the soft retina tissue. They also have limited selectivity due to their poor proximity to target cells in the degenerative retina. Here we present a soft artificial retina (thickness, 10 μm) where flexible ultrathin photosensitive transistors are integrated with three-dimensional stimulation electrodes of eutectic gallium–indium alloy. Platinum nanoclusters locally coated only on the tip of these three-dimensional liquid-metal electrodes show advantages in reducing the impedance of the stimulation electrodes. These microelectrodes can enhance the proximity to the target retinal ganglion cells and provide effective charge injections (72.84 mC cm −2 ) to elicit neural responses in the retina. Their low Young’s modulus (234 kPa), owing to their liquid form, can minimize damage to the retina. Furthermore, we used an unsupervised machine learning approach to effectively identify the evoked spikes to grade neural activities within the retinal ganglion cells. Results from in vivo experiments on a retinal degeneration mouse model reveal that the spatiotemporal distribution of neural responses on their retina can be mapped under selective localized illumination areas of light, suggesting the restoration of their vision.",['unsupervised machine learning']
2024,https://openalex.org/W4391103530,Medicine,Transformative Breast Cancer Diagnosis using CNNs with Optimized ReduceLROnPlateau and Early Stopping Enhancements,"Abstract Breast cancer stands as a paramount public health concern worldwide, underscoring an imperative necessity within the research sphere for precision-driven and efficacious methodologies facilitating accurate detection. The existing diagnostic approaches in breast cancer often suffer from limitations in accuracy and efficiency, leading to delayed detection and subsequent challenges in personalized treatment planning. The primary focus of this research is to overcome these shortcomings by harnessing the power of advanced deep learning techniques, thereby revolutionizing the precision and reliability of breast cancer classification. This research addresses the critical need for improved breast cancer diagnostics by introducing a novel Convolutional Neural Network (CNN) model integrated with an Early Stopping callback and ReduceLROnPlateau callback. By enhancing the precision and reliability of breast cancer classification, the study aims to overcome the limitations of existing diagnostic methods, ultimately leading to better patient outcomes and reduced mortality rates. The comprehensive methodology includes diverse datasets, meticulous image preprocessing, robust model training, and validation strategies, emphasizing the model's adaptability and reliability in varied clinical contexts. The findings showcase the CNN model's exceptional performance, achieving a 95.2% accuracy rate in distinguishing cancerous and non-cancerous breast tissue in the integrated dataset, thereby demonstrating its potential for enhancing clinical decision-making and fostering the development of AI-driven diagnostic solutions.","['Convolutional Neural Network (CNN)', 'Early Stopping callback']"
2024,https://openalex.org/W4391177783,Medicine,"Making food systems more resilient to food safety risks by including artificial intelligence, big data, and internet of things into food safety early warning and emerging risk identification tools","Abstract To enhance the resilience of food systems to food safety risks, it is vitally important for national authorities and international organizations to be able to identify emerging food safety risks and to provide early warning signals in a timely manner. This review provides an overview of existing and experimental applications of artificial intelligence (AI), big data, and internet of things as part of early warning and emerging risk identification tools and methods in the food safety domain. There is an ongoing rapid development of systems fed by numerous, real‐time, and diverse data with the aim of early warning and identification of emerging food safety risks. The suitability of big data and AI to support such systems is illustrated by two cases in which climate change drives the emergence of risks, namely, harmful algal blooms affecting seafood and fungal growth and mycotoxin formation in crops. Automation and machine learning are crucial for the development of future real‐time food safety risk early warning systems. Although these developments increase the feasibility and effectiveness of prospective early warning and emerging risk identification tools, their implementation may prove challenging, particularly for low‐ and middle‐income countries due to low connectivity and data availability. It is advocated to overcome these challenges by improving the capability and capacity of national authorities, as well as by enhancing their collaboration with the private sector and international organizations.",['machine learning']
2024,https://openalex.org/W4402780379,Medicine,Investigating Spatial Effects through Machine Learning and Leveraging Explainable AI for Child Malnutrition in Pakistan,"While socioeconomic gradients in regional health inequalities are firmly established, the synergistic interactions between socioeconomic deprivation and climate vulnerability within convenient proximity and neighbourhood locations with health disparities remain poorly explored and thus require deep understanding within a regional context. Furthermore, disregarding the importance of spatial spillover effects and nonlinear effects of covariates on childhood stunting are inevitable in dealing with an enduring issue of regional health inequalities. The present study aims to investigate the spatial inequalities in childhood stunting at the district level in Pakistan and validate the importance of spatial lag in predicting childhood stunting. Furthermore, it examines the presence of any nonlinear relationships among the selected independent features with childhood stunting. The study utilized data related to socioeconomic features from MICS 2017–2018 and climatic data from Integrated Contextual Analysis. A multi-model approach was employed to address the research questions, which included Ordinary Least Squares Regression (OLS), various Spatial Models, Machine Learning Algorithms and Explainable Artificial Intelligence methods. Firstly, OLS was used to analyse and test the linear relationships among selected variables. Secondly, Spatial Durbin Error Model (SDEM) was used to detect and capture the impact of spatial spillover on childhood stunting. Third, XGBoost and Random Forest machine learning algorithms were employed to examine and validate the importance of the spatial lag component. Finally, EXAI methods such as SHapley were utilized to identify potential nonlinear relationships. The study found a clear pattern of spatial clustering and geographical disparities in childhood stunting, with multidimensional poverty, high climate vulnerability and early marriage worsening childhood stunting. In contrast, low climate vulnerability, high exposure to mass media and high women’s literacy were found to reduce childhood stunting. The use of machine learning algorithms, specifically XGBoost and Random Forest, highlighted the significant role played by the average value in the neighbourhood in predicting childhood stunting in nearby districts, confirming that the spatial spillover effect is not bounded by geographical boundaries. Furthermore, EXAI methods such as partial dependency plot reveal the existence of a nonlinear relationship between multidimensional poverty and childhood stunting. The study’s findings provide valuable insights into the spatial distribution of childhood stunting in Pakistan, emphasizing the importance of considering spatial effects in predicting childhood stunting. Individual and household-level factors such as exposure to mass media and women’s literacy have shown positive implications for childhood stunting. It further provides a justification for the usage of EXAI methods to draw better insights and propose customised intervention policies accordingly.","['XGBoost', 'Random Forest', 'partial dependency plot']"
2024,https://openalex.org/W4391376295,Medicine,"Detection of a facemask in real-time using deep learning methods:
  Prevention of Covid 19","A health crisis is raging all over the world with the rapid transmission of the novel-coronavirus disease (Covid-19). Out of the guidelines issued by the World Health Organisation (WHO) to protect us against Covid-19, wearing a facemask is the most effective. Many countries have necessitated the wearing of face masks, but monitoring a large number of people to ensure that they are wearing masks in a crowded place is a challenging task in itself. The novel-coronavirus disease (Covid-19) has already affected our day-to-day life as well as world trade movements. By the end of April 2021, the world has recorded 144,358,956 confirmed cases of novel-coronavirus disease (Covid-19) including 3,066,113 deaths according to the world health organization (WHO). These increasing numbers motivate automated techniques for the detection of a facemask in real-time scenarios for the prevention of Covid-19. We propose a technique using deep learning that works for single and multiple people in a frame recorded via webcam in still or in motion. We have also experimented with our approach in night light. The accuracy of our model is good compared to the other approaches in the literature; ranging from 74% for multiple people in a nightlight to 99% for a single person in daylight.",['deep learning']
2024,https://openalex.org/W4393119757,Medicine,Unmasking bias in artificial intelligence: a systematic review of bias detection and mitigation strategies in electronic health record-based models,"Abstract Objectives Leveraging artificial intelligence (AI) in conjunction with electronic health records (EHRs) holds transformative potential to improve healthcare. However, addressing bias in AI, which risks worsening healthcare disparities, cannot be overlooked. This study reviews methods to handle various biases in AI models developed using EHR data. Materials and Methods We conducted a systematic review following the Preferred Reporting Items for Systematic Reviews and Meta-analyses guidelines, analyzing articles from PubMed, Web of Science, and IEEE published between January 01, 2010 and December 17, 2023. The review identified key biases, outlined strategies for detecting and mitigating bias throughout the AI model development, and analyzed metrics for bias assessment. Results Of the 450 articles retrieved, 20 met our criteria, revealing 6 major bias types: algorithmic, confounding, implicit, measurement, selection, and temporal. The AI models were primarily developed for predictive tasks, yet none have been deployed in real-world healthcare settings. Five studies concentrated on the detection of implicit and algorithmic biases employing fairness metrics like statistical parity, equal opportunity, and predictive equity. Fifteen studies proposed strategies for mitigating biases, especially targeting implicit and selection biases. These strategies, evaluated through both performance and fairness metrics, predominantly involved data collection and preprocessing techniques like resampling and reweighting. Discussion This review highlights evolving strategies to mitigate bias in EHR-based AI models, emphasizing the urgent need for both standardized and detailed reporting of the methodologies and systematic real-world testing and evaluation. Such measures are essential for gauging models’ practical impact and fostering ethical AI that ensures fairness and equity in healthcare.","['resampling', 'reweighting']"
2024,https://openalex.org/W4393941607,Medicine,Large language models as assistance for glaucoma surgical cases: a ChatGPT vs. Google Gemini comparison,"Abstract Purpose The aim of this study was to define the capability of ChatGPT-4 and Google Gemini in analyzing detailed glaucoma case descriptions and suggesting an accurate surgical plan. Methods Retrospective analysis of 60 medical records of surgical glaucoma was divided into “ordinary” ( n = 40) and “challenging” ( n = 20) scenarios. Case descriptions were entered into ChatGPT and Bard’s interfaces with the question “What kind of surgery would you perform?” and repeated three times to analyze the answers’ consistency. After collecting the answers, we assessed the level of agreement with the unified opinion of three glaucoma surgeons. Moreover, we graded the quality of the responses with scores from 1 (poor quality) to 5 (excellent quality), according to the Global Quality Score (GQS) and compared the results. Results ChatGPT surgical choice was consistent with those of glaucoma specialists in 35/60 cases (58%), compared to 19/60 (32%) of Gemini ( p = 0.0001). Gemini was not able to complete the task in 16 cases (27%). Trabeculectomy was the most frequent choice for both chatbots (53% and 50% for ChatGPT and Gemini, respectively). In “challenging” cases, ChatGPT agreed with specialists in 9/20 choices (45%), outperforming Google Gemini performances (4/20, 20%). Overall, GQS scores were 3.5 ± 1.2 and 2.1 ± 1.5 for ChatGPT and Gemini ( p = 0.002). This difference was even more marked if focusing only on “challenging” cases (1.5 ± 1.4 vs. 3.0 ± 1.5, p = 0.001). Conclusion ChatGPT-4 showed a good analysis performance for glaucoma surgical cases, either ordinary or challenging. On the other side, Google Gemini showed strong limitations in this setting, presenting high rates of unprecise or missed answers.",['Google Gemini']
2024,https://openalex.org/W4391235397,Medicine,Real-Time Plant Disease Dataset Development and Detection of Plant Disease Using Deep Learning,"Agriculture plays a significant role in meeting food needs and providing food security for the increasingly growing global population, which has increased by 0.88% since 2022. Plant diseases can reduce food production and affect food security. Worldwide crop loss due to plant disease is estimated to be around 14.1%. The lack of proper identification of plant disease at the early stages of infection can result in inappropriate disease control measures. Therefore, the automatic identification and diagnosis of plant diseases are highly recommended. Lack of availability of large amounts of data that are not processed to a large extent is one of the main challenges in plant disease diagnosis. In the current manuscript, we developed datasets for food grains specifically for rice, wheat, and maize to address the identified challenges. The developed datasets consider the common diseases (two bacterial diseases and two fungal diseases of rice, four fungal diseases of maize, and four fungal diseases of wheat) that affect crop yields and cause damage to the whole plant. The datasets developed were applied to eight fine-tuned deep learning models with the same training hyperparameters. The experimental results based on eight fine-tuned deep learning models show that, while recognizing maize leaf diseases, the models Xception and MobileNet performed best with a testing accuracy of 0.9580 and 0.9464 respectively. Similarly, while recognizing the wheat leaf diseases, the models MobileNetV2 and MobileNet performed best with a testing accuracy of 0.9632 and 0.9628 respectively. The Xception and Inception V3 models performed best, with a testing accuracy of 0.9728 and 0.9620, respectively, for recognizing rice leaf diseases. The research also proposes a new convolutional neural network (CNN) model trained from scratch on all three food grain datasets developed. The proposed model performs well and shows a testing accuracy of 0.9704, 0.9706, and 0.9808 respectively on the maize, rice, and wheat datasets.","['fine-tuned deep learning models', 'Xception', 'MobileNet', 'MobileNetV2', 'Inception V3', 'convolutional neural network (CNN) model trained from scratch']"
2024,https://openalex.org/W4396494945,Medicine,Vision–language foundation model for echocardiogram interpretation,"Abstract The development of robust artificial intelligence models for echocardiography has been limited by the availability of annotated clinical data. Here, to address this challenge and improve the performance of cardiac imaging models, we developed EchoCLIP, a vision–language foundation model for echocardiography, that learns the relationship between cardiac ultrasound images and the interpretations of expert cardiologists across a wide range of patients and indications for imaging. After training on 1,032,975 cardiac ultrasound videos and corresponding expert text, EchoCLIP performs well on a diverse range of benchmarks for cardiac image interpretation, despite not having been explicitly trained for individual interpretation tasks. EchoCLIP can assess cardiac function (mean absolute error of 7.1% when predicting left ventricular ejection fraction in an external validation dataset) and identify implanted intracardiac devices (area under the curve (AUC) of 0.84, 0.92 and 0.97 for pacemakers, percutaneous mitral valve repair and artificial aortic valves, respectively). We also developed a long-context variant (EchoCLIP-R) using a custom tokenizer based on common echocardiography concepts. EchoCLIP-R accurately identified unique patients across multiple videos (AUC of 0.86), identified clinical transitions such as heart transplants (AUC of 0.79) and cardiac surgery (AUC 0.77) and enabled robust image-to-text search (mean cross-modal retrieval rank in the top 1% of candidate text reports). These capabilities represent a substantial step toward understanding and applying foundation models in cardiovascular imaging for preliminary interpretation of echocardiographic findings.",['vision–language foundation model']
2024,https://openalex.org/W4391320803,Medicine,Oral squamous cell carcinoma detection using EfficientNet on histopathological images,"Introduction Oral Squamous Cell Carcinoma (OSCC) poses a significant challenge in oncology due to the absence of precise diagnostic tools, leading to delays in identifying the condition. Current diagnostic methods for OSCC have limitations in accuracy and efficiency, highlighting the need for more reliable approaches. This study aims to explore the discriminative potential of histopathological images of oral epithelium and OSCC. By utilizing a database containing 1224 images from 230 patients, captured at varying magnifications and publicly available, a customized deep learning model based on EfficientNetB3 was developed. The model’s objective was to differentiate between normal epithelium and OSCC tissues by employing advanced techniques such as data augmentation, regularization, and optimization. Methods The research utilized a histopathological imaging database for Oral Cancer analysis, incorporating 1224 images from 230 patients. These images, taken at various magnifications, formed the basis for training a specialized deep learning model built upon the EfficientNetB3 architecture. The model underwent training to distinguish between normal epithelium and OSCC tissues, employing sophisticated methodologies including data augmentation, regularization techniques, and optimization strategies. Results The customized deep learning model achieved significant success, showcasing a remarkable 99% accuracy when tested on the dataset. This high accuracy underscores the model’s efficacy in effectively discerning between normal epithelium and OSCC tissues. Furthermore, the model exhibited impressive precision, recall, and F1-score metrics, reinforcing its potential as a robust diagnostic tool for OSCC. Discussion This research demonstrates the promising potential of employing deep learning models to address the diagnostic challenges associated with OSCC. The model’s ability to achieve a 99% accuracy rate on the test dataset signifies a considerable leap forward in earlier and more accurate detection of OSCC. Leveraging advanced techniques in machine learning, such as data augmentation and optimization, has shown promising results in improving patient outcomes through timely and precise identification of OSCC.",['deep learning model based on EfficientNetB3']
2024,https://openalex.org/W4400993192,Medicine,Damage identification of steel bridge based on data augmentation and adaptive optimization neural network,"With the advancement of deep learning, data-driven structural damage identification (SDI) has shown considerable development. However, collecting vibration signals related to structural damage poses certain challenges, which can undermine the accuracy of the identification results produced by data-driven SDI methods in scenarios where data is scarce. This paper introduces an innovative approach to bridge SDI in a few-shot context by integrating an adaptive simulated annealing particle swarm optimization-convolutional neural network (ASAPSO-CNN) as the foundational framework, augmented by data enhancement techniques. Firstly, three specific types of noise are introduced to augment the source signals used for training. Subsequently, the source signals and augmented signals are recombined to construct a four-dimensional matrix as the input to the CNN, while defining the damage feature vector as the output. Secondly, a CNN is constructed to establish the mapping relationship between the input and output. Then, an adaptive fitness function is proposed that simultaneously considers the accuracy of SDI, model complexity, and training efficiency. The ASAPSO is employed to adaptively optimize the hyperparameters of the CNN. The proposed method is validated on an experimental model of a three-span continuous beam. It is compared with four other data-driven methods, demonstrating good effectiveness and robustness of SDI under cases of scarce data. Finally, the effectiveness of this SDI method is validated in a real-world case of a steel truss bridge.",['convolutional neural network (CNN)']
2024,https://openalex.org/W4390588437,Medicine,Enhancing heart disease prediction using a self-attention-based transformer model,"Abstract Cardiovascular diseases (CVDs) continue to be the leading cause of more than 17 million mortalities worldwide. The early detection of heart failure with high accuracy is crucial for clinical trials and therapy. Patients will be categorized into various types of heart disease based on characteristics like blood pressure, cholesterol levels, heart rate, and other characteristics. With the use of an automatic system, we can provide early diagnoses for those who are prone to heart failure by analyzing their characteristics. In this work, we deploy a novel self-attention-based transformer model, that combines self-attention mechanisms and transformer networks to predict CVD risk. The self-attention layers capture contextual information and generate representations that effectively model complex patterns in the data. Self-attention mechanisms provide interpretability by giving each component of the input sequence a certain amount of attention weight. This includes adjusting the input and output layers, incorporating more layers, and modifying the attention processes to collect relevant information. This also makes it possible for physicians to comprehend which features of the data contributed to the model's predictions. The proposed model is tested on the Cleveland dataset, a benchmark dataset of the University of California Irvine (UCI) machine learning (ML) repository. Comparing the proposed model to several baseline approaches, we achieved the highest accuracy of 96.51%. Furthermore, the outcomes of our experiments demonstrate that the prediction rate of our model is higher than that of other cutting-edge approaches used for heart disease prediction.","['self-attention-based transformer model', 'self-attention mechanisms', 'transformer networks']"
2024,https://openalex.org/W4393353042,Medicine,SNC_Net: Skin Cancer Detection by Integrating Handcrafted and Deep Learning-Based Features Using Dermoscopy Images,"The medical sciences are facing a major problem with the auto-detection of disease due to the fast growth in population density. Intelligent systems assist medical professionals in early disease detection and also help to provide consistent treatment that reduces the mortality rate. Skin cancer is considered to be the deadliest and most severe kind of cancer. Medical professionals utilize dermoscopy images to make a manual diagnosis of skin cancer. This method is labor-intensive and time-consuming and demands a considerable level of expertise. Automated detection methods are necessary for the early detection of skin cancer. The occurrence of hair and air bubbles in dermoscopic images affects the diagnosis of skin cancer. This research aims to classify eight different types of skin cancer, namely actinic keratosis (AKs), dermatofibroma (DFa), melanoma (MELa), basal cell carcinoma (BCCa), squamous cell carcinoma (SCCa), melanocytic nevus (MNi), vascular lesion (VASn), and benign keratosis (BKs). In this study, we propose SNC_Net, which integrates features derived from dermoscopic images through deep learning (DL) models and handcrafted (HC) feature extraction methods with the aim of improving the performance of the classifier. A convolutional neural network (CNN) is employed for classification. Dermoscopy images from the publicly accessible ISIC 2019 dataset for skin cancer detection is utilized to train and validate the model. The performance of the proposed model is compared with four baseline models, namely EfficientNetB0 (B1), MobileNetV2 (B2), DenseNet-121 (B3), and ResNet-101 (B4), and six state-of-the-art (SOTA) classifiers. With an accuracy of 97.81%, a precision of 98.31%, a recall of 97.89%, and an F1 score of 98.10%, the proposed model outperformed the SOTA classifiers as well as the four baseline models. Moreover, an Ablation study is also performed on the proposed method to validate its performance. The proposed method therefore assists dermatologists and other medical professionals in early skin cancer detection.","['deep learning (DL) models', 'convolutional neural network (CNN)', 'EfficientNetB0', 'MobileNetV2', 'DenseNet-121', 'ResNet-101']"
2024,https://openalex.org/W4400937555,Medicine,The diagnostic and triage accuracy of the GPT-3 artificial intelligence model: an observational study,"BackgroundArtificial intelligence (AI) applications in health care have been effective in many areas of medicine, but they are often trained for a single task using labelled data, making deployment and generalisability challenging. How well a general-purpose AI language model performs diagnosis and triage relative to physicians and laypeople is not well understood.MethodsWe compared the predictive accuracy of Generative Pre-trained Transformer 3 (GPT-3)'s diagnostic and triage ability for 48 validated synthetic case vignettes (<50 words; sixth-grade reading level or below) of both common (eg, viral illness) and severe (eg, heart attack) conditions to a nationally representative sample of 5000 lay people from the USA who could use the internet to find the correct options and 21 practising physicians at Harvard Medical School. There were 12 vignettes for each of four triage categories: emergent, within one day, within 1 week, and self-care. The correct diagnosis and triage category (ie, ground truth) for each vignette was determined by two general internists at Harvard Medical School. For each vignette, human respondents and GPT-3 were prompted to list diagnoses in order of likelihood, and the vignette was marked as correct if the ground-truth diagnosis was in the top three of the listed diagnoses. For triage accuracy, we examined whether the human respondents' and GPT-3's selected triage was exactly correct according to the four triage categories, or matched a dichotomised triage variable (emergent or within 1 day vs within 1 week or self-care). We estimated GPT-3's diagnostic and triage confidence on a given vignette using a modified bootstrap resampling procedure, and examined how well calibrated GPT-3's confidence was by computing calibration curves and Brier scores. We also performed subgroup analysis by case acuity, and an error analysis for triage advice to characterise how its advice might affect patients using this tool to decide if they should seek medical care immediately.FindingsAmong all cases, GPT-3 replied with the correct diagnosis in its top three for 88% (42/48, 95% CI 75–94) of cases, compared with 54% (2700/5000, 53–55) for lay individuals (p<0.0001) and 96% (637/666, 94–97) for physicians (p=0·012). GPT-3 triaged 70% correct (34/48, 57–82) versus 74% (3706/5000, 73–75; p=0.60) for lay individuals and 91% (608/666, 89–93%; p<0.0001) for physicians. As measured by the Brier score, GPT-3 confidence in its top prediction was reasonably well calibrated for diagnosis (Brier score=0·18) and triage (Brier score=0·22). We observed an inverse relationship between case acuity and GPT-3 accuracy (p<0·0001) with a fitted trend line of –8·33% decrease in accuracy for every level of increase in case acuity. For triage error analysis, GPT-3 deprioritised truly emergent cases in seven instances.InterpretationA general-purpose AI language model without any content-specific training could perform diagnosis at levels close to, but below, physicians and better than lay individuals. We found that GPT-3's performance was inferior to physicians for triage, sometimes by a large margin, and its performance was closer to that of lay individuals. Although the diagnostic performance of GPT-3 was comparable to physicians, it was significantly better than a typical person using a search engine.FundingThe National Heart, Lung, and Blood Institute.",['Generative Pre-trained Transformer 3 (GPT-3)']
2024,https://openalex.org/W4392285688,Medicine,Machine Learning and Digital Biomarkers Can Detect Early Stages of Neurodegenerative Diseases,"Neurodegenerative diseases (NDs) such as Alzheimer’s Disease (AD) and Parkinson’s Disease (PD) are devastating conditions that can develop without noticeable symptoms, causing irreversible damage to neurons before any signs become clinically evident. NDs are a major cause of disability and mortality worldwide. Currently, there are no cures or treatments to halt their progression. Therefore, the development of early detection methods is urgently needed to delay neuronal loss as soon as possible. Despite advancements in Medtech, the early diagnosis of NDs remains a challenge at the intersection of medical, IT, and regulatory fields. Thus, this review explores “digital biomarkers” (tools designed for remote neurocognitive data collection and AI analysis) as a potential solution. The review summarizes that recent studies combining AI with digital biomarkers suggest the possibility of identifying pre-symptomatic indicators of NDs. For instance, research utilizing convolutional neural networks for eye tracking has achieved significant diagnostic accuracies. ROC-AUC scores reached up to 0.88, indicating high model performance in differentiating between PD patients and healthy controls. Similarly, advancements in facial expression analysis through tools have demonstrated significant potential in detecting emotional changes in ND patients, with some models reaching an accuracy of 0.89 and a precision of 0.85. This review follows a structured approach to article selection, starting with a comprehensive database search and culminating in a rigorous quality assessment and meaning for NDs of the different methods. The process is visualized in 10 tables with 54 parameters describing different approaches and their consequences for understanding various mechanisms in ND changes. However, these methods also face challenges related to data accuracy and privacy concerns. To address these issues, this review proposes strategies that emphasize the need for rigorous validation and rapid integration into clinical practice. Such integration could transform ND diagnostics, making early detection tools more cost-effective and globally accessible. In conclusion, this review underscores the urgent need to incorporate validated digital health tools into mainstream medical practice. This integration could indicate a new era in the early diagnosis of neurodegenerative diseases, potentially altering the trajectory of these conditions for millions worldwide. Thus, by highlighting specific and statistically significant findings, this review demonstrates the current progress in this field and the potential impact of these advancements on the global management of NDs.",['convolutional neural networks']
2024,https://openalex.org/W4390607226,Medicine,RanMerFormer: Randomized vision transformer with token merging for brain tumor classification,"Brains are the control center of the nervous system in human bodies, and brain tumor is one of the most deadly diseases. Currently, magnetic resonance imaging (MRI) is the most effective way to brain tumors early detection in clinical diagnoses due to its superior imaging quality for soft tissues. Manual analysis of brain MRI is error-prone which depends on empirical experience and the fatigue state of the radiologists to a large extent. Computer-aided diagnosis (CAD) systems are becoming more and more impactful because they can provide accurate prediction results based on medical images with advanced techniques from computer vision. Therefore, a novel CAD method for brain tumor classification named RanMerFormer is presented in this paper. A pre-trained vision transformer is used as the backbone model. Then, a merging mechanism is proposed to remove the redundant tokens in the vision transformer, which improves computing efficiency substantially. Finally, a randomized vector functional-link serves as the head in the proposed RanMerFormer, which can be trained swiftly. All the simulation results are obtained from two public benchmark datasets, which reveal that the proposed RanMerFormer can achieve state-of-the-art performance for brain tumor classification. The trained RanMerFormer can be applied in real-world scenarios to assist in brain tumor diagnosis.","['pre-trained vision transformer', 'randomized vector functional-link']"
2024,https://openalex.org/W4391023920,Medicine,A hybrid deep CNN model for brain tumor image multi-classification,"Abstract The current approach to diagnosing and classifying brain tumors relies on the histological evaluation of biopsy samples, which is invasive, time-consuming, and susceptible to manual errors. These limitations underscore the pressing need for a fully automated, deep-learning-based multi-classification system for brain malignancies. This article aims to leverage a deep convolutional neural network (CNN) to enhance early detection and presents three distinct CNN models designed for different types of classification tasks. The first CNN model achieves an impressive detection accuracy of 99.53% for brain tumors. The second CNN model, with an accuracy of 93.81%, proficiently categorizes brain tumors into five distinct types: normal, glioma, meningioma, pituitary, and metastatic. Furthermore, the third CNN model demonstrates an accuracy of 98.56% in accurately classifying brain tumors into their different grades. To ensure optimal performance, a grid search optimization approach is employed to automatically fine-tune all the relevant hyperparameters of the CNN models. The utilization of large, publicly accessible clinical datasets results in robust and reliable classification outcomes. This article conducts a comprehensive comparison of the proposed models against classical models, such as AlexNet, DenseNet121, ResNet-101, VGG-19, and GoogleNet, reaffirming the superiority of the deep CNN-based approach in advancing the field of brain tumor classification and early detection.","['deep convolutional neural network (CNN)', 'AlexNet', 'DenseNet121', 'ResNet-101', 'VGG-19', 'GoogleNet']"
2024,https://openalex.org/W4391341367,Medicine,Automated Tool Support for Glaucoma Identification With Explainability Using Fundus Images,"Glaucoma is a progressive eye condition that causes irreversible vision loss due to damage to the optic nerve. Recent developments in deep learning and the accessibility of computing resources have provided tool support for automated glaucoma diagnosis. Despite deep learning's advances in disease diagnosis using medical images, generic convolutional neural networks are still not widely used in medical practices due to the limited trustworthiness of these models. Although deep learning-based glaucoma classification has gained popularity in recent years, only a few of them have addressed the explainability and interpretability of the models, which increases confidence in using such applications. This study presents state-of-the-art deep learning techniques to segment and classify fundus images to predict glaucoma conditions and applies visualization techniques to explain the results to ease understandability. Our predictions are based on U-Net with attention mechanisms with ResNet50 for the segmentation process and a modified Inception V3 architecture for the classification. Attention U-Net with modified ResNet50 backbone obtained 99.58% and 98.05% accuracies for optic disc segmentation and optic cup segmentation, respectively for the RIM-ONE dataset. Additionally, we generate heatmaps that highlight the regions that impacted the glaucoma diagnosis using both Gradient-weighted Class Activation Mapping (Grad-CAM) and Grad-CAM++. Our model that classifies the segmented images achieves accuracy, sensitivity, and specificity values of 98.97%, 99.42%, and 95.59%, respectively, with the RIM-ONE dataset. This model can be used as a support tool for automated glaucoma identification using fundus images.","['U-Net with attention mechanisms', 'ResNet50', 'modified Inception V3 architecture', 'Attention U-Net with modified ResNet50 backbone', 'Gradient-weighted Class Activation Mapping (Grad-CAM)', 'Grad-CAM++']"
2024,https://openalex.org/W4391610180,Medicine,"Generative artificial intelligence in drug discovery: basic framework, recent advances, challenges, and opportunities","There are two main ways to discover or design small drug molecules. The first involves fine-tuning existing molecules or commercially successful drugs through quantitative structure-activity relationships and virtual screening. The second approach involves generating new molecules through de novo drug design or inverse quantitative structure-activity relationship. Both methods aim to get a drug molecule with the best pharmacokinetic and pharmacodynamic profiles. However, bringing a new drug to market is an expensive and time-consuming endeavor, with the average cost being estimated at around $2.5 billion. One of the biggest challenges is screening the vast number of potential drug candidates to find one that is both safe and effective. The development of artificial intelligence in recent years has been phenomenal, ushering in a revolution in many fields. The field of pharmaceutical sciences has also significantly benefited from multiple applications of artificial intelligence, especially drug discovery projects. Artificial intelligence models are finding use in molecular property prediction, molecule generation, virtual screening, synthesis planning, repurposing, among others. Lately, generative artificial intelligence has gained popularity across domains for its ability to generate entirely new data, such as images, sentences, audios, videos, novel chemical molecules, etc. Generative artificial intelligence has also delivered promising results in drug discovery and development. This review article delves into the fundamentals and framework of various generative artificial intelligence models in the context of drug discovery via de novo drug design approach. Various basic and advanced models have been discussed, along with their recent applications. The review also explores recent examples and advances in the generative artificial intelligence approach, as well as the challenges and ongoing efforts to fully harness the potential of generative artificial intelligence in generating novel drug molecules in a faster and more affordable manner. Some clinical-level assets generated form generative artificial intelligence have also been discussed in this review to show the ever-increasing application of artificial intelligence in drug discovery through commercial partnerships.","['inverse quantitative structure-activity relationship', 'generative artificial intelligence models']"
2024,https://openalex.org/W4392703844,Medicine,Collaborative Enhancement of Consistency and Accuracy in US Diagnosis of Thyroid Nodules Using Large Language Models,"Background Large language models (LLMs) hold substantial promise for medical imaging interpretation. However, there is a lack of studies on their feasibility in handling reasoning questions associated with medical diagnosis. Purpose To investigate the viability of leveraging three publicly available LLMs to enhance consistency and diagnostic accuracy in medical imaging based on standardized reporting, with pathology as the reference standard. Materials and Methods US images of thyroid nodules with pathologic results were retrospectively collected from a tertiary referral hospital between July 2022 and December 2022 and used to evaluate malignancy diagnoses generated by three LLMs-OpenAI's ChatGPT 3.5, ChatGPT 4.0, and Google's Bard. Inter- and intra-LLM agreement of diagnosis were evaluated. Then, diagnostic performance, including accuracy, sensitivity, specificity, and area under the receiver operating characteristic curve (AUC), was evaluated and compared for the LLMs and three interactive approaches: human reader combined with LLMs, image-to-text model combined with LLMs, and an end-to-end convolutional neural network model. Results A total of 1161 US images of thyroid nodules (498 benign, 663 malignant) from 725 patients (mean age, 42.2 years ± 14.1 [SD]; 516 women) were evaluated. ChatGPT 4.0 and Bard displayed substantial to almost perfect intra-LLM agreement (κ range, 0.65-0.86 [95% CI: 0.64, 0.86]), while ChatGPT 3.5 showed fair to substantial agreement (κ range, 0.36-0.68 [95% CI: 0.36, 0.68]). ChatGPT 4.0 had an accuracy of 78%-86% (95% CI: 76%, 88%) and sensitivity of 86%-95% (95% CI: 83%, 96%), compared with 74%-86% (95% CI: 71%, 88%) and 74%-91% (95% CI: 71%, 93%), respectively, for Bard. Moreover, with ChatGPT 4.0, the image-to-text-LLM strategy exhibited an AUC (0.83 [95% CI: 0.80, 0.85]) and accuracy (84% [95% CI: 82%, 86%]) comparable to those of the human-LLM interaction strategy with two senior readers and one junior reader and exceeding those of the human-LLM interaction strategy with one junior reader. Conclusion LLMs, particularly integrated with image-to-text approaches, show potential in enhancing diagnostic medical imaging. ChatGPT 4.0 was optimal for consistency and diagnostic accuracy when compared with Bard and ChatGPT 3.5. © RSNA, 2024","['image-to-text model combined with LLMs', 'end-to-end convolutional neural network model']"
2024,https://openalex.org/W4393021028,Medicine,Foresight—a generative pretrained transformer for modelling of patient timelines using electronic health records: a retrospective modelling study,"BackgroundAn electronic health record (EHR) holds detailed longitudinal information about a patient's health status and general clinical history, a large portion of which is stored as unstructured, free text. Existing approaches to model a patient's trajectory focus mostly on structured data and a subset of single-domain outcomes. This study aims to evaluate the effectiveness of Foresight, a generative transformer in temporal modelling of patient data, integrating both free text and structured formats, to predict a diverse array of future medical outcomes, such as disorders, substances (eg, to do with medicines, allergies, or poisonings), procedures, and findings (eg, relating to observations, judgements, or assessments).MethodsForesight is a novel transformer-based pipeline that uses named entity recognition and linking tools to convert EHR document text into structured, coded concepts, followed by providing probabilistic forecasts for future medical events, such as disorders, substances, procedures, and findings. The Foresight pipeline has four main components: (1) CogStack (data retrieval and preprocessing); (2) the Medical Concept Annotation Toolkit (structuring of the free-text information from EHRs); (3) Foresight Core (deep-learning model for biomedical concept modelling); and (4) the Foresight web application. We processed the entire free-text portion from three different hospital datasets (King's College Hospital [KCH], South London and Maudsley [SLaM], and the US Medical Information Mart for Intensive Care III [MIMIC-III]), resulting in information from 811 336 patients and covering both physical and mental health institutions. We measured the performance of models using custom metrics derived from precision and recall.FindingsForesight achieved a precision@10 (ie, of 10 forecasted candidates, at least one is correct) of 0·68 (SD 0·0027) for the KCH dataset, 0·76 (0·0032) for the SLaM dataset, and 0·88 (0·0018) for the MIMIC-III dataset, for forecasting the next new disorder in a patient timeline. Foresight also achieved a precision@10 value of 0·80 (0·0013) for the KCH dataset, 0·81 (0·0026) for the SLaM dataset, and 0·91 (0·0011) for the MIMIC-III dataset, for forecasting the next new biomedical concept. In addition, Foresight was validated on 34 synthetic patient timelines by five clinicians and achieved a relevancy of 33 (97% [95% CI 91–100]) of 34 for the top forecasted candidate disorder. As a generative model, Foresight can forecast follow-on biomedical concepts for as many steps as required.InterpretationForesight is a general-purpose model for biomedical concept modelling that can be used for real-world risk forecasting, virtual trials, and clinical research to study the progression of disorders, to simulate interventions and counterfactuals, and for educational purposes.FundingNational Health Service Artificial Intelligence Laboratory, National Institute for Health and Care Research Biomedical Research Centre, and Health Data Research UK.","['generative transformer', 'named entity recognition']"
2024,https://openalex.org/W4398183427,Medicine,Evaluating the accuracy of a state-of-the-art large language model for prediction of admissions from the emergency room,"Abstract Background Artificial intelligence (AI) and large language models (LLMs) can play a critical role in emergency room operations by augmenting decision-making about patient admission. However, there are no studies for LLMs using real-world data and scenarios, in comparison to and being informed by traditional supervised machine learning (ML) models. We evaluated the performance of GPT-4 for predicting patient admissions from emergency department (ED) visits. We compared performance to traditional ML models both naively and when informed by few-shot examples and/or numerical probabilities. Methods We conducted a retrospective study using electronic health records across 7 NYC hospitals. We trained Bio-Clinical-BERT and XGBoost (XGB) models on unstructured and structured data, respectively, and created an ensemble model reflecting ML performance. We then assessed GPT-4 capabilities in many scenarios: through Zero-shot, Few-shot with and without retrieval-augmented generation (RAG), and with and without ML numerical probabilities. Results The Ensemble ML model achieved an area under the receiver operating characteristic curve (AUC) of 0.88, an area under the precision-recall curve (AUPRC) of 0.72 and an accuracy of 82.9%. The naïve GPT-4's performance (0.79 AUC, 0.48 AUPRC, and 77.5% accuracy) showed substantial improvement when given limited, relevant data to learn from (ie, RAG) and underlying ML probabilities (0.87 AUC, 0.71 AUPRC, and 83.1% accuracy). Interestingly, RAG alone boosted performance to near peak levels (0.82 AUC, 0.56 AUPRC, and 81.3% accuracy). Conclusions The naïve LLM had limited performance but showed significant improvement in predicting ED admissions when supplemented with real-world examples to learn from, particularly through RAG, and/or numerical probabilities from traditional ML models. Its peak performance, although slightly lower than the pure ML model, is noteworthy given its potential for providing reasoning behind predictions. Further refinement of LLMs with real-world data is necessary for successful integration as decision-support tools in care settings.","['GPT-4', 'XGBoost (XGB)', 'Ensemble model', 'Zero-shot', 'Few-shot', 'Retrieval-augmented generation (RAG)']"
2024,https://openalex.org/W4390706643,Medicine,Present and Future Innovations in AI and Cardiac MRI,"Cardiac MRI is used to diagnose and treat patients with a multitude of cardiovascular diseases. Despite the growth of clinical cardiac MRI, complicated image prescriptions and long acquisition protocols limit the specialty and restrain its impact on the practice of medicine. Artificial intelligence (AI)-the ability to mimic human intelligence in learning and performing tasks-will impact nearly all aspects of MRI. Deep learning (DL) primarily uses an artificial neural network to learn a specific task from example data sets. Self-driving scanners are increasingly available, where AI automatically controls cardiac image prescriptions. These scanners offer faster image collection with higher spatial and temporal resolution, eliminating the need for cardiac triggering or breath holding. In the future, fully automated inline image analysis will most likely provide all contour drawings and initial measurements to the reader. Advanced analysis using radiomic or DL features may provide new insights and information not typically extracted in the current analysis workflow. AI may further help integrate these features with clinical, genetic, wearable-device, and ""omics"" data to improve patient outcomes. This article presents an overview of AI and its application in cardiac MRI, including in image acquisition, reconstruction, and processing, and opportunities for more personalized cardiovascular care through extraction of novel imaging markers.","['Deep learning (DL)', 'artificial neural network']"
2024,https://openalex.org/W4391317367,Medicine,Automated localization of mandibular landmarks in the construction of mandibular median sagittal plane,"Abstract Objective To use deep learning to segment the mandible and identify three-dimensional (3D) anatomical landmarks from cone-beam computed tomography (CBCT) images, the planes constructed from the mandibular midline landmarks were compared and analyzed to find the best mandibular midsagittal plane (MMSP). Methods A total of 400 participants were randomly divided into a training group ( n = 360) and a validation group ( n = 40). Normal individuals were used as the test group ( n = 50). The PointRend deep learning mechanism segmented the mandible from CBCT images and accurately identified 27 anatomic landmarks via PoseNet. 3D coordinates of 5 central landmarks and 2 pairs of side landmarks were obtained for the test group. Every 35 combinations of 3 midline landmarks were screened using the template mapping technique. The asymmetry index (AI) was calculated for each of the 35 mirror planes. The template mapping technique plane was used as the reference plane; the top four planes with the smallest AIs were compared through distance, volume difference, and similarity index to find the plane with the fewest errors. Results The mandible was segmented automatically in 10 ± 1.5 s with a 0.98 Dice similarity coefficient. The mean landmark localization error for the 27 landmarks was 1.04 ± 0.28 mm. MMSP should use the plane made by B (supramentale), Gn (gnathion), and F (mandibular foramen). The average AI grade was 1.6 (min–max: 0.59–3.61). There was no significant difference in distance or volume ( P &gt; 0.05); however, the similarity index was significantly different ( P &lt; 0.01). Conclusion Deep learning can automatically segment the mandible, identify anatomic landmarks, and address medicinal demands in people without mandibular deformities. The most accurate MMSP was the B-Gn-F plane.","['PointRend deep learning mechanism', 'PoseNet']"
2024,https://openalex.org/W4391508432,Medicine,Artificial intelligence-driven virtual rehabilitation for people living in the community: A scoping review,"Abstract Virtual Rehabilitation (VRehab) is a promising approach to improving the physical and mental functioning of patients living in the community. The use of VRehab technology results in the generation of multi-modal datasets collected through various devices. This presents opportunities for the development of Artificial Intelligence (AI) techniques in VRehab, namely the measurement, detection, and prediction of various patients’ health outcomes. The objective of this scoping review was to explore the applications and effectiveness of incorporating AI into home-based VRehab programs. PubMed/MEDLINE, Embase, IEEE Xplore, Web of Science databases, and Google Scholar were searched from inception until June 2023 for studies that applied AI for the delivery of VRehab programs to the homes of adult patients. After screening 2172 unique titles and abstracts and 51 full-text studies, 13 studies were included in the review. A variety of AI algorithms were applied to analyze data collected from various sensors and make inferences about patients’ health outcomes, most involving evaluating patients’ exercise quality and providing feedback to patients. The AI algorithms used in the studies were mostly fuzzy rule-based methods, template matching, and deep neural networks. Despite the growing body of literature on the use of AI in VRehab, very few studies have examined its use in patients’ homes. Current research suggests that integrating AI with home-based VRehab can lead to improved rehabilitation outcomes for patients. However, further research is required to fully assess the effectiveness of various forms of AI-driven home-based VRehab, taking into account its unique challenges and using standardized metrics.","['fuzzy rule-based methods', 'deep neural networks']"
2024,https://openalex.org/W4392406184,Medicine,A Lesion-Based Diabetic Retinopathy Detection Through Hybrid Deep Learning Model,"Diabetic retinopathy (DR) can be defined as visual impairment caused by prolonged diabetes affecting the blood vessels in the retina. Globally, it stands as the primary contributor to blindness, impacting approximately 191 million individuals. While prior research has addressed DR classification using retinal fundus images, existing methods often focus on isolated lesion detection, lacking a comprehensive framework for the simultaneous identification of all lesions. Previous studies concentrated on early-stage features like exudates, aneurysms, hemorrhages, and blood vessels, sidelining severe-stage lesions such as cotton wool spots, venous beading, very severe intraretinal microvascular abnormalities (IRMA), diffuse intraretinal hemorrhages, capillary degeneration, highly activated microglia, and retinal pigment epithelium (RPE) damage. In this study, a deep learning approach is proposed to classify DR fundus images by severity levels, utilizing GoogleNet and ResNet models based on adaptive particle swarm optimizer (APSO), for enhanced feature extraction. The extracted features from the hybrid model are further used with different machine learning models like random forest, support vector machine, decision tree, and linear regression models. Experimental results showcased the proposed hybrid framework outperforming advanced approaches with a remarkable 94% accuracy on the benchmark dataset. This method demonstrates potential enhancements in precision, recall, accuracy, and F1 score for different DR severity levels.","['deep learning', 'GoogleNet', 'ResNet', 'adaptive particle swarm optimizer (APSO)', 'random forest', 'support vector machine', 'decision tree', 'linear regression']"
2024,https://openalex.org/W4395037579,Medicine,Assessing ChatGPT 4.0’s test performance and clinical diagnostic accuracy on USMLE STEP 2 CK and clinical case reports,"Abstract While there is data assessing the test performance of artificial intelligence (AI) chatbots, including the Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0), there is scarce data on its diagnostic accuracy of clinical cases. We assessed the large language model (LLM), ChatGPT 4.0, on its ability to answer questions from the United States Medical Licensing Exam (USMLE) Step 2, as well as its ability to generate a differential diagnosis based on corresponding clinical vignettes from published case reports. A total of 109 Step 2 Clinical Knowledge (CK) practice questions were inputted into both ChatGPT 3.5 and ChatGPT 4.0, asking ChatGPT to pick the correct answer. Compared to its previous version, ChatGPT 3.5, we found improved accuracy of ChatGPT 4.0 when answering these questions, from 47.7 to 87.2% ( p = 0.035) respectively. Utilizing the topics tested on Step 2 CK questions, we additionally found 63 corresponding published case report vignettes and asked ChatGPT 4.0 to come up with its top three differential diagnosis. ChatGPT 4.0 accurately created a shortlist of differential diagnoses in 74.6% of the 63 case reports (74.6%). We analyzed ChatGPT 4.0’s confidence in its diagnosis by asking it to rank its top three differentials from most to least likely. Out of the 47 correct diagnoses, 33 were the first (70.2%) on the differential diagnosis list, 11 were second (23.4%), and three were third (6.4%). Our study shows the continued iterative improvement in ChatGPT’s ability to answer standardized USMLE questions accurately and provides insights into ChatGPT’s clinical diagnostic accuracy.","['Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0)', 'large language model (LLM)']"
2024,https://openalex.org/W4402521185,Medicine,Advanced Ensemble Machine Learning Techniques for Optimizing Diabetes Mellitus Prognostication: A Detailed Examination of Hospital Data,"Diabetes is a chronic disease that affects millions of people worldwide. Early diagnosis and effective management are crucial for reducing its complications. Diabetes is the fourth-highest cause of mortality due to its association with various comorbidities, including heart disease, nerve damage, blood vessel damage, and blindness. The potential of machine learning algorithms in predicting Diabetes and related conditions is significant, and mining diabetes data is an efficient method for extracting new insights.The primary objective of this study is to develop an enhanced ensemble model to predict Diabetes with improved accuracy by leveraging various machine learning algorithms.This study tested several popular machine learning algorithms commonly used in diabetes prediction, including Naive Bayes (NB), Generalized Linear Model (GLM), Logistic Regression (LR), Fast Large Margin (FLM), Deep Learning (DL), Decision Tree (DT), Random Forest (RF), Gradient Boosted Trees (GBT), and Support Vector Machine (SVM). The performance of these algorithms was compared, and two different ensemble techniques—stacking and voting—were used to build a more accurate predictive model.The top three algorithms based on accuracy were Deep Learning, Naive Bayes, and Gradient Boosted Trees. The machine learning algorithms revealed that individuals with Diabetes are significantly affected by the number of chronic conditions they have, as well as their gender and age. The ensemble models, particularly the stacking method, provided higher accuracy than individual algorithms. The stacking ensemble model achieved a slightly better accuracy of 99.94% compared to 99.34% for the voting method.Building an ensemble model significantly increased the accuracy of predicting Diabetes and related conditions. The stacking ensemble model, in particular, demonstrated superior performance, highlighting the importance of combining multiple machine learning approaches to enhance predictive accuracy","['Naive Bayes (NB)', 'Logistic Regression (LR)', 'Deep Learning (DL)', 'Decision Tree (DT)', 'Random Forest (RF)', 'Gradient Boosted Trees (GBT)', 'Support Vector Machine (SVM)', 'stacking ensemble', 'voting ensemble']"
2024,https://openalex.org/W4404134492,Medicine,Bias in medical AI: Implications for clinical decision-making,"Biases in medical artificial intelligence (AI) arise and compound throughout the AI lifecycle. These biases can have significant clinical consequences, especially in applications that involve clinical decision-making. Left unaddressed, biased medical AI can lead to substandard clinical decisions and the perpetuation and exacerbation of longstanding healthcare disparities. We discuss potential biases that can arise at different stages in the AI development pipeline and how they can affect AI algorithms and clinical decision-making. Bias can occur in data features and labels, model development and evaluation, deployment, and publication. Insufficient sample sizes for certain patient groups can result in suboptimal performance, algorithm underestimation, and clinically unmeaningful predictions. Missing patient findings can also produce biased model behavior, including capturable but nonrandomly missing data, such as diagnosis codes, and data that is not usually or not easily captured, such as social determinants of health. Expertly annotated labels used to train supervised learning models may reflect implicit cognitive biases or substandard care practices. Overreliance on performance metrics during model development may obscure bias and diminish a model's clinical utility. When applied to data outside the training cohort, model performance can deteriorate from previous validation and can do so differentially across subgroups. How end users interact with deployed solutions can introduce bias. Finally, where models are developed and published, and by whom, impacts the trajectories and priorities of future medical AI development. Solutions to mitigate bias must be implemented with care, which include the collection of large and diverse data sets, statistical debiasing methods, thorough model evaluation, emphasis on model interpretability, and standardized bias reporting and transparency requirements. Prior to real-world implementation in clinical settings, rigorous validation through clinical trials is critical to demonstrate unbiased application. Addressing biases across model development stages is crucial for ensuring all patients benefit equitably from the future of medical AI.","['supervised learning', 'statistical debiasing methods']"
2024,https://openalex.org/W4391135342,Medicine,Performance of Generative Pretrained Transformer on the National Medical Licensing Examination in Japan,"The remarkable performance of ChatGPT, launched in November 2022, has significantly impacted the field of natural language processing, inspiring the application of large language models as supportive tools in clinical practice and research worldwide. Although GPT-3.5 recently scored high on the United States Medical Licensing Examination, its performance on medical licensing examinations of other nations, especially non-English speaking nations, has not been sufficiently evaluated. This study assessed GPT’s performance on the National Medical Licensing Examination (NMLE) in Japan and compared it with the actual minimal passing rate for this exam. In particular, the performances of both the GPT-3.5 and GPT-4 models were considered for the comparative analysis. We initially used the GPT models and several prompts for 290 questions without image data from the 116 th NMLE (held in February 2022 in Japan) to maximize the performance for delivering correct answers and explanations of the questions. Thereafter, we tested the performance of the best GPT model (GPT-4) with optimized prompts on a dataset of 262 questions without images from the latest 117 th NMLE (held in February 2023). The best model with the optimized prompts scored 82.7% for the essential questions and 77.2% for the basic and clinical questions, both of which sufficed the minimum passing scoring rates of 80.0% and 74.6%, respectively. After an exploratory analysis of 56 incorrect answers from the model, we identified the three major factors contributing to the generation of the incorrect answers—insufficient medical knowledge, information on Japan-specific medical system and guidelines, and mathematical errors. In conclusion, GPT-4 with our optimized prompts achieved a minimum passing scoring rate in the latest 117 th NMLE in Japan. Beyond its original design of answering examination questions for humans, these artificial intelligence (AI) models can serve as one of the best “sidekicks” for solving problems and addressing the unmet needs in the medical and healthcare fields.","['GPT-3.5', 'GPT-4']"
2024,https://openalex.org/W4395049366,Medicine,A novel SpaSA based hyper-parameter optimized FCEDN with adaptive CNN classification for skin cancer detection,"Abstract Skin cancer is the most prevalent kind of cancer in people. It is estimated that more than 1 million people get skin cancer every year in the world. The effectiveness of the disease’s therapy is significantly impacted by early identification of this illness. Preprocessing is the initial detecting stage in enhancing the quality of skin images by removing undesired background noise and objects. This study aims is to compile preprocessing techniques for skin cancer imaging that are currently accessible. Researchers looking into automated skin cancer diagnosis might use this article as an excellent place to start. The fully convolutional encoder–decoder network and Sparrow search algorithm (FCEDN-SpaSA) are proposed in this study for the segmentation of dermoscopic images. The individual wolf method and the ensemble ghosting technique are integrated to generate a neighbour-based search strategy in SpaSA for stressing the correct balance between navigation and exploitation. The classification procedure is accomplished by using an adaptive CNN technique to discriminate between normal skin and malignant skin lesions suggestive of disease. Our method provides classification accuracies comparable to commonly used incremental learning techniques while using less energy, storage space, memory access, and training time (only network updates with new training samples, no network sharing). In a simulation, the segmentation performance of the proposed technique on the ISBI 2017, ISIC 2018, and PH2 datasets reached accuracies of 95.28%, 95.89%, 92.70%, and 98.78%, respectively, on the same dataset and assessed the classification performance. It is accurate 91.67% of the time. The efficiency of the suggested strategy is demonstrated through comparisons with cutting-edge methodologies.","['fully convolutional encoder–decoder network', 'Sparrow search algorithm (SpaSA)', 'adaptive CNN technique', 'incremental learning techniques']"
2024,https://openalex.org/W4390753190,Medicine,Investigating the impact of motion in the scanner on brain age predictions,"Abstract Brain Age Gap (BAG) is defined as the difference between the brain’s predicted age and the chronological age of an individual. Magnetic resonance imaging (MRI)-based BAG can quantify acceleration of brain aging, and is used to infer brain health as aging and disease interact. Motion in the scanner is a common occurrence that can affect the acquired MRI data and act as a major confound in the derived models. As such, age-related changes in head motion may impact the observed age-related differences. However, the relationship between head motion and BAG as estimated by structural MRI has not been systematically examined. The aim of this study is to assess the impact of motion on voxel-based morphometry (VBM) based BAG. Data were obtained from two sources: i) T1-weighted (T1w) MRIs from the Cambridge Centre for Ageing and Neuroscience (CamCAN) were used to train the brain age prediction model, and ii) T1w MRIs from the Movement-related artifacts (MR-ART) dataset were used to assess the impact of motion on BAG. MR-ART includes one motion-free and two motion-affected (one low and one high) 3D T1w MRIs. We also visually rated the motion levels of the MR-ART MRIs from 0 to 5, with 0 meaning no motion and 5 high motion levels. All images were pre-processed through a standard VBM pipeline. GM density across cortical and subcortical regions were then used to train the brain age prediction model and assess the relationship between BAG and MRI motion. Principal component analysis was used to perform dimension reduction and extract the VBM-based features. BAG was estimated by regressing out the portion of delta age explained by chronological age. Linear mixed-effects models were used to investigate the relationship between BAG and motion session as well as motion severity, including participant IDs as random effects. We repeated the same analysis using cortical thickness based on FreeSurfer 7.4.1 and to compare the results for volumetric versus surface-based measures of brain morphometry. In contrast with the session with no induced motion, predicted delta age was significantly higher for high motion sessions 2.35 years (t = 5.17, p &amp;lt; 0.0001), with marginal effect for low motion sessions 0.95 years (t = 2.11, p = 0.035) for VBM analysis as well as 3.46 years (t = 11.45, p &amp;lt; 0.0001) for high motion and 2.28 years (t = 7.54, p &amp;lt; 0.0001) for low motion based on cortical thickness. In addition, delta age was significantly associated with motion severity as evaluated by visual rating 0.45 years per rating level (t = 4.59, p &amp;lt; 0.0001) for VBM analysis and 0.83 years per motion level (t = 12.89, p &amp;lt; 0.0001) for cortical thickness analysis. Motion in the scanner can significantly impact brain age estimates, and needs to be accounted for as a confound, particularly when studying populations that are known to have higher levels of motion in the scanner. These results have significant implications for brain age studies in aging and neurodegeneration. Based on these findings, we recommend assessment and inclusion of visual motion ratings in such studies. In cases that the visual rating proves prohibitive, we recommend the inclusion of normalized Euler number from FreeSurfer as defined in the manuscript as a covariate in the models.","['principal component analysis', 'regression']"
2024,https://openalex.org/W4390987311,Medicine,Reliability of ChatGPT for performing triage task in the emergency department using the Korean Triage and Acuity Scale,"Background Artificial intelligence (AI) technology can enable more efficient decision-making in healthcare settings. There is a growing interest in improving the speed and accuracy of AI systems in providing responses for given tasks in healthcare settings. Objective This study aimed to assess the reliability of ChatGPT in determining emergency department (ED) triage accuracy using the Korean Triage and Acuity Scale (KTAS). Methods Two hundred and two virtual patient cases were built. The gold standard triage classification for each case was established by an experienced ED physician. Three other human raters (ED paramedics) were involved and rated the virtual cases individually. The virtual cases were also rated by two different versions of the chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0). Inter-rater reliability was examined using Fleiss’ kappa and intra-class correlation coefficient (ICC). Results The kappa values for the agreement between the four human raters and ChatGPTs were .523 (version 4.0) and .320 (version 3.5). Of the five levels, the performance was poor when rating patients at levels 1 and 5, as well as case scenarios with additional text descriptions. There were differences in the accuracy of the different versions of GPTs. The ICC between version 3.5 and the gold standard was .520, and that between version 4.0 and the gold standard was .802. Conclusions A substantial level of inter-rater reliability was revealed when GPTs were used as KTAS raters. The current study showed the potential of using GPT in emergency healthcare settings. Considering the shortage of experienced manpower, this AI method may help improve triaging accuracy.","['chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0)']"
2024,https://openalex.org/W4391145465,Medicine,Assessing generalisability of deep learning-based polyp detection and segmentation methods through a computer vision challenge,"Abstract Polyps are well-known cancer precursors identified by colonoscopy. However, variability in their size, appearance, and location makes the detection of polyps challenging. Moreover, colonoscopy surveillance and removal of polyps are highly operator-dependent procedures and occur in a highly complex organ topology. There exists a high missed detection rate and incomplete removal of colonic polyps. To assist in clinical procedures and reduce missed rates, automated methods for detecting and segmenting polyps using machine learning have been achieved in past years. However, the major drawback in most of these methods is their ability to generalise to out-of-sample unseen datasets from different centres, populations, modalities, and acquisition systems. To test this hypothesis rigorously, we, together with expert gastroenterologists, curated a multi-centre and multi-population dataset acquired from six different colonoscopy systems and challenged the computational expert teams to develop robust automated detection and segmentation methods in a crowd-sourcing Endoscopic computer vision challenge. This work put forward rigorous generalisability tests and assesses the usability of devised deep learning methods in dynamic and actual clinical colonoscopy procedures. We analyse the results of four top performing teams for the detection task and five top performing teams for the segmentation task. Our analyses demonstrate that the top-ranking teams concentrated mainly on accuracy over the real-time performance required for clinical applicability. We further dissect the devised methods and provide an experiment-based hypothesis that reveals the need for improved generalisability to tackle diversity present in multi-centre datasets and routine clinical procedures.","['machine learning', 'deep learning']"
2024,https://openalex.org/W4393201840,Medicine,"Clinical gait analysis using video-based pose estimation: Multiple perspectives, clinical populations, and measuring change","Gait dysfunction is common in many clinical populations and often has a profound and deleterious impact on independence and quality of life. Gait analysis is a foundational component of rehabilitation because it is critical to identify and understand the specific deficits that should be targeted prior to the initiation of treatment. Unfortunately, current state-of-the-art approaches to gait analysis (e.g., marker-based motion capture systems, instrumented gait mats) are largely inaccessible due to prohibitive costs of time, money, and effort required to perform the assessments. Here, we demonstrate the ability to perform quantitative gait analyses in multiple clinical populations using only simple videos recorded using low-cost devices (tablets). We report four primary advances: 1) a novel, versatile workflow that leverages an open-source human pose estimation algorithm (OpenPose) to perform gait analyses using videos recorded from multiple different perspectives (e.g., frontal, sagittal), 2) validation of this workflow in three different populations of participants (adults without gait impairment, persons post-stroke, and persons with Parkinson’s disease) via comparison to ground-truth three-dimensional motion capture, 3) demonstration of the ability to capture clinically relevant, condition-specific gait parameters, and 4) tracking of within-participant changes in gait, as is required to measure progress in rehabilitation and recovery. Importantly, our workflow has been made freely available and does not require prior gait analysis expertise. The ability to perform quantitative gait analyses in nearly any setting using only low-cost devices and computer vision offers significant potential for dramatic improvement in the accessibility of clinical gait analysis across different patient populations.",['human pose estimation algorithm (OpenPose)']
2024,https://openalex.org/W4396570916,Medicine,ELRL-MD: a deep learning approach for myocarditis diagnosis using cardiac magnetic resonance images with ensemble and reinforcement learning integration,"Abstract Objective. Myocarditis poses a significant health risk, often precipitated by viral infections like coronavirus disease, and can lead to fatal cardiac complications. As a less invasive alternative to the standard diagnostic practice of endomyocardial biopsy, which is highly invasive and thus limited to severe cases, cardiac magnetic resonance (CMR) imaging offers a promising solution for detecting myocardial abnormalities. Approach. This study introduces a deep model called ELRL-MD that combines ensemble learning and reinforcement learning (RL) for effective myocarditis diagnosis from CMR images. The model begins with pre-training via the artificial bee colony (ABC) algorithm to enhance the starting point for learning. An array of convolutional neural networks (CNNs) then works in concert to extract and integrate features from CMR images for accurate diagnosis. Leveraging the Z-Alizadeh Sani myocarditis CMR dataset, the model employs RL to navigate the dataset’s imbalance by conceptualizing diagnosis as a decision-making process. Main results. ELRL-DM demonstrates remarkable efficacy, surpassing other deep learning, conventional machine learning, and transfer learning models, achieving an F-measure of 88.2% and a geometric mean of 90.6%. Extensive experimentation helped pinpoint the optimal reward function settings and the perfect count of CNNs. Significance. The study addresses the primary technical challenge of inherent data imbalance in CMR imaging datasets and the risk of models converging on local optima due to suboptimal initial weight settings. Further analysis, leaving out ABC and RL components, confirmed their contributions to the model’s overall performance, underscoring the effectiveness of addressing these critical technical challenges.","['ensemble learning', 'reinforcement learning (RL)', 'artificial bee colony (ABC) algorithm', 'convolutional neural networks (CNNs)', 'deep learning', 'transfer learning']"
2024,https://openalex.org/W4396831262,Medicine,GPT-4 Turbo with Vision fails to outperform text-only GPT-4 Turbo in the Japan Diagnostic Radiology Board Examination,"Abstract Purpose To assess the performance of GPT-4 Turbo with Vision (GPT-4TV), OpenAI’s latest multimodal large language model, by comparing its ability to process both text and image inputs with that of the text-only GPT-4 Turbo (GPT-4 T) in the context of the Japan Diagnostic Radiology Board Examination (JDRBE). Materials and methods The dataset comprised questions from JDRBE 2021 and 2023. A total of six board-certified diagnostic radiologists discussed the questions and provided ground-truth answers by consulting relevant literature as necessary. The following questions were excluded: those lacking associated images, those with no unanimous agreement on answers, and those including images rejected by the OpenAI application programming interface. The inputs for GPT-4TV included both text and images, whereas those for GPT-4 T were entirely text. Both models were deployed on the dataset, and their performance was compared using McNemar’s exact test. The radiological credibility of the responses was assessed by two diagnostic radiologists through the assignment of legitimacy scores on a five-point Likert scale. These scores were subsequently used to compare model performance using Wilcoxon's signed-rank test. Results The dataset comprised 139 questions. GPT-4TV correctly answered 62 questions (45%), whereas GPT-4 T correctly answered 57 questions (41%). A statistical analysis found no significant performance difference between the two models (P = 0.44). The GPT-4TV responses received significantly lower legitimacy scores from both radiologists than the GPT-4 T responses. Conclusion No significant enhancement in accuracy was observed when using GPT-4TV with image input compared with that of using text-only GPT-4 T for JDRBE questions.",['GPT-4 Turbo (GPT-4 T)']
2024,https://openalex.org/W4390531926,Medicine,The role of artificial intelligence in generating original scientific research,"Artificial intelligence (AI) is a revolutionary technology that is finding wide application across numerous sectors. Large language models (LLMs) are an emerging subset technology of AI and have been developed to communicate using human languages. At their core, LLMs are trained with vast amounts of information extracted from the internet, including text and images. Their ability to create human-like, expert text in almost any subject means they are increasingly being used as an aid to presentation, particularly in scientific writing. However, we wondered whether LLMs could go further, generating original scientific research and preparing the results for publication. We tasked GPT-4, an LLM, to write an original pharmaceutics manuscript, on a topic that is itself novel. It was able to conceive a research hypothesis, define an experimental protocol, produce photo-realistic images of printlets, generate believable analytical data from a range of instruments and write a convincing publication-ready manuscript with evidence of critical interpretation. The model achieved all this is less than 1h. Moreover, the generated data were multi-modal in nature, including thermal analyses, vibrational spectroscopy and dissolution testing, demonstrating multi-disciplinary expertise in the LLM. One area in which the model failed, however, was in referencing to the literature. Since the generated experimental results appeared believable though, we suggest that LLMs could certainly play a role in scientific research but with human input, interpretation and data validation. We discuss the potential benefits and current bottlenecks for realising this ambition here.",['GPT-4']
2024,https://openalex.org/W4391061191,Medicine,LBO-MPAM: Ladybug Beetle Optimization-based multilayer perceptron attention module for segmenting the skin lesion and automatic localization,"In recent years, skin cancer has been the most dangerous disease noticed among people worldwide. Skin cancer should be identified earlier to reduce the rate of mortality. Employing dermoscopic images can identify and categorise skin cancer effectively. But, the visual evaluation is a complex procedure to be done in the dermoscopic image. However, Deep learning (DL) is an efficient method for skin cancer detection; however, segmenting the skin lesion and automatic localisation in an earlier stage is complicated. In this paper, a novel Ladybug Beetle Optimization-Double Attention Based Multilevel 1-D CNN (LBO-DAM 1-D CNN) technique is proposed to detect and classify skin cancer. To improve skin lesion type discriminability, the two types of attention modules are introduced. The Ultra-Lightweight Subspace Attention Module (ULSAM) is utilised for classifying the feature maps into different stages to validate the frequency from different image samples. However, the multilayer perceptron attention module (MLPAM) is determined to provide information regarding skin cancer classification and diminish the noise and unwanted data. To minimise data loss, it is then combined with hierarchical complementarity during classification. Second, a modified MLPAM is used to extract significant feature spaces for network learning, select the most important information, and reduce feature space redundancy. The Ladybug Beetle Optimization (LBO) algorithm provides the optimal classification solution by minimising the loss rate of DAM 1-D CNN architecture. The experimentation is conducted on three different datasets such as ISIC2020, HAM10000, and the melanoma detection dataset. The experimental results revealed that the proposed method is compared with different existing methods such as IMFO-KELM, Mask RCNN, M-SVM, DCNN-9, and TL-CNN with different datasets. These methods attained 94.56, 92.65, 90.56, 88.65, and 95.5 for the ISIC2020 dataset but the proposed method enhanced the classification performance by attaining 97.02. Also, the validation is based on metrics, namely, accuracy, precision, sensitivity, and F1-score of 97.03%, 97.05%, 97.58%, and 97.27% for a total of 500 epochs.","['Deep learning (DL)', 'Mask RCNN', 'M-SVM']"
2024,https://openalex.org/W4391878291,Medicine,Effective lung nodule detection using deep CNN with dual attention mechanisms,"Abstract Novel methods are required to enhance lung cancer detection, which has overtaken other cancer-related causes of death as the major cause of cancer-related mortality. Radiologists have long-standing methods for locating lung nodules in patients with lung cancer, such as computed tomography (CT) scans. Radiologists must manually review a significant amount of CT scan pictures, which makes the process time-consuming and prone to human error. Computer-aided diagnosis (CAD) systems have been created to help radiologists with their evaluations in order to overcome these difficulties. These systems make use of cutting-edge deep learning architectures. These CAD systems are designed to improve lung nodule diagnosis efficiency and accuracy. In this study, a bespoke convolutional neural network (CNN) with a dual attention mechanism was created, which was especially crafted to concentrate on the most important elements in images of lung nodules. The CNN model extracts informative features from the images, while the attention module incorporates both channel attention and spatial attention mechanisms to selectively highlight significant features. After the attention module, global average pooling is applied to summarize the spatial information. To evaluate the performance of the proposed model, extensive experiments were conducted using benchmark dataset of lung nodules. The results of these experiments demonstrated that our model surpasses recent models and achieves state-of-the-art accuracy in lung nodule detection and classification tasks.","['convolutional neural network (CNN)', 'dual attention mechanism', 'channel attention', 'spatial attention', 'global average pooling']"
2024,https://openalex.org/W4392004069,Medicine,A precise model for skin cancer diagnosis using hybrid U-Net and improved MobileNet-V3 with hyperparameters optimization,"Abstract Skin cancer is a frequently occurring and possibly deadly disease that necessitates prompt and precise diagnosis in order to ensure efficacious treatment. This paper introduces an innovative approach for accurately identifying skin cancer by utilizing Convolution Neural Network architecture and optimizing hyperparameters. The proposed approach aims to increase the precision and efficacy of skin cancer recognition and consequently enhance patients' experiences. This investigation aims to tackle various significant challenges in skin cancer recognition, encompassing feature extraction, model architecture design, and optimizing hyperparameters. The proposed model utilizes advanced deep-learning methodologies to extract complex features and patterns from skin cancer images. We enhance the learning procedure of deep learning by integrating Standard U-Net and Improved MobileNet-V3 with optimization techniques, allowing the model to differentiate malignant and benign skin cancers. Also substituted the crossed-entropy loss function of the Mobilenet-v3 mathematical framework with a bias loss function to enhance the accuracy. The model's squeeze and excitation component was replaced with the practical channel attention component to achieve parameter reduction. Integrating cross-layer connections among Mobile modules has been proposed to leverage synthetic features effectively. The dilated convolutions were incorporated into the model to enhance the receptive field. The optimization of hyperparameters is of utmost importance in improving the efficiency of deep learning models. To fine-tune the model's hyperparameter, we employ sophisticated optimization methods such as the Bayesian optimization method using pre-trained CNN architecture MobileNet-V3. The proposed model is compared with existing models, i.e., MobileNet, VGG-16, MobileNet-V2, Resnet-152v2 and VGG-19 on the “HAM-10000 Melanoma Skin Cancer dataset"". The empirical findings illustrate that the proposed optimized hybrid MobileNet-V3 model outperforms existing skin cancer detection and segmentation techniques based on high precision of 97.84%, sensitivity of 96.35%, accuracy of 98.86% and specificity of 97.32%. The enhanced performance of this research resulted in timelier and more precise diagnoses, potentially contributing to life-saving outcomes and mitigating healthcare expenditures.","['Standard U-Net', 'Improved MobileNet-V3', 'dilated convolutions', 'Bayesian optimization method', 'pre-trained CNN architecture MobileNet-V3']"
2024,https://openalex.org/W4400644938,Medicine,Leveraging artificial intelligence in vaccine development: A narrative review,"Vaccine development stands as a cornerstone of public health efforts, pivotal in curbing infectious diseases and reducing global morbidity and mortality. However, traditional vaccine development methods are often time-consuming, costly, and inefficient. The advent of artificial intelligence (AI) has ushered in a new era in vaccine design, offering unprecedented opportunities to expedite the process. This narrative review explores the role of AI in vaccine development, focusing on antigen selection, epitope prediction, adjuvant identification, and optimization strategies. AI algorithms, including machine learning and deep learning, leverage genomic data, protein structures, and immune system interactions to predict antigenic epitopes, assess immunogenicity, and prioritize antigens for experimentation. Furthermore, AI-driven approaches facilitate the rational design of immunogens and the identification of novel adjuvant candidates with optimal safety and efficacy profiles. Challenges such as data heterogeneity, model interpretability, and regulatory considerations must be addressed to realize the full potential of AI in vaccine development. Integrating emerging technologies, such as single-cell omics and synthetic biology, promises to enhance vaccine design precision and scalability. This review underscores the transformative impact of AI on vaccine development and highlights the need for interdisciplinary collaborations and regulatory harmonization to accelerate the delivery of safe and effective vaccines against infectious diseases.","['machine learning', 'deep learning']"
2024,https://openalex.org/W4391361574,Medicine,Efficient pneumonia detection using Vision Transformers on chest X-rays,"Abstract Pneumonia is a widespread and acute respiratory infection that impacts people of all ages. Early detection and treatment of pneumonia are essential for avoiding complications and enhancing clinical results. We can reduce mortality, improve healthcare efficiency, and contribute to the global battle against a disease that has plagued humanity for centuries by devising and deploying effective detection methods. Detecting pneumonia is not only a medical necessity but also a humanitarian imperative and a technological frontier. Chest X-rays are a frequently used imaging modality for diagnosing pneumonia. This paper examines in detail a cutting-edge method for detecting pneumonia implemented on the Vision Transformer (ViT) architecture on a public dataset of chest X-rays available on Kaggle. To acquire global context and spatial relationships from chest X-ray images, the proposed framework deploys the ViT model, which integrates self-attention mechanisms and transformer architecture. According to our experimentation with the proposed Vision Transformer-based framework, it achieves a higher accuracy of 97.61%, sensitivity of 95%, and specificity of 98% in detecting pneumonia from chest X-rays. The ViT model is preferable for capturing global context, comprehending spatial relationships, and processing images that have different resolutions. The framework establishes its efficacy as a robust pneumonia detection solution by surpassing convolutional neural network (CNN) based architectures.","['Vision Transformer (ViT)', 'self-attention mechanisms', 'transformer architecture', 'convolutional neural network (CNN) based architectures']"
2024,https://openalex.org/W4391671371,Medicine,Collaborative threat intelligence: Enhancing IoT security through blockchain and machine learning integration,"Ensuring robust security in the Internet of Things (IoT) landscape is of paramount importance. This research article presents a novel approach to enhance IoT security by leveraging collaborative threat intelligence and integrating blockchain technology with machine learning (ML) models. The iOS application acts as a central control centre, facilitating the reporting and sharing of detected threats. The shared threat data is securely stored on a blockchain network, enabling ML models to access and learn from a diverse range of threat scenarios. The research focuses on implementing Random Forest, Decision Tree classifier, Ensemble, LSTM, and CNN models on the IoT23 dataset within the context of a Collaborative Threat Intelligence Framework for IoT Security. Through an iterative process, the models' accuracy is improved by reducing false negatives through the collaborative threat intelligence system. The article investigates the implementation details, privacy considerations, and the seamless integration of ML-based techniques for continuous model improvement. Experimental evaluations on the IoT23 dataset demonstrate the effectiveness of the proposed system in enhancing IoT security and mitigating potential threats. The research contributes to the advancement of collaborative threat intelligence and blockchain technology in the context of IoT security, paving the way for more secure and reliable IoT deployments.","['Random Forest', 'Decision Tree classifier', 'Ensemble', 'LSTM', 'CNN']"
2024,https://openalex.org/W4400981456,Medicine,Multimodal data integration for oncology in the era of deep neural networks: a review,"Cancer research encompasses data across various scales, modalities, and resolutions, from screening and diagnostic imaging to digitized histopathology slides to various types of molecular data and clinical records. The integration of these diverse data types for personalized cancer care and predictive modeling holds the promise of enhancing the accuracy and reliability of cancer screening, diagnosis, and treatment. Traditional analytical methods, which often focus on isolated or unimodal information, fall short of capturing the complex and heterogeneous nature of cancer data. The advent of deep neural networks has spurred the development of sophisticated multimodal data fusion techniques capable of extracting and synthesizing information from disparate sources. Among these, Graph Neural Networks (GNNs) and Transformers have emerged as powerful tools for multimodal learning, demonstrating significant success. This review presents the foundational principles of multimodal learning including oncology data modalities, taxonomy of multimodal learning, and fusion strategies. We delve into the recent advancements in GNNs and Transformers for the fusion of multimodal data in oncology, spotlighting key studies and their pivotal findings. We discuss the unique challenges of multimodal learning, such as data heterogeneity and integration complexities, alongside the opportunities it presents for a more nuanced and comprehensive understanding of cancer. Finally, we present some of the latest comprehensive multimodal pan-cancer data sources. By surveying the landscape of multimodal data integration in oncology, our goal is to underline the transformative potential of multimodal GNNs and Transformers. Through technological advancements and the methodological innovations presented in this review, we aim to chart a course for future research in this promising field. This review may be the first that highlights the current state of multimodal modeling applications in cancer using GNNs and transformers, presents comprehensive multimodal oncology data sources, and sets the stage for multimodal evolution, encouraging further exploration and development in personalized cancer care.","['deep neural networks', 'Graph Neural Networks (GNNs)', 'Transformers']"
2024,https://openalex.org/W4390870882,Medicine,A domain adaptation approach to damage classification with an application to bridge monitoring,"Data-driven machine-learning algorithms generally suffer from a lack of labelled health-state data, mainly those referring to damage conditions. To address such an issue, population-based structural health monitoring seeks to enrich the original dataset by transferring knowledge from a population of monitored structures. Within this context, this paper presents a transfer learning approach, based on domain adaptation, to leverage information from completely-labelled bridge structure data to accurately predict new instances of an unknown target domain. Since intrinsic structural differences may cause distribution shifts, domain adaptation attempts to minimise the distance between the domains and to learn a mapping within a shared feature space. Specifically, the methodology involves the long-term acquisition of natural frequencies from several structural scenarios. Such damage-sensitive features are then aligned via domain adaptation so that a machine-learning algorithm can effectively utilise the labelled source domain data and generalise well to the unlabelled target-domain data. The described procedure is applied to two case studies, including the Z24 and the S101 benchmark bridges and their finite element models, respectively. The results demonstrate the successful exchange of health-state labels to identify the damage class within a population of bridges equipped with SHM systems, showing potential to reduce computational efforts and to deal with scarce or poor data sets in application to bridge network monitoring.","['transfer learning', 'domain adaptation']"
2024,https://openalex.org/W4391317914,Medicine,Exploring data mining and machine learning in gynecologic oncology,"Abstract Gynecologic (GYN) malignancies are gaining new and much-needed attention, perpetually fueling literature. Intra-/inter-tumor heterogeneity and “frightened” global distribution by race, ethnicity, and human development index, are pivotal clues to such ubiquitous interest. To advance “precision medicine” and downplay the heavy burden, data mining (DM) is timely in clinical GYN oncology. No consolidated work has been conducted to examine the depth and breadth of DM applicability as an adjunct to GYN oncology, emphasizing machine learning (ML)-based schemes. This systematic literature review (SLR) synthesizes evidence to fill knowledge gaps, flaws, and limitations. We report this SLR in compliance with Kitchenham and Charters’ guidelines. Defined research questions and PICO crafted a search string across five libraries: PubMed, IEEE Xplore, ScienceDirect, SpringerLink, and Google Scholar—over the past decade. Of the 3499 potential records, 181 primary studies were eligible for in-depth analysis. A spike (60.53%) corollary to cervical neoplasms is denoted onward 2019, predominantly featuring empirical solution proposals drawn from cohorts. Medical records led (23.77%, 53 art.). DM-ML in use is primarily built on neural networks (127 art.), appoint classification (73.19%, 172 art.) and diagnoses (42%, 111 art.), all devoted to assessment. Summarized evidence is sufficient to guide and support the clinical utility of DM schemes in GYN oncology. Gaps persist, inculpating the interoperability of single-institute scrutiny. Cross-cohort generalizability is needed to establish evidence while avoiding outcome reporting bias to locally, site-specific trained models. This SLR is exempt from ethics approval as it entails published articles.",['neural networks']
2024,https://openalex.org/W4392200867,Medicine,Revolutionizing core muscle analysis in female sexual dysfunction based on machine learning,"Abstract The purpose of this study is to investigate the role of core muscles in female sexual dysfunction (FSD) and develop comprehensive rehabilitation programs to address this issue. We aim to answer the following research questions: what are the roles of core muscles in FSD, and how can machine and deep learning models accurately predict changes in core muscles during FSD? FSD is a common condition that affects women of all ages, characterized by symptoms such as decreased libido, difficulty achieving orgasm, and pain during intercourse. We conducted a comprehensive analysis of changes in core muscles during FSD using machine and deep learning. We evaluated the performance of multiple models, including multi-layer perceptron (MLP), long short-term memory (LSTM), convolutional neural network (CNN), recurrent neural network (RNN), ElasticNetCV, random forest regressor, SVR, and Bagging regressor. The models were evaluated based on mean squared error (MSE), mean absolute error (MAE), and R-squared (R 2 ) score. Our results show that CNN and random forest regressor are the most accurate models for predicting changes in core muscles during FSD. CNN achieved the lowest MSE (0.002) and the highest R 2 score (0.988), while random forest regressor also performed well with an MSE of 0.0021 and an R 2 score of 0.9905. Our study demonstrates that machine and deep learning models can accurately predict changes in core muscles during FSD. The neglected core muscles play a significant role in FSD, highlighting the need for comprehensive rehabilitation programs that address these muscles. By developing these programs, we can improve the quality of life for women with FSD and help them achieve optimal sexual health.","['multi-layer perceptron (MLP)', 'long short-term memory (LSTM)', 'convolutional neural network (CNN)', 'recurrent neural network (RNN)', 'ElasticNetCV', 'random forest regressor', 'SVR', 'Bagging regressor']"
2024,https://openalex.org/W4392356867,Medicine,The SAFE procedure: a practical stopping heuristic for active learning-based screening in systematic reviews and meta-analyses,"Abstract Active learning has become an increasingly popular method for screening large amounts of data in systematic reviews and meta-analyses. The active learning process continually improves its predictions on the remaining unlabeled records, with the goal of identifying all relevant records as early as possible. However, determining the optimal point at which to stop the active learning process is a challenge. The cost of additional labeling of records by the reviewer must be balanced against the cost of erroneous exclusions. This paper introduces the SAFE procedure, a practical and conservative set of stopping heuristics that offers a clear guideline for determining when to end the active learning process in screening software like ASReview. The eclectic mix of stopping heuristics helps to minimize the risk of missing relevant papers in the screening process. The proposed stopping heuristic balances the costs of continued screening with the risk of missing relevant records, providing a practical solution for reviewers to make informed decisions on when to stop screening. Although active learning can significantly enhance the quality and efficiency of screening, this method may be more applicable to certain types of datasets and problems. Ultimately, the decision to stop the active learning process depends on careful consideration of the trade-off between the costs of additional record labeling against the potential errors of the current model for the specific dataset and context.",['active learning']
2024,https://openalex.org/W4392565345,Medicine,Empowering personalized pharmacogenomics with generative AI solutions,"Abstract Objective This study evaluates an AI assistant developed using OpenAI’s GPT-4 for interpreting pharmacogenomic (PGx) testing results, aiming to improve decision-making and knowledge sharing in clinical genetics and to enhance patient care with equitable access. Materials and Methods The AI assistant employs retrieval-augmented generation (RAG), which combines retrieval and generative techniques, by harnessing a knowledge base (KB) that comprises data from the Clinical Pharmacogenetics Implementation Consortium (CPIC). It uses context-aware GPT-4 to generate tailored responses to user queries from this KB, further refined through prompt engineering and guardrails. Results Evaluated against a specialized PGx question catalog, the AI assistant showed high efficacy in addressing user queries. Compared with OpenAI’s ChatGPT 3.5, it demonstrated better performance, especially in provider-specific queries requiring specialized data and citations. Key areas for improvement include enhancing accuracy, relevancy, and representative language in responses. Discussion The integration of context-aware GPT-4 with RAG significantly enhanced the AI assistant’s utility. RAG’s ability to incorporate domain-specific CPIC data, including recent literature, proved beneficial. Challenges persist, such as the need for specialized genetic/PGx models to improve accuracy and relevancy and addressing ethical, regulatory, and safety concerns. Conclusion This study underscores generative AI’s potential for transforming healthcare provider support and patient accessibility to complex pharmacogenomic information. While careful implementation of large language models like GPT-4 is necessary, it is clear that they can substantially improve understanding of pharmacogenomic data. With further development, these tools could augment healthcare expertise, provider productivity, and the delivery of equitable, patient-centered healthcare services.",['retrieval-augmented generation (RAG)']
2024,https://openalex.org/W4392820641,Medicine,Analysis of human errors in human-autonomy collaboration in autonomous ships operations through shore control experimental data,"Human-autonomy collaboration plays a pivotal role in the development of Maritime autonomous surface ships (MASS), as Shore control center (SCC) operators may engage in the control loop by directly operating the MASS, or, in the supervisory loop, monitoring the MASS and taking over control when needed. Thus, efficient human performance during takeover control and operation is crucial for the safety of MASS operations. However, since the MASS is still in the early phase of development, the mechanism of human errors is unknown, and the data on human-autonomy collaborative operation is scarce. Human reliability analysis (HRA) aims to assess human errors qualitatively and quantitatively, and is widely used in various complex systems to help safety analysis. This study is dedicated to incorporating advanced HRA methods elements to identify and quantify human errors during taking over control and operation of a MASS in collision avoidance scenarios. It presents virtual experimental results, combined with theoretical human error identification and assessment methods. At first, we apply the Human-System Interaction in Autonomy (H-SIA) method to identify potential human errors; secondly, we identify relevant Performance Shaping Factors (PSFs) including Experience, Boredom, Task complexity, Available time and Pre-warning, and performance measures of the human errors, and implement them in the virtual experiment based on a full-scale autonomous ferry research vessel called milliAmpere2. Finally, we build a Bayesian Network (BN) to present causal and probabilistic relationships between PSFs and human errors through experimental data. The results show that available time has the highest impact on takeover performance of operators, followed by task complexity and pre-warning. Boredom does not present a significant sole impact unless combined with available time. Experience does not show a significant impact on human performance. In addition to the relevance of the human errors analysis to the safe development and operational design of MASS, the developed method benefits other human-autonomy collaborative systems. The developed BN model shows adaptability to assess human error probabilities, and the practical significance of integrating experimental data into the existing HRA methodologies for complex systems.",['Bayesian Network (BN)']
2024,https://openalex.org/W4396722287,Medicine,Performance of an Open-Source Large Language Model in Extracting Information from Free-Text Radiology Reports,"Purpose To assess the performance of a local open-source large language model (LLM) in various information extraction tasks from real-life emergency brain MRI reports. Materials and Methods All consecutive emergency brain MRI reports written in 2022 from a French quaternary center were retrospectively reviewed. Two radiologists identified MRI scans that were performed in the emergency department for headaches. Four radiologists scored the reports' conclusions as either normal or abnormal. Abnormalities were labeled as either headache-causing or incidental. Vicuna (LMSYS Org), an open-source LLM, performed the same tasks. Vicuna's performance metrics were evaluated using the radiologists' consensus as the reference standard. Results Among the 2398 reports during the study period, radiologists identified 595 that included headaches in the indication (median age of patients, 35 years [IQR, 26-51 years]; 68% [403 of 595] women). A positive finding was reported in 227 of 595 (38%) cases, 136 of which could explain the headache. The LLM had a sensitivity of 98.0% (95% CI: 96.5, 99.0) and specificity of 99.3% (95% CI: 98.8, 99.7) for detecting the presence of headache in the clinical context, a sensitivity of 99.4% (95% CI: 98.3, 99.9) and specificity of 98.6% (95% CI: 92.2, 100.0) for the use of contrast medium injection, a sensitivity of 96.0% (95% CI: 92.5, 98.2) and specificity of 98.9% (95% CI: 97.2, 99.7) for study categorization as either normal or abnormal, and a sensitivity of 88.2% (95% CI: 81.6, 93.1) and specificity of 73% (95% CI: 62, 81) for causal inference between MRI findings and headache. Conclusion An open-source LLM was able to extract information from free-text radiology reports with excellent accuracy without requiring further training.","['Vicuna (open-source large language model, LLM)']"
2024,https://openalex.org/W4399667220,Medicine,"Triage Performance Across Large Language Models, ChatGPT, and Untrained Doctors in Emergency Medicine: Comparative Study","Background Large language models (LLMs) have demonstrated impressive performances in various medical domains, prompting an exploration of their potential utility within the high-demand setting of emergency department (ED) triage. This study evaluated the triage proficiency of different LLMs and ChatGPT, an LLM-based chatbot, compared to professionally trained ED staff and untrained personnel. We further explored whether LLM responses could guide untrained staff in effective triage. Objective This study aimed to assess the efficacy of LLMs and the associated product ChatGPT in ED triage compared to personnel of varying training status and to investigate if the models’ responses can enhance the triage proficiency of untrained personnel. Methods A total of 124 anonymized case vignettes were triaged by untrained doctors; different versions of currently available LLMs; ChatGPT; and professionally trained raters, who subsequently agreed on a consensus set according to the Manchester Triage System (MTS). The prototypical vignettes were adapted from cases at a tertiary ED in Germany. The main outcome was the level of agreement between raters’ MTS level assignments, measured via quadratic-weighted Cohen κ. The extent of over- and undertriage was also determined. Notably, instances of ChatGPT were prompted using zero-shot approaches without extensive background information on the MTS. The tested LLMs included raw GPT-4, Llama 3 70B, Gemini 1.5, and Mixtral 8x7b. Results GPT-4–based ChatGPT and untrained doctors showed substantial agreement with the consensus triage of professional raters (κ=mean 0.67, SD 0.037 and κ=mean 0.68, SD 0.056, respectively), significantly exceeding the performance of GPT-3.5–based ChatGPT (κ=mean 0.54, SD 0.024; P&lt;.001). When untrained doctors used this LLM for second-opinion triage, there was a slight but statistically insignificant performance increase (κ=mean 0.70, SD 0.047; P=.97). Other tested LLMs performed similar to or worse than GPT-4–based ChatGPT or showed odd triaging behavior with the used parameters. LLMs and ChatGPT models tended toward overtriage, whereas untrained doctors undertriaged. Conclusions While LLMs and the LLM-based product ChatGPT do not yet match professionally trained raters, their best models’ triage proficiency equals that of untrained ED doctors. In its current form, LLMs or ChatGPT thus did not demonstrate gold-standard performance in ED triage and, in the setting of this study, failed to significantly improve untrained doctors’ triage when used as decision support. Notable performance enhancements in newer LLM versions over older ones hint at future improvements with further technological development and specific training.","['zero-shot approaches', 'GPT-4', 'Llama 3 70B', 'GPT-3.5']"
2024,https://openalex.org/W4403545332,Medicine,Evaluating AI and Machine Learning Models in Breast Cancer Detection: A Review of Convolutional Neural Networks (CNN) and Global Research Trends,"Numerous studies have highlighted the significance of artificial intelligence (AI) in breast cancer diagnosis. However, systematic reviews of AI applications in this field often lack cohesion, with each study adopting a unique approach. The aim of this study is to provide a detailed examination of AI's role in breast cancer diagnosis through citation analysis, helping to categorize the key areas that attract academic attention. It also includes a thematic analysis to identify the specific research topics within each category. A total of 30,200 studies related to breast cancer and AI, published between 2015 and 2024, were sourced from databases such as IEEE, Scopus, PubMed, Springer, and Google Scholar. After applying inclusion and exclusion criteria, 32 relevant studies were identified. Most of these studies utilized classification models for breast cancer prediction, with high accuracy being the most commonly reported performance metric. Convolutional Neural Networks (CNN) emerged as the preferred model in many studies. The findings indicate that both the quantity and quality of AI-based algorithms in breast cancer diagnosis are increases in the given years. AI is increasingly seen as a complement to healthcare sector and clinical expertise, with the target of enhancing the accessibility and affordability of quality healthcare worldwide.",['Convolutional Neural Networks (CNN)']
2024,https://openalex.org/W4390777660,Medicine,Unlocking the Potential of XAI for Improved Alzheimer’s Disease Detection and Classification Using a ViT-GRU Model,"Alzheimer's Disease (AD) is a significant cause of dementia worldwide, and its progression from mild to severe affects an individual's ability to perform daily activities independently. The accurate and early diagnosis of AD is crucial for effective clinical intervention. However, interpreting AD from medical images can be challenging, even for experienced radiologists. Therefore, there is a need for an automatic diagnosis of AD, and researchers have investigated the potential of utilizing Artificial Intelligence (AI) techniques, particularly deep learning models, to address this challenge. This study proposes a framework that combines a Vision Transformer (ViT) and a Gated Recurrent Unit (GRU) to detect AD characteristics from Magnetic Resonance Imaging (MRI) images accurately and reliably. The ViT identifies crucial features from the input image, and the GRU establishes clear correlations between these features. The proposed model overcomes the class imbalance issue in the MRI image dataset and achieves superior accuracy and performance compared to existing methods. The model was trained on the Alzheimer's MRI Preprocessed Dataset obtained from Kaggle, achieving notable accuracies of 99.53% for 4-class and 99.69% for binary classification. It also demonstrated a high accuracy of 99.26% for 3-class on the AD Neuroimaging Initiative (ADNI) Baseline Database. These results were validated through a thorough 10-fold cross-validation process. Furthermore, Explainable AI (XAI) techniques were incorporated to make the model interpretable and explainable. This allows clinicians to understand the model's decision-making process and gain insights into the underlying factors driving the AD diagnosis.","['Vision Transformer (ViT)', 'Gated Recurrent Unit (GRU)']"
2024,https://openalex.org/W4391166899,Medicine,"Prediction of atmospheric PM2.5 level by machine learning techniques in Isfahan, Iran","Abstract With increasing levels of air pollution, air quality prediction has attracted more attention. Mathematical models are being developed by researchers to achieve precise predictions. Monitoring and prediction of atmospheric PM 2.5 levels, as a predominant pollutant, is essential in emission mitigation programs. In this study, meteorological datasets from 9 years in Isfahan city, a large metropolis of Iran, were applied to predict the PM 2.5 levels, using four machine learning algorithms including Artificial Neural |Networks (ANNs), K-Nearest-Neighbors (KNN), Support Vector |Machines (SVMs) and ensembles of classification trees Random Forest (RF). The data from 7 air quality monitoring stations located in Isfahan City were taken into consideration. The Confusion Matrix and Cross-Entropy Loss were used to analyze the performance of classification models. Several parameters, including sensitivity, specificity, accuracy, F1 score, precision, and the area under the curve (AUC), are computed to assess model performance. Finally, by introducing the predicted data for 2020 into ArcGIS software and using the IDW (Inverse Distance Weighting) method, interpolation was conducted for the area of Isfahan city and the pollution map was illustrated for each month of the year. The results showed that, based on the accuracy percentage, the ANN model has a better performance (90.1%) in predicting PM 2.5 grades compared to the other models for the applied meteorological dataset, followed by RF (86.1%), SVM (84.6%) and KNN (82.2%) models, respectively. Therefore, ANN modelling provides a feasible procedure for the managerial planning of air pollution control.","['Artificial Neural Networks (ANNs)', 'K-Nearest-Neighbors (KNN)', 'Support Vector Machines (SVMs)', 'Random Forest (RF)']"
2024,https://openalex.org/W4391810207,Medicine,Machine Learning–Based Prediction of Suicidality in Adolescents With Allergic Rhinitis: Derivation and Validation in 2 Independent Nationwide Cohorts,"Background Given the additional risk of suicide-related behaviors in adolescents with allergic rhinitis (AR), it is important to use the growing field of machine learning (ML) to evaluate this risk. Objective This study aims to evaluate the validity and usefulness of an ML model for predicting suicide risk in patients with AR. Methods We used data from 2 independent survey studies, Korea Youth Risk Behavior Web-based Survey (KYRBS; n=299,468) for the original data set and Korea National Health and Nutrition Examination Survey (KNHANES; n=833) for the external validation data set, to predict suicide risks of AR in adolescents aged 13 to 18 years, with 3.45% (10,341/299,468) and 1.4% (12/833) of the patients attempting suicide in the KYRBS and KNHANES studies, respectively. The outcome of interest was the suicide attempt risks. We selected various ML-based models with hyperparameter tuning in the discovery and performed an area under the receiver operating characteristic curve (AUROC) analysis in the train, test, and external validation data. Results The study data set included 299,468 (KYRBS; original data set) and 833 (KNHANES; external validation data set) patients with AR recruited between 2005 and 2022. The best-performing ML model was the random forest model with a mean AUROC of 84.12% (95% CI 83.98%-84.27%) in the original data set. Applying this result to the external validation data set revealed the best performance among the models, with an AUROC of 89.87% (sensitivity 83.33%, specificity 82.58%, accuracy 82.59%, and balanced accuracy 82.96%). While looking at feature importance, the 5 most important features in predicting suicide attempts in adolescent patients with AR are depression, stress status, academic achievement, age, and alcohol consumption. Conclusions This study emphasizes the potential of ML models in predicting suicide risks in patients with AR, encouraging further application of these models in other conditions to enhance adolescent health and decrease suicide rates.",['random forest']
2024,https://openalex.org/W4393033647,Medicine,Optimized Brain Tumor Detection: A Dual-Module Approach for MRI Image Enhancement and Tumor Classification,"Neurological and brain-related cancers are one of the main causes of death worldwide. A commonly used tool in diagnosing these conditions is Magnetic Resonance Imaging (MRI), yet the manual evaluation of MRI images by medical experts presents difficulties due to time constraints and variability. This research introduces a novel, two-module computerized method aimed at increasing the speed and accuracy of brain tumor detection. The first module, termed the Image Enhancement Technique, utilizes a trio of machine learning and imaging strategies—adaptive Wiener filtering, neural networks, and independent component analysis—to normalize images and combat issues such as noise and varying low region contrast. The second module uses Support Vector Machines to validate the output of the first module and perform tumor segmentation and classification. Applied to various types of brain tumors, including meningiomas and pituitary tumors, our method exhibited significant improvements in contrast and classification efficiency. It achieved an average sensitivity and specificity of 0.991, accuracy of 0.989, and a Dice score (DSC) of 0.981. Furthermore, the processing time of our method, averaging at 0.43 seconds, was markedly lower compared to existing methods. These results underscore the superior performance of our approach over current state-of-the-art methods in terms of sensitivity, specificity, precision, and DSC. Future enhancements will seek to increase the robustness of the tumor classification method by employing a standardized approach across a suite of classifiers.","['neural networks', 'independent component analysis', 'Support Vector Machines']"
2024,https://openalex.org/W4393141882,Medicine,Artificial Intelligence (AI) for Early Diagnosis of Retinal Diseases,"Artificial intelligence (AI) has emerged as a transformative tool in the field of ophthalmology, revolutionizing disease diagnosis and management. This paper provides a comprehensive overview of AI applications in various retinal diseases, highlighting its potential to enhance screening efficiency, facilitate early diagnosis, and improve patient outcomes. Herein, we elucidate the fundamental concepts of AI, including machine learning (ML) and deep learning (DL), and their application in ophthalmology, underscoring the significance of AI-driven solutions in addressing the complexity and variability of retinal diseases. Furthermore, we delve into the specific applications of AI in retinal diseases such as diabetic retinopathy (DR), age-related macular degeneration (AMD), Macular Neovascularization, retinopathy of prematurity (ROP), retinal vein occlusion (RVO), hypertensive retinopathy (HR), Retinitis Pigmentosa, Stargardt disease, best vitelliform macular dystrophy, and sickle cell retinopathy. We focus on the current landscape of AI technologies, including various AI models, their performance metrics, and clinical implications. Furthermore, we aim to address challenges and pitfalls associated with the integration of AI in clinical practice, including the “black box phenomenon”, biases in data representation, and limitations in comprehensive patient assessment. In conclusion, this review emphasizes the collaborative role of AI alongside healthcare professionals, advocating for a synergistic approach to healthcare delivery. It highlights the importance of leveraging AI to augment, rather than replace, human expertise, thereby maximizing its potential to revolutionize healthcare delivery, mitigate healthcare disparities, and improve patient outcomes in the evolving landscape of medicine.","['machine learning (ML)', 'deep learning (DL)']"
2024,https://openalex.org/W4393405326,Medicine,"Developing Deep LSTMs With Later Temporal Attention for Predicting COVID-19 Severity, Clinical Outcome, and Antibody Level by Screening Serological Indicators Over Time","Objective: The clinical course of COVID-19, as well as the immunological reaction, is notable for its extreme variability. Identifying the main associated factors might help understand the disease progression and physiological status of COVID-19 patients. The dynamic changes of the antibody against Spike protein are crucial for understanding the immune response. This work explores a temporal attention (TA) mechanism of deep learning to predict COVID-19 disease severity, clinical outcomes, and Spike antibody levels by screening serological indicators over time. Methods: We use feature selection techniques to filter feature subsets that are highly correlated with the target. The specific deep Long Short-Term Memory (LSTM) models are employed to capture the dynamic changes of disease severity, clinical outcome, and Spike antibody level. We also propose deep LSTMs with a TA mechanism to emphasize the later blood test records because later records often attract more attention from doctors. Results: Risk factors highly correlated with COVID-19 are revealed. LSTM achieves the highest classification accuracy for disease severity prediction. Temporal Attention Long Short-Term Memory (TA-LSTM) achieves the best performance for clinical outcome prediction. For Spike antibody level prediction, LSTM achieves the best permanence. Conclusion: The experimental results demonstrate the effectiveness of the proposed models. The proposed models can provide a computer-aided medical diagnostics system by simply using time series of serological indicators.","['deep Long Short-Term Memory (LSTM) models', 'deep LSTMs with a temporal attention (TA) mechanism']"
2024,https://openalex.org/W4401537518,Medicine,A New Brain Network Construction Paradigm for Brain Disorder via Diffusion-Based Graph Contrastive Learning,"Brain network analysis plays an increasingly important role in studying brain function and the exploring of disease mechanisms. However, existing brain network construction tools have some limitations, including dependency on empirical users, weak consistency in repeated experiments and time-consuming processes. In this work, a diffusion-based brain network pipeline, DGCL is designed for end-to-end construction of brain networks. Initially, the brain region-aware module (BRAM) precisely determines the spatial locations of brain regions by the diffusion process, avoiding subjective parameter selection. Subsequently, DGCL employs graph contrastive learning to optimize brain connections by eliminating individual differences in redundant connections unrelated to diseases, thereby enhancing the consistency of brain networks within the same group. Finally, the node-graph contrastive loss and classification loss jointly constrain the learning process of the model to obtain the reconstructed brain network, which is then used to analyze important brain connections. Validation on two datasets, ADNI and ABIDE, demonstrates that DGCL surpasses traditional methods and other deep learning models in predicting disease development stages. Significantly, the proposed model improves the efficiency and generalization of brain network construction. In summary, the proposed DGCL can be served as a universal brain network construction scheme, which can effectively identify important brain connections through generative paradigms and has the potential to provide disease interpretability support for neuroscience research.","['diffusion process', 'graph contrastive learning']"
2024,https://openalex.org/W4390659128,Medicine,Multi-Class Kidney Abnormalities Detecting Novel System Through Computed Tomography,"Impaired renal function poses a risk across all age groups. Because of the global shortage of nephrologists, the growing public health concern over renal failure, and technological improvements, there is a demand for an AI-driven system capable of autonomously detecting kidney abnormalities. Chronic kidney disease, commonly known as chronic renal failure, is characterized by a progressive decline in kidney function. Renal failure can be caused by a variety of reasons, including cysts, stones, and tumors. Chronic kidney disease may not have apparent symptoms at first, resulting in instances staying untreated until they reach an advanced state. Tumors are dense clumps of tissue that can cause direct injury to glands, spinal cells, and other organs. The presence of a substantial number of solids in the digestive tract causes kidney stone disease, also known as urolithiasis. This study used a deep learning model to detect kidney illnesses to solve the global scarcity of urologists. The project entailed obtaining and annotating a large dataset of 12,446 CT whole abdomen and urogram images, with an emphasis on kidney stones, cysts, and tumors, which are the most common types of renal illness. The dataset was divided into four categories: cyst, tumor, stone, and normal. Data was collected from several hospitals in the Dhaka area. This work presents an innovative and customizable platform for the clinical diagnosis of kidney diseases such as tumors, stones, and cysts. Our YOLOv8 model's enhanced accuracy opens up new possibilities for identifying kidney cysts, stones, and tumors. We used criteria like accuracy, precision, recall, F1 score, and specificity to evaluate its performance. The network attained an accuracy rate of 82.52%, 85.76% precision, 75.28% recall, 75.72% F1 score, and 93.12% specificity.","['deep learning model', 'YOLOv8']"
2024,https://openalex.org/W4391437034,Medicine,A methodical exploration of imaging modalities from dataset to detection through machine learning paradigms in prominent lung disease diagnosis: a review,"Abstract Background Lung diseases, both infectious and non-infectious, are the most prevalent cause of mortality overall in the world. Medical research has identified pneumonia, lung cancer, and Corona Virus Disease 2019 (COVID-19) as prominent lung diseases prioritized over others. Imaging modalities, including X-rays, computer tomography (CT) scans, magnetic resonance imaging (MRIs), positron emission tomography (PET) scans, and others, are primarily employed in medical assessments because they provide computed data that can be utilized as input datasets for computer-assisted diagnostic systems. Imaging datasets are used to develop and evaluate machine learning (ML) methods to analyze and predict prominent lung diseases. Objective This review analyzes ML paradigms, imaging modalities' utilization, and recent developments for prominent lung diseases. Furthermore, the research also explores various datasets available publically that are being used for prominent lung diseases. Methods The well-known databases of academic studies that have been subjected to peer review, namely ScienceDirect, arXiv, IEEE Xplore, MDPI, and many more, were used for the search of relevant articles. Applied keywords and combinations used to search procedures with primary considerations for review, such as pneumonia, lung cancer, COVID-19, various imaging modalities, ML, convolutional neural networks (CNNs), transfer learning, and ensemble learning. Results This research finding indicates that X-ray datasets are preferred for detecting pneumonia, while CT scan datasets are predominantly favored for detecting lung cancer. Furthermore, in COVID-19 detection, X-ray datasets are prioritized over CT scan datasets. The analysis reveals that X-rays and CT scans have surpassed all other imaging techniques. It has been observed that using CNNs yields a high degree of accuracy and practicability in identifying prominent lung diseases. Transfer learning and ensemble learning are complementary techniques to CNNs to facilitate analysis. Furthermore, accuracy is the most favored metric for assessment.","['machine learning (ML)', 'convolutional neural networks (CNNs)', 'transfer learning', 'ensemble learning']"
2024,https://openalex.org/W4392056032,Medicine,A novel fusion framework of deep bottleneck residual convolutional neural network for breast cancer classification from mammogram images,"With over 2.1 million new cases of breast cancer diagnosed annually, the incidence and mortality rate of this disease pose severe global health issues for women. Identifying the disease’s influence is the only practical way to lessen it immediately. Numerous research works have developed automated methods using different medical imaging to identify BC. Still, the precision of each strategy differs based on the available resources, the issue’s nature, and the dataset being used. We proposed a novel deep bottleneck convolutional neural network with a quantum optimization algorithm for breast cancer classification and diagnosis from mammogram images. Two novel deep architectures named three-residual blocks bottleneck and four-residual blocks bottle have been proposed with parallel and single paths. Bayesian Optimization (BO) has been employed to initialize hyperparameter values and train the architectures on the selected dataset. Deep features are extracted from the global average pool layer of both models. After that, a kernel-based canonical correlation analysis and entropy technique is proposed for the extracted deep features fusion. The fused feature set is further refined using an optimization technique named quantum generalized normal distribution optimization. The selected features are finally classified using several neural network classifiers, such as bi-layered and wide-neural networks. The experimental process was conducted on a publicly available mammogram imaging dataset named INbreast, and a maximum accuracy of 96.5% was obtained. Moreover, for the proposed method, the sensitivity rate is 96.45, the precision rate is 96.5, the F1 score value is 96.64, the MCC value is 92.97%, and the Kappa value is 92.97%, respectively. The proposed architectures are further utilized for the diagnosis process of infected regions. In addition, a detailed comparison has been conducted with a few recent techniques showing the proposed framework’s higher accuracy and precision rate.","['deep bottleneck convolutional neural network', 'Bayesian Optimization (BO)', 'kernel-based canonical correlation analysis', 'bi-layered neural network classifier', 'wide-neural network classifier']"
2024,https://openalex.org/W4392139441,Medicine,Artificial intelligence for radiographic imaging detection of caries lesions: a systematic review,"Abstract Background The aim of this systematic review is to evaluate the diagnostic performance of Artificial Intelligence (AI) models designed for the detection of caries lesion (CL). Materials and methods An electronic literature search was conducted on PubMed, Web of Science, SCOPUS, LILACS and Embase databases for retrospective, prospective and cross-sectional studies published until January 2023, using the following keywords: artificial intelligence (AI), machine learning (ML), deep learning (DL), artificial neural networks (ANN), convolutional neural networks (CNN), deep convolutional neural networks (DCNN), radiology, detection, diagnosis and dental caries (DC). The quality assessment was performed using the guidelines of QUADAS-2. Results Twenty articles that met the selection criteria were evaluated. Five studies were performed on periapical radiographs, nine on bitewings, and six on orthopantomography. The number of imaging examinations included ranged from 15 to 2900. Four studies investigated ANN models, fifteen CNN models, and two DCNN models. Twelve were retrospective studies, six cross-sectional and two prospective. The following diagnostic performance was achieved in detecting CL: sensitivity from 0.44 to 0.86, specificity from 0.85 to 0.98, precision from 0.50 to 0.94, PPV (Positive Predictive Value) 0.86, NPV (Negative Predictive Value) 0.95, accuracy from 0.73 to 0.98, area under the curve (AUC) from 0.84 to 0.98, intersection over union of 0.3–0.4 and 0.78, Dice coefficient 0.66 and 0.88, F1-score from 0.64 to 0.92. According to the QUADAS-2 evaluation, most studies exhibited a low risk of bias. Conclusion AI-based models have demonstrated good diagnostic performance, potentially being an important aid in CL detection. Some limitations of these studies are related to the size and heterogeneity of the datasets. Future studies need to rely on comparable, large, and clinically meaningful datasets. Protocol PROSPERO identifier: CRD42023470708","['Artificial Neural Networks (ANN)', 'Convolutional Neural Networks (CNN)', 'Deep Convolutional Neural Networks (DCNN)']"
2024,https://openalex.org/W4394967854,Medicine,Potential of Large Language Models in Health Care: Delphi Study,"Background A large language model (LLM) is a machine learning model inferred from text data that captures subtle patterns of language use in context. Modern LLMs are based on neural network architectures that incorporate transformer methods. They allow the model to relate words together through attention to multiple words in a text sequence. LLMs have been shown to be highly effective for a range of tasks in natural language processing (NLP), including classification and information extraction tasks and generative applications. Objective The aim of this adapted Delphi study was to collect researchers’ opinions on how LLMs might influence health care and on the strengths, weaknesses, opportunities, and threats of LLM use in health care. Methods We invited researchers in the fields of health informatics, nursing informatics, and medical NLP to share their opinions on LLM use in health care. We started the first round with open questions based on our strengths, weaknesses, opportunities, and threats framework. In the second and third round, the participants scored these items. Results The first, second, and third rounds had 28, 23, and 21 participants, respectively. Almost all participants (26/28, 93% in round 1 and 20/21, 95% in round 3) were affiliated with academic institutions. Agreement was reached on 103 items related to use cases, benefits, risks, reliability, adoption aspects, and the future of LLMs in health care. Participants offered several use cases, including supporting clinical tasks, documentation tasks, and medical research and education, and agreed that LLM-based systems will act as health assistants for patient education. The agreed-upon benefits included increased efficiency in data handling and extraction, improved automation of processes, improved quality of health care services and overall health outcomes, provision of personalized care, accelerated diagnosis and treatment processes, and improved interaction between patients and health care professionals. In total, 5 risks to health care in general were identified: cybersecurity breaches, the potential for patient misinformation, ethical concerns, the likelihood of biased decision-making, and the risk associated with inaccurate communication. Overconfidence in LLM-based systems was recognized as a risk to the medical profession. The 6 agreed-upon privacy risks included the use of unregulated cloud services that compromise data security, exposure of sensitive patient data, breaches of confidentiality, fraudulent use of information, vulnerabilities in data storage and communication, and inappropriate access or use of patient data. Conclusions Future research related to LLMs should not only focus on testing their possibilities for NLP-related tasks but also consider the workflows the models could contribute to and the requirements regarding quality, integration, and regulations needed for successful implementation in practice.","['large language model (LLM)', 'transformer methods']"
2024,https://openalex.org/W4399055889,Medicine,Tomato Leaf Disease Detection using Convolutional Neural Networks,"One of the most important crops that is grown in enormous amounts and has an excellent market value comprises the tomato. They are grown and eaten in large quantities not only in India but also globally. Disease is the primary factor affecting the quantity and quality of this crop’s production. In earlier research, the plant’s leaves solely were taken into account for disease identification; however, in many cases, the illness only affects the fruit, leaving the other plant parts healthy. Using the unaided eye to diagnose a disease can occasionally lead to a prognosis that is off, meaning the wrong pesticide is applied and the plant may get spoiled. The farmers find it challenging to diagnose the disease because specialists are scarce in many of the affected areas. It’s an expensive and time-consuming process, even though professionals are accessible in certain sectors. Early disease detection would lessen the impact on plants and increase agricultural yield. As a result, it is essential to recognise these illnesses accurately and use the appropriate pesticide. These is- sues can be resolved by an automated system. We have developed a system to tackle this problem, which employs a convolutional neural network (CNN) to detect the ailment and recommends a pesticide to aid in its eradication. Since CNN offers its highest level of accuracy, our system incorporates it.",['convolutional neural network (CNN)']
2024,https://openalex.org/W4391174596,Medicine,Generative Large Language Models for Detection of Speech Recognition Errors in Radiology Reports,"This study evaluated the ability of generative large language models (LLMs) to detect speech recognition errors in radiology reports. A dataset of 3233 CT and MRI reports was assessed by radiologists for speech recognition errors. Errors were categorized as clinically significant or not clinically significant. Performances of five generative LLMs—GPT-3.5-turbo, GPT-4, text-davinci-003, Llama-v2–70B-chat, and Bard—were compared in detecting these errors, using manual error detection as the reference standard. Prompt engineering was used to optimize model performance. GPT-4 demonstrated high accuracy in detecting clinically significant errors (precision, 76.9%; recall, 100%; F1 score, 86.9%) and not clinically significant errors (precision, 93.9%; recall, 94.7%; F1 score, 94.3%). Text-davinci-003 achieved F1 scores of 72% and 46.6% for clinically significant and not clinically significant errors, respectively. GPT-3.5-turbo obtained 59.1% and 32.2% F1 scores, while Llama-v2–70B-chat scored 72.8% and 47.7%. Bard showed the lowest accuracy, with F1 scores of 47.5% and 20.9%. GPT-4 effectively identified challenging errors of nonsense phrases and internally inconsistent statements. Longer reports, resident dictation, and overnight shifts were associated with higher error rates. In conclusion, advanced generative LLMs show potential for automatic detection of speech recognition errors in radiology reports. Keywords: CT, Large Language Model, Machine Learning, MRI, Natural Language Processing, Radiology Reports, Speech, Unsupervised Learning Supplemental material is available for this article. © RSNA, 2024","['generative large language models (LLMs)', 'GPT-3.5-turbo', 'GPT-4', 'text-davinci-003', 'Llama-v2–70B-chat']"
2024,https://openalex.org/W4391480252,Medicine,Performance of convolutional neural networks for the classification of brain tumors using magnetic resonance imaging,"Brain tumors are a diverse group of neoplasms that are challenging to detect and classify due to their varying characteristics. Deep learning techniques have proven to be effective in tumor classification. However, there is a lack of studies that compare these techniques using a common methodology. This work aims to analyze the performance of convolutional neural networks in the classification of brain tumors. We propose a network consisting of a few convolutional layers, batch normalization, and max-pooling. Then, we explore recent deep architectures, such as VGG, ResNet, EfficientNet, or ConvNeXt. The study relies on two magnetic resonance imaging datasets with over 3000 images of three types of tumors –gliomas, meningiomas, and pituitary tumors–, as well as images without tumors. We determine the optimal hyperparameters of the networks using the training and validation sets. The training and test sets are used to assess the performance of the models from different perspectives, including training from scratch, data augmentation, transfer learning, and fine-tuning. The experiments are performed using the TensorFlow and Keras libraries in Python. We compare the accuracy of the models and analyze their complexity based on the capacity of the networks, their training times, and image throughput. Several networks achieve high accuracy rates on both datasets, with the best model achieving 98.7% accuracy, which is on par with state-of-the-art methods. The average precision for each type of tumor is 94.3% for gliomas, 93.8% for meningiomas, 97.9% for pituitary tumors, and 95.3% for images without tumors. VGG is the largest model with over 171 million parameters, whereas MobileNet and EfficientNetB0 are the smallest ones with 3.2 and 5.9 million parameters, respectively. These two neural networks are also the fastest to train with 23.7 and 25.4 seconds per epoch, respectively. On the other hand, ConvNext is the slowest model with 58.2 seconds per epoch. Our custom model obtained the highest image throughput with 234.37 images per second, followed by MobileNet with 226 images per second. ConvNext obtained the smallest throughput with 97.35 images per second. ResNet, MobileNet, and EfficientNet are the most accurate networks, with MobileNet and EfficientNet demonstrating superior performance in terms of complexity. Most models achieve the best accuracy using transfer learning followed by a fine-tuning step. However, data augmentation does not contribute to increasing the accuracy of the models in general.","['convolutional neural networks', 'VGG', 'ResNet', 'EfficientNet', 'ConvNeXt', 'transfer learning', 'fine-tuning']"
2024,https://openalex.org/W4391697089,Medicine,A Minimal and Multi-Source Recording Setup for Ankle Joint Kinematics Estimation During Walking Using Only Proximal Information From Lower Limb,"In this study, a minimal setup for the ankle joint kinematics estimation is proposed relying only on proximal information of the lower-limb, i.e. thigh muscles activity and joint kinematics. To this purpose, myoelectric activity of Rectus Femoris (RF), Biceps Femoris (BF), and Vastus Medialis (VM) were recorded by surface electromyography (sEMG) from six healthy subjects during unconstrained walking task. For each subject, the angular kinematics of hip and ankle joints were synchronously recorded with sEMG signal for a total of 288 gait cycles. Two feature sets were extracted from sEMG signals, i.e. time domain (TD) and wavelet (WT) and compared to have a compromise between the reliability and computational capacity, they were used for feeding three regression models, i.e. Artificial Neural Networks, Random Forest, and Least Squares - Support Vector Machine (LS-SVM). BF together with LS-SVM provided the best ankle angle estimation in both TD and WT domains (RMSE < 5.6 deg). The inclusion of Hip joint trajectory significantly enhanced the regression performances of the model (RMSE < 4.5 deg). Results showed the feasibility of estimating the ankle trajectory using only proximal and limited information from the lower limb which would maximize a potential transfemoral amputee user's comfortability while facing the challenge of having a small amount of information thus requiring robust data-driven models. These findings represent a significant step towards the development of a minimal setup useful for the control design of ankle active prosthetics and rehabilitative solutions.","['Artificial Neural Networks', 'Random Forest', 'Least Squares - Support Vector Machine (LS-SVM)']"
2024,https://openalex.org/W4399685394,Engineering,Advanced Modelling of Soil Organic Carbon Content in Coal Mining Areas Using Integrated Spectral Analysis: A Dengcao Coal Mine Case Study,"Effective modelling and integrated spectral analysis approaches can advance modelling precision. To develop an integrated spectral forecast modelling of soil organic carbon (SOC), this research investigated a mining coal in Dengcao Coal Mine Area, Zhengzhou. The study utilizes the Lasso and Ranger algorithms were utilized in spectral band analysis. Four primary models employed during this process include Artificial Neural Network (ANN), Support Vector Machine, Random Forest (RF), and Partial Least Squares Regression (PLSR). The ideal model was chosen. The results showed that, in contrast to when band collection was based on Lasso algorithm modelling, model precision was higher when it was based on the Ranger algorithm. ANN model had an ideal goodness acceptance, and the modelling developed by RF showed the steadiest modelling consequences. Based on the results, a distinct method is proposed in this study for band assortment at the earlier stage of integrated spectral modelling of SOC. The Ranger method can be used to check the spectral particles, and RF or ANN can be chosen to develop the prediction modelling based on different statistics sets, which is appropriate to create the prediction modelling of SOC content in Dengcao Coal Mine Area. This research avails a position for the integrated spectral of Analysis for Advanced Modelling of Soil Organic Carbon Content in Coal Sources alongside a theoretical foundation for innovating portable device for the integrated spectral assessment of SOC content in coal mining habitats. This study might be significant for the changing modelling and monitoring of SOC in mining and environmental areas.","['Lasso', 'Artificial Neural Network (ANN)', 'Support Vector Machine', 'Random Forest (RF)']"
2024,https://openalex.org/W4399657851,Engineering,Fusion of finite element and machine learning methods to predict rock shear strength parameters,"Abstract The trial-and-error method for calibrating rock mechanics parameters has the disadvantages of complexity, being time-consuming, and difficulty in ensuring accuracy. Harnessing the repeatability and scalability intrinsic to numerical simulation calculations and amalgamating them with the data-driven attributes of machine learning methods, this study uses the finite element analysis software RS2 to establish 252 sets of sandstone sample data. The recursive feature elimination and cross-validation method is employed for feature selection. The shear strength parameters of sandstone are predicted using machine learning models optimized by the particle swarm optimization (PSO) algorithm, including the backpropagation neural network, Bayesian ridge regression, support vector regression (SVR), and light gradient boosting machine. The predicted value of cohesion is proposed as the input feature to predict the friction angle. The results indicate that the optimal input characteristics for predicting cohesion are elastic modulus, Poisson's ratio, peak stress, and peak strain, while the optimal input characteristics for predicting friction angle are peak stress and cohesion. The PSO-SVR model demonstrates the best performance. The maximum error between the predicted values of cohesion and friction angle and the calculated results of RSData program are 3.5% and 4.31%, respectively. The finite element calculation is in good agreement with the stress–strain curve obtained in the laboratory. The sensitivity analysis indicates that SVR's prediction performance for cohesion and friction angle tends to be stable when the sample size is &amp;gt;25. These results offer a valuable reference for accurately predicting rock mechanics parameters.","['recursive feature elimination', 'backpropagation neural network', 'Bayesian ridge regression', 'support vector regression (SVR)', 'light gradient boosting machine']"
2024,https://openalex.org/W4401070841,Engineering,Transformer-Based Visual Segmentation: A Survey,"Visual segmentation seeks to partition images, video frames, or point clouds into multiple segments or groups. This technique has numerous real-world applications, such as autonomous driving, image editing, robot sensing, and medical analysis. Over the past decade, deep learning-based methods have made remarkable strides in this area. Recently, transformers, a type of neural network based on self-attention originally designed for natural language processing, have considerably surpassed previous convolutional or recurrent approaches in various vision processing tasks. Specifically, vision transformers offer robust, unified, and even simpler solutions for various segmentation tasks. This survey provides a thorough overview of transformer-based visual segmentation, summarizing recent advancements. We first review the background, encompassing problem definitions, datasets, and prior convolutional methods. Next, we summarize a meta-architecture that unifies all recent transformer-based approaches. Based on this meta-architecture, we examine various method designs, including modifications to the meta-architecture and associated applications. We also present several specific subfields, including 3D point cloud segmentation, foundation model tuning, domain-aware segmentation, efficient segmentation, and medical segmentation. Additionally, we compile and re-evaluate the reviewed methods on several well-established datasets. Finally, we identify open challenges in this field and propose directions for future research. The project page can be found at <uri xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">https://github.com/lxtGH/Awesome-Segmentation-With-Transformer</uri> .","['transformers', 'convolutional approaches', 'recurrent approaches', 'vision transformers']"
2024,https://openalex.org/W4390837884,Engineering,The deep learning applications in IoT-based bio- and medical informatics: a systematic literature review,"Abstract Nowadays, machine learning (ML) has attained a high level of achievement in many contexts. Considering the significance of ML in medical and bioinformatics owing to its accuracy, many investigators discussed multiple solutions for developing the function of medical and bioinformatics challenges using deep learning (DL) techniques. The importance of DL in Internet of Things (IoT)-based bio- and medical informatics lies in its ability to analyze and interpret large amounts of complex and diverse data in real time, providing insights that can improve healthcare outcomes and increase efficiency in the healthcare industry. Several applications of DL in IoT-based bio- and medical informatics include diagnosis, treatment recommendation, clinical decision support, image analysis, wearable monitoring, and drug discovery. The review aims to comprehensively evaluate and synthesize the existing body of the literature on applying deep learning in the intersection of the IoT with bio- and medical informatics. In this paper, we categorized the most cutting-edge DL solutions for medical and bioinformatics issues into five categories based on the DL technique utilized: convolutional neural network , recurrent neural network , generative adversarial network , multilayer perception , and hybrid methods. A systematic literature review was applied to study each one in terms of effective properties, like the main idea, benefits, drawbacks, methods, simulation environment, and datasets. After that, cutting-edge research on DL approaches and applications for bioinformatics concerns was emphasized. In addition, several challenges that contributed to DL implementation for medical and bioinformatics have been addressed, which are predicted to motivate more studies to develop medical and bioinformatics research progressively. According to the findings, most articles are evaluated using features like accuracy, sensitivity, specificity, F -score, latency, adaptability, and scalability.","['convolutional neural network', 'recurrent neural network', 'generative adversarial network', 'hybrid methods']"
2024,https://openalex.org/W4391018556,Engineering,Battery safety: Machine learning-based prognostics,"Lithium-ion batteries play a pivotal role in a wide range of applications, from electronic devices to large-scale electrified transportation systems and grid-scale energy storage. Nevertheless, they are vulnerable to both progressive aging and unexpected failures, which can result in catastrophic events such as explosions or fires. Given their expanding global presence, the safety of these batteries and potential hazards from serious malfunctions are now major public concerns. Over the past decade, scholars and industry experts are intensively exploring methods to monitor battery safety, spanning from materials to cell, pack and system levels and across various spectral, spatial, and temporal scopes. In this Review, we start by summarizing the mechanisms and nature of battery failures. Following this, we explore the intricacies in predicting battery system evolution and delve into the specialized knowledge essential for data-driven, machine learning models. We offer an exhaustive review spotlighting the latest strides in battery fault diagnosis and failure prognosis via an array of machine learning approaches. Our discussion encompasses: (1) supervised and reinforcement learning integrated with battery models, apt for predicting faults/failures and probing into failure causes and safety protocols at the cell level; (2) unsupervised, semi-supervised, and self-supervised learning, advantageous for harnessing vast data sets from battery modules/packs; (3) few-shot learning tailored for gleaning insights from scarce examples, alongside physics-informed machine learning to bolster model generalization and optimize training in data-scarce settings. We conclude by casting light on the prospective horizons of comprehensive, real-world battery prognostics and management.","['supervised learning', 'reinforcement learning', 'unsupervised learning', 'semi-supervised learning', 'self-supervised learning', 'few-shot learning', 'physics-informed machine learning']"
2024,https://openalex.org/W4394935921,Engineering,Machine learning-based predictive model for thermal comfort and energy optimization in smart buildings,"In the current context of energy transition and increasing climate change, optimizing building performance has become a critical objective. Efficient energy use and occupant comfort are paramount considerations in building design and operation. To address these challenges, this study introduces a predictive model leveraging Machine Learning (ML) algorithms. The model aims to predict thermal comfort levels and optimize energy consumption in Heating, Ventilation, and Air Conditioning (HVAC) systems. Four distinct ML algorithms Support Vector Machine (SVM), Artificial Neural Network (ANN), Random Forest (RF), and EXtreme Gradient Boosting (XGBOOST) are employed for this purpose. Data for the model is collected using a network of Raspberry Pi boards equipped with multiple sensors. Performance evaluation of the ML algorithms is conducted using statistical error metrics, including, Root Mean Square Error (RMSE), Mean Square Error (MSE), Mean Absolute Error (MAE), and coefficient of determination (R2). Results reveal that the RF and XGBOOST algorithms exhibit superior performance, achieving accuracies of 96.7% and 9.64% respectively. In contrast, the SVM algorithm demonstrates inferior performance with a R2 of 81.1%. These findings underscore the predictive capability of the RF and XGBOOST model in forecasting Predicted Mean Vote (PMV) values. The proposed model holds promise for enhancing occupant thermal comfort in buildings while simultaneously optimizing energy consumption in HVAC systems. Further research could explore the practical applications of these findings in building design and operation.","['Support Vector Machine (SVM)', 'Artificial Neural Network (ANN)', 'Random Forest (RF)', 'EXtreme Gradient Boosting (XGBOOST)']"
2024,https://openalex.org/W4400020165,Engineering,"Big data, machine learning, and digital twin assisted additive manufacturing: A review","Additive manufacturing (AM) has undergone significant development over the past decades, resulting in vast amounts of data that carry valuable information. Numerous research studies have been conducted to extract insights from AM data and utilize it for optimizing various aspects such as the manufacturing process, supply chain, and real-time monitoring. Data integration into proposed digital twin frameworks and the application of machine learning techniques is expected to play pivotal roles in advancing AM in the future. In this paper, we provide an overview of machine learning and digital twin-assisted AM. On one hand, we discuss the research domain and highlight the machine-learning methods utilized in this field, including material analysis, design optimization, process parameter optimization, defect detection and monitoring, and sustainability. On the other hand, we examine the status of digital twin-assisted AM from the current research status to the technical approach and offer insights into future developments and perspectives in this area. This review paper aims to examine present research and development in the convergence of big data, machine learning, and digital twin-assisted AM. Although there are numerous review papers on machine learning for additive manufacturing and others on digital twins for AM, no existing paper has considered how these concepts are intrinsically connected and interrelated. Our paper is the first to integrate the three concepts big data, machine learning, and digital twins and propose a cohesive framework for how they can work together to improve the efficiency, accuracy, and sustainability of AM processes. By exploring latest advancements and applications within these domains, our objective is to emphasize the potential advantages and future possibilities associated with integration of these technologies in AM.",['machine learning']
2024,https://openalex.org/W4390494339,Engineering,"A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection in Industrial Time Series: Methods, Applications, and Directions","Automating the monitoring of industrial processes has the potential to enhance efficiency and optimize quality by promptly detecting abnormal events and thus facilitating timely interventions. Deep learning, with its capacity to discern non-trivial patterns within large datasets, plays a pivotal role in this process. Standard deep learning methods are suitable to solve a specific task given a specific type of data. During training, deep learning demands large volumes of labeled data. However, due to the dynamic nature of the industrial processes and environment, it is impractical to acquire large-scale labeled data for standard deep learning training for every slightly different case anew. Deep transfer learning offers a solution to this problem. By leveraging knowledge from related tasks and accounting for variations in data distributions, the transfer learning framework solves new tasks with little or even no additional labeled data. The approach bypasses the need to retrain a model from scratch for every new setup and dramatically reduces the labeled data requirement. This survey first provides an in-depth review of deep transfer learning, examining the problem settings of transfer learning and classifying the prevailing deep transfer learning methods. Moreover, we delve into applications of deep transfer learning in the context of a broad spectrum of time series anomaly detection tasks prevalent in primary industrial domains, e.g., manufacturing process monitoring, predictive maintenance, energy management, and infrastructure facility monitoring. We discuss the challenges and limitations of deep transfer learning in industrial contexts and conclude the survey with practical directions and actionable suggestions to address the need to leverage diverse time series data for anomaly detection in an increasingly dynamic production environment.","['deep learning', 'deep transfer learning', 'transfer learning framework']"
2024,https://openalex.org/W4399326707,Engineering,Enhancing precision agriculture: A comprehensive review of machine learning and AI vision applications in all-terrain vehicle for farm automation,"The automation of all-terrain vehicles (ATVs) through the integration of advanced technologies such as machine learning (ML) and artificial intelligence (AI) vision has significantly changed precision agriculture. This paper aims to analyse and develop trends to provide comprehensive knowledge of the current state of ATV-based precision agriculture and the future possibilities of ML and AI. A bibliometric analysis was conducted through network diagram with keywords taken from previous publications in the domain. This review comprehensively analyses the potential of machine learning and artificial intelligence in transforming farming operations through the automation of tasks and the deployment of all-terrain vehicles. The research extensively analyses how machine learning methods have influenced several aspects of agricultural activities, such as planting, harvesting, spraying, weeding, crop monitoring, and others. AI vision systems are being researched for their ability to enhance precise and prompt decision-making in ATV-driven agricultural automation. These technologies have been thoroughly tested to show how they can improve crop yield, reducing overall investment, and make farming more efficient. Examples include machine learning-based seeding accuracy, AI-enabled crop health monitoring, and the use of AI vision for accurate pesticide application. The assessment examines challenges such as data privacy problems and scalability constraints, along with potential advancements and future prospects in the field. This will assist researchers and practitioners in making well-informed judgments regarding farming practices that are efficient, sustainable, and technologically robust.",['machine learning']
2024,https://openalex.org/W4391332961,Engineering,A novel framework for developing environmentally sustainable and cost-effective ultra-high-performance concrete (UHPC) using advanced machine learning and multi-objective optimization techniques,"This study aims to propose a novel framework for strength prediction and multi-objective optimization (MOO) of economical and environmentally sustainable ultra-high-performance concrete (UHPC) which aids in intelligent, sustainable, and resilient construction. Different tree- and boosting ensemble-based machine learning (ML) models are integrated to form an accurate and reliable prediction model for the uniaxial compressive strength of UHPC. The optimized models are integrated into a super learner model, resulting in a robust predictive model that is used as one of the objective functions in the MOO problem. A total of 19 objective functions are considered, including cost, uniaxial compressive strength, and 17 environmental impact categories that comprehensively evaluate the environmental sustainability of the UHPC mix. The resulting impacts from the mid-point indicators were calculated using the Eco-invent v3.7 Life Cycle Inventory database. The results showed that the super learner model accurately predicted the uniaxial compressive strength of UHPC. The MOO resulted in Pareto fronts, demonstrating the trade-off among the uniaxial compressive strength, cost, and environmental sustainability of the mix and a broad range of solutions that can be obtained for the 19 objectives. The study provides a useful tool for designers and decision-makers to select the optimal UHPC mixture that meets specific project requirements. Finally, for the practical application of the ML predictive model and MOO algorithm for UHPC, a graphical user interface-based software tool, FAI-OSUSCONCRET, was developed. This software tool offers fast, accurate, and intelligent predictions and multi-objective optimizations tailored to specific project requirements, thus resulting in a UHPC mixture that perfectly meets project needs.","['tree-based ensemble machine learning models', 'boosting ensemble-based machine learning models', 'super learner model']"
2024,https://openalex.org/W4391168980,Engineering,Utilizing Hybrid Machine Learning and Soft Computing Techniques for Landslide Susceptibility Mapping in a Drainage Basin,"The hydrological system of thebasin of Lake Urmia is complex, deriving its supply from a network comprising 13 perennial rivers, along withnumerous small springs and direct precipitation onto the lake’s surface. Among these contributors, approximately half of the inflow is attributed to the Zarrineh River and the Simineh River. Remarkably, Lake Urmia lacks a natural outlet, with its water loss occurring solely through evaporation processes. This study employed a comprehensive methodology integrating ground surveys, remote sensing analyses, and meticulous documentation of historical landslides within the basin as primary information sources. Through this investigative approach, we preciselyidentified and geolocated a total of 512 historical landslide occurrences across the Urmia Lake drainage basin, leveraging GPS technology for precision. Thisarticle introduces a suite of hybrid machine learning predictive models, such as support-vector machine (SVM), random forest (RF), decision trees (DT), logistic regression (LR), fuzzy logic (FL), and the technique for order of preference by similarity to the ideal solution (TOPSIS). These models were strategically deployed to assess landslide susceptibility within the region. The outcomes of the landslide susceptibility assessment reveal that the main high susceptible zones for landslide occurrence are concentrated in the northwestern, northern, northeastern, and some southern and southeastern areas of the region. Moreover, when considering the implementation of predictions using different algorithms, it became evident that SVM exhibited superior performance regardingboth accuracy (0.89) and precision (0.89), followed by RF, with and accuracy of 0.83 and a precision of 0.83. However, it is noteworthy that TOPSIS yielded the lowest accuracy value among the algorithms assessed.","['support-vector machine (SVM)', 'random forest (RF)', 'decision trees (DT)', 'logistic regression (LR)']"
2024,https://openalex.org/W4391831565,Engineering,Comparison of Random Forest and XGBoost Classifiers Using Integrated Optical and SAR Features for Mapping Urban Impervious Surface,"The integration of optical and SAR datasets through ensemble machine learning models shows promising results in urban remote sensing applications. The integration of multi-sensor datasets enhances the accuracy of information extraction. This research presents a comparison of two ensemble machine learning classifiers (random forest and extreme gradient boost (XGBoost)) classifiers using an integration of optical and SAR features and simple layer stacking (SLS) techniques. Therefore, Sentinel-1 (SAR) and Landsat 8 (optical) datasets were used with SAR textures and enhanced modified indices to extract features for the year 2023. The classification process utilized two machine learning algorithms, random forest and XGBoost, for urban impervious surface extraction. The study focused on three significant East Asian cities with diverse urban dynamics: Jakarta, Manila, and Seoul. This research proposed a novel index called the Normalized Blue Water Index (NBWI), which distinguishes water from other features and was utilized as an optical feature. Results showed an overall accuracy of 81% for UIS classification using XGBoost and 77% with RF while classifying land use land cover into four major classes (water, vegetation, bare soil, and urban impervious). However, the proposed framework with the XGBoost classifier outperformed the RF algorithm and Dynamic World (DW) data product and comparatively showed higher classification accuracy. Still, all three results show poor separability with bare soil class compared to ground truth data. XGBoost outperformed random forest and Dynamic World in classification accuracy, highlighting its potential use in urban remote sensing applications.","['ensemble machine learning models', 'random forest', 'extreme gradient boost (XGBoost)']"
2024,https://openalex.org/W4390511794,Engineering,Firefly algorithm based WSN-IoT security enhancement with machine learning for intrusion detection,"Abstract A Wireless Sensor Network (WSN) aided by the Internet of Things (IoT) is a collaborative system of WSN systems and IoT networks are work to exchange, gather, and handle data. The primary objective of this collaboration is to enhance data analysis and automation to facilitate improved decision-making. Securing IoT with the assistance of WSN necessitates the implementation of protective measures to confirm the safety and reliability of the interconnected WSN and IoT components. This research significantly advances the current state of the art in IoT and WSN security by synergistically harnessing the potential of machine learning and the Firefly Algorithm. The contributions of this work are twofold: firstly, the proposed FA-ML technique exhibits an exceptional capability to enhance intrusion detection accuracy within the WSN-IoT landscape. Secondly, the amalgamation of the Firefly Algorithm and machine learning introduces a novel dimension to the domain of security-oriented optimization techniques. The implications of this research resonate across various sectors, ranging from critical infrastructure protection to industrial automation and beyond, where safeguarding the integrity of interconnected systems are of paramount importance. The amalgamation of cutting-edge machine learning and bio-inspired algorithms marks a pivotal step forward in crafting robust and intelligent security measures for the evolving landscape of IoT-driven technologies. For intrusion detection in the WSN-IoT, the FA-ML method employs a support vector machine (SVM) machine model for classification with parameter tuning accomplished using a Grey Wolf Optimizer (GWO) algorithm. The experimental evaluation is simulated using NSL-KDD Dataset, revealing the remarkable enhancement of the FA-ML technique, achieving a maximum accuracy of 99.34%. In comparison, the KNN-PSO and XGBoost models achieved lower accuracies of 96.42% and 95.36%, respectively. The findings validate the potential of the FA-ML technique as an active security solution for WSN-IoT systems, harnessing the power of machine learning and the Firefly Algorithm to bolster intrusion detection capabilities.","['Firefly Algorithm', 'machine learning', 'support vector machine (SVM)', 'Grey Wolf Optimizer (GWO)', 'XGBoost']"
2024,https://openalex.org/W4391512775,Engineering,Peak and ultimate stress-strain model of confined ultra-high-performance concrete (UHPC) using hybrid machine learning model with conditional tabular generative adversarial network,"Ultra-high-performance concrete (UHPC) has gained prominence owing to its exceptional physical and mechanical properties and improved sustainability, making it ideal for large-scale structural applications. While numerous analytical studies have focused on predicting the stress-strain response of unconfined UHPC, there remains a lack of a reliable model for predicting the stress-strain response of confined UHPC, which poses challenges to efficient design and broader adoption, particularly in seismically active regions. To bridge this gap, the present study introduces a framework that implements machine learning (ML) models augmented by a state-of-the-art conditional tabular generative adversarial network (CTGAN) and Optuna, which a next-generation optimization framework, to accurately predict the peak and ultimate axial stress-strain responses of UHPC confined with either normal-strength steel or high-strength steel. The Optuna-optimized CTGAN is employed to address the issue of limited data by generating synthetic datasets of hypothetical confined UHPC specimens. A comprehensive database of confined UHPC stress-strain responses was compiled from existing literature and used to condition the CTGAN. The augmented database is then leveraged to develop a hybrid ML model that integrates extreme gradient boosting, gradient boosting machine, support vector regression, and K-nearest neighbors for predicting peak and ultimate stress-strain responses of confined UHPC. The predictive accuracy of the proposed hybrid ML model is evaluated and compared with a diverse set of ML models of varying complexity, and the results demonstrate its superior performance in predicting the peak and ultimate stress-strain response of confined UHPC. Furthermore, a graphical user interface of the proposed model is developed to facilitate its practical implementation and provide a rapid, autonomous, and accurate prediction of the stress-strain response of confined UHPC at both peak and ultimate states.","['conditional tabular generative adversarial network (CTGAN)', 'extreme gradient boosting', 'gradient boosting machine', 'support vector regression', 'K-nearest neighbors']"
2024,https://openalex.org/W4393001808,Engineering,Multi-Source and Multi-modal Deep Network Embedding for Cross-Network Node Classification,"In recent years, to address the issue of networked data sparsity in node classification tasks, cross-network node classification (CNNC) leverages the richer information from a source network to enhance the performance of node classification in the target network, which typically has sparser information. However, in real-world applications, labeled nodes may be collected from multiple sources with multiple modalities (e.g., text, vision, and video). Naive application of single-source and single-modal CNNC methods may result in sub-optimal solutions. To this end, in this article, we propose a model called Multi-source and Multi-modal Cross-network Deep Network Embedding (M 2 CDNE) for cross-network node classification. In M 2 CDNE, we propose a deep multi-modal network embedding approach that combines the extracted deep multi-modal features to make the node vector representations network invariant. In addition, we apply dynamic adversarial adaptation to assess the significance of marginal and conditional probability distributions between each source and target network to make node vector representations label discriminative. Furthermore, we devise to classify nodes in the target network through the related source classifier and aggregate different predictions utilizing respective network weights, corresponding to the discrepancy between each source and target network. Extensive experiments performed on real-world datasets demonstrate that the proposed M 2 CDNE significantly outperforms the state-of-the-art approaches.",['deep multi-modal network embedding']
2024,https://openalex.org/W4390533101,Engineering,A vehicular network based intelligent transport system for smart cities using machine learning algorithms,"Abstract Smart cities and the Internet of Things have enabled the integration of communicating devices for efficient decision-making. Notably, traffic congestion is one major problem faced by daily commuters in urban cities. In developed countries, specialized sensors are deployed to gather traffic information to predict traffic patterns. Any traffic updates are shared with the commuters via the Internet. Such solutions become impracticable when physical infrastructure and Internet connectivity are either non-existent or very limited. In case of developing countries, no roadside units are available and Internet connectivity is still an issue in remote areas. Internet traffic analysis is a thriving field of study due to the myriad ways in which it may be put to practical use. In the intelligent Internet-of-Vehicles (IOVs), traffic congestion can be predicted and identified using cutting-edge technologies. Using tree-based decision-tree, random-forest, extra-tree, and XGBoost machine learning (ML) strategies, this research proposes an intelligent-transport-system for the IOVs-based vehicular network traffic in a smart city set-up. The suggested system uses ensemble learning and averages the selection of crucial features to give high detection accuracy at minimal computational costs, as demonstrated by the simulation results. For IOV-based vehicular network traffic, the tree-based ML approaches with feature-selection (FS) outperformed those without FS. When contrasted to the lowest KNN accuracy of 96.6% and the highest SVM accuracy of 98.01%, the Stacking approach demonstrates superior accuracy as 99.05%.","['decision-tree', 'random-forest', 'extra-tree', 'XGBoost', 'ensemble learning', 'feature-selection (FS)', 'KNN', 'SVM', 'Stacking']"
2024,https://openalex.org/W4390817508,Engineering,Conventional to Deep Ensemble Methods for Hyperspectral Image Classification: A Comprehensive Survey,"Hyperspectral image classification has become a hot research topic. HSI has been widely used in a wide range of real-world application areas due to the in-depth spectral information stored within each pixel. Noticeably, the detailed features - i.e., a nonlinear correlation between the obtained spectral data and the correlating HSI data object, generate efficient classification results that are complex for traditional techniques. Deep Learning (DL) has recently been validated as an influential feature extractor that efficiently identifies the nonlinear issues that have arisen in various computer vision challenges. This motivates using DL for Hyperspectral Image Classification (HSIC), which shows promising results. This survey provides a brief description of DL for HSIC and compares cutting-edge methodologies in the field. We will first summarize the key challenges for HSIC, and then we will discuss the superiority of DL and DL-ensemble in addressing these issues. In this article, we divide the state-of-the-art DL methodologies and DL with ensemble into spectral features, spatial features, and combined spatial-spectral features in order to comprehensively and critically evaluate the progress (future research directions as well) of such methodologies for HSIC. Furthermore, we will take into account that DL involves a substantial percentage of labeled training images, whereas obtaining such a number for HSI is time and cost-consuming. As a result, this survey describes some methodologies for improving the classification performance of DL techniques, which can serve as future recommendations.",['Deep Learning (DL)']
2024,https://openalex.org/W4391301691,Engineering,AI-Driven Digital Twin Model for Reliable Lithium-Ion Battery Discharge Capacity Predictions,"The present study proposes a novel method for predicting the discharge capabilities of lithium-ion (Li-ion) batteries using a digital twin model in practice. By combining cutting-edge machine learning techniques, such as AdaBoost and long short-term memory (LSTM) network, with a semiempirical mathematical structure, the digital twin (DT)—a virtual representation that mimics the behavior of actual batteries in real time is constructed. Various metaheuristic optimization methods, such as antlion, grey wolf optimization (GWO), and improved grey wolf optimization (IGWO), are used to adjust hyperparameters in order to optimize the models. As indicators of performance, mean absolute error (MAE) and root-mean-square error (RMSE) are applied to the models after they have undergone extensive training and ten-fold cross-validation. The models are rigorously trained and cross-validated using the NASA battery aging dataset, a widely accepted benchmark dataset for battery research. The IGWO-AdaBoost digital twin model emerges as the standout performer, achieving exceptional accuracy in predicting the discharge capacity. This model demonstrates the lowest mean absolute error (MAE) of 0.01, showcasing its superior precision in estimating discharge capabilities. Additionally, the root mean square error (RMSE) for the IGWO-AdaBoost DT model is also the lowest at 0.01. The findings of this study offer insightful information about the potential utilization of the digital twin model to accurately predict the discharge capacity of batteries.","['AdaBoost', 'long short-term memory (LSTM) network', 'antlion optimization', 'grey wolf optimization (GWO)', 'improved grey wolf optimization (IGWO)']"
2024,https://openalex.org/W4390667445,Engineering,Automated data processing and feature engineering for deep learning and big data applications: A survey,"Modern approach to artificial intelligence (AI) aims to design algorithms that learn directly from data. This approach has achieved impressive results and has contributed significantly to the progress of AI, particularly in the sphere of supervised deep learning. It has also simplified the design of machine learning systems as the learning process is highly automated. However, not all data processing tasks in conventional deep learning pipelines have been automated. In most cases data has to be manually collected, preprocessed and further extended through data augmentation before they can be effective for training. Recently, special techniques for automating these tasks have emerged. The automation of data processing tasks is driven by the need to utilize large volumes of complex, heterogeneous data for machine learning and big data applications. Today, end-to-end automated data processing systems based on automated machine learning (AutoML) techniques are capable of taking raw data and transforming them into useful features for Big Data tasks by automating all intermediate processing stages. In this work, we present a thorough review of approaches for automating data processing tasks in deep learning pipelines, including automated data preprocessing– e.g., data cleaning, labeling, missing data imputation, and categorical data encoding–as well as data augmentation (including synthetic data generation using generative AI methods) and feature engineering–specifically, automated feature extraction, feature construction and feature selection. In addition to automating specific data processing tasks, we discuss the use of AutoML methods and tools to simultaneously optimize all stages of the machine learning pipeline.","['supervised deep learning', 'automated machine learning (AutoML)', 'synthetic data generation using generative AI methods', 'feature construction', 'feature selection']"
2024,https://openalex.org/W4392980686,Engineering,Data-driven evolution of water quality models: An in-depth investigation of innovative outlier detection approaches-A case study of Irish Water Quality Index (IEWQI) model,"Recently, there has been a significant advancement in the water quality index (WQI) models utilizing data-driven approaches, especially those integrating machine learning and artificial intelligence (ML/AI) technology. Although, several recent studies have revealed that the data-driven model has produced inconsistent results due to the data outliers, which significantly impact model reliability and accuracy. The present study was carried out to assess the impact of data outliers on a recently developed Irish Water Quality Index (IEWQI) model, which relies on data-driven techniques. To the author's best knowledge, there has been no systematic framework for evaluating the influence of data outliers on such models. For the purposes of assessing the outlier impact of the data outliers on the water quality (WQ) model, this was the first initiative in research to introduce a comprehensive approach that combines machine learning with advanced statistical techniques. The proposed framework was implemented in Cork Harbour, Ireland, to evaluate the IEWQI model's sensitivity to outliers in input indicators to assess the water quality. In order to detect the data outlier, the study utilized two widely used ML techniques, including Isolation Forest (IF) and Kernel Density Estimation (KDE) within the dataset, for predicting WQ with and without these outliers. For validating the ML results, the study used five commonly used statistical measures. The performance metric (R2) indicates that the model performance improved slightly (R2 increased from 0.92 to 0.95) in predicting WQ after removing the data outlier from the input. But the IEWQI scores revealed that there were no statistically significant differences among the actual values, predictions with outliers, and predictions without outliers, with a 95% confidence interval at p < 0.05. The results of model uncertainty also revealed that the model contributed <1% uncertainty to the final assessment results for using both datasets (with and without outliers). In addition, all statistical measures indicated that the ML techniques provided reliable results that can be utilized for detecting outliers and their impacts on the IEWQI model. The findings of the research reveal that although the data outliers had no significant impact on the IEWQI model architecture, they had moderate impacts on the rating schemes' of the model. This finding indicated that detecting the data outliers could improve the accuracy of the IEWQI model in rating WQ as well as be helpful in mitigating the model eclipsing problem. In addition, the results of the research provide evidence of how the data outliers influenced the data-driven model in predicting WQ and reliability, particularly since the study confirmed that the IEWQI model's could be effective for accurately rating WQ despite the presence of the data outliers in the input. It could occur due to the spatio-temporal variability inherent in WQ indicators. However, the research assesses the influence of data input outliers on the IEWQI model and underscores important areas for future investigation. These areas include expanding temporal analysis using multi-year data, examining spatial outlier patterns, and evaluating detection methods. Moreover, it is essential to explore the real-world impacts of revised rating categories, involve stakeholders in outlier management, and fine-tune model parameters. Analysing model performance across varying temporal and spatial resolutions and incorporating additional environmental data can significantly enhance the accuracy of WQ assessment. Consequently, this study offers valuable insights to strengthen the IEWQI model's robustness and provides avenues for enhancing its utility in broader WQ assessment applications. Moreover, the study successfully adopted the framework for evaluating how data input outliers affect the data-driven model, such as the IEWQI model. The current study has been carried out in Cork Harbour for only a single year of WQ data. The framework should be tested across various domains for evaluating the response of the IEWQI model's in terms of the spatio-temporal resolution of the domain. Nevertheless, the study recommended that future research should be conducted to adjust or revise the IEWQI model's rating schemes and investigate the practical effects of data outliers on updated rating categories. However, the study provides potential recommendations for enhancing the IEWQI model's adaptability and reveals its effectiveness in expanding its applicability in more general WQ assessment scenarios.",['Isolation Forest (IF)']
2024,https://openalex.org/W4391226403,Engineering,Machine learning for multi-dimensional performance optimization and predictive modelling of nanopowder-mixed electric discharge machining (EDM),"Abstract Aluminium 6061 (Al6061) is a widely used material for various industrial applications due to low density and high strength. Nevertheless, the conventional machining operations are not the best choice for the machining purposes. Therefore, amongst all the non-conventional machining operations, electric discharge machining (EDM) is opted to carry out the research due to its wide ability to cut the materials. But the high electrode wear rate (EWR) and high dimensional inaccuracy or overcut (OC) of EDM limit its usage. Consequently, nanopowder is added to the dielectric medium to address the abovementioned issues. Nanopowder mixed EDM (NPMEDM) process is a complex process in terms of performance predictability for different materials. Similarly, the interactions between the process parameters such as peak current ( I p ), spark voltage ( S v ), pulse on time ( P on ) and powder concentration ( C p ) in dielectric enhance the parametric sensitivity. In addition, the cryogenic treatment (CT) of electrodes makes the process complex limiting conventional simulation approaches for modelling inter-relationships. An alternative approach requires experimental exploration and systematic investigation to model EWR and overcutting problems of EDM. Thus, artificial neural networks (ANNs) are used for predictive modelling of the process which are integrated with multi-objective genetic algorithm (MOGA) for parametric optimization. The approach uses experimental data based on response surface methodology (RSM) design of experiments. Moreover, the process physics is thoroughly discussed with parametric effect analysis supported with evidence of microscopic images, scanning electron microscopy (SEM) and 3D surface topographic images. Based on multi-dimensional optimization results, the NT brass electrode showed an improvement of 65.02% in EWR and 59.73% in OC using deionized water. However, CT brass electrode showed 78.41% reduction in EWR and 67.79% improved dimensional accuracy in deionized water. In addition to that, CT brass electrode gave 27.69% less EWR and 81.40% improved OC in deionized water compared to kerosene oil.","['artificial neural networks (ANNs)', 'multi-objective genetic algorithm (MOGA)']"
2024,https://openalex.org/W4394015596,Engineering,Predicting the mechanical properties of plastic concrete: An optimization method by using genetic programming and ensemble learners,"This study presents a comparative analysis of individual and ensemble learning algorithms (ELAs) to predict the compressive strength (CS) and flexural strength (FS) of plastic concrete. Multilayer perceptron neuron network (MLPNN), Support vector machine (SVM), random forest (RF), and decision tree (DT) were used as base learners, which were then combined with bagging and Adaboost methods to improve the predictive performance. In addition, gene expression programming (GEP) was used to develop computational equations that can be used to predict the CS and FS of plastic concrete. An extensive database containing 357 and 125 data points was obtained from the literature, and the eight most impactful ingredients were used in the model's development. The accuracy of all models was assessed using several statistical measures, including an error matrix, Akaike information criterion (AIC), K-fold cross-validation, and other external validation equations. Furthermore, sensitivity and SHAP analysis were performed to evaluate input variables' relative significance and impact on the anticipated CS and FS. Based on statistical measures and other validation criteria, GEP outpaces all other individual models, whereas, in ELAs, the SVR ensemble with Adaboost and RF modified with the Bagging technique demonstrated superior performance. SHapley Additive exPlanations (SHAP) and sensitivity analysis reveal that plastic, cement, water, and the age of the specimens have the highest influence, while superplasticizer has the lowest impact, which is consistent with experimental studies. Moreover, GUI and GEP-based simple mathematical correlation can enhance the practical scope of this study and be an effective tool for the pre-mix design of plastic concrete.","['Multilayer perceptron neuron network (MLPNN)', 'Support vector machine (SVM)', 'random forest (RF)', 'decision tree (DT)', 'bagging', 'Adaboost', 'gene expression programming (GEP)', 'SVR ensemble with Adaboost']"
2024,https://openalex.org/W4391855187,Engineering,Machine learning-assisted in-situ adaptive strategies for the control of defects and anomalies in metal additive manufacturing,"In metal additive manufacturing (AM), the material microstructure and part geometry are formed incrementally. Consequently, the resulting part could be defect- and anomaly-free if sufficient care is taken to deposit each layer under optimal process conditions. Conventional closed-loop control (CLC) engineering solutions which sought to achieve this were deterministic and rule-based, thus resulting in limited success in the stochastic environment experienced in the highly dynamic AM process. On the other hand, emerging machine learning (ML) based strategies are better suited to providing the robustness, scope, flexibility, and scalability required for process control in an uncertain environment. Offline ML models that help optimise AM process parameters before a build begins and online ML models that efficiently processed in-situ sensory data to detect and diagnose flaws in real-time (or near-real-time) have been developed. However, ML models that enable a process to take evasive or corrective actions in relation to flaws via on the fly decision-making are only emerging. These models must possess prognostic capabilities to provide context-sensitive recommendations for in-situ process control based on real-time diagnostics. In this article, we pinpoint the shortcomings in traditional CLC strategies, and provide a framework for defect and anomaly control through ML-assisted CLC in AM. We discuss flaws in terms of their causes, in-situ detectability, and controllability, and examine their management under three scenarios: avoidance, mitigation, and repair. Then, we summarise the research into ML models developed for offline optimisation and in-situ diagnosis before initiating a detailed conversation on the implementation of ML-assisted in-situ process control. We found that researchers favoured reinforcement learning approaches or inverse ML models for making rapid, situation-aware control decisions. We also observed that, to-date, the defects addressed were those that may be quantified relatively easily autonomously, and that mitigation (rather than avoidance or repair) was the aim of ML-assisted in-situ control strategies. Additionally, we highlight the various technologies that must seamlessly combine to advance the field of autonomous in-situ control so that it becomes a reality in industrial settings. Finally, we raise awareness of seldom discussed, yet highly pertinent, topics relevant to adaptive control. Our work closes a significant gap in the current AM literature by broaching wide-ranging discussions on matters relevant to in-situ adaptive control in AM.","['online ML models', 'reinforcement learning approaches']"
2024,https://openalex.org/W4392640075,Engineering,Performance assessment of machine learning algorithms for mapping of land use/land cover using remote sensing data,"The rapid increase in population accelerates the rate of change of Land use/Land cover (LULC) in various parts of the world. This phenomenon caused a huge strain for natural resources. Hence, continues monitoring of LULC changes gained a significant importance for management of natural resources and assessing the climate change impacts. Recently, application of machine learning algorithms on RS (remote sensing) data for rapid and accurate mapping of LULC gained significant importance due to growing need of LULC estimation for ecosystem services, natural resource management and environmental management. Hence, it is crucial to access and compare the performance of different machine learning classifiers for accurate mapping of LULC. The primary objective of this study was to compare the performance of CART (Classification and Regression Tree), RF (Random Forest) and SVM (Support Vector Machine) for LULC estimation by processing RS data on Google Earth Engine (GEE). In total four classes of LULC (Water Bodies, Vegetation Cover, Urban Land and Barren Land) for city of Lahore were extracted using satellite images from Landsat-7, Landsat-8 and Landsat-9 for years 2008, 2015 and 2022, respectively. According to results, RF is the best performing classifier with maximum overall accuracy of 95.2% and highest Kappa coefficient value of 0.87, SVM achieved maximum accuracy of 89.8% with highest Kappa of 0.84 and CART showed maximum overall accuracy of 89.7% with Kappa value of 0.79. Results from this study can give assistance for decision makers, planners and RS experts to choose a suitable machine learning algorithm for LULC classification in an unplanned urbanized city like Lahore.","['Classification and Regression Tree (CART)', 'Random Forest (RF)', 'Support Vector Machine (SVM)']"
2024,https://openalex.org/W4390754233,Engineering,Groundwater Quality Assessment and Irrigation Water Quality Index Prediction Using Machine Learning Algorithms,"The evaluation of groundwater quality is crucial for irrigation purposes; however, due to financial constraints in developing countries, such evaluations suffer from insufficient sampling frequency, hindering comprehensive assessments. Therefore, associated with machine learning approaches and the irrigation water quality index (IWQI), this research aims to evaluate the groundwater quality in Naama, a region in southwest Algeria. Hydrochemical parameters (cations, anions, pH, and EC), qualitative indices (SAR,RSC,Na%,MH,and PI), as well as geospatial representations were used to determine the groundwater’s suitability for irrigation in the study area. In addition, efficient machine learning approaches for forecasting IWQI utilizing Extreme Gradient Boosting (XGBoost), Support vector regression (SVR), and K-Nearest Neighbours (KNN) models were implemented. In this research, 166 groundwater samples were used to calculate the irrigation index. The results showed that 42.18% of them were of excellent quality, 34.34% were of very good quality, 6.63% were good quality, 9.64% were satisfactory, and 4.21% were considered unsuitable for irrigation. On the other hand, results indicate that XGBoost excels in accuracy and stability, with a low RMSE (of 2.8272 and a high R of 0.9834. SVR with only four inputs (Ca2+, Mg2+, Na+, and K) demonstrates a notable predictive capability with a low RMSE of 2.6925 and a high R of 0.98738, while KNN showcases robust performance. The distinctions between these models have important implications for making informed decisions in agricultural water management and resource allocation within the region.","['Extreme Gradient Boosting (XGBoost)', 'Support Vector Regression (SVR)', 'K-Nearest Neighbours (KNN)']"
2024,https://openalex.org/W4391248672,Engineering,Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning,"Recent development in computing power has resulted in performance improvements on holistic(none-occluded) person Re-Identification (ReID) tasks. Nevertheless, the precision of the recent research will diminish when a pedestrian is obstructed by obstacles. Within the realm of 2D space, the loss of information from obstructed objects continues to pose significant challenges in the context of person ReID. Person is a 3D non-grid object, and thus semantic representation learning in only 2D space limits the understanding of occluded person. In the present work, we propose a network based on 3D multi-view learning, allowing it to acquire geometric and shape details of an occluded pedestrian from 3D space. Simultaneously, it capitalizes on advancements in 2D-based networks to extract semantic representations from 3D multi-views. Specifically, the surface random selection strategy is proposed to convert images of 2D RGB into 3D multi-views. Using this strategy, we build four extensive 3D multi-view data collections for person ReID. After that, Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning(MV-3DSReID), is proposed for identifying the person by learning person geometry and structure representation from the groups of multi-view images. In comparison to alternative data formats (e.g., 2D RGB, 3D point cloud), multi-view images complement each other's detailed features of the 3D object by adjusting rendering viewpoints, thus facilitating a more comprehensive understanding of the person for both holistic and occluded ReID situations. Experiments on occluded and holistic ReID tasks demonstrate performance levels comparable to state-of-the-art methods, validating the effectiveness of our proposed approach in tackling challenges related to occlusion. The code is available at https://github.com/hangjiaqi1/MV-TransReID.",['3D multi-view learning']
2024,https://openalex.org/W4391973098,Engineering,The use of machine learning techniques to investigate the properties of metakaolin-based geopolymer concrete,"The construction industry significantly contributes to global greenhouse gas emissions, highlighting the imperative for developing environmentally friendly construction materials. Geopolymers, particularly those utilizing metakaolin (MK), have emerged as a promising green alternative to conventional concrete. However, the acquisition of MK-based geopolymer concrete with optimal mechanical properties poses challenges due to numerous influential factors, disagreement over various findings, and the lack of a reliable predictive model. This study aimed to address this gap by employing a wide range of machine learning methods, namely gradient boosting machine, random forest, decision tree, artificial neural network, and support vector machine. Different optimization and regularization techniques were used to comprehensively understand the factors affecting the compressive strength of MK-based geopolymer concrete, including mixture design, chemical characteristics of the initial binder and activators, and different curing regimes. The results demonstrated the exceptional performance of the gradient boosting machine in predicting the compressive strength of MK-based geopolymer concrete, achieving a coefficient of determination of 0.983 and a mean absolute error of 1.615 MPa. Additionally, the study employed partial dependence plots, feature importance analysis, and SHapley Additive exPlanations (SHAP) to elucidate the proposed models. The coarse-to-fine aggregate ratio, H2O/Na2O molar ratio, extra water content, and sodium hydroxide concentration were identified as the most critical parameters affecting the compressive strength of MK-based geopolymer concrete. This research contributes to advancing the development of sustainable construction materials, streamlining experimental tasks, minimizing the need for labor and materials, improving time efficiency, and providing valuable insights for optimizing the design of MK-based geopolymer concrete.","['gradient boosting machine', 'random forest', 'decision tree', 'artificial neural network', 'support vector machine']"
2024,https://openalex.org/W4392529708,Engineering,A machine learning-based framework for clustering residential electricity load profiles to enhance demand response programs,"Load shapes derived from smart meter data are frequently employed to analyze daily energy consumption patterns, particularly in the context of applications like Demand Response (DR). Nevertheless, one of the most important challenges to this endeavor lies in identifying the most suitable consumer clusters with similar consumption behaviors. In this paper, we present a novel machine learning based framework in order to achieve optimal load profiling through a real case study, utilizing data from almost 5000 households in London. Four widely used clustering algorithms are applied specifically K-means, K-medoids, Hierarchical Agglomerative Clustering and Density-based Spatial Clustering. An empirical analysis as well as multiple evaluation metrics are leveraged to assess those algorithms. Following that, we redefine the problem as a probabilistic classification one, with the classifier emulating the behavior of a clustering algorithm, leveraging Explainable AI (xAI) to enhance the interpretability of our solution. According to the clustering algorithm analysis the optimal number of clusters for this case is seven. Despite that, our methodology shows that two of the clusters, almost 10% of the dataset, exhibit significant internal dissimilarity. As a result, these clusters have been excluded from consideration for DR programs. The scalability and versatility of our solution makes it an ideal choice for power utility companies aiming to segment their users for creating more targeted DR programs.","['K-means', 'K-medoids', 'Hierarchical Agglomerative Clustering', 'Density-based Spatial Clustering', 'probabilistic classification', 'Explainable AI (xAI)']"
2024,https://openalex.org/W4400937555,Engineering,The diagnostic and triage accuracy of the GPT-3 artificial intelligence model: an observational study,"BackgroundArtificial intelligence (AI) applications in health care have been effective in many areas of medicine, but they are often trained for a single task using labelled data, making deployment and generalisability challenging. How well a general-purpose AI language model performs diagnosis and triage relative to physicians and laypeople is not well understood.MethodsWe compared the predictive accuracy of Generative Pre-trained Transformer 3 (GPT-3)'s diagnostic and triage ability for 48 validated synthetic case vignettes (<50 words; sixth-grade reading level or below) of both common (eg, viral illness) and severe (eg, heart attack) conditions to a nationally representative sample of 5000 lay people from the USA who could use the internet to find the correct options and 21 practising physicians at Harvard Medical School. There were 12 vignettes for each of four triage categories: emergent, within one day, within 1 week, and self-care. The correct diagnosis and triage category (ie, ground truth) for each vignette was determined by two general internists at Harvard Medical School. For each vignette, human respondents and GPT-3 were prompted to list diagnoses in order of likelihood, and the vignette was marked as correct if the ground-truth diagnosis was in the top three of the listed diagnoses. For triage accuracy, we examined whether the human respondents' and GPT-3's selected triage was exactly correct according to the four triage categories, or matched a dichotomised triage variable (emergent or within 1 day vs within 1 week or self-care). We estimated GPT-3's diagnostic and triage confidence on a given vignette using a modified bootstrap resampling procedure, and examined how well calibrated GPT-3's confidence was by computing calibration curves and Brier scores. We also performed subgroup analysis by case acuity, and an error analysis for triage advice to characterise how its advice might affect patients using this tool to decide if they should seek medical care immediately.FindingsAmong all cases, GPT-3 replied with the correct diagnosis in its top three for 88% (42/48, 95% CI 75–94) of cases, compared with 54% (2700/5000, 53–55) for lay individuals (p<0.0001) and 96% (637/666, 94–97) for physicians (p=0·012). GPT-3 triaged 70% correct (34/48, 57–82) versus 74% (3706/5000, 73–75; p=0.60) for lay individuals and 91% (608/666, 89–93%; p<0.0001) for physicians. As measured by the Brier score, GPT-3 confidence in its top prediction was reasonably well calibrated for diagnosis (Brier score=0·18) and triage (Brier score=0·22). We observed an inverse relationship between case acuity and GPT-3 accuracy (p<0·0001) with a fitted trend line of –8·33% decrease in accuracy for every level of increase in case acuity. For triage error analysis, GPT-3 deprioritised truly emergent cases in seven instances.InterpretationA general-purpose AI language model without any content-specific training could perform diagnosis at levels close to, but below, physicians and better than lay individuals. We found that GPT-3's performance was inferior to physicians for triage, sometimes by a large margin, and its performance was closer to that of lay individuals. Although the diagnostic performance of GPT-3 was comparable to physicians, it was significantly better than a typical person using a search engine.FundingThe National Heart, Lung, and Blood Institute.",['Generative Pre-trained Transformer 3 (GPT-3)']
2024,https://openalex.org/W4390738871,Engineering,Internet of things sensors and support vector machine integrated intelligent irrigation system for agriculture industry,"Abstract Because there is more demand for freshwater around the world and the world’s population is growing at the same time, there is a severe lack of freshwater resources in the central part of the planet. The world’s current population of 7.2 billion people is expected to grow to over 9 billion by the year 2050. The vast majority of freshwater is used for things like cooking, cleaning, and farming. Most industrialised countries are in desperate need of smart irrigation systems, which are now a must-have because of how quickly technology is improving. In article presents IoT based Sensor integrated intelligent irrigation system for agriculture industry. IoT based humidity and soil sensors are used to collect soil related data. This data is stored in a centralized cloud. Features are selected by CFS algorithm. This will help in discarding irrelevant data. Clustering of data is performed by K means algorithm. This will help in keeping similar data together. Then classification model is build using the SVM, Random Forest and Naïve Bayes algorithm. Model is trained, validated and tested using the acquired data. Historical soil and humidity related data is also used in training the model. K-means SVM hybrid classifier is achieving better results for classification, prediction of water demand and saving fresh water by intelligent irrigation. K-means SVM hybrid classifier has achieved accuracy rate of 98.5 percent. Specificity, recall and precision of K-means SVM hybrid classifier is also higher than random forest and naïve bayes classifier.","['CFS algorithm', 'K means algorithm', 'SVM', 'Random Forest', 'Naïve Bayes algorithm']"
2024,https://openalex.org/W4393210635,Engineering,Energy and economic analysis of building integrated photovoltaic thermal system: Seasonal dynamic modeling assisted with machine learning-aided method and multi-objective genetic optimization,"Building integrated photovoltaic thermal (BIPV/T) systems offer a highly effective means of generating clean energy for both electricity and heating purposes in residential buildings. Hence, this article introduces a new BIPV/T system to optimally minimize the energy consumption of a household residential building. The meticulous design of the proposed BIPV/T system is accomplished through MATLAB/Simulink® dynamic modeling. Performance analysis for the BIPV/T system is performed under different seasonal conditions with in-depth techno-economic analyses to estimate the expected enhancement in the thermal, electrical, and economic performance of the system. Moreover, a sensitivity analysis is conducted to explore the impact of various factors on the energetic and economic performances of the proposed BIPV/T system. More so, the two-layer feed-forward back-propagation artificial neural network modeling is developed to accurately predict the hourly solar radiation and ambient temperature for the BIPV/T. Additionally, a multi-objective optimization using the NSGA-II method is also conducted for the minimization of the total BIPV/T plant area and maximization of the total efficiency and net thermal power of the system as well as to estimate the optimized operating conditions for input variables across different seasons within the provided ranges. The sensitivity analysis revealed that higher solar flux levels lead to increased electric output power of the BIPV/T plant, but total efficiency decreases due to higher thermal losses. Moreover, the proposed NSGA-II shows a feasible method to attain a maximum net thermal power and optimal total efficiency of 5320 W and 63% with a minimal total plant area of 32.89 m2 that attained a very low deviation index from the ideal solution. The levelised cost of electricity is obtained as 0.10 $/kWh under the optimal conditions. Thus, these findings offer valuable insights into the potential of BIPV/T systems as a sustainable and efficient energy solution for residential applications.",['two-layer feed-forward back-propagation artificial neural network']
2024,https://openalex.org/W4390607226,Engineering,RanMerFormer: Randomized vision transformer with token merging for brain tumor classification,"Brains are the control center of the nervous system in human bodies, and brain tumor is one of the most deadly diseases. Currently, magnetic resonance imaging (MRI) is the most effective way to brain tumors early detection in clinical diagnoses due to its superior imaging quality for soft tissues. Manual analysis of brain MRI is error-prone which depends on empirical experience and the fatigue state of the radiologists to a large extent. Computer-aided diagnosis (CAD) systems are becoming more and more impactful because they can provide accurate prediction results based on medical images with advanced techniques from computer vision. Therefore, a novel CAD method for brain tumor classification named RanMerFormer is presented in this paper. A pre-trained vision transformer is used as the backbone model. Then, a merging mechanism is proposed to remove the redundant tokens in the vision transformer, which improves computing efficiency substantially. Finally, a randomized vector functional-link serves as the head in the proposed RanMerFormer, which can be trained swiftly. All the simulation results are obtained from two public benchmark datasets, which reveal that the proposed RanMerFormer can achieve state-of-the-art performance for brain tumor classification. The trained RanMerFormer can be applied in real-world scenarios to assist in brain tumor diagnosis.","['pre-trained vision transformer', 'randomized vector functional-link']"
2024,https://openalex.org/W4399303474,Engineering,Improving Forest Above-Ground Biomass Estimation by Integrating Individual Machine Learning Models,"The accurate estimation of forest above-ground biomass (AGB) is crucial for sustainable forest management and tracking the carbon cycle of forest ecosystem. Machine learning algorithms have been proven to have great potential in forest AGB estimation with remote sensing data. Though many studies have demonstrated that a single machine learning model can produce highly accurate estimations of forest AGB in many situations, efforts are still required to explore the possible improvement in forest AGB estimation for a specific scenario under study. This study aims to investigate the performance of novel ensemble machine learning methods for forest AGB estimation and analyzes whether these methods are affected by forest types, independent variables, and spatial autocorrelation. Four well-known machine learning models (CatBoost, LightGBM, random forest (RF), and XGBoost) were compared for forest AGB estimation in the study using eight scenarios devised on the basis of two study regions, two variable types, and two validation strategies. Subsequently, a hybrid model combining the strengths of these individual models was proposed for forest AGB estimation. The findings indicated that no individual model outperforms the others in all scenarios. The RF model demonstrates superior performance in scenarios 5, 6, and 7, while the CatBoost model shows the best performance in the remaining scenarios. Moreover, the proposed hybrid model consistently has the best performance in all scenarios in spite of some uncertainties. The ensemble strategy developed in this study for the hybrid model substantially improves estimation accuracy and exhibits greater stability, effectively addressing the challenge of model selection encountered in the forest AGB forecasting process.","['CatBoost', 'LightGBM', 'random forest (RF)', 'XGBoost', 'ensemble machine learning methods']"
2024,https://openalex.org/W4391018616,Engineering,Short-term power load forecasting based on AC-BiLSTM model,"The practice of ultra-short-term power load forecasting serves as a critical strategy for enabling rapid response and real-time dispatch in power systems. By improving the accuracy of load forecasting, both the safety of power systems and the efficiency of electricity usage can be significantly enhanced. Addressing the challenges posed by the non-linear and temporal characteristics of grid load data, this study introduces a novel ultra-short-term power load forecasting model, integrating Convolutional Neural Networks (CNN), Bidirectional Long Short-Term Memory networks (BiLSTM), and an Attention mechanism, referred to as the AC-BiLSTM model. This innovative approach harnesses the power of CNN and BiLSTM to extract spatio-temporal features of load data, while the Attention mechanism allocates optimal weights to the hidden states of the BiLSTM model, thereby amplifying crucial historical load sequence data and minimizing information loss. The final output of the model is then determined through a fully connected layer. To validate the efficacy of this approach, an empirical study was conducted using real load data from a specific region. The results, obtained from two contrasting experimental scenarios, demonstrate a significant enhancement in forecasting accuracy. This finding underscores the potential of the AC-BiLSTM model as a reliable tool for both strategic planning and maintaining operational stability in power systems.","['Convolutional Neural Networks (CNN)', 'Bidirectional Long Short-Term Memory networks (BiLSTM)', 'Attention mechanism']"
2024,https://openalex.org/W4391178461,Engineering,Assessment of surrogate models for flood inundation: The physics-guided LSG model vs. state-of-the-art machine learning models,"Hydrodynamic models can accurately simulate flood inundation but are limited by their high computational demand that scales non-linearly with model complexity, resolution, and domain size. Therefore, it is often not feasible to use high-resolution hydrodynamic models for real-time flood predictions or when a large number of predictions are needed for probabilistic flood design. Computationally efficient surrogate models have been developed to address this issue. The recently developed Low-fidelity, Spatial analysis, and Gaussian Process Learning (LSG) model has shown strong performance in both computational efficiency and simulation accuracy. The LSG model is a physics-guided surrogate model that simulates flood inundation by first using an extremely coarse and simplified (i.e. low-fidelity) hydrodynamic model to provide an initial estimate of flood inundation. Then, the low-fidelity estimate is upskilled via Empirical Orthogonal Functions (EOF) analysis and Sparse Gaussian Process models to provide accurate high-resolution predictions. Despite the promising results achieved thus far, the LSG model has not been benchmarked against other surrogate models. Such a comparison is needed to fully understand the value of the LSG model and to provide guidance for future research efforts in flood inundation simulation. This study compares the LSG model to four state-of-the-art surrogate flood inundation models. The surrogate models are assessed for their ability to simulate the temporal and spatial evolution of flood inundation for events both within and beyond the range used for model training. The models are evaluated for three distinct case studies in Australia and the United Kingdom. The LSG model is found to be superior in accuracy for both flood extent and water depth, including when applied to flood events outside the range of training data used, while achieving high computational efficiency. In addition, the low-fidelity model is found to play a crucial role in achieving the overall superior performance of the LSG model.","['Gaussian Process Learning', 'Sparse Gaussian Process models']"
2024,https://openalex.org/W4391592188,Engineering,Prompt Engineering or Fine-Tuning? A Case Study on Phishing Detection with Large Language Models,"Large Language Models (LLMs) are reshaping the landscape of Machine Learning (ML) application development. The emergence of versatile LLMs capable of undertaking a wide array of tasks has reduced the necessity for intensive human involvement in training and maintaining ML models. Despite these advancements, a pivotal question emerges: can these generalized models negate the need for task-specific models? This study addresses this question by comparing the effectiveness of LLMs in detecting phishing URLs when utilized with prompt-engineering techniques versus when fine-tuned. Notably, we explore multiple prompt-engineering strategies for phishing URL detection and apply them to two chat models, GPT-3.5-turbo and Claude 2. In this context, the maximum result achieved was an F1-score of 92.74% by using a test set of 1000 samples. Following this, we fine-tune a range of base LLMs, including GPT-2, Bloom, Baby LLaMA, and DistilGPT-2—all primarily developed for text generation—exclusively for phishing URL detection. The fine-tuning approach culminated in a peak performance, achieving an F1-score of 97.29% and an AUC of 99.56% on the same test set, thereby outperforming existing state-of-the-art methods. These results highlight that while LLMs harnessed through prompt engineering can expedite application development processes, achieving a decent performance, they are not as effective as dedicated, task-specific LLMs.",['fine-tuning']
2024,https://openalex.org/W4391720077,Engineering,Artificial intelligence-based evaluation of the factors affecting the sales of an iron and steel company,"It is important to predict the sales of an iron and steel company and to identify the variables that influence these sales for future planning. The aim in this study was to identify and model the key factors that influence the sales volume of an iron and steel company using artificial neural networks (ANNs). We attempted to obtain an integrated result from the performance/sales levels of 5 models, to use the ANN approach with hybrid algorithms, and also to present an exemplary application in the base metals industry, where there is a limited number of studies. This study contributes to the literature as the first application of artificial intelligence methods in the iron and steel industry. The ANN models incorporated 6 macroeconomic variables and price-to-sales data and their results were evaluated. An ordinary least squares regression model was also used to facilitate the comparison of results, while gray relational analysis (GRA) was used to draw a comprehensive conclusion based on the ANN results. The results showed that the variables USD/TL exchange rate, product prices, and interest rates, in descending order, had the highest degree of influence in determining the sales of the iron and steel company. Furthermore, these variables are crucial for forecasting future sales and strategic planning. The study showed that the ANN outperformed classical regression models in terms of prediction accuracy. In the model applications conducted for 5 different product groups, it was observed that 3 models (models 2, 3, and 4), including model 4, which sold a higher volume of products than the total of the other products, had an overall performance above 80%. In addition, GRA was found to be a valuable tool for synthesizing insights from different ANN models based on their respective performance levels.","['artificial neural networks (ANNs)', 'ordinary least squares regression model']"
2024,https://openalex.org/W4391997375,Engineering,A machine learning approach to predict the efficiency of corrosion inhibition by natural product-based organic inhibitors,"Abstract This paper presents a quantitative structure–property relationship (QSPR)-based machine learning (ML) framework designed for predicting corrosion inhibition efficiency (CIE) values in natural organic inhibitor compounds. The modeling dataset comprises 50 natural organic compounds, with 11 quantum chemical properties (QCP) serving as input features, and the target variable being the corrosion inhibition efficiency (CIE) value. To enhance the predictive accuracy of the ML model, the kernel density estimation (KDE) function is employed to generate virtual samples during the training process, with the overarching goal of refining the precision of the ML model. Three distinct models, namely random forest (RF), gradient boosting (GB), and k-nearest neighbor (KNN), are tested in the study. The results demonstrate a noteworthy enhancement in the prediction performance of the models, attributable to the incorporation of virtual samples that effectively improve the correlation between input features and target values. Consequently, the accuracy of the predicted CIE values is significantly augmented, aligning more closely with the actual CIE values. Performance improvements were evident across all models after the incorporation of virtual samples. The GB, RF, and KNN models exhibited increments in R 2 values from 0.557 to 0.996, 0.522 to 0.999, and 0.415 to 0.994, respectively, concomitant with the introduction of 500 virtual samples. Additionally, each model demonstrated a notable reduction in RMSE values, transitioning from 1.41 to 0.19, 1.27 to 0.10, and 1.22 to 0.16, respectively. While the GB model initially outperformed others before the addition of virtual samples, the performance of the model exhibited fluctuation as the number of virtual samples varied. This behavior suggests that the KDE function provides a certain level of resilience against model variations. The proposed approach contributes to the effective design and exploration of corrosion inhibitor candidates, offering a reliable and accurate predictive tool that bridges the gap between theoretical studies and experimental synthesis.","['random forest (RF)', 'gradient boosting (GB)', 'k-nearest neighbor (KNN)']"
2024,https://openalex.org/W4392356648,Engineering,Cost-sensitive learning for imbalanced medical data: a review,"Abstract Integrating Machine Learning (ML) in medicine has unlocked many opportunities to harness complex medical data, enhancing patient outcomes and advancing the field. However, the inherent imbalanced distribution of medical data poses a significant challenge, resulting in biased ML models that perform poorly on minority classes. Mitigating the impact of class imbalance has prompted researchers to explore various strategies, wherein Cost-Sensitive Learning (CSL) arises as a promising approach to improve the accuracy and reliability of ML models. This paper presents the first review of CSL for imbalanced medical data. A comprehensive exploration of the existing literature encompassed papers published from January 2010 to December 2022 and sourced from five major digital libraries. A total of 173 papers were selected, analysed, and classified based on key criteria, including publication years, channels and sources, research types, empirical types, medical sub-fields, medical tasks, CSL approaches, strengths and weaknesses of CSL, frequently used datasets and data types, evaluation metrics, and development tools. The results indicate a noteworthy publication rise, particularly since 2020, and a strong preference for CSL direct approaches. Data type analysis unveiled diverse modalities, with medical images prevailing. The underutilisation of cost-related metrics and the prevalence of Python as the primary programming tool are highlighted. The strengths and weaknesses analysis covered three aspects: CSL strategy, CSL approaches, and relevant works. This study serves as a valuable resource for researchers seeking to explore the current state of research, identify strengths and gaps in the existing literature and advance CSL’s application for imbalanced medical data.","['Machine Learning (ML)', 'Cost-Sensitive Learning (CSL)']"
2024,https://openalex.org/W4390501772,Engineering,Remote sensing based forest cover classification using machine learning,"Abstract Pakistan falls significantly below the recommended forest coverage level of 20 to 30 percent of total area, with less than 6 percent of its land under forest cover. This deficiency is primarily attributed to illicit deforestation for wood and charcoal, coupled with a failure to embrace advanced techniques for forest estimation, monitoring, and supervision. Remote sensing techniques leveraging Sentinel-2 satellite images were employed. Both single-layer stacked images and temporal layer stacked images from various dates were utilized for forest classification. The application of an artificial neural network (ANN) supervised classification algorithm yielded notable results. Using a single-layer stacked image from Sentinel-2, an impressive 91.37% training overall accuracy and 0.865 kappa coefficient were achieved, along with 93.77% testing overall accuracy and a 0.902 kappa coefficient. Furthermore, the temporal layer stacked image approach demonstrated even better results. This method yielded 98.07% overall training accuracy, 97.75% overall testing accuracy, and kappa coefficients of 0.970 and 0.965, respectively. The random forest (RF) algorithm, when applied, achieved 99.12% overall training accuracy, 92.90% testing accuracy, and kappa coefficients of 0.986 and 0.882. Notably, with the temporal layer stacked image of the Sentinel-2 satellite, the RF algorithm reached exceptional performance with 99.79% training accuracy, 96.98% validation accuracy, and kappa coefficients of 0.996 and 0.954. In terms of forest cover estimation, the ANN algorithm identified 31.07% total forest coverage in the District Abbottabad region. In comparison, the RF algorithm recorded a slightly higher 31.17% of the total forested area. This research highlights the potential of advanced remote sensing techniques and machine learning algorithms in improving forest cover assessment and monitoring strategies.","['artificial neural network (ANN) supervised classification algorithm', 'random forest (RF) algorithm']"
2024,https://openalex.org/W4392714183,Engineering,Explainability and Interpretability in Electric Load Forecasting Using Machine Learning Techniques – A Review,"Electric Load Forecasting (ELF) is the central instrument for planning and controlling demand response programs, electricity trading, and consumption optimization. Due to the increasing automation of these processes, meaningful and transparent forecasts become more and more important. Still, at the same time, the complexity of the used machine learning models and architectures increases. Because there is an increasing interest in interpretable and explainable load forecasting methods, this work conducts a literature review to present already applied approaches regarding explainability and interpretability for load forecasts using Machine Learning. Based on extensive literature research covering eight publication portals, recurring modeling approaches, trends, and modeling techniques are identified and clustered by properties to achieve more interpretable and explainable load forecasts. The results on interpretability show an increase in the use of probabilistic models, methods for time series decomposition and the use of fuzzy logic in addition to classically interpretable models. Dominant explainable approaches are Feature Importance and Attention mechanisms. The discussion shows that a lot of knowledge from the related field of time series forecasting still needs to be adapted to the problems in ELF. Compared to other applications of explainable and interpretable methods such as clustering, there are currently relatively few research results, but with an increasing trend.","['probabilistic models', 'Attention mechanisms']"
2024,https://openalex.org/W4392830014,Engineering,A Deep Learning-Based CAE Approach for Simulating 3D Vehicle Wheels Under Real-World Conditions,"The implementation of deep learning (DL) in computer-aided engineering (CAE) can significantly improve the accuracy and efficiency of simulating 3D vehicle wheels under real-world conditions. While traditional CAE methods can be time-consuming and computationally expensive, DL can reduce simulation time and development cycles across all industries. This work explores the role of DL and AI in virtual manufacturing and CAE and investigates how they can be used to improve the accuracy and efficiency of simulations for 3D vehicle wheels. Deep learning models can learn the complex relationships between different wheel design parameters, such as tire load distribution, stress distribution, and fatigue life. Once trained, these models can be embedded into CAE software, allowing for faster and more accurate simulations of wheel performance. This interdisciplinary study uses various deep learning techniques, including convolutional neural networks (CNNs), generative adversarial networks (GANs), and recurrent neural networks (RNNs), to create a more efficient and accurate relationship between CAD modeling and CAE simulation. The research aims to leverage the potential of deep learning models to automate 3D CAD design, accurately predict CAE results, and provide in-depth explanations and verifications. The benefits of this research are expected to extend to the automotive industry's pursuit of more robust and resilient wheel designs. By streamlining the product development process from conceptual design to engineering performance evaluation, this study has the potential to revolutionize the automotive industry's product development cycle.","['deep learning (DL)', 'convolutional neural networks (CNNs)', 'generative adversarial networks (GANs)', 'recurrent neural networks (RNNs)']"
2024,https://openalex.org/W4393055891,Engineering,A new intelligently optimized model reference adaptive controller using GA and WOA-based MPPT techniques for photovoltaic systems,"Recently, the integration of renewable energy sources, specifically photovoltaic (PV) systems, into power networks has grown in significance for sustainable energy generation. Researchers have investigated different control algorithms for maximum power point tracking (MPPT) to enhance the efficiency of PV systems. This article presents an innovative method to address the problem of maximum power point tracking in photovoltaic systems amidst swiftly changing weather conditions. MPPT techniques supply maximum power to the load during irradiance fluctuations and ambient temperatures. A novel optimal model reference adaptive controller is developed and designed based on the MIT rule to seek global maximum power without ripples rapidly. The suggested controller is also optimized through two popular meta-heuristic algorithms: The genetic algorithm (GA) and the whale optimization algorithm (WOA). These meta-heuristic approaches have been exploited to overcome the difficulty of selecting the adaptation gain of the MRAC controller. The reference voltage for MPPT is generated in the study through an adaptive neuro-fuzzy inference system. The suggested controller's performance is tested via MATLAB/Simulink software under varying temperature and radiation circumstances. Simulation is carried out using a Soltech 1sth-215-p module coupled to a boost converter, which powers a resistive load. Furthermore, to emphasize the recommended algorithm's performance, a comparative study was done between the optimal MRAC using GA and WOA and the conventional incremental conductance (INC) method.","['genetic algorithm (GA)', 'whale optimization algorithm (WOA)', 'adaptive neuro-fuzzy inference system']"
2024,https://openalex.org/W4393339929,Engineering,Optimizing landslide susceptibility mapping using machine learning and geospatial techniques,"Landslides present a substantial risk to human lives, the environment, and infrastructure. Consequently, it is crucial to highlight the regions prone to future landslides by examining the correlation between past landslides and various geo-environmental factors. This study aims to investigate the optimal data selection and machine learning model, or ensemble technique, for evaluating the vulnerability of areas to landslides and determining the most accurate approach. To attain our objectives, we considered two different scenarios for selecting landslide-free random points (a slope threshold and a buffer-based approach) and performed a comparative analysis of five machine learning models for landslide susceptibility mapping, namely: Support Vector Machine (SVM), Logistic Regression (LR), Linear Discriminant Analysis (LDA), Random Forest (RF), and Extreme Gradient Boosting (XGBoost). The study area for this research is an area in Polk County in Western North Carolina that has experienced fatal landslides, leading to casualties and significant damage to infrastructure, properties, and road networks. The model construction process involves the utilization of a dataset comprising 1215 historical landslide occurrences and 1215 non-landslide points. We integrated a total of fourteen geospatial data layers, consisting of topographic variables, soil data, geological data, and land cover attributes. We use various metrics to assess the models' performance, including accuracy, F1-score, Kappa score, and AUC-ROC. In addition, we used the seeded-cell area index (SCAI) to evaluate map consistency. The ensemble of the five models using Weighted Average produces outstanding results, with an AUC-ROC of 99.4% for the slope threshold scenario and 91.8% for the buffer-based scenario. Our findings emphasize the significant impact of non-landslide random sampling on model performance in landslide susceptibility mapping. Furthermore, by optimally identifying landslide-prone regions and hotspots that need urgent risk management and land use planning, our study demonstrates the effectiveness of machine learning models in analyzing landslide susceptibility and providing valuable insights for informed decision-making and disaster risk reduction initiatives.","['Support Vector Machine (SVM)', 'Logistic Regression (LR)', 'Linear Discriminant Analysis (LDA)', 'Random Forest (RF)', 'Extreme Gradient Boosting (XGBoost)', 'ensemble technique using Weighted Average']"
2024,https://openalex.org/W4399144385,Engineering,Assessment of technical water quality in mining based on machine learning methods,"Introduction. Mining requires water treatment and wastewater processing, abstraction and discharge during mining increases consumption several times. Since water consumption in mining and processing is usually associated with domestic, industrial and technical needs, the need for water supply systems required for water treatment increases. Water from different sources can be used for treatment: incoming water, process and reused water, and wastewater. But the water obtained from any of the sources must meet all the norms and requirements. Water quality is determined by physical, chemical and bacteriological properties. The main directions for improving water consumption by mining enterprises are to reduce the consumption of drinking water from rivers, lakes and municipal water supply, as well as to expand the use of mine and quarry water for domestic and technical needs. Materials and methods. As training data for training the neural network, a dataset that includes water quality data obtained from fresh water sources was selected for the methods work, and using machine learning, develops a model that predicts whether the water is suitable for technical use in mines. This dataset includes 2293 values (samples) as well as 9 attributes. Correlation, neural network, and decision tree methods were used to build the models in this study. Results. Various machine learning methods (neural network and decision trees) were used to build a predictive model to assess the quality of water that would be suitable for use in the mining industry for technical purposes. With the help of the built models were processed data obtained from public sources, when analyzing which it was found that the method of decision trees was more accurate. The constructed model, for determining dependencies, thus, has high accuracy (small error). To increase the practical significance of the study, a number of transformations of the initial data set were carried out, in particular, an experiment with the division of attributes into groups of importance, in relation to the data, taking into account the subject area. The results obtained made it clear that checking only for hazardous impurities does not guarantee the suitability of water, but almost completely excludes (low significance factor) samples with impurities that do not meet the requirements, and the model can have practical significance. Allocation of the group for rapid quality determination, showed that for the express test, in an emergency situation or under time constraints, the possibility of practical use of the obtained model, has a justification, due to the small error. In general, the conducted experiments have shown that when taking into account the costs (total) for data collection, it makes sense to use models, taking into account the reduction of collected data, on the parameters (factors) of technical water. Discussion. In general, on the basis of the conducted research, we can talk about the successful application of machine learning methods in determining the suitability of technical water in the mining industry. During the experiments, the decision tree method performed particularly well, with the lowest error values. In addition, further work can be carried out to reduce the error in the models, in particular, by possibly increasing the number of attributes, as well as more fine-tuning of the applied machine learning methods. Conclusions. The authors conclude that machine learning techniques can be successfully integrated to determine the quality and suitability of process water in the mining industry in today’s world. Resume. The paper compares machine learning methods such as decision trees and neural network method. The comparative analysis of these methods and their quality of information processing is shown on the example of a set of data on water quality in the mining industry. With the help of built models were processed data obtained from open sources, when analyzing which it was found that the method of decision trees was more accurate. The constructed model for determining dependencies has high accuracy (small error). Suggestions for practical applications and future research directions. This study can form the basis for research in this or related fields to conduct further studies on the reliability and accuracy of using machine learning to predict the quality of water used in the mining industry. Continued work in the above direction may be the rationale for wider use of the above methods to improve various meaningful production performance in this or related areas.","['neural network', 'decision tree']"
2024,https://openalex.org/W4401386421,Engineering,Machine learning prediction of mechanical properties in metal additive manufacturing,"Predicting mechanical properties in metal additive manufacturing (MAM) is essential for ensuring the performance and reliability of printed parts, as well as their suitability for specific applications. However, conducting experiments to estimate mechanical properties in MAM processes can be laborious and expensive, and they are often limited to specific materials and processes. Machine learning (ML) methods offer a more flexible and cost-effective approach to predicting mechanical properties based on processing parameters and material properties. In this study, we introduce a comprehensive framework for benchmarking ML models for predicting mechanical properties. We compiled an extensive experimental dataset from over 90 MAM articles and data sheets from a diverse range of sources, encompassing 140 different MAM data sheets. This dataset includes information on MAM processing conditions, machines, materials, and resulting mechanical properties such as yield strength, ultimate tensile strength, elastic modulus, elongation, hardness, and surface roughness. Our framework incorporates physics-aware featurization specific to MAM, adjustable ML models, and tailored evaluation metrics to construct a comprehensive learning framework for predicting mechanical properties. Additionally, we explore the Explainable AI method, specifically SHAP analysis, to elucidate and interpret the predicted values of ML models for mechanical properties. Furthermore, data-driven explicit models were developed to estimate mechanical properties based on processing parameters and material properties, offering enhanced interpretability compared to conventional ML models.",['SHAP analysis']
2024,https://openalex.org/W4390748349,Engineering,Charging management of electric vehicles with the presence of renewable resources,"Considering the increasing use of electric vehicles, the establishment of charging stations to exchange power between the grid and electric devices, and the integration of charging stations with solar power generation sources, the optimal use of electric vehicle charging stations in the power system. The purpose of cost reduction in the presence of the intelligent environment is a challenge that must be investigated so that this platform is suitable for predicting the behaviour of vehicles and, as a result, optimizing their presence in the power network. This research presents a relatively complete radial distribution network development planning model in two scenarios. In the first scenario, the effects of electric vehicles are not considered, and only the effects of distributed production (renewable and dispatchable) are considered. Studies have been done on a sample 54-bus network, a common system in most Distribution expansion planning (DEP) articles for distribution networks. In addition, the real data of American highways have been used to create raw input data. Also, due to the distance limit, the information on vehicles under 100 miles has been received as electric vehicle information. The clustering method and Capiola multivariate probability distribution functions have created suitable vehicle scenarios during different planning years. Capiola's method increases the accuracy of vehicle load forecasting according to a predetermined growth rate. The DEP problem in this research is modeled as an optimization problem based on scenario, dynamic, and in 5 one-year time frames (5-year time horizon and one-year accuracy). The results indicate that, in the presence of electric vehicles and distributed production sources, the technical characteristics of the network are improved. Similarly, the use of DGs, in addition to reducing the cost of equipment, has reduced undistributed energy in the system. But 10,000 vehicles, which have been applied to the network as an uncontrolled load, have caused an increase in undistributed energy. The cost of equipment required for the network development is almost as much as 5%.",['clustering method']
2024,https://openalex.org/W4391612257,Engineering,Machine learning for the management of biochar yield and properties of biomass sources for sustainable energy,"Abstract Biochar is emerging as a potential solution for biomass conversion to meet the ever increasing demand for sustainable energy. Efficient management systems are needed in order to exploit fully the potential of biochar. Modern machine learning (ML) techniques, and in particular ensemble approaches and explainable AI methods, are valuable for forecasting the properties and efficiency of biochar properly. Machine‐learning‐based forecasts, optimization, and feature selection are critical for improving biomass management techniques. In this research, we explore the influences of these techniques on the accurate forecasting of biochar yield and properties for a range of biomass sources. We emphasize the importance of the interpretability of a model, as this improves human comprehension and trust in ML predictions. Sensitivity analysis is shown to be an effective technique for finding crucial biomass characteristics that influence the synthesis of biochar. Precision prognostics have far‐reaching ramifications, influencing industries such as biomass logistics, conversion technologies, and the successful use of biomass as renewable energy. These advances can make a substantial contribution to a greener future and can encourage the development of a circular biobased economy. This work emphasizes the importance of using sophisticated data‐driven methodologies such as ML in biochar synthesis, to usher in ecologically friendly energy solutions. These breakthroughs hold the key to a more sustainable and environmentally friendly future.","['ensemble approaches', 'feature selection']"
2024,https://openalex.org/W4391878291,Engineering,Effective lung nodule detection using deep CNN with dual attention mechanisms,"Abstract Novel methods are required to enhance lung cancer detection, which has overtaken other cancer-related causes of death as the major cause of cancer-related mortality. Radiologists have long-standing methods for locating lung nodules in patients with lung cancer, such as computed tomography (CT) scans. Radiologists must manually review a significant amount of CT scan pictures, which makes the process time-consuming and prone to human error. Computer-aided diagnosis (CAD) systems have been created to help radiologists with their evaluations in order to overcome these difficulties. These systems make use of cutting-edge deep learning architectures. These CAD systems are designed to improve lung nodule diagnosis efficiency and accuracy. In this study, a bespoke convolutional neural network (CNN) with a dual attention mechanism was created, which was especially crafted to concentrate on the most important elements in images of lung nodules. The CNN model extracts informative features from the images, while the attention module incorporates both channel attention and spatial attention mechanisms to selectively highlight significant features. After the attention module, global average pooling is applied to summarize the spatial information. To evaluate the performance of the proposed model, extensive experiments were conducted using benchmark dataset of lung nodules. The results of these experiments demonstrated that our model surpasses recent models and achieves state-of-the-art accuracy in lung nodule detection and classification tasks.","['convolutional neural network (CNN)', 'dual attention mechanism', 'channel attention', 'spatial attention', 'global average pooling']"
2024,https://openalex.org/W4392157869,Engineering,Transfer learning with graph neural networks for improved molecular property prediction in the multi-fidelity setting,"Abstract We investigate the potential of graph neural networks for transfer learning and improving molecular property prediction on sparse and expensive to acquire high-fidelity data by leveraging low-fidelity measurements as an inexpensive proxy for a targeted property of interest. This problem arises in discovery processes that rely on screening funnels for trading off the overall costs against throughput and accuracy. Typically, individual stages in these processes are loosely connected and each one generates data at different scale and fidelity. We consider this setup holistically and demonstrate empirically that existing transfer learning techniques for graph neural networks are generally unable to harness the information from multi-fidelity cascades. Here, we propose several effective transfer learning strategies and study them in transductive and inductive settings. Our analysis involves a collection of more than 28 million unique experimental protein-ligand interactions across 37 targets from drug discovery by high-throughput screening and 12 quantum properties from the dataset QMugs. The results indicate that transfer learning can improve the performance on sparse tasks by up to eight times while using an order of magnitude less high-fidelity training data. Moreover, the proposed methods consistently outperform existing transfer learning strategies for graph-structured data on drug discovery and quantum mechanics datasets.","['graph neural networks', 'transfer learning', 'transfer learning strategies']"
2024,https://openalex.org/W4396686667,Engineering,Optimal design of steel exoskeleton for the retrofitting of RC buildings via genetic algorithm,"In recent decades, steel exoskeletons have gathered significant attention as a seismic retrofitting technique for existing structures. The design methods proposed so far are focused on the identification of the system's overall parameters through simplified models. Although these methodologies provide helpful guidance at the preliminary design stage, they do not consider aspects such as the distribution of the exoskeletons and sizing of their components. To overcome these limitations, an optimization process based on the Genetic Algorithm is proposed in this paper to identify the optimal exoskeleton number and spatial arrangement, and to determine the optimal size of their constituent elements. The algorithm aims to minimize the weight of the retrofit solution while keeping the whole existing structure in the elastic field and ensuring the structural verification of the exoskeleton's elements. The analyses have been conducted using a finite-element code with an Open Application Programming Interface, which allows the models to be handled through automatic routines. The proposed optimization tool has been applied to several case studies, considering two different layouts for the exoskeletons. Finally, the effectiveness of the retrofit method has been demonstrated, and the proposed optimization tool has been able to significantly reduce the weight and cost of the intervention.",['Genetic Algorithm']
2024,https://openalex.org/W4398787803,Engineering,Transformer-based Generative Adversarial Networks in Computer Vision: A Comprehensive Survey,"Generative Adversarial Networks (GANs) have been very successful for synthesizing the images in a given dataset. The artificially generated images by GANs are very realistic. The GANs have shown potential usability in several computer vision applications, including image generation, image-to-image translation, video synthesis, etc. Conventionally, the generator network is the backbone of GANs, which generates the samples and the discriminator network is used to facilitate the training of the generator network. The generator and discriminator networks are usually a Convolutional Neural Network (CNN). The convolution-based networks exploit the local relationship in a layer, which requires the deep networks to extract the abstract features. However, recently developed Transformer networks are able to exploit the global relationship with tremendous performance improvement for several problems in computer vision. Motivated from the success of Transformer networks and GANs, recent works have tried to exploit the Transformers in GAN framework for the image/video synthesis. This paper presents a comprehensive survey on the developments and advancements in GANs utilizing the Transformer networks for computer vision applications. The performance comparison for several applications on benchmark datasets is also performed and analyzed. The conducted survey will be very useful to understand the research trends & gaps related with Transformer-based GANs and to develop the advanced GAN architectures by exploiting the global and local relationships for different applications.","['Generative Adversarial Networks (GANs)', 'Convolutional Neural Network (CNN)', 'Transformer networks']"
2024,https://openalex.org/W4400110237,Engineering,A new integrated intelligent computing paradigm for predicting joints shear strength,"Joints shear strength is a critical parameter during the design and construction of geotechnical engineering structures. The prevailing models mostly adopt the form of empirical functions, employing mathematical regression techniques to represent experimental data. As an alternative approach, this paper proposes a new integrated intelligent computing paradigm that aims to predict joints shear strength. Five metaheuristic optimization algorithms, including the chameleon swarm algorithm (CSA), slime mold algorithm, transient search optimization algorithm, equilibrium optimizer and social network search algorithm, were employed to enhance the performance of the multilayered perception (MLP) model. Efficiency comparisons were conducted between the proposed CSA-MLP model and twelve classical models, employing statistical indicators such as root mean square error (RMSE), correlation coefficient (R2), mean absolute error (MAE), and variance accounted for (VAF) to evaluate the performance of each model. The sensitivity analysis of parameters that impact joints shear strength was conducted. Finally, the feasibility and limitations of this study were discussed. The results revealed that, in comparison to other models, the CSA-MLP model exhibited the most appropriate performance in terms of R2 (0.88), RMSE (0.19), MAE (0.15), and VAF (90.32%) values. The result of sensitivity analysis showed that the normal stress and the joint roughness coefficient were the most critical factors influencing joints shear strength. This paper presented an efficacious attempt toward swift prediction of joints shear strength, thus avoiding the need for costly in-site and laboratory tests.","['slime mold algorithm', 'equilibrium optimizer']"
2024,https://openalex.org/W4400721646,Engineering,"A Comprehensive Review on the Role of Artificial Intelligence in Power System Stability, Control, and Protection: Insights and Future Directions","This review comprehensively examines the burgeoning field of intelligent techniques to enhance power systems’ stability, control, and protection. As global energy demands increase and renewable energy sources become more integrated, maintaining the stability and reliability of both conventional power systems and smart grids is crucial. Traditional methods are increasingly insufficient for handling today’s power grids’ complex, dynamic nature. This paper discusses the adoption of advanced intelligence methods, including artificial intelligence (AI), deep learning (DL), machine learning (ML), metaheuristic optimization algorithms, and other AI techniques such as fuzzy logic, reinforcement learning, and model predictive control to address these challenges. It underscores the critical importance of power system stability and the new challenges of integrating diverse energy sources. The paper reviews various intelligent methods used in power system analysis, emphasizing their roles in predictive maintenance, fault detection, real-time control, and monitoring. It details extensive research on the capabilities of AI and ML algorithms to enhance the precision and efficiency of protection systems, showing their effectiveness in accurately identifying and resolving faults. Additionally, it explores the potential of fuzzy logic in decision-making under uncertainty, reinforcement learning for dynamic stability control, and the integration of IoT and big data analytics for real-time system monitoring and optimization. Case studies from the literature are presented, offering valuable insights into practical applications. The review concludes by identifying current limitations and suggesting areas for future research, highlighting the need for more robust, flexible, and scalable intelligent systems in the power sector. This paper is a valuable resource for researchers, engineers, and policymakers, providing a detailed understanding of the current and future potential of intelligent techniques in power system stability, control, and protection.","['deep learning (DL)', 'machine learning (ML)', 'reinforcement learning']"
2024,https://openalex.org/W4401289975,Engineering,Application of ANFIS approach for prediction of performance measures in wire electric discharge machining of SAE 1010,"Due to its exceptional quality, SAE 1010 is highly recommended for automotive applications, particularly in the manufacturing of headed fasteners and bolts. The primary application of this technology is in automobiles, while it also holds significant potential for various other technological disciplines. Utilizing alternative techniques for removing material has proven to be essential in overcoming numerous machining challenges that were previously difficult to solve. It possesses numerous practical applications in aircraft engineering and exhibits significant potential for implementation in other technical domains. Manufacturing complicated curved components using traditional machining methods might provide challenges. In order to prevent such issues, a wide range of cutting-edge machining methods have been developed. Wire Electrical Discharge Machining (WEDM) is a variance of Electrical Discharge Machining (EDM) that is suitable for this particular use. This study employs Taguchi's technique to examine the Wire Electrical Discharge Machining (WEDM) of SAE 1010 steel from an environmentally friendly viewpoint by employing a natural dielectric fluid in order to minimize its ecological footprint. This study aims to optimize the process variable and develop a hybrid predictive model based on grey approach for foretelling the necessary performance measures by considering various performance metrics, including material removal rate, surface roughness, and tolerance errors. The significance of process variables has been determined with the help of Analysis of variance (ANOVA) and it is inferred that pulse on duration is the most contributing factor for all the desired performance measures. A hybrid technique was used by an artificial intelligence technology to project the selected output measure. The outcomes on performance of the evolved ANFIS model shows the prediction capability of the model developed with least errors (MAPE – 0.0417, RMSE − 0.00023, MAE – 0.000419, Correlation coefficient 0.9997). The outcomes of the analysis indicate that the model is both efficient and accurate in its predictions, could be valuable to the manufacturer since it establishes targets for important performance indicators.","['hybrid predictive model based on grey approach', 'ANFIS model']"
2024,https://openalex.org/W4390870882,Engineering,A domain adaptation approach to damage classification with an application to bridge monitoring,"Data-driven machine-learning algorithms generally suffer from a lack of labelled health-state data, mainly those referring to damage conditions. To address such an issue, population-based structural health monitoring seeks to enrich the original dataset by transferring knowledge from a population of monitored structures. Within this context, this paper presents a transfer learning approach, based on domain adaptation, to leverage information from completely-labelled bridge structure data to accurately predict new instances of an unknown target domain. Since intrinsic structural differences may cause distribution shifts, domain adaptation attempts to minimise the distance between the domains and to learn a mapping within a shared feature space. Specifically, the methodology involves the long-term acquisition of natural frequencies from several structural scenarios. Such damage-sensitive features are then aligned via domain adaptation so that a machine-learning algorithm can effectively utilise the labelled source domain data and generalise well to the unlabelled target-domain data. The described procedure is applied to two case studies, including the Z24 and the S101 benchmark bridges and their finite element models, respectively. The results demonstrate the successful exchange of health-state labels to identify the damage class within a population of bridges equipped with SHM systems, showing potential to reduce computational efforts and to deal with scarce or poor data sets in application to bridge network monitoring.","['transfer learning', 'domain adaptation']"
2024,https://openalex.org/W4391478629,Engineering,Enhancing photovoltaic parameter estimation: integration of non-linear hunting and reinforcement learning strategies with golden jackal optimizer,"Abstract The advancement of Photovoltaic (PV) systems hinges on the precise optimization of their parameters. Among the numerous optimization techniques, the effectiveness of each often rests on their inherent parameters. This research introduces a new methodology, the Reinforcement Learning-based Golden Jackal Optimizer (RL-GJO). This approach uniquely combines reinforcement learning with the Golden Jackal Optimizer to enhance its efficiency and adaptability in handling various optimization problems. Furthermore, the research incorporates an advanced non-linear hunting strategy to optimize the algorithm’s performance. The proposed algorithm is first validated using 29 CEC2017 benchmark test functions and five engineering-constrained design problems. Secondly, rigorous testing on PV parameter estimation benchmark datasets, including the single-diode model, double-diode model, three-diode model, and a representative PV module, was carried out to highlight the superiority of RL-GJO. The results were compelling: the root mean square error values achieved by RL-GJO were markedly lower than those of the original algorithm and other prevalent optimization methods. The synergy between reinforcement learning and GJO in this approach facilitates faster convergence and improved solution quality. This integration not only improves the performance metrics but also ensures a more efficient optimization process, especially in complex PV scenarios. With an average Freidman’s rank test values of 1.564 for numerical and engineering design problems and 1.742 for parameter estimation problems, the proposed RL-GJO is performing better than the original GJO and other peers. The proposed RL-GJO stands out as a reliable tool for PV parameter estimation. By seamlessly combining reinforcement learning with the golden jackal optimizer, it sets a new benchmark in PV optimization, indicating a promising avenue for future research and applications.",['Reinforcement Learning']
2024,https://openalex.org/W4392106623,Engineering,Machine learning assisted prediction of solar to liquid fuel production: a case study,"In this era of heightened environmental awareness, the global community faces the critical challenge of climate change. Renewable energy (RE) emerges as a vital contender to mitigate global warming and meet increasing energy needs. Nonetheless, the fluctuating nature of renewable energy sources underscores the necessity for efficient conversion and storage strategies. This pioneering research focuses on the transformation of solar energy (SE) into liquid fuels, with a specific emphasis on formic acid (FA) as a case study, done in Binh Thuan, Vietnam. The paper unveils a technology designed to convert solar energy into formic acid, ensuring its stability and storage at ambient conditions. It involves detailed simulations to quantify the daily and monthly electricity output from photovoltaic (PV) systems and the corresponding mass of formic acid producible through solar energy. The simulation of a dual-axis solar tracking system for the PV panels, intended to maximize solar energy capture, is one of the project's illustrations. The elevation and azimuth angles, which are two essential tracking system parameters, are extensively studied in the present research. The project makes use of machine learning algorithms in the field of predictive modeling, specifically Artificial Neural Networks (ANN) and Support Vector Machines (SVM). These tools play a crucial role in modeling PV power output and formic acid production while accounting for a variety of influencing factors. A comparative study shows that SVM outperforms ANN in accurately predicting the production of FA and PV power generation, both of which are the major goals. This model is a predictive tool that can be used to forecast these goals based on certain causal variables. Overall, it is observed that the maximum power produced with 2-axis solar tracker was achieved in February as 2355 kW resulting in the highest formic acid production of 2.25 ×106 grams. The study's broad ramifications demonstrate solar liquid fuel technology's potential as a long-term fix in the field of renewable energy. In addition to advancing the field of renewable energy storage, the study represents a major step toward tackling the global challenge of climate change.","['Artificial Neural Networks (ANN)', 'Support Vector Machines (SVM)']"
2024,https://openalex.org/W4394585959,Engineering,Statistical Machine Learning for Power Flow Analysis Considering the Influence of Weather Factors on Photovoltaic Power Generation,"It is generally accepted that the impact of weather variation is gradually increasing in modern distribution networks with the integration of high-proportion photovoltaic (PV) power generation and weather-sensitive loads. This article analyzes power flow using a novel stochastic weather generator (SWG) based on statistical machine learning (SML). The proposed SML model, which incorporates generative adversarial networks (GANs), probability theory, and information theory, enables the generation and evaluation of simulated hourly weather data throughout the year. The GAN model captures various weather variation characteristics, including weather uncertainties, diurnal variations, and seasonal patterns. Compared to shallow learning models, the proposed deep learning model exhibits significant advantages in stochastic weather simulation. The simulated data generated by the proposed model closely resemble real data in terms of time-series regularity, integrity, and stochasticity. The SWG is applied to model PV power generation and weather-sensitive loads. Then, we actively conduct a power flow analysis (PFA) on a real distribution network in Guangdong, China, using simulated data for an entire year. The results provide evidence that the GAN-based SWG surpasses the shallow machine learning approach in terms of accuracy. The proposed model ensures accurate analysis of weather-related power flow and provides valuable insights for the analysis, planning, and design of distribution networks.","['statistical machine learning (SML)', 'generative adversarial networks (GANs)', 'shallow learning models', 'deep learning model']"
2024,https://openalex.org/W4391206025,Engineering,Short-term wind speed forecasting using an optimized three-phase convolutional neural network fused with bidirectional long short-term memory network model,"Wind energy is an environment friendly, low-carbon, and cost-effective renewable energy source. It is, however, difficult to integrate wind energy into a mixed energy grid due to its high volatility and intermittency. For wind energy conversion systems to be reliable and efficient, accurate wind speed (WS) forecasting is fundamental. This study cascades a convolutional neural network (CNN) with a bidirectional long short-term memory (BiLSTM) in order to obtain a model for hourly WS forecasting by utilizing several meteorological variables as model inputs to study their effects on predicted WS. For input selection, the mutation grey wolf optimizer (TMGWO) is used. For efficient optimization of CBiLSTM hyperparameters, a hybrid Bayesian Optimization and HyperBand (BOHB) algorithm is used. The combined usage of TMGWO, BOHB, and CBiLSTM leads to a three-phase hybrid model (i.e., 3P-CBiLSTM). The performance of 3P-CBiLSTM is benchmarked against the standalone and hybrid BiLSTMs, LSTMs, gradient boosting (GBRs), random forest (RFRs), and decision tree regressors (DTRs). The statistical analysis of forecasted WS reveals that the 3P-CBiLSTM is highly effective over the other benchmark forecasting methods. This objective model also registers the highest percentage of forecasted errors (≈ 53.4 – 81.8%) within the smallest error range ≤ |0.25| ms−1 amongst all tested study sites. Despite the remarkable results achieved, the CBiLSTM model cannot be generally understood, so the eXplainable Artificial Intelligence (xAI) technique was used for explaining local and global model outputs, based on Local Interpretable Model-Agnostic Explanations (LIME) and SHapley Additive exPlanations (SHAP). Both of the xAI methods determined that the antecedent WS is the most significant predictor of the short-term WS forecasting. Therefore, we aver that the proposed model can be employed to help wind farm operators in making quality decisions in maximizing wind power integration into the grid with reduced intermittency.","['convolutional neural network (CNN)', 'bidirectional long short-term memory (BiLSTM)', 'mutation grey wolf optimizer (TMGWO)', 'hybrid Bayesian Optimization and HyperBand (BOHB) algorithm', 'long short-term memory (LSTM)', 'gradient boosting regressors (GBRs)', 'random forest regressors (RFRs)', 'decision tree regressors (DTRs)', 'Local Interpretable Model-Agnostic Explanations (LIME)', 'SHapley Additive exPlanations (SHAP)']"
2024,https://openalex.org/W4392450360,Engineering,Geographically weighted machine learning for modeling spatial heterogeneity in traffic crash frequency and determinants in US,"Spatial analyses of traffic crashes have drawn much interest due to the nature of the spatial dependence and spatial heterogeneity in the crash data. This study makes the best of Geographically Weighted Random Forest (GW-RF) model to explore the local associations between crash frequency and various influencing factors in the US, including road network attributes, socio-economic characteristics, and land use factors collected from multiple data sources. Special emphasis is put on modeling the spatial heterogeneity in the effects of a factor on crash frequency in different geographical areas in a data-driven way. The GW-RF model outperforms global models (e.g. Random Forest) and conventional geographically weighted regression, demonstrating superior predictive accuracy and elucidating spatial variations. The GW-RF model reveals spatial distinctions in the effects of certain factors on crash frequency. For example, the importance of intersection density varies significantly across regions, with high significance in the southern and northeastern areas. Low-grade road density emerges as influential in specific cities. The findings highlight the significance of different factors in influencing crash frequency across zones. Road network factors, particularly intersection density, exhibit high importance universally, while socioeconomic variables demonstrate moderate effects. Interestingly, land use variables show relatively lower importance. The outcomes could help to allocate resources and implement tailored interventions to reduce the likelihood of crashes.","['Geographically Weighted Random Forest (GW-RF)', 'Random Forest']"
2024,https://openalex.org/W4392714432,Engineering,"Hybrid physics-machine learning models for predicting rate of penetration in the Halahatang oil field, Tarim Basin","Abstract Rate of penetration (ROP) is a key factor in drilling optimization, cost reduction and drilling cycle shortening. Due to the systematicity, complexity and uncertainty of drilling operations, however, it has always been a problem to establish a highly accurate and interpretable ROP prediction model to guide and optimize drilling operations. To solve this problem in the Tarim Basin, this study proposes four categories of hybrid physics-machine learning (ML) methods for modeling. One of which is residual modeling, in which an ML model learns to predict errors or residuals, via a physical model; the second is integrated coupling, in which the output of the physical model is used as an input to the ML model; the third is simple average, in which predictions from both the physical model and the ML model are combined; and the last is bootstrap aggregating (bagging), which follows the idea of ensemble learning to combine different physical models’ advantages. A total of 5655 real data points from the Halahatang oil field were used to test the performance of the various models. The results showed that the residual modeling model, with an R 2 of 0.9936, had the best performance, followed by the simple average model and bagging with R 2 values of 0.9394 and 0.5998, respectively. From the view of prediction accuracy, and model interpretability, the hybrid physics-ML model with residual modeling is the optimal method for ROP prediction.","['residual modeling', 'bootstrap aggregating (bagging)']"
2024,https://openalex.org/W4391429082,Engineering,Simulation-based multi-objective genetic optimization for promoting energy efficiency and thermal comfort in existing buildings of hot climate,"This study conducts a detailed analysis to improve to enhance the energy performance of residential buildings in UAE through various retrofit measures. The applied methodology involved developing a calibrated building energy model for a two-story residential building, followed by a parametric analysis of six design variables, including wall and roof insulation, glazing, infiltration rate, window shading, and setpoint and setback temperatures to evaluate their impact on annual energy consumption. Additionally, a sensitivity analysis was conducted to assess the importance of the investigated design variables on building energy use. An optimization approach using the non-dominated sorting genetic algorithm (NSGA-II) was then implemented to optimize energy consumption while minimizing discomfort conditions. The key findings from the parametric simulations show significant energy savings: a 38.8 % reduction from improved wall insulation (achieving a U-value of 0.14 W/m2K), a 2.3 % decrease with better roof insulation, a 9.8 % saving from using triple clear glass glazing, a 9.6 % reduction by lowering the infiltration rate to 2.5 m³/h.m2, 7.5 % savings from window shading, and a 25.7 % decrease by optimizing cooling setpoints. A sensitivity analysis highlighted the dominant impact of wall insulation and cooling setpoint temperatures on energy usage. Followed by the cooling setpoint temperature. The subsequent NSGA-II optimization yielded 106 Pareto optimal solutions from 1897 iterations, offering a balance between reducing energy consumption (10,942 to 20,250 kWh/year, averaging 60 % savings) and minimizing discomfort hours (296–1230 h). These results provide actionable insights for stakeholders in the retrofitting process, emphasizing the significant energy-saving potential of specific retrofit measures.",['non-dominated sorting genetic algorithm (NSGA-II)']
2024,https://openalex.org/W4391665000,Engineering,A comprehensive review of critical analysis of biodegradable waste PCM for thermal energy storage systems using machine learning and deep learning to predict dynamic behavior,"This article explores the use of phase change materials (PCMs) derived from waste, in energy storage systems. It emphasizes the potential of these PCMs in addressing concerns related to fossil fuel usage and environmental impact. This article also highlights the aspects of these PCMs including reduced reliance on renewable resources minimized greenhouse gas emissions and waste reduction. The study also discusses approaches such as integrating nanotechnology to enhance thermal conductivity and utilizing machine learning and deep learning techniques for predicting dynamic behavior. The article provides an overall view of research on biodegradable waste-based PCMs and how they can play a promising role in achieving energy-efficient and sustainable thermal storage systems. However, specific conclusions drawn from the presented results are not explicitly outlined, leaving room, for investigation and exploration in this evolving field. Artificial neural network (ANN) predictive models for thermal energy storage devices perform differently. With a 4% adjusted mean absolute error, the Gaussian radial basis function kernel Support Vector Regression (SVR) model captured heat-related charging and discharging issues. The ANN model predicted finned tube heat and heat flux better than the numerical model. SVM models outperformed ANN and ANFIS in some datasets. Material property predictions favored gradient boosting, but Linear Regression and SVR models performed better, emphasizing application- and dataset-specific model selection. These predictive models provide insights into the complex thermal performance of building structures, aiding in the design and operation of energy-efficient systems. Biodegradable waste-based PCMs' sustainability includes carbon footprint, waste reduction, biodegradability, and circular economy alignment. Nanotechnology, machine learning, and deep learning improve thermal conductivity and prediction. Circular economy principles include waste reduction and carbon footprint reduction. Specific results-based conclusions are not stated. Presenting a comprehensive overview of current research highlights biodegradable waste-based PCMs' potential for energy-efficient and sustainable thermal storage systems.","['machine learning', 'deep learning', 'Artificial neural network (ANN)', 'Gaussian radial basis function kernel Support Vector Regression (SVR)', 'ANN model', 'SVM models', 'ANFIS', 'gradient boosting', 'Linear Regression']"
2024,https://openalex.org/W4399369266,Engineering,Enhancing Skin Cancer Diagnosis Using Swin Transformer with Hybrid Shifted Window-Based Multi-head Self-attention and SwiGLU-Based MLP,"Abstract Skin cancer is one of the most frequently occurring cancers worldwide, and early detection is crucial for effective treatment. Dermatologists often face challenges such as heavy data demands, potential human errors, and strict time limits, which can negatively affect diagnostic outcomes. Deep learning–based diagnostic systems offer quick, accurate testing and enhanced research capabilities, providing significant support to dermatologists. In this study, we enhanced the Swin Transformer architecture by implementing the hybrid shifted window-based multi-head self-attention (HSW-MSA) in place of the conventional shifted window-based multi-head self-attention (SW-MSA). This adjustment enables the model to more efficiently process areas of skin cancer overlap, capture finer details, and manage long-range dependencies, while maintaining memory usage and computational efficiency during training. Additionally, the study replaces the standard multi-layer perceptron (MLP) in the Swin Transformer with a SwiGLU-based MLP, an upgraded version of the gated linear unit (GLU) module, to achieve higher accuracy, faster training speeds, and better parameter efficiency. The modified Swin model-base was evaluated using the publicly accessible ISIC 2019 skin dataset with eight classes and was compared against popular convolutional neural networks (CNNs) and cutting-edge vision transformer (ViT) models. In an exhaustive assessment on the unseen test dataset, the proposed Swin-Base model demonstrated exceptional performance, achieving an accuracy of 89.36%, a recall of 85.13%, a precision of 88.22%, and an F1-score of 86.65%, surpassing all previously reported research and deep learning models documented in the literature.","['Swin Transformer architecture', 'shifted window-based multi-head self-attention (SW-MSA)', 'multi-layer perceptron (MLP)', 'SwiGLU-based MLP', 'gated linear unit (GLU) module', 'convolutional neural networks (CNNs)', 'vision transformer (ViT) models']"
2024,https://openalex.org/W4391304535,Engineering,Sustainable electric discharge machining using alumina-mixed deionized water as dielectric: Process modelling by artificial neural networks underpinning net-zero from industry,"The requirement for materials possessing both high strength and low density has garnered significant attention from industries and researchers in recent times. Among these materials, aluminum 6061 (Al6061) exhibits the desired properties. However, due to its diverse machining capabilities, powder-mixed electric discharge machining (PMEDM) has emerged as a viable option for cutting such materials. This method has been criticized for its high energy consumption and limited cutting efficiency. Furthermore, conventional dielectric (kerosene) employed in EDM has drastic environmental and operator's health concerns. To address the abovementioned issues, deionized water has been employed in this study which enhances the reusability of resources and minimizes the cost of the dielectric. Herein, to make the process sustainable, and to keep the environment free from hazardous fumes, generated during the machining process, deionized water has been used. In addition to that, to uplift the machining responses, alumina (Al2O3) nano-powder has been engaged. To conduct the study, response surface methodology (RSM) was employed. This investigation aimed to analyze the impact on the material removal rate (MRR), surface roughness (SR), and specific energy consumption (SEC) by using microscopy analysis, scanning electron microscopy (SEM), 3D surfaces profilometry, energy dispersive x-ray (EDX) analysis and after that, the machining responses are modelled using the artificial neural networks (ANN) technique. It was observed that by utilizing non-dominated sorting genetic algorithms (NSGA-II) an improvement of 87.42 % in MRR, 3.4 % better surface finish and 0.7 % better SEC have been obtained. Notably, CO2 emissions were found to be 94.27 % lower by using the deionized water as dielectric compared to those produced by kerosene oil.","['artificial neural networks (ANN)', 'non-dominated sorting genetic algorithms (NSGA-II)']"
2024,https://openalex.org/W4393144919,Engineering,A Novel Fuzzy Neural Network Architecture Search Framework for Defect Recognition With Uncertainties,"Defect recognition is an important task in intelligent manufacturing. Due to the subjectivity of human annotation, the collected defect data usually contains a lot of noise and unpredictable uncertainties, which have a great negative influence on defect recognition. It is a significant challenge to discover an effective defect recognition model with satisfactory uncertainty processing ability. A natural way is to automatically search for an efficient deep model, which can be realized by neural architecture search (NAS). To achieve this, we propose an efficient fuzzy NAS framework for defect recognition, where the searched architecture can effectively handle uncertain information from the given datasets. Specifically, we first design a fuzzy search space and the related encoding strategy for fuzzy NAS. Then, we propose a comparator-based evolutionary search approach, where an online end-to-end comparator is learned to directly determine the selection of candidate architectures from the evolutionary population. The comparator works in an end-to-end way and it transforms the complex ranking problem of evaluating architectures into a simple classification task, which overcomes the rank disorder issue suffered from traditional performance predictors. A series of experimental results demonstrate that the architecture with fewer #Params (1.22 M) search by fuzzy neural architecture search framework for defect recognition method achieves higher accuracy (92.26%) compared to the state-of-the-art results (i.e., DARTS-PV) on the ELPV dataset, as well as competitive results (accuracy = 76.4%, #Params = 1.04 M) on the CODEBRIM dataset. Experimental results show the effectiveness and efficiency of our proposed method in handling uncertain problems.",['neural architecture search (NAS)']
2024,https://openalex.org/W4395479913,Engineering,Machinability investigation of natural fibers reinforced polymer matrix composite under drilling: Leveraging machine learning in bioengineering applications,"The growing demand for fiber-reinforced polymer (FRP) in industrial applications has prompted the exploration of natural fiber-based composites as a viable alternative to synthetic fibers. Using jute–rattan fiber-reinforced composite offers the potential for environmentally sustainable waste material decomposition and cost reduction compared to conventional fiber materials. This article focuses on the impact of different machining constraints on surface roughness and delamination during the drilling process of the jute–rattan FRP composite. Inspired by this unexplored research area, this article emphasizes the influence of various machining constraints on surface roughness and delamination in drilling jute–rattan FRP composite. Response surface methodology designs the experiment using drill bit material, spindle speed, and feed rate as input variables to measure surface roughness and delamination factors. The technique of order of preference by similarity to the ideal solution method is used to optimize the machining parameters, and for predicting surface roughness and delamination, two machine learning-based models named random forest (RF) and support vector machine (SVM) are utilized. To evaluate the accuracy of the predicted values, the correlation coefficient (R2), mean absolute percentage error, and mean squared error were used. RF performed better in comparison with SVM, with a higher value of R2 for both testing and training datasets, which is 0.997, 0.981, and 0.985 for surface roughness, entry delamination, and exit delamination, respectively. Hence, this study presents an innovative methodology for predicting surface roughness and delamination through machine learning techniques.","['random forest (RF)', 'support vector machine (SVM)']"
2024,https://openalex.org/W4396634174,Engineering,AISClean: AIS data-driven vessel trajectory reconstruction under uncertain conditions,"In maritime transportation, intelligent vessel surveillance has become increasingly prevalent and widespread by collecting and analyzing high massive spatial data from automatic identification system (AIS). The state-of-the-art AIS devices contain various functionalities, such as position transmission, tracking navigation, etc. Widely equipped shipboard AIS devices provide a large amount of real-time and historical vessel trajectory data for maritime management. However, the original AIS data often suffers from unwanted noise (i.e., poorly tracked timestamped points for vessel trajectories) and missing (i.e., no data is received or transmitted for a long term) data during signal acquisition, transmission, and analog-to-digital conversion. This degradation in data quality poses significant risks, including potential miscalculations in vessel collision avoidance systems, inaccuracies in emission calculations, and challenges in port management. In this work, a data-driven vessel trajectory reconstruction framework considering historical features is proposed to enhance the reliability of vessel trajectory. Specifically, a series of statistical methods are proposed to identify noisy data and missing data. Then, a model combining Geohash and dynamic time warping algorithms is developed to restore the trajectories degraded by random noise and missing data in vessel trajectories. Comparative experiments with baseline methods on multiple datasets verify the effectiveness of the proposed data-driven model.",['dynamic time warping']
2024,https://openalex.org/W4400234709,Engineering,Eco-friendly mix design of slag-ash-based geopolymer concrete using explainable deep learning,"Geopolymer concrete is a sustainable and eco-friendly substitute for traditional OPC (Ordinary Portland Cement) based concrete, as it reduces greenhouse gas emissions. With various supplementary cementitious materials, the compressive strength of geopolymer concrete should be accurately predicted. Recent studies have applied deep learning techniques to predict the compressive strength of geopolymer concrete yet its hidden decision-making criteria diminish the end-users' trust in predictions. To bridge this gap, the authors first developed three deep learning models: an artificial neural network (ANN), a deep neural network (DNN), and a 1D convolution neural network (CNN) to predict the compressive strength of slag ash-based geopolymer concrete. The performance indices for accuracy revealed that the DNN model outperforms the other two models. Subsequently, Shapley additive explanations (SHAP) were used to explain the best-performed deep learning model, DNN, and its compressive strength predictions. SHAP exhibited how the importance of each feature and its relationship contributes to the compressive strength prediction of the DNN model. Finally, the authors developed a novel DNN-based open-source software interface to predict the mix design proportions for a given target compressive strength (using inverse modeling technique) for slag ash-based geopolymer concrete. Additionally, the software calculates the Global Warming Potential (kg CO2 equivalent) for each mix design to select the mix designs with low greenhouse emissions.","['artificial neural network (ANN)', 'deep neural network (DNN)', '1D convolution neural network (CNN)', 'Shapley additive explanations (SHAP)']"
2024,https://openalex.org/W4400496339,Engineering,Metal–Organic Framework Stability in Water and Harsh Environments from Data-Driven Models Trained on the Diverse WS24 Data Set,"Metal-organic frameworks (MOFs) are porous materials with applications in gas separations and catalysis, but a lack of water stability often limits their practical use given the ubiquity of water. Consequently, it is useful to predict whether a MOF is water-stable before investing time and resources into synthesis. Existing heuristics for designing water-stable MOFs lack generality and limit the diversity of explored chemistry due to narrowly defined criteria. Machine learning (ML) models offer the promise to improve the generality of predictions but require data. In an improvement on previous efforts, we enlarge the available training data for MOF water stability prediction by over 400%, adding 911 MOFs with water stability labels assigned through semiautomated manuscript analysis to curate the new data set WS24. The additional data are shown to improve ML model performance (test ROC-AUC > 0.8) over diverse chemistry for the prediction of both water stability and stability in harsher acidic conditions. We illustrate how the expanded data set and models can be used with a previously developed activation stability model in combination with genetic algorithms to quickly screen ∼10,000 MOFs from a space of hundreds of thousands for candidates with multivariate stability (upon activation, in water, and in acid). We uncover metal- and geometry-specific design rules for robust MOFs. The data set and ML models developed in this work, which we disseminate through an easy-to-use web interface, are expected to contribute toward the accelerated discovery of novel, water-stable MOFs for applications such as direct air gas capture and water treatment.",['genetic algorithms']
2024,https://openalex.org/W4401015316,Engineering,Deep learning approaches for visual faults diagnosis of photovoltaic systems: State-of-the-Art review,"PV systems are prone to external environmental conditions that affect PV system operations. Visual inspection of the impacts of faults on PV system is considered a better practice rather than onsite fault detection mechanisms. Faults such as hotspot, dark area, cracks, glass break, wavy lines, snail tracks, corrosion, discoloration, junction box failure and delamination faults have different visual symptoms. EL technology, infrared thermography, and photoluminescence approaches are used to extract and visualize the impact of faults on PV modules. DL based algorithms such as, CNN, ANN, RNN, AE, DBN, TL and hybrid algorithms have shown promising results in domain of visual PV fault detection. This article critically overviews working mechanism of DL algorithms in terms of their limitations, complexity, interpretability, training dataset requirements and capability to work with another DL algorithms. This research article also reviews, critically analyzes, and systematically presents different clustering algorithms based on their clustering mechanism, distance metrics, convergence criteria. Additionally, their performance is also evaluated in terms of DI, CHI, DBI, S-score, and homogeneity. Moreover, this research work explicitly identifies and explains the limitations and contributions of recent and older techniques employed for features extraction, data preprocessing, and decision making by performing SWOT analysis. This research work also recommends future research directions for industry and academia.","['CNN', 'ANN', 'RNN', 'AE', 'clustering algorithms']"
2024,https://openalex.org/W4401075136,Engineering,Metaheuristic optimization algorithms-based prediction modeling for titanium dioxide-Assisted photocatalytic degradation of air contaminants,"Airborne contaminants pose significant environmental and health challenges. Titanium dioxide (TiO2) has emerged as a leading photocatalyst in the degradation of air contaminants compared to other photocatalysts due to its inherent inertness, cost-effectiveness, and photostability. To assess its effectiveness, laboratory examinations are frequently employed to measure the photocatalytic degradation rate of TiO2. However, this approach involves time-consuming requirements, labor-intensive tasks, and high costs. In literature, ensemble or standalone models are commonly used for assessing the performance of TiO2 photocatalytic degradation of water and air contaminants. Nonetheless, the application of metaheuristic hybrid models has the potential to be more effective in predictive accuracy and efficiency. Accordingly, this research utilized hybrid machine learning (ML) algorithms to estimate the photo-degradation rate constants of organic air pollutants using TiO2 nanoparticles and exposure to ultraviolet light. Six metaheuristics optimization algorithms, namely, nuclear reaction optimization (NRO), differential evolution algorithm (DEA), human felicity algorithm (HFA), lightning search algorithm (LSA), Harris hawks algorithm (HHA), and tunicate swarm algorithm (TSA) were combined with random forest (RF) technique to establish the hybrid models. A database of 200 data points was acquired from experimental studies for model training and testing. Furthermore, multiple statistical indicators and 10-fold cross-validation were employed to examine the established hybrid model's accuracy and robustness. The TSA-RF model demonstrated superior prediction accuracy among the six suggested models, achieving an impressive correlation (R) of 0.90 and a lower root mean square error (RMSE) of 0.25. In contrast, the HFA-RF, HHA-RF, and NRO-RF models exhibited a slightly lower R-value of 0.88, with RMSE scores of 0.32. The DEA-RF and LSA-RF models, while effective, showed a marginally lower R-value of 0.85, with RMSE values of 0.45 and 0.44, respectively. Moreover, the SHapley Additive exPlanation (SHAP) results indicated that the degradation rates of air contaminants through photocatalysis were most notably influenced by factors such as the reactor sizes, photocatalyst dosage, humidity, and intensity.","['random forest (RF)', 'differential evolution algorithm (DEA)', 'Harris hawks algorithm (HHA)', 'SHapley Additive exPlanation (SHAP)']"
2024,https://openalex.org/W4403158403,Engineering,Artificial intelligence alphafold model for molecular biology and drug discovery: a machine-learning-driven informatics investigation,"AlphaFold model has reshaped biological research. However, vast unstructured data in the entire AlphaFold field requires further analysis to fully understand the current research landscape and guide future exploration. Thus, this scientometric analysis aimed to identify critical research clusters, track emerging trends, and highlight underexplored areas in this field by utilizing machine-learning-driven informatics methods. Quantitative statistical analysis reveals that the AlphaFold field is enjoying an astonishing development trend (Annual Growth Rate = 180.13%) and global collaboration (International Co-authorship = 33.33%). Unsupervised clustering algorithm, time series tracking, and global impact assessment point out that Cluster 3 (Artificial Intelligence-Powered Advancements in AlphaFold for Structural Biology) has the greatest influence (Average Citation = 48.36 ± 184.98). Additionally, regression curve and hotspot burst analysis highlight ""structure prediction"" (s = 12.40, R2 = 0.9480, p = 0.0051), ""artificial intelligence"" (s = 5.00, R2 = 0.8096, p = 0.0375), ""drug discovery"" (s = 1.90, R2 = 0.7987, p = 0.0409), and ""molecular dynamics"" (s = 2.40, R2 = 0.8000, p = 0.0405) as core hotspots driving the research frontier. More importantly, the Walktrap algorithm further reveals that ""structure prediction, artificial intelligence, molecular dynamics"" (Relevance Percentage[RP] = 100%, Development Percentage[DP] = 25.0%), ""sars-cov-2, covid-19, vaccine design"" (RP = 97.8%, DP = 37.5%), and ""homology modeling, virtual screening, membrane protein"" (RP = 89.9%, DP = 26.1%) are closely intertwined with the AlphaFold model but remain underexplored, which implies a broad exploration space. In conclusion, through the machine-learning-driven informatics methods, this scientometric analysis offers an objective and comprehensive overview of global AlphaFold research, identifying critical research clusters and hotspots while prospectively pointing out underexplored critical areas.",['unsupervised clustering algorithm']
2024,https://openalex.org/W4390776100,Engineering,Hybrid KNN-SVM machine learning approach for solar power forecasting,"Predictions about solar power will have a significant impact on large-scale renewable energy plants. Photovoltaic (PV) power generation forecasting is particularly sensitive to measuring the uncertainty in weather conditions. Although several conventional techniques like long short-term memory (LSTM), support vector machine (SVM), etc. are available, but due to some restrictions, their application is limited. To enhance the precision of forecasting solar power from solar farms, a hybrid machine learning model that includes blends of the K-Nearest Neighbor (KNN) machine learning technique with the SVM to increase reliability for power system operators is proposed in this investigation. The conventional LSTM technique is also implemented to compare the performance of the proposed hybrid technique. The suggested hybrid model is improved by the use of structural diversity and data diversity in KNN and SVM, respectively. For the solar power predictions, the suggested method was tested on the Jodhpur real-time series dataset obtained from the data centers of weather stations using Meteonorm. The data set includes metrics such as Hourly Average Temperature (HAT), Hourly Total Sunlight Duration (HTSD), Hourly Total Global Solar Radiation (HTGSR), and Hourly Total Photovoltaic Energy Generation (HTPEG). The collated data has been segmented into training data, validation data, and testing data. Furthermore, the proposed technique performed better when evaluated on the three performance indices, viz., accuracy, sensitivity, and specificity. Compared with the conventional LSTM technique, the hybrid technique improved the prediction with 98% accuracy.","['long short-term memory (LSTM)', 'support vector machine (SVM)', 'K-Nearest Neighbor (KNN)', 'hybrid machine learning model (KNN + SVM)']"
2024,https://openalex.org/W4390939303,Engineering,A Reliable and Robust Deep Learning Model for Effective Recyclable Waste Classification,"In response to the growing waste problem caused by industrialization and modernization, the need for an automated waste sorting and recycling system for sustainable waste management has become ever more pressing. Deep learning has made significant advancements in image classification, making it ideally suited for waste sorting applications. This application depends on the development of a suitable deep learning model capable of accurately categorizing various categories of waste. In this study, we present RWC-Net (recyclable waste classification network), a novel deep learning model designed for the classification of six distinct waste categories using the TrashNet dataset of 2,527 images of waste. The performance of our model is subjected to intensive quantitative and qualitative evaluations and is compared to various state-of-art waste classification techniques. The proposed model outperformed several state-of-the-art models by obtaining a remarkable overall accuracy rate of 95.01 percent. In addition, it receives high F1-scores for each of the six waste categories: 97.24% for cardboard, 96.18% for glass, 94% for metal, 95.73% for paper, 93.67% for plastic, and 88.55% for litter. The reliability of the model is demonstrated qualitatively through the saliency maps generated by Score-CAM (class activation mapping) model, which provide visual insights into its performance across various waste categories. These results highlight the model's accuracy and demonstrate its potential as an effective automated waste classification and management solution.","['Deep learning', 'Score-CAM (class activation mapping)']"
2024,https://openalex.org/W4391202802,Engineering,Learning optimal inter-class margin adaptively for few-shot class-incremental learning via neural collapse-based meta-learning,"Few-Shot Class-Incremental Learning (FSCIL) aims to learn new classes incrementally with a limited number of samples per class. It faces issues of forgetting previously learned classes and overfitting on few-shot classes. An efficient strategy is to learn features that are discriminative in both base and incremental sessions. Current methods improve discriminability by manually designing inter-class margins based on empirical observations, which can be suboptimal. The emerging Neural Collapse (NC) theory provides a theoretically optimal inter-class margin for classification, serving as a basis for adaptively computing the margin. Yet, it is designed for closed, balanced data, not for sequential or few-shot imbalanced data. To address this gap, we propose a Meta-learning- and NC-based FSCIL method, MetaNC-FSCIL, to compute the optimal margin adaptively and maintain it at each incremental session. Specifically, we first compute the theoretically optimal margin based on the NC theory. Then we introduce a novel loss function to ensure that the loss value is minimized precisely when the inter-class margin reaches its theoretically best. Motivated by the intuition that ""learn how to preserve the margin"" matches the meta-learning's goal of ""learn how to learn"", we embed the loss function in base-session meta-training to preserve the margin for future meta-testing sessions. Experimental results demonstrate the effectiveness of MetaNC-FSCIL, achieving superior performance on multiple datasets. The code is available at https://github.com/qihangran/metaNC-FSCIL.","['Few-Shot Class-Incremental Learning (FSCIL)', 'Neural Collapse (NC) theory', 'Meta-learning']"
2024,https://openalex.org/W4392081637,Engineering,Hybrid deep learning models for time series forecasting of solar power,"Abstract Forecasting solar power production accurately is critical for effectively planning and managing renewable energy systems. This paper introduces and investigates novel hybrid deep learning models for solar power forecasting using time series data. The research analyzes the efficacy of various models for capturing the complex patterns present in solar power data. In this study, all of the possible combinations of convolutional neural network (CNN), long short-term memory (LSTM), and transformer (TF) models are experimented. These hybrid models also compared with the single CNN, LSTM and TF models with respect to different kinds of optimizers. Three different evaluation metrics are also employed for performance analysis. Results show that the CNN–LSTM–TF hybrid model outperforms the other models, with a mean absolute error (MAE) of 0.551% when using the Nadam optimizer. However, the TF–LSTM model has relatively low performance, with an MAE of 16.17%, highlighting the difficulties in making reliable predictions of solar power. This result provides valuable insights for optimizing and planning renewable energy systems, highlighting the significance of selecting appropriate models and optimizers for accurate solar power forecasting. This is the first time such a comprehensive work presented that also involves transformer networks in hybrid models for solar power forecasting.","['convolutional neural network (CNN)', 'long short-term memory (LSTM)', 'transformer (TF)', 'CNN–LSTM–TF hybrid model']"
2024,https://openalex.org/W4392499245,Engineering,Exploring the role of skin temperature in thermal sensation and thermal comfort: A comprehensive review,"The role of skin temperature as a determinant of human thermal sensation and comfort has gained increasing recognition, prompting a need for a systematic review. This review examines the relationship between skin temperature and thermal sensation, synthesizing insights from 172 studies published since 2000. It uniquely focuses on the indispensable roles of local and mean skin temperatures, a perspective not comprehensively explored in previous literature. The review reveals that the most common measurement points for skin temperature are the face and hands, attributed to their higher thermal sensitivity and the practical ease of measurement. It establishes a clear linear relationship between mean skin temperature and user thermal sensation, though affected by the choice of measurement locations and number of points. A notable finding is the varying impact of local skin temperature on overall thermal sensation in changing environments, with local heating less influential than cooling. The review also uncovers significant demographic variations in thermal sensation, strongly influenced by differing skin temperatures across age groups, genders, and climatic regions. For example, elderly populations exhibit a decreased temperature sensitivity, especially towards warmth. Gender differences are also significant, with females experiencing higher skin temperatures in warmer environments and lower in colder ones. Machine learning (ML)-based methods, especially classification tree-based and support vector machine (SVM) techniques, dominate in predicting thermal sensation and comfort, leveraging skin temperature data. While ML methods are prevalent, statistical regression-based approaches offer valuable empirical insights. Thermo-physiological model-based methods provide reliable results by incorporating detailed skin temperature dynamics. The review identifies a gap in understanding how gender, age, and regional differences influence thermal comfort in diverse environments. The study recommends conducting more nuanced experiments to dissect the impact of these factors and proposes the integration of individual demographic variables into ML models to personalize thermal comfort predictions.","['support vector machine (SVM)', 'statistical regression-based approaches']"
2024,https://openalex.org/W4392509422,Engineering,A novel framework for predicting active flow control by combining deep reinforcement learning and masked deep neural network,"Active flow control (AFC) through deep reinforcement learning (DRL) is computationally demanding. To address this, a masked deep neural network (MDNN), aiming to replace the computational fluid dynamics (CFD) environment, is developed to predict unsteady flow fields under the influence of arbitrary object motion. Then, a novel DRL-MDNN framework that combines the MDNN-based environment with the DRL algorithm is proposed. To validate the reliability of the framework, a blind test in a pulsating baffle system is designed. Vibration damping is considered to be the objective, and a traditional DRL-CFD framework is constructed for comparison. After training, a spatiotemporal evolution of 200 time steps under the influence of arbitrary object motion is predicted by the MDNN. The details of the flow field are compared with the CFD results, and a relative error within 5% is achieved, which satisfies the accuracy of serving as an interactive environment for DRL algorithms. The DRL-MDNN and traditional DRL-CFD frameworks are then applied to the pulsating baffle system to find the optimal control strategy. The results indicate that both frameworks achieve similar control performance, reducing vibration by 90%. Considering the resources expended in establishing the database, the computational resource consumption of the DRL-MDNN framework is reduced by 95%, and the interactive response time during each episode is decreased by 98.84% compared to the traditional DRL-CFD framework.",['deep reinforcement learning (DRL)']
2024,https://openalex.org/W4395069357,Engineering,Characterizing land use/land cover change dynamics by an enhanced random forest machine learning model: a Google Earth Engine implementation,"Abstract Land use and land cover (LULC) analysis is crucial for understanding societal development and assessing changes during the Anthropocene era. Conventional LULC mapping faces challenges in capturing changes under cloud cover and limited ground truth data. To enhance the accuracy and comprehensiveness of the descriptions of LULC changes, this investigation employed a combination of advanced techniques. Specifically, multitemporal 30 m resolution Landsat-8 satellite imagery was utilized, in addition to the cloud computing capabilities of the Google Earth Engine (GEE) platform. Additionally, the study incorporated the random forest (RF) algorithm. This study aimed to generate continuous LULC maps for 2014 and 2020 for the Shrirampur area of Maharashtra, India. A novel multiple composite RF approach based on LULC classification was utilized to generate the final LULC classification maps utilizing the RF-50 and RF-100 tree models. Both RF models utilized seven input bands (B1 to B7) as the dataset for LULC classification. By incorporating these bands, the models were able to influence the spectral information captured by each band to classify the LULC categories accurately. The inclusion of multiple bands enhanced the discrimination capabilities of the classifiers, increasing the comprehensiveness of the assessment of the LULC classes. The analysis indicated that RF-100 exhibited higher training and validation/testing accuracy for 2014 and 2020 (0.99 and 0.79/0.80, respectively). The study further revealed that agricultural land, built-up land, and water bodies have changed adequately and have undergone substantial variation among the LULC classes in the study area. Overall, this research provides novel insights into the application of machine learning (ML) models for LULC mapping and emphasizes the importance of selecting the optimal tree combination for enhancing the accuracy and reliability of LULC maps based on the GEE and different RF tree models. The present investigation further enabled the interpretation of pixel-level LULC interactions while improving image classification accuracy and suggested the best models for the classification of LULC maps through the identification of changes in LULC classes.",['random forest (RF) algorithm']
2024,https://openalex.org/W4396656165,Engineering,Analysing LULC transformations using remote sensing data: insights from a multilayer perceptron neural network approach,"The study examines the complex dynamics of changes in LULC over three decades, focused on the years 1992, 2002, 2012, and 2022. The research highlights the significance of comprehending these alterations within the framework of environmental and socio-economic consequences. The changes in land use and land cover (LULC) have significant and far-reaching effects on ecosystems, biodiversity, and human livelihoods. This study offers useful information for politicians, conservationists, and urban planners by examining historical patterns and forecasting future changes. The study utilized a Multilayer Perceptron Neural Network (MLP-NN), a well-known machine learning technique that excels at collecting intricate patterns. This model's design had three layers: input, hidden, and output. The model underwent 10,000 iterations during its training process, and a thorough statistical analysis was conducted to assess the impact of each driving component. The MLP-NN model demonstrated impressive performance, with a skill measure of 0.8724 and an accuracy rate of 89.08%. The accuracy of the LULC estimates for 2022 was verified by comparing them with observed data, ensuring the model's reliability. Moreover, the presence of evidence likely was found to be a significant factor that had a substantial impact on the accuracy of the model. The study highlights the effectiveness of the MLP-NN model in accurately predicting changes in LULC. The model's exceptional accuracy and proficiency make it a powerful tool for future LULC forecasts. Identifying the primary causes of model performance and understanding their implications may help to enhance land management strategies, encourage spatial planning, guide accurate decision-making, and facilitate the development of policies that align with sustainable growth and development.",['Multilayer Perceptron Neural Network (MLP-NN)']
2024,https://openalex.org/W4399154552,Engineering,Seeking in Ride-on-Demand Service: A Reinforcement Learning Model With Dynamic Price Prediction,"Recent years witness the increasing popularity of ride-on-demand (RoD) services such as Uber and Didi. Compared with traditional taxi, RoD service is more ""data-driven"" and adopts dynamic pricing to manipulate the supply and demand in real time. Dynamic price could be viewed as an accurate and quantitative indicator of the supply and demand, and could provide clues to drivers, passengers, and the service providers, possibly reshaping the ways in which some problems are solved. In this paper, we focus on the seeking route recommendation problem that aims at increasing driver revenue by recommending highly profitable seeking routes to drivers of vacant cars with the help of dynamic prices. We first justify our motivation by showing the importance of route recommendation and answering why it is necessary to consider dynamic prices, based on the analysis of real service data. We then design a dynamic price prediction model to generate the dynamic prices at any given time and location based on multi-source urban data. After that, a reinforcement learning model is adopted to perform seeking route recommendation based on predicted dynamic prices. We conduct extensive experiments in different spatio-temporal combinations and make comparisons with multiple baselines. Results first show that our dynamic price prediction model achieves an accuracy ranging from 83.82% to 90.67% under different settings. It also proves that considering the real-time predicted dynamic prices significantly increases driver revenue by, for example, 12% and 47.5% during weekday evening rush hours, than merely using the average prices or completely ignoring dynamic prices.",['reinforcement learning model']
2024,https://openalex.org/W4399734362,Engineering,Data oversampling and imbalanced datasets: an investigation of performance for machine learning and feature engineering,"Abstract The classification of imbalanced datasets is a prominent task in text mining and machine learning. The number of samples in each class is not uniformly distributed; one class contains a large number of samples while the other has a small number. Overfitting of the model occurs as a result of imbalanced datasets, resulting in poor performance. In this study, we compare different oversampling techniques like synthetic minority oversampling technique (SMOTE), support vector machine SMOTE (SVM-SMOTE), Border-line SMOTE, K-means SMOTE, and adaptive synthetic (ADASYN) oversampling to address the issue of imbalanced datasets and enhance the performance of machine learning models. Preprocessing significantly enhances the quality of input data by reducing noise, redundant data, and unnecessary data. This enables the machines to identify crucial patterns that facilitate the extraction of significant and pertinent information from the preprocessed data. This study preprocesses the data using various top-level preprocessing steps. Furthermore, two imbalanced Twitter datasets are used to compare the performance of oversampling techniques with six machine learning models including random forest (RF), SVM, K-nearest neighbor (KNN), AdaBoost (ADA), logistic regression (LR), and decision tree (DT). In addition, the bag of words (BoW) and term frequency and inverse document frequency (TF-IDF) features extraction approaches are used to extract features from the tweets. The experiments indicate that SMOTE and ADASYN perform much better than other techniques thus providing higher accuracy. Additionally, overall results show that SVM with ’linear’ kernel tends to attain the highest accuracy and recall score of 99.67% and 1.00% on ADASYN oversampled datasets and 99.57% accuracy on SMOTE oversampled dataset with TF-IDF features. The SVM model using 10-fold cross-validation experiments achieved 97.40 mean accuracy with a 0.008 standard deviation. Our approach achieved 2.62% greater accuracy as compared to other current methods.","['synthetic minority oversampling technique (SMOTE)', 'Border-line SMOTE', 'K-means SMOTE', 'adaptive synthetic (ADASYN) oversampling', 'random forest (RF)', 'SVM', 'K-nearest neighbor (KNN)', 'AdaBoost (ADA)', 'logistic regression (LR)', 'decision tree (DT)']"
2024,https://openalex.org/W4390618081,Engineering,Making Sense of Machine Learning: A Review of Interpretation Techniques and Their Applications,"Transparency in AI models is essential for promoting human–AI collaboration and ensuring regulatory compliance. However, interpreting these models is a complex process influenced by various methods and datasets. This study presents a comprehensive overview of foundational interpretation techniques, meticulously referencing the original authors and emphasizing their pivotal contributions. Recognizing the seminal work of these pioneers is imperative for contextualizing the evolutionary trajectory of interpretation in the field of AI. Furthermore, this research offers a retrospective analysis of interpretation techniques, critically evaluating their inherent strengths and limitations. We categorize these techniques into model-based, representation-based, post hoc, and hybrid methods, delving into their diverse applications. Furthermore, we analyze publication trends over time to see how the adoption of advanced computational methods within various categories of interpretation techniques has shaped the development of AI interpretability over time. This analysis highlights a notable preference shift towards data-driven approaches in the field. Moreover, we consider crucial factors such as the suitability of these techniques for generating local or global insights and their compatibility with different data types, including images, text, and tabular data. This structured categorization serves as a guide for practitioners navigating the landscape of interpretation techniques in AI. In summary, this review not only synthesizes various interpretation techniques but also acknowledges the contributions of their original authors. By emphasizing the origins of these techniques, we aim to enhance AI model explainability and underscore the importance of recognizing biases, uncertainties, and limitations inherent in the methods and datasets. This approach promotes the ethical and practical use of interpretation insights, empowering AI practitioners, researchers, and professionals to make informed decisions when selecting techniques for responsible AI implementation in real-world scenarios.","['model-based methods', 'representation-based methods', 'hybrid methods']"
2024,https://openalex.org/W4390686423,Engineering,Real-life data-driven model predictive control for building energy systems comparing different machine learning models,"By considering forecasts and exploiting storage effects, model predictive control can achieve significant energy and cost savings in the building sector. However, due to the high individual modeling effort, model predictive control lacks practical applicability. For that reason, data-driven process models, approximating the system behavior based on measurements, have become increasingly popular in recent years. Still, scientific literature lacks consent about the most promising model types and efficient workflows to integrate different machine learning models into a model predictive controller. With this work, we present a workflow to provide efficient model predictive controllers based on measurement data automatically. The main idea is to translate different machine learning models into optimization syntax to enable efficient optimization with full access to gradients. We currently consider artificial neural networks, gaussian process regression, and simple linear regression process models. We use a generic model ontology to automatize the controller generation further and test the methodology on two real-life use cases. The first use case is the application of five office rooms with smart thermostat valves. The second use case is a test hall with an air handling unit and a concrete core activation. Using only two days of initial training data, we deploy controllers based on the different model types for six weeks in the offices and apply online learning to improve the models continuously. We observe only minor differences in controller performance despite the artificial neural networks showing the highest prediction accuracy. The second use case shows that the simple linear models require less controller tuning effort. Thus, for practical applications, we recommend linear regression models.","['artificial neural networks', 'gaussian process regression', 'linear regression']"
2024,https://openalex.org/W4391684052,Engineering,Enhancing MPPT performance for partially shaded photovoltaic arrays through backstepping control with Genetic Algorithm-optimized gains,"As the significance and complexity of solar panel performance, particularly at their maximum power point (MPP), continue to grow, there is a demand for improved monitoring systems. The presence of variable weather conditions in Maroua, including potential partial shadowing caused by cloud cover or urban buildings, poses challenges to the efficiency of solar systems. This study introduces a new approach to tracking the Global Maximum Power Point (GMPP) in photovoltaic systems within the context of solar research conducted in Cameroon. The system utilizes Genetic Algorithm (GA) and Backstepping Controller (BSC) methodologies. The Backstepping Controller (BSC) dynamically adjusts the duty cycle of the Single Ended Primary Inductor Converter (SEPIC) to align with the reference voltage of the Genetic Algorithm (GA) in Maroua's dynamic environment. This environment, characterized by intermittent sunlight and the impact of local factors and urban shadowing, affects the production of energy. The Genetic Algorithm is employed to enhance the efficiency of BSC gains in Maroua's solar environment. This optimization technique expedites the tracking process and minimizes oscillations in the GMPP. The adaptability of the learning algorithm to specific conditions improves energy generation, even in the challenging environment of Maroua. This study introduces a novel approach to enhance the efficiency of photovoltaic systems in Maroua, Cameroon, by tailoring them to the specific solar dynamics of the region. In terms of performance, our approach surpasses the INC-BSC, P&O-BSC, GA-BSC, and PSO-BSC methodologies. In practice, the stabilization period following shadowing typically requires fewer than three iterations. Additionally, our Maximum Power Point Tracking (MPPT) technology is based on the Global Maximum Power Point (GMPP) methodology, contrasting with alternative technologies that prioritize the Local Maximum Power Point (LMPP). This differentiation is particularly relevant in areas with partial shading, such as Maroua, where the use of LMPP-based technologies can result in power losses. The proposed method demonstrates significant performance by achieving a minimum 33% reduction in power losses.",['Genetic Algorithm (GA)']
2024,https://openalex.org/W4399685394,Engineering,Advanced Modelling of Soil Organic Carbon Content in Coal Mining Areas Using Integrated Spectral Analysis: A Dengcao Coal Mine Case Study,"Effective modelling and integrated spectral analysis approaches can advance modelling precision. To develop an integrated spectral forecast modelling of soil organic carbon (SOC), this research investigated a mining coal in Dengcao Coal Mine Area, Zhengzhou. The study utilizes the Lasso and Ranger algorithms were utilized in spectral band analysis. Four primary models employed during this process include Artificial Neural Network (ANN), Support Vector Machine, Random Forest (RF), and Partial Least Squares Regression (PLSR). The ideal model was chosen. The results showed that, in contrast to when band collection was based on Lasso algorithm modelling, model precision was higher when it was based on the Ranger algorithm. ANN model had an ideal goodness acceptance, and the modelling developed by RF showed the steadiest modelling consequences. Based on the results, a distinct method is proposed in this study for band assortment at the earlier stage of integrated spectral modelling of SOC. The Ranger method can be used to check the spectral particles, and RF or ANN can be chosen to develop the prediction modelling based on different statistics sets, which is appropriate to create the prediction modelling of SOC content in Dengcao Coal Mine Area. This research avails a position for the integrated spectral of Analysis for Advanced Modelling of Soil Organic Carbon Content in Coal Sources alongside a theoretical foundation for innovating portable device for the integrated spectral assessment of SOC content in coal mining habitats. This study might be significant for the changing modelling and monitoring of SOC in mining and environmental areas.","['Lasso', 'Artificial Neural Network (ANN)', 'Support Vector Machine', 'Random Forest (RF)']"
2024,https://openalex.org/W4391359414,Engineering,Autopilot control unmanned aerial vehicle system for sewage defect detection using deep learning,"Abstract This work proposes the use of an unmanned aerial vehicle (UAV) with an autopilot to identify the defects present in municipal sewerage pipes. The framework also includes an effective autopilot control mechanism that can direct the flight path of a UAV within a sewer line. Both of these breakthroughs have been addressed throughout this work. The UAV's camera proved useful throughout a sewage inspection, providing important contextual data that helped analyze the sewerage line's internal condition. A plethora of information useful for understanding the sewerage line's inner functioning and extracting interior visual details can be obtained from camera‐recorded sewerage imagery if a defect is present. In the case of sewerage inspections, nevertheless, the impact of a false negative is significantly higher than that of a false positive. One of the trickiest parts of the procedure is identifying defective sewerage pipelines and false negatives. In order to get rid of the false negative outcome or false positive outcome, a guided image filter (GIF) is implemented in this proposed method during the pre‐processing stage. Afterwards, the algorithms Gabor transform (GT) and stroke width transform (SWT) were used to obtain the features of the UAV‐captured surveillance image. The UAV camera's sewerage image is then classified as “defective” or “not defective” using the obtained features by a Weighted Naive Bayes Classifier (WNBC). Next, images of the sewerage lines captured by the UAV are analyzed using speed‐up robust features (SURF) and deep learning to identify different types of defects. As a result, the proposed methodology achieved more favorable outcomes than prior existing approaches in terms of the following metrics: mean PSNR (71.854), mean MSE (0.0618), mean RMSE (0.2485), mean SSIM (98.71%), mean accuracy (98.372), mean specificity (97.837%), mean precision (93.296%), mean recall (94.255%), mean F1‐score (93.773%), and mean processing time (35.43 min).","['Weighted Naive Bayes Classifier (WNBC)', 'deep learning']"
2024,https://openalex.org/W4391092744,Engineering,DEA-Net: Single Image Dehazing Based on Detail-Enhanced Convolution and Content-Guided Attention,"Single image dehazing is a challenging ill-posed problem which estimates latent haze-free images from observed hazy images. Some existing deep learning based methods are devoted to improving the model performance via increasing the depth or width of convolution. The learning ability of Convolutional Neural Network (CNN) structure is still under-explored. In this paper, a Detail-Enhanced Attention Block (DEAB) consisting of Detail-Enhanced Convolution (DEConv) and Content-Guided Attention (CGA) is proposed to boost the feature learning for improving the dehazing performance. Specifically, the DEConv contains difference convolutions which can integrate prior information to complement the vanilla one and enhance the representation capacity. Then by using the re-parameterization technique, DEConv is equivalently converted into a vanilla convolution to reduce parameters and computational cost. By assigning the unique Spatial Importance Map (SIM) to every channel, CGA can attend more useful information encoded in features. In addition, a CGA-based mixup fusion scheme is presented to effectively fuse the features and aid the gradient flow. By combining above mentioned components, we propose our Detail-Enhanced Attention Network (DEA-Net) for recovering high-quality haze-free images. Extensive experimental results demonstrate the effectiveness of our DEA-Net, outperforming the state-of-the-art (SOTA) methods by boosting the PSNR index over 41 dB with only 3.653 M parameters. (The source code of our DEA-Net is available at https://github.com/cecret3350/DEA-Net.).","['Convolutional Neural Network (CNN)', 're-parameterization technique']"
2024,https://openalex.org/W4392367648,Engineering,Hardware implementation of memristor-based artificial neural networks,"Abstract Artificial Intelligence (AI) is currently experiencing a bloom driven by deep learning (DL) techniques, which rely on networks of connected simple computing units operating in parallel. The low communication bandwidth between memory and processing units in conventional von Neumann machines does not support the requirements of emerging applications that rely extensively on large sets of data. More recent computing paradigms, such as high parallelization and near-memory computing, help alleviate the data communication bottleneck to some extent, but paradigm- shifting concepts are required. Memristors, a novel beyond-complementary metal-oxide-semiconductor (CMOS) technology, are a promising choice for memory devices due to their unique intrinsic device-level properties, enabling both storing and computing with a small, massively-parallel footprint at low power. Theoretically, this directly translates to a major boost in energy efficiency and computational throughput, but various practical challenges remain. In this work we review the latest efforts for achieving hardware-based memristive artificial neural networks (ANNs), describing with detail the working principia of each block and the different design alternatives with their own advantages and disadvantages, as well as the tools required for accurate estimation of performance metrics. Ultimately, we aim to provide a comprehensive protocol of the materials and methods involved in memristive neural networks to those aiming to start working in this field and the experts looking for a holistic approach.","['deep learning (DL)', 'artificial neural networks (ANNs)']"
2024,https://openalex.org/W4400881081,Engineering,TransUNet: Rethinking the U-Net architecture design for medical image segmentation through the lens of transformers,"Medical image segmentation is crucial for healthcare, yet convolution-based methods like U-Net face limitations in modeling long-range dependencies. To address this, Transformers designed for sequence-to-sequence predictions have been integrated into medical image segmentation. However, a comprehensive understanding of Transformers' self-attention in U-Net components is lacking. TransUNet, first introduced in 2021, is widely recognized as one of the first models to integrate Transformer into medical image analysis. In this study, we present the versatile framework of TransUNet that encapsulates Transformers' self-attention into two key modules: (1) a Transformer encoder tokenizing image patches from a convolution neural network (CNN) feature map, facilitating global context extraction, and (2) a Transformer decoder refining candidate regions through cross-attention between proposals and U-Net features. These modules can be flexibly inserted into the U-Net backbone, resulting in three configurations: Encoder-only, Decoder-only, and Encoder+Decoder. TransUNet provides a library encompassing both 2D and 3D implementations, enabling users to easily tailor the chosen architecture. Our findings highlight the encoder's efficacy in modeling interactions among multiple abdominal organs and the decoder's strength in handling small targets like tumors. It excels in diverse medical applications, such as multi-organ segmentation, pancreatic tumor segmentation, and hepatic vessel segmentation. Notably, our TransUNet achieves a significant average Dice improvement of 1.06% and 4.30% for multi-organ segmentation and pancreatic tumor segmentation, respectively, when compared to the highly competitive nn-UNet, and surpasses the top-1 solution in the BrasTS2021 challenge. 2D/3D Code and models are available at https://github.com/Beckschen/TransUNet and https://github.com/Beckschen/TransUNet-3D, respectively.","['U-Net', 'Transformers', 'TransUNet', 'Transformer encoder', 'Transformer decoder', 'convolution neural network (CNN)', 'nn-UNet']"
2024,https://openalex.org/W4399657851,Engineering,Fusion of finite element and machine learning methods to predict rock shear strength parameters,"Abstract The trial-and-error method for calibrating rock mechanics parameters has the disadvantages of complexity, being time-consuming, and difficulty in ensuring accuracy. Harnessing the repeatability and scalability intrinsic to numerical simulation calculations and amalgamating them with the data-driven attributes of machine learning methods, this study uses the finite element analysis software RS2 to establish 252 sets of sandstone sample data. The recursive feature elimination and cross-validation method is employed for feature selection. The shear strength parameters of sandstone are predicted using machine learning models optimized by the particle swarm optimization (PSO) algorithm, including the backpropagation neural network, Bayesian ridge regression, support vector regression (SVR), and light gradient boosting machine. The predicted value of cohesion is proposed as the input feature to predict the friction angle. The results indicate that the optimal input characteristics for predicting cohesion are elastic modulus, Poisson's ratio, peak stress, and peak strain, while the optimal input characteristics for predicting friction angle are peak stress and cohesion. The PSO-SVR model demonstrates the best performance. The maximum error between the predicted values of cohesion and friction angle and the calculated results of RSData program are 3.5% and 4.31%, respectively. The finite element calculation is in good agreement with the stress–strain curve obtained in the laboratory. The sensitivity analysis indicates that SVR's prediction performance for cohesion and friction angle tends to be stable when the sample size is &amp;gt;25. These results offer a valuable reference for accurately predicting rock mechanics parameters.","['recursive feature elimination', 'backpropagation neural network', 'Bayesian ridge regression', 'support vector regression (SVR)', 'light gradient boosting machine']"
2024,https://openalex.org/W4392611940,Engineering,Deep learning-based structural health monitoring,"This article provides a comprehensive review of deep learning-based structural health monitoring (DL-based SHM). It encompasses a broad spectrum of DL theories and applications including nondestructive approaches; computer vision-based methods, digital twins, unmanned aerial vehicles (UAVs), and their integration with DL; vibration-based strategies including sensor fault and data recovery methods; and physics-informed DL approaches. Connections between traditional machine learning and DL-based methods as well as relations of local to global approaches including their extensive integrations are established. The state-of-the-art methods, including their advantages and limitations are presented. The review draws on current literature on the topic, also providing a synergistic analysis leading to the understanding of the evolution of DL as a basis for presenting the future research and development needs. Our overall finding is that despite the rapid progression of digital technology along with the progression of DL, the DL-based SHM appears to be in its infant stages with enormous potential for future developments to bring the SHM technology to a common practical use with wide scope applications, performance reliability, cost, and degree of automation. It is anticipated that this review paper will serve as a basic resource for readers seeking comprehensive and holistic understanding of the subject matter.","['deep learning (DL)', 'physics-informed deep learning (DL) approaches']"
2024,https://openalex.org/W4390706297,Engineering,TTST: A Top-<i>k</i> Token Selective Transformer for Remote Sensing Image Super-Resolution,"Transformer-based method has demonstrated promising performance in image super-resolution tasks, due to its long-range and global aggregation capability. However, the existing Transformer brings two critical challenges for applying it in large-area earth observation scenes: (1) redundant token representation due to most irrelevant tokens; (2) single-scale representation which ignores scale correlation modeling of similar ground observation targets. To this end, this paper proposes to adaptively eliminate the interference of irreverent tokens for a more compact self-attention calculation. Specifically, we devise a Residual Token Selective Group (RTSG) to grasp the most crucial token by dynamically selecting the top- <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> <tex-math notation=""LaTeX"">$k$ </tex-math></inline-formula> keys in terms of score ranking for each query. For better feature aggregation, a Multi-scale Feed-forward Layer (MFL) is developed to generate an enriched representation of multi-scale feature mixtures during feed-forward process. Moreover, we also proposed a Global Context Attention (GCA) to fully explore the most informative components, thus introducing more inductive bias to the RTSG for an accurate reconstruction. In particular, multiple cascaded RTSGs form our final Top- <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> <tex-math notation=""LaTeX"">$k$ </tex-math></inline-formula> Token Selective Transformer (TTST) to achieve progressive representation. Extensive experiments on simulated and real-world remote sensing datasets demonstrate our TTST could perform favorably against state-of-the-art CNN-based and Transformer-based methods, both qualitatively and quantitatively. In brief, TTST outperforms the state-of-the-art approach (HAT-L) in terms of PSNR by 0.14 dB on average, but only accounts for 47.26% and 46.97% of its computational cost and parameters. The code and pre-trained TTST will be available at <uri xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">https://github.com/XY-boy/TTST</uri> for validation.","['Transformer-based method', 'Global Context Attention (GCA)']"
2024,https://openalex.org/W4401070841,Engineering,Transformer-Based Visual Segmentation: A Survey,"Visual segmentation seeks to partition images, video frames, or point clouds into multiple segments or groups. This technique has numerous real-world applications, such as autonomous driving, image editing, robot sensing, and medical analysis. Over the past decade, deep learning-based methods have made remarkable strides in this area. Recently, transformers, a type of neural network based on self-attention originally designed for natural language processing, have considerably surpassed previous convolutional or recurrent approaches in various vision processing tasks. Specifically, vision transformers offer robust, unified, and even simpler solutions for various segmentation tasks. This survey provides a thorough overview of transformer-based visual segmentation, summarizing recent advancements. We first review the background, encompassing problem definitions, datasets, and prior convolutional methods. Next, we summarize a meta-architecture that unifies all recent transformer-based approaches. Based on this meta-architecture, we examine various method designs, including modifications to the meta-architecture and associated applications. We also present several specific subfields, including 3D point cloud segmentation, foundation model tuning, domain-aware segmentation, efficient segmentation, and medical segmentation. Additionally, we compile and re-evaluate the reviewed methods on several well-established datasets. Finally, we identify open challenges in this field and propose directions for future research. The project page can be found at <uri xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">https://github.com/lxtGH/Awesome-Segmentation-With-Transformer</uri> .","['transformers', 'convolutional approaches', 'recurrent approaches', 'vision transformers']"
2024,https://openalex.org/W4391974599,Engineering,"Generative AI for Transformative Healthcare: A Comprehensive Study of Emerging Models, Applications, Case Studies, and Limitations","Generative artificial intelligence (GAI) can be broadly described as an artificial intelligence system capable of generating images, text, and other media types with human prompts. GAI models like ChatGPT, DALL-E, and Bard have recently caught the attention of industry and academia equally. GAI applications span various industries like art, gaming, fashion, and healthcare. In healthcare, GAI shows promise in medical research, diagnosis, treatment, and patient care and is already making strides in real-world deployments. There has yet to be any detailed study concerning the applications and scope of GAI in healthcare. Addressing this research gap, we explore several applications, real-world scenarios, and limitations of GAI in healthcare. We examine how GAI models like ChatGPT and DALL-E can be leveraged to aid in the applications of medical imaging, drug discovery, personalized patient treatment, medical simulation and training, clinical trial optimization, mental health support, healthcare operations and research, medical chatbots, human movement simulation, and a few more applications. Along with applications, we cover four real-world healthcare scenarios that employ GAI: visual snow syndrome diagnosis, molecular drug optimization, medical education, and dentistry. We also provide an elaborate discussion on seven healthcare-customized LLMs like Med-PaLM, BioGPT, DeepHealth, etc.,Since GAI is still evolving, it poses challenges like the lack of professional expertise in decision making, risk of patient data privacy, issues in integrating with existing healthcare systems, and the problem of data bias which are elaborated on in this work along with several other challenges. We also put forward multiple directions for future research in GAI for healthcare.","['healthcare-customized LLMs like Med-PaLM', 'healthcare-customized LLMs like BioGPT']"
2024,https://openalex.org/W4390837884,Engineering,The deep learning applications in IoT-based bio- and medical informatics: a systematic literature review,"Abstract Nowadays, machine learning (ML) has attained a high level of achievement in many contexts. Considering the significance of ML in medical and bioinformatics owing to its accuracy, many investigators discussed multiple solutions for developing the function of medical and bioinformatics challenges using deep learning (DL) techniques. The importance of DL in Internet of Things (IoT)-based bio- and medical informatics lies in its ability to analyze and interpret large amounts of complex and diverse data in real time, providing insights that can improve healthcare outcomes and increase efficiency in the healthcare industry. Several applications of DL in IoT-based bio- and medical informatics include diagnosis, treatment recommendation, clinical decision support, image analysis, wearable monitoring, and drug discovery. The review aims to comprehensively evaluate and synthesize the existing body of the literature on applying deep learning in the intersection of the IoT with bio- and medical informatics. In this paper, we categorized the most cutting-edge DL solutions for medical and bioinformatics issues into five categories based on the DL technique utilized: convolutional neural network , recurrent neural network , generative adversarial network , multilayer perception , and hybrid methods. A systematic literature review was applied to study each one in terms of effective properties, like the main idea, benefits, drawbacks, methods, simulation environment, and datasets. After that, cutting-edge research on DL approaches and applications for bioinformatics concerns was emphasized. In addition, several challenges that contributed to DL implementation for medical and bioinformatics have been addressed, which are predicted to motivate more studies to develop medical and bioinformatics research progressively. According to the findings, most articles are evaluated using features like accuracy, sensitivity, specificity, F -score, latency, adaptability, and scalability.","['convolutional neural network', 'recurrent neural network', 'generative adversarial network', 'hybrid methods']"
2024,https://openalex.org/W4391018556,Engineering,Battery safety: Machine learning-based prognostics,"Lithium-ion batteries play a pivotal role in a wide range of applications, from electronic devices to large-scale electrified transportation systems and grid-scale energy storage. Nevertheless, they are vulnerable to both progressive aging and unexpected failures, which can result in catastrophic events such as explosions or fires. Given their expanding global presence, the safety of these batteries and potential hazards from serious malfunctions are now major public concerns. Over the past decade, scholars and industry experts are intensively exploring methods to monitor battery safety, spanning from materials to cell, pack and system levels and across various spectral, spatial, and temporal scopes. In this Review, we start by summarizing the mechanisms and nature of battery failures. Following this, we explore the intricacies in predicting battery system evolution and delve into the specialized knowledge essential for data-driven, machine learning models. We offer an exhaustive review spotlighting the latest strides in battery fault diagnosis and failure prognosis via an array of machine learning approaches. Our discussion encompasses: (1) supervised and reinforcement learning integrated with battery models, apt for predicting faults/failures and probing into failure causes and safety protocols at the cell level; (2) unsupervised, semi-supervised, and self-supervised learning, advantageous for harnessing vast data sets from battery modules/packs; (3) few-shot learning tailored for gleaning insights from scarce examples, alongside physics-informed machine learning to bolster model generalization and optimize training in data-scarce settings. We conclude by casting light on the prospective horizons of comprehensive, real-world battery prognostics and management.","['supervised learning', 'reinforcement learning', 'unsupervised learning', 'semi-supervised learning', 'self-supervised learning', 'few-shot learning', 'physics-informed machine learning']"
2024,https://openalex.org/W4391385913,Engineering,Chained machine learning model for predicting load capacity and ductility of steel fiber–reinforced concrete beams,"Abstract One of the main issues associated with steel fiber–reinforced concrete (SFRC) beams is the ability to anticipate their flexural response. With a comprehensive grid search, several stacked models (i.e., chained, parallel) consisting of various machine learning (ML) algorithms and artificial neural networks (ANNs) were developed to predict the flexural response of SFRC beams. The flexural performance of SFRC beams under bending was assessed based on 193 experimental specimens from real‐life beam models. The ML techniques were applied to predict SFRC beam responses to bending load as functions of the steel fiber properties, concrete elastic modulus, beam dimensions, and reinforcement details. The accuracy of the models was evaluated using the coefficient of determination (), mean absolute error (MAE), and root mean square error (RMSE) of actual versus predicted values. The findings revealed that the proposed technique exhibited notably superior performance, delivering faster and more accurate predictions compared to both the ANNs and parallel models. Shapley diagrams were used to analyze variable contributions quantitatively. Shapley values show that the chained model prediction of ductility index is highly affected by two other targets (peak load and peak deflection) that show the chained algorithm utilizing the prediction of previous steps for enhancing the prediction of the target feature. The proposed model can be viewed as a function of significant input variables that permit the quick assessment of the likely performance of SFRC beams in bending.","['stacked models (chained)', 'artificial neural networks (ANNs)']"
2024,https://openalex.org/W4396973073,Engineering,DA-TransUNet: integrating spatial and channel dual attention with transformer U-net for medical image segmentation,"Accurate medical image segmentation is critical for disease quantification and treatment evaluation. While traditional U-Net architectures and their transformer-integrated variants excel in automated segmentation tasks. Existing models also struggle with parameter efficiency and computational complexity, often due to the extensive use of Transformers. However, they lack the ability to harness the image’s intrinsic position and channel features. Research employing Dual Attention mechanisms of position and channel have not been specifically optimized for the high-detail demands of medical images. To address these issues, this study proposes a novel deep medical image segmentation framework, called DA-TransUNet, aiming to integrate the Transformer and dual attention block (DA-Block) into the traditional U-shaped architecture. Also, DA-TransUNet tailored for the high-detail requirements of medical images, optimizes the intermittent channels of Dual Attention (DA) and employs DA in each skip-connection to effectively filter out irrelevant information. This integration significantly enhances the model’s capability to extract features, thereby improving the performance of medical image segmentation. DA-TransUNet is validated in medical image segmentation tasks, consistently outperforming state-of-the-art techniques across 5 datasets. In summary, DA-TransUNet has made significant strides in medical image segmentation, offering new insights into existing techniques. It strengthens model performance from the perspective of image features, thereby advancing the development of high-precision automated medical image diagnosis. The codes and parameters of our model will be publicly available at https://github.com/SUN-1024/DA-TransUnet .","['U-Net architectures', 'Dual Attention mechanisms', 'DA-TransUNet']"
2024,https://openalex.org/W4401819987,Engineering,"Artificial intelligence for geoscience: Progress, challenges and perspectives","Public summary•What does AI bring to geoscience? AI has been accelerating and deepening our understanding of Earth Systems in an unprecedented way, including the atmosphere, lithosphere, hydrosphere, cryosphere, biosphere, anthroposphere and the interactions between spheres.•What are the noteworthy challenges of AI in geoscience? As we embrace the huge potential of AI in geoscience, several challenges arise including reliability and interpretability, ethical issues, data security, and high demand and cost.•What is the future of AI in geoscience? The synergy between traditional principles and modern AI-driven techniques holds immense promise and will shape the trajectory of geoscience in upcoming years.AbstractThis paper explores the evolution of geoscientific inquiry, tracing the progression from traditional physics-based models to modern data-driven approaches facilitated by significant advancements in artificial intelligence (AI) and data collection techniques. Traditional models, which are grounded in physical and numerical frameworks, provide robust explanations by explicitly reconstructing underlying physical processes. However, their limitations in comprehensively capturing Earth's complexities and uncertainties pose challenges in optimization and real-world applicability. In contrast, contemporary data-driven models, particularly those utilizing machine learning (ML) and deep learning (DL), leverage extensive geoscience data to glean insights without requiring exhaustive theoretical knowledge. ML techniques have shown promise in addressing Earth science-related questions. Nevertheless, challenges such as data scarcity, computational demands, data privacy concerns, and the ""black-box"" nature of AI models hinder their seamless integration into geoscience. The integration of physics-based and data-driven methodologies into hybrid models presents an alternative paradigm. These models, which incorporate domain knowledge to guide AI methodologies, demonstrate enhanced efficiency and performance with reduced training data requirements. This review provides a comprehensive overview of geoscientific research paradigms, emphasizing untapped opportunities at the intersection of advanced AI techniques and geoscience. It examines major methodologies, showcases advances in large-scale models, and discusses the challenges and prospects that will shape the future landscape of AI in geoscience. The paper outlines a dynamic field ripe with possibilities, poised to unlock new understandings of Earth's complexities and further advance geoscience exploration.Graphical abstract","['machine learning (ML)', 'deep learning (DL)', 'hybrid models']"
2024,https://openalex.org/W4398243924,Engineering,Optimizing renewable energy systems through artificial intelligence: Review and future prospects,"The global transition toward sustainable energy sources has prompted a surge in the integration of renewable energy systems (RES) into existing power grids. To improve the efficiency, reliability, and economic viability of these systems, the synergistic application of artificial intelligence (AI) methods has emerged as a promising avenue. This study presents a comprehensive review of the current state of research at the intersection of renewable energy and AI, highlighting key methodologies, challenges, and achievements. It covers a spectrum of AI utilizations in optimizing different facets of RES, including resource assessment, energy forecasting, system monitoring, control strategies, and grid integration. Machine learning algorithms, neural networks, and optimization techniques are explored for their role in complex data sets, enhancing predictive capabilities, and dynamically adapting RES. Furthermore, the study discusses the challenges faced in the implementation of AI in RES, such as data variability, model interpretability, and real-time adaptability. The potential benefits of overcoming these challenges include increased energy yield, reduced operational costs, and improved grid stability. The review concludes with an exploration of prospects and emerging trends in the field. Anticipated advancements in AI, such as explainable AI, reinforcement learning, and edge computing, are discussed in the context of their potential impact on optimizing RES. Additionally, the paper envisions the integration of AI-driven solutions into smart grids, decentralized energy systems, and the development of autonomous energy management systems. This investigation provides important insights into the current landscape of AI applications in RES.","['neural networks', 'reinforcement learning']"
2024,https://openalex.org/W4392931267,Engineering,Dynamic Event-Triggered Control for a Class of Uncertain Strict-Feedback Systems via an Improved Adaptive Neural Networks Backstepping Approach,"This article focuses on a dynamic event-triggered adaptive neural networks backstepping control for a class of uncertain strict-feedback systems with communication constraints. The uncertain terms including external disturbances and unknown nonlinear functions are approximated by radial basis function neural networks, in which the weight update laws are obtained via the gradient descent algorithm, ensuring the local boundedness of the approximation error of neural networks. Then, to enhance the transmission efficiency of control signals, a dynamic event-triggered mechanism is introduced, which enables the dynamic adjustment of threshold parameters in response to the actual tracking performance. It is strictly proved via the Lyapunov stability criterion that the tracking error can converge to a desired small neighborhood of the origin, and all signals in the closed-loop system are bounded. Finally, the validity of the control strategy is demonstrated through a simulation example. <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">Note to Practitioners</i> — In practical network control systems, control signals are typically transmitted continuously or periodically to devices through the communication network in the form of data packets. As communication networks are usually shared by various system nodes, and resources such as communication channel bandwidth and computational capabilities are limited, improving the transmission efficiency of control signals becomes a crucial design problem for controllers in network control systems. Therefore, This study introduces a control method via event-triggered sampling, aiming to enhance sampling efficiency while ensuring the stability and reliability of the system. The proposed control method is suitable for a broad category of strict-feedback nonlinear systems with communication constraints, offering notable advantages such as low-complexity design and straightforward implementation.","['radial basis function neural networks', 'gradient descent algorithm']"
2024,https://openalex.org/W4392503764,Engineering,Mental-LLM,"Advances in large language models (LLMs) have empowered a variety of applications. However, there is still a significant gap in research when it comes to understanding and enhancing the capabilities of LLMs in the field of mental health. In this work, we present a comprehensive evaluation of multiple LLMs on various mental health prediction tasks via online text data, including Alpaca, Alpaca-LoRA, FLAN-T5, GPT-3.5, and GPT-4. We conduct a broad range of experiments, covering zero-shot prompting, few-shot prompting, and instruction fine-tuning. The results indicate a promising yet limited performance of LLMs with zero-shot and few-shot prompt designs for mental health tasks. More importantly, our experiments show that instruction finetuning can significantly boost the performance of LLMs for all tasks simultaneously. Our best-finetuned models, Mental-Alpaca and Mental-FLAN-T5, outperform the best prompt design of GPT-3.5 (25 and 15 times bigger) by 10.9% on balanced accuracy and the best of GPT-4 (250 and 150 times bigger) by 4.8%. They further perform on par with the state-of-the-art task-specific language model. We also conduct an exploratory case study on LLMs' capability on mental health reasoning tasks, illustrating the promising capability of certain models such as GPT-4. We summarize our findings into a set of action guidelines for potential methods to enhance LLMs' capability for mental health tasks. Meanwhile, we also emphasize the important limitations before achieving deployability in real-world mental health settings, such as known racial and gender bias. We highlight the important ethical risks accompanying this line of research.","['zero-shot prompting', 'few-shot prompting', 'instruction fine-tuning']"
2024,https://openalex.org/W4392239564,Engineering,Human-AI collaboration patterns in AI-assisted academic writing,"Artificial Intelligence (AI) has increasingly influenced higher education, notably in academic writing where AI-powered assisting tools offer both opportunities and challenges. Recently, the rapid growth of generative AI (GAI) has brought its impacts into sharper focus, yet the dynamics of its utilisation in academic writing remain largely unexplored. This paper focuses on examining the nature of human-AI interactions in academic writing, specifically investigating the strategies doctoral students employ when collaborating with a GAI-powered assisting tool. This study involves 626 recorded activities on how ten doctoral students interact with GAI-powered assisting tool during academic writing. AI-driven learning analytics approach was adopted for three layered analyses: (1) data pre-processing and analysis with quantitative content analysis, (2) sequence analysis with Hidden Markov Model (HMM) and hierarchical sequence clustering, and (3) pattern analysis with process mining. Findings indicate that doctoral students engaging in iterative, highly interactive processes with the GAI-powered assisting tool generally achieve better performance in the writing task. In contrast, those who use GAI merely as a supplementary information source, maintaining a linear writing approach, tend to get lower writing performance. This study points to the need for further investigations into human-AI collaboration in learning in higher education, with implications for tailored educational strategies and solutions.",['Hidden Markov Model (HMM)']
2024,https://openalex.org/W4393072087,Engineering,FI-NPI: Exploring Optimal Control in Parallel Platform Systems,"Typically, the current and speed loop closure of servo motor of the parallel platform is accomplished with incremental PI regulation. The control method has strong robustness, but the parameter tuning process is cumbersome, and it is difficult to achieve the optimal control state. In order to further optimize the performance, this paper proposes a double-loop control structure based on fuzzy integral and neuron proportional integral (FI-NPI). The structure makes full use of the control advantages of the fuzzy controller and integrator to improve the performance of speed closed-loop control. And through the feedforward branch, the speed error is used as the teacher signal for neuron supervised learning, which improves the effect of current closed-loop control. Through comparative simulation experiments, this paper verifies that the FI-NPI controller has a faster dynamic response speed than the traditional PI controller. Finally, in this paper, the FI-NPI controller is implemented in C language in the servo-driven lower computer, and the speed closed-loop test of the BLDC motor is carried out. The experimental results show that the FI-NPI double-loop controller is better than the traditional double-PI controller in performance indicators such as convergence rate and RMSE, which confirms that the FI-NPI double-loop controller is more suitable for BLDC servo control.",['fuzzy integral']
2024,https://openalex.org/W4390770894,Engineering,"A review on microgrid optimization with meta-heuristic techniques: Scopes, trends and recommendation","Microgrids (MGs) use renewable sources to meet the growing demand for energy with increasing consumer needs and technological advancement. They operate independently as small-scale energy networks using distributed energy resources. However, the intermittent nature of renewable energy sources and poor power quality are essential operational problems that must be mitigated to improve the MG's performance. To address these challenges, researchers have introduced heuristic optimization mechanisms for MGs. However, local minima and the inability to find a global minimum in heuristic methods create errors in non-linear and nonconvex optimization, posing challenges in dealing with several operational aspects of MG such as energy management optimization, cost-effective dispatch, dependability, storage sizing, cyber-attack minimization, and grid integration. These challenges affect MG's performance by adding complexity to the management of storage capacity, cost minimization, reliability assurance, and balance of renewable sources, which accelerates the need for meta-heuristic optimization algorithms (MHOAs). This paper presents a state-of-the-art review of MHOAs and their role in improving the operational performance of MGs. Firstly, the fundamentals of MG optimization are discussed to explore the scopes, requisites, and opportunities of MHOAs in MG networks. Secondly, several MHOAs in the MG domain are described, and their recent trends in MG's techno-economic analysis, load forecasting, resiliency improvement, control operation, fault diagnosis, and energy management are summarized. The summary reveals that nearly 25% of the research in these areas utilizes the particle swarm optimization method, while the genetic and grey wolf algorithms are utilized by nearly 10% and 5% of the works studied in this paper, respectively, for optimizing the MG's performance. This result summarizes that MHOA presents a system-agnostic optimization approach, offering a new avenue for enhancing the effectiveness of future MGs. Finally, we highlight some challenges that emerge during the integration of MHOAs into MGs, potentially motivating researchers to conduct further studies in this area.","['genetic algorithm', 'grey wolf algorithm']"
2024,https://openalex.org/W4392465065,Engineering,A novel Swin transformer approach utilizing residual multi-layer perceptron for diagnosing brain tumors in MRI images,"Abstract Serious consequences due to brain tumors necessitate a timely and accurate diagnosis. However, obstacles such as suboptimal imaging quality, issues with data integrity, varying tumor types and stages, and potential errors in interpretation hinder the achievement of precise and prompt diagnoses. The rapid identification of brain tumors plays a pivotal role in ensuring patient safety. Deep learning-based systems hold promise in aiding radiologists to make diagnoses swiftly and accurately. In this study, we present an advanced deep learning approach based on the Swin Transformer. The proposed method introduces a novel Hybrid Shifted Windows Multi-Head Self-Attention module (HSW-MSA) along with a rescaled model. This enhancement aims to improve classification accuracy, reduce memory usage, and simplify training complexity. The Residual-based MLP (ResMLP) replaces the traditional MLP in the Swin Transformer, thereby improving accuracy, training speed, and parameter efficiency. We evaluate the Proposed-Swin model on a publicly available brain MRI dataset with four classes, using only test data. Model performance is enhanced through the application of transfer learning and data augmentation techniques for efficient and robust training. The Proposed-Swin model achieves a remarkable accuracy of 99.92%, surpassing previous research and deep learning models. This underscores the effectiveness of the Swin Transformer with HSW-MSA and ResMLP improvements in brain tumor diagnosis. This method introduces an innovative diagnostic approach using HSW-MSA and ResMLP in the Swin Transformer, offering potential support to radiologists in timely and accurate brain tumor diagnosis, ultimately improving patient outcomes and reducing risks.","['Swin Transformer', 'Residual-based MLP (ResMLP)', 'transfer learning']"
2024,https://openalex.org/W4394935921,Engineering,Machine learning-based predictive model for thermal comfort and energy optimization in smart buildings,"In the current context of energy transition and increasing climate change, optimizing building performance has become a critical objective. Efficient energy use and occupant comfort are paramount considerations in building design and operation. To address these challenges, this study introduces a predictive model leveraging Machine Learning (ML) algorithms. The model aims to predict thermal comfort levels and optimize energy consumption in Heating, Ventilation, and Air Conditioning (HVAC) systems. Four distinct ML algorithms Support Vector Machine (SVM), Artificial Neural Network (ANN), Random Forest (RF), and EXtreme Gradient Boosting (XGBOOST) are employed for this purpose. Data for the model is collected using a network of Raspberry Pi boards equipped with multiple sensors. Performance evaluation of the ML algorithms is conducted using statistical error metrics, including, Root Mean Square Error (RMSE), Mean Square Error (MSE), Mean Absolute Error (MAE), and coefficient of determination (R2). Results reveal that the RF and XGBOOST algorithms exhibit superior performance, achieving accuracies of 96.7% and 9.64% respectively. In contrast, the SVM algorithm demonstrates inferior performance with a R2 of 81.1%. These findings underscore the predictive capability of the RF and XGBOOST model in forecasting Predicted Mean Vote (PMV) values. The proposed model holds promise for enhancing occupant thermal comfort in buildings while simultaneously optimizing energy consumption in HVAC systems. Further research could explore the practical applications of these findings in building design and operation.","['Support Vector Machine (SVM)', 'Artificial Neural Network (ANN)', 'Random Forest (RF)', 'EXtreme Gradient Boosting (XGBOOST)']"
2024,https://openalex.org/W4400020165,Engineering,"Big data, machine learning, and digital twin assisted additive manufacturing: A review","Additive manufacturing (AM) has undergone significant development over the past decades, resulting in vast amounts of data that carry valuable information. Numerous research studies have been conducted to extract insights from AM data and utilize it for optimizing various aspects such as the manufacturing process, supply chain, and real-time monitoring. Data integration into proposed digital twin frameworks and the application of machine learning techniques is expected to play pivotal roles in advancing AM in the future. In this paper, we provide an overview of machine learning and digital twin-assisted AM. On one hand, we discuss the research domain and highlight the machine-learning methods utilized in this field, including material analysis, design optimization, process parameter optimization, defect detection and monitoring, and sustainability. On the other hand, we examine the status of digital twin-assisted AM from the current research status to the technical approach and offer insights into future developments and perspectives in this area. This review paper aims to examine present research and development in the convergence of big data, machine learning, and digital twin-assisted AM. Although there are numerous review papers on machine learning for additive manufacturing and others on digital twins for AM, no existing paper has considered how these concepts are intrinsically connected and interrelated. Our paper is the first to integrate the three concepts big data, machine learning, and digital twins and propose a cohesive framework for how they can work together to improve the efficiency, accuracy, and sustainability of AM processes. By exploring latest advancements and applications within these domains, our objective is to emphasize the potential advantages and future possibilities associated with integration of these technologies in AM.",['machine learning']
2024,https://openalex.org/W4390494339,Engineering,"A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection in Industrial Time Series: Methods, Applications, and Directions","Automating the monitoring of industrial processes has the potential to enhance efficiency and optimize quality by promptly detecting abnormal events and thus facilitating timely interventions. Deep learning, with its capacity to discern non-trivial patterns within large datasets, plays a pivotal role in this process. Standard deep learning methods are suitable to solve a specific task given a specific type of data. During training, deep learning demands large volumes of labeled data. However, due to the dynamic nature of the industrial processes and environment, it is impractical to acquire large-scale labeled data for standard deep learning training for every slightly different case anew. Deep transfer learning offers a solution to this problem. By leveraging knowledge from related tasks and accounting for variations in data distributions, the transfer learning framework solves new tasks with little or even no additional labeled data. The approach bypasses the need to retrain a model from scratch for every new setup and dramatically reduces the labeled data requirement. This survey first provides an in-depth review of deep transfer learning, examining the problem settings of transfer learning and classifying the prevailing deep transfer learning methods. Moreover, we delve into applications of deep transfer learning in the context of a broad spectrum of time series anomaly detection tasks prevalent in primary industrial domains, e.g., manufacturing process monitoring, predictive maintenance, energy management, and infrastructure facility monitoring. We discuss the challenges and limitations of deep transfer learning in industrial contexts and conclude the survey with practical directions and actionable suggestions to address the need to leverage diverse time series data for anomaly detection in an increasingly dynamic production environment.","['deep learning', 'deep transfer learning', 'transfer learning framework']"
2024,https://openalex.org/W4393162950,Engineering,Predicting the thermal distribution in a convective wavy fin using a novel training physics-informed neural network method,"Abstract Fins are widely used in many industrial applications, including heat exchangers. They benefit from a relatively economical design cost, are lightweight, and are quite miniature. Thus, this study investigates the influence of a wavy fin structure subjected to convective effects with internal heat generation. The thermal distribution, considered a steady condition in one dimension, is described by a unique implementation of a physics-informed neural network (PINN) as part of machine-learning intelligent strategies for analyzing heat transfer in a convective wavy fin. This novel research explores the use of PINNs to examine the effect of the nonlinearity of temperature equation and boundary conditions by altering the hyperparameters of the architecture. The non-linear ordinary differential equation (ODE) involved with heat transfer is reduced into a dimensionless form utilizing the non-dimensional variables to simplify the problem. Furthermore, Runge–Kutta Fehlberg’s fourth–fifth order (RKF-45) approach is implemented to evaluate the simplified equations numerically. To predict the wavy fin's heat transfer properties, an advanced neural network model is created without using a traditional data-driven approach, the ability to solve ODEs explicitly by incorporating a mean squared error-based loss function. The obtained results divulge that an increase in the thermal conductivity variable upsurges the thermal distribution. In contrast, a decrease in temperature profile is caused due to the augmentation in the convective-conductive variable values.",['physics-informed neural network (PINN)']
2024,https://openalex.org/W4399326707,Engineering,Enhancing precision agriculture: A comprehensive review of machine learning and AI vision applications in all-terrain vehicle for farm automation,"The automation of all-terrain vehicles (ATVs) through the integration of advanced technologies such as machine learning (ML) and artificial intelligence (AI) vision has significantly changed precision agriculture. This paper aims to analyse and develop trends to provide comprehensive knowledge of the current state of ATV-based precision agriculture and the future possibilities of ML and AI. A bibliometric analysis was conducted through network diagram with keywords taken from previous publications in the domain. This review comprehensively analyses the potential of machine learning and artificial intelligence in transforming farming operations through the automation of tasks and the deployment of all-terrain vehicles. The research extensively analyses how machine learning methods have influenced several aspects of agricultural activities, such as planting, harvesting, spraying, weeding, crop monitoring, and others. AI vision systems are being researched for their ability to enhance precise and prompt decision-making in ATV-driven agricultural automation. These technologies have been thoroughly tested to show how they can improve crop yield, reducing overall investment, and make farming more efficient. Examples include machine learning-based seeding accuracy, AI-enabled crop health monitoring, and the use of AI vision for accurate pesticide application. The assessment examines challenges such as data privacy problems and scalability constraints, along with potential advancements and future prospects in the field. This will assist researchers and practitioners in making well-informed judgments regarding farming practices that are efficient, sustainable, and technologically robust.",['machine learning']
2024,https://openalex.org/W4390604402,Engineering,A novel and dynamic land use/cover change research framework based on an improved PLUS model and a fuzzy multiobjective programming model,"Spatial reconstruction and scenario simulation of historical processes and future trends of land use/cover change (LUCC) can help to reveal the historical background of land conversion and the spatial distribution of future land. Moreover, there is a close relationship between the spatiotemporal dynamics of land use/cover and changes in different ecosystem services (ESs). Using this relationship to simulate future land use scenarios is important. In this study, an LUCC dynamic analysis framework (LSTM-PLUS-FMOP) was constructed based on a deep learning time series forecasting model (LSTM), a parallelized urban land use simulation (PLUS) model and a fuzzy multiobjective programming (FMOP) model. The PLUS model was used to analyze the driving mechanism of land expansion and explore the land conversion pattern. In addition, three land conversion scenarios were established: natural land expansion (NLE), economic development priority (EDP) and regional sustainable development (RSD). The FMOP model and the relationship between LUCC and ES were used to perform a spatial simulation of land conversion. The uncertainty parameters in the model were treated by intuitionistic fuzzy numbers (IFSs). This study applied the constructed framework to the Yellow River Basin of Shaanxi Province (YRB-SX). The results showed that (1) from 2000 to 2020, the cropland area of the YRB-SX continuously decreased by 12.67 × 104 ha, while the built-up area continuously increased by 28.25 × 104 ha. The net reduction in woodland and grassland area was 13.90 × 104 ha. (2) The relative error range of land prediction using the LSTM model was 0.0003– 0.0042. This model had better accuracy than the Markov chain prediction model. (3) The cropland area decreased by 0.26% (NLE), 0.85% (EDP) and 1.68% (RSD) under the three scenarios. The built-up area increased by 25.01%, 32.76% and 14.72%, respectively. The RSD scenario followed the principles of ecological protection and spatial constraints, which mitigated the degradation of the ecosystem to some extent. This coupled simulation framework will help to obtain land allocation schemes that meet the requirements of ecological protection and provide solutions for rational land management.",['LSTM']
2024,https://openalex.org/W4391168980,Engineering,Utilizing Hybrid Machine Learning and Soft Computing Techniques for Landslide Susceptibility Mapping in a Drainage Basin,"The hydrological system of thebasin of Lake Urmia is complex, deriving its supply from a network comprising 13 perennial rivers, along withnumerous small springs and direct precipitation onto the lake’s surface. Among these contributors, approximately half of the inflow is attributed to the Zarrineh River and the Simineh River. Remarkably, Lake Urmia lacks a natural outlet, with its water loss occurring solely through evaporation processes. This study employed a comprehensive methodology integrating ground surveys, remote sensing analyses, and meticulous documentation of historical landslides within the basin as primary information sources. Through this investigative approach, we preciselyidentified and geolocated a total of 512 historical landslide occurrences across the Urmia Lake drainage basin, leveraging GPS technology for precision. Thisarticle introduces a suite of hybrid machine learning predictive models, such as support-vector machine (SVM), random forest (RF), decision trees (DT), logistic regression (LR), fuzzy logic (FL), and the technique for order of preference by similarity to the ideal solution (TOPSIS). These models were strategically deployed to assess landslide susceptibility within the region. The outcomes of the landslide susceptibility assessment reveal that the main high susceptible zones for landslide occurrence are concentrated in the northwestern, northern, northeastern, and some southern and southeastern areas of the region. Moreover, when considering the implementation of predictions using different algorithms, it became evident that SVM exhibited superior performance regardingboth accuracy (0.89) and precision (0.89), followed by RF, with and accuracy of 0.83 and a precision of 0.83. However, it is noteworthy that TOPSIS yielded the lowest accuracy value among the algorithms assessed.","['support-vector machine (SVM)', 'random forest (RF)', 'decision trees (DT)', 'logistic regression (LR)']"
2024,https://openalex.org/W4391831565,Engineering,Comparison of Random Forest and XGBoost Classifiers Using Integrated Optical and SAR Features for Mapping Urban Impervious Surface,"The integration of optical and SAR datasets through ensemble machine learning models shows promising results in urban remote sensing applications. The integration of multi-sensor datasets enhances the accuracy of information extraction. This research presents a comparison of two ensemble machine learning classifiers (random forest and extreme gradient boost (XGBoost)) classifiers using an integration of optical and SAR features and simple layer stacking (SLS) techniques. Therefore, Sentinel-1 (SAR) and Landsat 8 (optical) datasets were used with SAR textures and enhanced modified indices to extract features for the year 2023. The classification process utilized two machine learning algorithms, random forest and XGBoost, for urban impervious surface extraction. The study focused on three significant East Asian cities with diverse urban dynamics: Jakarta, Manila, and Seoul. This research proposed a novel index called the Normalized Blue Water Index (NBWI), which distinguishes water from other features and was utilized as an optical feature. Results showed an overall accuracy of 81% for UIS classification using XGBoost and 77% with RF while classifying land use land cover into four major classes (water, vegetation, bare soil, and urban impervious). However, the proposed framework with the XGBoost classifier outperformed the RF algorithm and Dynamic World (DW) data product and comparatively showed higher classification accuracy. Still, all three results show poor separability with bare soil class compared to ground truth data. XGBoost outperformed random forest and Dynamic World in classification accuracy, highlighting its potential use in urban remote sensing applications.","['ensemble machine learning models', 'random forest', 'extreme gradient boost (XGBoost)']"
2024,https://openalex.org/W4392543906,Engineering,A Multilevel Multimodal Fusion Transformer for Remote Sensing Semantic Segmentation,"Accurate semantic segmentation of remote sensing data plays a crucial role in the success of geoscience research and applications. Recently, multimodal fusion-based segmentation models have attracted much attention due to their outstanding performance as compared to conventional single-modal techniques. However, most of these models perform their fusion operation using convolutional neural networks (CNN) or the vision transformer (Vit), resulting in insufficient local-global contextual modeling and representative capabilities. In this work, a multilevel multimodal fusion scheme called FTransUNet is proposed to provide a robust and effective multimodal fusion backbone for semantic segmentation by integrating both CNN and Vit into one unified fusion framework. Firstly, the shallow-level features are first extracted and fused through convolutional layers and shallow-level feature fusion (SFF) modules. After that, deep-level features characterizing semantic information and spatial relationships are extracted and fused by a well-designed Fusion Vit (FVit). It applies Adaptively Mutually Boosted Attention (Ada-MBA) layers and Self-Attention (SA) layers alternately in a three-stage scheme to learn cross-modality representations of high inter-class separability and low intra-class variations. Specifically, the proposed Ada-MBA computes SA and Cross-Attention (CA) in parallel to enhance intra- and cross-modality contextual information simultaneously while steering attention distribution towards semantic-aware regions. As a result, FTransUNet can fuse shallow-level and deep-level features in a multilevel manner, taking full advantage of CNN and transformer to accurately characterize local details and global semantics, respectively. Extensive experiments confirm the superior performance of the proposed FTransUNet compared with other multimodal fusion approaches on two fine-resolution remote sensing datasets, namely ISPRS Vaihingen and Potsdam. The source code in this work is available at https://github.com/sstary/SSRS.","['convolutional neural networks (CNN)', 'vision transformer (Vit)', 'Self-Attention (SA) layers', 'Cross-Attention (CA)']"
2024,https://openalex.org/W4390511794,Engineering,Firefly algorithm based WSN-IoT security enhancement with machine learning for intrusion detection,"Abstract A Wireless Sensor Network (WSN) aided by the Internet of Things (IoT) is a collaborative system of WSN systems and IoT networks are work to exchange, gather, and handle data. The primary objective of this collaboration is to enhance data analysis and automation to facilitate improved decision-making. Securing IoT with the assistance of WSN necessitates the implementation of protective measures to confirm the safety and reliability of the interconnected WSN and IoT components. This research significantly advances the current state of the art in IoT and WSN security by synergistically harnessing the potential of machine learning and the Firefly Algorithm. The contributions of this work are twofold: firstly, the proposed FA-ML technique exhibits an exceptional capability to enhance intrusion detection accuracy within the WSN-IoT landscape. Secondly, the amalgamation of the Firefly Algorithm and machine learning introduces a novel dimension to the domain of security-oriented optimization techniques. The implications of this research resonate across various sectors, ranging from critical infrastructure protection to industrial automation and beyond, where safeguarding the integrity of interconnected systems are of paramount importance. The amalgamation of cutting-edge machine learning and bio-inspired algorithms marks a pivotal step forward in crafting robust and intelligent security measures for the evolving landscape of IoT-driven technologies. For intrusion detection in the WSN-IoT, the FA-ML method employs a support vector machine (SVM) machine model for classification with parameter tuning accomplished using a Grey Wolf Optimizer (GWO) algorithm. The experimental evaluation is simulated using NSL-KDD Dataset, revealing the remarkable enhancement of the FA-ML technique, achieving a maximum accuracy of 99.34%. In comparison, the KNN-PSO and XGBoost models achieved lower accuracies of 96.42% and 95.36%, respectively. The findings validate the potential of the FA-ML technique as an active security solution for WSN-IoT systems, harnessing the power of machine learning and the Firefly Algorithm to bolster intrusion detection capabilities.","['Firefly Algorithm', 'machine learning', 'support vector machine (SVM)', 'Grey Wolf Optimizer (GWO)', 'XGBoost']"
2024,https://openalex.org/W4391512775,Engineering,Peak and ultimate stress-strain model of confined ultra-high-performance concrete (UHPC) using hybrid machine learning model with conditional tabular generative adversarial network,"Ultra-high-performance concrete (UHPC) has gained prominence owing to its exceptional physical and mechanical properties and improved sustainability, making it ideal for large-scale structural applications. While numerous analytical studies have focused on predicting the stress-strain response of unconfined UHPC, there remains a lack of a reliable model for predicting the stress-strain response of confined UHPC, which poses challenges to efficient design and broader adoption, particularly in seismically active regions. To bridge this gap, the present study introduces a framework that implements machine learning (ML) models augmented by a state-of-the-art conditional tabular generative adversarial network (CTGAN) and Optuna, which a next-generation optimization framework, to accurately predict the peak and ultimate axial stress-strain responses of UHPC confined with either normal-strength steel or high-strength steel. The Optuna-optimized CTGAN is employed to address the issue of limited data by generating synthetic datasets of hypothetical confined UHPC specimens. A comprehensive database of confined UHPC stress-strain responses was compiled from existing literature and used to condition the CTGAN. The augmented database is then leveraged to develop a hybrid ML model that integrates extreme gradient boosting, gradient boosting machine, support vector regression, and K-nearest neighbors for predicting peak and ultimate stress-strain responses of confined UHPC. The predictive accuracy of the proposed hybrid ML model is evaluated and compared with a diverse set of ML models of varying complexity, and the results demonstrate its superior performance in predicting the peak and ultimate stress-strain response of confined UHPC. Furthermore, a graphical user interface of the proposed model is developed to facilitate its practical implementation and provide a rapid, autonomous, and accurate prediction of the stress-strain response of confined UHPC at both peak and ultimate states.","['conditional tabular generative adversarial network (CTGAN)', 'extreme gradient boosting', 'gradient boosting machine', 'support vector regression', 'K-nearest neighbors']"
2024,https://openalex.org/W4392462461,Engineering,Sentiment Analysis in the Age of Generative AI,"Abstract In the rapidly advancing age of Generative AI, Large Language Models (LLMs) such as ChatGPT stand at the forefront of disrupting marketing practice and research. This paper presents a comprehensive exploration of LLMs’ proficiency in sentiment analysis, a core task in marketing research for understanding consumer emotions, opinions, and perceptions. We benchmark the performance of three state-of-the-art LLMs, i.e., GPT-3.5, GPT-4, and Llama 2, against established, high-performing transfer learning models. Despite their zero-shot nature, our research reveals that LLMs can not only compete with but in some cases also surpass traditional transfer learning methods in terms of sentiment classification accuracy. We investigate the influence of textual data characteristics and analytical procedures on classification accuracy, shedding light on how data origin, text complexity, and prompting techniques impact LLM performance. We find that linguistic features such as the presence of lengthy, content-laden words improve classification performance, while other features such as single-sentence reviews and less structured social media text documents reduce performance. Further, we explore the explainability of sentiment classifications generated by LLMs. The findings indicate that LLMs, especially Llama 2, offer remarkable classification explanations, highlighting their advanced human-like reasoning capabilities. Collectively, this paper enriches the current understanding of sentiment analysis, providing valuable insights and guidance for the selection of suitable methods by marketing researchers and practitioners in the age of Generative AI.","['GPT-3.5', 'GPT-4', 'Llama 2', 'transfer learning models']"
2024,https://openalex.org/W4393001808,Engineering,Multi-Source and Multi-modal Deep Network Embedding for Cross-Network Node Classification,"In recent years, to address the issue of networked data sparsity in node classification tasks, cross-network node classification (CNNC) leverages the richer information from a source network to enhance the performance of node classification in the target network, which typically has sparser information. However, in real-world applications, labeled nodes may be collected from multiple sources with multiple modalities (e.g., text, vision, and video). Naive application of single-source and single-modal CNNC methods may result in sub-optimal solutions. To this end, in this article, we propose a model called Multi-source and Multi-modal Cross-network Deep Network Embedding (M 2 CDNE) for cross-network node classification. In M 2 CDNE, we propose a deep multi-modal network embedding approach that combines the extracted deep multi-modal features to make the node vector representations network invariant. In addition, we apply dynamic adversarial adaptation to assess the significance of marginal and conditional probability distributions between each source and target network to make node vector representations label discriminative. Furthermore, we devise to classify nodes in the target network through the related source classifier and aggregate different predictions utilizing respective network weights, corresponding to the discrepancy between each source and target network. Extensive experiments performed on real-world datasets demonstrate that the proposed M 2 CDNE significantly outperforms the state-of-the-art approaches.",['deep multi-modal network embedding']
2024,https://openalex.org/W4390533101,Engineering,A vehicular network based intelligent transport system for smart cities using machine learning algorithms,"Abstract Smart cities and the Internet of Things have enabled the integration of communicating devices for efficient decision-making. Notably, traffic congestion is one major problem faced by daily commuters in urban cities. In developed countries, specialized sensors are deployed to gather traffic information to predict traffic patterns. Any traffic updates are shared with the commuters via the Internet. Such solutions become impracticable when physical infrastructure and Internet connectivity are either non-existent or very limited. In case of developing countries, no roadside units are available and Internet connectivity is still an issue in remote areas. Internet traffic analysis is a thriving field of study due to the myriad ways in which it may be put to practical use. In the intelligent Internet-of-Vehicles (IOVs), traffic congestion can be predicted and identified using cutting-edge technologies. Using tree-based decision-tree, random-forest, extra-tree, and XGBoost machine learning (ML) strategies, this research proposes an intelligent-transport-system for the IOVs-based vehicular network traffic in a smart city set-up. The suggested system uses ensemble learning and averages the selection of crucial features to give high detection accuracy at minimal computational costs, as demonstrated by the simulation results. For IOV-based vehicular network traffic, the tree-based ML approaches with feature-selection (FS) outperformed those without FS. When contrasted to the lowest KNN accuracy of 96.6% and the highest SVM accuracy of 98.01%, the Stacking approach demonstrates superior accuracy as 99.05%.","['decision-tree', 'random-forest', 'extra-tree', 'XGBoost', 'ensemble learning', 'feature-selection (FS)', 'KNN', 'SVM', 'Stacking']"
2024,https://openalex.org/W4390817508,Engineering,Conventional to Deep Ensemble Methods for Hyperspectral Image Classification: A Comprehensive Survey,"Hyperspectral image classification has become a hot research topic. HSI has been widely used in a wide range of real-world application areas due to the in-depth spectral information stored within each pixel. Noticeably, the detailed features - i.e., a nonlinear correlation between the obtained spectral data and the correlating HSI data object, generate efficient classification results that are complex for traditional techniques. Deep Learning (DL) has recently been validated as an influential feature extractor that efficiently identifies the nonlinear issues that have arisen in various computer vision challenges. This motivates using DL for Hyperspectral Image Classification (HSIC), which shows promising results. This survey provides a brief description of DL for HSIC and compares cutting-edge methodologies in the field. We will first summarize the key challenges for HSIC, and then we will discuss the superiority of DL and DL-ensemble in addressing these issues. In this article, we divide the state-of-the-art DL methodologies and DL with ensemble into spectral features, spatial features, and combined spatial-spectral features in order to comprehensively and critically evaluate the progress (future research directions as well) of such methodologies for HSIC. Furthermore, we will take into account that DL involves a substantial percentage of labeled training images, whereas obtaining such a number for HSI is time and cost-consuming. As a result, this survey describes some methodologies for improving the classification performance of DL techniques, which can serve as future recommendations.",['Deep Learning (DL)']
2024,https://openalex.org/W4392232974,Engineering,Business analytics and decision science: A review of techniques in strategic business decision making,"Business analytics and decision science have emerged as pivotal domains in enhancing strategic business decision-making processes. This review delves into various techniques that organizations employ to optimize their operations and achieve competitive advantages. At the forefront of strategic decision-making is data analytics, where vast amounts of data are analyzed to extract valuable insights. Descriptive analytics provides a historical perspective by examining past data trends, enabling businesses to understand their performance over time. This retrospective analysis serves as a foundation for predictive analytics, which utilizes statistical models and machine learning algorithms to forecast future trends and outcomes. By leveraging predictive analytics, organizations can anticipate market shifts, customer preferences, and potential risks, thereby making informed decisions. Prescriptive analytics uses predictive models to guide strategic decision-making, utilizing optimization algorithms and simulation tools to identify optimal actions. Decision science integrates analytical techniques with human judgment, focusing on consumer behavior and psychological factors to tailor marketing strategies and product offerings. Additionally, artificial intelligence (AI) and machine learning (ML) technologies are revolutionizing strategic decision-making by automating complex tasks and providing real-time insights. Natural language processing (NLP) algorithms analyze unstructured data sources, such as customer reviews and social media posts, to extract valuable information and sentiment analysis. This enables businesses to gauge customer satisfaction levels and identify areas for improvement promptly. Decision trees, regression analysis, and clustering techniques are widely used in business analytics to segment customers, identify patterns, forecast sales trends, evaluate alternatives, assess risks, and optimize resource allocation. In conclusion, business analytics and decision science offer a plethora of techniques that empower organizations to make informed, data-driven decisions. By leveraging descriptive, predictive, and prescriptive analytics, along with AI and ML technologies, businesses can navigate complex environments, capitalize on opportunities, and mitigate risks effectively. This review underscores the importance of integrating analytical techniques with human expertise to achieve strategic objectives and sustainable growth.","['decision trees', 'regression analysis', 'clustering techniques']"
2024,https://openalex.org/W4395683385,Engineering,NAVIGATING THE FUTURE: INTEGRATING AI AND MACHINE LEARNING IN HR PRACTICES FOR A DIGITAL WORKFORCE,"As organizations navigate the complexities of the digital age, the role of Human Resources (HR) is evolving to meet the demands of a digital workforce. This review explores the integration of Artificial Intelligence (AI) and Machine Learning (ML) in HR practices to enhance efficiency, effectiveness, and employee satisfaction in the digital era. AI and ML technologies offer HR departments the opportunity to streamline operations, improve decision-making processes, and enhance employee experiences. By leveraging AI and ML, HR professionals can automate routine tasks such as recruitment, onboarding, training, and performance evaluation, allowing them to focus on more strategic initiatives that drive organizational success. One of the key advantages of integrating AI and ML in HR practices is the ability to personalize employee experiences. These technologies can analyze large volumes of data to identify patterns and trends, enabling HR professionals to tailor programs and policies to meet the unique needs of individual employees. This personalization can lead to higher levels of employee engagement, satisfaction, and retention. Furthermore, AI and ML can help HR departments make more informed decisions by providing data-driven insights. These technologies can analyze employee data to identify areas for improvement, predict future trends, and develop strategies to address challenges proactively. By leveraging these insights, HR professionals can make strategic decisions that align with the organization's goals and objectives. However, integrating AI and ML in HR practices also presents challenges, such as data privacy concerns, ethical considerations, and the need for upskilling HR professionals to use these technologies effectively. Organizations must address these challenges to realize the full potential of AI and ML in HR practices. In conclusion, integrating AI and ML in HR practices offers organizations the opportunity to enhance efficiency, effectiveness, and employee satisfaction in the digital age. By leveraging these technologies, HR departments can streamline operations, personalize employee experiences, and make more informed decisions that drive organizational success. As organizations increasingly turn to digital solutions, the role of artificial intelligence (AI) and machine learning (ML) in Human Resources becomes pivotal. This paper will focus on how AI and ML are being integrated into HR functions such as recruitment, onboarding, and employee engagement. It will also discuss the ethical implications and the challenges of maintaining human touch in an increasingly automated workplace. Case studies of companies leading in digital HR practices will be highlighted to provide real-world insights. Keywords: Digital Force, HR Practices, AI, Machine Learning, Future.",['Machine Learning (ML)']
2024,https://openalex.org/W4391301691,Engineering,AI-Driven Digital Twin Model for Reliable Lithium-Ion Battery Discharge Capacity Predictions,"The present study proposes a novel method for predicting the discharge capabilities of lithium-ion (Li-ion) batteries using a digital twin model in practice. By combining cutting-edge machine learning techniques, such as AdaBoost and long short-term memory (LSTM) network, with a semiempirical mathematical structure, the digital twin (DT)—a virtual representation that mimics the behavior of actual batteries in real time is constructed. Various metaheuristic optimization methods, such as antlion, grey wolf optimization (GWO), and improved grey wolf optimization (IGWO), are used to adjust hyperparameters in order to optimize the models. As indicators of performance, mean absolute error (MAE) and root-mean-square error (RMSE) are applied to the models after they have undergone extensive training and ten-fold cross-validation. The models are rigorously trained and cross-validated using the NASA battery aging dataset, a widely accepted benchmark dataset for battery research. The IGWO-AdaBoost digital twin model emerges as the standout performer, achieving exceptional accuracy in predicting the discharge capacity. This model demonstrates the lowest mean absolute error (MAE) of 0.01, showcasing its superior precision in estimating discharge capabilities. Additionally, the root mean square error (RMSE) for the IGWO-AdaBoost DT model is also the lowest at 0.01. The findings of this study offer insightful information about the potential utilization of the digital twin model to accurately predict the discharge capacity of batteries.","['AdaBoost', 'long short-term memory (LSTM) network', 'antlion optimization', 'grey wolf optimization (GWO)', 'improved grey wolf optimization (IGWO)']"
2024,https://openalex.org/W4391559452,Engineering,Multi-USV Task Planning Method Based on Improved Deep Reinforcement Learning,"A safe and reliable task planning method is a prerequisite for the collaborative execution of ocean observation data collection tasks by multiple unmanned surface vessels (multi-USVs). Deep Reinforcement Learning (DRL) combines the powerful nonlinear function-fitting capabilities of deep neural networks with the decision-making and control abilities of reinforcement learning, providing a novel approach to solving the multi-USV task planning problem. However, when applied to the field of multi-USV task planning, it faces challenges such as a vast exploration space, extended training times, and unstable training process. To this end, this paper proposes a multi-USV task planning method based on improved deep reinforcement learning. The proposed method draws on the idea of a value decomposition network, breaking down the multi-USV task planning problem into two subproblems: task allocation and autonomous collision avoidance. Different state spaces, action spaces, and reward functions are designed for the various subproblems. Based on this, a deep neural network is used to map the state space of each subproblem to the action space of each USV, and the generated strategy of the deep neural network is assessed based on the corresponding reward function. This successfully integrates task allocation and path planning into a comprehensive task planning framework. Deep neural networks consist of the Actor networks and the Critic networks. During the training phase of the Critic network, different methods are used to train different Critic networks to improve the convergence speed of the algorithm. An improved temporal difference error method is specifically applied to train the Critic network for evaluating autonomous collision avoidance strategies, resulting in improving the autonomous collision avoidance ability of USVs. At the same time, to improve the efficiency of task allocation, hierarchical mechanisms, and regional division mechanisms are introduced to construct sub-system task planning models, which further decompose the task planning problem. A combination of successor features and an improved temporal difference error method is specifically applied to train another Critic network for evaluating the sub-systems task allocation schemes and collaborative motion trajectories, aiming to enhance the allocation efficiency of the sub-systems. Furthermore, transfer learning is employed to merge the sub-system task planning, using it as a constraint to direct the exploration and assessment of both the cluster task allocation schemes and the cluster collaborative motion trajectories. This enables rapid and accurate learning for task allocation within the multi-USV cluster. During the training phase of the Actor network, the introduction of the experience replay method and target network technique is employed to enhance the proximal policy optimization algorithm. This facilitates distributed joint training of the Actor network, thereby improving the accuracy of the algorithm. Simulation results validate the effectiveness and superiority of this method.","['Deep Reinforcement Learning (DRL)', 'deep neural network', 'Actor networks', 'Critic networks', 'successor features', 'transfer learning', 'experience replay method', 'target network technique', 'proximal policy optimization algorithm']"
2024,https://openalex.org/W4390667445,Engineering,Automated data processing and feature engineering for deep learning and big data applications: A survey,"Modern approach to artificial intelligence (AI) aims to design algorithms that learn directly from data. This approach has achieved impressive results and has contributed significantly to the progress of AI, particularly in the sphere of supervised deep learning. It has also simplified the design of machine learning systems as the learning process is highly automated. However, not all data processing tasks in conventional deep learning pipelines have been automated. In most cases data has to be manually collected, preprocessed and further extended through data augmentation before they can be effective for training. Recently, special techniques for automating these tasks have emerged. The automation of data processing tasks is driven by the need to utilize large volumes of complex, heterogeneous data for machine learning and big data applications. Today, end-to-end automated data processing systems based on automated machine learning (AutoML) techniques are capable of taking raw data and transforming them into useful features for Big Data tasks by automating all intermediate processing stages. In this work, we present a thorough review of approaches for automating data processing tasks in deep learning pipelines, including automated data preprocessing– e.g., data cleaning, labeling, missing data imputation, and categorical data encoding–as well as data augmentation (including synthetic data generation using generative AI methods) and feature engineering–specifically, automated feature extraction, feature construction and feature selection. In addition to automating specific data processing tasks, we discuss the use of AutoML methods and tools to simultaneously optimize all stages of the machine learning pipeline.","['supervised deep learning', 'automated machine learning (AutoML)', 'synthetic data generation using generative AI methods', 'feature construction', 'feature selection']"
2024,https://openalex.org/W4392980686,Engineering,Data-driven evolution of water quality models: An in-depth investigation of innovative outlier detection approaches-A case study of Irish Water Quality Index (IEWQI) model,"Recently, there has been a significant advancement in the water quality index (WQI) models utilizing data-driven approaches, especially those integrating machine learning and artificial intelligence (ML/AI) technology. Although, several recent studies have revealed that the data-driven model has produced inconsistent results due to the data outliers, which significantly impact model reliability and accuracy. The present study was carried out to assess the impact of data outliers on a recently developed Irish Water Quality Index (IEWQI) model, which relies on data-driven techniques. To the author's best knowledge, there has been no systematic framework for evaluating the influence of data outliers on such models. For the purposes of assessing the outlier impact of the data outliers on the water quality (WQ) model, this was the first initiative in research to introduce a comprehensive approach that combines machine learning with advanced statistical techniques. The proposed framework was implemented in Cork Harbour, Ireland, to evaluate the IEWQI model's sensitivity to outliers in input indicators to assess the water quality. In order to detect the data outlier, the study utilized two widely used ML techniques, including Isolation Forest (IF) and Kernel Density Estimation (KDE) within the dataset, for predicting WQ with and without these outliers. For validating the ML results, the study used five commonly used statistical measures. The performance metric (R2) indicates that the model performance improved slightly (R2 increased from 0.92 to 0.95) in predicting WQ after removing the data outlier from the input. But the IEWQI scores revealed that there were no statistically significant differences among the actual values, predictions with outliers, and predictions without outliers, with a 95% confidence interval at p < 0.05. The results of model uncertainty also revealed that the model contributed <1% uncertainty to the final assessment results for using both datasets (with and without outliers). In addition, all statistical measures indicated that the ML techniques provided reliable results that can be utilized for detecting outliers and their impacts on the IEWQI model. The findings of the research reveal that although the data outliers had no significant impact on the IEWQI model architecture, they had moderate impacts on the rating schemes' of the model. This finding indicated that detecting the data outliers could improve the accuracy of the IEWQI model in rating WQ as well as be helpful in mitigating the model eclipsing problem. In addition, the results of the research provide evidence of how the data outliers influenced the data-driven model in predicting WQ and reliability, particularly since the study confirmed that the IEWQI model's could be effective for accurately rating WQ despite the presence of the data outliers in the input. It could occur due to the spatio-temporal variability inherent in WQ indicators. However, the research assesses the influence of data input outliers on the IEWQI model and underscores important areas for future investigation. These areas include expanding temporal analysis using multi-year data, examining spatial outlier patterns, and evaluating detection methods. Moreover, it is essential to explore the real-world impacts of revised rating categories, involve stakeholders in outlier management, and fine-tune model parameters. Analysing model performance across varying temporal and spatial resolutions and incorporating additional environmental data can significantly enhance the accuracy of WQ assessment. Consequently, this study offers valuable insights to strengthen the IEWQI model's robustness and provides avenues for enhancing its utility in broader WQ assessment applications. Moreover, the study successfully adopted the framework for evaluating how data input outliers affect the data-driven model, such as the IEWQI model. The current study has been carried out in Cork Harbour for only a single year of WQ data. The framework should be tested across various domains for evaluating the response of the IEWQI model's in terms of the spatio-temporal resolution of the domain. Nevertheless, the study recommended that future research should be conducted to adjust or revise the IEWQI model's rating schemes and investigate the practical effects of data outliers on updated rating categories. However, the study provides potential recommendations for enhancing the IEWQI model's adaptability and reveals its effectiveness in expanding its applicability in more general WQ assessment scenarios.",['Isolation Forest (IF)']
2024,https://openalex.org/W4394015596,Engineering,Predicting the mechanical properties of plastic concrete: An optimization method by using genetic programming and ensemble learners,"This study presents a comparative analysis of individual and ensemble learning algorithms (ELAs) to predict the compressive strength (CS) and flexural strength (FS) of plastic concrete. Multilayer perceptron neuron network (MLPNN), Support vector machine (SVM), random forest (RF), and decision tree (DT) were used as base learners, which were then combined with bagging and Adaboost methods to improve the predictive performance. In addition, gene expression programming (GEP) was used to develop computational equations that can be used to predict the CS and FS of plastic concrete. An extensive database containing 357 and 125 data points was obtained from the literature, and the eight most impactful ingredients were used in the model's development. The accuracy of all models was assessed using several statistical measures, including an error matrix, Akaike information criterion (AIC), K-fold cross-validation, and other external validation equations. Furthermore, sensitivity and SHAP analysis were performed to evaluate input variables' relative significance and impact on the anticipated CS and FS. Based on statistical measures and other validation criteria, GEP outpaces all other individual models, whereas, in ELAs, the SVR ensemble with Adaboost and RF modified with the Bagging technique demonstrated superior performance. SHapley Additive exPlanations (SHAP) and sensitivity analysis reveal that plastic, cement, water, and the age of the specimens have the highest influence, while superplasticizer has the lowest impact, which is consistent with experimental studies. Moreover, GUI and GEP-based simple mathematical correlation can enhance the practical scope of this study and be an effective tool for the pre-mix design of plastic concrete.","['Multilayer perceptron neuron network (MLPNN)', 'Support vector machine (SVM)', 'random forest (RF)', 'decision tree (DT)', 'bagging', 'Adaboost', 'gene expression programming (GEP)', 'SHapley Additive exPlanations (SHAP)']"
2024,https://openalex.org/W4391089359,Engineering,Groundwater level prediction using an improved SVR model integrated with hybrid particle swarm optimization and firefly algorithm,"The demand for water resources has increased due to rapid increase of metropolitan areas brought on by growth in population and industrialisation. In addition, the groundwater recharge is being afftected by shifting land use pattern caused by urban development. Using precise and trustworthy estimates of groundwater level is vital for the sustainable groundwater resources management in the face of changing climatic circumstances. In this context, machine learning (ML) methods offer a new and promising approach for accurately forecasting long-term changes in the groundwater level (GWL) without computational effort of developing a comprehensive flow model. In order to simulate GWL, five data-driven (DD) models, including the hybridization of support vector regression (SVR) with two optimisation algorithms i.e., firefly algorithm and particle swarm optimisation (FFAPSO), SVR-FFA, SVR-PSO, SVR and Multilayer perception (MLP), have been examined in the present study. Spatial clustering was utilised to choose four observation wells within Cuttack district in order to study and assess the water levels. Six scenarios were created by incorporating numerous variables, such as GWL in the previous months, evapotranspiration, temperature, precipitation, and river discharge. The goal was to identify the variables that were most efficient in predicting GWL. The SVR-FFAPSO model performs best in GWL forecasting for Khuntuni station, according to the quantitative analysis with correlation coefficient (R) = 0.9978, Nash–Sutcliffe efficiency (NSE) = 0.9933, mean absolute error (MAE) = 0.00025 (m), root mean squared error (RMSE) = 0.00775 (m) during the training phase. It is advised that groundwater monitoring network and data collecting system are strengthen in India for ensuring effective modelling of long-term management of groundwater resources.","['support vector regression (SVR)', 'firefly algorithm', 'SVR-PSO']"
2024,https://openalex.org/W4391855187,Engineering,Machine learning-assisted in-situ adaptive strategies for the control of defects and anomalies in metal additive manufacturing,"In metal additive manufacturing (AM), the material microstructure and part geometry are formed incrementally. Consequently, the resulting part could be defect- and anomaly-free if sufficient care is taken to deposit each layer under optimal process conditions. Conventional closed-loop control (CLC) engineering solutions which sought to achieve this were deterministic and rule-based, thus resulting in limited success in the stochastic environment experienced in the highly dynamic AM process. On the other hand, emerging machine learning (ML) based strategies are better suited to providing the robustness, scope, flexibility, and scalability required for process control in an uncertain environment. Offline ML models that help optimise AM process parameters before a build begins and online ML models that efficiently processed in-situ sensory data to detect and diagnose flaws in real-time (or near-real-time) have been developed. However, ML models that enable a process to take evasive or corrective actions in relation to flaws via on the fly decision-making are only emerging. These models must possess prognostic capabilities to provide context-sensitive recommendations for in-situ process control based on real-time diagnostics. In this article, we pinpoint the shortcomings in traditional CLC strategies, and provide a framework for defect and anomaly control through ML-assisted CLC in AM. We discuss flaws in terms of their causes, in-situ detectability, and controllability, and examine their management under three scenarios: avoidance, mitigation, and repair. Then, we summarise the research into ML models developed for offline optimisation and in-situ diagnosis before initiating a detailed conversation on the implementation of ML-assisted in-situ process control. We found that researchers favoured reinforcement learning approaches or inverse ML models for making rapid, situation-aware control decisions. We also observed that, to-date, the defects addressed were those that may be quantified relatively easily autonomously, and that mitigation (rather than avoidance or repair) was the aim of ML-assisted in-situ control strategies. Additionally, we highlight the various technologies that must seamlessly combine to advance the field of autonomous in-situ control so that it becomes a reality in industrial settings. Finally, we raise awareness of seldom discussed, yet highly pertinent, topics relevant to adaptive control. Our work closes a significant gap in the current AM literature by broaching wide-ranging discussions on matters relevant to in-situ adaptive control in AM.","['online ML models', 'reinforcement learning approaches']"
2024,https://openalex.org/W4391973028,Engineering,A comprehensive evaluation of large Language models on benchmark biomedical text processing tasks,"Recently, Large Language Models (LLMs) have demonstrated impressive capability to solve a wide range of tasks. However, despite their success across various tasks, no prior work has investigated their capability in the biomedical domain yet. To this end, this paper aims to evaluate the performance of LLMs on benchmark biomedical tasks. For this purpose, a comprehensive evaluation of 4 popular LLMs in 6 diverse biomedical tasks across 26 datasets has been conducted. To the best of our knowledge, this is the first work that conducts an extensive evaluation and comparison of various LLMs in the biomedical domain. Interestingly, we find based on our evaluation that in biomedical datasets that have smaller training sets, zero-shot LLMs even outperform the current state-of-the-art models when they were fine-tuned only on the training set of these datasets. This suggests that pre-training on large text corpora makes LLMs quite specialized even in the biomedical domain. We also find that not a single LLM can outperform other LLMs in all tasks, with the performance of different LLMs may vary depending on the task. While their performance is still quite poor in comparison to the biomedical models that were fine-tuned on large training sets, our findings demonstrate that LLMs have the potential to be a valuable tool for various biomedical tasks that lack large annotated data.","['zero-shot learning', 'fine-tuning']"
2024,https://openalex.org/W4392640075,Engineering,Performance assessment of machine learning algorithms for mapping of land use/land cover using remote sensing data,"The rapid increase in population accelerates the rate of change of Land use/Land cover (LULC) in various parts of the world. This phenomenon caused a huge strain for natural resources. Hence, continues monitoring of LULC changes gained a significant importance for management of natural resources and assessing the climate change impacts. Recently, application of machine learning algorithms on RS (remote sensing) data for rapid and accurate mapping of LULC gained significant importance due to growing need of LULC estimation for ecosystem services, natural resource management and environmental management. Hence, it is crucial to access and compare the performance of different machine learning classifiers for accurate mapping of LULC. The primary objective of this study was to compare the performance of CART (Classification and Regression Tree), RF (Random Forest) and SVM (Support Vector Machine) for LULC estimation by processing RS data on Google Earth Engine (GEE). In total four classes of LULC (Water Bodies, Vegetation Cover, Urban Land and Barren Land) for city of Lahore were extracted using satellite images from Landsat-7, Landsat-8 and Landsat-9 for years 2008, 2015 and 2022, respectively. According to results, RF is the best performing classifier with maximum overall accuracy of 95.2% and highest Kappa coefficient value of 0.87, SVM achieved maximum accuracy of 89.8% with highest Kappa of 0.84 and CART showed maximum overall accuracy of 89.7% with Kappa value of 0.79. Results from this study can give assistance for decision makers, planners and RS experts to choose a suitable machine learning algorithm for LULC classification in an unplanned urbanized city like Lahore.","['Classification and Regression Tree (CART)', 'Random Forest (RF)', 'Support Vector Machine (SVM)']"
2024,https://openalex.org/W4393405236,Engineering,Transformer and Graph Convolution-Based Unsupervised Detection of Machine Anomalous Sound Under Domain Shifts,"Thanks to the development of deep learning, machine abnormal sound detection (MASD) based on unsupervised learning has exhibited excellent performance. However, in the task of unsupervised MASD, there are discrepancies between the acoustic characteristics of the test set and the training set under the physical parameter changes (domain shifts) of the same machine's operating conditions. Existing methods not only struggle to stably learn the sound signal features under various domain shifts but also inevitably increase computational overhead. To address these issues, we propose an unsupervised machine abnormal sound detection model based on Transformer and Dynamic Graph Convolution (Unsuper-TDGCN) in this paper. Firstly, we design a network that models time-frequency domain features to capture both global and local spatial and time-frequency interactions, thus improving the model's stability under domain shifts. Then, we introduce a Dynamic Graph Convolutional Network (DyGCN) to model the dependencies between features under domain shifts, enhancing the model's ability to perceive changes in domain features. Finally, a Domain Self-adaptive Network (DSN) is employed to compensate for the performance decline caused by domain shifts, thereby improving the model's adaptive ability for detecting anomalous sounds in MASD tasks under domain shifts. The effectiveness of our proposed model has been validated on multiple datasets.","['unsupervised learning', 'Transformer', 'Dynamic Graph Convolutional Network (DyGCN)']"
2024,https://openalex.org/W4401667275,Engineering,Artificial intelligence for literature reviews: opportunities and challenges,"Abstract This paper presents a comprehensive review of the use of Artificial Intelligence (AI) in Systematic Literature Reviews (SLRs). A SLR is a rigorous and organised methodology that assesses and integrates prior research on a given topic. Numerous tools have been developed to assist and partially automate the SLR process. The increasing role of AI in this field shows great potential in providing more effective support for researchers, moving towards the semi-automatic creation of literature reviews. Our study focuses on how AI techniques are applied in the semi-automation of SLRs, specifically in the screening and extraction phases. We examine 21 leading SLR tools using a framework that combines 23 traditional features with 11 AI features. We also analyse 11 recent tools that leverage large language models for searching the literature and assisting academic writing. Finally, the paper discusses current trends in the field, outlines key research challenges, and suggests directions for future research. We highlight three primary research challenges: integrating advanced AI solutions, such as large language models and knowledge graphs, improving usability, and developing a standardised evaluation framework. We also propose best practices to ensure more robust evaluations in terms of performance, usability, and transparency. Overall, this review offers a detailed overview of AI-enhanced SLR tools for researchers and practitioners, providing a foundation for the development of next-generation AI solutions in this field.",['knowledge graphs']
2024,https://openalex.org/W4390480832,Engineering,Joint Optimization Risk Factor and Energy Consumption in IoT Networks With TinyML-Enabled Internet of UAVs,"The high mobility of Internet of Unmanned Aerial Vehicles (IUAVs) has attracted attention in the field of data collection. With the rapid development of the Internet of Things (IoT), more and more data are generated by IoT networks. IUAV-aided IoT networks can efficiently collect data in specific areas, which is of great significance in disaster relief. In the data collection task, it is necessary to plan the flight trajectory for the data collector—IUAV, so that the IUAV can collect data efficiently. However, existing research basically only considers the efficiency of data collection by IUAVs, but rarely considers the safety of IUAVs during flight. Therefore, this paper proposes an IUAV trajectory planning algorithm that integrates energy efficiency and safety using local search to address the issues mentioned above. At the same time, a Tiny Machine Learning (TinyML) algorithm is designed to assist the IUAV in making real-time decisions during flight. First, we build a general mathematical model that describes the risk in a particular region. Then consider guiding the IUAV to a safer trajectory by introducing virtual nodes in the flight trajectory. Furthermore, we designed a local search algorithm for the three tasks of IUAV access sequence, IoT Networks cluster heads selection and virtual nodes selection, and solved them through iterative optimization. We also consider the unreachable situation of the virtual nodes and use TinyML technology to help the IUAV adjust the position of the virtual nodes in real time in case of an emergency.In the end, an IUAV trajectory is obtained that can efficiently collect IoT networks' data and fly safely. We have conducted a large number of simulation experiments to demonstrate the efficiency of the proposed algorithm compared to the baseline algorithm.",['Tiny Machine Learning (TinyML)']
2024,https://openalex.org/W4390754233,Engineering,Groundwater Quality Assessment and Irrigation Water Quality Index Prediction Using Machine Learning Algorithms,"The evaluation of groundwater quality is crucial for irrigation purposes; however, due to financial constraints in developing countries, such evaluations suffer from insufficient sampling frequency, hindering comprehensive assessments. Therefore, associated with machine learning approaches and the irrigation water quality index (IWQI), this research aims to evaluate the groundwater quality in Naama, a region in southwest Algeria. Hydrochemical parameters (cations, anions, pH, and EC), qualitative indices (SAR,RSC,Na%,MH,and PI), as well as geospatial representations were used to determine the groundwater’s suitability for irrigation in the study area. In addition, efficient machine learning approaches for forecasting IWQI utilizing Extreme Gradient Boosting (XGBoost), Support vector regression (SVR), and K-Nearest Neighbours (KNN) models were implemented. In this research, 166 groundwater samples were used to calculate the irrigation index. The results showed that 42.18% of them were of excellent quality, 34.34% were of very good quality, 6.63% were good quality, 9.64% were satisfactory, and 4.21% were considered unsuitable for irrigation. On the other hand, results indicate that XGBoost excels in accuracy and stability, with a low RMSE (of 2.8272 and a high R of 0.9834. SVR with only four inputs (Ca2+, Mg2+, Na+, and K) demonstrates a notable predictive capability with a low RMSE of 2.6925 and a high R of 0.98738, while KNN showcases robust performance. The distinctions between these models have important implications for making informed decisions in agricultural water management and resource allocation within the region.","['Extreme Gradient Boosting (XGBoost)', 'Support Vector Regression (SVR)', 'K-Nearest Neighbours (KNN)']"
2024,https://openalex.org/W4391312031,Engineering,Artificial intelligence (AI) in renewable energy: A review of predictive maintenance and energy optimization,"The integration of Artificial Intelligence (AI) in the renewable energy sector has emerged as a transformative force, enhancing the efficiency and sustainability of energy systems. This paper provides a comprehensive review of the application of AI in two critical aspects of renewable energy in relation to predictive maintenance and energy optimization. Predictive maintenance, enabled by AI, has revolutionized the renewable energy landscape by predicting and preventing equipment failures before they occur. Utilizing machine learning algorithms, AI analyzes vast amounts of data from sensors and historical performance to identify patterns indicative of potential faults. This proactive approach not only minimizes downtime but also extends the lifespan of renewable energy infrastructure, resulting in substantial cost savings and improved reliability. Furthermore, AI plays a pivotal role in optimizing the energy output of renewable sources. Through advanced data analytics and real-time monitoring, AI algorithms can adapt to changing environmental conditions, predicting energy production patterns and optimizing resource allocation. This ensures maximum energy yield from renewable sources, making them more competitive with traditional energy sources. The paper delves into specific AI techniques such as deep learning, neural networks, and predictive analytics employed for predictive maintenance and energy optimization in various renewable energy systems like solar, wind, and hydropower. Challenges and opportunities associated with implementing AI in renewable energy are discussed, including data security, interoperability, and the need for standardized frameworks. The synthesis of AI technologies with renewable energy not only addresses operational challenges but also contributes to the global transition towards sustainable and clean energy solutions. This review serves as a valuable resource for researchers, practitioners, and policymakers seeking insights into the evolving landscape of AI applications in the renewable energy sector. As technology continues to advance, the synergies between AI and renewable energy are poised to shape the future of the global energy paradigm.","['deep learning', 'neural networks']"
2024,https://openalex.org/W4391679299,Engineering,Generative Pre-Trained Transformer (GPT) in Research: A Systematic Review on Data Augmentation,"GPT (Generative Pre-trained Transformer) represents advanced language models that have significantly reshaped the academic writing landscape. These sophisticated language models offer invaluable support throughout all phases of research work, facilitating idea generation, enhancing drafting processes, and overcoming challenges like writer’s block. Their capabilities extend beyond conventional applications, contributing to critical analysis, data augmentation, and research design, thereby elevating the efficiency and quality of scholarly endeavors. Strategically narrowing its focus, this review explores alternative dimensions of GPT and LLM applications, specifically data augmentation and the generation of synthetic data for research. Employing a meticulous examination of 412 scholarly works, it distills a selection of 77 contributions addressing three critical research questions: (1) GPT on Generating Research data, (2) GPT on Data Analysis, and (3) GPT on Research Design. The systematic literature review adeptly highlights the central focus on data augmentation, encapsulating 48 pertinent scholarly contributions, and extends to the proactive role of GPT in critical analysis of research data and shaping research design. Pioneering a comprehensive classification framework for “GPT’s use on Research Data”, the study classifies existing literature into six categories and 14 sub-categories, providing profound insights into the multifaceted applications of GPT in research data. This study meticulously compares 54 pieces of literature, evaluating research domains, methodologies, and advantages and disadvantages, providing scholars with profound insights crucial for the seamless integration of GPT across diverse phases of their scholarly pursuits.",['Generative Pre-trained Transformer (GPT)']
2024,https://openalex.org/W4390480870,Engineering,GraphGST: Graph Generative Structure-Aware Transformer for Hyperspectral Image Classification,"Transformer holds significance in deep learning (DL) research. Node embedding (NE) and positional encoding (PE) are usually two indispensable components in a Transformer. The former can excavate hidden correlations from the data, while the latter can store locational relationships between nodes. Recently, the Transformer has been applied for hyperspectral image (HSI) classification because the model can capture long-range dependencies to aggregate global features for representation learning. In an HSI, adjacent pixels tend to be homogeneous, while the NE does not identify the positional information of pixels. Therefore, PE is crucial for Transformers to understand locational relationships between pixels. However, in this area, most Transformer-based methods randomly generate PEs without considering their physical meaning, which leads to weak representations. This article proposes a new graph generative structure-aware Transformer (GraphGST) to solve the above-mentioned PE problem when implementing HSI classification. In our GraphGST, a new absolute PE (APE) is established to acquire pixels' absolute positional sequences (APSs) and is integrated into the Transformer architecture. Moreover, a generative mechanism with self-supervised learning is developed to achieve cross-view contrastive learning (CL), aiming to enhance the representation learning of the Transformer. The proposed GraphGST model can capture local-to-global correlations, and the extracted APSs can complement the spectral features of pixels to assist in NE. Several experiments with real HSIs are conducted to evaluate the effectiveness of our GraphGST. The proposed method demonstrates very competitive performance compared with other state-of-the-art (SOTA) approaches. Our source codes will be provided in the following link <uri xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">https://github.com/yuanchaosu/TGRS-graphGST</uri> .","['Transformer', 'Node embedding (NE)', 'Absolute positional encoding (APE)', 'Self-supervised learning', 'Cross-view contrastive learning (CL)']"
2024,https://openalex.org/W4391130239,Engineering,Learning to Aggregate Multi-Scale Context for Instance Segmentation in Remote Sensing Images,"The task of instance segmentation in remote sensing images, aiming at performing per-pixel labeling of objects at the instance level, is of great importance for various civil applications. Despite previous successes, most existing instance segmentation methods designed for natural images encounter sharp performance degradations when they are directly applied to top-view remote sensing images. Through careful analysis, we observe that the challenges mainly come from the lack of discriminative object features due to severe scale variations, low contrasts, and clustered distributions. In order to address these problems, a novel context aggregation network (CATNet) is proposed to improve the feature extraction process. The proposed model exploits three lightweight plug-and-play modules, namely, dense feature pyramid network (DenseFPN), spatial context pyramid (SCP), and hierarchical region of interest extractor (HRoIE), to aggregate global visual context at feature, spatial, and instance domains, respectively. DenseFPN is a multi-scale feature propagation module that establishes more flexible information flows by adopting interlevel residual connections, cross-level dense connections, and feature reweighting strategy. Leveraging the attention mechanism, SCP further augments the features by aggregating global spatial context into local regions. For each instance, HRoIE adaptively generates RoI features for different downstream tasks. Extensive evaluations of the proposed scheme on iSAID, DIOR, NWPU VHR-10, and HRSID datasets demonstrate that the proposed approach outperforms state-of-the-arts under similar computational costs. Source code and pretrained models are available at https://github.com/yeliudev/CATNet.","['dense feature pyramid network (DenseFPN)', 'attention mechanism']"
2024,https://openalex.org/W4391248672,Engineering,Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning,"Recent development in computing power has resulted in performance improvements on holistic(none-occluded) person Re-Identification (ReID) tasks. Nevertheless, the precision of the recent research will diminish when a pedestrian is obstructed by obstacles. Within the realm of 2D space, the loss of information from obstructed objects continues to pose significant challenges in the context of person ReID. Person is a 3D non-grid object, and thus semantic representation learning in only 2D space limits the understanding of occluded person. In the present work, we propose a network based on 3D multi-view learning, allowing it to acquire geometric and shape details of an occluded pedestrian from 3D space. Simultaneously, it capitalizes on advancements in 2D-based networks to extract semantic representations from 3D multi-views. Specifically, the surface random selection strategy is proposed to convert images of 2D RGB into 3D multi-views. Using this strategy, we build four extensive 3D multi-view data collections for person ReID. After that, Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning(MV-3DSReID), is proposed for identifying the person by learning person geometry and structure representation from the groups of multi-view images. In comparison to alternative data formats (e.g., 2D RGB, 3D point cloud), multi-view images complement each other's detailed features of the 3D object by adjusting rendering viewpoints, thus facilitating a more comprehensive understanding of the person for both holistic and occluded ReID situations. Experiments on occluded and holistic ReID tasks demonstrate performance levels comparable to state-of-the-art methods, validating the effectiveness of our proposed approach in tackling challenges related to occlusion. The code is available at https://github.com/hangjiaqi1/MV-TransReID.",['3D multi-view learning']
2024,https://openalex.org/W4391973098,Engineering,The use of machine learning techniques to investigate the properties of metakaolin-based geopolymer concrete,"The construction industry significantly contributes to global greenhouse gas emissions, highlighting the imperative for developing environmentally friendly construction materials. Geopolymers, particularly those utilizing metakaolin (MK), have emerged as a promising green alternative to conventional concrete. However, the acquisition of MK-based geopolymer concrete with optimal mechanical properties poses challenges due to numerous influential factors, disagreement over various findings, and the lack of a reliable predictive model. This study aimed to address this gap by employing a wide range of machine learning methods, namely gradient boosting machine, random forest, decision tree, artificial neural network, and support vector machine. Different optimization and regularization techniques were used to comprehensively understand the factors affecting the compressive strength of MK-based geopolymer concrete, including mixture design, chemical characteristics of the initial binder and activators, and different curing regimes. The results demonstrated the exceptional performance of the gradient boosting machine in predicting the compressive strength of MK-based geopolymer concrete, achieving a coefficient of determination of 0.983 and a mean absolute error of 1.615 MPa. Additionally, the study employed partial dependence plots, feature importance analysis, and SHapley Additive exPlanations (SHAP) to elucidate the proposed models. The coarse-to-fine aggregate ratio, H2O/Na2O molar ratio, extra water content, and sodium hydroxide concentration were identified as the most critical parameters affecting the compressive strength of MK-based geopolymer concrete. This research contributes to advancing the development of sustainable construction materials, streamlining experimental tasks, minimizing the need for labor and materials, improving time efficiency, and providing valuable insights for optimizing the design of MK-based geopolymer concrete.","['gradient boosting machine', 'random forest', 'decision tree', 'artificial neural network', 'support vector machine']"
2024,https://openalex.org/W4394685122,Engineering,Sequence Training and Data Shuffling to Enhance the Accuracy of Recurrent Neural Network Based Battery Voltage Models,"&lt;div class=""section abstract""&gt;&lt;div class=""htmlview paragraph""&gt;Battery terminal voltage modelling is crucial for various applications, including electric vehicles, renewable energy systems, and portable electronics. Terminal voltage models are used to determine how a battery will respond under load and can be used to calculate run-time, power capability, and heat generation and as a component of state estimation approaches, such as for state of charge. Previous studies have shown better voltage modelling accuracy for long short-term memory (LSTM) recurrent neural networks than other traditional methods (e.g., equivalent circuit and electrochemical models). This study presents two new approaches – sequence training and data shuffling – to improve LSTM battery voltage models further, making them an even better candidate for the high-accuracy modelling of lithium-ion batteries. Because the LSTM memory captures information from past time steps, it must typically be trained using one series of continuous data. Instead, the proposed sequence training approach feeds a fixed window of prior data (e.g., 100 seconds) into the LSTM at each time step to initialize the memory states properly and then only uses the output at the current time step. With this method, the LSTM just requires the prior data window to be continuous, thereby allowing the handling of discontinuities. This also means that during the training process, the data can be shuffled randomly, enabling mini-batches to speed up the training significantly. When these approaches were applied, LSTM voltage estimation error was reduced by 22%, from 28.5 mV to 22.3 mV RMS error over four drive cycles and temperatures from -20 to 25°C.&lt;/div&gt;&lt;/div&gt;","['long short-term memory (LSTM) recurrent neural networks', 'sequence training']"
2024,https://openalex.org/W4390975281,Engineering,Semantic and Instance Segmentation in Coastal Urban Spatial Perception: A Multi-Task Learning Framework with an Attention Mechanism,"With the continuous acceleration of urbanization, urban planning and design require more in-depth research and development. Street view images can express rich urban features and guide residents’ emotions toward a city, thereby providing the most intuitive reflection of their perception of the city’s spatial quality. However, current researchers mainly conduct research on urban spatial quality through subjective experiential judgment, which includes problems such as a high cost and a low judgment accuracy. In response to these problems, this study proposes a multi-task learning urban spatial attribute perception model that integrates an attention mechanism. Via this model, the existing attributes of urban street scenes are analyzed. Then, the model is improved by introducing semantic segmentation and instance segmentation to identify and match the qualities of the urban space. The experimental results show that the multi-task learning urban spatial attribute perception model with an integrated attention mechanism has prediction accuracies of 79.54%, 78.62%, 79.68%, 77.42%, 78.45%, and 76.98% for the urban spatial attributes of beauty, boredom, depression, liveliness, safety, and richness, respectively. The accuracy of the multi-task learning urban spatial scene feature image segmentation model with an integrated attention mechanism is 95.4, 94.8, 96.2, 92.1, and 96.7 for roads, walls, sky, vehicles, and buildings, respectively. The multi-task learning urban spatial scene feature image segmentation model with an integrated attention mechanism has a higher recognition accuracy for urban spatial buildings than other models. These research results indicate the model’s effectiveness in matching urban spatial quality with public perception.","['multi-task learning', 'attention mechanism', 'semantic segmentation', 'instance segmentation']"
2024,https://openalex.org/W4391404732,Engineering,"The Convergence of Intelligent Tutoring, Robotics, and IoT in Smart Education for the Transition from Industry 4.0 to 5.0","This review paper provides a comprehensive analysis of the automation of smart education in the context of Industry 5.0 from 78 papers, focusing on the integration of advanced technologies and the development of innovative, effective, and ethical educational solutions for the future workforce. As the world transitions into an era characterized by human–machine collaboration and rapidly evolving technologies, there is an urgent need to recognize the pivotal role of smart education in preparing individuals for the opportunities and challenges presented by the new industrial landscape. The paper examines key components of smart education, including intelligent tutoring systems, adaptive learning environments, learning analytics, and the application of the Internet of Things (IoT) in education. It also discusses the role of advanced technologies such as artificial intelligence (AI), machine learning (ML), robotics, and augmented and virtual reality (AR/VR) in shaping personalized and immersive learning experiences. The review highlights the importance of smart education in addressing the growing demand for upskilling and reskilling, fostering a culture of lifelong learning, and promoting adaptability, resilience, and self-improvement among learners. Furthermore, the paper delves into the challenges and ethical considerations associated with the implementation of smart education, addressing issues such as data privacy, the digital divide, teacher and student readiness, and the potential biases in AI-driven systems. Through a presentation of case studies and examples of successful smart education initiatives, the review aims to inspire educators, policymakers, and industry stakeholders to collaborate and innovate in the design and implementation of effective smart education solutions. Conclusively, the paper outlines emerging trends, future directions, and potential research opportunities in the field of smart education, emphasizing the importance of continuous improvement and the integration of new technologies to ensure that education remains relevant and effective in the context of Industry 5.0. By providing a holistic understanding of the key components, challenges, and potential solutions associated with smart education, this review paper seeks to contribute to the ongoing discourse surrounding the automation of smart education and its role in preparing the workforce for the future of work.",['machine learning (ML)']
2024,https://openalex.org/W4391482136,Engineering,A comprehensive analysis of the emerging modern trends in research on photovoltaic systems and desalination in the era of artificial intelligence and machine learning,"Integration of photovoltaic (PV) systems, desalination technologies, and Artificial Intelligence (AI) combined with Machine Learning (ML) has introduced a new era of remarkable research and innovation. This review article thoroughly examines the recent advancements in the field, focusing on the interplay between PV systems and water desalination within the framework of AI and ML applications, along with it analyses current research to identify significant patterns, obstacles, and prospects in this interdisciplinary field. Furthermore, review examines the incorporation of AI and ML methods in improving the performance of PV systems. This includes raising their efficiency, implementing predictive maintenance strategies, and enabling real-time monitoring. It also explores the transformative influence of intelligent algorithms on desalination techniques, specifically addressing concerns pertaining to energy usage, scalability, and environmental sustainability. This article provides a thorough analysis of the current literature, identifying areas where research is lacking and suggesting potential future avenues for investigation. These advancements have resulted in increased efficiency, decreased expenses, and improved sustainability of PV system. By utilizing artificial intelligence technologies, freshwater productivity can increase by 10 % and efficiency. This review offers significant and informative perspectives for researchers, engineers, and policymakers involved in renewable energy and water technology. It sheds light on the latest advancements in photovoltaic systems and desalination, which are facilitated by AI and ML. The review aims to guide towards a more sustainable and technologically advanced future.",['Machine Learning (ML)']
2024,https://openalex.org/W4391574742,Engineering,Optimum tuned mass damper inerter under near-fault pulse-like ground motions of buildings including soil-structure interaction,"This study investigates the effectiveness of the tuned mass damper inerter (TMDI) in mitigating building response, considering the soil structure interaction (SSI). Three types of models are examined: single degree of freedom (SDOF), low-rise multi-degree of freedom (MDOF), and high-rise MDOF. Additionally, the natural period of the SDOF model is varied to explore the TMDI's efficacy across different ranges. Frequency and time domain analysis are conducted under pulse-like ground motions. The H2 and genetic algorithm (GA) are used to optimize the parameters of the TMDI. In this optimization method the transfer function for displacement response is minimized. In time domain analysis we used Newmark's integration method to solve the equation of motion for all the cases considered. It is found that the optimized TMDI proves highly effective in mitigating the displacement response of the buildings, accounting for SSI. Notably, its efficiency is more pronounced when pulse period aligns closely with the buildings' natural period. In addition, a notable pattern emerges, wherein the TMDI excels in mitigating response for buildings experiencing large motion, thereby enhancing safety under severe conditions. These findings offer valuable insights into the application and optimization of the TMDI to enhance seismic performance in various buildings, while considering complex interaction with the soil.",['genetic algorithm (GA)']
2024,https://openalex.org/W4391693184,Engineering,3DUV-NetR+: A 3D hybrid semantic architecture using transformers for brain tumor segmentation with MultiModal MR images,"Brain tumor segmentation plays a substantial role in Medical Image Analysis (MIS). In this regard, automatic segmentation methods facilitate precise and efficient segmentation, significantly contributing to diagnosis and treatment planning in medical applications. Recently, several Deep Learning-based architectures have been proposed to revolutionize the MIS field. Particularly, the combination of Convolution Neural Networks (CNNs) and Transformers has greatly enhanced and developed segmentation results. Moreover, the Attention mechanism in Transformers allows the modeling of long-range contextual features extracted from CNNs' encoder part. This paper proposes a hybrid advanced 3D model for brain tumor segmentation using multi-modal magnetic resonance images. The model benefits from the features extracted from the encoder of 3DU-Net and V-Net architectures at each depth. Then, a concatenation between these features and their fusion is carried out at each decoder depth to build new significant features followed by a 3D convolution layer and Transformers block for more contextual information. In addition, a final convolution block is applied to get the segmented tumor. To this end, the model is evaluated on the BraTS 2020 dataset to segment different sub-regions of brain tumors. The obtained results demonstrate the effectiveness of the proposed model in terms of dice similarity coefficient (DSC) and Hausdorff Distance (HD). For DSC, 91.95% and 82.80% and 81.70% for Whole Tumor(WT), Tumor Core (TC), and Enhancing Tumor(ET), respectively are archived, while for HD, 4.9 mm, 6.0 mm and 3.8 mm for WT, TC and ET are accomplished.","['Convolution Neural Networks (CNNs)', 'Transformers', 'Attention mechanism in Transformers', '3DU-Net', 'V-Net', '3D convolution layer']"
2024,https://openalex.org/W4392529708,Engineering,A machine learning-based framework for clustering residential electricity load profiles to enhance demand response programs,"Load shapes derived from smart meter data are frequently employed to analyze daily energy consumption patterns, particularly in the context of applications like Demand Response (DR). Nevertheless, one of the most important challenges to this endeavor lies in identifying the most suitable consumer clusters with similar consumption behaviors. In this paper, we present a novel machine learning based framework in order to achieve optimal load profiling through a real case study, utilizing data from almost 5000 households in London. Four widely used clustering algorithms are applied specifically K-means, K-medoids, Hierarchical Agglomerative Clustering and Density-based Spatial Clustering. An empirical analysis as well as multiple evaluation metrics are leveraged to assess those algorithms. Following that, we redefine the problem as a probabilistic classification one, with the classifier emulating the behavior of a clustering algorithm, leveraging Explainable AI (xAI) to enhance the interpretability of our solution. According to the clustering algorithm analysis the optimal number of clusters for this case is seven. Despite that, our methodology shows that two of the clusters, almost 10% of the dataset, exhibit significant internal dissimilarity. As a result, these clusters have been excluded from consideration for DR programs. The scalability and versatility of our solution makes it an ideal choice for power utility companies aiming to segment their users for creating more targeted DR programs.","['K-means', 'K-medoids', 'Hierarchical Agglomerative Clustering', 'Density-based Spatial Clustering', 'probabilistic classification', 'Explainable AI (xAI)']"
2024,https://openalex.org/W4400937555,Engineering,The diagnostic and triage accuracy of the GPT-3 artificial intelligence model: an observational study,"BackgroundArtificial intelligence (AI) applications in health care have been effective in many areas of medicine, but they are often trained for a single task using labelled data, making deployment and generalisability challenging. How well a general-purpose AI language model performs diagnosis and triage relative to physicians and laypeople is not well understood.MethodsWe compared the predictive accuracy of Generative Pre-trained Transformer 3 (GPT-3)'s diagnostic and triage ability for 48 validated synthetic case vignettes (<50 words; sixth-grade reading level or below) of both common (eg, viral illness) and severe (eg, heart attack) conditions to a nationally representative sample of 5000 lay people from the USA who could use the internet to find the correct options and 21 practising physicians at Harvard Medical School. There were 12 vignettes for each of four triage categories: emergent, within one day, within 1 week, and self-care. The correct diagnosis and triage category (ie, ground truth) for each vignette was determined by two general internists at Harvard Medical School. For each vignette, human respondents and GPT-3 were prompted to list diagnoses in order of likelihood, and the vignette was marked as correct if the ground-truth diagnosis was in the top three of the listed diagnoses. For triage accuracy, we examined whether the human respondents' and GPT-3's selected triage was exactly correct according to the four triage categories, or matched a dichotomised triage variable (emergent or within 1 day vs within 1 week or self-care). We estimated GPT-3's diagnostic and triage confidence on a given vignette using a modified bootstrap resampling procedure, and examined how well calibrated GPT-3's confidence was by computing calibration curves and Brier scores. We also performed subgroup analysis by case acuity, and an error analysis for triage advice to characterise how its advice might affect patients using this tool to decide if they should seek medical care immediately.FindingsAmong all cases, GPT-3 replied with the correct diagnosis in its top three for 88% (42/48, 95% CI 75–94) of cases, compared with 54% (2700/5000, 53–55) for lay individuals (p<0.0001) and 96% (637/666, 94–97) for physicians (p=0·012). GPT-3 triaged 70% correct (34/48, 57–82) versus 74% (3706/5000, 73–75; p=0.60) for lay individuals and 91% (608/666, 89–93%; p<0.0001) for physicians. As measured by the Brier score, GPT-3 confidence in its top prediction was reasonably well calibrated for diagnosis (Brier score=0·18) and triage (Brier score=0·22). We observed an inverse relationship between case acuity and GPT-3 accuracy (p<0·0001) with a fitted trend line of –8·33% decrease in accuracy for every level of increase in case acuity. For triage error analysis, GPT-3 deprioritised truly emergent cases in seven instances.InterpretationA general-purpose AI language model without any content-specific training could perform diagnosis at levels close to, but below, physicians and better than lay individuals. We found that GPT-3's performance was inferior to physicians for triage, sometimes by a large margin, and its performance was closer to that of lay individuals. Although the diagnostic performance of GPT-3 was comparable to physicians, it was significantly better than a typical person using a search engine.FundingThe National Heart, Lung, and Blood Institute.",['Generative Pre-trained Transformer 3 (GPT-3)']
2024,https://openalex.org/W4390492410,Engineering,Deep Learning for Integrated Origin–Destination Estimation and Traffic Sensor Location Problems,"Traffic control and management applications require the full realization of traffic flow data. Frequently, such data are acquired by traffic sensors with two issues: it is not practicable or even possible to place traffic sensors on every link in a network; sensors do not provide direct information about origin–destination (O–D) demand flows. Therefore, it is imperative to locate the best places to deploy traffic sensors and then augment the knowledge obtained from this link flow sample to predict the entire traffic flow of the network. This article provides a resilient deep learning (DL) architecture combined with a global sensitivity analysis tool to solve O–D estimation and sensor location problems simultaneously. The proposed DL architecture is based on the stacked sparse autoencoder (SAE) model for accurately estimating the entire O–D flows of the network using link flows, thus reversing the conventional traffic assignment problem. The SAE model extracts traffic flow characteristics and derives a meaningful relationship between traffic flow data and network topology. To train the proposed DL architecture, synthetic link flow data were created randomly from the historical demand data of the network. Finally, a global sensitivity analysis was implemented to prioritize the importance of each link in the O–D estimation step to solve the sensor location problem. Two networks of different sizes were used to validate the performance of the model. The efficiency of the proposed method for solving the combination of traffic flow estimation and sensor location problems was confirmed from a low root-mean-square error with a reduction in the number of link flows required.",['stacked sparse autoencoder (SAE) model']
2024,https://openalex.org/W4400798015,Engineering,Evaluation of artificial intelligence-powered screening for sexually transmitted infections-related skin lesions using clinical images and metadata,"Abstract Background Sexually transmitted infections (STIs) pose a significant global public health challenge. Early diagnosis and treatment reduce STI transmission, but rely on recognising symptoms and care-seeking behaviour of the individual. Digital health software that distinguishes STI skin conditions could improve health-seeking behaviour. We developed and evaluated a deep learning model to differentiate STIs from non-STIs based on clinical images and symptoms. Methods We used 4913 clinical images of genital lesions and metadata from the Melbourne Sexual Health Centre collected during 2010–2023. We developed two binary classification models to distinguish STIs from non-STIs: (1) a convolutional neural network (CNN) using images only and (2) an integrated model combining both CNN and fully connected neural network (FCN) using images and metadata. We evaluated the model performance by the area under the ROC curve (AUC) and assessed metadata contributions to the Image-only model. Results Our study included 1583 STI and 3330 non-STI images. Common STI diagnoses were syphilis (34.6%), genital warts (24.5%) and herpes (19.4%), while most non-STIs (80.3%) were conditions such as dermatitis, lichen sclerosis and balanitis. In both STI and non-STI groups, the most frequently observed groups were 25–34 years (48.6% and 38.2%, respectively) and heterosexual males (60.3% and 45.9%, respectively). The Image-only model showed a reasonable performance with an AUC of 0.859 (SD 0.013). The Image + Metadata model achieved a significantly higher AUC of 0.893 (SD 0.018) compared to the Image-only model ( p &lt; 0.01). Out of 21 metadata, the integration of demographic and dermatological metadata led to the most significant improvement in model performance, increasing AUC by 6.7% compared to the baseline Image-only model. Conclusions The Image + Metadata model outperformed the Image-only model in distinguishing STIs from other skin conditions. Using it as a screening tool in a clinical setting may require further development and evaluation with larger datasets.","['convolutional neural network (CNN)', 'fully connected neural network (FCN)']"
2024,https://openalex.org/W4391243055,Social Sciences,Systematic literature review: Quantum machine learning and its applications,"Quantum physics has changed the way we understand our environment, and one of its branches, quantum mechanics, has demonstrated accurate and consistent theoretical results. Quantum computing is the process of performing calculations using quantum mechanics. This field studies the quantum behavior of certain subatomic particles (photons, electrons, etc.) for subsequent use in performing calculations, as well as for large-scale information processing. These advantages are achieved through the use of quantum features, such as entanglement or superposition. These capabilities can give quantum computers an advantage in terms of computational time and cost over classical computers. Nowadays, scientific challenges are impossible to perform by classical computation due to computational complexity (more bytes than atoms in the observable universe) or the time it would take (thousands of years), and quantum computation is the only known answer. However, current quantum devices do not have yet the necessary qubits and are not fault-tolerant enough to achieve these goals. Nonetheless, there are other fields like machine learning, finance, or chemistry where quantum computation could be useful with current quantum devices. This manuscript aims to present a review of the literature published between 2017 and 2023 to identify, analyze, and classify the different types of algorithms used in quantum machine learning and their applications. The methodology follows the guidelines related to Systematic Literature Review methods, such as the one proposed by Kitchenham and other authors in the software engineering field. Consequently, this study identified 94 articles that used quantum machine learning techniques and algorithms and shows their implementation using computational quantum circuits or ansatzs. The main types of found algorithms are quantum implementations of classical machine learning algorithms, such as support vector machines or the k-nearest neighbor model, and classical deep learning algorithms, like quantum neural networks. One of the most relevant applications in the machine learning field is image classification. Many articles, especially within the classification, try to solve problems currently answered by classical machine learning but using quantum devices and algorithms. Even though results are promising, quantum machine learning is far from achieving its full potential. An improvement in quantum hardware is required for this potential to be achieved since the existing quantum computers lack enough quality, speed, and scale to allow quantum computing to achieve its full potential.","['support vector machines', 'k-nearest neighbor model', 'quantum neural networks']"
2024,https://openalex.org/W4393119757,Social Sciences,Unmasking bias in artificial intelligence: a systematic review of bias detection and mitigation strategies in electronic health record-based models,"Abstract Objectives Leveraging artificial intelligence (AI) in conjunction with electronic health records (EHRs) holds transformative potential to improve healthcare. However, addressing bias in AI, which risks worsening healthcare disparities, cannot be overlooked. This study reviews methods to handle various biases in AI models developed using EHR data. Materials and Methods We conducted a systematic review following the Preferred Reporting Items for Systematic Reviews and Meta-analyses guidelines, analyzing articles from PubMed, Web of Science, and IEEE published between January 01, 2010 and December 17, 2023. The review identified key biases, outlined strategies for detecting and mitigating bias throughout the AI model development, and analyzed metrics for bias assessment. Results Of the 450 articles retrieved, 20 met our criteria, revealing 6 major bias types: algorithmic, confounding, implicit, measurement, selection, and temporal. The AI models were primarily developed for predictive tasks, yet none have been deployed in real-world healthcare settings. Five studies concentrated on the detection of implicit and algorithmic biases employing fairness metrics like statistical parity, equal opportunity, and predictive equity. Fifteen studies proposed strategies for mitigating biases, especially targeting implicit and selection biases. These strategies, evaluated through both performance and fairness metrics, predominantly involved data collection and preprocessing techniques like resampling and reweighting. Discussion This review highlights evolving strategies to mitigate bias in EHR-based AI models, emphasizing the urgent need for both standardized and detailed reporting of the methodologies and systematic real-world testing and evaluation. Such measures are essential for gauging models’ practical impact and fostering ethical AI that ensures fairness and equity in healthcare.","['resampling', 'reweighting']"
2024,https://openalex.org/W4402827393,Social Sciences,Larger and more instructable language models become less reliable,"Abstract The prevailing methods to make large language models more powerful and amenable have been based on continuous scaling up (that is, increasing their size, data volume and computational resources 1 ) and bespoke shaping up (including post-filtering 2,3 , fine tuning or use of human feedback 4,5 ). However, larger and more instructable large language models may have become less reliable. By studying the relationship between difficulty concordance, task avoidance and prompting stability of several language model families, here we show that easy instances for human participants are also easy for the models, but scaled-up, shaped-up models do not secure areas of low difficulty in which either the model does not err or human supervision can spot the errors. We also find that early models often avoid user questions but scaled-up, shaped-up models tend to give an apparently sensible yet wrong answer much more often, including errors on difficult questions that human supervisors frequently overlook. Moreover, we observe that stability to different natural phrasings of the same question is improved by scaling-up and shaping-up interventions, but pockets of variability persist across difficulty levels. These findings highlight the need for a fundamental shift in the design and development of general-purpose artificial intelligence, particularly in high-stakes areas for which a predictable distribution of errors is paramount.","['post-filtering', 'fine tuning', 'use of human feedback']"
2024,https://openalex.org/W4392343921,Social Sciences,Data extraction for evidence synthesis using a large language model: A proof‐of‐concept study,"Abstract Data extraction is a crucial, yet labor‐intensive and error‐prone part of evidence synthesis. To date, efforts to harness machine learning for enhancing efficiency of the data extraction process have fallen short of achieving sufficient accuracy and usability. With the release of large language models (LLMs), new possibilities have emerged to increase efficiency and accuracy of data extraction for evidence synthesis. The objective of this proof‐of‐concept study was to assess the performance of an LLM (Claude 2) in extracting data elements from published studies, compared with human data extraction as employed in systematic reviews. Our analysis utilized a convenience sample of 10 English‐language, open‐access publications of randomized controlled trials included in a single systematic review. We selected 16 distinct types of data, posing varying degrees of difficulty (160 data elements across 10 studies). We used the browser version of Claude 2 to upload the portable document format of each publication and then prompted the model for each data element. Across 160 data elements, Claude 2 demonstrated an overall accuracy of 96.3% with a high test–retest reliability (replication 1: 96.9%; replication 2: 95.0% accuracy). Overall, Claude 2 made 6 errors on 160 data items. The most common errors ( n = 4) were missed data items. Importantly, Claude 2's ease of use was high; it required no technical expertise or labeled training data for effective operation (i.e., zero‐shot learning). Based on findings of our proof‐of‐concept study, leveraging LLMs has the potential to substantially enhance the efficiency and accuracy of data extraction for evidence syntheses.",['zero‐shot learning']
2024,https://openalex.org/W4391508432,Social Sciences,Artificial intelligence-driven virtual rehabilitation for people living in the community: A scoping review,"Abstract Virtual Rehabilitation (VRehab) is a promising approach to improving the physical and mental functioning of patients living in the community. The use of VRehab technology results in the generation of multi-modal datasets collected through various devices. This presents opportunities for the development of Artificial Intelligence (AI) techniques in VRehab, namely the measurement, detection, and prediction of various patients’ health outcomes. The objective of this scoping review was to explore the applications and effectiveness of incorporating AI into home-based VRehab programs. PubMed/MEDLINE, Embase, IEEE Xplore, Web of Science databases, and Google Scholar were searched from inception until June 2023 for studies that applied AI for the delivery of VRehab programs to the homes of adult patients. After screening 2172 unique titles and abstracts and 51 full-text studies, 13 studies were included in the review. A variety of AI algorithms were applied to analyze data collected from various sensors and make inferences about patients’ health outcomes, most involving evaluating patients’ exercise quality and providing feedback to patients. The AI algorithms used in the studies were mostly fuzzy rule-based methods, template matching, and deep neural networks. Despite the growing body of literature on the use of AI in VRehab, very few studies have examined its use in patients’ homes. Current research suggests that integrating AI with home-based VRehab can lead to improved rehabilitation outcomes for patients. However, further research is required to fully assess the effectiveness of various forms of AI-driven home-based VRehab, taking into account its unique challenges and using standardized metrics.","['fuzzy rule-based methods', 'deep neural networks']"
2024,https://openalex.org/W4393092671,Social Sciences,CFSSynergy: Combining Feature-Based and Similarity-Based Methods for Drug Synergy Prediction,"Drug synergy prediction plays a vital role in cancer treatment. Because experimental approaches are labor-intensive and expensive, computational-based approaches get more attention. There are two types of computational methods for drug synergy prediction: feature-based and similarity-based. In feature-based methods, the main focus is to extract more discriminative features from drug pairs and cell lines to pass to the task predictor. In similarity-based methods, the similarities among all drugs and cell lines are utilized as features and fed into the task predictor. In this work, a novel approach, called CFSSynergy, that combines these two viewpoints is proposed. First, a discriminative representation is extracted for paired drugs and cell lines as input. We have utilized transformer-based architecture for drugs. For cell lines, we have created a similarity matrix between proteins using the Node2Vec algorithm. Then, the new cell line representation is computed by multiplying the protein–protein similarity matrix and the initial cell line representation. Next, we compute the similarity between unique drugs and unique cells using the learned representation for paired drugs and cell lines. Then, we compute a new representation for paired drugs and cell lines based on the similarity-based features and the learned features. Finally, these features are fed to XGBoost as a task predictor. Two well-known data sets were used to evaluate the performance of our proposed method: DrugCombDB and OncologyScreen. The CFSSynergy approach consistently outperformed existing methods in comparative evaluations. This substantiates the efficacy of our approach in capturing complex synergistic interactions between drugs and cell lines, setting it apart from conventional similarity-based or feature-based methods.","['transformer-based architecture', 'Node2Vec algorithm', 'XGBoost']"
2024,https://openalex.org/W4390755438,Social Sciences,A voting gray wolf optimizer-based ensemble learning models for intrusion detection in the Internet of Things,"Abstract The Internet of Things (IoT) has garnered considerable attention from academic and industrial circles as a pivotal technology in recent years. The escalation of security risks is observed to be associated with the growing interest in IoT applications. Intrusion detection systems (IDS) have been devised as viable instruments for identifying and averting malicious actions in this context. Several techniques described in academic papers are thought to be very accurate, but they cannot be used in the real world because the datasets used to build and test the models do not accurately reflect and simulate the IoT network. Existing methods, on the other hand, deal with these issues, but they are not good enough for commercial use because of their lack of precision, low detection rate, receiver operating characteristic (ROC), and false acceptance rate (FAR). The effectiveness of these solutions is predominantly dependent on individual learners and is consequently influenced by the inherent limitations of each learning algorithm. This study introduces a new approach for detecting intrusion attacks in an IoT network, which involves the use of an ensemble learning technique based on gray wolf optimizer (GWO). The novelty of this study lies in the proposed voting gray wolf optimizer (GWO) ensemble model, which incorporates two crucial components: a traffic analyzer and a classification phase engine. The model employs a voting technique to combine the probability averages of the base learners. Secondly, the combination of feature selection and feature extraction techniques is to reduce dimensionality. Thirdly, the utilization of GWO is employed to optimize the parameters of ensemble models. Similarly, the approach employs the most authentic intrusion detection datasets that are accessible and amalgamates multiple learners to generate ensemble learners. The hybridization of information gain (IG) and principal component analysis (PCA) was employed to reduce dimensionality. The study utilized a novel GWO ensemble learning approach that incorporated a decision tree, random forest, K-nearest neighbor, and multilayer perceptron for classification. To evaluate the efficacy of the proposed model, two authentic datasets, namely, BoT-IoT and UNSW-NB15, were scrutinized. The GWO-optimized ensemble model demonstrates superior accuracy when compared to other machine learning-based and deep learning models. Specifically, the model achieves an accuracy rate of 99.98%, a DR of 99.97%, a precision rate of 99.94%, an ROC rate of 99.99%, and an FAR rate of 1.30 on the BoT-IoT dataset. According to the experimental results, the proposed ensemble model optimized by GWO achieved an accuracy of 100%, a DR of 99.9%, a precision of 99.59%, an ROC of 99.40%, and an FAR of 1.5 when tested on the UNSW-NB15 dataset.","['ensemble learning technique', 'gray wolf optimizer (GWO)', 'voting technique', 'feature selection', 'information gain (IG)', 'principal component analysis (PCA)', 'decision tree', 'random forest', 'K-nearest neighbor', 'multilayer perceptron']"
2024,https://openalex.org/W4391454392,Social Sciences,UANet: An Uncertainty-Aware Network for Building Extraction From Remote Sensing Images,"Building extraction aims to segment building pixels from remote sensing images and plays an essential role in many applications, such as city planning and urban dynamic monitoring. Over the past few years, deep learning methods with encoder–decoder architectures have achieved remarkable performance due to their powerful feature representation capability. Nevertheless, due to the varying scales and styles of buildings, conventional deep learning models always suffer from uncertain predictions and cannot accurately distinguish the complete footprints of the building from the complex distribution of ground objects, leading to a large degree of omission and commission. In this paper, we realize the importance of uncertain prediction and propose a novel and straightforward Uncertainty-Aware Network (UANet) to alleviate this problem. Specifically, we first apply a general encoder–decoder network to obtain a building extraction map with relatively high uncertainty. Second, in order to aggregate the useful information in the highest-level features, we design a Prior Information Guide Module to guide the highest-level features in learning the prior information from the conventional extraction map. Third, based on the uncertain extraction map, we introduce an Uncertainty Rank Algorithm to measure the uncertainty level of each pixel belonging to the foreground and the background. We further combine this algorithm with the proposed Uncertainty-Aware Fusion Module to facilitate level-by-level feature refinement and obtain the final refined extraction map with low uncertainty. To verify the performance of our proposed UANet, we conduct extensive experiments on three public building datasets, including the WHU building dataset, the Massachusetts building dataset, and the Inria aerial image dataset. Results demonstrate that the proposed UANet outperforms other state-of-the-art algorithms by a large margin. The source code of the proposed UANet is available at https://github.com/Henryjiepanli/Uncertainty-aware-Network.","['deep learning methods with encoder–decoder architectures', 'encoder–decoder network']"
2024,https://openalex.org/W4393380945,Social Sciences,One-Step Multi-View Clustering With Diverse Representation,"Multi-View clustering has attracted broad attention due to its capacity to utilize consistent and complementary information among views. Although tremendous progress has been made recently, most existing methods undergo high complexity, preventing them from being applied to large-scale tasks. Multi-View clustering via matrix factorization is a representative to address this issue. However, most of them map the data matrices into a fixed dimension, limiting the model's expressiveness. Moreover, a range of methods suffers from a two-step process, i.e., multimodal learning and the subsequent <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> <tex-math notation=""LaTeX"">$k$</tex-math> </inline-formula> -means, inevitably causing a suboptimal clustering result. In light of this, we propose a one-step multi-view clustering with diverse representation (OMVCDR) method, which incorporates multi-view learning and <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> <tex-math notation=""LaTeX"">$k$</tex-math> </inline-formula> -means into a unified framework. Specifically, we first project original data matrices into various latent spaces to attain comprehensive information and auto-weight them in a self-supervised manner. Then, we directly use the information matrices under diverse dimensions to obtain consensus discrete clustering labels. The unified work of representation learning and clustering boosts the quality of the final results. Furthermore, we develop an efficient optimization algorithm with proven convergence to solve the resultant problem. Comprehensive experiments on various datasets demonstrate the promising clustering performance of our proposed method. The code is publicly available at https://github.com/wanxinhang/OMVCDR.","['Multi-View clustering via matrix factorization', 'k-means', 'multi-view learning', 'representation learning']"
2024,https://openalex.org/W4401434014,Social Sciences,Crafting personalized learning paths with AI for lifelong learning: a systematic literature review,"The rapid evolution of knowledge requires constantly acquiring and updating skills, making lifelong learning crucial. Despite decades of artificial intelligence, recent advances promote new solutions to personalize learning in this context. The purpose of this article is to explore the current state of research on the development of artificial intelligence-mediated solutions for the design of personalized learning paths. To achieve this, a systematic literature review (SRL) of 78 articles published between 2019 and 2024 from the Scopus and Web or Science databases was conducted, answering seven questions grouped into three themes: characteristics of the published research, context of the research, and type of solution analyzed. This study identified that: (a) the greatest production of scientific research on the topic is developed in China, India and the United States, (b) the focus is mainly directed towards the educational context at the higher education level with areas of opportunity for application in the work context, and (c) the development of adaptive learning technologies predominates; however, there is a growing interest in the application of generative language models. This article contributes to the growing interest and literature related to personalized learning under artificial intelligence mediated solutions that will serve as a basis for academic institutions and organizations to design programs under this model.",['generative language models']
2024,https://openalex.org/W4394961856,Social Sciences,Applications and challenges of neural networks in otolaryngology (Review),"Artificial Intelligence (AI) has become a topic of interest that is frequently debated in all research fields. The medical field is no exception, where several unanswered questions remain. When and how this field can benefit from AI support in daily routines are the most frequently asked questions. The present review aims to present the types of neural networks (NNs) available for development, discussing their advantages, disadvantages and how they can be applied practically. In addition, the present review summarizes how NNs (combined with various other features) have already been applied in studies in the ear nose throat research field, from assisting diagnosis to treatment management. Although the answer to this question regarding AI remains elusive, understanding the basics and types of applicable NNs can lead to future studies possibly using more than one type of NN. This approach may bypass the actual limitations in accuracy and relevance of information generated by AI. The proposed studies, the majority of which used convolutional NNs, obtained accuracies varying 70-98%, with a number of studies having the AI trained on a limited number of cases (<100 patients). The lack of standardization in AI protocols for research negatively affects data homogeneity and transparency of databases.","['neural networks (NNs)', 'convolutional neural networks (convolutional NNs)']"
2024,https://openalex.org/W4390618081,Social Sciences,Making Sense of Machine Learning: A Review of Interpretation Techniques and Their Applications,"Transparency in AI models is essential for promoting human–AI collaboration and ensuring regulatory compliance. However, interpreting these models is a complex process influenced by various methods and datasets. This study presents a comprehensive overview of foundational interpretation techniques, meticulously referencing the original authors and emphasizing their pivotal contributions. Recognizing the seminal work of these pioneers is imperative for contextualizing the evolutionary trajectory of interpretation in the field of AI. Furthermore, this research offers a retrospective analysis of interpretation techniques, critically evaluating their inherent strengths and limitations. We categorize these techniques into model-based, representation-based, post hoc, and hybrid methods, delving into their diverse applications. Furthermore, we analyze publication trends over time to see how the adoption of advanced computational methods within various categories of interpretation techniques has shaped the development of AI interpretability over time. This analysis highlights a notable preference shift towards data-driven approaches in the field. Moreover, we consider crucial factors such as the suitability of these techniques for generating local or global insights and their compatibility with different data types, including images, text, and tabular data. This structured categorization serves as a guide for practitioners navigating the landscape of interpretation techniques in AI. In summary, this review not only synthesizes various interpretation techniques but also acknowledges the contributions of their original authors. By emphasizing the origins of these techniques, we aim to enhance AI model explainability and underscore the importance of recognizing biases, uncertainties, and limitations inherent in the methods and datasets. This approach promotes the ethical and practical use of interpretation insights, empowering AI practitioners, researchers, and professionals to make informed decisions when selecting techniques for responsible AI implementation in real-world scenarios.","['model-based methods', 'representation-based methods', 'hybrid methods']"
2024,https://openalex.org/W4391723759,Social Sciences,Artificial Intelligence to Automate Network Meta-Analyses: Four Case Studies to Evaluate the Potential Application of Large Language Models,"The emergence of artificial intelligence, capable of human-level performance on some tasks, presents an opportunity to revolutionise development of systematic reviews and network meta-analyses (NMAs). In this pilot study, we aim to assess use of a large-language model (LLM, Generative Pre-trained Transformer 4 [GPT-4]) to automatically extract data from publications, write an R script to conduct an NMA and interpret the results. We considered four case studies involving binary and time-to-event outcomes in two disease areas, for which an NMA had previously been conducted manually. For each case study, a Python script was developed that communicated with the LLM via application programming interface (API) calls. The LLM was prompted to extract relevant data from publications, to create an R script to be used to run the NMA and then to produce a small report describing the analysis. The LLM had a > 99% success rate of accurately extracting data across 20 runs for each case study and could generate R scripts that could be run end-to-end without human input. It also produced good quality reports describing the disease area, analysis conducted, results obtained and a correct interpretation of the results. This study provides a promising indication of the feasibility of using current generation LLMs to automate data extraction, code generation and NMA result interpretation, which could result in significant time savings and reduce human error. This is provided that routine technical checks are performed, as recommend for human-conducted analyses. Whilst not currently 100% consistent, LLMs are likely to improve with time.","['large-language model (LLM, Generative Pre-trained Transformer 4 [GPT-4])']"
2024,https://openalex.org/W4390506438,Social Sciences,Artificial intelligence for oral squamous cell carcinoma detection based on oral photographs: A comprehensive literature review,"Abstract Introduction Oral squamous cell carcinoma (OSCC) presents a significant global health challenge. The integration of artificial intelligence (AI) and computer vision holds promise for the early detection of OSCC through the analysis of digitized oral photographs. This literature review explores the landscape of AI‐driven OSCC automatic detection, assessing both the performance and limitations of the current state of the art. Materials and Methods An electronic search using several data base was conducted, and a systematic review performed in accordance with PRISMA guidelines (CRD42023441416). Results Several studies have demonstrated remarkable results for this task, consistently achieving sensitivity rates exceeding 85% and accuracy rates surpassing 90%, often encompassing around 1000 images. The review scrutinizes these studies, shedding light on their methodologies, including the use of recent machine learning and pattern recognition approaches coupled with different supervision strategies. However, comparing the results from different papers is challenging due to variations in the datasets used. Discussion Considering these findings, this review underscores the urgent need for more robust and reliable datasets in the field of OSCC detection. Furthermore, it highlights the potential of advanced techniques such as multi‐task learning, attention mechanisms, and ensemble learning as crucial tools in enhancing the accuracy and sensitivity of OSCC detection through oral photographs. Conclusion These insights collectively emphasize the transformative impact of AI‐driven approaches on early OSCC diagnosis, with the potential to significantly improve patient outcomes and healthcare practices.","['machine learning', 'multi-task learning', 'attention mechanisms', 'ensemble learning']"
2024,https://openalex.org/W4391096835,Social Sciences,Diagnostic Performance Comparison between Generative AI and Physicians: A Systematic Review and Meta-Analysis,"Abstract Background The rapid advancement of generative artificial intelligence (AI) has led to the wide dissemination of models with exceptional understanding and generation of human language. Their integration into healthcare has shown potential for improving medical diagnostics, yet a comprehensive diagnostic performance evaluation of generative AI models and the comparison of their diagnostic performance with that of physicians has not been extensively explored. Methods In this systematic review and meta-analysis, a comprehensive search of Medline, Scopus, Web of Science, Cochrane Central, and MedRxiv was conducted for studies published from June 2018 through December 2023, focusing on those that validate generative AI models for diagnostic tasks. The risk of bias was assessed using the Prediction Model Study Risk of Bias Assessment Tool. Meta-regression was performed to summarize the performance of the models and to compare the accuracy of the models with that of physicians. Results The search resulted in 54 studies being included in the meta-analysis. Nine generative AI models were evaluated across 17 medical specialties. The quality assessment indicated a high risk of bias in the majority of studies, primarily due to small sample sizes. The overall accuracy for generative AI models across 54 studies was 56.9% (95% confidence interval [CI]: 51.0–62.7%). The meta-analysis demonstrated that, on average, physicians exceeded the accuracy of the models (difference in accuracy: 14.4% [95% CI: 4.9–23.8%], p-value =0.004). However, both Prometheus (Bing) and GPT-4 showed slightly better performance compared to non-experts (-2.3% [95% CI: -27.0–22.4%], p-value = 0.848 and -0.32% [95% CI: -14.4–13.7%], p-value = 0.962), but slightly underperformed when compared to experts (10.9% [95% CI: -13.1–35.0%], p-value = 0.356 and 12.9% [95% CI: 0.15–25.7%], p-value = 0.048). The sub-analysis revealed significantly improved accuracy in the fields of Gynecology, Pediatrics, Orthopedic surgery, Plastic surgery, and Otolaryngology, while showing reduced accuracy for Neurology, Psychiatry, Rheumatology, and Endocrinology compared to that of General Medicine. No significant heterogeneity was observed based on the risk of bias. Conclusions Generative AI exhibits promising diagnostic capabilities, with accuracy varying significantly by model and medical specialty. Although they have not reached the reliability of expert physicians, the findings suggest that generative AI models have the potential to enhance healthcare delivery and medical education, provided they are integrated with caution and their limitations are well-understood. Key Points Question: What is the diagnostic accuracy of generative AI models and how does this accuracy compare to that of physicians? Findings: This meta-analysis found that generative AI models have a pooled accuracy of 56.9% (95% confidence interval: 51.0–62.7%). The accuracy of expert physicians exceeds that of AI in all specialties, however, some generative AI models are comparable to non-expert physicians. Meaning: The diagnostic performance of generative AI models suggests that they do not match the level of experienced physicians but that they may have potential applications in healthcare delivery and medical education.",['generative AI models']
2024,https://openalex.org/W4393222088,Social Sciences,Methodological insights into ChatGPT’s screening performance in systematic reviews,"Abstract Background The screening process for systematic reviews and meta-analyses in medical research is a labor-intensive and time-consuming task. While machine learning and deep learning have been applied to facilitate this process, these methods often require training data and user annotation. This study aims to assess the efficacy of ChatGPT, a large language model based on the Generative Pretrained Transformers (GPT) architecture, in automating the screening process for systematic reviews in radiology without the need for training data. Methods A prospective simulation study was conducted between May 2nd and 24th, 2023, comparing ChatGPT’s performance in screening abstracts against that of general physicians (GPs). A total of 1198 abstracts across three subfields of radiology were evaluated. Metrics such as sensitivity, specificity, positive and negative predictive values (PPV and NPV), workload saving, and others were employed. Statistical analyses included the Kappa coefficient for inter-rater agreement, ROC curve plotting, AUC calculation, and bootstrapping for p-values and confidence intervals. Results ChatGPT completed the screening process within an hour, while GPs took an average of 7–10 days. The AI model achieved a sensitivity of 95% and an NPV of 99%, slightly outperforming the GPs’ sensitive consensus (i.e., including records if at least one person includes them). It also exhibited remarkably low false negative counts and high workload savings, ranging from 40 to 83%. However, ChatGPT had lower specificity and PPV compared to human raters. The average Kappa agreement between ChatGPT and other raters was 0.27. Conclusions ChatGPT shows promise in automating the article screening phase of systematic reviews, achieving high sensitivity and workload savings. While not entirely replacing human expertise, it could serve as an efficient first-line screening tool, particularly in reducing the burden on human resources. Further studies are needed to fine-tune its capabilities and validate its utility across different medical subfields.","['machine learning', 'deep learning', 'Generative Pretrained Transformers (GPT) architecture']"
2024,https://openalex.org/W4394835724,Social Sciences,Machine Learning-Assisted Design of Advanced Polymeric Materials,"ConspectusPolymeric material research is encountering a new paradigm driven by machine learning (ML) and big data. The ML-assisted design has proven to be a successful approach for designing novel high-performance polymeric materials. This goal is mainly achieved through the following procedure: structure representation and database construction, establishment of a ML-based property prediction model, virtual design and high-throughput screening. The key to this approach lies in training ML models that delineate structure–property relationships based on available polymer data (e.g., structure, component, and property data), enabling the screening of promising polymers that satisfy the targeted property requirements. However, the relative scarcity of high-quality polymer data and the complex polymeric multiscale structure–property relationships pose challenges for this ML-assisted design method, such as data and modeling challenges.In this Account, we summarize the state-of-the-art advancements concerning the ML-assisted design of polymeric materials. Regarding structure representation and database construction, the digital representations of polymers are the predominant methods in cheminformatics along with some newly developed methods that integrate the polymeric multiscale structure characteristics. When establishing a ML-based property prediction model, the key is choosing and optimizing ML models to attain high-precision predictions across a vast chemical structure space. Advanced ML algorithms, such as transfer learning and multitask learning, have been utilized to address the data and modeling challenges. During the ML-assisted screening process, by defining and combining polymer genes, virtual polymer candidates are generated, and subsequently, their properties are predicted and high-throughput screened using ML property prediction models. Finally, the promising polymers identified through this approach are verified by computer simulations and experiments.We provide an overview of our recent efforts toward developing ML-assisted design approaches for discovering advanced polymeric materials and emphasize the intricate nature of polymer structural design. To well describe the multiscale structures of polymers, new structure representation methods, such as polymer fingerprint and cross-linking descriptors, were developed. Moreover, a multifidelity learning method was proposed to leverage the multisource isomerous polymer data from experiments and simulations. Additionally, graph neural networks and Bayesian optimization methods have been developed and applied for predicting polymer properties as well as designing polymer structures and compositions.Finally, we identify the current challenges and point out the development directions in this emerging field. It is highly desirable to establish new structure representation and advanced ML modeling methods for polymeric materials, particularly when constructing polymer large models based on chemical language. Through this Account, we seek to stimulate further interest and foster active collaborations for developing ML-assisted design approaches and realizing the innovation of advanced polymeric materials.","['transfer learning', 'multifidelity learning', 'graph neural networks', 'Bayesian optimization']"
2024,https://openalex.org/W4398169659,Social Sciences,The Sociodemographic Biases in Machine Learning Algorithms: A Biomedical Informatics Perspective,"Artificial intelligence models represented in machine learning algorithms are promising tools for risk assessment used to guide clinical and other health care decisions. Machine learning algorithms, however, may house biases that propagate stereotypes, inequities, and discrimination that contribute to socioeconomic health care disparities. The biases include those related to some sociodemographic characteristics such as race, ethnicity, gender, age, insurance, and socioeconomic status from the use of erroneous electronic health record data. Additionally, there is concern that training data and algorithmic biases in large language models pose potential drawbacks. These biases affect the lives and livelihoods of a significant percentage of the population in the United States and globally. The social and economic consequences of the associated backlash cannot be underestimated. Here, we outline some of the sociodemographic, training data, and algorithmic biases that undermine sound health care risk assessment and medical decision-making that should be addressed in the health care system. We present a perspective and overview of these biases by gender, race, ethnicity, age, historically marginalized communities, algorithmic bias, biased evaluations, implicit bias, selection/sampling bias, socioeconomic status biases, biased data distributions, cultural biases and insurance status bias, conformation bias, information bias and anchoring biases and make recommendations to improve large language model training data, including de-biasing techniques such as counterfactual role-reversed sentences during knowledge distillation, fine-tuning, prefix attachment at training time, the use of toxicity classifiers, retrieval augmented generation and algorithmic modification to mitigate the biases moving forward.","['knowledge distillation', 'fine-tuning', 'retrieval augmented generation']"
2024,https://openalex.org/W4399363436,Social Sciences,Collective Constitutional AI: Aligning a Language Model with Public Input,"There is growing consensus that language model (LM) developers should not be the sole deciders of LM behavior, creating a need for methods that enable the broader public to collectively shape the behavior of LM systems that affect them. To address this need, we present Collective Constitutional AI (CCAI): a multi-stage process for sourcing and integrating public input into LMs—from identifying a target population to sourcing principles to training and evaluating a model. We demonstrate the real-world practicality of this approach by creating what is, to our knowledge, the first LM fine-tuned with collectively sourced public input and evaluating this model against a baseline model trained with established principles from a LM developer. Our quantitative evaluations demonstrate several benefits of our approach: the CCAI-trained model shows lower bias across nine social dimensions compared to the baseline model, while maintaining equivalent performance on language, math, and helpful-harmless evaluations. Qualitative comparisons of the models suggest that the models differ on the basis of their respective constitutions, e.g., when prompted with contentious topics, the CCAI-trained model tends to generate responses that reframe the matter positively instead of a refusal. These results demonstrate a promising, tractable pathway toward publicly informed development of language models.",['fine-tuning']
2024,https://openalex.org/W4399715357,Social Sciences,AI-POWERED FRAUD DETECTION IN BANKING: SAFEGUARDING FINANCIAL TRANSACTIONS,"The banking industry's metamorphosis through digitalization has unquestionably revolutionized accessibility and convenience for customers worldwide. However, this paradigm shift has ushered in a new era of challenges, most notably in the realm of cybersecurity. Conventional rule-based fraud detection strategies have struggled to keep pace with the rapid evolution of cyber threats, prompting a surge of interest in more adaptive approaches like unsupervised learning. Furthermore, the COVID-19 pandemic has exacerbated the issue of bank fraud due to the widespread transition to online platforms and the proliferation of charitable funds, which present ripe opportunities for exploitation by cybercriminals. In response to these pressing concerns, this study delves into the realm of machine learning algorithms for the analysis and identification of fraudulent banking transactions. Notably, it contributes scientific novelty by developing models specifically tailored to this purpose and implementing innovative preprocessing techniques to enhance detection accuracy. Utilizing a diverse array of algorithms, including Random Forest, K-Nearest Neighbor (KNN), Naïve Bayes, Decision Trees, and Logistic Regression, the study showcases promising results. In particular, logistic regression and decision tree models exhibit impressive accuracy and Area Under the Curve (AUC) values of approximately 0.98, 0.97 and 0.95, 0.94, respectively. Given the pervasive nature of banking fraud in our digital society, the utilization of artificial intelligence algorithms for fraud detection stands as a critical and timely endeavor, promising enhanced security and trust in the financial ecosystem.","['unsupervised learning', 'Random Forest', 'K-Nearest Neighbor (KNN)', 'Naïve Bayes', 'Decision Trees', 'Logistic Regression']"
2024,https://openalex.org/W4391655051,Social Sciences,Do large language models show decision heuristics similar to humans? A case study using GPT-3.5.,"A Large Language Model (LLM) is an artificial intelligence system trained on vast amounts of natural language data, enabling it to generate human-like responses to written or spoken language input. Generative Pre-Trained Transformer (GPT)-3.5 is an example of an LLM that supports a conversational agent called ChatGPT. In this work, we used a series of novel prompts to determine whether ChatGPT shows heuristics and other context-sensitive responses. We also tested the same prompts on human participants. Across four studies, we found that ChatGPT was influenced by random anchors in making estimates (anchoring, Study 1); it judged the likelihood of two events occurring together to be higher than the likelihood of either event occurring alone, and it was influenced by anecdotal information (representativeness and availability heuristic, Study 2); it found an item to be more efficacious when its features were presented positively rather than negatively-even though both presentations contained statistically equivalent information (framing effect, Study 3); and it valued an owned item more than a newly found item even though the two items were objectively identical (endowment effect, Study 4). In each study, human participants showed similar effects. Heuristics and context-sensitive responses in humans are thought to be driven by cognitive and affective processes such as loss aversion and effort reduction. The fact that an LLM-which lacks these processes-also shows such responses invites consideration of the possibility that language is sufficiently rich to carry these effects and may play a role in generating these effects in humans. (PsycInfo Database Record (c) 2024 APA, all rights reserved).",['Generative Pre-Trained Transformer (GPT)-3.5']
2024,https://openalex.org/W4401941326,Social Sciences,Predicting ground vibration during rock blasting using relevance vector machine improved with dual kernels and metaheuristic algorithms,"The ground vibration caused by rock blasting is an extremely hazardous outcome of the blasting operation. Blasting activity has detrimental effects on both the ecology and the human population living in proximity to the area. Evaluating the magnitude of blasting vibrations requires careful evaluation of the peak particle velocity (PPV) as a fundamental and essential parameter for quantifying vibration velocity. Therefore, this study employs models using the relevance vector machine (RVM) approach for predicting the PPV resulting from quarry blasting. This investigation utilized the conventional and optimized RVM models for the first time in ground vibration prediction. This work compares thirty-three RVM models to choose the most efficient performance model. The following conclusions have been mapped from the outcomes of the several analyses. The performance evaluation of each RVM model demonstrates each model achieved a performance of more than 0.85 during the testing phase, there was a strong correlation observed between the actual ground vibrations and the predicted ones. The analysis of performance metrics (RMSE = 21.2999 mm/s, 16.2272 mm/s, R = 0.9175, PI = 1.59, IOA = 0.8239, IOS = 0.2541), score analysis (= 93), REC curve (= 6.85E-03, close to the actual, i.e., 0), curve fitting (= 1.05 close to best fit, i.e., 1), AD test (= 11.607 close to the actual, i.e., 9.790), Wilcoxon test (= 95%), Uncertainty analysis (WCB = 0.0134), and computational cost (= 0.0180) demonstrate that PSO_DRVM model MD29 outperformed better than other RVM models in the testing phase. This study will help mining and civil engineers and blasting experts to select the best kernel function and its hyperparameters in estimating ground vibration during rock blasting project. In the context of the mining and civil industry, the application of this study offers significant potential for enhancing safety protocols and optimizing operational efficiency.","['relevance vector machine (RVM)', 'conventional RVM', 'optimized RVM']"
2024,https://openalex.org/W4402305045,Social Sciences,Triplet Contrastive Representation Learning for Unsupervised Vehicle Re-identification,"Part feature learning plays a crucial role in achieving fine-grained semantic understanding in unsupervised vehicle re-identification. However, existing approaches directly model part and global features, which can easily lead to severe gradient vanishing issues due to their unequal feature information and unreliable pseudo-labels. To address this problem, in this paper, we propose a triplet contrastive representation learning (TCRL) framework, which leverages cluster features to bridge the part features and global features for unsupervised vehicle re-identification. Specifically, TCRL devises three memory banks to store the instance/cluster features and proposes a proxy contrastive loss (PCL) to make contrastive learning between adjacent memory banks, thus presenting the associations between the part and global features as a transition of the part-cluster and cluster-global associations. Since the cluster memory bank copes with all the vehicle features, it can summarize them into a discriminative feature representation. To deeply exploit the instance/cluster information, TCRL proposes two additional loss functions. For the instance-level feature, a hybrid contrastive loss (HCL) re-defines the sample correlations by approaching the positive instance features and pushing all negative instance features away. For the cluster-level feature, a weighted regularization cluster contrastive loss (WRCCL) refines the pseudo labels by penalizing the mislabeled images according to the instance similarity. Extensive experiments show that TCRL outperforms many state-of-the-art unsupervised vehicle re-identification approaches.","['contrastive learning', 'proxy contrastive loss (PCL)', 'hybrid contrastive loss (HCL)']"
2024,https://openalex.org/W4391618879,Social Sciences,Likelihood-based feature representation learning combined with neighborhood information for predicting circRNA–miRNA associations,"Connections between circular RNAs (circRNAs) and microRNAs (miRNAs) assume a pivotal position in the onset, evolution, diagnosis and treatment of diseases and tumors. Selecting the most potential circRNA-related miRNAs and taking advantage of them as the biological markers or drug targets could be conducive to dealing with complex human diseases through preventive strategies, diagnostic procedures and therapeutic approaches. Compared to traditional biological experiments, leveraging computational models to integrate diverse biological data in order to infer potential associations proves to be a more efficient and cost-effective approach. This paper developed a model of Convolutional Autoencoder for CircRNA-MiRNA Associations (CA-CMA) prediction. Initially, this model merged the natural language characteristics of the circRNA and miRNA sequence with the features of circRNA-miRNA interactions. Subsequently, it utilized all circRNA-miRNA pairs to construct a molecular association network, which was then fine-tuned by labeled samples to optimize the network parameters. Finally, the prediction outcome is obtained by utilizing the deep neural networks classifier. This model innovatively combines the likelihood objective that preserves the neighborhood through optimization, to learn the continuous feature representation of words and preserve the spatial information of two-dimensional signals. During the process of 5-fold cross-validation, CA-CMA exhibited exceptional performance compared to numerous prior computational approaches, as evidenced by its mean area under the receiver operating characteristic curve of 0.9138 and a minimal SD of 0.0024. Furthermore, recent literature has confirmed the accuracy of 25 out of the top 30 circRNA-miRNA pairs identified with the highest CA-CMA scores during case studies. The results of these experiments highlight the robustness and versatility of our model.","['Convolutional Autoencoder', 'deep neural networks classifier']"
2024,https://openalex.org/W4401567811,Social Sciences,DisenSemi: Semi-Supervised Graph Classification via Disentangled Representation Learning,"Graph classification is a critical task in numerous multimedia applications, where graphs are employed to represent diverse types of multimedia data, including images, videos, and social networks. Nevertheless, in the real world, labeled graph data are always limited or scarce. To address this issue, we focus on the semi-supervised graph classification task, which involves both supervised and unsupervised models learning from labeled and unlabeled data. In contrast to recent approaches that transfer the entire knowledge from the unsupervised model to the supervised one, we argue that an effective transfer should only retain the relevant semantics that align well with the supervised task. We introduce a novel framework termed in this article, which learns disentangled representation for semi-supervised graph classification. Specifically, a disentangled graph encoder is proposed to generate factorwise graph representations for both supervised and unsupervised models. Then, we train two models via supervised objective and mutual information (MI)-based constraints, respectively. To ensure the meaningful transfer of knowledge from the unsupervised encoder to the supervised one, we further define an MI-based disentangled consistency regularization between two models and identify the corresponding rationale that aligns well with the current graph classification task. Experiments conducted on various publicly available datasets demonstrate the effectiveness of our .","['semi-supervised graph classification', 'disentangled graph encoder']"
2024,https://openalex.org/W4391029001,Social Sciences,Smart energy management in residential buildings: the impact of knowledge and behavior,"Abstract A new technology called smart energy management makes use of IoT concepts to enhance energy efficiency and lower waste in structures. The goal of this study is to comprehend how household energy management knowledge affects energy usage, user behavior, related expenses, and environmental effect. Through a survey of 100 valid replies in Palestine, the research model assessed the knowledge and consumption habits of building occupants. Smart PLS software was used to analyze the research model using partial least squares structural equation modeling (PLS-SEM). Using path coefficients and behavior as a mediating variable, the structural model connected the latent variables. The mediation hypotheses were tested using the Preacher and Hayes method, and the indirect effect and confidence intervals were estimated and calculated using bootstrapping. The findings demonstrated that by lowering energy use and enhancing overall building performance, residential buildings that implement smart energy consumption management systems may move toward a more sustainable future. Furthermore, the study found that education and awareness campaigns are necessary to increase residents’ knowledge of these systems to promote energy savings. The results also indicated statistically significant indirect effects, supporting the existence of mediation of the behavior construct. Path coefficient values and P -values were presented to further support the study’s hypotheses. Such smart energy management systems represent an important innovation in building management and can help create more sustainable and efficient buildings.",['bootstrapping']
2024,https://openalex.org/W4392955615,Social Sciences,Variation in social media sensitivity across people and contexts,"Abstract Social media impacts people’s wellbeing in different ways, but relatively little is known about why this is the case. Here we introduce the construct of “social media sensitivity” to understand how social media and wellbeing associations differ across people and the contexts in which these platforms are used. In a month-long large-scale intensive longitudinal study (total n = 1632; total number of observations = 120,599), we examined for whom and under which circumstances social media was associated with positive and negative changes in social and affective wellbeing. Applying a combination of frequentist and Bayesian multilevel models, we found a small negative average association between social media use AND subsequent wellbeing, but the associations were heterogenous across people. People with psychologically vulnerable dispositions (e.g., those who were depressed, lonely, not satisfied with life) tended to experience heightened negative social media sensitivity in comparison to people who were not psychologically vulnerable. People also experienced heightened negative social media sensitivity when in certain types of places (e.g., in social places, in nature) and while around certain types of people (e.g., around family members, close ties), as compared to using social media in other contexts. Our results suggest that an understanding of the effects of social media on wellbeing should account for the psychological dispositions of social media users, and the physical and social contexts surrounding their use. We discuss theoretical and practical implications of social media sensitivity for scholars, policymakers, and those in the technology industry.",['Bayesian multilevel models']
2024,https://openalex.org/W4390506124,Social Sciences,Machine learning models for predicting preeclampsia: a systematic review,"Abstract Background This systematic review provides an overview of machine learning (ML) approaches for predicting preeclampsia. Method This review adhered to the Preferred Reporting Items for Systematic Reviews and Meta-Analyzes (PRISMA) guidelines. We searched the Cochrane Central Register, PubMed, EMBASE, ProQuest, Scopus, and Google Scholar up to February 2023. Search terms were limited to “preeclampsia” AND “artificial intelligence” OR “machine learning” OR “deep learning.” All studies that used ML-based analysis for predicting preeclampsia in pregnant women were considered. Non-English articles and those that are unrelated to the topic were excluded. The PROBAST was used to assess the risk of bias and applicability of each included study. Results The search strategy yielded 128 citations; after duplicates were removed and title and abstract screening was completed, 18 full-text articles were evaluated for eligibility. Four studies were included in this review. Two studies were at low risk of bias, and two had low to moderate risk. All of the study designs included were retrospective cohort studies. Nine distinct models were chosen as ML models from the four studies. Maternal characteristics, medical history, medication intake, obstetrical history, and laboratory and ultrasound findings obtained during prenatal care visits were candidate predictors to train the ML model. Elastic net, stochastic gradient boosting, extreme gradient boosting, and Random forest were among the best models to predict preeclampsia. All four studies used metrics such as the area under the curve, true positive rate, negative positive rate, accuracy, precision, recall, and F1 score. The AUC of ML models varied from 0.860 to 0.973 in four studies. Conclusion The results of studies yielded high prediction performance of ML models for preeclampsia risk from routine early pregnancy information.","['Elastic net', 'stochastic gradient boosting', 'extreme gradient boosting', 'Random forest']"
2024,https://openalex.org/W4391558438,Social Sciences,UniLog: Automatic Logging via LLM and In-Context Learning,"Logging, which aims to determine the position of logging statements, the verbosity levels, and the log messages, is a crucial process for software reliability enhancement. In recent years, numerous automatic logging tools have been designed to assist developers in one of the logging tasks (e.g., providing suggestions on whether to log in try-catch blocks). These tools are useful in certain situations yet cannot provide a comprehensive logging solution in general. Moreover, although recent research has started to explore end-to-end logging, it is still largely constrained by the high cost of fine-tuning, hindering its practical usefulness in software development. To address these problems, this paper proposes UniLog, an automatic logging framework based on the in-context learning (ICL) paradigm of large language models (LLMs). Specifically, UniLog can generate an appropriate logging statement with only a prompt containing five demonstration examples without any model tuning. In addition, UniLog can further enhance its logging ability after warmup with only a few hundred random samples. We evaluated UniLog on a large dataset containing 12,012 code snippets extracted from 1,465 GitHub repositories. The results show that UniLog achieved the state-of-the-art performance in automatic logging: (1) 76.9% accuracy in selecting logging positions, (2) 72.3% accuracy in predicting verbosity levels, and (3) 27.1 BLEU-4 score in generating log messages. Meanwhile, UniLog requires less than 4% of the parameter tuning time needed by fine-tuning the same LLM.","['in-context learning (ICL) paradigm of large language models (LLMs)', 'fine-tuning']"
2024,https://openalex.org/W4398183551,Social Sciences,A Survey on Malware Detection with Graph Representation Learning,"Malware detection has become a major concern due to the increasing number and complexity of malware. Traditional detection methods based on signatures and heuristics are used for malware detection, but unfortunately, they suffer from poor generalization to unknown attacks and can be easily circumvented using obfuscation techniques. In recent years, Machine Learning (ML) and notably Deep Learning (DL) achieved impressive results in malware detection by learning useful representations from data and have become a solution preferred over traditional methods. Recently, the application of Graph Representation Learning (GRL) techniques on graph-structured data has demonstrated impressive capabilities in malware detection. This success benefits notably from the robust structure of graphs, which are challenging for attackers to alter, and their intrinsic explainability capabilities. In this survey, we provide an in-depth literature review to summarize and unify existing works under the common approaches and architectures. We notably demonstrate that Graph Neural Networks (GNNs) reach competitive results in learning robust embeddings from malware represented as expressive graph structures such as Function Call Graphs (FCGs) and Control Flow Graphs (CFGs). This study also discusses the robustness of GRL-based methods to adversarial attacks, contrasts their effectiveness with other ML/DL approaches, and outlines future research for practical deployment.","['Machine Learning (ML)', 'Deep Learning (DL)', 'Graph Representation Learning (GRL)', 'Graph Neural Networks (GNNs)']"
2024,https://openalex.org/W4390662926,Social Sciences,Artificial intelligence performance in detecting lymphoma from medical imaging: a systematic review and meta-analysis,"Abstract Background Accurate diagnosis and early treatment are essential in the fight against lymphatic cancer. The application of artificial intelligence (AI) in the field of medical imaging shows great potential, but the diagnostic accuracy of lymphoma is unclear. This study was done to systematically review and meta-analyse researches concerning the diagnostic performance of AI in detecting lymphoma using medical imaging for the first time. Methods Searches were conducted in Medline, Embase, IEEE and Cochrane up to December 2023. Data extraction and assessment of the included study quality were independently conducted by two investigators. Studies that reported the diagnostic performance of an AI model/s for the early detection of lymphoma using medical imaging were included in the systemic review. We extracted the binary diagnostic accuracy data to obtain the outcomes of interest: sensitivity (SE), specificity (SP), and Area Under the Curve (AUC). The study was registered with the PROSPERO, CRD42022383386. Results Thirty studies were included in the systematic review, sixteen of which were meta-analyzed with a pooled sensitivity of 87% (95%CI 83–91%), specificity of 94% (92–96%), and AUC of 97% (95–98%). Satisfactory diagnostic performance was observed in subgroup analyses based on algorithms types (machine learning versus deep learning, and whether transfer learning was applied), sample size (≤ 200 or &gt; 200), clinicians versus AI models and geographical distribution of institutions (Asia versus non-Asia). Conclusions Even if possible overestimation and further studies with a better standards for application of AI algorithms in lymphoma detection are needed, we suggest the AI may be useful in lymphoma diagnosis.","['machine learning', 'deep learning', 'transfer learning']"
2024,https://openalex.org/W4390939347,Social Sciences,Adaptive Attention-Based Graph Representation Learning to Detect Phishing Accounts on the Ethereum Blockchain,"With Ethereum blockchain advancement, the Ethereum platform gathers numerous users. In this context, traditional phishing appears new fraud methods, resulting in significant losses. Currently, network embedding methods are considered effective solutions in the field of phishing detection. However, investigating existing Ethereum phishing node detection algorithms finds they are not optimal and still face two issues. Firstly, the Ethereum network's topology is unsatisfactory, with nodes exhibiting a long-tail distribution in their degree. Current technologies typically allow high-degree nodes to acquire high-quality embeddings, while low-degree nodes, constrained by limited structure, obtain embeddings of lower quality, significantly impacting the detection accuracy of downstream tasks. Secondly, different features of nodes will suffer losses during the fusion process, resulting in the final learned feature embedding being suboptimal. This paper presents an attention-based graphical representation learning approach (ABGRL) to address these problems. ABGRL extracts different feature information by means of multiple channels, and fuses the different feature information using adaptive attention convolution to select the feature information that has the greatest impact on the downstream task. Then the tail node feature information is enhanced by a self-supervised regression model with robust tail node embedding. Finally, the effectiveness of the proposed model was validated through extensive experiments.",['network embedding methods']
2024,https://openalex.org/W4391127198,Social Sciences,Risk predictions of surgical wound complications based on a machine learning algorithm: A systematic review,"Abstract Surgical wounds may arise due to harm inflicted upon soft tissue during surgical intervention, and many complications and injuries may accompany them. These complications can lead to prolonged hospitalization and poorer clinical outcomes. Also, Machine learning (ML) is a Section of artificial intelligence (AI) that has emerged in medical care and is increasingly used for diagnosis, complications, prognosis and recurrence prediction. This study aims to investigate surgical wound risk predictions and management using a ML algorithm by R programming language analysis. The systematic review, following PRISMA guidelines, spanned electronic databases using search terms like ‘machine learning’, ‘surgical’ and ‘wound’. Inclusion criteria covered experimental studies from 1990 to the present on ML's application in surgical wound evaluation. Exclusion criteria included studies lacking full text, focusing on ML in all surgeries, neglecting wound assessment and duplications. Two authors rigorously assessed titles, abstracts and full texts, excluding reviews and guidelines. Ultimately, relevant articles were then analysed. The present study identified nine articles employing ML for surgical wound management. The analysis encompassed various surgical procedures, including Cardiothoracic, Caesarean total abdominal colectomy, Burn plastic surgery, facial plastic surgery, laparotomy, minimal invasive surgery, hernia repair and unspecified surgeries. ML was skillful in evaluating surgical site infections (SSI) in seven studies, while two extended its use to burn‐grade diagnosis and wound classification. Support Vector Machine (SVM) and Convolutional Neural Network (CNN) were the most utilized algorithms. ANN achieved a 96% accuracy in facial plastic surgery wound management. CNN demonstrated commendable accuracies in various surgeries, and SVM exhibited high accuracy in multiple surgeries and burn plastic surgery. In sum, these findings underscore ML's potential for significant improvements in postoperative management and the development of enhanced care techniques, particularly in surgical wound management.","['Support Vector Machine (SVM)', 'Convolutional Neural Network (CNN)', 'Artificial Neural Network (ANN)']"
2024,https://openalex.org/W4400617823,Social Sciences,Wind farm site selection using geographic information system and fuzzy decision making model,"As the demand for renewable energy sources increases, finding the right places to install wind turbines becomes more and more important. The goal of this research is to create and implement a technique that uses geographic information system (GIS) technology to discover appropriate wind farm locations utilizing multi-criteria decision-making (MCDM) approaches. The complexity of this decision-making process, which includes multiple criteria and uncertainty, requires the use of advanced techniques. Fuzzy MCDM methods provide a framework for evaluating and prioritizing potential wind farm sites, taking into account subjective judgments and linguistic terms. In this article, Fuzzy Stepwise Weight Evaluation Ratio Analysis (F-SWARA) is preferred for prioritizing and ranking the criteria in the wind farm installation, while Fuzzy Measurement Alternatives and Ranking by Compromise Solution (F-MARCOS) are used to determine the most suitable location for the wind farm. A database of alternatives and criteria was created using GIS, which was converted into a fuzzy decision matrix via triangular fuzzy numbers. In order to make this evaluation, Sivas province, located in the middle of Turkey, was chosen as the study area. Results obtained show that 36,5% of the whole study area is very suitable for wind farm, and Gürün and Kangal districts are suitable for wind farm. According to the result of F-SWARA method used to evaluate the criteria, wind speed is the most important criteria with a weight of 0,45039. According to the F-MARCOS method used for wind farm site selection, Ulaş district was determined the most suitable location. Furthermore, a sensitivity analysis was performed to test the robustness of the proposed methodology and the results revealed that the proposed integrated MCDM framework is feasible.","['Fuzzy Stepwise Weight Evaluation Ratio Analysis (F-SWARA)', 'Fuzzy Measurement Alternatives and Ranking by Compromise Solution (F-MARCOS)']"
2024,https://openalex.org/W4401487891,Social Sciences,CARLA: Self-supervised contrastive representation learning for time series anomaly detection,"One main challenge in time series anomaly detection (TSAD) is the lack of labelled data in many real-life scenarios. Most of the existing anomaly detection methods focus on learning the normal behaviour of unlabelled time series in an unsupervised manner. The normal boundary is often defined tightly, resulting in slight deviations being classified as anomalies, consequently leading to a high false positive rate and a limited ability to generalise normal patterns. To address this, we introduce a novel end-to-end self-supervised ContrAstive Representation Learning approach for time series Anomaly detection (CARLA). While existing contrastive learning methods assume that augmented time series windows are positive samples and temporally distant windows are negative samples, we argue that these assumptions are limited as augmentation of time series can transform them to negative samples, and a temporally distant window can represent a positive sample. Existing approaches to contrastive learning for time series have directly copied methods developed for image analysis. We argue that these methods do not transfer well. Instead, our contrastive approach leverages existing generic knowledge about time series anomalies and injects various types of anomalies as negative samples. Therefore, CARLA not only learns normal behaviour but also learns deviations indicating anomalies. It creates similar representations for temporally close windows and distinct ones for anomalies. Additionally, it leverages the information about representations' neighbours through a self-supervised approach to classify windows based on their nearest/furthest neighbours to further enhance the performance of anomaly detection. In extensive tests on seven major real-world TSAD datasets, CARLA shows superior performance (F1 and AU-PR) over state-of-the-art self-supervised, semi-supervised, and unsupervised TSAD methods for univariate time series and multivariate time series. Our research highlights the immense potential of contrastive representation learning in advancing the TSAD field, thus paving the way for novel applications and in-depth exploration.","['self-supervised ContrAstive Representation Learning', 'contrastive learning', 'self-supervised approach', 'semi-supervised methods', 'unsupervised methods']"
2024,https://openalex.org/W4391097175,Social Sciences,Toward Improving Breast Cancer Classification Using an Adaptive Voting Ensemble Learning Algorithm,"Over the past decade, breast cancer has been the most common type of cancer in women. Different methods were proposed for breast cancer detection. These methods mainly classify and categorize malignant and Benign tumors. Machine learning is a practical approach for breast cancer classification. Data mining and classification are effective methods to predict and categorize breast cancer. The optimum classification for detecting Breast Cancer (BC) is ensemble-based. The ensemble approach involves using multiple ways to find the best possible solution. This study used the Wisconsin Breast Cancer Diagnostic (WBCD) dataset. We created a voting ensemble classifier that combines four different machine learning models: Extra Trees Classifier (ETC), Light Gradient Boosting Machine (LightGBM), Ridge Classifier (RC), and Linear Discriminant Analysis (LDA). The proposed ELRL-E approach achieved an accuracy of 97.6%, a precision of 96.4%, a recall of 100%, and an F1 score of 98.1%. Various output evaluations are used to evaluate the performance and efficiency of the proposed model and other classifiers. Overall, the recommended strategy performed better. Results are directly compared with the individual classifier and different recognized state-of-the-art classifiers. The primary objective of this study is to identify the most influential ensemble machine learning classifier for breast cancer detection and diagnosis in terms of accuracy and AUC score.","['Machine learning', 'ensemble-based classification', 'voting ensemble classifier', 'Extra Trees Classifier (ETC)', 'Light Gradient Boosting Machine (LightGBM)', 'Ridge Classifier (RC)', 'Linear Discriminant Analysis (LDA)']"
2024,https://openalex.org/W4396767636,Social Sciences,From explainable to interpretable deep learning for natural language processing in healthcare: How far from reality?,"Deep learning (DL) has substantially enhanced natural language processing (NLP) in healthcare research. However, the increasing complexity of DL-based NLP necessitates transparent model interpretability, or at least explainability, for reliable decision-making. This work presents a thorough scoping review of explainable and interpretable DL in healthcare NLP. The term ""eXplainable and Interpretable Artificial Intelligence"" (XIAI) is introduced to distinguish XAI from IAI. Different models are further categorized based on their functionality (model-, input-, output-based) and scope (local, global). Our analysis shows that attention mechanisms are the most prevalent emerging IAI technique. The use of IAI is growing, distinguishing it from XAI. The major challenges identified are that most XIAI does not explore ""global"" modelling processes, the lack of best practices, and the lack of systematic evaluation and benchmarks. One important opportunity is to use attention mechanisms to enhance multi-modal XIAI for personalized medicine. Additionally, combining DL with causal logic holds promise. Our discussion encourages the integration of XIAI in Large Language Models (LLMs) and domain-specific smaller models. In conclusion, XIAI adoption in healthcare requires dedicated in-house expertise. Collaboration with domain experts, end-users, and policymakers can lead to ready-to-use XIAI methods across NLP and medical tasks. While challenges exist, XIAI techniques offer a valuable foundation for interpretable NLP algorithms in healthcare.","['deep learning (DL)', 'attention mechanisms']"
2024,https://openalex.org/W4400903160,Social Sciences,Deep Learning for Pneumonia Detection in Chest X-ray Images: A Comprehensive Survey,"This paper addresses the significant problem of identifying the relevant background and contextual literature related to deep learning (DL) as an evolving technology in order to provide a comprehensive analysis of the application of DL to the specific problem of pneumonia detection via chest X-ray (CXR) imaging, which is the most common and cost-effective imaging technique available worldwide for pneumonia diagnosis. This paper in particular addresses the key period associated with COVID-19, 2020–2023, to explain, analyze, and systematically evaluate the limitations of approaches and determine their relative levels of effectiveness. The context in which DL is applied as both an aid to and an automated substitute for existing expert radiography professionals, who often have limited availability, is elaborated in detail. The rationale for the undertaken research is provided, along with a justification of the resources adopted and their relevance. This explanatory text and the subsequent analyses are intended to provide sufficient detail of the problem being addressed, existing solutions, and the limitations of these, ranging in detail from the specific to the more general. Indeed, our analysis and evaluation agree with the generally held view that the use of transformers, specifically, vision transformers (ViTs), is the most promising technique for obtaining further effective results in the area of pneumonia detection using CXR images. However, ViTs require extensive further research to address several limitations, specifically the following: biased CXR datasets, data and code availability, the ease with which a model can be explained, systematic methods of accurate model comparison, the notion of class imbalance in CXR datasets, and the possibility of adversarial attacks, the latter of which remains an area of fundamental research.","['deep learning (DL)', 'transformers', 'vision transformers (ViTs)']"
2024,https://openalex.org/W4390659208,Social Sciences,GraphCL-DTA: A Graph Contrastive Learning With Molecular Semantics for Drug-Target Binding Affinity Prediction,"Drug-target binding affinity prediction plays an important role in the early stages of drug discovery, which can infer the strength of interactions between new drugs and new targets. However, the performance of previous computational models is limited by the following drawbacks. The learning of drug representation relies only on supervised data without considering the information in the molecular graph itself. Moreover, most previous studies tended to design complicated representation learning modules, while uniformity used to measure representation quality is ignored. In this study, we propose GraphCL-DTA, a graph contrastive learning with molecular semantics for drug-target binding affinity prediction. This graph contrastive learning framework replaces the dropout-based data augmentation strategy by performing data augmentation in the embedding space, thereby better preserving the semantic information of the molecular graph. A more essential and effective drug representation can be learned through this graph contrastive framework without additional supervised data. Next, we design a new loss function that can be directly used to adjust the uniformity of drug and target representations. By directly optimizing the uniformity of representations, the representation quality of drugs and targets can be improved. The effectiveness of the above innovative elements is verified on two real datasets, KIBA and Davis. Compared with the GraphDTA model, the relative improvement of the GraphCL-DTA model on the two datasets is 2.7% and 4.5%. The graph contrastive learning framework and uniformity function in the GraphCL-DTA model can be embedded into other computational models as independent modules to improve their generalization capability.","['graph contrastive learning', 'data augmentation in the embedding space']"
2024,https://openalex.org/W4390738651,Social Sciences,Enhancing Multi-UAV Reconnaissance and Search Through Double Critic DDPG With Belief Probability Maps,"Unmanned Aerial Vehicles (UAVs) have recently attracted significant attention due to their potential applications in reconnaissance and search. This paper aims to investigate the issue of multi-UAV cooperative reconnaissance and search (MCRS) to ensure ample coverage of the mission area and precise localization of static targets. The MCRS problem is modeled as a multi-objective optimization problem, taking into account the credibility of search results. To achieve this, we design a belief probability map based on the Dempster-Shafer (DS) evidence theory, comprising an uncertainty map and two target maps. This representation enables a clear depiction of both the presence of the target and the uncertainty within the map. Subsequently, we reformulate this multi-objective optimization problem within the framework of Decentralized Partially Observable Markov Decision Process (Dec-POMDP). To address this reformulation, a new deep reinforcement learning approach called Double Critic Deep Deterministic Policy Gradient (DCDDPG) is proposed. Specifically, we introduce both a centralized critic and a local critic for each UAV agent to estimate the action-value function. This approach helps balance the bias in the action-value function estimation and the variance in the policy updates, thereby improving the coordination effect. Extensive simulation results demonstrate that DCDDPG outperforms existing techniques in terms of search efficiency and coverage.",['Decentralized Partially Observable Markov Decision Process (Dec-POMDP)']
2024,https://openalex.org/W4390825338,Social Sciences,PEGA: A Privacy-Preserving Genetic Algorithm for Combinatorial Optimization,"Evolutionary algorithms (EAs), such as the genetic algorithm (GA), offer an elegant way to handle combinatorial optimization problems (COPs). However, limited by expertise and resources, most users lack the capability to implement EAs for solving COPs. An intuitive and promising solution is to outsource evolutionary operations to a cloud server, however, it poses privacy concerns. To this end, this article proposes a novel computing paradigm called evolutionary computation as a service (ECaaS), where a cloud server renders evolutionary computation services for users while ensuring their privacy. Following the concept of ECaaS, this article presents privacy-preserving genetic algorithm (PEGA), a privacy-preserving GA designed specifically for COPs. PEGA enables users, regardless of their domain expertise or resource availability, to outsource COPs to the cloud server that holds a competitive GA and approximates the optimal solution while safeguarding privacy. Notably, PEGA features the following characteristics. First, PEGA empowers users without domain expertise or sufficient resources to solve COPs effectively. Second, PEGA protects the privacy of users by preventing the leakage of optimization problem details. Third, PEGA performs comparably to the conventional GA when approximating the optimal solution. To realize its functionality, we implement PEGA falling in a twin-server architecture and evaluate it on two widely known COPs: 1) the traveling Salesman problem (TSP) and 2) the 0/1 knapsack problem (KP). Particularly, we utilize encryption cryptography to protect users' privacy and carefully design a suite of secure computing protocols to support evolutionary operators of GA on encrypted chromosomes. Privacy analysis demonstrates that PEGA successfully preserves the confidentiality of COP contents. Experimental evaluation results on several TSP datasets and KP datasets reveal that PEGA performs equivalently to the conventional GA in approximating the optimal solution.","['evolutionary algorithms (EAs)', 'genetic algorithm (GA)']"
2024,https://openalex.org/W4391430106,Social Sciences,A soft voting ensemble learning approach for credit card fraud detection,"With the advancement of e-commerce and modern technological development, credit cards are widely used for both online and offline purchases, which has increased the number of daily fraudulent transactions. Many organizations and financial institutions worldwide lose billions of dollars annually because of credit card fraud. Due to the global distribution of both legitimate and fraudulent transactions, it is difficult to discern between the two. Furthermore, because only a small proportion of transactions are fraudulent, there is a problem of class imbalance. Hence, an effective fraud-detection methodology is required to sustain the reliability of the payment system. Machine learning has recently emerged as a viable substitute for identifying this type of fraud. However, ML approaches have difficulty identifying fraud with high prediction accuracy, while also decreasing misclassification costs due to the size of the imbalanced data. In this research, a soft voting ensemble learning approach for detecting credit card fraud on imbalanced data is proposed. To do this, the proposed approach is evaluated and compared with numerous sophisticated sampling techniques (i.e., oversampling, undersampling, and hybrid sampling) to overcome the class imbalance problem. We develop several credit card fraud classifiers, including ensemble classifiers, with and without sampling techniques. According to the experimental results, the proposed soft-voting approach outperforms individual classifiers. With a false negative rate (FNR) of 0.0306, it achieves a precision of 0.9870, recall of 0.9694, f1-score of 0.8764, and AUROC of 0.9936.","['soft voting ensemble learning', 'undersampling', 'ensemble classifiers']"
2024,https://openalex.org/W4392245149,Social Sciences,Towards development of functional climate-driven early warning systems for climate-sensitive infectious diseases: Statistical models and recommendations,"Climate, weather and environmental change have significantly influenced patterns of infectious disease transmission, necessitating the development of early warning systems to anticipate potential impacts and respond in a timely and effective way. Statistical modelling plays a pivotal role in understanding the intricate relationships between climatic factors and infectious disease transmission. For example, time series regression modelling and spatial cluster analysis have been employed to identify risk factors and predict spatial and temporal patterns of infectious diseases. Recently advanced spatio-temporal models and machine learning offer an increasingly robust framework for modelling uncertainty, which is essential in climate-driven disease surveillance due to the dynamic and multifaceted nature of the data. Moreover, Artificial Intelligence (AI) techniques, including deep learning and neural networks, excel in capturing intricate patterns and hidden relationships within climate and environmental data sets. Web-based data has emerged as a powerful complement to other datasets encompassing climate variables and disease occurrences. However, given the complexity and non-linearity of climate-disease interactions, advanced techniques are required to integrate and analyse these diverse data to obtain more accurate predictions of impending outbreaks, epidemics or pandemics. This article presents an overview of an approach to creating climate-driven early warning systems with a focus on statistical model suitability and selection, along with recommendations for utilizing spatio-temporal and machine learning techniques. By addressing the limitations and embracing the recommendations for future research, we could enhance preparedness and response strategies, ultimately contributing to the safeguarding of public health in the face of evolving climate challenges.","['spatio-temporal models', 'machine learning', 'deep learning', 'neural networks']"
2024,https://openalex.org/W4392791479,Social Sciences,Health equity assessment of machine learning performance (HEAL): a framework and dermatology AI model case study,"BackgroundArtificial intelligence (AI) has repeatedly been shown to encode historical inequities in healthcare. We aimed to develop a framework to quantitatively assess the performance equity of health AI technologies and to illustrate its utility via a case study.MethodsHere, we propose a methodology to assess whether health AI technologies prioritise performance for patient populations experiencing worse outcomes, that is complementary to existing fairness metrics. We developed the Health Equity Assessment of machine Learning performance (HEAL) framework designed to quantitatively assess the performance equity of health AI technologies via a four-step interdisciplinary process to understand and quantify domain-specific criteria, and the resulting HEAL metric. As an illustrative case study (analysis conducted between October 2022 and January 2023), we applied the HEAL framework to a dermatology AI model. A set of 5420 teledermatology cases (store-and-forward cases from patients of 20 years or older, submitted from primary care providers in the USA and skin cancer clinics in Australia), enriched for diversity in age, sex and race/ethnicity, was used to retrospectively evaluate the AI model's HEAL metric, defined as the likelihood that the AI model performs better for subpopulations with worse average health outcomes as compared to others. The likelihood that AI performance was anticorrelated to pre-existing health outcomes was estimated using bootstrap methods as the probability that the negated Spearman's rank correlation coefficient (i.e., ""R"") was greater than zero. Positive values of R suggest that subpopulations with poorer health outcomes have better AI model performance. Thus, the HEAL metric, defined as p (R >0), measures how likely the AI technology is to prioritise performance for subpopulations with worse average health outcomes as compared to others (presented as a percentage below). Health outcomes were quantified as disability-adjusted life years (DALYs) when grouping by sex and age, and years of life lost (YLLs) when grouping by race/ethnicity. AI performance was measured as top-3 agreement with the reference diagnosis from a panel of 3 dermatologists per case.FindingsAcross all dermatologic conditions, the HEAL metric was 80.5% for prioritizing AI performance of racial/ethnic subpopulations based on YLLs, and 92.1% and 0.0% respectively for prioritizing AI performance of sex and age subpopulations based on DALYs. Certain dermatologic conditions were significantly associated with greater AI model performance compared to a reference category of less common conditions. For skin cancer conditions, the HEAL metric was 73.8% for prioritizing AI performance of age subpopulations based on DALYs.InterpretationAnalysis using the proposed HEAL framework showed that the dermatology AI model prioritised performance for race/ethnicity, sex (all conditions) and age (cancer conditions) subpopulations with respect to pre-existing health disparities. More work is needed to investigate ways of promoting equitable AI performance across age for non-cancer conditions and to better understand how AI models can contribute towards improving equity in health outcomes.FundingGoogle LLC.",['bootstrap methods']
2024,https://openalex.org/W4392960540,Social Sciences,A sentiment analysis approach for understanding users’ perception of metaverse marketplace,"This research explores the user perceptions of the Metaverse Marketplace, analyzing a substantial dataset of over 860,000 Twitter posts through sentiment analysis and topic modeling techniques. The study aims to uncover the driving factors behind user engagement and sentiment in this novel digital trading space. Key findings highlight a predominantly positive user sentiment, with significant enthusiasm for the marketplace's revenue generation and entertainment potential, particularly within the gaming sector. Users express appreciation for the innovative opportunities the Metaverse Marketplace offers for artists, designers, and traders in handling and trading digital assets. This positive outlook is tempered by notable concerns regarding security and privacy within the Metaverse, pointing to a critical area for development and assurance. The study also reveals a substantial neutral sentiment, reflecting users' cautious but interested stance, particularly regarding the marketplace's role in investment and passive income opportunities. This balanced view underscores the evolving nature of user perceptions in this emerging field. Theoretically, the research enriches the discourse on technology adoption, particularly in virtual environments, by highlighting perceived benefits and enjoyment as significant adoption drivers. These insights are invaluable for stakeholders in the Metaverse Marketplace, guiding the development of more secure, engaging, and user-friendly platforms. While providing a pioneering perspective on Metaverse user perceptions, the study acknowledges its limitation to Twitter data, suggesting the need for broader research methodologies for a more holistic understanding.",['topic modeling']
2024,https://openalex.org/W4392979783,Social Sciences,BEVSOC: Self-Supervised Contrastive Learning for Calibration-Free BEV 3-D Object Detection,"3D object detection based on multi-view cameras and bird's-eye view (BEV) representation is a key task for autonomous driving, as it enables the perception systems to understand the surrounding scenes. However, most existing BEV representation methods rely on the projection matrix of camera intrinsic and extrinsic parameters, which requires a complex and time-consuming calibration process that may introduce errors and degrade the detection performance. Moreover, the calibration results may vary due to environmental changes and affect the stability of the detection system. To address this problem, we propose a calibration-free 3D object detection method that leverages a group-equivariant convolutional network to extract features from multi-view images and a projection network module to learn the implicit 3D-to-2D projection relationship for obtaining BEV representation. Furthermore, we employ contrastive learning to pre-train the projection network module without using manually annotated data. By exploiting the multi-view camera data through contrastive learning, our proposed method eliminates the need for tedious calibration, avoids calibration errors, and reduces the dependence on a large amount of annotated data for calibration-free 3D object detection. We evaluate our method on the nuScenes dataset and demonstrate its competitive performance. Our method improves the stability and reliability of 3D object detection in long-term autonomous driving.","['group-equivariant convolutional network', 'contrastive learning']"
2024,https://openalex.org/W4395110469,Social Sciences,ac4C-AFL: A high-precision identification of human mRNA N4-acetylcytidine sites based on adaptive feature representation learning,"RNA N4-acetylcytidine (ac4C) is a highly conserved RNA modification that plays a crucial role in controlling mRNA stability, processing, and translation. Consequently, accurate identification of ac4C sites across the genome is critical for understanding gene expression regulation mechanisms. In this study, we have developed ac4C-AFL, a bioinformatics tool that precisely identifies ac4C sites from primary RNA sequences. In ac4C-AFL, we identified the optimal sequence length for model building and implemented an adaptive feature representation strategy that is capable of extracting the most representative features from RNA. To identify the most relevant features, we proposed a novel ensemble feature importance scoring strategy to rank features effectively. We then used this information to conduct the sequential forward search, which individually determine the optimal feature set from the 16 sequence-derived feature descriptors. Utilizing these optimal feature descriptors, we constructed 176 baseline models using 11 popular classifiers. The most efficient baseline models were identified using the two-step feature selection approach, whose predicted scores were integrated and trained with the appropriate classifier to develop the final prediction model. Our rigorous cross-validations and independent tests demonstrate that ac4C-AFL surpasses contemporary tools in predicting ac4C sites. Moreover, we have developed a publicly accessible web server at https://balalab-skku.org/ac4C-AFL/.",['sequential forward search']
2024,https://openalex.org/W4396919944,Social Sciences,CrossHAR: Generalizing Cross-dataset Human Activity Recognition via Hierarchical Self-Supervised Pretraining,"The increasing availability of low-cost wearable devices and smartphones has significantly advanced the field of sensor-based human activity recognition (HAR), attracting considerable research interest. One of the major challenges in HAR is the domain shift problem in cross-dataset activity recognition, which occurs due to variations in users, device types, and sensor placements between the source dataset and the target dataset. Although domain adaptation methods have shown promise, they typically require access to the target dataset during the training process, which might not be practical in some scenarios. To address these issues, we introduce CrossHAR, a new HAR model designed to improve model performance on unseen target datasets. CrossHAR involves three main steps: (i) CrossHAR explores the sensor data generation principle to diversify the data distribution and augment the raw sensor data. (ii) CrossHAR then employs a hierarchical self-supervised pretraining approach with the augmented data to develop a generalizable representation. (iii) Finally, CrossHAR fine-tunes the pretrained model with a small set of labeled data in the source dataset, enhancing its performance in cross-dataset HAR. Our extensive experiments across multiple real-world HAR datasets demonstrate that CrossHAR outperforms current state-of-the-art methods by 10.83% in accuracy, demonstrating its effectiveness in generalizing to unseen target datasets.","['domain adaptation methods', 'fine-tuning']"
2024,https://openalex.org/W4398257517,Social Sciences,Transferable deep generative modeling of intrinsically disordered protein conformations,"Intrinsically disordered proteins have dynamic structures through which they play key biological roles. The elucidation of their conformational ensembles is a challenging problem requiring an integrated use of computational and experimental methods. Molecular simulations are a valuable computational strategy for constructing structural ensembles of disordered proteins but are highly resource-intensive. Recently, machine learning approaches based on deep generative models that learn from simulation data have emerged as an efficient alternative for generating structural ensembles. However, such methods currently suffer from limited transferability when modeling sequences and conformations absent in the training data. Here, we develop a novel generative model that achieves high levels of transferability for intrinsically disordered protein ensembles. The approach, named idpSAM, is a latent diffusion model based on transformer neural networks. It combines an autoencoder to learn a representation of protein geometry and a diffusion model to sample novel conformations in the encoded space. IdpSAM was trained on a large dataset of simulations of disordered protein regions performed with the ABSINTH implicit solvent model. Thanks to the expressiveness of its neural networks and its training stability, idpSAM faithfully captures 3D structural ensembles of test sequences with no similarity in the training set. Our study also demonstrates the potential for generating full conformational ensembles from datasets with limited sampling and underscores the importance of training set size for generalization. We believe that idpSAM represents a significant progress in transferable protein ensemble modeling through machine learning.","['deep generative models', 'latent diffusion model', 'transformer neural networks', 'autoencoder', 'diffusion model']"
2024,https://openalex.org/W4390496539,Social Sciences,A machine learning-based classification model to support university students with dyslexia with personalized tools and strategies,"Abstract Dyslexia is a specific learning disorder that causes issues related to reading, which affects around 10% of the worldwide population. This can compromise comprehension and memorization skills, and result in anxiety and lack of self-esteem, if no support is provided. Moreover, this support should be highly personalized, to be actually helpful. In this paper, a model to classify the most useful methodologies to support students with dyslexia has been created, with a focus on university alumni. The prediction algorithm is based on supervised machine learning techniques; starting from the issues that dyslexic students experience during their career, it is capable of suggesting customized support digital tools and learning strategies for each of them. The algorithm was trained and tested on data acquired through a self-evaluation questionnaire, which was designed and then spread to more than 1200 university students. It allowed 17 useful tools and 22 useful strategies to be detected. The results of the testing showed an average prediction accuracy higher than 90%, which rises to 94% by renouncing to guess the less-predictable 8 tools/strategies. In the light of this, it is possible to state that the implemented algorithm can achieve the set goal and, thus, reduce the gap between dyslexic and non-dyslexic students. This achievement paves the way for a new modality of facing the problem of dyslexia by university institutions, which aims at modifying teaching activities toward students’ needs, instead of simply reducing their study load or duties. This complies with the definition and the aims of inclusivity.",['supervised machine learning techniques']
2024,https://openalex.org/W4391131339,Social Sciences,Supervised Machine Learning Approaches for Predicting Key Pollutants and for the Sustainable Enhancement of Urban Air Quality: A Systematic Review,"Urban air pollution is a pressing global issue driven by factors such as swift urbanization, population expansion, and heightened industrial activities. To address this challenge, the integration of Machine Learning (ML) into smart cities presents a promising avenue. Our article offers comprehensive insights into recent advancements in air quality research, employing the PRISMA method as a cornerstone for the reviewing process, while simultaneously exploring the application of frequently employed ML methodologies. Focusing on supervised learning algorithms, the study meticulously analyzes air quality data, elucidating their unique benefits and challenges. These frequently employed ML techniques, including LSTM (Long Short-Term Memory), RF (Random Forest), ANN (Artificial Neural Networks), and SVR (Support Vector Regression), are instrumental in our quest for cleaner, healthier urban environments. By accurately predicting key pollutants such as particulate matter (PM), nitrogen oxides (NOx), carbon monoxide (CO), and ozone (O3), these methods offer tangible solutions for society. They enable informed decision-making for urban planners and policymakers, leading to proactive, sustainable strategies to combat urban air pollution. As a result, the well-being and health of urban populations are significantly improved. In this revised abstract, the importance of frequently employed ML methods in the context of air quality is explicitly emphasized, underlining their role in improving urban environments and enhancing the well-being of urban populations.","['LSTM (Long Short-Term Memory)', 'RF (Random Forest)', 'ANN (Artificial Neural Networks)', 'SVR (Support Vector Regression)']"
2024,https://openalex.org/W4391255815,Social Sciences,"Real Estate Industry Sustainable Solution (Environmental, Social, and Governance) Significance Assessment—AI-Powered Algorithm Implementation","As the global imperative for sustainable development intensifies, the real estate industry stands at the intersection of environmental responsibility and economic viability. This paper presents a comprehensive exploration of the significance of sustainable solutions within the real estate sector, employing advanced artificial intelligence (AI) algorithms to assess their impact. This study focuses on the integration of AI-powered tools in a decision-making process analysis. The research methodology involves the development and implementation of AI algorithms capable of analyzing vast datasets related to real estate attributes. By leveraging machine learning techniques, the algorithm assesses the significance of energy efficiency solutions along with other intrinsic and extrinsic attributes. This paper examines the effectiveness of these solutions in relation to the influence on property prices with a framework based on an AI-driven algorithm. The findings aim to inform real estate professionals and investors about the tangible advantages of integrating AI technologies into sustainable solutions, promoting a more informed and responsible approach to industry practices. This research contributes to the growing interest in the connection of the real estate sector, sustainability, and AI, offering insights that can guide strategic decision making. By implementing the random forest method in the real estate feature significance assessment original methodology, it has been shown that AI-powered algorithms can be a useful tool from the perspective of real estate price prediction. The methodology’s ability to handle non-linear relationships and provide insights into feature importance proved advantageous in comparison to the multiple regression analysis.",['random forest method']
2024,https://openalex.org/W4391853581,Social Sciences,A Survey on Information Bottleneck,"This survey is for the remembrance of one of the creators of the information bottleneck theory, Prof. Naftali Tishby, passing away at the age of 68 on August, 2021. Information bottleneck (IB), a novel information theoretic approach for pattern analysis and representation learning, has gained widespread popularity since its birth in 1999. It provides an elegant balance between data compression and information preservation, and improves its prediction or representation ability accordingly. This survey summarizes both the theoretical progress and practical applications on IB over the past 20-plus years, where its basic theory, optimization, extensive models and task-oriented algorithms are systematically explored. Existing IB methods are roughly divided into two parts: traditional and deep IB, where the former contains the IBs optimized by traditional machine learning analysis techniques without involving any neural networks, and the latter includes the IBs involving the interpretation, optimization and improvement of deep neural works (DNNs). Specifically, based on the technique taxonomy, traditional IBs are further classified into three categories: Basic, Informative and Propagating IB; While the deep IBs, based on the taxonomy of problem settings, contain Debate: Understanding DNNs with IB, Optimizing DNNs Using IB, and DNN-based IB methods. Furthermore, some potential issues deserving future research are discussed. This survey attempts to draw a more complete picture of IB, from which the subsequent studies can benefit.",['Information bottleneck (IB)']
2024,https://openalex.org/W4392242086,Social Sciences,"Geographic and Demographic Differences in the Proportion of Individuals Living in Households With a Firearm, 1990-2018","Importance Measures of the proportion of individuals living in households with a firearm (HFR), over time, across states, and by demographic groups are needed to evaluate disparities in firearm violence and the effects of firearm policies. Objective To estimate HFR across states, years, and demographic groups in the US. Design, Setting, and Participants In this survey study, substate HFR totals from 1990 to 2018 were estimated using bayesian multilevel regression with poststratification to analyze survey data on HFR from the Behavioral Risk Factor Surveillance System and the General Social Survey. HFR was estimated for 16 substate demographic groups defined by gender, race, marital status, and urbanicity in each state and year. Exposures Survey responses indicating household firearm ownership were analyzed and compared with a common proxy for firearm ownership, the fraction of suicides completed with a firearm (FSS). Main Outcome and Measure HFR, FSS, and their correlations and differences. Results Among US adults in 2018, HFR was significantly higher among married, nonurban, non-Hispanic White and American Indian male individuals (65.0%; 95% credible interval [CI], 61.5%-68.7%) compared with their unmarried, urban, female counterparts from other racial and ethnic groups (7.3%; 95% CIs, 6.0%-9.2%). Marginal HFR rates for larger demographic groups also revealed important differences, with racial minority groups and urban dwellers having less than half the HFR of either White and American Indian (39.5%; 95% CI, 37.4%-42.9% vs 17.2%; 95% CI, 15.5%-19.9%) or nonurban populations (46.0%; 95% CI, 43.8%-49.5% vs 23.1%; 95% CI, 21.3%-26.2%). Population growth among groups less likely to own firearms, rather than changes in ownership within demographic groups, explains 30% of the 7 percentage point decline in HFR nationally from 1990 to 2018. Comparing HFR estimates with FSS revealed the expected high overall correlation across states (r = 0.84), but scaled FSS differed from HFR by as many as 20 percentage points for some states and demographic groups. Conclusions and Relevance This survey study of HFR providing detailed, publicly available HFR estimates highlights key disparities among individuals in households with firearms across states and demographic groups; it also identifies potential biases in the use of FSS as a proxy for firearm ownership rates. These findings are essential for researchers, policymakers, and public health experts looking to address geographic and demographic disparities in firearm violence.",['bayesian multilevel regression with poststratification']
2024,https://openalex.org/W4392449656,Social Sciences,Augmenting Reinforcement Learning With Transformer-Based Scene Representation Learning for Decision-Making of Autonomous Driving,"Decision-making for urban autonomous driving is challenging due to the stochastic nature of interactive traffic participants and the complexity of road structures. Although reinforcement learning (RL)-based decision-making schemes are promising to handle urban driving scenarios, they suffer from low sample efficiency and poor adaptability. In this paper, we propose the Scene-Rep Transformer to enhance RL decision-making capabilities through improved scene representation encoding and sequential predictive latent distillation. Specifically, a multi-stage Transformer (MST) encoder is constructed to model not only the interaction awareness between the ego vehicle and its neighbors but also intention awareness between the agents and their candidate routes. A sequential latent Transformer (SLT) with self-supervised learning objectives is employed to distill future predictive information into the latent scene representation, in order to reduce the exploration space and speed up training. The final decision-making module based on soft actor-critic (SAC) takes as input the refined latent scene representation from the Scene-Rep Transformer and generates decisions. The framework is validated in five challenging simulated urban scenarios with dense traffic, and its performance is manifested quantitatively by substantial improvements in data efficiency and performance in terms of success rate, safety, and efficiency. Qualitative results reveal that our framework is able to extract the intentions of neighbor agents, enabling better decision-making and more diversified driving behaviors.","['reinforcement learning (RL)', 'Transformer', 'self-supervised learning', 'soft actor-critic (SAC)']"
2024,https://openalex.org/W4392714571,Social Sciences,Machine learning study using 2020 SDHS data to determine poverty determinants in Somalia,"Abstract Extensive research has been conducted on poverty in developing countries using conventional regression analysis, which has limited prediction capability. This study aims to address this gap by applying advanced machine learning (ML) methods to predict poverty in Somalia. Utilizing data from the first-ever 2020 Somalia Demographic and Health Survey (SDHS), a cross-sectional study design is considered. ML methods, including random forest (RF), decision tree (DT), support vector machine (SVM), and logistic regression, are tested and applied using R software version 4.1.2, while conventional methods are analyzed using STATA version 17. Evaluation metrics, such as confusion matrix, accuracy, precision, sensitivity, specificity, recall, F1 score, and area under the receiver operating characteristic (AUROC), are employed to assess the performance of predictive models. The prevalence of poverty in Somalia is notable, with approximately seven out of ten Somalis living in poverty, making it one of the highest rates in the region. Among nomadic pastoralists, agro-pastoralists, and internally displaced persons (IDPs), the poverty average stands at 69%, while urban areas have a lower poverty rate of 60%. The accuracy of prediction ranged between 67.21% and 98.36% for the advanced ML methods, with the RF model demonstrating the best performance. The results reveal geographical region, household size, respondent age group, husband employment status, age of household head, and place of residence as the top six predictors of poverty in Somalia. The findings highlight the potential of ML methods to predict poverty and uncover hidden information that traditional statistical methods cannot detect, with the RF model identified as the best classifier for predicting poverty in Somalia.","['random forest (RF)', 'decision tree (DT)', 'support vector machine (SVM)', 'logistic regression']"
2024,https://openalex.org/W4393153153,Social Sciences,TimesURL: Self-Supervised Contrastive Learning for Universal Time Series Representation Learning,"Learning universal time series representations applicable to various types of downstream tasks is challenging but valuable in real applications. Recently, researchers have attempted to leverage the success of self-supervised contrastive learning (SSCL) in Computer Vision(CV) and Natural Language Processing(NLP) to tackle time series representation. Nevertheless, due to the special temporal characteristics, relying solely on empirical guidance from other domains may be ineffective for time series and difficult to adapt to multiple downstream tasks. To this end, we review three parts involved in SSCL including 1) designing augmentation methods for positive pairs, 2) constructing (hard) negative pairs, and 3) designing SSCL loss. For 1) and 2), we find that unsuitable positive and negative pair construction may introduce inappropriate inductive biases, which neither preserve temporal properties nor provide sufficient discriminative features. For 3), just exploring segment- or instance-level semantics information is not enough for learning universal representation. To remedy the above issues, we propose a novel self-supervised framework named TimesURL. Specifically, we first introduce a frequency-temporal-based augmentation to keep the temporal property unchanged. And then, we construct double Universums as a special kind of hard negative to guide better contrastive learning. Additionally, we introduce time reconstruction as a joint optimization objective with contrastive learning to capture both segment-level and instance-level information. As a result, TimesURL can learn high-quality universal representations and achieve state-of-the-art performance in 6 different downstream tasks, including short- and long-term forecasting, imputation, classification, anomaly detection and transfer learning.",['self-supervised contrastive learning (SSCL)']
2024,https://openalex.org/W4394749617,Social Sciences,MS-BACL: enhancing metabolic stability prediction through bond graph augmentation and contrastive learning,"Abstract Motivation Accurately predicting molecular metabolic stability is of great significance to drug research and development, ensuring drug safety and effectiveness. Existing deep learning methods, especially graph neural networks, can reveal the molecular structure of drugs and thus efficiently predict the metabolic stability of molecules. However, most of these methods focus on the message passing between adjacent atoms in the molecular graph, ignoring the relationship between bonds. This makes it difficult for these methods to estimate accurate molecular representations, thereby being limited in molecular metabolic stability prediction tasks. Results We propose the MS-BACL model based on bond graph augmentation technology and contrastive learning strategy, which can efficiently and reliably predict the metabolic stability of molecules. To our knowledge, this is the first time that bond-to-bond relationships in molecular graph structures have been considered in the task of metabolic stability prediction. We build a bond graph based on ‘atom-bond-atom’, and the model can simultaneously capture the information of atoms and bonds during the message propagation process. This enhances the model’s ability to reveal the internal structure of the molecule, thereby improving the structural representation of the molecule. Furthermore, we perform contrastive learning training based on the molecular graph and its bond graph to learn the final molecular representation. Multiple sets of experimental results on public datasets show that the proposed MS-BACL model outperforms the state-of-the-art model. Availability and Implementation The code and data are publicly available at https://github.com/taowang11/MS.","['deep learning', 'graph neural networks', 'contrastive learning strategy']"
2024,https://openalex.org/W4394893217,Social Sciences,"Advancements in machine visions for fruit sorting and grading: A bibliometric analysis, systematic review, and future research directions","This research conducted a bibliometric analysis of scholarly literature on fruit sorting and grading using machine vision, identifying primary themes, sources, most-cited publications, and countries. The literature and bibliometric analysis were thoroughly evaluated to consolidate knowledge, identify research trends, and propose specific research opportunities within the context of machine vision for fruit sorting and grading. Research articles from 2011 to 2023, indexed in the main collections of the Dimensions, Web-of-science, and Scopus databases, were examined. Findings were presented quantitatively, using tables and graphs to emphasize the key performance factors for article writing and citation. Upon applying inclusion and exclusion criteria, 129 out of 1,812 discovered articles were included for examination, while 1,683 studies were excluded due to non-compliance with the requirements and duplicates. Thirty-four (34) case study publications on machine vision applications for fruit sorting and grading were comprehensively examined to identify the adopted methodologies and future research opportunities. Covered methodologies include fruit varieties, data volumes, data collection, classification methods, and accuracy metrics. The study's findings indicate a significant increase in deep learning applications for fruit recognition in the recent five years (2019-2023), with excellent results achieved either by utilizing new models or with pre-trained networks for transfer learning. The research also identifies gaps and future directions for machine vision in fruit sorting and grading, such as enhancing system robustness, scalability, and adaptability, integrating multiple sensors and technological methods, and developing evaluation and comparison standards and criteria. The paper concludes that machine vision holds promise as a potent tool for fruit quality assessment, but further research and development are needed to address existing challenges and meet the growing demands of the fruit industry.","['deep learning', 'pre-trained networks for transfer learning']"
2024,https://openalex.org/W4396240923,Social Sciences,Sequential predictive learning is a unifying theory for hippocampal representation and replay,"Abstract The mammalian hippocampus contains a cognitive map that represents an animal’s position in the environment 1 and generates offline “replay” 2,3 for the purposes of recall 4 , planning 5,6 , and forming long term memories 7 . Recently, it’s been found that artificial neural networks trained to predict sensory inputs develop spatially tuned cells 8 , aligning with predictive theories of hippocampal function 9–11 . However, whether predictive learning can also account for the ability to produce offline replay is unknown. Here, we find that spatially-tuned cells, which robustly emerge from all forms of predictive learning, do not guarantee the presence of a cognitive map with the ability to generate replay. Offline simulations only emerged in networks that used recurrent connections and head-direction information to predict multi-step observation sequences, which promoted the formation of a continuous attractor reflecting the geometry of the environment. These offline trajectories were able to show wake-like statistics, autonomously replay recently experienced locations, and could be directed by a virtual head direction signal. Further, we found that networks trained to make cyclical predictions of future observation sequences were able to rapidly learn a cognitive map and produced sweeping representations of future positions reminiscent of hippocampal theta sweeps 12 . These results demonstrate how hippocampal-like representation and replay can emerge in neural networks engaged in predictive learning, and suggest that hippocampal theta sequences reflect a circuit that implements a data-efficient algorithm for sequential predictive learning. Together, this framework provides a unifying theory for hippocampal functions and hippocampal-inspired approaches to artificial intelligence.","['artificial neural networks', 'recurrent connections']"
2024,https://openalex.org/W4399501912,Social Sciences,Combating the Challenges of False Positives in AI-Driven Anomaly Detection Systems and Enhancing Data Security in the Cloud,"Anomaly detection is critical for network security, fraud detection, and system health monitoring applications. Traditional methods like statistical approaches and distance-based techniques often struggle with high-dimensional and complex data, leading to high false positive rates. This study addresses the challenge by investigating advanced AI-driven techniques to reduce false positives and enhance data security within cloud computing environments. This study employs deep learning models, integrates contextual data, and incorporates comprehensive security measures to enhance anomaly detection performance. Data from synthetic sources, such as the NSL-KDD dataset and real-world cloud environments, were utilized to capture user behavior logs, system states, and network traffic. Over 50 academic journals were reviewed, and 21 were selected based on inclusion criteria, such as relevance to AI-driven anomaly detection, empirical performance metrics, and the focus on cloud environments, and exclusion criteria that filtered out studies lacking empirical data or not specific to cloud-based systems. Methodologically, the research involves a comparative analysis of different AI techniques and their impact on false positive rates, accuracy, precision, and recall. The findings demonstrate that deep learning techniques significantly outperform traditional methods, achieving a lower false positive rate and higher accuracy. The results underscore the importance of contextual data and robust security protocols in reliable anomaly detection. This research fills a gap by thoroughly evaluating advanced AI techniques for reducing false positives in cloud environments. The study's significance lies in guiding the development of more effective anomaly detection systems, thereby enhancing security and reliability across various applications. Additionally, organizations should invest in continuously developing and integrating AI-driven anomaly detection systems with comprehensive security measures to improve their effectiveness the study suggests that further study be conducted with large datasets to evaluate the effectiveness of Hybrid anomaly detection systems in detecting and addressing false positives.",['Hybrid anomaly detection systems']
2024,https://openalex.org/W4390905130,Social Sciences,Long-Term Preference Mining With Temporal and Spatial Fusion for Point-of-Interest Recommendation,"The growth of the tourism industry has greatly boosted the Point-of-Interest (POI) recommendation tasks using Location-based Social Networks (LBSNs). The ever-evolving nature of user preferences poses a major problem. To address this, we propose a Long-Term Preference Mining (LTPM) approach that utilizes the Temporal Recency (TR) measure in the visits along with the location-aware recommendation based on Spatial Proximity (SP) to the user's location. The temporal dynamics and changing preferences are exploited based on the modified Long Short-term Memory (LSTM) that utilizes the time decay. The spatial considerations are modeled in two aspects: geographical proximity based on enhanced representation learning using orthogonal mapping. Second, the Region-of-Interest (ROI) is based on spatial griding and metric learning to capture the spatial relationships between POIs to enhance the metric space representation. The final recommendations are based on a multi-head attention mechanism that allocates the weights to different features. The combination of three models, called, LTPM-TRSP approach captures the user-POI, POI-POI, and POI-time relationships by focusing on the informative representation of sequential and spatial data. The category-aware final recommendations based on comprehensive historical behavior and geographical context are quite efficacious. The experimentation on three real-world datasets, Gowalla, Foursquare, and Weeplaces, also suggests the potency compared to other state-of-the-art approaches.","['Long Short-term Memory (LSTM)', 'metric learning', 'multi-head attention mechanism']"
2024,https://openalex.org/W4391256320,Social Sciences,Gas adsorption meets deep learning: voxelizing the potential energy surface of metal-organic frameworks,"Abstract Intrinsic properties of metal-organic frameworks (MOFs), such as their ultra porosity and high surface area, deem them promising solutions for problems involving gas adsorption. Nevertheless, due to their combinatorial nature, a huge number of structures is feasible which renders cumbersome the selection of the best candidates with traditional techniques. Recently, machine learning approaches have emerged as efficient tools to deal with this challenge, by allowing researchers to rapidly screen large databases of MOFs via predictive models. The performance of the latter is tightly tied to the mathematical representation of a material, thus necessitating the use of informative descriptors. In this work, a generalized framework to predict gaseous adsorption properties is presented, using as one and only descriptor the capstone of chemical information: the potential energy surface (PES). In order to be machine understandable, the PES is voxelized and subsequently a 3D convolutional neural network (CNN) is exploited to process this 3D energy image. As a proof of concept, the proposed pipeline is applied on predicting $${\hbox {CO}_{2}}$$ <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""> <mml:msub> <mml:mtext>CO</mml:mtext> <mml:mn>2</mml:mn> </mml:msub> </mml:math> uptake in MOFs. The resulting model outperforms a conventional model built with geometric descriptors and requires two orders of magnitude less training data to reach a given level of performance. Moreover, the transferability of the approach to different host-guest systems is demonstrated, examining $${\hbox {CH}_4}$$ <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""> <mml:msub> <mml:mtext>CH</mml:mtext> <mml:mn>4</mml:mn> </mml:msub> </mml:math> uptake in COFs. The generic character of the proposed methodology, inherited from the PES, renders it applicable to fields other than reticular chemistry.",['3D convolutional neural network (CNN)']
2024,https://openalex.org/W4391013663,Social Sciences,Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model,"Recently the state space models (SSMs) with efficient hardware-aware designs, i.e., the Mamba deep learning model, have shown great potential for long sequence modeling. Meanwhile building efficient and generic vision backbones purely upon SSMs is an appealing direction. However, representing visual data is challenging for SSMs due to the position-sensitivity of visual data and the requirement of global context for visual understanding. In this paper, we show that the reliance on self-attention for visual representation learning is not necessary and propose a new generic vision backbone with bidirectional Mamba blocks (Vim), which marks the image sequences with position embeddings and compresses the visual representation with bidirectional state space models. On ImageNet classification, COCO object detection, and ADE20k semantic segmentation tasks, Vim achieves higher performance compared to well-established vision transformers like DeiT, while also demonstrating significantly improved computation & memory efficiency. For example, Vim is 2.8$\times$ faster than DeiT and saves 86.8% GPU memory when performing batch inference to extract features on images with a resolution of 1248$\times$1248. The results demonstrate that Vim is capable of overcoming the computation & memory constraints on performing Transformer-style understanding for high-resolution images and it has great potential to be the next-generation backbone for vision foundation models. Code is available at https://github.com/hustvl/Vim.","['state space models (SSMs)', 'vision transformers', 'DeiT']"
2024,https://openalex.org/W4392599656,Social Sciences,Generative AI in Medical Practice: In-Depth Exploration of Privacy and Security Challenges,"As advances in artificial intelligence (AI) continue to transform and revolutionize the field of medicine, understanding the potential uses of generative AI in health care becomes increasingly important. Generative AI, including models such as generative adversarial networks and large language models, shows promise in transforming medical diagnostics, research, treatment planning, and patient care. However, these data-intensive systems pose new threats to protected health information. This Viewpoint paper aims to explore various categories of generative AI in health care, including medical diagnostics, drug discovery, virtual health assistants, medical research, and clinical decision support, while identifying security and privacy threats within each phase of the life cycle of such systems (ie, data collection, model development, and implementation phases). The objectives of this study were to analyze the current state of generative AI in health care, identify opportunities and privacy and security challenges posed by integrating these technologies into existing health care infrastructure, and propose strategies for mitigating security and privacy risks. This study highlights the importance of addressing the security and privacy threats associated with generative AI in health care to ensure the safe and effective use of these systems. The findings of this study can inform the development of future generative AI systems in health care and help health care organizations better understand the potential benefits and risks associated with these systems. By examining the use cases and benefits of generative AI across diverse domains within health care, this paper contributes to theoretical discussions surrounding AI ethics, security vulnerabilities, and data privacy regulations. In addition, this study provides practical insights for stakeholders looking to adopt generative AI solutions within their organizations.",['generative adversarial networks']
2024,https://openalex.org/W4392014897,Social Sciences,Comprehensive systematic review of information fusion methods in smart cities and urban environments,"Smart cities result from integrating advanced technologies and intelligent sensors into modern urban infrastructure. The Internet of Things (IoT) and data integration are pivotal in creating interconnected and intelligent urban spaces. In this literature review, we explore the different methods of information fusion used in smart cities, along with their advantages and challenges. However, there are notable challenges in managing diverse data sources, handling large data volumes, and meeting the near-real-time demands of various smart city applications. The review aims to examine smart city applications in detail, incorporating quality evaluation and information fusion techniques and identifying critical issues while outlining promising research directions. In order to accomplish our goal, we conducted a comprehensive search of literature and applied selective criteria. We identified 59 recent studies addressing machine learning (ML) and deep learning (DL) techniques in smart city applications. These studies were obtained from various databases such as ScienceDirect (SD), Scopus, Web of Science (WoS), and IEEE Xplore. The main objective of this study is to provide more detailed insights into smart cities by supplementing existing research. The word cloud visualisation of machine learning/deep learning and information fusion in smart cities papers shows a diverse landscape, covering both technical aspects of artificial intelligence and practical applications in urban settings. Apart from technical exploration, the study also delves into the ethical and privacy implications arising in smart cities. Moreover, it thoroughly examines the challenges that must be addressed to realise this urban revolution's potential fully.","['machine learning (ML)', 'deep learning (DL)']"
2024,https://openalex.org/W4391243055,Social Sciences,Systematic literature review: Quantum machine learning and its applications,"Quantum physics has changed the way we understand our environment, and one of its branches, quantum mechanics, has demonstrated accurate and consistent theoretical results. Quantum computing is the process of performing calculations using quantum mechanics. This field studies the quantum behavior of certain subatomic particles (photons, electrons, etc.) for subsequent use in performing calculations, as well as for large-scale information processing. These advantages are achieved through the use of quantum features, such as entanglement or superposition. These capabilities can give quantum computers an advantage in terms of computational time and cost over classical computers. Nowadays, scientific challenges are impossible to perform by classical computation due to computational complexity (more bytes than atoms in the observable universe) or the time it would take (thousands of years), and quantum computation is the only known answer. However, current quantum devices do not have yet the necessary qubits and are not fault-tolerant enough to achieve these goals. Nonetheless, there are other fields like machine learning, finance, or chemistry where quantum computation could be useful with current quantum devices. This manuscript aims to present a review of the literature published between 2017 and 2023 to identify, analyze, and classify the different types of algorithms used in quantum machine learning and their applications. The methodology follows the guidelines related to Systematic Literature Review methods, such as the one proposed by Kitchenham and other authors in the software engineering field. Consequently, this study identified 94 articles that used quantum machine learning techniques and algorithms and shows their implementation using computational quantum circuits or ansatzs. The main types of found algorithms are quantum implementations of classical machine learning algorithms, such as support vector machines or the k-nearest neighbor model, and classical deep learning algorithms, like quantum neural networks. One of the most relevant applications in the machine learning field is image classification. Many articles, especially within the classification, try to solve problems currently answered by classical machine learning but using quantum devices and algorithms. Even though results are promising, quantum machine learning is far from achieving its full potential. An improvement in quantum hardware is required for this potential to be achieved since the existing quantum computers lack enough quality, speed, and scale to allow quantum computing to achieve its full potential.","['support vector machines', 'k-nearest neighbor model', 'quantum neural networks']"
2024,https://openalex.org/W4391974599,Social Sciences,"Generative AI for Transformative Healthcare: A Comprehensive Study of Emerging Models, Applications, Case Studies, and Limitations","Generative artificial intelligence (GAI) can be broadly described as an artificial intelligence system capable of generating images, text, and other media types with human prompts. GAI models like ChatGPT, DALL-E, and Bard have recently caught the attention of industry and academia equally. GAI applications span various industries like art, gaming, fashion, and healthcare. In healthcare, GAI shows promise in medical research, diagnosis, treatment, and patient care and is already making strides in real-world deployments. There has yet to be any detailed study concerning the applications and scope of GAI in healthcare. Addressing this research gap, we explore several applications, real-world scenarios, and limitations of GAI in healthcare. We examine how GAI models like ChatGPT and DALL-E can be leveraged to aid in the applications of medical imaging, drug discovery, personalized patient treatment, medical simulation and training, clinical trial optimization, mental health support, healthcare operations and research, medical chatbots, human movement simulation, and a few more applications. Along with applications, we cover four real-world healthcare scenarios that employ GAI: visual snow syndrome diagnosis, molecular drug optimization, medical education, and dentistry. We also provide an elaborate discussion on seven healthcare-customized LLMs like Med-PaLM, BioGPT, DeepHealth, etc.,Since GAI is still evolving, it poses challenges like the lack of professional expertise in decision making, risk of patient data privacy, issues in integrating with existing healthcare systems, and the problem of data bias which are elaborated on in this work along with several other challenges. We also put forward multiple directions for future research in GAI for healthcare.","['healthcare-customized LLMs like Med-PaLM', 'healthcare-customized LLMs like BioGPT']"
2024,https://openalex.org/W4392239564,Social Sciences,Human-AI collaboration patterns in AI-assisted academic writing,"Artificial Intelligence (AI) has increasingly influenced higher education, notably in academic writing where AI-powered assisting tools offer both opportunities and challenges. Recently, the rapid growth of generative AI (GAI) has brought its impacts into sharper focus, yet the dynamics of its utilisation in academic writing remain largely unexplored. This paper focuses on examining the nature of human-AI interactions in academic writing, specifically investigating the strategies doctoral students employ when collaborating with a GAI-powered assisting tool. This study involves 626 recorded activities on how ten doctoral students interact with GAI-powered assisting tool during academic writing. AI-driven learning analytics approach was adopted for three layered analyses: (1) data pre-processing and analysis with quantitative content analysis, (2) sequence analysis with Hidden Markov Model (HMM) and hierarchical sequence clustering, and (3) pattern analysis with process mining. Findings indicate that doctoral students engaging in iterative, highly interactive processes with the GAI-powered assisting tool generally achieve better performance in the writing task. In contrast, those who use GAI merely as a supplementary information source, maintaining a linear writing approach, tend to get lower writing performance. This study points to the need for further investigations into human-AI collaboration in learning in higher education, with implications for tailored educational strategies and solutions.",['Hidden Markov Model (HMM)']
2024,https://openalex.org/W4393072609,Social Sciences,"A comprehensive survey of research towards AI-enabled unmanned aerial systems in pre-, active-, and post-wildfire management","Wildfires have emerged as one of the most destructive natural disasters worldwide, causing catastrophic losses. These losses have underscored the urgent need to improve public knowledge and advance existing techniques in wildfire management. Recently, the use of Artificial Intelligence (AI) in wildfires, propelled by the integration of Unmanned Aerial Vehicles (UAVs) and deep learning models, has created an unprecedented momentum to implement and develop more effective wildfire management. Although existing survey papers have explored learning-based approaches in wildfire, drone use in disaster management, and wildfire risk assessment, a comprehensive review emphasizing the application of AI-enabled UAV systems and investigating the role of learning-based methods throughout the overall workflow of multi-stage wildfire management, including pre-fire (e.g., vision-based vegetation fuel measurement), active-fire (e.g., fire growth modeling), and post-fire tasks (e.g., evacuation planning) is notably lacking. This survey synthesizes and integrates state-of-the-science reviews and research at the nexus of wildfire observations and modeling, AI, and UAVs - topics at the forefront of advances in wildfire management, elucidating the role of AI in performing monitoring and actuation tasks from pre-fire, through the active-fire stage, to post-fire management. To this aim, we provide an extensive analysis of the existing remote sensing systems with a particular focus on the UAV advancements, device specifications, and sensor technologies relevant to wildfire management. We also examine the pre-fire and post-fire management approaches, including fuel monitoring, prevention strategies, as well as evacuation planning, damage assessment, and operation strategies. Additionally, we review and summarize a wide range of computer vision techniques in active-fire management, with an emphasis on Machine Learning (ML), Reinforcement Learning (RL), and Deep Learning (DL) algorithms for wildfire classification, segmentation, detection, and monitoring tasks. Ultimately, we underscore the substantial advancement in wildfire modeling through the integration of cutting-edge AI techniques and UAV-based data, providing novel insights and enhanced predictive capabilities to understand dynamic wildfire behavior.","['Machine Learning (ML)', 'Reinforcement Learning (RL)', 'Deep Learning (DL)']"
2024,https://openalex.org/W4394009485,Social Sciences,AI-Driven Clinical Decision Support Systems: An Ongoing Pursuit of Potential,"Clinical Decision Support Systems (CDSS) are essential tools in contemporary healthcare, enhancing clinicians' decisions and patient outcomes. The integration of artificial intelligence (AI) is now revolutionizing CDSS even further. This review delves into AI technologies transforming CDSS, their applications in healthcare decision-making, associated challenges, and the potential trajectory toward fully realizing AI-CDSS's potential. The review begins by laying the groundwork with a definition of CDSS and its function within the healthcare field. It then highlights the increasingly significant role that AI is playing in enhancing CDSS effectiveness and efficiency, underlining its evolving prominence in shaping healthcare practices. It examines the integration of AI technologies into CDSS, including machine learning algorithms like neural networks and decision trees, natural language processing, and deep learning. It also addresses the challenges associated with AI integration, such as interpretability and bias. We then shift to AI applications within CDSS, with real-life examples of AI-driven diagnostics, personalized treatment recommendations, risk prediction, early intervention, and AI-assisted clinical documentation. The review emphasizes user-centered design in AI-CDSS integration, addressing usability, trust, workflow, and ethical and legal considerations. It acknowledges prevailing obstacles and suggests strategies for successful AI-CDSS adoption, highlighting the need for workflow alignment and interdisciplinary collaboration. The review concludes by summarizing key findings, underscoring AI's transformative potential in CDSS, and advocating for continued research and innovation. It emphasizes the need for collaborative efforts to realize a future where AI-powered CDSS optimizes healthcare delivery and improves patient outcomes.","['neural networks', 'decision trees', 'deep learning']"
2024,https://openalex.org/W4400145965,Social Sciences,A systematic review of trustworthy artificial intelligence applications in natural disasters,"Artificial intelligence (AI) holds significant promise for advancing natural disaster management through the use of predictive models that analyze extensive datasets, identify patterns, and forecast potential disasters. These models facilitate proactive measures such as early warning systems (EWSs), evacuation planning, and resource allocation, addressing the substantial challenges associated with natural disasters. This study offers a comprehensive exploration of trustworthy AI applications in natural disasters, encompassing disaster management, risk assessment, and disaster prediction. This research is underpinned by an extensive review of reputable sources, including Science Direct (SD), Scopus, IEEE Xplore (IEEE), and Web of Science (WoS). Three queries were formulated to retrieve 981 papers from the earliest documented scientific production until February 2024. After meticulous screening, deduplication, and application of the inclusion and exclusion criteria, 108 studies were included in the quantitative synthesis. This study provides a specific taxonomy of AI applications in natural disasters and explores the motivations, challenges, recommendations, and limitations of recent advancements. It also offers an overview of recent techniques and developments in disaster management using explainable artificial intelligence (XAI), data fusion, data mining, machine learning (ML), deep learning (DL), fuzzy logic, and multicriteria decision-making (MCDM). This systematic contribution addresses seven open issues and provides critical solutions through essential insights, laying the groundwork for various future works in trustworthiness AI-based natural disaster management. Despite the potential benefits, challenges persist in the application of AI to natural disaster management. In these contexts, this study identifies several unused and used areas in natural disaster-based AI theory, collects the disaster datasets, ML, and DL techniques, and offers a valuable XAI approach to unravel the complex relationships and dynamics involved and the utilization of data fusion techniques in decision-making processes related to natural disasters. Finally, the study extensively analyzed ethical considerations, bias, and consequences in natural disaster-based AI.","['machine learning (ML)', 'deep learning (DL)']"
2024,https://openalex.org/W4390667862,Social Sciences,Integration of Generative AI Techniques and Applications in Student Behavior and Cognitive Achievement in Arab Higher Education,"The integration of Artificial Intelligence (AI) in higher education has the power to revolutionize the learning experience by fostering engagement, personalization, efficiency, and innovation. AI offers a wide range of exciting possibilities where AI-powered tools enable students to receive tailored feedback and guidance, enabling them to learn at their own pace and excel academically. This research aims to investigate the effects of generative AI techniques and applications on students' cognitive achievement through student behavior. Data was collected through surveys in three Arab countries including Oman, Jordan and Yemen. 768 students from these Arab country's universities were participated in completing surveys randomly. Structure Equation Modeling SEM-PLS was adopted to analysis data. Results reveal that generative AI techniques and applications have positive and significant effects on students' cognitive achievement in Arab higher education institutions. Results also reveal that student behavior enhances the relationship among AI techniques, applications and cognitive achievement. These results highlight the crucial role of AI applications among students in higher education while the integration of this emerging technology is still at the first stage, students' interaction with and utility of these applications show high satisfactory level of their impact on students' behavior and cognitive achievement. This research contributes to literature of generative AI applications giving evidence from Arab region and filling the gap regarding usage of these applications in higher education.",['generative AI techniques']
2024,https://openalex.org/W4398203672,Social Sciences,Hallucination Rates and Reference Accuracy of ChatGPT and Bard for Systematic Reviews: Comparative Analysis,"Background Large language models (LLMs) have raised both interest and concern in the academic community. They offer the potential for automating literature search and synthesis for systematic reviews but raise concerns regarding their reliability, as the tendency to generate unsupported (hallucinated) content persist. Objective The aim of the study is to assess the performance of LLMs such as ChatGPT and Bard (subsequently rebranded Gemini) to produce references in the context of scientific writing. Methods The performance of ChatGPT and Bard in replicating the results of human-conducted systematic reviews was assessed. Using systematic reviews pertaining to shoulder rotator cuff pathology, these LLMs were tested by providing the same inclusion criteria and comparing the results with original systematic review references, serving as gold standards. The study used 3 key performance metrics: recall, precision, and F1-score, alongside the hallucination rate. Papers were considered “hallucinated” if any 2 of the following information were wrong: title, first author, or year of publication. Results In total, 11 systematic reviews across 4 fields yielded 33 prompts to LLMs (3 LLMs×11 reviews), with 471 references analyzed. Precision rates for GPT-3.5, GPT-4, and Bard were 9.4% (13/139), 13.4% (16/119), and 0% (0/104) respectively (P&lt;.001). Recall rates were 11.9% (13/109) for GPT-3.5 and 13.7% (15/109) for GPT-4, with Bard failing to retrieve any relevant papers (P&lt;.001). Hallucination rates stood at 39.6% (55/139) for GPT-3.5, 28.6% (34/119) for GPT-4, and 91.4% (95/104) for Bard (P&lt;.001). Further analysis of nonhallucinated papers retrieved by GPT models revealed significant differences in identifying various criteria, such as randomized studies, participant criteria, and intervention criteria. The study also noted the geographical and open-access biases in the papers retrieved by the LLMs. Conclusions Given their current performance, it is not recommended for LLMs to be deployed as the primary or exclusive tool for conducting systematic reviews. Any references generated by such models warrant thorough validation by researchers. The high occurrence of hallucinations in LLMs highlights the necessity for refining their training and functionality before confidently using them for rigorous academic purposes.","['GPT-3.5', 'GPT-4']"
2024,https://openalex.org/W4398183308,Social Sciences,The applications of nature‐inspired algorithms in Internet of Things‐based healthcare service: A systematic literature review,"Abstract Nature‐inspired algorithms revolve around the intersection of nature‐inspired algorithms and the IoT within the healthcare domain. This domain addresses the emerging trends and potential synergies between nature‐inspired computational approaches and IoT technologies for advancing healthcare services. Our research aims to fill gaps in addressing algorithmic integration challenges, real‐world implementation issues, and the efficacy of nature‐inspired algorithms in IoT‐based healthcare. We provide insights into the practical aspects and limitations of such applications through a systematic literature review. Specifically, we address the need for a comprehensive understanding of the applications of nature‐inspired algorithms in IoT‐based healthcare, identifying gaps such as the lack of standardized evaluation metrics and studies on integration challenges and security considerations. By bridging these gaps, our paper offers insights and directions for future research in this domain, exploring the diverse landscape of nature‐inspired algorithms in healthcare. Our chosen methodology is a Systematic Literature Review (SLR) to investigate related papers rigorously. Categorizing these algorithms into groups such as genetic algorithms, particle swarm optimization, cuckoo algorithms, ant colony optimization, other approaches, and hybrid methods, we employ meticulous classification based on critical criteria. MATLAB emerges as the predominant programming language, constituting 37.9% of cases, showcasing a prevalent choice among researchers. Our evaluation emphasizes adaptability as the paramount parameter, accounting for 18.4% of considerations. By shedding light on attributes, limitations, and potential directions for future research and development, this review aims to contribute to a comprehensive understanding of nature‐inspired algorithms in the dynamic landscape of IoT‐based healthcare services.","['genetic algorithms', 'cuckoo algorithms', 'hybrid methods']"
2024,https://openalex.org/W4393119757,Social Sciences,Unmasking bias in artificial intelligence: a systematic review of bias detection and mitigation strategies in electronic health record-based models,"Abstract Objectives Leveraging artificial intelligence (AI) in conjunction with electronic health records (EHRs) holds transformative potential to improve healthcare. However, addressing bias in AI, which risks worsening healthcare disparities, cannot be overlooked. This study reviews methods to handle various biases in AI models developed using EHR data. Materials and Methods We conducted a systematic review following the Preferred Reporting Items for Systematic Reviews and Meta-analyses guidelines, analyzing articles from PubMed, Web of Science, and IEEE published between January 01, 2010 and December 17, 2023. The review identified key biases, outlined strategies for detecting and mitigating bias throughout the AI model development, and analyzed metrics for bias assessment. Results Of the 450 articles retrieved, 20 met our criteria, revealing 6 major bias types: algorithmic, confounding, implicit, measurement, selection, and temporal. The AI models were primarily developed for predictive tasks, yet none have been deployed in real-world healthcare settings. Five studies concentrated on the detection of implicit and algorithmic biases employing fairness metrics like statistical parity, equal opportunity, and predictive equity. Fifteen studies proposed strategies for mitigating biases, especially targeting implicit and selection biases. These strategies, evaluated through both performance and fairness metrics, predominantly involved data collection and preprocessing techniques like resampling and reweighting. Discussion This review highlights evolving strategies to mitigate bias in EHR-based AI models, emphasizing the urgent need for both standardized and detailed reporting of the methodologies and systematic real-world testing and evaluation. Such measures are essential for gauging models’ practical impact and fostering ethical AI that ensures fairness and equity in healthcare.","['resampling', 'reweighting']"
2024,https://openalex.org/W4401667275,Social Sciences,Artificial intelligence for literature reviews: opportunities and challenges,"Abstract This paper presents a comprehensive review of the use of Artificial Intelligence (AI) in Systematic Literature Reviews (SLRs). A SLR is a rigorous and organised methodology that assesses and integrates prior research on a given topic. Numerous tools have been developed to assist and partially automate the SLR process. The increasing role of AI in this field shows great potential in providing more effective support for researchers, moving towards the semi-automatic creation of literature reviews. Our study focuses on how AI techniques are applied in the semi-automation of SLRs, specifically in the screening and extraction phases. We examine 21 leading SLR tools using a framework that combines 23 traditional features with 11 AI features. We also analyse 11 recent tools that leverage large language models for searching the literature and assisting academic writing. Finally, the paper discusses current trends in the field, outlines key research challenges, and suggests directions for future research. We highlight three primary research challenges: integrating advanced AI solutions, such as large language models and knowledge graphs, improving usability, and developing a standardised evaluation framework. We also propose best practices to ensure more robust evaluations in terms of performance, usability, and transparency. Overall, this review offers a detailed overview of AI-enhanced SLR tools for researchers and practitioners, providing a foundation for the development of next-generation AI solutions in this field.",['knowledge graphs']
2024,https://openalex.org/W4402827393,Social Sciences,Larger and more instructable language models become less reliable,"Abstract The prevailing methods to make large language models more powerful and amenable have been based on continuous scaling up (that is, increasing their size, data volume and computational resources 1 ) and bespoke shaping up (including post-filtering 2,3 , fine tuning or use of human feedback 4,5 ). However, larger and more instructable large language models may have become less reliable. By studying the relationship between difficulty concordance, task avoidance and prompting stability of several language model families, here we show that easy instances for human participants are also easy for the models, but scaled-up, shaped-up models do not secure areas of low difficulty in which either the model does not err or human supervision can spot the errors. We also find that early models often avoid user questions but scaled-up, shaped-up models tend to give an apparently sensible yet wrong answer much more often, including errors on difficult questions that human supervisors frequently overlook. Moreover, we observe that stability to different natural phrasings of the same question is improved by scaling-up and shaping-up interventions, but pockets of variability persist across difficulty levels. These findings highlight the need for a fundamental shift in the design and development of general-purpose artificial intelligence, particularly in high-stakes areas for which a predictable distribution of errors is paramount.","['post-filtering', 'fine tuning', 'use of human feedback']"
2024,https://openalex.org/W4392343921,Social Sciences,Data extraction for evidence synthesis using a large language model: A proof‐of‐concept study,"Abstract Data extraction is a crucial, yet labor‐intensive and error‐prone part of evidence synthesis. To date, efforts to harness machine learning for enhancing efficiency of the data extraction process have fallen short of achieving sufficient accuracy and usability. With the release of large language models (LLMs), new possibilities have emerged to increase efficiency and accuracy of data extraction for evidence synthesis. The objective of this proof‐of‐concept study was to assess the performance of an LLM (Claude 2) in extracting data elements from published studies, compared with human data extraction as employed in systematic reviews. Our analysis utilized a convenience sample of 10 English‐language, open‐access publications of randomized controlled trials included in a single systematic review. We selected 16 distinct types of data, posing varying degrees of difficulty (160 data elements across 10 studies). We used the browser version of Claude 2 to upload the portable document format of each publication and then prompted the model for each data element. Across 160 data elements, Claude 2 demonstrated an overall accuracy of 96.3% with a high test–retest reliability (replication 1: 96.9%; replication 2: 95.0% accuracy). Overall, Claude 2 made 6 errors on 160 data items. The most common errors ( n = 4) were missed data items. Importantly, Claude 2's ease of use was high; it required no technical expertise or labeled training data for effective operation (i.e., zero‐shot learning). Based on findings of our proof‐of‐concept study, leveraging LLMs has the potential to substantially enhance the efficiency and accuracy of data extraction for evidence syntheses.",['zero-shot learning']
2024,https://openalex.org/W4399857583,Social Sciences,Integrating artificial intelligence to assess emotions in learning environments: a systematic literature review,"Introduction Artificial Intelligence (AI) is transforming multiple sectors within our society, including education. In this context, emotions play a fundamental role in the teaching-learning process given that they influence academic performance, motivation, information retention, and student well-being. Thus, the integration of AI in emotional assessment within educational environments offers several advantages that can transform how we understand and address the socio-emotional development of students. However, there remains a lack of comprehensive approach that systematizes advancements, challenges, and opportunities in this field. Aim This systematic literature review aims to explore how artificial intelligence (AI) is used to evaluate emotions within educational settings. We provide a comprehensive overview of the current state of research, focusing on advancements, challenges, and opportunities in the domain of AI-driven emotional assessment within educational settings. Method The review involved a search across the following academic databases: Pubmed, Web of Science, PsycINFO and Scopus. Forty-one articles were selected that meet the established inclusion criteria. These articles were analyzed to extract key insights related to the integration of AI and emotional assessment within educational environments. Results The findings reveal a variety of AI-driven approaches that were developed to capture and analyze students’ emotional states during learning activities. The findings are summarized in four fundamental topics: (1) emotion recognition in education, (2) technology integration and learning outcomes, (3) special education and assistive technology, (4) affective computing. Among the key AI techniques employed are machine learning and facial recognition, which are used to assess emotions. These approaches demonstrate promising potential in enhancing pedagogical strategies and creating adaptive learning environments that cater to individual emotional needs. The review identified emerging factors that, while important, require further investigation to understand their relationships and implications fully. These elements could significantly enhance the use of AI in assessing emotions within educational settings. Specifically, we are referring to: (1) federated learning, (2) convolutional neural network (CNN), (3) recurrent neural network (RNN), (4) facial expression databases, and (5) ethics in the development of intelligent systems. Conclusion This systematic literature review showcases the significance of AI in revolutionizing educational practices through emotion assessment. While advancements are evident, challenges related to accuracy, privacy, and cross-cultural validity were also identified. The synthesis of existing research highlights the need for further research into refining AI models for emotion recognition and emphasizes the importance of ethical considerations in implementing AI technologies within educational contexts.","['machine learning', 'federated learning', 'convolutional neural network (CNN)', 'recurrent neural network (RNN)']"
2024,https://openalex.org/W4391508432,Social Sciences,Artificial intelligence-driven virtual rehabilitation for people living in the community: A scoping review,"Abstract Virtual Rehabilitation (VRehab) is a promising approach to improving the physical and mental functioning of patients living in the community. The use of VRehab technology results in the generation of multi-modal datasets collected through various devices. This presents opportunities for the development of Artificial Intelligence (AI) techniques in VRehab, namely the measurement, detection, and prediction of various patients’ health outcomes. The objective of this scoping review was to explore the applications and effectiveness of incorporating AI into home-based VRehab programs. PubMed/MEDLINE, Embase, IEEE Xplore, Web of Science databases, and Google Scholar were searched from inception until June 2023 for studies that applied AI for the delivery of VRehab programs to the homes of adult patients. After screening 2172 unique titles and abstracts and 51 full-text studies, 13 studies were included in the review. A variety of AI algorithms were applied to analyze data collected from various sensors and make inferences about patients’ health outcomes, most involving evaluating patients’ exercise quality and providing feedback to patients. The AI algorithms used in the studies were mostly fuzzy rule-based methods, template matching, and deep neural networks. Despite the growing body of literature on the use of AI in VRehab, very few studies have examined its use in patients’ homes. Current research suggests that integrating AI with home-based VRehab can lead to improved rehabilitation outcomes for patients. However, further research is required to fully assess the effectiveness of various forms of AI-driven home-based VRehab, taking into account its unique challenges and using standardized metrics.","['fuzzy rule-based methods', 'deep neural networks']"
2024,https://openalex.org/W4396908686,Social Sciences,Firefighter Skill Advancement through IoT-Enabled Virtual Reality and CNN-Based Training,"To maintain the safety and efficacy of firefighters in various circumstances, modern firefighting necessitates constantly improving skills and training techniques. Utilizing the Internet of Things (IoT), virtual reality (VR), and convolutional neural networks (CNN), this paper details a novel method for training firefighters. The proposed system collects real-time data on ambient variables, equipment state, and firefighter biometrics via integrating IoT sensors into firefighting equipment and training settings. Using this information, it can develop lifelike VR training simulations of difficult and potentially dangerous scenarios. To make the training settings more realistic and malleable, CNN-based algorithms are used to assess the data. The capacity to simulate a wide variety of firefighting situations, customize training difficulty depending on individual and team performance, and provide instant feedback and performance metrics to trainees are all major benefits of this method. The method also allows teachers to check in and evaluate their learners remotely, improving instruction quality. An IoT-enabled VR and CNN-based training technique has shown promising preliminary results in pilot trials, suggesting it might greatly enhance firefighter competence, situational awareness, and decision-making ability. Because of this, it has the potential to completely alter the way firefighters are informed and prepared for the ever-changing dangers users may encounter on the job.",['convolutional neural networks (CNN)']
2024,https://openalex.org/W4391936064,Social Sciences,Adaptive Segmentation Enhanced Asynchronous Federated Learning for Sustainable Intelligent Transportation Systems,"The proliferation of advanced embedded and communication technologies has facilitated the possibility of modern Intelligent Transportation System (ITS). The hierarchical nature of such large-scale and distributed systems brings obvious challenges in creating a scalable and sustainable computing environment, and hence the development and application of edge intelligence become critical. Federated learning (FL), as an emerging distributed machine learning paradigm, aims to offer secure knowledge sharing and effective learning across multiple devices. However, conventional FL may fall into trouble when facing large-scale and network-agnostic systems with fast moving devices and changing network attributes. In this study, we propose an Adaptive Segmentation enhanced Asynchronous Federated Learning (AS-AFL) model, aiming to improve the learning efficiency and reliability in sustainable ITS via a decentralized fashion. Specifically, a meta-learning based adaptive segmentation scheme is designed to automatically separate the client nodes (e.g., vehicles) into multiple edge groups according to their homogeneous attributes. An integrated aggregation mechanism is then developed to realize the horizontal FL among a group of similar client nodes via the so-called intra-group synchronous aggregation, while allowing the vertical FL across different groups via the so-called inter-group asynchronous aggregation. Experiment and evaluation results based on an open-source dataset demonstrate the outstanding learning and communication performance of our proposed model, compared with several conventional FL schemes in a distributed ITS application scenario.","['Federated learning (FL)', 'meta-learning based adaptive segmentation']"
2024,https://openalex.org/W4393092671,Social Sciences,CFSSynergy: Combining Feature-Based and Similarity-Based Methods for Drug Synergy Prediction,"Drug synergy prediction plays a vital role in cancer treatment. Because experimental approaches are labor-intensive and expensive, computational-based approaches get more attention. There are two types of computational methods for drug synergy prediction: feature-based and similarity-based. In feature-based methods, the main focus is to extract more discriminative features from drug pairs and cell lines to pass to the task predictor. In similarity-based methods, the similarities among all drugs and cell lines are utilized as features and fed into the task predictor. In this work, a novel approach, called CFSSynergy, that combines these two viewpoints is proposed. First, a discriminative representation is extracted for paired drugs and cell lines as input. We have utilized transformer-based architecture for drugs. For cell lines, we have created a similarity matrix between proteins using the Node2Vec algorithm. Then, the new cell line representation is computed by multiplying the protein–protein similarity matrix and the initial cell line representation. Next, we compute the similarity between unique drugs and unique cells using the learned representation for paired drugs and cell lines. Then, we compute a new representation for paired drugs and cell lines based on the similarity-based features and the learned features. Finally, these features are fed to XGBoost as a task predictor. Two well-known data sets were used to evaluate the performance of our proposed method: DrugCombDB and OncologyScreen. The CFSSynergy approach consistently outperformed existing methods in comparative evaluations. This substantiates the efficacy of our approach in capturing complex synergistic interactions between drugs and cell lines, setting it apart from conventional similarity-based or feature-based methods.","['transformer-based architecture', 'Node2Vec algorithm', 'XGBoost']"
2024,https://openalex.org/W4396831262,Social Sciences,GPT-4 Turbo with Vision fails to outperform text-only GPT-4 Turbo in the Japan Diagnostic Radiology Board Examination,"Abstract Purpose To assess the performance of GPT-4 Turbo with Vision (GPT-4TV), OpenAI’s latest multimodal large language model, by comparing its ability to process both text and image inputs with that of the text-only GPT-4 Turbo (GPT-4 T) in the context of the Japan Diagnostic Radiology Board Examination (JDRBE). Materials and methods The dataset comprised questions from JDRBE 2021 and 2023. A total of six board-certified diagnostic radiologists discussed the questions and provided ground-truth answers by consulting relevant literature as necessary. The following questions were excluded: those lacking associated images, those with no unanimous agreement on answers, and those including images rejected by the OpenAI application programming interface. The inputs for GPT-4TV included both text and images, whereas those for GPT-4 T were entirely text. Both models were deployed on the dataset, and their performance was compared using McNemar’s exact test. The radiological credibility of the responses was assessed by two diagnostic radiologists through the assignment of legitimacy scores on a five-point Likert scale. These scores were subsequently used to compare model performance using Wilcoxon's signed-rank test. Results The dataset comprised 139 questions. GPT-4TV correctly answered 62 questions (45%), whereas GPT-4 T correctly answered 57 questions (41%). A statistical analysis found no significant performance difference between the two models (P = 0.44). The GPT-4TV responses received significantly lower legitimacy scores from both radiologists than the GPT-4 T responses. Conclusion No significant enhancement in accuracy was observed when using GPT-4TV with image input compared with that of using text-only GPT-4 T for JDRBE questions.",['GPT-4 Turbo (GPT-4 T)']
2024,https://openalex.org/W4390755438,Social Sciences,A voting gray wolf optimizer-based ensemble learning models for intrusion detection in the Internet of Things,"Abstract The Internet of Things (IoT) has garnered considerable attention from academic and industrial circles as a pivotal technology in recent years. The escalation of security risks is observed to be associated with the growing interest in IoT applications. Intrusion detection systems (IDS) have been devised as viable instruments for identifying and averting malicious actions in this context. Several techniques described in academic papers are thought to be very accurate, but they cannot be used in the real world because the datasets used to build and test the models do not accurately reflect and simulate the IoT network. Existing methods, on the other hand, deal with these issues, but they are not good enough for commercial use because of their lack of precision, low detection rate, receiver operating characteristic (ROC), and false acceptance rate (FAR). The effectiveness of these solutions is predominantly dependent on individual learners and is consequently influenced by the inherent limitations of each learning algorithm. This study introduces a new approach for detecting intrusion attacks in an IoT network, which involves the use of an ensemble learning technique based on gray wolf optimizer (GWO). The novelty of this study lies in the proposed voting gray wolf optimizer (GWO) ensemble model, which incorporates two crucial components: a traffic analyzer and a classification phase engine. The model employs a voting technique to combine the probability averages of the base learners. Secondly, the combination of feature selection and feature extraction techniques is to reduce dimensionality. Thirdly, the utilization of GWO is employed to optimize the parameters of ensemble models. Similarly, the approach employs the most authentic intrusion detection datasets that are accessible and amalgamates multiple learners to generate ensemble learners. The hybridization of information gain (IG) and principal component analysis (PCA) was employed to reduce dimensionality. The study utilized a novel GWO ensemble learning approach that incorporated a decision tree, random forest, K-nearest neighbor, and multilayer perceptron for classification. To evaluate the efficacy of the proposed model, two authentic datasets, namely, BoT-IoT and UNSW-NB15, were scrutinized. The GWO-optimized ensemble model demonstrates superior accuracy when compared to other machine learning-based and deep learning models. Specifically, the model achieves an accuracy rate of 99.98%, a DR of 99.97%, a precision rate of 99.94%, an ROC rate of 99.99%, and an FAR rate of 1.30 on the BoT-IoT dataset. According to the experimental results, the proposed ensemble model optimized by GWO achieved an accuracy of 100%, a DR of 99.9%, a precision of 99.59%, an ROC of 99.40%, and an FAR of 1.5 when tested on the UNSW-NB15 dataset.","['ensemble learning technique', 'gray wolf optimizer (GWO)', 'voting technique', 'feature selection', 'information gain (IG)', 'principal component analysis (PCA)', 'decision tree', 'random forest', 'K-nearest neighbor', 'multilayer perceptron']"
2024,https://openalex.org/W4392865184,Social Sciences,Artificial intelligence and multimodal data fusion for smart healthcare: topic modeling and bibliometrics,"Abstract Advancements in artificial intelligence (AI) have driven extensive research into developing diverse multimodal data analysis approaches for smart healthcare. There is a scarcity of large-scale analysis of literature in this field based on quantitative approaches. This study performed a bibliometric and topic modeling examination on 683 articles from 2002 to 2022, focusing on research topics and trends, journals, countries/regions, institutions, authors, and scientific collaborations. Results showed that, firstly, the number of articles has grown from 1 in 2002 to 220 in 2022, with a majority being published in interdisciplinary journals that link healthcare and medical research and information technology and AI. Secondly, the significant rise in the quantity of research articles can be attributed to the increasing contribution of scholars from non-English speaking countries/regions and the noteworthy contributions made by authors in the USA and India. Thirdly, researchers show a high interest in diverse research issues, especially, cross-modality magnetic resonance imaging (MRI) for brain tumor analysis, cancer prognosis through multi-dimensional data analysis, and AI-assisted diagnostics and personalization in healthcare, with each topic experiencing a significant increase in research interest. There is an emerging trend towards issues such as applying generative adversarial networks and contrastive learning for multimodal medical image fusion and synthesis and utilizing the combined spatiotemporal resolution of functional MRI and electroencephalogram in a data-centric manner. This study is valuable in enhancing researchers’ and practitioners’ understanding of the present focal points and upcoming trajectories in AI-powered smart healthcare based on multimodal data analysis.","['generative adversarial networks', 'contrastive learning']"
2024,https://openalex.org/W4392884001,Social Sciences,Developing a Multi-Criteria Decision-Making model for nuclear power plant location selection using Fuzzy Analytic Hierarchy Process and Fuzzy VIKOR methods focused on socio-economic factors,"In response to its position as the fourth most populous country globally, Indonesia is exploring constructing nuclear power plants (NPPs) as a sustainable energy solution. A pivotal step in this initiative is selecting an appropriate NPP site. This study employs two Multi-Criteria Decision-Making (MCDM) methods, the Fuzzy Analytic Hierarchy Process (Fuzzy-AHP) and Fuzzy VIKOR, to identify the most suitable location for an NPP, focusing on socio-economic factors. The Fuzzy-AHP method is utilized to prioritize ten sub-criteria: transmission network, operating costs, economic impact, security, transportation network, legal considerations, the impact of tourism, land ownership, historical sites, and public acceptance. Following this, the Fuzzy VIKOR method leverages these prioritized criteria to evaluate two potential sites: East Kalimantan and West Kalimantan. The analysis reveals that security, transmission, and transportation networks emerge as the top priorities. The application of the Fuzzy VIKOR algorithm identifies West Kalimantan as the optimal site for NPP construction, evidenced by its lower VIKOR index of 0.3599, indicating a higher overall preference based on the evaluated criteria. The study demonstrates that the integration of Fuzzy-AHP and Fuzzy VIKOR methods prioritizes critical socio-economic factors and quantitatively assesses potential sites, offering a systematic and objective approach to support decision-making in NPP site selection.",['Fuzzy VIKOR']
2024,https://openalex.org/W4402890475,Social Sciences,"Foundation models in robotics: Applications, challenges, and the future","We survey applications of pretrained foundation models in robotics. Traditional deep learning models in robotics are trained on small datasets tailored for specific tasks, which limits their adaptability across diverse applications. In contrast, foundation models pretrained on internet-scale data appear to have superior generalization capabilities, and in some instances display an emergent ability to find zero-shot solutions to problems that are not present in the training data. Foundation models may hold the potential to enhance various components of the robot autonomy stack, from perception to decision-making and control. For example, large language models can generate code or provide common sense reasoning, while vision-language models enable open-vocabulary visual recognition. However, significant open research challenges remain, particularly around the scarcity of robot-relevant training data, safety guarantees and uncertainty quantification, and real-time execution. In this survey, we study recent papers that have used or built foundation models to solve robotics problems. We explore how foundation models contribute to improving robot capabilities in the domains of perception, decision-making, and control. We discuss the challenges hindering the adoption of foundation models in robot autonomy and provide opportunities and potential pathways for future advancements. The GitHub project corresponding to this paper can be found here: https://github.com/robotics-survey/Awesome-Robotics-Foundation-Models .","['pretrained foundation models', 'vision-language models']"
2024,https://openalex.org/W4391454392,Social Sciences,UANet: An Uncertainty-Aware Network for Building Extraction From Remote Sensing Images,"Building extraction aims to segment building pixels from remote sensing images and plays an essential role in many applications, such as city planning and urban dynamic monitoring. Over the past few years, deep learning methods with encoder–decoder architectures have achieved remarkable performance due to their powerful feature representation capability. Nevertheless, due to the varying scales and styles of buildings, conventional deep learning models always suffer from uncertain predictions and cannot accurately distinguish the complete footprints of the building from the complex distribution of ground objects, leading to a large degree of omission and commission. In this paper, we realize the importance of uncertain prediction and propose a novel and straightforward Uncertainty-Aware Network (UANet) to alleviate this problem. Specifically, we first apply a general encoder–decoder network to obtain a building extraction map with relatively high uncertainty. Second, in order to aggregate the useful information in the highest-level features, we design a Prior Information Guide Module to guide the highest-level features in learning the prior information from the conventional extraction map. Third, based on the uncertain extraction map, we introduce an Uncertainty Rank Algorithm to measure the uncertainty level of each pixel belonging to the foreground and the background. We further combine this algorithm with the proposed Uncertainty-Aware Fusion Module to facilitate level-by-level feature refinement and obtain the final refined extraction map with low uncertainty. To verify the performance of our proposed UANet, we conduct extensive experiments on three public building datasets, including the WHU building dataset, the Massachusetts building dataset, and the Inria aerial image dataset. Results demonstrate that the proposed UANet outperforms other state-of-the-art algorithms by a large margin. The source code of the proposed UANet is available at https://github.com/Henryjiepanli/Uncertainty-aware-Network.","['deep learning methods with encoder–decoder architectures', 'encoder–decoder network']"
2024,https://openalex.org/W4393380945,Social Sciences,One-Step Multi-View Clustering With Diverse Representation,"Multi-View clustering has attracted broad attention due to its capacity to utilize consistent and complementary information among views. Although tremendous progress has been made recently, most existing methods undergo high complexity, preventing them from being applied to large-scale tasks. Multi-View clustering via matrix factorization is a representative to address this issue. However, most of them map the data matrices into a fixed dimension, limiting the model's expressiveness. Moreover, a range of methods suffers from a two-step process, i.e., multimodal learning and the subsequent <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> <tex-math notation=""LaTeX"">$k$</tex-math> </inline-formula> -means, inevitably causing a suboptimal clustering result. In light of this, we propose a one-step multi-view clustering with diverse representation (OMVCDR) method, which incorporates multi-view learning and <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> <tex-math notation=""LaTeX"">$k$</tex-math> </inline-formula> -means into a unified framework. Specifically, we first project original data matrices into various latent spaces to attain comprehensive information and auto-weight them in a self-supervised manner. Then, we directly use the information matrices under diverse dimensions to obtain consensus discrete clustering labels. The unified work of representation learning and clustering boosts the quality of the final results. Furthermore, we develop an efficient optimization algorithm with proven convergence to solve the resultant problem. Comprehensive experiments on various datasets demonstrate the promising clustering performance of our proposed method. The code is publicly available at https://github.com/wanxinhang/OMVCDR.","['Multi-View clustering via matrix factorization', 'k-means', 'multi-view learning', 'representation learning']"
2024,https://openalex.org/W4399054302,Social Sciences,Artificial Intelligence in Point-of-Care Biosensing: Challenges and Opportunities,"The integration of artificial intelligence (AI) into point-of-care (POC) biosensing has the potential to revolutionize diagnostic methodologies by offering rapid, accurate, and accessible health assessment directly at the patient level. This review paper explores the transformative impact of AI technologies on POC biosensing, emphasizing recent computational advancements, ongoing challenges, and future prospects in the field. We provide an overview of core biosensing technologies and their use at the POC, highlighting ongoing issues and challenges that may be solved with AI. We follow with an overview of AI methodologies that can be applied to biosensing, including machine learning algorithms, neural networks, and data processing frameworks that facilitate real-time analytical decision-making. We explore the applications of AI at each stage of the biosensor development process, highlighting the diverse opportunities beyond simple data analysis procedures. We include a thorough analysis of outstanding challenges in the field of AI-assisted biosensing, focusing on the technical and ethical challenges regarding the widespread adoption of these technologies, such as data security, algorithmic bias, and regulatory compliance. Through this review, we aim to emphasize the role of AI in advancing POC biosensing and inform researchers, clinicians, and policymakers about the potential of these technologies in reshaping global healthcare landscapes.",['neural networks']
2024,https://openalex.org/W4399426804,Social Sciences,Evaluating the persuasive influence of political microtargeting with large language models,"Recent advancements in large language models (LLMs) have raised the prospect of scalable, automated, and fine-grained political microtargeting on a scale previously unseen; however, the persuasive influence of microtargeting with LLMs remains unclear. Here, we build a custom web application capable of integrating self-reported demographic and political data into GPT-4 prompts in real-time, facilitating the live creation of unique messages tailored to persuade individual users on four political issues. We then deploy this application in a preregistered randomized control experiment ( n = 8,587) to investigate the extent to which access to individual-level data increases the persuasive influence of GPT-4. Our approach yields two key findings. First, messages generated by GPT-4 were broadly persuasive, in some cases increasing support for an issue stance by up to 12 percentage points. Second, in aggregate, the persuasive impact of microtargeted messages was not statistically different from that of non-microtargeted messages (4.83 vs. 6.20 percentage points, respectively, P = 0.226). These trends hold even when manipulating the type and number of attributes used to tailor the message. These findings suggest—contrary to widespread speculation—that the influence of current LLMs may reside not in their ability to tailor messages to individuals but rather in the persuasiveness of their generic, nontargeted messages. We release our experimental dataset, GPTarget2024 , as an empirical baseline for future research.",['GPT-4']
2024,https://openalex.org/W4401434014,Social Sciences,Crafting personalized learning paths with AI for lifelong learning: a systematic literature review,"The rapid evolution of knowledge requires constantly acquiring and updating skills, making lifelong learning crucial. Despite decades of artificial intelligence, recent advances promote new solutions to personalize learning in this context. The purpose of this article is to explore the current state of research on the development of artificial intelligence-mediated solutions for the design of personalized learning paths. To achieve this, a systematic literature review (SRL) of 78 articles published between 2019 and 2024 from the Scopus and Web or Science databases was conducted, answering seven questions grouped into three themes: characteristics of the published research, context of the research, and type of solution analyzed. This study identified that: (a) the greatest production of scientific research on the topic is developed in China, India and the United States, (b) the focus is mainly directed towards the educational context at the higher education level with areas of opportunity for application in the work context, and (c) the development of adaptive learning technologies predominates; however, there is a growing interest in the application of generative language models. This article contributes to the growing interest and literature related to personalized learning under artificial intelligence mediated solutions that will serve as a basis for academic institutions and organizations to design programs under this model.",['generative language models']
2024,https://openalex.org/W4390876710,Social Sciences,Utilisation of Deep Learning (DL) and Neural Networks (NN) Algorithms for Energy Power Generation: A Social Network and Bibliometric Analysis (2004-2022),"The research landscape on the applications of advanced computational tools (ACTs) such as machine/deep learning and neural network algorithms for energy and power generation (EPG) was critically examined through publication trends and bibliometrics data analysis. The Elsevier Scopus database and the PRISMA methodology were employed to identify and screen the published documents, whereas the bibliometric analysis software VOSviewer was used to analyse the co-authorships, citations, and keyword occurrences. The results showed that 152 documents have been published on the topic comprising conference proceedings (58.6%) and articles (41.4%) between 2004 and 2022. Publication trends analysis revealed the number of publications increased from 1 to 31 or by 3,000% over the same period, which was ascribed to the growing scientific interest and research impact of the topic. Stakeholder analysis revealed the top authors/researchers are Anvari M, Ghaderi SF and Saberi M, whereas the most prolific affiliation and nations actively engaged in the topic are the North China Electric Power University, and China, respectively. Conversely, the top funding agency actively backing research on the topic is the National Natural Science Foundation of China (NSFC). Co-authorship analysis revealed high levels of collaboration between researching nations compared to authors and affiliations. Hotspot analysis revealed three major thematic focus areas namely; Energy Grid Forecasting, Power Generation Control, and Intelligent Energy Optimization. In conclusion, the study showed that the application of ACTs in EPG is an active, multidisciplinary, and impact area of research with potential for more impactful contributions to research and society at large.","['machine learning', 'deep learning', 'neural network algorithms']"
2024,https://openalex.org/W4394967854,Social Sciences,Potential of Large Language Models in Health Care: Delphi Study,"Background A large language model (LLM) is a machine learning model inferred from text data that captures subtle patterns of language use in context. Modern LLMs are based on neural network architectures that incorporate transformer methods. They allow the model to relate words together through attention to multiple words in a text sequence. LLMs have been shown to be highly effective for a range of tasks in natural language processing (NLP), including classification and information extraction tasks and generative applications. Objective The aim of this adapted Delphi study was to collect researchers’ opinions on how LLMs might influence health care and on the strengths, weaknesses, opportunities, and threats of LLM use in health care. Methods We invited researchers in the fields of health informatics, nursing informatics, and medical NLP to share their opinions on LLM use in health care. We started the first round with open questions based on our strengths, weaknesses, opportunities, and threats framework. In the second and third round, the participants scored these items. Results The first, second, and third rounds had 28, 23, and 21 participants, respectively. Almost all participants (26/28, 93% in round 1 and 20/21, 95% in round 3) were affiliated with academic institutions. Agreement was reached on 103 items related to use cases, benefits, risks, reliability, adoption aspects, and the future of LLMs in health care. Participants offered several use cases, including supporting clinical tasks, documentation tasks, and medical research and education, and agreed that LLM-based systems will act as health assistants for patient education. The agreed-upon benefits included increased efficiency in data handling and extraction, improved automation of processes, improved quality of health care services and overall health outcomes, provision of personalized care, accelerated diagnosis and treatment processes, and improved interaction between patients and health care professionals. In total, 5 risks to health care in general were identified: cybersecurity breaches, the potential for patient misinformation, ethical concerns, the likelihood of biased decision-making, and the risk associated with inaccurate communication. Overconfidence in LLM-based systems was recognized as a risk to the medical profession. The 6 agreed-upon privacy risks included the use of unregulated cloud services that compromise data security, exposure of sensitive patient data, breaches of confidentiality, fraudulent use of information, vulnerabilities in data storage and communication, and inappropriate access or use of patient data. Conclusions Future research related to LLMs should not only focus on testing their possibilities for NLP-related tasks but also consider the workflows the models could contribute to and the requirements regarding quality, integration, and regulations needed for successful implementation in practice.","['large language model (LLM)', 'transformer methods']"
2024,https://openalex.org/W4400853276,Social Sciences,Unveiling the dynamics of AI applications: A review of reviews using scientometrics and BERTopic modeling,"In a world that has rapidly transformed through the advent of artificial intelligence (AI), our systematic review, guided by the PRISMA protocol, investigates a decade of AI research, revealing insights into its evolution and impact. Our study, examining 3,767 articles, has drawn considerable attention, as evidenced by an impressive 63,577 citations, underscoring the scholarly community's profound engagement. Our study reveals a collaborative landscape with 18,189 contributing authors, reflecting a robust network of researchers advancing AI and machine learning applications. Review categories focus on systematic reviews and bibliometric analyses, indicating an increasing emphasis on comprehensive literature synthesis and quantitative analysis. The findings also suggest an opportunity to explore emerging methodologies such as topic modeling and meta-analysis. We dissect the state of the art presented in these reviews, finding themes throughout the broad scholarly discourse through thematic clustering and BERTopic modeling. Categorization of study articles across fields of research indicates dominance in Information and Computing Sciences, followed by Biomedical and Clinical Sciences. Subject categories reveal interconnected clusters across various sectors, notably in healthcare, engineering, business intelligence, and computational technologies. Semantic analysis via BERTopic revealed nineteen clusters mapped to themes such as AI in health innovations, AI for sustainable development, AI and deep learning, AI in education, and ethical considerations. Future research directions are suggested, emphasizing the need for intersectional bias mitigation, holistic health approaches, AI's role in environmental sustainability, and the ethical deployment of generative AI.","['topic modeling', 'BERTopic modeling']"
2024,https://openalex.org/W4403656816,Social Sciences,"Advancing the Sustainable Development Goals (SDGs) through artificial intelligence, machine learning, and deep learning","The use of Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) significantly has the touch of transformational potential towards bringing the Sustainable Development Goals (SDGs) to be addressed in various industries. This research investigates the new developments and applications of these technologies in advancing sustainability programs in industry-intensive domains. Industries are beginning to undergo a major change by making today with the help of AI, ML, and DL that resources can be optimized, energy efficiency can be improved, and environmental impacts can be mitigated. A number of other trends - including predictive analytics and intelligent automation, allow for smarter and more efficient production, waste minimization and circular economy practices. AI-powered solutions are also now being used in the energy sector to maximize the generation of renewable energy, optimize grid management, and aid in the transition to low carbon energy systems. This will enable industries achieve better environmental benefits and higher operational efficiencies through big data analytics and IoT. AI and ML are also crucial in smart cities, urban planning, public services that delivery efficiency and overall support the sustainability agenda. The results reinforce the importance of strong regulatory structures and interdisciplinary collaboration to optimally leverage AI, ML, and DL to the SDGs, which will be intrinsic to designing for resilience and sustainability.","['Machine Learning (ML)', 'Deep Learning (DL)']"
2024,https://openalex.org/W4394961856,Social Sciences,Applications and challenges of neural networks in otolaryngology (Review),"Artificial Intelligence (AI) has become a topic of interest that is frequently debated in all research fields. The medical field is no exception, where several unanswered questions remain. When and how this field can benefit from AI support in daily routines are the most frequently asked questions. The present review aims to present the types of neural networks (NNs) available for development, discussing their advantages, disadvantages and how they can be applied practically. In addition, the present review summarizes how NNs (combined with various other features) have already been applied in studies in the ear nose throat research field, from assisting diagnosis to treatment management. Although the answer to this question regarding AI remains elusive, understanding the basics and types of applicable NNs can lead to future studies possibly using more than one type of NN. This approach may bypass the actual limitations in accuracy and relevance of information generated by AI. The proposed studies, the majority of which used convolutional NNs, obtained accuracies varying 70-98%, with a number of studies having the AI trained on a limited number of cases (<100 patients). The lack of standardization in AI protocols for research negatively affects data homogeneity and transparency of databases.","['neural networks (NNs)', 'convolutional neural networks (convolutional NNs)']"
2024,https://openalex.org/W4397028793,Social Sciences,A Hierarchical 3D Gaussian Representation for Real-Time Rendering of Very Large Datasets,"Novel view synthesis has seen major advances in recent years, with 3D Gaussian splatting offering an excellent level of visual quality, fast training and real-time rendering. However, the resources needed for training and rendering inevitably limit the size of the captured scenes that can be represented with good visual quality. We introduce a hierarchy of 3D Gaussians that preserves visual quality for very large scenes, while offering an efficient Level-of-Detail (LOD) solution for efficient rendering of distant content with effective level selection and smooth transitions between levels. We introduce a divide-and-conquer approach that allows us to train very large scenes in independent chunks. We consolidate the chunks into a hierarchy that can be optimized to further improve visual quality of Gaussians merged into intermediate nodes. Very large captures typically have sparse coverage of the scene, presenting many challenges to the original 3D Gaussian splatting training method; we adapt and regularize training to account for these issues. We present a complete solution, that enables real-time rendering of very large scenes and can adapt to available resources thanks to our LOD method. We show results for captured scenes with up to tens of thousands of images with a simple and affordable rig, covering trajectories of up to several kilometers and lasting up to one hour.",['3D Gaussian splatting']
2024,https://openalex.org/W4392592756,Social Sciences,Beyond Discrimination: Generative AI Applications and Ethical Challenges in Forensic Psychiatry,"The advent and growing popularity of generative artificial intelligence (GenAI) holds the potential to revolutionise AI applications in forensic psychiatry and criminal justice, which traditionally relied on discriminative AI algorithms. Generative AI models mark a significant shift from the previously prevailing paradigm through their ability to generate seemingly new realistic data and analyse and integrate a vast amount of unstructured content from different data formats. This potential extends beyond reshaping conventional practices, like risk assessment, diagnostic support, and treatment and rehabilitation plans, to creating new opportunities in previously underexplored areas, such as training and education. This paper examines the transformative impact of generative artificial intelligence on AI applications in forensic psychiatry and criminal justice. First, it introduces generative AI and its prevalent models. Following this, it reviews the current applications of discriminative AI in forensic psychiatry. Subsequently, it presents a thorough exploration of the potential of generative AI to transform established practices and introduce novel applications through multimodal generative models, data generation and data augmentation. Finally, it provides a comprehensive overview of ethical and legal issues associated with deploying generative AI models, focusing on their impact on individuals as well as their broader societal implications. In conclusion, this paper aims to contribute to the ongoing discourse concerning the dynamic challenges of generative AI applications in forensic contexts, highlighting potential opportunities, risks, and challenges. It advocates for interdisciplinary collaboration and emphasises the necessity for thorough, responsible evaluations of generative AI models before widespread adoption into domains where decisions with substantial life-altering consequences are routinely made.","['generative AI models', 'multimodal generative models']"
2024,https://openalex.org/W4392911004,Social Sciences,Unlocking the Potential of Artificial Intelligence in Fashion Design and E-Commerce Applications: The Case of Midjourney,"The fashion industry has shown increasing interest in applying artificial intelligence (AI), yet there is a significant gap in exploring the potential of emerging diffusion-modeling-based AI image-generation systems for fashion design and commerce. Therefore, this study aims to assess the effectiveness of Midjourney, one such AI system, in both fashion design and related commerce applications. We employed the action research approach with the Functional, Expressive, and Aesthetic (FEA) Consumer Needs Model as the theoretical framework. Our research comprised three stages: refining an initial idea into well-defined textual design concepts, facilitating concept development, and validating the preceding observations and reflections by creating a new line of hemp-based products that were evaluated by targeted consumers through an online survey. Findings reveal that this AI tool can assist fashion designers in creating both visually expressive attire and ready-to-wear products, meeting defined design criteria and consumer needs. Midjourney shows promise in streamlining the fashion design process by enhancing ideation and optimizing design details. Potential e-commercial applications of such AI systems were proposed, benefiting physical and digital fashion businesses. It is noted that, to date, the major limitations of using Midjourney encompass its restriction to only facilitating early fashion design stages and necessitating substantial involvement from designers.",['diffusion-modeling-based AI image-generation systems']
2024,https://openalex.org/W4390618081,Social Sciences,Making Sense of Machine Learning: A Review of Interpretation Techniques and Their Applications,"Transparency in AI models is essential for promoting human–AI collaboration and ensuring regulatory compliance. However, interpreting these models is a complex process influenced by various methods and datasets. This study presents a comprehensive overview of foundational interpretation techniques, meticulously referencing the original authors and emphasizing their pivotal contributions. Recognizing the seminal work of these pioneers is imperative for contextualizing the evolutionary trajectory of interpretation in the field of AI. Furthermore, this research offers a retrospective analysis of interpretation techniques, critically evaluating their inherent strengths and limitations. We categorize these techniques into model-based, representation-based, post hoc, and hybrid methods, delving into their diverse applications. Furthermore, we analyze publication trends over time to see how the adoption of advanced computational methods within various categories of interpretation techniques has shaped the development of AI interpretability over time. This analysis highlights a notable preference shift towards data-driven approaches in the field. Moreover, we consider crucial factors such as the suitability of these techniques for generating local or global insights and their compatibility with different data types, including images, text, and tabular data. This structured categorization serves as a guide for practitioners navigating the landscape of interpretation techniques in AI. In summary, this review not only synthesizes various interpretation techniques but also acknowledges the contributions of their original authors. By emphasizing the origins of these techniques, we aim to enhance AI model explainability and underscore the importance of recognizing biases, uncertainties, and limitations inherent in the methods and datasets. This approach promotes the ethical and practical use of interpretation insights, empowering AI practitioners, researchers, and professionals to make informed decisions when selecting techniques for responsible AI implementation in real-world scenarios.","['model-based methods', 'representation-based methods', 'hybrid methods']"
2024,https://openalex.org/W4391723759,Social Sciences,Artificial Intelligence to Automate Network Meta-Analyses: Four Case Studies to Evaluate the Potential Application of Large Language Models,"The emergence of artificial intelligence, capable of human-level performance on some tasks, presents an opportunity to revolutionise development of systematic reviews and network meta-analyses (NMAs). In this pilot study, we aim to assess use of a large-language model (LLM, Generative Pre-trained Transformer 4 [GPT-4]) to automatically extract data from publications, write an R script to conduct an NMA and interpret the results. We considered four case studies involving binary and time-to-event outcomes in two disease areas, for which an NMA had previously been conducted manually. For each case study, a Python script was developed that communicated with the LLM via application programming interface (API) calls. The LLM was prompted to extract relevant data from publications, to create an R script to be used to run the NMA and then to produce a small report describing the analysis. The LLM had a > 99% success rate of accurately extracting data across 20 runs for each case study and could generate R scripts that could be run end-to-end without human input. It also produced good quality reports describing the disease area, analysis conducted, results obtained and a correct interpretation of the results. This study provides a promising indication of the feasibility of using current generation LLMs to automate data extraction, code generation and NMA result interpretation, which could result in significant time savings and reduce human error. This is provided that routine technical checks are performed, as recommend for human-conducted analyses. Whilst not currently 100% consistent, LLMs are likely to improve with time.","['large-language model (LLM, Generative Pre-trained Transformer 4 [GPT-4])']"
2024,https://openalex.org/W4392186815,Social Sciences,BioLORD-2023: semantic textual representations fusing large language models and clinical knowledge graph insights,"Abstract Objective In this study, we investigate the potential of large language models (LLMs) to complement biomedical knowledge graphs in the training of semantic models for the biomedical and clinical domains. Materials and Methods Drawing on the wealth of the Unified Medical Language System knowledge graph and harnessing cutting-edge LLMs, we propose a new state-of-the-art approach for obtaining high-fidelity representations of biomedical concepts and sentences, consisting of 3 steps: an improved contrastive learning phase, a novel self-distillation phase, and a weight averaging phase. Results Through rigorous evaluations of diverse downstream tasks, we demonstrate consistent and substantial improvements over the previous state of the art for semantic textual similarity (STS), biomedical concept representation (BCR), and clinically named entity linking, across 15+ datasets. Besides our new state-of-the-art biomedical model for English, we also distill and release a multilingual model compatible with 50+ languages and finetuned on 7 European languages. Discussion Many clinical pipelines can benefit from our latest models. Our new multilingual model enables a range of languages to benefit from our advancements in biomedical semantic representation learning, opening a new avenue for bioinformatics researchers around the world. As a result, we hope to see BioLORD-2023 becoming a precious tool for future biomedical applications. Conclusion In this article, we introduced BioLORD-2023, a state-of-the-art model for STS and BCR designed for the clinical domain.","['contrastive learning', 'self-distillation', 'weight averaging']"
2024,https://openalex.org/W4401726216,Social Sciences,Improving accuracy of GPT-3/4 results on biomedical data using a retrieval-augmented language model,"Large language models (LLMs) have made a significant impact on the fields of general artificial intelligence. General purpose LLMs exhibit strong logic and reasoning skills and general world knowledge but can sometimes generate misleading results when prompted on specific subject areas. LLMs trained with domain-specific knowledge can reduce the generation of misleading information (i.e. hallucinations) and enhance the precision of LLMs in specialized contexts. Training new LLMs on specific corpora however can be resource intensive. Here we explored the use of a retrieval-augmented generation (RAG) model which we tested on literature specific to a biomedical research area. OpenAI’s GPT-3.5, GPT-4, Microsoft’s Prometheus, and a custom RAG model were used to answer 19 questions pertaining to diffuse large B-cell lymphoma (DLBCL) disease biology and treatment. Eight independent reviewers assessed LLM responses based on accuracy, relevance, and readability, rating responses on a 3-point scale for each category. These scores were then used to compare LLM performance. The performance of the LLMs varied across scoring categories. On accuracy and relevance, the RAG model outperformed other models with higher scores on average and the most top scores across questions. GPT-4 was more comparable to the RAG model on relevance versus accuracy. By the same measures, GPT-4 and GPT-3.5 had the highest scores for readability of answers when compared to the other LLMs. GPT-4 and 3.5 also had more answers with hallucinations than the other LLMs, due to non-existent references and inaccurate responses to clinical questions. Our findings suggest that an oncology research-focused RAG model may outperform general-purpose LLMs in accuracy and relevance when answering subject-related questions. This framework can be tailored to Q&amp;A in other subject areas. Further research will help understand the impact of LLM architectures, RAG methodologies, and prompting techniques in answering questions across different subject areas.","['retrieval-augmented generation (RAG) model', 'OpenAI’s GPT-3.5', 'OpenAI’s GPT-4', 'Microsoft’s Prometheus']"
2024,https://openalex.org/W4403618367,Social Sciences,"Exploring Rich Subjective Quality Information for Image Quality
  Assessment in the Wild","Traditional in the wild image quality assessment (IQA) models are generally trained with the quality labels of mean opinion score (MOS), while missing the rich subjective quality information contained in the quality ratings, for example, the standard deviation of opinion scores (SOS) or even distribution of opinion scores (DOS). In this paper, we propose a novel IQA method named RichIQA to explore the rich subjective rating information beyond MOS to predict image quality in the wild. RichIQA is characterized by two key novel designs: (1) a three-stage image quality prediction network which exploits the powerful feature representation capability of the Convolutional vision Transformer (CvT) and mimics the short-term and long-term memory mechanisms of human brain; (2) a multi-label training strategy in which rich subjective quality information like MOS, SOS and DOS are concurrently used to train the quality prediction network. Powered by these two novel designs, RichIQA is able to predict the image quality in terms of a distribution, from which the mean image quality can be subsequently obtained. Extensive experimental results verify that the three-stage network is tailored to predict rich quality information, while the multi-label training strategy can fully exploit the potentials within subjective quality rating and enhance the prediction performance and generalizability of the network. RichIQA outperforms state-of-the-art competitors on multiple large-scale in the wild IQA databases with rich subjective rating labels. The code of RichIQA will be made publicly available on GitHub.",['Convolutional vision Transformer (CvT)']
2024,https://openalex.org/W4390506438,Social Sciences,Artificial intelligence for oral squamous cell carcinoma detection based on oral photographs: A comprehensive literature review,"Abstract Introduction Oral squamous cell carcinoma (OSCC) presents a significant global health challenge. The integration of artificial intelligence (AI) and computer vision holds promise for the early detection of OSCC through the analysis of digitized oral photographs. This literature review explores the landscape of AI‐driven OSCC automatic detection, assessing both the performance and limitations of the current state of the art. Materials and Methods An electronic search using several data base was conducted, and a systematic review performed in accordance with PRISMA guidelines (CRD42023441416). Results Several studies have demonstrated remarkable results for this task, consistently achieving sensitivity rates exceeding 85% and accuracy rates surpassing 90%, often encompassing around 1000 images. The review scrutinizes these studies, shedding light on their methodologies, including the use of recent machine learning and pattern recognition approaches coupled with different supervision strategies. However, comparing the results from different papers is challenging due to variations in the datasets used. Discussion Considering these findings, this review underscores the urgent need for more robust and reliable datasets in the field of OSCC detection. Furthermore, it highlights the potential of advanced techniques such as multi‐task learning, attention mechanisms, and ensemble learning as crucial tools in enhancing the accuracy and sensitivity of OSCC detection through oral photographs. Conclusion These insights collectively emphasize the transformative impact of AI‐driven approaches on early OSCC diagnosis, with the potential to significantly improve patient outcomes and healthcare practices.","['machine learning', 'multi-task learning', 'attention mechanisms', 'ensemble learning']"
2024,https://openalex.org/W4390917123,Social Sciences,Decision-making for solar panel selection using Sugeno-Weber triangular norm-based on q-rung orthopair fuzzy information,"Solar power is an alternative energy derived from the sun. Solar power is more environmentally friendly and sustainable than burning fossil fuels which releases harmful greenhouse gas emissions. Therefore, this study aims to evaluate a reliable solar panel based on certain characteristics by incorporating the theory of the decision-making process. To serve this goal, this study discusses a well-known aggregation model of the q-rung orthopair fuzzy set, which is a broader and flexible environment of fuzzy sets and intuitionistic fuzzy sets used to handle unpredictable information of human opinions. The key components of this article are to demonstrate some realistic operations of Sugeno–Weber triangular norms considering q-rung orthopair fuzzy information. These operations provide authentic estimated information during the decision-making process. We developed a class of new aggregation operators using the q-rung orthopair fuzzy information system, including q-rung orthopair fuzzy Sugeno–Weber power weighted average and q-rung orthopair fuzzy Sugeno–Weber power weighted geometric operators. Some realistic characteristics and special cases are also demonstrated to show the compatibility of the proposed methodologies. An innovative approach to the multi-attribute decision-making problem is utilized to resolve different real-life applications considering various criteria or attributes. To show the intensity and applicability of the proposed approaches, we explored a numerical example for efficient solar panel selection based on the proposed methodologies. Furthermore, we presented a comprehensive comparison technique to compare the findings of the existing methods with the proposed aggregation approaches. Finally, the proposed research work is summarized, and the future prospects are discussed.","['q-rung orthopair fuzzy set', 'q-rung orthopair fuzzy Sugeno–Weber power weighted average', 'q-rung orthopair fuzzy Sugeno–Weber power weighted geometric operators']"
2024,https://openalex.org/W4391096835,Social Sciences,Diagnostic Performance Comparison between Generative AI and Physicians: A Systematic Review and Meta-Analysis,"Abstract Background The rapid advancement of generative artificial intelligence (AI) has led to the wide dissemination of models with exceptional understanding and generation of human language. Their integration into healthcare has shown potential for improving medical diagnostics, yet a comprehensive diagnostic performance evaluation of generative AI models and the comparison of their diagnostic performance with that of physicians has not been extensively explored. Methods In this systematic review and meta-analysis, a comprehensive search of Medline, Scopus, Web of Science, Cochrane Central, and MedRxiv was conducted for studies published from June 2018 through December 2023, focusing on those that validate generative AI models for diagnostic tasks. The risk of bias was assessed using the Prediction Model Study Risk of Bias Assessment Tool. Meta-regression was performed to summarize the performance of the models and to compare the accuracy of the models with that of physicians. Results The search resulted in 54 studies being included in the meta-analysis. Nine generative AI models were evaluated across 17 medical specialties. The quality assessment indicated a high risk of bias in the majority of studies, primarily due to small sample sizes. The overall accuracy for generative AI models across 54 studies was 56.9% (95% confidence interval [CI]: 51.0–62.7%). The meta-analysis demonstrated that, on average, physicians exceeded the accuracy of the models (difference in accuracy: 14.4% [95% CI: 4.9–23.8%], p-value =0.004). However, both Prometheus (Bing) and GPT-4 showed slightly better performance compared to non-experts (-2.3% [95% CI: -27.0–22.4%], p-value = 0.848 and -0.32% [95% CI: -14.4–13.7%], p-value = 0.962), but slightly underperformed when compared to experts (10.9% [95% CI: -13.1–35.0%], p-value = 0.356 and 12.9% [95% CI: 0.15–25.7%], p-value = 0.048). The sub-analysis revealed significantly improved accuracy in the fields of Gynecology, Pediatrics, Orthopedic surgery, Plastic surgery, and Otolaryngology, while showing reduced accuracy for Neurology, Psychiatry, Rheumatology, and Endocrinology compared to that of General Medicine. No significant heterogeneity was observed based on the risk of bias. Conclusions Generative AI exhibits promising diagnostic capabilities, with accuracy varying significantly by model and medical specialty. Although they have not reached the reliability of expert physicians, the findings suggest that generative AI models have the potential to enhance healthcare delivery and medical education, provided they are integrated with caution and their limitations are well-understood. Key Points Question: What is the diagnostic accuracy of generative AI models and how does this accuracy compare to that of physicians? Findings: This meta-analysis found that generative AI models have a pooled accuracy of 56.9% (95% confidence interval: 51.0–62.7%). The accuracy of expert physicians exceeds that of AI in all specialties, however, some generative AI models are comparable to non-expert physicians. Meaning: The diagnostic performance of generative AI models suggests that they do not match the level of experienced physicians but that they may have potential applications in healthcare delivery and medical education.",['generative AI models']
2024,https://openalex.org/W4392447932,Social Sciences,Systematic Review of Large Language Models for Patient Care: Current Applications and Challenges,"Abstract The introduction of large language models (LLMs) into clinical practice promises to improve patient education and empowerment, thereby personalizing medical care and broadening access to medical knowledge. Despite the popularity of LLMs, there is a significant gap in systematized information on their use in patient care. Therefore, this systematic review aims to synthesize current applications and limitations of LLMs in patient care using a data-driven convergent synthesis approach. We searched 5 databases for qualitative, quantitative, and mixed methods articles on LLMs in patient care published between 2022 and 2023. From 4,349 initial records, 89 studies across 29 medical specialties were included, primarily examining models based on the GPT-3.5 (53.2%, n=66 of 124 different LLMs examined per study) and GPT-4 (26.6%, n=33/124) architectures in medical question answering, followed by patient information generation, including medical text summarization or translation, and clinical documentation. Our analysis delineates two primary domains of LLM limitations: design and output. Design limitations included 6 second-order and 12 third-order codes, such as lack of medical domain optimization, data transparency, and accessibility issues, while output limitations included 9 second-order and 32 third-order codes, for example, non-reproducibility, non-comprehensiveness, incorrectness, unsafety, and bias. In conclusion, this study is the first review to systematically map LLM applications and limitations in patient care, providing a foundational framework and taxonomy for their implementation and evaluation in healthcare settings.","['GPT-3.5', 'GPT-4']"
2024,https://openalex.org/W4393159297,Social Sciences,PathAsst: A Generative Foundation AI Assistant towards Artificial General Intelligence of Pathology,"As advances in large language models (LLMs) and multimodal techniques continue to mature, the development of general-purpose multimodal large language models (MLLMs) has surged, offering significant applications in interpreting natural images. However, the field of pathology has largely remained untapped, particularly in gathering high-quality data and designing comprehensive model frameworks. To bridge the gap in pathology MLLMs, we present PathAsst, a multimodal generative foundation AI assistant to revolutionize diagnostic and predictive analytics in pathology. The development of PathAsst involves three pivotal steps: data acquisition, CLIP model adaptation, and the training of PathAsst's multimodal generative capabilities. Firstly, we collect over 207K high-quality pathology image-text pairs from authoritative sources. Leveraging the advanced power of ChatGPT, we generate over 180K instruction-following samples. Furthermore, we devise additional instruction-following data specifically tailored for invoking eight pathology-specific sub-models we prepared, allowing the PathAsst to effectively collaborate with these models, enhancing its diagnostic ability. Secondly, by leveraging the collected data, we construct PathCLIP, a pathology-dedicated CLIP, to enhance PathAsst's capabilities in interpreting pathology images. Finally, we integrate PathCLIP with the Vicuna-13b and utilize pathology-specific instruction-tuning data to enhance the multimodal generation capacity of PathAsst and bolster its synergistic interactions with sub-models. The experimental results of PathAsst show the potential of harnessing AI-powered generative foundation model to improve pathology diagnosis and treatment processes. We open-source our dataset, as well as a comprehensive toolkit for extensive pathology data collection and preprocessing at https://github.com/superjamessyx/Generative-Foundation-AI-Assistant-for-Pathology.","['CLIP model adaptation', 'instruction-tuning']"
2024,https://openalex.org/W4393222088,Social Sciences,Methodological insights into ChatGPT’s screening performance in systematic reviews,"Abstract Background The screening process for systematic reviews and meta-analyses in medical research is a labor-intensive and time-consuming task. While machine learning and deep learning have been applied to facilitate this process, these methods often require training data and user annotation. This study aims to assess the efficacy of ChatGPT, a large language model based on the Generative Pretrained Transformers (GPT) architecture, in automating the screening process for systematic reviews in radiology without the need for training data. Methods A prospective simulation study was conducted between May 2nd and 24th, 2023, comparing ChatGPT’s performance in screening abstracts against that of general physicians (GPs). A total of 1198 abstracts across three subfields of radiology were evaluated. Metrics such as sensitivity, specificity, positive and negative predictive values (PPV and NPV), workload saving, and others were employed. Statistical analyses included the Kappa coefficient for inter-rater agreement, ROC curve plotting, AUC calculation, and bootstrapping for p-values and confidence intervals. Results ChatGPT completed the screening process within an hour, while GPs took an average of 7–10 days. The AI model achieved a sensitivity of 95% and an NPV of 99%, slightly outperforming the GPs’ sensitive consensus (i.e., including records if at least one person includes them). It also exhibited remarkably low false negative counts and high workload savings, ranging from 40 to 83%. However, ChatGPT had lower specificity and PPV compared to human raters. The average Kappa agreement between ChatGPT and other raters was 0.27. Conclusions ChatGPT shows promise in automating the article screening phase of systematic reviews, achieving high sensitivity and workload savings. While not entirely replacing human expertise, it could serve as an efficient first-line screening tool, particularly in reducing the burden on human resources. Further studies are needed to fine-tune its capabilities and validate its utility across different medical subfields.","['machine learning', 'deep learning', 'Generative Pretrained Transformers (GPT) architecture']"
2024,https://openalex.org/W4394835724,Social Sciences,Machine Learning-Assisted Design of Advanced Polymeric Materials,"ConspectusPolymeric material research is encountering a new paradigm driven by machine learning (ML) and big data. The ML-assisted design has proven to be a successful approach for designing novel high-performance polymeric materials. This goal is mainly achieved through the following procedure: structure representation and database construction, establishment of a ML-based property prediction model, virtual design and high-throughput screening. The key to this approach lies in training ML models that delineate structure–property relationships based on available polymer data (e.g., structure, component, and property data), enabling the screening of promising polymers that satisfy the targeted property requirements. However, the relative scarcity of high-quality polymer data and the complex polymeric multiscale structure–property relationships pose challenges for this ML-assisted design method, such as data and modeling challenges.In this Account, we summarize the state-of-the-art advancements concerning the ML-assisted design of polymeric materials. Regarding structure representation and database construction, the digital representations of polymers are the predominant methods in cheminformatics along with some newly developed methods that integrate the polymeric multiscale structure characteristics. When establishing a ML-based property prediction model, the key is choosing and optimizing ML models to attain high-precision predictions across a vast chemical structure space. Advanced ML algorithms, such as transfer learning and multitask learning, have been utilized to address the data and modeling challenges. During the ML-assisted screening process, by defining and combining polymer genes, virtual polymer candidates are generated, and subsequently, their properties are predicted and high-throughput screened using ML property prediction models. Finally, the promising polymers identified through this approach are verified by computer simulations and experiments.We provide an overview of our recent efforts toward developing ML-assisted design approaches for discovering advanced polymeric materials and emphasize the intricate nature of polymer structural design. To well describe the multiscale structures of polymers, new structure representation methods, such as polymer fingerprint and cross-linking descriptors, were developed. Moreover, a multifidelity learning method was proposed to leverage the multisource isomerous polymer data from experiments and simulations. Additionally, graph neural networks and Bayesian optimization methods have been developed and applied for predicting polymer properties as well as designing polymer structures and compositions.Finally, we identify the current challenges and point out the development directions in this emerging field. It is highly desirable to establish new structure representation and advanced ML modeling methods for polymeric materials, particularly when constructing polymer large models based on chemical language. Through this Account, we seek to stimulate further interest and foster active collaborations for developing ML-assisted design approaches and realizing the innovation of advanced polymeric materials.","['transfer learning', 'multifidelity learning', 'graph neural networks', 'Bayesian optimization']"
2024,https://openalex.org/W4395663988,Social Sciences,Navigating the Power of Artificial Intelligence in Risk Management: A Comparative Analysis,"This study presents a responsive analysis of the role of artificial intelligence (AI) in risk management, contrasting traditional approaches with those augmented by AI and highlighting the challenges and opportunities that emerge. AI, intense learning methodologies such as convolutional neural networks (CNNs), have been identified as pivotal in extracting meaningful insights from image data, a form of analysis that holds significant potential in identifying and managing risks across various industries. The research methodology involves a strategic selection and processing of images for analysis and introduces three case studies that serve as benchmarks for evaluation. These case studies showcase the application of AI, in place of image processing capabilities, to identify hazards, evaluate risks, and suggest control measures. The comparative evaluation focuses on the accuracy, relevance, and practicality of the AI-generated findings alongside the system’s response time and comprehensive understanding of the context. Results reveal that AI can significantly enhance risk assessment processes, offering rapid and detailed insights. However, the study also recognises the intrinsic limitations of AI in contextual interpretation, advocating for a synergy between technological and domain-specific expertise. The conclusion underscores the transformative potential of AI in risk management, supporting continued research to further integrate AI effectively into risk assessment frameworks.",['convolutional neural networks (CNNs)']
2024,https://openalex.org/W4398169659,Social Sciences,The Sociodemographic Biases in Machine Learning Algorithms: A Biomedical Informatics Perspective,"Artificial intelligence models represented in machine learning algorithms are promising tools for risk assessment used to guide clinical and other health care decisions. Machine learning algorithms, however, may house biases that propagate stereotypes, inequities, and discrimination that contribute to socioeconomic health care disparities. The biases include those related to some sociodemographic characteristics such as race, ethnicity, gender, age, insurance, and socioeconomic status from the use of erroneous electronic health record data. Additionally, there is concern that training data and algorithmic biases in large language models pose potential drawbacks. These biases affect the lives and livelihoods of a significant percentage of the population in the United States and globally. The social and economic consequences of the associated backlash cannot be underestimated. Here, we outline some of the sociodemographic, training data, and algorithmic biases that undermine sound health care risk assessment and medical decision-making that should be addressed in the health care system. We present a perspective and overview of these biases by gender, race, ethnicity, age, historically marginalized communities, algorithmic bias, biased evaluations, implicit bias, selection/sampling bias, socioeconomic status biases, biased data distributions, cultural biases and insurance status bias, conformation bias, information bias and anchoring biases and make recommendations to improve large language model training data, including de-biasing techniques such as counterfactual role-reversed sentences during knowledge distillation, fine-tuning, prefix attachment at training time, the use of toxicity classifiers, retrieval augmented generation and algorithmic modification to mitigate the biases moving forward.","['knowledge distillation', 'fine-tuning', 'retrieval augmented generation']"
2024,https://openalex.org/W4399363436,Social Sciences,Collective Constitutional AI: Aligning a Language Model with Public Input,"There is growing consensus that language model (LM) developers should not be the sole deciders of LM behavior, creating a need for methods that enable the broader public to collectively shape the behavior of LM systems that affect them. To address this need, we present Collective Constitutional AI (CCAI): a multi-stage process for sourcing and integrating public input into LMs—from identifying a target population to sourcing principles to training and evaluating a model. We demonstrate the real-world practicality of this approach by creating what is, to our knowledge, the first LM fine-tuned with collectively sourced public input and evaluating this model against a baseline model trained with established principles from a LM developer. Our quantitative evaluations demonstrate several benefits of our approach: the CCAI-trained model shows lower bias across nine social dimensions compared to the baseline model, while maintaining equivalent performance on language, math, and helpful-harmless evaluations. Qualitative comparisons of the models suggest that the models differ on the basis of their respective constitutions, e.g., when prompted with contentious topics, the CCAI-trained model tends to generate responses that reframe the matter positively instead of a refusal. These results demonstrate a promising, tractable pathway toward publicly informed development of language models.",['fine-tuning']
2024,https://openalex.org/W4399715357,Social Sciences,AI-POWERED FRAUD DETECTION IN BANKING: SAFEGUARDING FINANCIAL TRANSACTIONS,"The banking industry's metamorphosis through digitalization has unquestionably revolutionized accessibility and convenience for customers worldwide. However, this paradigm shift has ushered in a new era of challenges, most notably in the realm of cybersecurity. Conventional rule-based fraud detection strategies have struggled to keep pace with the rapid evolution of cyber threats, prompting a surge of interest in more adaptive approaches like unsupervised learning. Furthermore, the COVID-19 pandemic has exacerbated the issue of bank fraud due to the widespread transition to online platforms and the proliferation of charitable funds, which present ripe opportunities for exploitation by cybercriminals. In response to these pressing concerns, this study delves into the realm of machine learning algorithms for the analysis and identification of fraudulent banking transactions. Notably, it contributes scientific novelty by developing models specifically tailored to this purpose and implementing innovative preprocessing techniques to enhance detection accuracy. Utilizing a diverse array of algorithms, including Random Forest, K-Nearest Neighbor (KNN), Naïve Bayes, Decision Trees, and Logistic Regression, the study showcases promising results. In particular, logistic regression and decision tree models exhibit impressive accuracy and Area Under the Curve (AUC) values of approximately 0.98, 0.97 and 0.95, 0.94, respectively. Given the pervasive nature of banking fraud in our digital society, the utilization of artificial intelligence algorithms for fraud detection stands as a critical and timely endeavor, promising enhanced security and trust in the financial ecosystem.","['unsupervised learning', 'Random Forest', 'K-Nearest Neighbor (KNN)', 'Naïve Bayes', 'Decision Trees', 'Logistic Regression']"
2024,https://openalex.org/W4390933379,Social Sciences,"A Systematic Review of Graph Neural Network in Healthcare-Based Applications: Recent Advances, Trends, and Future Directions","Graph neural network (GNN) is a formidable deep learning framework that enables the analysis and modeling of intricate relationships present in data structured as graphs. In recent years, a burgeoning interest has arisen in exploiting the latent capabilities of GNN for healthcare-based applications, capitalizing on their aptitude for modeling complex relationships and unearthing profound insights from graph-structured data. However, to the best of our knowledge, no study has systemically reviewed the GNN studies conducted in the healthcare domain. This study has furnished an all-encompassing and erudite overview of the prevailing cutting-edge research on GNN in healthcare. Through analysis and assimilation of studies, current research trends, recurrent challenges, and promising future opportunities in GNN for healthcare applications have been identified. China emerged as the leading country to conduct GNN-based studies in the healthcare domain, followed by the USA, UK, and Turkey. Among various aspects of healthcare, disease prediction and drug discovery emerge as the most prominent areas of focus for GNN application, indicating the potential of GNN for advancing diagnostic and therapeutic approaches. This study proposed research questions regarding diverse aspects of GNN in the healthcare domain and addressed them through an in-depth analysis. This study can provide practitioners and researchers with profound insights into the current landscape of GNN applications in healthcare and can guide healthcare institutes, researchers, and governments by demonstrating the ways in which GNN can contribute to the development of effective and efficient healthcare systems.",['Graph neural network (GNN)']
2024,https://openalex.org/W4390765902,Social Sciences,Pseudo-spectral angle mapping for automated pixel-level analysis of highly multiplexed tissue image data,"Abstract The rapid development of highly multiplexed microscopy systems has enabled the study of cells embedded within their native tissue, which is providing exciting insights into the spatial features of human disease [1]. However, computational methods for analyzing these high-content images are still emerging, and there is a need for more robust and generalizable tools for evaluating the cellular constituents and underlying stroma captured by high-plex imaging [2]. To address this need, we have adapted spectral angle mapping – an algorithm used widely in hyperspectral image analysis – to compress the channel dimension of high-plex immunofluorescence images. As many high-plex immunofluorescence imaging experiments probe unique sets of protein markers, existing cell and pixel classification models do not typically generalize well. Pseudospectral angle mapping (pSAM) uses reference pseudospectra – or pixel vectors – to assign each pixel in an image a similarity score to several cell class reference vectors, which are defined by each unique staining panel. Here, we demonstrate that the class maps provided by pSAM can directly provide insight into the prevalence of each class defined by reference pseudospectra. In a dataset of high-plex images of colon biopsies from patients with gut autoimmune conditions, sixteen pSAM class representation maps were combined with instance segmentation of cells to provide cell class predictions. Finally, pSAM detected a diverse set of structure and immune cells when applied to a novel dataset of kidney biopsies imaged with a 43-marker panel. In summary, pSAM provides a powerful and readily generalizable method for evaluating high-plex immunofluorescence image data. Significance Statement Understanding the cellular constituents captured by highly multiplexed tissue imaging is a major limitation affecting the usability of these novel imaging methods. Many imaging experiments have uniquely designed staining panels, reducing the generalizability of cell classification models to new datasets. We present pseudospectral angle mapping (pSAM), which can compress high-dimensional image data into class representations. We demonstrate that the class representations generated by pSAM can be used to interpret high-plex image data and guide cell classification. Importantly, we also demonstrate that pSAM can generalize to new image datasets—collected with a different staining panel in samples from different tissues—without manual image annotation, subjective intensity gating, or re-training an algorithm.",['spectral angle mapping']
