year,openalex_id,domain,title,abstract,extracted methods,verified extracted methods
2024,https://openalex.org/W4392173735,Biology,"A Comprehensive Survey of Continual Learning: Theory, Method and Application","To cope with real-world dynamics, an intelligent system needs to incrementally acquire, update, accumulate, and exploit knowledge throughout its lifetime. This ability, known as continual learning, provides a foundation for AI systems to develop themselves adaptively. In a general sense, continual learning is explicitly limited by catastrophic forgetting, where learning a new task usually results in a dramatic performance drop of the old tasks. Beyond this, increasingly numerous advances have emerged in recent years that largely extend the understanding and application of continual learning. The growing and widespread interest in this direction demonstrates its realistic significance as well as complexity. In this work, we present a comprehensive survey of continual learning, seeking to bridge the basic settings, theoretical foundations, representative methods, and practical applications. Based on existing theoretical and empirical results, we summarize the general objectives of continual learning as ensuring a proper stability-plasticity trade-off and an adequate intra/inter-task generalizability in the context of resource efficiency. Then we provide a state-of-the-art and elaborated taxonomy, extensively analyzing how representative strategies address continual learning, and how they are adapted to particular challenges in various applications. Through an in-depth discussion of promising directions, we believe that such a holistic perspective can greatly facilitate subsequent exploration in this field and beyond.",<method>continual learning</method>,<method>continual learning</method>
2024,https://openalex.org/W4392984771,Biology,Global prediction of extreme floods in ungauged watersheds,"Abstract Floods are one of the most common natural disasters, with a disproportionate impact in developing countries that often lack dense streamflow gauge networks 1 . Accurate and timely warnings are critical for mitigating flood risks 2 , but hydrological simulation models typically must be calibrated to long data records in each watershed. Here we show that artificial intelligence-based forecasting achieves reliability in predicting extreme riverine events in ungauged watersheds at up to a five-day lead time that is similar to or better than the reliability of nowcasts (zero-day lead time) from a current state-of-the-art global modelling system (the Copernicus Emergency Management Service Global Flood Awareness System). In addition, we achieve accuracies over five-year return period events that are similar to or better than current accuracies over one-year return period events. This means that artificial intelligence can provide flood warnings earlier and over larger and more impactful events in ungauged basins. The model developed here was incorporated into an operational early warning system that produces publicly available (free and open) forecasts in real time in over 80 countries. This work highlights a need for increasing the availability of hydrological data to continue to improve global access to reliable flood warnings.",<method>artificial intelligence-based forecasting</method>,No methods remaining
2024,https://openalex.org/W4392872715,Biology,GLC_FCS30D: the first global 30 m land-cover dynamics monitoring product with a fine classification system for the period from 1985 to 2022 generated using dense-time-series Landsat imagery and the continuous change-detection method,"Abstract. Land-cover change has been identified as an important cause or driving force of global climate change and is a significant research topic. Over the past few decades, global land-cover mapping has progressed; however, long-time-series global land-cover-change monitoring data are still sparse, especially those at 30 m resolution. In this study, we describe GLC_FCS30D, a novel global 30 m land-cover dynamics monitoring dataset containing 35 land-cover subcategories and covering the period 1985–2022 in 26 time steps (maps were updated every 5 years before 2000 and annually after 2000). GLC_FCS30D has been developed using continuous change detection and all available Landsat imagery based on the Google Earth Engine platform. Specifically, we first take advantage of the continuous change-detection model and the full time series of Landsat observations to capture the time points of changed pixels and identify the temporally stable areas. Then, we apply a spatiotemporal refinement method to derive the globally distributed and high-confidence training samples from these temporally stable areas. Next, local adaptive classification models are used to update the land-cover information for the changed pixels, and a temporal-consistency optimization algorithm is adopted to improve their temporal stability and suppress some false changes. Further, the GLC_FCS30D product is validated using 84 526 globally distributed validation samples from 2020. It achieves an overall accuracy of 80.88 % (±0.27 %) for the basic classification system (10 major land-cover types) and 73.04 % (±0.30 %) for the LCCS (Land Cover Classification System) level-1 validation system (17 LCCS land-cover types). Meanwhile, two third-party time-series datasets used for validation from the United States and Europe Union are also collected for analyzing accuracy variations, and the results show that GLC_FCS30D offers significant stability in terms of variation across the accuracy time series and achieves mean accuracies of 79.50 % (±0.50 %) and 81.91 % (±0.09 %) over the two regions. Lastly, we draw conclusions about the global land-cover-change information from the GLC_FCS30D dataset; namely, that forest and cropland variations have dominated global land-cover change over past 37 years, the net loss of forests reached about 2.5 million km2, and the net gain in cropland area is approximately 1.3 million km2. Therefore, the novel dataset GLC_FCS30D is an accurate land-cover-dynamics time-series monitoring product that benefits from its diverse classification system, high spatial resolution, and long time span (1985–2022); thus, it will effectively support global climate change research and promote sustainable development analysis. The GLC_FCS30D dataset is available via https://doi.org/10.5281/zenodo.8239305 (Liu et al., 2023).","<method>continuous change-detection model</method>, <method>spatiotemporal refinement method</method>, <method>local adaptive classification models</method>, <method>temporal-consistency optimization algorithm</method>",No methods remaining
2024,https://openalex.org/W1578086085,Biology,Genotype by Environment Interaction and Adaptation in Barley Breeding: Basic Concepts and Methods of Analysis,"Genotype by environment interaction (GE) has important consequences in barley breeding. It often complicates testing and selection of superior genotypes, reducing genetic progress in breeding programs. This drawback may be overcome by a better understanding of the genetic and environmental factors that determine GE and adaptation of genotypes. An important array of statistical techniques is nowadays available to breeders and researchers to cope with the presence of relevant GE in multi-environment trials. This paper begins with a review of recent literature on the latest barley studies on GE and adaptation, including potential biotic and abiotic causes underlying GE. Most studies reported are empirical, describing postdictively genotypic performance across environments. As an alternative, methods allowing a more analytical approach are proposed, in which genotypes and environments are characterized in terms of external variables that affect genotypic performance. These methods are applied to a real barley data set. After data description, a number of selected multiplicative models are developed, namely the additive main effects and multiplicative interaction (AMMI) model, and the factorial regression model. Finally, the implications of GE in barley breeding are discussed. As an appendix, the SAS programs are given for the models described. Key-words: genotype by environment interaction, adaptation, AMMI, factorial regression, breeding programs","<method>additive main effects and multiplicative interaction (AMMI) model</method>, <method>factorial regression model</method>",<method>additive main effects and multiplicative interaction (AMMI) model</method>
2024,https://openalex.org/W4392754729,Biology,"Revolutionizing agriculture with artificial intelligence: plant disease detection methods, applications, and their limitations","Accurate and rapid plant disease detection is critical for enhancing long-term agricultural yield. Disease infection poses the most significant challenge in crop production, potentially leading to economic losses. Viruses, fungi, bacteria, and other infectious organisms can affect numerous plant parts, including roots, stems, and leaves. Traditional techniques for plant disease detection are time-consuming, require expertise, and are resource-intensive. Therefore, automated leaf disease diagnosis using artificial intelligence (AI) with Internet of Things (IoT) sensors methodologies are considered for the analysis and detection. This research examines four crop diseases: tomato, chilli, potato, and cucumber. It also highlights the most prevalent diseases and infections in these four types of vegetables, along with their symptoms. This review provides detailed predetermined steps to predict plant diseases using AI. Predetermined steps include image acquisition, preprocessing, segmentation, feature selection, and classification. Machine learning (ML) and deep understanding (DL) detection models are discussed. A comprehensive examination of various existing ML and DL-based studies to detect the disease of the following four crops is discussed, including the datasets used to evaluate these studies. We also provided the list of plant disease detection datasets. Finally, different ML and DL application problems are identified and discussed, along with future research prospects, by combining AI with IoT platforms like smart drones for field-based disease detection and monitoring. This work will help other practitioners in surveying different plant disease detection strategies and the limits of present systems.","<method>artificial intelligence (AI)</method>, <method>machine learning (ML)</method>, <method>deep learning (DL)</method>",<method>machine learning (ML)</method><method>deep learning (DL)</method>
2024,https://openalex.org/W4390946589,Biology,Deep-STP: a deep learning-based approach to predict snake toxin proteins by using word embeddings,"Snake venom contains many toxic proteins that can destroy the circulatory system or nervous system of prey. Studies have found that these snake venom proteins have the potential to treat cardiovascular and nervous system diseases. Therefore, the study of snake venom protein is conducive to the development of related drugs. The research technologies based on traditional biochemistry can accurately identify these proteins, but the experimental cost is high and the time is long. Artificial intelligence technology provides a new means and strategy for large-scale screening of snake venom proteins from the perspective of computing. In this paper, we developed a sequence-based computational method to recognize snake toxin proteins. Specially, we utilized three different feature descriptors, namely g-gap , natural vector and word 2 vector, to encode snake toxin protein sequences. The analysis of variance (ANOVA), gradient-boost decision tree algorithm (GBDT) combined with incremental feature selection (IFS) were used to optimize the features, and then the optimized features were input into the deep learning model for model training. The results show that our model can achieve a prediction performance with an accuracy of 82.00% in 10-fold cross-validation. The model is further verified on independent data, and the accuracy rate reaches to 81.14%, which demonstrated that our model has excellent prediction performance and robustness.","<method>gradient-boost decision tree algorithm (GBDT)</method>, <method>incremental feature selection (IFS)</method>, <method>deep learning model</method>",<method>gradient-boost decision tree algorithm (GBDT)</method><method>incremental feature selection (IFS)</method><method>deep learning model</method>
2024,https://openalex.org/W4392791588,Biology,Can large language models replace humans in systematic reviews? Evaluating <scp>GPT</scp>‐4's efficacy in screening and extracting data from peer‐reviewed and grey literature in multiple languages,"Systematic reviews are vital for guiding practice, research and policy, although they are often slow and labour-intensive. Large language models (LLMs) could speed up and automate systematic reviews, but their performance in such tasks has yet to be comprehensively evaluated against humans, and no study has tested Generative Pre-Trained Transformer (GPT)-4, the biggest LLM so far. This pre-registered study uses a ""human-out-of-the-loop"" approach to evaluate GPT-4's capability in title/abstract screening, full-text review and data extraction across various literature types and languages. Although GPT-4 had accuracy on par with human performance in some tasks, results were skewed by chance agreement and dataset imbalance. Adjusting for these caused performance scores to drop across all stages: for data extraction, performance was moderate, and for screening, it ranged from none in highly balanced literature datasets (~1:1) to moderate in those datasets where the ratio of inclusion to exclusion in studies was imbalanced (~1:3). When screening full-text literature using highly reliable prompts, GPT-4's performance was more robust, reaching ""human-like"" levels. Although our findings indicate that, currently, substantial caution should be exercised if LLMs are being used to conduct systematic reviews, they also offer preliminary evidence that, for certain review tasks delivered under specific conditions, LLMs can rival human performance.","<method>Large language models (LLMs)</method>, <method>Generative Pre-Trained Transformer (GPT)-4</method>",<method>Generative Pre-Trained Transformer (GPT)-4</method>
2024,https://openalex.org/W4399777548,Biology,Feature reduction for hepatocellular carcinoma prediction using machine learning algorithms,"Abstract Hepatocellular carcinoma (HCC) is a highly prevalent form of liver cancer that necessitates accurate prediction models for early diagnosis and effective treatment. Machine learning algorithms have demonstrated promising results in various medical domains, including cancer prediction. In this study, we propose a comprehensive approach for HCC prediction by comparing the performance of different machine learning algorithms before and after applying feature reduction methods. We employ popular feature reduction techniques, such as weighting features, hidden features correlation, feature selection, and optimized selection, to extract a reduced feature subset that captures the most relevant information related to HCC. Subsequently, we apply multiple algorithms, including Naive Bayes, support vector machines (SVM), Neural Networks, Decision Tree, and K nearest neighbors (KNN), to both the original high-dimensional dataset and the reduced feature set. By comparing the predictive accuracy, precision, F Score, recall, and execution time of each algorithm, we assess the effectiveness of feature reduction in enhancing the performance of HCC prediction models. Our experimental results, obtained using a comprehensive dataset comprising clinical features of HCC patients, demonstrate that feature reduction significantly improves the performance of all examined algorithms. Notably, the reduced feature set consistently outperforms the original high-dimensional dataset in terms of prediction accuracy and execution time. After applying feature reduction techniques, the employed algorithms, namely decision trees, Naive Bayes, KNN, neural networks, and SVM achieved accuracies of 96%, 97.33%, 94.67%, 96%, and 96.00%, respectively.","<method>Naive Bayes</method>, <method>support vector machines (SVM)</method>, <method>Neural Networks</method>, <method>Decision Tree</method>, <method>K nearest neighbors (KNN)</method>",<method>Naive Bayes</method><method>support vector machines (SVM)</method><method>Neural Networks</method><method>Decision Tree</method><method>K nearest neighbors (KNN)</method>
2024,https://openalex.org/W4391019749,Biology,CIFAKE: Image Classification and Explainable Identification of AI-Generated Synthetic Images,"Recent advances in synthetic data have enabled the generation of images with such high quality that human beings cannot tell the difference between real-life photographs and Artificial Intelligence (AI) generated images. Given the critical necessity of data reliability and authentication, this article proposes to enhance our ability to recognise AI-generated images through computer vision. Initially, a synthetic dataset is generated that mirrors the ten classes of the already available CIFAR-10 dataset with latent diffusion, providing a contrasting set of images for comparison to real photographs. The model is capable of generating complex visual attributes, such as photorealistic reflections in water. The two sets of data present as a binary classification problem with regard to whether the photograph is real or generated by AI. This study then proposes the use of a Convolutional Neural Network (CNN) to classify the images into two categories; Real or Fake. Following hyperparameter tuning and the training of 36 individual network topologies, the optimal approach could correctly classify the images with 92.98% accuracy. Finally, this study implements explainable AI via Gradient Class Activation Mapping to explore which features within the images are useful for classification. Interpretation reveals interesting concepts within the image, in particular, noting that the actual entity itself does not hold useful information for classification; instead, the model focuses on small visual imperfections in the background of the images. The complete dataset engineered for this study, referred to as the CIFAKE dataset, is made publicly available to the research community for future work.","<method>latent diffusion</method>, <method>Convolutional Neural Network (CNN)</method>, <method>hyperparameter tuning</method>, <method>Gradient Class Activation Mapping</method>",<method>latent diffusion</method><method>Convolutional Neural Network (CNN)</method><method>Gradient Class Activation Mapping</method>
2024,https://openalex.org/W4395050972,Biology,Optimization of hepatological clinical guidelines interpretation by large language models: a retrieval augmented generation-based framework,"Abstract Large language models (LLMs) can potentially transform healthcare, particularly in providing the right information to the right provider at the right time in the hospital workflow. This study investigates the integration of LLMs into healthcare, specifically focusing on improving clinical decision support systems (CDSSs) through accurate interpretation of medical guidelines for chronic Hepatitis C Virus infection management. Utilizing OpenAI’s GPT-4 Turbo model, we developed a customized LLM framework that incorporates retrieval augmented generation (RAG) and prompt engineering. Our framework involved guideline conversion into the best-structured format that can be efficiently processed by LLMs to provide the most accurate output. An ablation study was conducted to evaluate the impact of different formatting and learning strategies on the LLM’s answer generation accuracy. The baseline GPT-4 Turbo model’s performance was compared against five experimental setups with increasing levels of complexity: inclusion of in-context guidelines, guideline reformatting, and implementation of few-shot learning. Our primary outcome was the qualitative assessment of accuracy based on expert review, while secondary outcomes included the quantitative measurement of similarity of LLM-generated responses to expert-provided answers using text-similarity scores. The results showed a significant improvement in accuracy from 43 to 99% ( p &lt; 0.001), when guidelines were provided as context in a coherent corpus of text and non-text sources were converted into text. In addition, few-shot learning did not seem to improve overall accuracy. The study highlights that structured guideline reformatting and advanced prompt engineering (data quality vs. data quantity) can enhance the efficacy of LLM integrations to CDSSs for guideline delivery.","<method>Large language models (LLMs)</method>, <method>OpenAI’s GPT-4 Turbo model</method>, <method>retrieval augmented generation (RAG)</method>, <method>prompt engineering</method>, <method>few-shot learning</method>",<method>OpenAI’s GPT-4 Turbo model</method><method>retrieval augmented generation (RAG)</method><method>few-shot learning</method>
2024,https://openalex.org/W4399885374,Biology,Survival Prediction Across Diverse Cancer Types Using Neural Networks,"Gastric cancer and Colon adenocarcinoma represent widespread and challenging malignancies with high mortality rates and complex treatment landscapes. In response to the critical need for accurate prognosis in cancer patients, the medical community has embraced the 5-year survival rate as a vital metric for estimating patient outcomes. This study introduces a pioneering approach to enhance survival prediction models for gastric and Colon adenocarcinoma patients. Leveraging advanced image analysis techniques, we sliced whole slide images (WSI) of these cancers, extracting comprehensive features to capture nuanced tumor characteristics. Subsequently, we constructed patient-level graphs, encapsulating intricate spatial relationships within tumor tissues. These graphs served as inputs for a sophisticated 4-layer graph convolutional neural network (GCN), designed to exploit the inherent connectivity of the data for comprehensive analysis and prediction. By integrating patients' total survival time and survival status, we computed C-index values for gastric cancer and Colon adenocarcinoma, yielding 0.57 and 0.64, respectively. Significantly surpassing previous convolutional neural network models, these results underscore the efficacy of our approach in accurately predicting patient survival outcomes. This research holds profound implications for both the medical and AI communities, offering insights into cancer biology and progression while advancing personalized treatment strategies. Ultimately, our study represents a significant stride in leveraging AI-driven methodologies to revolutionize cancer prognosis and improve patient outcomes on a global scale.","<method>graph convolutional neural network (GCN)</method>, <method>convolutional neural network</method>",<method>graph convolutional neural network (GCN)</method><method>convolutional neural network</method>
2024,https://openalex.org/W4390652362,Biology,A comprehensive review of the development of land use regression approaches for modeling spatiotemporal variations of ambient air pollution: A perspective from 2011 to 2023,"Land use regression (LUR) models are widely used in epidemiological and environmental studies to estimate humans' exposure to air pollution within urban areas. However, the early models, developed using linear regressions and data from fixed monitoring stations and passive sampling, were primarily designed to model traditional and criteria air pollutants and had limitations in capturing high-resolution spatiotemporal variations of air pollution. Over the past decade, there has been a notable development of multi-source observations from low-cost monitors, mobile monitoring, and satellites, in conjunction with the integration of advanced statistical methods and spatially and temporally dynamic predictors, which have facilitated significant expansion and advancement of LUR approaches. This paper reviews and synthesizes the recent advances in LUR approaches from the perspectives of the changes in air quality data acquisition, novel predictor variables, advances in model-developing approaches, improvements in validation methods, model transferability, and modeling software as reported in 155 LUR studies published between 2011 and 2023. We demonstrate that these developments have enabled LUR models to be developed for larger study areas and encompass a wider range of criteria and unregulated air pollutants. LUR models in the conventional spatial structure have been complemented by more complex spatiotemporal structures. Compared with linear models, advanced statistical methods yield better predictions when handling data with complex relationships and interactions. Finally, this study explores new developments, identifies potential pathways for further breakthroughs in LUR methodologies, and proposes future research directions. In this context, LUR approaches have the potential to make a significant contribution to future efforts to model the patterns of long- and short-term exposure of urban populations to air pollution.","<method>linear regressions</method>, <method>advanced statistical methods</method>",No methods remaining
2024,https://openalex.org/W4400659510,Biology,Aspect-based drug review classification through a hybrid model with ant colony optimization using deep learning,"Abstract The task of aspect-level sentiment analysis is intricately designed to determine the sentiment polarity directed towards a specific target within a sentence. With the increasing availability of online reviews and the growing importance of healthcare decisions, analyzing drug reviews has become a critical task. Traditional sentiment analysis, which categorizes a whole review as positive, negative, or neutral, provides limited insights for consumers and healthcare professionals. Aspect-based sentiment analysis (ABSA) aims to overcome these limitations by identifying and evaluating the sentiment associated with specific aspects or attributes of drugs mentioned in the reviews. Various fields, including business, politics, and medicine, have been explored in the context of sentiment analysis. Automation of online user reviews allows pharmaceutical companies to assess large amounts of user feedback. This helps extract pharmacological efficacy and side effect insights. The data collected could improve pharmacovigilance. Reviewing user comments can provide valuable data that can be used to improve drug safety and efficacy monitoring procedures. This improves pharmacovigilance processes, improving pharmaceutical outcomes understanding and corporate decision-making. Therefore, we propose a pre-trained RoBERTa with a Bi-LSTM model to categorise drug reviews from online sources and pre-process the text data. Ant Colony Optimization can be used in feature selection for ABSA, helping to identify the most relevant aspects and sentiments. Further, RoBERTa is fine-tuned to perform ABSA on the dataset, enabling the system to categorize aspects and determine the associated sentiment. The outcomes reveal that the suggested framework has achieved higher accuracy (96.78%) and F1 score (98.29%) on druglib.com, and 95.02% on the drugs.com dataset, than several prior state-of-the-art methods.","<method>pre-trained RoBERTa</method>, <method>Bi-LSTM model</method>, <method>Ant Colony Optimization</method>, <method>fine-tuned RoBERTa</method>",<method>pre-trained RoBERTa</method><method>Bi-LSTM model</method><method>fine-tuned RoBERTa</method>
2024,https://openalex.org/W4390494339,Biology,"A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection in Industrial Time Series: Methods, Applications, and Directions","Automating the monitoring of industrial processes has the potential to enhance efficiency and optimize quality by promptly detecting abnormal events and thus facilitating timely interventions. Deep learning, with its capacity to discern non-trivial patterns within large datasets, plays a pivotal role in this process. Standard deep learning methods are suitable to solve a specific task given a specific type of data. During training, deep learning demands large volumes of labeled data. However, due to the dynamic nature of the industrial processes and environment, it is impractical to acquire large-scale labeled data for standard deep learning training for every slightly different case anew. Deep transfer learning offers a solution to this problem. By leveraging knowledge from related tasks and accounting for variations in data distributions, the transfer learning framework solves new tasks with little or even no additional labeled data. The approach bypasses the need to retrain a model from scratch for every new setup and dramatically reduces the labeled data requirement. This survey first provides an in-depth review of deep transfer learning, examining the problem settings of transfer learning and classifying the prevailing deep transfer learning methods. Moreover, we delve into applications of deep transfer learning in the context of a broad spectrum of time series anomaly detection tasks prevalent in primary industrial domains, e.g., manufacturing process monitoring, predictive maintenance, energy management, and infrastructure facility monitoring. We discuss the challenges and limitations of deep transfer learning in industrial contexts and conclude the survey with practical directions and actionable suggestions to address the need to leverage diverse time series data for anomaly detection in an increasingly dynamic production environment.","<method>deep learning</method>, <method>standard deep learning methods</method>, <method>deep transfer learning</method>, <method>transfer learning framework</method>",<method>deep learning</method><method>deep transfer learning</method><method>transfer learning framework</method>
2024,https://openalex.org/W4399326707,Biology,Enhancing precision agriculture: A comprehensive review of machine learning and AI vision applications in all-terrain vehicle for farm automation,"The automation of all-terrain vehicles (ATVs) through the integration of advanced technologies such as machine learning (ML) and artificial intelligence (AI) vision has significantly changed precision agriculture. This paper aims to analyse and develop trends to provide comprehensive knowledge of the current state of ATV-based precision agriculture and the future possibilities of ML and AI. A bibliometric analysis was conducted through network diagram with keywords taken from previous publications in the domain. This review comprehensively analyses the potential of machine learning and artificial intelligence in transforming farming operations through the automation of tasks and the deployment of all-terrain vehicles. The research extensively analyses how machine learning methods have influenced several aspects of agricultural activities, such as planting, harvesting, spraying, weeding, crop monitoring, and others. AI vision systems are being researched for their ability to enhance precise and prompt decision-making in ATV-driven agricultural automation. These technologies have been thoroughly tested to show how they can improve crop yield, reducing overall investment, and make farming more efficient. Examples include machine learning-based seeding accuracy, AI-enabled crop health monitoring, and the use of AI vision for accurate pesticide application. The assessment examines challenges such as data privacy problems and scalability constraints, along with potential advancements and future prospects in the field. This will assist researchers and practitioners in making well-informed judgments regarding farming practices that are efficient, sustainable, and technologically robust.","<method>machine learning</method>, <method>artificial intelligence vision</method>, <method>machine learning methods</method>, <method>AI vision systems</method>, <method>machine learning-based seeding accuracy</method>, <method>AI-enabled crop health monitoring</method>, <method>AI vision for accurate pesticide application</method>",<method>machine learning</method>
2024,https://openalex.org/W4394579747,Biology,An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing: Algorithm Development and Validation Study,"Background Large language models (LLMs) have shown remarkable capabilities in natural language processing (NLP), especially in domains where labeled data are scarce or expensive, such as the clinical domain. However, to unlock the clinical knowledge hidden in these LLMs, we need to design effective prompts that can guide them to perform specific clinical NLP tasks without any task-specific training data. This is known as in-context learning, which is an art and science that requires understanding the strengths and weaknesses of different LLMs and prompt engineering approaches. Objective The objective of this study is to assess the effectiveness of various prompt engineering techniques, including 2 newly introduced types—heuristic and ensemble prompts, for zero-shot and few-shot clinical information extraction using pretrained language models. Methods This comprehensive experimental study evaluated different prompt types (simple prefix, simple cloze, chain of thought, anticipatory, heuristic, and ensemble) across 5 clinical NLP tasks: clinical sense disambiguation, biomedical evidence extraction, coreference resolution, medication status extraction, and medication attribute extraction. The performance of these prompts was assessed using 3 state-of-the-art language models: GPT-3.5 (OpenAI), Gemini (Google), and LLaMA-2 (Meta). The study contrasted zero-shot with few-shot prompting and explored the effectiveness of ensemble approaches. Results The study revealed that task-specific prompt tailoring is vital for the high performance of LLMs for zero-shot clinical NLP. In clinical sense disambiguation, GPT-3.5 achieved an accuracy of 0.96 with heuristic prompts and 0.94 in biomedical evidence extraction. Heuristic prompts, alongside chain of thought prompts, were highly effective across tasks. Few-shot prompting improved performance in complex scenarios, and ensemble approaches capitalized on multiple prompt strengths. GPT-3.5 consistently outperformed Gemini and LLaMA-2 across tasks and prompt types. Conclusions This study provides a rigorous evaluation of prompt engineering methodologies and introduces innovative techniques for clinical information extraction, demonstrating the potential of in-context learning in the clinical domain. These findings offer clear guidelines for future prompt-based clinical NLP research, facilitating engagement by non-NLP experts in clinical NLP advancements. To the best of our knowledge, this is one of the first works on the empirical evaluation of different prompt engineering approaches for clinical NLP in this era of generative artificial intelligence, and we hope that it will inspire and inform future research in this area.","<method>in-context learning</method>, <method>prompt engineering</method>, <method>heuristic prompts</method>, <method>ensemble prompts</method>, <method>simple prefix prompts</method>, <method>simple cloze prompts</method>, <method>chain of thought prompts</method>, <method>anticipatory prompts</method>, <method>few-shot prompting</method>, <method>zero-shot prompting</method>",<method>in-context learning</method><method>few-shot prompting</method><method>zero-shot prompting</method>
2024,https://openalex.org/W4397001018,Biology,A systematic review of hyperspectral imaging in precision agriculture: Analysis of its current state and future prospects,"Hyperspectral sensor adaptability in precision agriculture to digital images is still at its nascent stage. Hyperspectral imaging (HSI) is data rich in solving agricultural problems like disease detection, weed detection, stress detection, crop monitoring, nutrient application, soil mineralogy, yield estimation, and sorting applications. With modern precision agriculture, the challenge now is to bring these applications to the field for real-time solutions, where machines are enabled to conduct analyses without expert supervision and communicate the results to users for better management of farmlands; a necessary step to gain complete autonomy in agricultural farmlands. Significant advancements in HSI technology for precision agriculture are required to fully realize its potential. As a wide-ranging collection of the status of HSI and analysis in precision agriculture is lacking, this review endeavors to provide a comprehensive overview of the recent advancements and trends of HSI in precision agriculture for real-time applications. In this study, a systematic review of 163 scientific articles published over the past twenty years (2003–2023) was conducted. Of these, 97 were selected for further analysis based on their relevance to the topic at hand. Topics include conventional data preprocessing techniques, hyperspectral data acquisition, data compression methods, and segmentation methods. The hardware implementation of field-programmable gate arrays (FPGAs) and graphics processing units (GPUs) for high-speed data processing and application of machine learning and deep learning technologies were explored. This review highlights the potential of HSI as a powerful tool for precision agriculture, particularly in real-time applications, discusses limitations, and provides insights into future research directions.","<method>machine learning</method>, <method>deep learning</method>",<method>machine learning</method><method>deep learning</method>
2024,https://openalex.org/W4398782611,Biology,Transition versus physical climate risk pricing in European financial markets: a text-based approach,"Under its climate regulation, the EU is expected to become the first continent with a net-zero emissions balance. We study the pricing of climate risks, physical and transition, within European markets. Using text-analysis, we construct two novel (daily) physical and transition risk indicators for the period 2005–2021 and two global climate risk vocabularies. Applying our climate risk indices to an asset pricing test framework, we document the emergence of economically significant transition and physical risk premia post-2015. From a firm-level analysis, using firms' GHG emissions, GHG emissions intensity, environmental, and ESG scores, we find that rises in transition (physical) risk are typically associated with an increase (decrease) in the return of green (brown) stocks. Firm-level information is used by investors to proxy firms' climate-risks exposure, especially for transition risk since 2015, whereas the sectoral classification appears to proxy firms' exposures to physical risk. From a country-level analysis emerges an intensified connection between European stock markets and climate risks post-2015, yet with some heterogeneity. Our results have important economic implications and show that investors demand compensation for their exposure to both climate risk types. Our novel climate risk vocabularies and indicators find several applications in identifying, measuring, and studying climate risks.",<method>text-analysis</method>,No methods remaining
2024,https://openalex.org/W4390597725,Biology,Critical review on water quality analysis using IoT and machine learning models,"Water quality and its management are the most precise concerns confronting humanity globally. This article evaluates the various sensors used for water quality monitoring and focuses on the water quality index considering the multiple physical, chemical, and biological parameters. A Review of Internet of Things (IoT) research for water quality monitoring and analysis, sensors used for water quality can help remote monitoring of the water quality parameters using various IoT-based sensors that convey the assembled estimations utilizing Low-Power Wide Area Network innovations. Overall, the IoT system was 95 % accurate in measuring pH, Turbidity, TDS, and Temperature, while the traditional method was only 85 % accurate. Also, this study reviewed the different A.I. techniques used to assess water quality, including conventional machine learning techniques, Support Vector Machines, Deep Neural Networks, and K-nearest neighbors. Compared to traditional methods, machine learning and deep learning can significantly increase the accuracy of measurements of groundwater quality. However, various variables, such as the caliber of the training data, the water quality metrics' complexity, and the monitoring frequency, will affect the accuracy. The geographical information system (GIS) is used for spatial data analysis and managing water resources. The quality of its data is also reviewed in the paper. Based on these analyses, the study has forecasted the future sensors, Geospatial Technology, and machine learning techniques for water quality monitoring and analysis.","<method>conventional machine learning techniques</method>, <method>Support Vector Machines</method>, <method>Deep Neural Networks</method>, <method>K-nearest neighbors</method>",<method>Support Vector Machines</method><method>Deep Neural Networks</method><method>K-nearest neighbors</method>
2024,https://openalex.org/W4391332961,Biology,A novel framework for developing environmentally sustainable and cost-effective ultra-high-performance concrete (UHPC) using advanced machine learning and multi-objective optimization techniques,"This study aims to propose a novel framework for strength prediction and multi-objective optimization (MOO) of economical and environmentally sustainable ultra-high-performance concrete (UHPC) which aids in intelligent, sustainable, and resilient construction. Different tree- and boosting ensemble-based machine learning (ML) models are integrated to form an accurate and reliable prediction model for the uniaxial compressive strength of UHPC. The optimized models are integrated into a super learner model, resulting in a robust predictive model that is used as one of the objective functions in the MOO problem. A total of 19 objective functions are considered, including cost, uniaxial compressive strength, and 17 environmental impact categories that comprehensively evaluate the environmental sustainability of the UHPC mix. The resulting impacts from the mid-point indicators were calculated using the Eco-invent v3.7 Life Cycle Inventory database. The results showed that the super learner model accurately predicted the uniaxial compressive strength of UHPC. The MOO resulted in Pareto fronts, demonstrating the trade-off among the uniaxial compressive strength, cost, and environmental sustainability of the mix and a broad range of solutions that can be obtained for the 19 objectives. The study provides a useful tool for designers and decision-makers to select the optimal UHPC mixture that meets specific project requirements. Finally, for the practical application of the ML predictive model and MOO algorithm for UHPC, a graphical user interface-based software tool, FAI-OSUSCONCRET, was developed. This software tool offers fast, accurate, and intelligent predictions and multi-objective optimizations tailored to specific project requirements, thus resulting in a UHPC mixture that perfectly meets project needs.","<method>tree-based ensemble machine learning models</method>, <method>boosting ensemble-based machine learning models</method>, <method>super learner model</method>, <method>multi-objective optimization (MOO)</method>",<method>tree-based ensemble machine learning models</method><method>boosting ensemble-based machine learning models</method><method>super learner model</method>
2024,https://openalex.org/W4391168980,Biology,Utilizing Hybrid Machine Learning and Soft Computing Techniques for Landslide Susceptibility Mapping in a Drainage Basin,"The hydrological system of thebasin of Lake Urmia is complex, deriving its supply from a network comprising 13 perennial rivers, along withnumerous small springs and direct precipitation onto the lake’s surface. Among these contributors, approximately half of the inflow is attributed to the Zarrineh River and the Simineh River. Remarkably, Lake Urmia lacks a natural outlet, with its water loss occurring solely through evaporation processes. This study employed a comprehensive methodology integrating ground surveys, remote sensing analyses, and meticulous documentation of historical landslides within the basin as primary information sources. Through this investigative approach, we preciselyidentified and geolocated a total of 512 historical landslide occurrences across the Urmia Lake drainage basin, leveraging GPS technology for precision. Thisarticle introduces a suite of hybrid machine learning predictive models, such as support-vector machine (SVM), random forest (RF), decision trees (DT), logistic regression (LR), fuzzy logic (FL), and the technique for order of preference by similarity to the ideal solution (TOPSIS). These models were strategically deployed to assess landslide susceptibility within the region. The outcomes of the landslide susceptibility assessment reveal that the main high susceptible zones for landslide occurrence are concentrated in the northwestern, northern, northeastern, and some southern and southeastern areas of the region. Moreover, when considering the implementation of predictions using different algorithms, it became evident that SVM exhibited superior performance regardingboth accuracy (0.89) and precision (0.89), followed by RF, with and accuracy of 0.83 and a precision of 0.83. However, it is noteworthy that TOPSIS yielded the lowest accuracy value among the algorithms assessed.","<method>support-vector machine (SVM)</method>, <method>random forest (RF)</method>, <method>decision trees (DT)</method>, <method>logistic regression (LR)</method>, <method>fuzzy logic (FL)</method>, <method>technique for order of preference by similarity to the ideal solution (TOPSIS)</method>",<method>support-vector machine (SVM)</method><method>random forest (RF)</method><method>decision trees (DT)</method><method>logistic regression (LR)</method>
2024,https://openalex.org/W4391831565,Biology,Comparison of Random Forest and XGBoost Classifiers Using Integrated Optical and SAR Features for Mapping Urban Impervious Surface,"The integration of optical and SAR datasets through ensemble machine learning models shows promising results in urban remote sensing applications. The integration of multi-sensor datasets enhances the accuracy of information extraction. This research presents a comparison of two ensemble machine learning classifiers (random forest and extreme gradient boost (XGBoost)) classifiers using an integration of optical and SAR features and simple layer stacking (SLS) techniques. Therefore, Sentinel-1 (SAR) and Landsat 8 (optical) datasets were used with SAR textures and enhanced modified indices to extract features for the year 2023. The classification process utilized two machine learning algorithms, random forest and XGBoost, for urban impervious surface extraction. The study focused on three significant East Asian cities with diverse urban dynamics: Jakarta, Manila, and Seoul. This research proposed a novel index called the Normalized Blue Water Index (NBWI), which distinguishes water from other features and was utilized as an optical feature. Results showed an overall accuracy of 81% for UIS classification using XGBoost and 77% with RF while classifying land use land cover into four major classes (water, vegetation, bare soil, and urban impervious). However, the proposed framework with the XGBoost classifier outperformed the RF algorithm and Dynamic World (DW) data product and comparatively showed higher classification accuracy. Still, all three results show poor separability with bare soil class compared to ground truth data. XGBoost outperformed random forest and Dynamic World in classification accuracy, highlighting its potential use in urban remote sensing applications.","<method>ensemble machine learning models</method>, <method>random forest</method>, <method>extreme gradient boost (XGBoost)</method>, <method>simple layer stacking (SLS)</method>",<method>ensemble machine learning models</method><method>random forest</method><method>extreme gradient boost (XGBoost)</method>
2024,https://openalex.org/W4391037822,Biology,Estimating compressive strength of concrete containing rice husk ash using interpretable machine learning-based models,"The construction sector is a major contributor to global greenhouse gas emissions. Using recycled and waste materials in concrete is a practical solution to address environmental challenges. Currently, agricultural waste is widely used as a substitute for cement in the production of eco-friendly concrete. However, traditional methods for assessing the strength of such materials are both expensive and time-consuming. Therefore, this study uses machine learning techniques to develop prediction models for the compressive strength (CS) of rice husk ash (RHA) concrete. The ML techniques used in the present study include random forest (RF), light gradient boosting machine (LightGBM), ridge regression, and extreme gradient boosting (XGBoost). A total of 348 values of CS were collected from the experimental studies, and five characteristics of RHA concrete were taken as input variables. For the performance assessment of the models, multiple statistical metrics were used. During the training phase, the correlation coefficients (R) obtained for ridge regression, RF, XGBoost, and LightGBM were 0.943, 0.981, 0.985, and 0.996, respectively. In the testing set, these values demonstrated even higher performance, with correlation coefficients of 0.971, 0.993, 0.992, and 0.998 for ridge regression, RF, XGBoost, and LightGBM, respectively. The statistical analysis revealed that the LightGBM model outperformed other models, whereas the ridge regression model exhibited comparatively lower accuracy. SHapley Additive exPlanation (SHAP) method was employed for the interpretability of the developed model. The SHAP analysis revealed that water-to-cement is a controlling parameter in estimating the CS of RHA concrete. In conclusion, this study provides valuable guidance for builders and researchers to estimate the CS of RHA concrete. However, it is suggested that more input variables be incorporated and hybrid models utilized to further enhance the reliability and precision of the models.","<method>random forest (RF)</method>, <method>light gradient boosting machine (LightGBM)</method>, <method>ridge regression</method>, <method>extreme gradient boosting (XGBoost)</method>, <method>SHapley Additive exPlanation (SHAP)</method>",<method>random forest (RF)</method><method>light gradient boosting machine (LightGBM)</method><method>ridge regression</method><method>extreme gradient boosting (XGBoost)</method><method>SHapley Additive exPlanation (SHAP)</method>
2024,https://openalex.org/W4393012885,Biology,Improving Thyroid Disorder Diagnosis via Ensemble Stacking and Bidirectional Feature Selection,"Thyroid disorders represent a significant global health challenge with hypothyroidism and hyperthyroidism as two common conditions arising from dysfunction in the thyroid gland.Accurate and timely diagnosis of these disorders is crucial for effective treatment and patient care.This research introduces a comprehensive approach to improve the accuracy of thyroid disorder diagnosis through the integration of ensemble stacking and advanced feature selection techniques.Sequential forward feature selection, sequential backward feature elimination, and bidirectional feature elimination are investigated in this study.In ensemble learning, random forest, adaptive boosting, and bagging classifiers are employed.The effectiveness of these techniques is evaluated using two different datasets obtained from the University of California Irvine-Machine Learning Repository, both of which undergo preprocessing steps, including outlier removal, addressing missing data, data cleansing, and feature reduction.Extensive experimentation demonstrates the remarkable success of proposed ensemble stacking and bidirectional feature elimination achieving 100% and 99.86% accuracy in identifying hyperthyroidism and hypothyroidism, respectively.Beyond enhancing detection accuracy, the ensemble stacking model also demonstrated a streamlined computational complexity which is pivotal for practical medical applications.It significantly outperformed existing studies with similar objectives underscoring the viability and effectiveness of the proposed scheme.This research offers an innovative perspective and sets the platform for improved thyroid disorder diagnosis with broader implications for healthcare and patient well-being.","<method>ensemble stacking</method>, <method>sequential forward feature selection</method>, <method>sequential backward feature elimination</method>, <method>bidirectional feature elimination</method>, <method>random forest</method>, <method>adaptive boosting</method>, <method>bagging classifiers</method>",<method>ensemble stacking</method><method>sequential forward feature selection</method><method>sequential backward feature elimination</method><method>random forest</method><method>adaptive boosting</method><method>bagging classifiers</method>
2024,https://openalex.org/W4396877909,Biology,The Capacity and Robustness Trade-off: Revisiting the Channel Independent Strategy for Multivariate Time Series Forecasting,"Multivariate time series data comprises various channels of variables. The multivariate forecasting models need to capture the relationship between the channels to accurately predict future values. However, recently, there has been an emergence of methods that employ the Channel Independent (CI) strategy. These methods view multivariate time series data as separate univariate time series and disregard the correlation between channels. Surprisingly, our empirical results have shown that models trained with the CI strategy outperform those trained with the Channel Dependent (CD) strategy, usually by a significant margin. Nevertheless, the reasons behind this phenomenon have not yet been thoroughly explored in the literature. This paper provides comprehensive empirical and theoretical analyses of the characteristics of multivariate time series datasets and the CI/CD strategy. Our results conclude that the CD approach has higher capacity but often lacks robustness to accurately predict distributionally drifted time series. In contrast, the CI approach trades capacity for robust prediction. Practical measures inspired by these analyses are proposed to address the capacity and robustness dilemma, including a modified CD method called Predict Residuals with Regularization (PRReg) that can surpass the CI strategy. We hope our findings can raise awareness among researchers about the characteristics of multivariate time series and inspire the construction of better forecasting models.","<method>Channel Independent (CI) strategy</method>, <method>Channel Dependent (CD) strategy</method>, <method>Predict Residuals with Regularization (PRReg)</method>",No methods remaining
2024,https://openalex.org/W4400873377,Biology,"Multi-Scenario Simulation of Land Use Change and Ecosystem Service Value Based on the Markov–FLUS Model in Ezhou City, China","Changes in land use patterns, types, and intensities significantly impact ecosystem services. This study follows the time series logic from history to the expected future to investigate the spatial and temporal characteristics of land use changes in Ezhou and their potential impacts on the ecosystem services value (ESV). The results show that the Markov–FLUS model has strong applicability in predicting the spatial pattern of land use, with a Kappa coefficient of 0.9433 and a FoM value of 0.1080. Between 2000 and 2020, construction land expanded continuously, while water area remained relatively stable, and other land types experienced varying degrees of contraction. Notably, the area of construction land expanded significantly compared to 2000, and it expanded by 70.99% in 2020. Moreover, the watershed area expanded by 9.30% from 2000 to 2010, but there was very little change in the following 10 years. Under the three scenarios, significant differences in land use changes were observed in Ezhou City, driven by human activities, particularly the strong expansion of construction land. In the inertial development scenario, construction land expanded to 313.39 km2 by 2030, representing a 38.30% increase from 2020. Conversely, under the farmland protection scenario, construction land increased to 237.66 km2, a 4.89% rise from 2020. However, in the ecological priority development scenario, the construction land area expanded to 253.59 km2, a 10.13% increase from 2020. Compared to 2020, the ESV losses in the inertia development and farmland protection scenarios were USD 4497.71 and USD 1072.23, respectively, by 2030. Conversely, the ESV under the ecological protection scenario increased by USD 2749.09, emphasizing the importance of prioritizing ecological protection in Ezhou City’s development. This study may provide new clues for the formulation of regional strategies for sustainable land use and ecosystem restoration.",<method>Markov–FLUS model</method>,No methods remaining
2024,https://openalex.org/W4390738897,Biology,Enhancing crop recommendation systems with explainable artificial intelligence: a study on agricultural decision-making,"Abstract Crop Recommendation Systems are invaluable tools for farmers, assisting them in making informed decisions about crop selection to optimize yields. These systems leverage a wealth of data, including soil characteristics, historical crop performance, and prevailing weather patterns, to provide personalized recommendations. In response to the growing demand for transparency and interpretability in agricultural decision-making, this study introduces XAI-CROP an innovative algorithm that harnesses eXplainable artificial intelligence (XAI) principles. The fundamental objective of XAI-CROP is to empower farmers with comprehensible insights into the recommendation process, surpassing the opaque nature of conventional machine learning models. The study rigorously compares XAI-CROP with prominent machine learning models, including Gradient Boosting (GB), Decision Tree (DT), Random Forest (RF), Gaussian Naïve Bayes (GNB), and Multimodal Naïve Bayes (MNB). Performance evaluation employs three essential metrics: Mean Squared Error (MSE), Mean Absolute Error (MAE), and R-squared (R2). The empirical results unequivocally establish the superior performance of XAI-CROP. It achieves an impressively low MSE of 0.9412, indicating highly accurate crop yield predictions. Moreover, with an MAE of 0.9874, XAI-CROP consistently maintains errors below the critical threshold of 1, reinforcing its reliability. The robust R 2 value of 0.94152 underscores XAI-CROP's ability to explain 94.15% of the data's variability, highlighting its interpretability and explanatory power.","<method>XAI-CROP</method>, <method>Gradient Boosting (GB)</method>, <method>Decision Tree (DT)</method>, <method>Random Forest (RF)</method>, <method>Gaussian Naïve Bayes (GNB)</method>, <method>Multimodal Naïve Bayes (MNB)</method>",<method>Gradient Boosting (GB)</method><method>Decision Tree (DT)</method><method>Random Forest (RF)</method><method>Gaussian Naïve Bayes (GNB)</method>
2024,https://openalex.org/W4391783116,Biology,Assessing water quality of an ecologically critical urban canal incorporating machine learning approaches,"This study assessed water quality (WQ) in Tongi Canal, an ecologically critical and economically important urban canal in Bangladesh. The researchers employed the Root Mean Square Water Quality Index (RMS-WQI) model, utilizing seven WQ indicators, including temperature, dissolve oxygen, electrical conductivity, lead, cadmium, and iron to calculate the water quality index (WQI) score. The results showed that most of the water sampling locations showed poor WQ, with many indicators violating Bangladesh's environmental conservation regulations. This study employed eight machine learning algorithms, where the Gaussian process regression (GPR) model demonstrated superior performance (training RMSE = 1.77, testing RMSE = 0.0006) in predicting WQI scores. To validate the GPR model's performance, several performance measures, including the coefficient of determination (R2), the Nash-Sutcliffe efficiency (NSE), the model efficiency factor (MEF), Z statistics, and Taylor diagram analysis, were employed. The GPR model exhibited higher sensitivity (R2 = 1.0) and efficiency (NSE = 1.0, MEF = 0.0) in predicting WQ. The analysis of model uncertainty (standard uncertainty = 7.08 ± 0.9025; expanded uncertainty = 7.08 ± 1.846) indicates that the RMS-WQI model holds potential for assessing the WQ of inland waterbodies. These findings indicate that the RMS-WQI model could be an effective approach for assessing inland waters across Bangladesh. The study's results showed that most of the WQ indicators did not meet the recommended guidelines, indicating that the water in the Tongi Canal is unsafe and unsuitable for various purposes. The study's implications extend beyond the Tongi Canal and could contribute to WQ management initiatives across Bangladesh.",<method>Gaussian process regression (GPR)</method>,<method>Gaussian process regression (GPR)</method>
2024,https://openalex.org/W4392454900,Biology,Compressive strength prediction of sustainable concrete incorporating rice husk ash (RHA) using hybrid machine learning algorithms and parametric analyses,"The construction industry is making efforts to reduce the environmental impact of cement production in concrete by incorporating alternative and supplementary cementitious materials, as well as lowering carbon emissions. One such material that has gained popularity in this context is rice husk ash (RHA) due to its pozzolanic reactions. This study aims to forecast the compressive strength (CS) of RHA-based concrete (RBC) by examining the effects of several factors such as cement, RHA content, curing age, water usage, aggregate amount, and superplasticizer content. To accomplish this, the study collected and analyzed data from literature, resulting in a dataset of 1404 observations. Several machine learning (ML) models, such as light gradient boosting (LGB), extreme gradient boosting (XGB), and random forest (RF), as well as hybrid machine learning (HML) approaches like XGB-LGB and XGB-RF were employed to thoroughly analyze these parameters and assess their impact on strength. The dataset was split into training and testing groups, and statistical analyses were performed to determine the relationships between the input parameters and CS. Moreover, the performance of all the models was evaluated using various statistical evaluation criteria, including mean absolute percentage error (MAPE), coefficient of efficiency (CE), root mean square error (RMSE), and coefficient of determination (R2). The hybrid XGB-LGB model was found to have higher precision (R2 = 0.95, and RMSE = 5.255 MPa) as compared to other models. SHAP (SHapley Additive exPlanations) analysis revealed that cement, RHA, and superplasticizer had a positive effect on strength. Overall, the study's findings suggest that the hybrid XGB-LGB model with the identified input parameters can be used to accurately predict the CS of RBC. The application of such technologies in the construction sector can facilitate the rapid and low-cost identification of material qualities and the impact of input parameters.","<method>light gradient boosting (LGB)</method>, <method>extreme gradient boosting (XGB)</method>, <method>random forest (RF)</method>, <method>hybrid machine learning (HML) approaches like XGB-LGB</method>, <method>hybrid machine learning (HML) approaches like XGB-RF</method>",<method>light gradient boosting (LGB)</method><method>extreme gradient boosting (XGB)</method><method>random forest (RF)</method>
2024,https://openalex.org/W4392131696,Biology,"Assessing Chilgoza Pine (Pinus gerardiana) forest fire severity: Remote sensing analysis, correlations, and predictive modeling for enhanced management strategies","Forest fires represent a critical global threat to both humans and ecosystems. This study examines the intensity and impacts of Chilgoza (Pinus gerardiana) Pine Forest fires by using advanced remote sensing techniques comprising Normalized Burn Ratio (NBR) and Difference Normalized Burn Ratio (dNBR) analyses based on Landsat 9 datasets. The study highlights the severe effect of these fires, resulting in noteworthy losses of livestock and private properties and widespread damage to 10,156.53 acres of the Chilgoza Pine Forest. A comprehensive variable correlation analysis is conducted to gain deeper insights into the influencing factors causing forest fires. Spearman's Rank Correlation Coefficient was used to assess the association between burnt and unburnt areas and various independent factors. The analysis reveals compelling evidence of significant correlations with forest fire prevalence. This study found moderate negative (-0.532, p < 0.05) and positive (0.513, p < 0.05) correlations with elevation and Land Surface Temperature (LST), respectively, and a weak positive correlation (0.252, p < 0.05) with a Wind Speed (V). To predict forest fire susceptibility and better understand the contributing factors, three machine learning models, Random Forest (RF), XGBoost, and logistic regression, are applied to assess variable importance scores. Among the considered factors, LST is the most critical variable, with consistently high variable importance scores (100%, 96%, and 59%) across all three models. Wind Speed (V) also proved influential in all models, with variable importance scores of 78%, 83%, and 61% for RF, XGBoost, and logistic regression, respectively. Moreover, elevation significantly influences the frequency of forest fires, as evidenced by variable importance scores ranging from 26% to 100%. Comparatively, the Random Forest model outperforms XGBoost and Logistic Regression in predicting forest fire vulnerability. During the training stage, the Random Forest (RF) model achieves an impressive classification accuracy of 99.1%, followed by XGBoost with 94.5% and Logistic Regression with 85.6%. On evaluation with the validation dataset, the accuracies remain promising, with RF at 96.4%, XGBoost at 91.1%, and Logistic Regression at 84.6%. Based on the Random Forest model, the identified high-risk sites offer valuable insights for proactive fire management and prevention strategies. This study provides a robust predictive model and a comprehensive understanding of forest fire severity and impacts. Future research should consider climate change scenarios and account for human activities to enhance fire behavior predictions and risk assessment models.","<method>Random Forest (RF)</method>, <method>XGBoost</method>, <method>logistic regression</method>",<method>Random Forest (RF)</method><method>XGBoost</method><method>logistic regression</method>
2024,https://openalex.org/W4390659289,Biology,Cognition-Driven Structural Prior for Instance-Dependent Label Transition Matrix Estimation,"The label transition matrix has emerged as a widely accepted method for mitigating label noise in machine learning. In recent years, numerous studies have centered on leveraging deep neural networks to estimate the label transition matrix for individual instances within the context of instance-dependent noise. However, these methods suffer from low search efficiency due to the large space of feasible solutions. Behind this drawback, we have explored that the real murderer lies in the invalid class transitions, that is, the actual transition probability between certain classes is zero but is estimated to have a certain value. To mask the <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">invalid class transitions</i> , we introduced a human-cognition-assisted method with structural information from human cognition. Specifically, we introduce a structured transition matrix network ( <bold xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">STMN</b> ) designed with an adversarial learning process to balance instance features and prior information from human cognition. The proposed method offers two advantages: 1) better estimation effectiveness is obtained by sparing the transition matrix and 2) better estimation accuracy is obtained with the assistance of human cognition. By exploiting these two advantages, our method parametrically estimates a sparse label transition matrix, effectively converting noisy labels into true labels. The efficiency and superiority of our proposed method are substantiated through comprehensive comparisons with state-of-the-art methods on three synthetic datasets and a real-world dataset. Our code will be available at https://github.com/WheatCao/STMN-Pytorch.","<method>label transition matrix</method>, <method>deep neural networks</method>, <method>human-cognition-assisted method</method>, <method>structured transition matrix network (STMN)</method>, <method>adversarial learning process</method>",<method>deep neural networks</method><method>adversarial learning process</method>
2024,https://openalex.org/W4392980686,Biology,Data-driven evolution of water quality models: An in-depth investigation of innovative outlier detection approaches-A case study of Irish Water Quality Index (IEWQI) model,"Recently, there has been a significant advancement in the water quality index (WQI) models utilizing data-driven approaches, especially those integrating machine learning and artificial intelligence (ML/AI) technology. Although, several recent studies have revealed that the data-driven model has produced inconsistent results due to the data outliers, which significantly impact model reliability and accuracy. The present study was carried out to assess the impact of data outliers on a recently developed Irish Water Quality Index (IEWQI) model, which relies on data-driven techniques. To the author's best knowledge, there has been no systematic framework for evaluating the influence of data outliers on such models. For the purposes of assessing the outlier impact of the data outliers on the water quality (WQ) model, this was the first initiative in research to introduce a comprehensive approach that combines machine learning with advanced statistical techniques. The proposed framework was implemented in Cork Harbour, Ireland, to evaluate the IEWQI model's sensitivity to outliers in input indicators to assess the water quality. In order to detect the data outlier, the study utilized two widely used ML techniques, including Isolation Forest (IF) and Kernel Density Estimation (KDE) within the dataset, for predicting WQ with and without these outliers. For validating the ML results, the study used five commonly used statistical measures. The performance metric (R2) indicates that the model performance improved slightly (R2 increased from 0.92 to 0.95) in predicting WQ after removing the data outlier from the input. But the IEWQI scores revealed that there were no statistically significant differences among the actual values, predictions with outliers, and predictions without outliers, with a 95% confidence interval at p < 0.05. The results of model uncertainty also revealed that the model contributed <1% uncertainty to the final assessment results for using both datasets (with and without outliers). In addition, all statistical measures indicated that the ML techniques provided reliable results that can be utilized for detecting outliers and their impacts on the IEWQI model. The findings of the research reveal that although the data outliers had no significant impact on the IEWQI model architecture, they had moderate impacts on the rating schemes' of the model. This finding indicated that detecting the data outliers could improve the accuracy of the IEWQI model in rating WQ as well as be helpful in mitigating the model eclipsing problem. In addition, the results of the research provide evidence of how the data outliers influenced the data-driven model in predicting WQ and reliability, particularly since the study confirmed that the IEWQI model's could be effective for accurately rating WQ despite the presence of the data outliers in the input. It could occur due to the spatio-temporal variability inherent in WQ indicators. However, the research assesses the influence of data input outliers on the IEWQI model and underscores important areas for future investigation. These areas include expanding temporal analysis using multi-year data, examining spatial outlier patterns, and evaluating detection methods. Moreover, it is essential to explore the real-world impacts of revised rating categories, involve stakeholders in outlier management, and fine-tune model parameters. Analysing model performance across varying temporal and spatial resolutions and incorporating additional environmental data can significantly enhance the accuracy of WQ assessment. Consequently, this study offers valuable insights to strengthen the IEWQI model's robustness and provides avenues for enhancing its utility in broader WQ assessment applications. Moreover, the study successfully adopted the framework for evaluating how data input outliers affect the data-driven model, such as the IEWQI model. The current study has been carried out in Cork Harbour for only a single year of WQ data. The framework should be tested across various domains for evaluating the response of the IEWQI model's in terms of the spatio-temporal resolution of the domain. Nevertheless, the study recommended that future research should be conducted to adjust or revise the IEWQI model's rating schemes and investigate the practical effects of data outliers on updated rating categories. However, the study provides potential recommendations for enhancing the IEWQI model's adaptability and reveals its effectiveness in expanding its applicability in more general WQ assessment scenarios.","<method>Isolation Forest (IF)</method>, <method>Kernel Density Estimation (KDE)</method>",<method>Isolation Forest (IF)</method>
2024,https://openalex.org/W4391235397,Biology,Real-Time Plant Disease Dataset Development and Detection of Plant Disease Using Deep Learning,"Agriculture plays a significant role in meeting food needs and providing food security for the increasingly growing global population, which has increased by 0.88% since 2022. Plant diseases can reduce food production and affect food security. Worldwide crop loss due to plant disease is estimated to be around 14.1%. The lack of proper identification of plant disease at the early stages of infection can result in inappropriate disease control measures. Therefore, the automatic identification and diagnosis of plant diseases are highly recommended. Lack of availability of large amounts of data that are not processed to a large extent is one of the main challenges in plant disease diagnosis. In the current manuscript, we developed datasets for food grains specifically for rice, wheat, and maize to address the identified challenges. The developed datasets consider the common diseases (two bacterial diseases and two fungal diseases of rice, four fungal diseases of maize, and four fungal diseases of wheat) that affect crop yields and cause damage to the whole plant. The datasets developed were applied to eight fine-tuned deep learning models with the same training hyperparameters. The experimental results based on eight fine-tuned deep learning models show that, while recognizing maize leaf diseases, the models Xception and MobileNet performed best with a testing accuracy of 0.9580 and 0.9464 respectively. Similarly, while recognizing the wheat leaf diseases, the models MobileNetV2 and MobileNet performed best with a testing accuracy of 0.9632 and 0.9628 respectively. The Xception and Inception V3 models performed best, with a testing accuracy of 0.9728 and 0.9620, respectively, for recognizing rice leaf diseases. The research also proposes a new convolutional neural network (CNN) model trained from scratch on all three food grain datasets developed. The proposed model performs well and shows a testing accuracy of 0.9704, 0.9706, and 0.9808 respectively on the maize, rice, and wheat datasets.","<method>fine-tuned deep learning models</method>, <method>Xception</method>, <method>MobileNet</method>, <method>MobileNetV2</method>, <method>Inception V3</method>, <method>convolutional neural network (CNN) model trained from scratch</method>",<method>fine-tuned deep learning models</method><method>Xception</method><method>MobileNet</method><method>MobileNetV2</method><method>Inception V3</method><method>convolutional neural network (CNN) model trained from scratch</method>
2024,https://openalex.org/W4396494945,Biology,Vision–language foundation model for echocardiogram interpretation,"Abstract The development of robust artificial intelligence models for echocardiography has been limited by the availability of annotated clinical data. Here, to address this challenge and improve the performance of cardiac imaging models, we developed EchoCLIP, a vision–language foundation model for echocardiography, that learns the relationship between cardiac ultrasound images and the interpretations of expert cardiologists across a wide range of patients and indications for imaging. After training on 1,032,975 cardiac ultrasound videos and corresponding expert text, EchoCLIP performs well on a diverse range of benchmarks for cardiac image interpretation, despite not having been explicitly trained for individual interpretation tasks. EchoCLIP can assess cardiac function (mean absolute error of 7.1% when predicting left ventricular ejection fraction in an external validation dataset) and identify implanted intracardiac devices (area under the curve (AUC) of 0.84, 0.92 and 0.97 for pacemakers, percutaneous mitral valve repair and artificial aortic valves, respectively). We also developed a long-context variant (EchoCLIP-R) using a custom tokenizer based on common echocardiography concepts. EchoCLIP-R accurately identified unique patients across multiple videos (AUC of 0.86), identified clinical transitions such as heart transplants (AUC of 0.79) and cardiac surgery (AUC 0.77) and enabled robust image-to-text search (mean cross-modal retrieval rank in the top 1% of candidate text reports). These capabilities represent a substantial step toward understanding and applying foundation models in cardiovascular imaging for preliminary interpretation of echocardiographic findings.","<method>vision–language foundation model</method>, <method>custom tokenizer</method>",<method>vision–language foundation model</method>
2024,https://openalex.org/W4398780590,Biology,Greater cane rat algorithm (GCRA): A nature-inspired metaheuristic for optimization problems,"This paper introduces a new metaheuristic technique known as the Greater Cane Rat Algorithm (GCRA) for addressing optimization problems. The optimization process of GCRA is inspired by the intelligent foraging behaviors of greater cane rats during and off mating season. Being highly nocturnal, they are intelligible enough to leave trails as they forage through reeds and grass. Such trails would subsequently lead to food and water sources and shelter. The exploration phase is achieved when they leave the different shelters scattered around their territory to forage and leave trails. It is presumed that the alpha male maintains knowledge about these routes, and as a result, other rats modify their location according to this information. Also, the males are aware of the breeding season and separate themselves from the group. The assumption is that once the group is separated during this season, the foraging activities are concentrated within areas of abundant food sources, which aids the exploitation. Hence, the smart foraging paths and behaviors during the mating season are mathematically represented to realize the design of the GCR algorithm and carry out the optimization tasks. The performance of GCRA is tested using twenty-two classical benchmark functions, ten CEC 2020 complex functions, and the CEC 2011 real-world continuous benchmark problems. To further test the performance of the proposed algorithm, six classic problems in the engineering domain were used. Furthermore, a thorough analysis of computational and convergence results is presented to shed light on the efficacy and stability levels of GCRA. The statistical significance of the results is compared with ten state-of-the-art algorithms using Friedman's and Wilcoxon's signed rank tests. These findings show that GCRA produced optimal or nearly optimal solutions and evaded the trap of local minima, distinguishing it from the rival optimization algorithms employed to tackle similar problems. The GCRA optimizer source code is publicly available at: https://www.mathworks.com/matlabcentral/fileexchange/165241-greater-cane-rat-algorithm-gcra",<method>Greater Cane Rat Algorithm (GCRA)</method>,No methods remaining
2024,https://openalex.org/W4391855187,Biology,Machine learning-assisted in-situ adaptive strategies for the control of defects and anomalies in metal additive manufacturing,"In metal additive manufacturing (AM), the material microstructure and part geometry are formed incrementally. Consequently, the resulting part could be defect- and anomaly-free if sufficient care is taken to deposit each layer under optimal process conditions. Conventional closed-loop control (CLC) engineering solutions which sought to achieve this were deterministic and rule-based, thus resulting in limited success in the stochastic environment experienced in the highly dynamic AM process. On the other hand, emerging machine learning (ML) based strategies are better suited to providing the robustness, scope, flexibility, and scalability required for process control in an uncertain environment. Offline ML models that help optimise AM process parameters before a build begins and online ML models that efficiently processed in-situ sensory data to detect and diagnose flaws in real-time (or near-real-time) have been developed. However, ML models that enable a process to take evasive or corrective actions in relation to flaws via on the fly decision-making are only emerging. These models must possess prognostic capabilities to provide context-sensitive recommendations for in-situ process control based on real-time diagnostics. In this article, we pinpoint the shortcomings in traditional CLC strategies, and provide a framework for defect and anomaly control through ML-assisted CLC in AM. We discuss flaws in terms of their causes, in-situ detectability, and controllability, and examine their management under three scenarios: avoidance, mitigation, and repair. Then, we summarise the research into ML models developed for offline optimisation and in-situ diagnosis before initiating a detailed conversation on the implementation of ML-assisted in-situ process control. We found that researchers favoured reinforcement learning approaches or inverse ML models for making rapid, situation-aware control decisions. We also observed that, to-date, the defects addressed were those that may be quantified relatively easily autonomously, and that mitigation (rather than avoidance or repair) was the aim of ML-assisted in-situ control strategies. Additionally, we highlight the various technologies that must seamlessly combine to advance the field of autonomous in-situ control so that it becomes a reality in industrial settings. Finally, we raise awareness of seldom discussed, yet highly pertinent, topics relevant to adaptive control. Our work closes a significant gap in the current AM literature by broaching wide-ranging discussions on matters relevant to in-situ adaptive control in AM.","<method>machine learning (ML) based strategies</method>, <method>offline ML models</method>, <method>online ML models</method>, <method>reinforcement learning approaches</method>, <method>inverse ML models</method>",<method>online ML models</method><method>reinforcement learning approaches</method>
2024,https://openalex.org/W4392640075,Biology,Performance assessment of machine learning algorithms for mapping of land use/land cover using remote sensing data,"The rapid increase in population accelerates the rate of change of Land use/Land cover (LULC) in various parts of the world. This phenomenon caused a huge strain for natural resources. Hence, continues monitoring of LULC changes gained a significant importance for management of natural resources and assessing the climate change impacts. Recently, application of machine learning algorithms on RS (remote sensing) data for rapid and accurate mapping of LULC gained significant importance due to growing need of LULC estimation for ecosystem services, natural resource management and environmental management. Hence, it is crucial to access and compare the performance of different machine learning classifiers for accurate mapping of LULC. The primary objective of this study was to compare the performance of CART (Classification and Regression Tree), RF (Random Forest) and SVM (Support Vector Machine) for LULC estimation by processing RS data on Google Earth Engine (GEE). In total four classes of LULC (Water Bodies, Vegetation Cover, Urban Land and Barren Land) for city of Lahore were extracted using satellite images from Landsat-7, Landsat-8 and Landsat-9 for years 2008, 2015 and 2022, respectively. According to results, RF is the best performing classifier with maximum overall accuracy of 95.2% and highest Kappa coefficient value of 0.87, SVM achieved maximum accuracy of 89.8% with highest Kappa of 0.84 and CART showed maximum overall accuracy of 89.7% with Kappa value of 0.79. Results from this study can give assistance for decision makers, planners and RS experts to choose a suitable machine learning algorithm for LULC classification in an unplanned urbanized city like Lahore.","<method>Classification and Regression Tree (CART)</method>, <method>Random Forest (RF)</method>, <method>Support Vector Machine (SVM)</method>",<method>Classification and Regression Tree (CART)</method><method>Random Forest (RF)</method><method>Support Vector Machine (SVM)</method>
2024,https://openalex.org/W4390754233,Biology,Groundwater Quality Assessment and Irrigation Water Quality Index Prediction Using Machine Learning Algorithms,"The evaluation of groundwater quality is crucial for irrigation purposes; however, due to financial constraints in developing countries, such evaluations suffer from insufficient sampling frequency, hindering comprehensive assessments. Therefore, associated with machine learning approaches and the irrigation water quality index (IWQI), this research aims to evaluate the groundwater quality in Naama, a region in southwest Algeria. Hydrochemical parameters (cations, anions, pH, and EC), qualitative indices (SAR,RSC,Na%,MH,and PI), as well as geospatial representations were used to determine the groundwater’s suitability for irrigation in the study area. In addition, efficient machine learning approaches for forecasting IWQI utilizing Extreme Gradient Boosting (XGBoost), Support vector regression (SVR), and K-Nearest Neighbours (KNN) models were implemented. In this research, 166 groundwater samples were used to calculate the irrigation index. The results showed that 42.18% of them were of excellent quality, 34.34% were of very good quality, 6.63% were good quality, 9.64% were satisfactory, and 4.21% were considered unsuitable for irrigation. On the other hand, results indicate that XGBoost excels in accuracy and stability, with a low RMSE (of 2.8272 and a high R of 0.9834. SVR with only four inputs (Ca2+, Mg2+, Na+, and K) demonstrates a notable predictive capability with a low RMSE of 2.6925 and a high R of 0.98738, while KNN showcases robust performance. The distinctions between these models have important implications for making informed decisions in agricultural water management and resource allocation within the region.","<method>Extreme Gradient Boosting (XGBoost)</method>, <method>Support vector regression (SVR)</method>, <method>K-Nearest Neighbours (KNN)</method>",<method>Extreme Gradient Boosting (XGBoost)</method><method>Support vector regression (SVR)</method><method>K-Nearest Neighbours (KNN)</method>
2024,https://openalex.org/W4391347933,Biology,CCL-DTI: contributing the contrastive loss in drug–target interaction prediction,"Abstract Background The Drug–Target Interaction (DTI) prediction uses a drug molecule and a protein sequence as inputs to predict the binding affinity value. In recent years, deep learning-based models have gotten more attention. These methods have two modules: the feature extraction module and the task prediction module. In most deep learning-based approaches, a simple task prediction loss (i.e., categorical cross entropy for the classification task and mean squared error for the regression task) is used to learn the model. In machine learning, contrastive-based loss functions are developed to learn more discriminative feature space. In a deep learning-based model, extracting more discriminative feature space leads to performance improvement for the task prediction module. Results In this paper, we have used multimodal knowledge as input and proposed an attention-based fusion technique to combine this knowledge. Also, we investigate how utilizing contrastive loss function along the task prediction loss could help the approach to learn a more powerful model. Four contrastive loss functions are considered: (1) max-margin contrastive loss function, (2) triplet loss function, (3) Multi-class N-pair Loss Objective, and (4) NT-Xent loss function. The proposed model is evaluated using four well-known datasets: Wang et al. dataset, Luo's dataset, Davis, and KIBA datasets. Conclusions Accordingly, after reviewing the state-of-the-art methods, we developed a multimodal feature extraction network by combining protein sequences and drug molecules, along with protein–protein interaction networks and drug–drug interaction networks. The results show it performs significantly better than the comparable state-of-the-art approaches.","<method>deep learning-based models</method>, <method>attention-based fusion technique</method>, <method>contrastive loss function</method>, <method>max-margin contrastive loss function</method>, <method>triplet loss function</method>, <method>Multi-class N-pair Loss Objective</method>, <method>NT-Xent loss function</method>, <method>multimodal feature extraction network</method>",<method>contrastive loss function</method><method>max-margin contrastive loss function</method><method>triplet loss function</method><method>Multi-class N-pair Loss Objective</method><method>NT-Xent loss function</method>
2024,https://openalex.org/W4391248672,Biology,Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning,"Recent development in computing power has resulted in performance improvements on holistic(none-occluded) person Re-Identification (ReID) tasks. Nevertheless, the precision of the recent research will diminish when a pedestrian is obstructed by obstacles. Within the realm of 2D space, the loss of information from obstructed objects continues to pose significant challenges in the context of person ReID. Person is a 3D non-grid object, and thus semantic representation learning in only 2D space limits the understanding of occluded person. In the present work, we propose a network based on 3D multi-view learning, allowing it to acquire geometric and shape details of an occluded pedestrian from 3D space. Simultaneously, it capitalizes on advancements in 2D-based networks to extract semantic representations from 3D multi-views. Specifically, the surface random selection strategy is proposed to convert images of 2D RGB into 3D multi-views. Using this strategy, we build four extensive 3D multi-view data collections for person ReID. After that, Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning(MV-3DSReID), is proposed for identifying the person by learning person geometry and structure representation from the groups of multi-view images. In comparison to alternative data formats (e.g., 2D RGB, 3D point cloud), multi-view images complement each other's detailed features of the 3D object by adjusting rendering viewpoints, thus facilitating a more comprehensive understanding of the person for both holistic and occluded ReID situations. Experiments on occluded and holistic ReID tasks demonstrate performance levels comparable to state-of-the-art methods, validating the effectiveness of our proposed approach in tackling challenges related to occlusion. The code is available at https://github.com/hangjiaqi1/MV-TransReID.","<method>3D multi-view learning</method>, <method>2D-based networks</method>, <method>surface random selection strategy</method>, <method>Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning (MV-3DSReID)</method>",<method>3D multi-view learning</method>
2024,https://openalex.org/W4392077419,Biology,Selection of sustainable food suppliers using the Pythagorean fuzzy CRITIC-MARCOS method,"Sustainable food supplier selection (SFSS) can be handled as an uncertain decision-making issue. The Pythagorean fuzzy set (PFS), a type of non-standard fuzzy set, offers an expanded description space for articulating fuzzy and uncertain data. Accordingly, this paper proposes a Pythagorean fuzzy synthetic decision method-based selection framework for solving the SFSS problem within a subjective context. Then, the weighted distance measures for the PFS are introduced to derive the importance degrees of the experts, which can provide a more objective decision result. Then, an information fusion method with a PFS-weighted power average (WPA) operator is introduced to form a group decision matrix competent to accommodate the deviation effect. Next, an extended PF-measurement of alternatives and ranking according to compromise solution (MARCOS) method integrating PF-criteria importance through inter-criteria correlation (CRITIC) is presented to calculate the priority of each supplier, which can capture the inter-correlations between criteria. Finally, a numerical example of SFSS is implemented to show the application of the proposed synthetic decision approach. Subsequently, the sensitivity analysis of distance parameters and comparison analysis among different SFSS approaches were conducted to test the rationality and advantages of the proposed framework for resolving the SFSS problem. The results show that the reported method can provide a practical way to resolve the SFSS problems with uncertain data.","<method>Pythagorean fuzzy synthetic decision method</method>, <method>weighted distance measures for the Pythagorean fuzzy set (PFS)</method>, <method>information fusion method with a PFS-weighted power average (WPA) operator</method>, <method>extended PF-measurement of alternatives and ranking according to compromise solution (MARCOS) method integrating PF-criteria importance through inter-criteria correlation (CRITIC)</method>",No methods remaining
2024,https://openalex.org/W4391097427,Biology,"Quantifying the direct and indirect effects of terrain, climate and human activity on the spatial pattern of kNDVI-based vegetation growth: A case study from the Minjiang River Basin, Southeast China","In the context of global change, it is vital to comprehensively understand the spatial pattern and driving mechanism of vegetation growth to maintain the stability of watershed ecosystems. Previous research has focused mainly on identifying the main drivers of vegetation growth, while the direct and indirect effects of climate, terrain, and human activity on vegetation growth have rarely been explored. This study used the Minjiang River Basin (MRB), an important ecological barrier and the largest watershed in southeastern China, as an example. The kernel normalized difference vegetation index (kNDVI) was calculated on the Google Earth Engine (GEE) platform to examine the spatial pattern and evolution characteristics of vegetation growth. The optimal parameter-based geographical detector (OPGD) and partial least squares structural equation modeling (PLS-SEM) were used to analyze how terrain, climate, and human activity influenced the spatial pattern of the kNDVI. (1) From 2001 to 2020, vegetation growth in the MRB was predominantly rated as excellent or good, and 88.93% of the area showed an increasing trend of vegetation growth. (2) The OPGD revealed that the primary drivers influencing the spatial distribution of the kNDVI in the MRB included population density, nighttime light, elevation and temperature, which explained >40% of the variation in the kNDVI. The interaction of all paired drivers enhanced the explanatory power of the kNDVI, among which the strongest interaction was between population density and elevation, and the second interaction was between population density and temperature. (3) PLS-SEM revealed that human activity had a direct negative effect on the kNDVI, while terrain and climate had direct and indirect positive effects on the kNDVI. Overall, the total effects of terrain, climate and human activity on the kNDVI were 0.594, 0.233 and − 0.495, respectively, indicating that the positive effect of terrain outweighed the negative effect of human activity on vegetation growth in the MRB. These findings not only provide scientific evidence for ecological conservation and management in the MRB but also offer a useful reference for other regions exploring the complex causes of spatial patterns of vegetation growth.","<method>optimal parameter-based geographical detector (OPGD)</method>, <method>partial least squares structural equation modeling (PLS-SEM)</method>",No methods remaining
2024,https://openalex.org/W4391796054,Biology,Optical remote sensing of crop biophysical and biochemical parameters: An overview of advances in sensor technologies and machine learning algorithms for precision agriculture,"This paper provides an overview of the recent developments in remote sensing technology and machine learning algorithms for estimating important biophysical and biochemical parameters for precision farming. The objectives are (i) to provide an overview of recent advances in remotely sensed retrieval of biophysical and biochemical parameters brought by the developments in sensor technologies and robust machine learning algorithms and (ii) to identify the sources of uncertainty in retrieving biophysical and biochemical parameters and implications for precision agriculture. The review revealed that developments in crop biophysical and biochemical parameters retrieval techniques were mainly driven by announcements and the availability of new sensors. Two ground-breaking events can be identified, i.e., the availability of Sentinel-2 and the SuperDove constellation. The two provide high temporal-high spatial resolution data relevant for site-specific management and super-spectral configuration, enabling retrieval of crop growth and health parameters. The free availability of Sentinel-2 triggered the testing of its spectral configurations and upscaling of retrieval approaches using simulated data from field spectrometers and airborne hyperspectral sensors. SuperDoves will likely reduce the cost of very high-resolution data while providing unprecedented capabilities for detailed, accurate and frequent characterisation of field variability. Studies showed that the red-edge bands and hybrid models coupling Radiative Transfer Model (RTM) and machine learning regression algorithms (MLRA) are promising for operational and accurate monitoring of stress-related crop parameters to aid time-sensitive agronomic decisions. However, such models were tested in Mediterranean climates and performed poorly in African semi-arid areas and China's temperate continental semi-humid monsoon climates. Therefore, locally-calibrated RTM models incorporating crop-type maps and other spatio-temporal constraints may reduce uncertainties when adapted to data-scarce regions. Generally, permanent experimental sites and a lack of systematic calibration data on various crops are some limiting factors to using remote sensing technologies for PA in Sub-Saharan Africa. Other complexities arise from farm configurations, such as small field sizes and mixed cropping practices. Therefore, future studies should develop generic, scalable and transferable models, especially within under-studied areas.",<method>machine learning regression algorithms (MLRA)</method>,No methods remaining
2024,https://openalex.org/W4393167823,Biology,Risk analysis and assessment of water resource carrying capacity based on weighted gray model with improved entropy weighting method in the central plains region of China,"The issue of global water shortage is a serious concern. The scientific evaluation of water resource carrying capacity (WRCC) serves as the foundation for implementing measures to protect water resources. In addition, most of the studies are based on the analysis and research of regional WRCC from the aspects of water quantity and water quality. There are few studies on the four aspects of water resources endowment conditions, society, economy and ecological environment, which is difficult to scientifically and accurately reflect the analysis and evaluation of regional WRCC by the four systems. Therefore, it is necessary to conduct a deeper discussion and Analysis on this topic. This study presents a WRCC index system and corresponding ranking criteria based on 20 influencing factors from four aspects: water resources endowment (WRE), economy, society, and ecological environment. In addition, by combining the improved entropy weighting method (EWM) with gray correlation analysis, the weighted gray technique for order preference by similarity to an ideal solution (TOPSIS) model is proposed for analyzing and assessing WRCC risk. Finally, the WRCC of the study area from 2012 to 2021 is comprehensively evaluated in the central plains region of China (CPROC) as an example. The results show that the comprehensive evaluation obtained a multi-year average value of 0.2935, and the water resources shortage in the CPROC is generally in grade III status. The comprehensive average value of Beijing is 0.345, and the comprehensive average value of Henan is 0.397. The overall degree of water resources shortage is in the state of grade V shortage, Shaanxi is in the state of grade IV shortage, and the degree of water resources in Tianjin and Shanxi is relatively good. This study provides corresponding scientific basis and methodological guidance for the sustainable utilization of water resources and healthy socio-economic performance in the CPROC.","<method>improved entropy weighting method (EWM)</method>, <method>gray correlation analysis</method>, <method>weighted gray technique for order preference by similarity to an ideal solution (TOPSIS) model</method>",No methods remaining
2024,https://openalex.org/W4394822945,Biology,A Critical Review of Artificial Intelligence Based Approaches in Intrusion Detection: A Comprehensive Analysis,"Intrusion detection (ID) is critical in securing computer networks against various malicious attacks. Recent advancements in machine learning (ML), deep learning (DL), federated learning (FL), and explainable artificial intelligence (XAI) have drawn significant attention as potential approaches for ID. DL-based approaches have shown impressive performance in ID by automatically learning relevant features from data but require significant labelled data and computational resources to train complex models. ML-based approaches require fewer computational resources and labelled data, but their ability to generalize to unseen data is limited. FL is a relatively new approach that enables multiple entities to train a model collectively without exchanging their data, providing privacy and security benefits, making it an attractive option for ID. However, FL-based approaches require more communication resources and additional computation to aggregate models from different entities. XAI is critical for understanding how AI models make decisions, improving interpretability and transparency. While existing literature has explored the strengths and weaknesses of DL, ML, FL, and XAI-based approaches for ID, a significant gap exists in providing a comprehensive analysis of the specific use cases and scenarios where each approach is most suitable. This paper seeks to fill this void by delivering an in-depth review that not only highlights strengths and weaknesses but also offers guidance for selecting the appropriate approach based on the unique ID context and available resources. The selection of an appropriate approach depends on the specific use case, and this work provides insights into which method is best suited for various network sizes, data availability, privacy, and security concerns, thus aiding practitioners in making informed decisions for their ID needs.","<method>machine learning (ML)</method>, <method>deep learning (DL)</method>, <method>federated learning (FL)</method>, <method>explainable artificial intelligence (XAI)</method>",<method>machine learning (ML)</method><method>deep learning (DL)</method><method>federated learning (FL)</method>
2024,https://openalex.org/W4395011414,Biology,"admetSAR3.0: a comprehensive platform for exploration, prediction and optimization of chemical ADMET properties","Abstract Absorption, distribution, metabolism, excretion and toxicity (ADMET) properties play a crucial role in drug discovery and chemical safety assessment. Built on the achievements of admetSAR and its successor, admetSAR2.0, this paper introduced the new version of the series, admetSAR3.0, as a comprehensive platform for chemical ADMET assessment, including search, prediction and optimization modules. In the search module, admetSAR3.0 hosted over 370 000 high-quality experimental ADMET data for 104 652 unique compounds, and supplemented chemical structure similarity search function to facilitate read-across. In the prediction module, we introduced comprehensive ADMET endpoints and two new sections for environmental and cosmetic risk assessments, empowering admetSAR3.0 to provide prediction for 119 endpoints, more than double numbers compared to the previous version. Furthermore, the advanced multi-task graph neural network framework offered robust and reliable support for ADMET prediction. In particular, a module named ADMETopt was added to automatically optimize the ADMET properties of query molecules through transformation rules or scaffold hopping. Finally, admetSAR3.0 provides user-friendly interfaces for multiple types of input data, such as SMILES string, chemical structure and batch molecule file, and supports various output types, including digital, chart displays and file downloads. In summary, admetSAR3.0 is anticipated to be a valuable and powerful tool in drug discovery and chemical safety assessment at http://lmmd.ecust.edu.cn/admetsar3/.",<method>multi-task graph neural network framework</method>,<method>multi-task graph neural network framework</method>
2024,https://openalex.org/W4401163187,Biology,Monthly climate prediction using deep convolutional neural network and long short-term memory,"Climate change affects plant growth, food production, ecosystems, sustainable socio-economic development, and human health. The different artificial intelligence models are proposed to simulate climate parameters of Jinan city in China, include artificial neural network (ANN), recurrent NN (RNN), long short-term memory neural network (LSTM), deep convolutional NN (CNN), and CNN-LSTM. These models are used to forecast six climatic factors on a monthly ahead. The climate data for 72 years (1 January 1951–31 December 2022) used in this study include monthly average atmospheric temperature, extreme minimum atmospheric temperature, extreme maximum atmospheric temperature, precipitation, average relative humidity, and sunlight hours. The time series of 12 month delayed data are used as input signals to the models. The efficiency of the proposed models are examined utilizing diverse evaluation criteria namely mean absolute error, root mean square error (RMSE), and correlation coefficient (R). The modeling result inherits that the proposed hybrid CNN-LSTM model achieves a greater accuracy than other compared models. The hybrid CNN-LSTM model significantly reduces the forecasting error compared to the models for the one month time step ahead. For instance, the RMSE values of the ANN, RNN, LSTM, CNN, and CNN-LSTM models for monthly average atmospheric temperature in the forecasting stage are 2.0669, 1.4416, 1.3482, 0.8015 and 0.6292 °C, respectively. The findings of climate simulations shows the potential of CNN-LSTM models to improve climate forecasting. Climate prediction will contribute to meteorological disaster prevention and reduction, as well as flood control and drought resistance.","<method>artificial neural network (ANN)</method>, <method>recurrent NN (RNN)</method>, <method>long short-term memory neural network (LSTM)</method>, <method>deep convolutional NN (CNN)</method>, <method>CNN-LSTM</method>",<method>artificial neural network (ANN)</method><method>recurrent NN (RNN)</method><method>long short-term memory neural network (LSTM)</method><method>deep convolutional NN (CNN)</method><method>CNN-LSTM</method>
2024,https://openalex.org/W4399303474,Biology,Improving Forest Above-Ground Biomass Estimation by Integrating Individual Machine Learning Models,"The accurate estimation of forest above-ground biomass (AGB) is crucial for sustainable forest management and tracking the carbon cycle of forest ecosystem. Machine learning algorithms have been proven to have great potential in forest AGB estimation with remote sensing data. Though many studies have demonstrated that a single machine learning model can produce highly accurate estimations of forest AGB in many situations, efforts are still required to explore the possible improvement in forest AGB estimation for a specific scenario under study. This study aims to investigate the performance of novel ensemble machine learning methods for forest AGB estimation and analyzes whether these methods are affected by forest types, independent variables, and spatial autocorrelation. Four well-known machine learning models (CatBoost, LightGBM, random forest (RF), and XGBoost) were compared for forest AGB estimation in the study using eight scenarios devised on the basis of two study regions, two variable types, and two validation strategies. Subsequently, a hybrid model combining the strengths of these individual models was proposed for forest AGB estimation. The findings indicated that no individual model outperforms the others in all scenarios. The RF model demonstrates superior performance in scenarios 5, 6, and 7, while the CatBoost model shows the best performance in the remaining scenarios. Moreover, the proposed hybrid model consistently has the best performance in all scenarios in spite of some uncertainties. The ensemble strategy developed in this study for the hybrid model substantially improves estimation accuracy and exhibits greater stability, effectively addressing the challenge of model selection encountered in the forest AGB forecasting process.","<method>CatBoost</method>, <method>LightGBM</method>, <method>random forest (RF)</method>, <method>XGBoost</method>, <method>ensemble machine learning methods</method>, <method>hybrid model</method>",<method>CatBoost</method><method>LightGBM</method><method>random forest (RF)</method><method>XGBoost</method><method>ensemble machine learning methods</method>
2024,https://openalex.org/W4401384485,Biology,GAN based augmentation using a hybrid loss function for dermoscopy images,"Dermatology is the most appropriate field to utilize pattern recognition-based automated techniques for objective, accurate, and rapid diagnosis because diagnosis mainly relies on visual examinations of skin lesions. Recent approaches utilizing deep learning techniques have shown remarkable results in this field. However, they necessitate a substantial quantity of images and the availability of dermoscopy images is often limited. Also, even if enough images are available, their labeling requires expert knowledge and is time-consuming. To overcome these issues, an efficient augmentation approach is needed to expand training datasets from input images. Therefore, in this work, a generative adversarial network has been developed using a new hybrid loss function constructed with traditional loss functions to enhance the generation power of the architecture. Also, the effect of the proposed approach and different generative network-based augmentations, which have been used with dermoscopy images in the literature, on the classification of skin lesions has been investigated. Therefore, the main contributions of this work are: (i) introducing a new generative model for the augmentation of dermoscopy images; (ii) presenting the effect of the proposed model on the classification of the images; (iii) comparative evaluations of the effectiveness of different generative network-based augmentations in the classification of seven forms of skin lesions. The classification accuracy when the proposed augmentation is used is 93.12%, which is higher than its counterparts. Experimental results indicate the significance of augmentation techniques in the classification of skin lesions and the efficiency of the proposed structure in improving the classification accuracy.","<method>deep learning techniques</method>, <method>generative adversarial network</method>, <method>generative network-based augmentations</method>",<method>generative adversarial network</method>
2024,https://openalex.org/W4391943312,Biology,"Machine Learning and Deep Learning in Synthetic Biology: Key Architectures, Applications, and Challenges","Machine learning (ML), particularly deep learning (DL), has made rapid and substantial progress in synthetic biology in recent years. Biotechnological applications of biosystems, including pathways, enzymes, and whole cells, are being probed frequently with time. The intricacy and interconnectedness of biosystems make it challenging to design them with the desired properties. ML and DL have a synergy with synthetic biology. Synthetic biology can be employed to produce large data sets for training models (for instance, by utilizing DNA synthesis), and ML/DL models can be employed to inform design (for example, by generating new parts or advising unrivaled experiments to perform). This potential has recently been brought to light by research at the intersection of engineering biology and ML/DL through achievements like the design of novel biological components, best experimental design, automated analysis of microscopy data, protein structure prediction, and biomolecular implementations of ANNs (Artificial Neural Networks). I have divided this review into three sections. In the first section, I describe predictive potential and basics of ML along with myriad applications in synthetic biology, especially in engineering cells, activity of proteins, and metabolic pathways. In the second section, I describe fundamental DL architectures and their applications in synthetic biology. Finally, I describe different challenges causing hurdles in the progress of ML/DL and synthetic biology along with their solutions.","<method>machine learning (ML)</method>, <method>deep learning (DL)</method>, <method>Artificial Neural Networks (ANNs)</method>",<method>machine learning (ML)</method><method>deep learning (DL)</method><method>Artificial Neural Networks (ANNs)</method>
2024,https://openalex.org/W4391997375,Biology,A machine learning approach to predict the efficiency of corrosion inhibition by natural product-based organic inhibitors,"Abstract This paper presents a quantitative structure–property relationship (QSPR)-based machine learning (ML) framework designed for predicting corrosion inhibition efficiency (CIE) values in natural organic inhibitor compounds. The modeling dataset comprises 50 natural organic compounds, with 11 quantum chemical properties (QCP) serving as input features, and the target variable being the corrosion inhibition efficiency (CIE) value. To enhance the predictive accuracy of the ML model, the kernel density estimation (KDE) function is employed to generate virtual samples during the training process, with the overarching goal of refining the precision of the ML model. Three distinct models, namely random forest (RF), gradient boosting (GB), and k-nearest neighbor (KNN), are tested in the study. The results demonstrate a noteworthy enhancement in the prediction performance of the models, attributable to the incorporation of virtual samples that effectively improve the correlation between input features and target values. Consequently, the accuracy of the predicted CIE values is significantly augmented, aligning more closely with the actual CIE values. Performance improvements were evident across all models after the incorporation of virtual samples. The GB, RF, and KNN models exhibited increments in R 2 values from 0.557 to 0.996, 0.522 to 0.999, and 0.415 to 0.994, respectively, concomitant with the introduction of 500 virtual samples. Additionally, each model demonstrated a notable reduction in RMSE values, transitioning from 1.41 to 0.19, 1.27 to 0.10, and 1.22 to 0.16, respectively. While the GB model initially outperformed others before the addition of virtual samples, the performance of the model exhibited fluctuation as the number of virtual samples varied. This behavior suggests that the KDE function provides a certain level of resilience against model variations. The proposed approach contributes to the effective design and exploration of corrosion inhibitor candidates, offering a reliable and accurate predictive tool that bridges the gap between theoretical studies and experimental synthesis.","<method>random forest (RF)</method>, <method>gradient boosting (GB)</method>, <method>k-nearest neighbor (KNN)</method>, <method>kernel density estimation (KDE)</method>",<method>random forest (RF)</method><method>gradient boosting (GB)</method><method>k-nearest neighbor (KNN)</method>
2024,https://openalex.org/W4395037579,Biology,Assessing ChatGPT 4.0’s test performance and clinical diagnostic accuracy on USMLE STEP 2 CK and clinical case reports,"Abstract While there is data assessing the test performance of artificial intelligence (AI) chatbots, including the Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0), there is scarce data on its diagnostic accuracy of clinical cases. We assessed the large language model (LLM), ChatGPT 4.0, on its ability to answer questions from the United States Medical Licensing Exam (USMLE) Step 2, as well as its ability to generate a differential diagnosis based on corresponding clinical vignettes from published case reports. A total of 109 Step 2 Clinical Knowledge (CK) practice questions were inputted into both ChatGPT 3.5 and ChatGPT 4.0, asking ChatGPT to pick the correct answer. Compared to its previous version, ChatGPT 3.5, we found improved accuracy of ChatGPT 4.0 when answering these questions, from 47.7 to 87.2% ( p = 0.035) respectively. Utilizing the topics tested on Step 2 CK questions, we additionally found 63 corresponding published case report vignettes and asked ChatGPT 4.0 to come up with its top three differential diagnosis. ChatGPT 4.0 accurately created a shortlist of differential diagnoses in 74.6% of the 63 case reports (74.6%). We analyzed ChatGPT 4.0’s confidence in its diagnosis by asking it to rank its top three differentials from most to least likely. Out of the 47 correct diagnoses, 33 were the first (70.2%) on the differential diagnosis list, 11 were second (23.4%), and three were third (6.4%). Our study shows the continued iterative improvement in ChatGPT’s ability to answer standardized USMLE questions accurately and provides insights into ChatGPT’s clinical diagnostic accuracy.","<method>Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0)</method>, <method>ChatGPT 3.5</method>, <method>large language model (LLM)</method>",<method>Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0)</method><method>large language model (LLM)</method>
2024,https://openalex.org/W4399173789,Biology,Utilizing Deep Learning and the Internet of Things to Monitor the Health of Aquatic Ecosystems to Conserve Biodiversity,"The decline in water conditions contributes to the crisis in clean water biodiversity. The interactions between water conditions indicators and the correlations among these variables and taxonomic groupings are intricate in their impact on biodiversity. However, since there are just a few kinds of Internet of Things (IoT) that are accessible to purchase, many chemical and biological measurements still need laboratory studies. The newest progress in Deep Learning and the IoT allows for the use of this method in the real-time surveillance of water quality, therefore contributing to preserving biodiversity. This paper presents a thorough examination of the scientific literature about the water quality factors that have a significant influence on the variety of freshwater ecosystems. It selected the ten most crucial water quality criteria. The connections between the quantifiable and valuable aspects of the IoT are assessed using a Generalized Regression-based Neural Networks (G-RNN) framework and a multi-variational polynomial regression framework. These models depend on historical data from the monitoring of water quality. The projected findings in an urbanized river were validated using a combination of traditional field water testing, in-lab studies, and the created IoT-depend water condition management system. The G-RNN effectively differentiates abnormal increases in variables from typical scenarios. The assessment coefficients for the system for degree 8 are as follows: 0.87, 0.73, 0.89, and 0.79 for N-O3-N, BO-D5, P-O4, and N-H3-N. The suggested methods and prototypes were verified against laboratory findings to assess their efficacy and effectiveness. The general efficacy was deemed suitable, with most forecasting mistakes smaller than 0.3 mg/L. This validation offers valuable insights into IoT methods' usage in pollutants released observation and additional water quality regulating usage, specifically for freshwater biodiversity preservation.","<method>Generalized Regression-based Neural Networks (G-RNN)</method>, <method>multi-variational polynomial regression framework</method>",No methods remaining
2024,https://openalex.org/W4401593044,Biology,Overcoming the Limits of Cross-Sensitivity: Pattern Recognition Methods for Chemiresistive Gas Sensor Array,"Abstract As information acquisition terminals for artificial olfaction, chemiresistive gas sensors are often troubled by their cross-sensitivity, and reducing their cross-response to ambient gases has always been a difficult and important point in the gas sensing area. Pattern recognition based on sensor array is the most conspicuous way to overcome the cross-sensitivity of gas sensors. It is crucial to choose an appropriate pattern recognition method for enhancing data analysis, reducing errors and improving system reliability, obtaining better classification or gas concentration prediction results. In this review, we analyze the sensing mechanism of cross-sensitivity for chemiresistive gas sensors. We further examine the types, working principles, characteristics, and applicable gas detection range of pattern recognition algorithms utilized in gas-sensing arrays. Additionally, we report, summarize, and evaluate the outstanding and novel advancements in pattern recognition methods for gas identification. At the same time, this work showcases the recent advancements in utilizing these methods for gas identification, particularly within three crucial domains: ensuring food safety, monitoring the environment, and aiding in medical diagnosis. In conclusion, this study anticipates future research prospects by considering the existing landscape and challenges. It is hoped that this work will make a positive contribution towards mitigating cross-sensitivity in gas-sensitive devices and offer valuable insights for algorithm selection in gas recognition applications.",<method>pattern recognition</method>,No methods remaining
2024,https://openalex.org/W4390492164,Biology,Efficient Camouflaged Object Detection Network Based on Global Localization Perception and Local Guidance Refinement,"Camouflaged Object Detection (COD) is a challenging visual task due to its complex contour, diverse scales, and high similarity to the background. Existing COD methods encounter two predicaments: One is that they are prone to falling into local perception, resulting in inaccurate object localization; Another issue is the difficulty in achieving precise object segmentation due to a lack of detailed information. In addition, most COD methods typically require larger parameter amounts and higher computational complexity in pursuit of better performance. To this end, we propose a global localization perception and local guidance refinement network (PRNet), that simultaneously addresses performance and computational costs. Through effective aggregation and use of semantic and details information, the PRNet can achieve accurate localization and refined segmentation of camouflaged objects. Specifically, with the help of a Cascaded Attention Perceptron (CAP) designed, we can effectively integrate and perceive multi-scale information to localize camouflaged objects. We also design a Guided Refinement Decoder (GRD) in a top-down manner to extract context information and aggregate details to further refine camouflaged prediction results. Extensive experimental results demonstrate that our PRNet outperforms 12 state-of-the-art models on 4 challenging datasets. Meanwhile, the PRNet has a smaller number of parameters (12.74M), lower computational complexity (10.24G), and real-time inference speed (105FPS). Source codes are available at https://github.com/hu-xh/PRNet.","<method>global localization perception and local guidance refinement network (PRNet)</method>, <method>Cascaded Attention Perceptron (CAP)</method>, <method>Guided Refinement Decoder (GRD)</method>",No methods remaining
2024,https://openalex.org/W4390501772,Biology,Remote sensing based forest cover classification using machine learning,"Abstract Pakistan falls significantly below the recommended forest coverage level of 20 to 30 percent of total area, with less than 6 percent of its land under forest cover. This deficiency is primarily attributed to illicit deforestation for wood and charcoal, coupled with a failure to embrace advanced techniques for forest estimation, monitoring, and supervision. Remote sensing techniques leveraging Sentinel-2 satellite images were employed. Both single-layer stacked images and temporal layer stacked images from various dates were utilized for forest classification. The application of an artificial neural network (ANN) supervised classification algorithm yielded notable results. Using a single-layer stacked image from Sentinel-2, an impressive 91.37% training overall accuracy and 0.865 kappa coefficient were achieved, along with 93.77% testing overall accuracy and a 0.902 kappa coefficient. Furthermore, the temporal layer stacked image approach demonstrated even better results. This method yielded 98.07% overall training accuracy, 97.75% overall testing accuracy, and kappa coefficients of 0.970 and 0.965, respectively. The random forest (RF) algorithm, when applied, achieved 99.12% overall training accuracy, 92.90% testing accuracy, and kappa coefficients of 0.986 and 0.882. Notably, with the temporal layer stacked image of the Sentinel-2 satellite, the RF algorithm reached exceptional performance with 99.79% training accuracy, 96.98% validation accuracy, and kappa coefficients of 0.996 and 0.954. In terms of forest cover estimation, the ANN algorithm identified 31.07% total forest coverage in the District Abbottabad region. In comparison, the RF algorithm recorded a slightly higher 31.17% of the total forested area. This research highlights the potential of advanced remote sensing techniques and machine learning algorithms in improving forest cover assessment and monitoring strategies.","<method>artificial neural network (ANN) supervised classification algorithm</method>, <method>random forest (RF) algorithm</method>",<method>artificial neural network (ANN) supervised classification algorithm</method><method>random forest (RF) algorithm</method>
2024,https://openalex.org/W4390954471,Biology,Traffic Sign Detection and Recognition Using YOLO Object Detection Algorithm: A Systematic Review,"Context: YOLO (You Look Only Once) is an algorithm based on deep neural networks with real-time object detection capabilities. This state-of-the-art technology is widely available, mainly due to its speed and precision. Since its conception, YOLO has been applied to detect and recognize traffic signs, pedestrians, traffic lights, vehicles, and so on. Objective: The goal of this research is to systematically analyze the YOLO object detection algorithm, applied to traffic sign detection and recognition systems, from five relevant aspects of this technology: applications, datasets, metrics, hardware, and challenges. Method: This study performs a systematic literature review (SLR) of studies on traffic sign detection and recognition using YOLO published in the years 2016–2022. Results: The search found 115 primary studies relevant to the goal of this research. After analyzing these investigations, the following relevant results were obtained. The most common applications of YOLO in this field are vehicular security and intelligent and autonomous vehicles. The majority of the sign datasets used to train, test, and validate YOLO-based systems are publicly available, with an emphasis on datasets from Germany and China. It has also been discovered that most works present sophisticated detection, classification, and processing speed metrics for traffic sign detection and recognition systems by using the different versions of YOLO. In addition, the most popular desktop data processing hardwares are Nvidia RTX 2080 and Titan Tesla V100 and, in the case of embedded or mobile GPU platforms, Jetson Xavier NX. Finally, seven relevant challenges that these systems face when operating in real road conditions have been identified. With this in mind, research has been reclassified to address these challenges in each case. Conclusions: This SLR is the most relevant and current work in the field of technology development applied to the detection and recognition of traffic signs using YOLO. In addition, insights are provided about future work that could be conducted to improve the field.",<method>YOLO (You Look Only Once)</method>,<method>YOLO (You Look Only Once)</method>
2024,https://openalex.org/W4393306481,Biology,Reliable water quality prediction and parametric analysis using explainable AI models,"Abstract The consumption of water constitutes the physical health of most of the living species and hence management of its purity and quality is extremely essential as contaminated water has to potential to create adverse health and environmental consequences. This creates the dire necessity to measure, control and monitor the quality of water. The primary contaminant present in water is Total Dissolved Solids (TDS), which is hard to filter out. There are various substances apart from mere solids such as potassium, sodium, chlorides, lead, nitrate, cadmium, arsenic and other pollutants. The proposed work aims to provide the automation of water quality estimation through Artificial Intelligence and uses Explainable Artificial Intelligence (XAI) for the explanation of the most significant parameters contributing towards the potability of water and the estimation of the impurities. XAI has the transparency and justifiability as a white-box model since the Machine Learning (ML) model is black-box and unable to describe the reasoning behind the ML classification. The proposed work uses various ML models such as Logistic Regression, Support Vector Machine (SVM), Gaussian Naive Bayes, Decision Tree (DT) and Random Forest (RF) to classify whether the water is drinkable. The various representations of XAI such as force plot, test patch, summary plot, dependency plot and decision plot generated in SHAPELY explainer explain the significant features, prediction score, feature importance and justification behind the water quality estimation. The RF classifier is selected for the explanation and yields optimum Accuracy and F1-Score of 0.9999, with Precision and Re-call of 0.9997 and 0.998 respectively. Thus, the work is an exploratory analysis of the estimation and management of water quality with indicators associated with their significance. This work is an emerging research at present with a vision of addressing the water quality for the future as well.","<method>Artificial Intelligence</method>, <method>Explainable Artificial Intelligence (XAI)</method>, <method>Logistic Regression</method>, <method>Support Vector Machine (SVM)</method>, <method>Gaussian Naive Bayes</method>, <method>Decision Tree (DT)</method>, <method>Random Forest (RF)</method>",<method>Logistic Regression</method><method>Support Vector Machine (SVM)</method><method>Gaussian Naive Bayes</method><method>Decision Tree (DT)</method><method>Random Forest (RF)</method>
2024,https://openalex.org/W4396609541,Biology,Robust Drone Delivery with Weather Information,"Problem definition: Drone delivery has recently garnered significant attention due to its potential for faster delivery at a lower cost than other delivery options. When scheduling drones from a depot for delivery to various destinations, the dispatcher must take into account the uncertain wind conditions, which affect the delivery times of drones to their destinations, leading to late deliveries. Methodology/results: To mitigate the risk of delivery delays caused by wind uncertainty, we propose a two-period drone scheduling model to robustly optimize the delivery schedule. In this framework, the scheduling decisions are made in the morning, with the provision for different delivery schedules in the afternoon that adapt to updated weather information available by midday. Our approach minimizes the essential riskiness index, which can simultaneously account for the probability of tardy delivery and the magnitude of lateness. Using wind observation data, we characterize the uncertain flight times via a cluster-wise ambiguity set, which has the benefit of tractability while avoiding overfitting the empirical distribution. A branch-and-cut (B&amp;C) algorithm is developed for this adaptive distributionally framework to improve its scalability. Our adaptive distributionally robust model can effectively reduce lateness in out-of-sample tests compared with other classical models. The proposed B&amp;C algorithm can solve instances to optimality within a shorter time frame than a general modeling toolbox. Managerial implications: Decision makers can use the adaptive robust model together with the cluster-wise ambiguity set to effectively reduce service lateness at customers for drone delivery systems. Funding: This work was supported by the National Natural Science Foundation of China [Grants 72101049 and 72232001], the Natural Science Foundation of Liaoning Province [Grant 2023-BS-091], the Fundamental Research Funds for the Central Universities [Grant DUT23RC(3)045], and the Major Project of the National Social Science Foundation [Grant 22&amp;ZD151]. Supplemental Material: The online appendices are available at https://doi.org/10.1287/msom.2022.0339 .","<method>branch-and-cut (B&C) algorithm</method>, <method>adaptive distributionally robust model</method>",No methods remaining
2024,https://openalex.org/W4399319394,Biology,Multi-task aquatic toxicity prediction model based on multi-level features fusion,"With the escalating menace of organic compounds in environmental pollution imperiling the survival of aquatic organisms, the investigation of organic compound toxicity across diverse aquatic species assumes paramount significance for environmental protection. Understanding how different species respond to these compounds helps assess the potential ecological impact of pollution on aquatic ecosystems as a whole. Compared with traditional experimental methods, deep learning methods have higher accuracy in predicting aquatic toxicity, faster data processing speed and better generalization ability. This article presents ATFPGT-multi, an advanced multi-task deep neural network prediction model for organic toxicity. The model integrates molecular fingerprints and molecule graphs to characterize molecules, enabling the simultaneous prediction of acute toxicity for the same organic compound across four distinct fish species. Furthermore, to validate the advantages of multi-task learning, we independently construct prediction models, named ATFPGT-single, for each fish species. We employ cross-validation in our experiments to assess the performance and generalization ability of ATFPGT-multi. The experimental results indicate, first, that ATFPGT-multi outperforms ATFPGT-single on four fish datasets with AUC improvements of 9.8%, 4%, 4.8%, and 8.2%, respectively, demonstrating the superiority of multi-task learning over single-task learning. Furthermore, in comparison with previous algorithms, ATFPGT-multi outperforms comparative methods, emphasizing that our approach exhibits higher accuracy and reliability in predicting aquatic toxicity. Moreover, ATFPGT-multi utilizes attention scores to identify molecular fragments associated with fish toxicity in organic molecules, as demonstrated by two organic molecule examples in the main text, demonstrating the interpretability of ATFPGT-multi. In summary, ATFPGT-multi provides important support and reference for the further development of aquatic toxicity assessment. All of codes and datasets are freely available online at https://github.com/zhaoqi106/ATFPGT-multi.","<method>deep learning methods</method>, <method>multi-task deep neural network prediction model</method>, <method>multi-task learning</method>, <method>single-task learning</method>, <method>cross-validation</method>",<method>deep learning methods</method><method>multi-task deep neural network prediction model</method><method>multi-task learning</method><method>single-task learning</method>
2024,https://openalex.org/W4391321561,Biology,A survey on training challenges in generative adversarial networks for biomedical image analysis,"Abstract In biomedical image analysis, the applicability of deep learning methods is directly impacted by the quantity of image data available. This is due to deep learning models requiring large image datasets to provide high-level performance. Generative Adversarial Networks (GANs) have been widely utilized to address data limitations through the generation of synthetic biomedical images. GANs consist of two models. The generator, a model that learns how to produce synthetic images based on the feedback it receives. The discriminator, a model that classifies an image as synthetic or real and provides feedback to the generator. Throughout the training process, a GAN can experience several technical challenges that impede the generation of suitable synthetic imagery. First, the mode collapse problem whereby the generator either produces an identical image or produces a uniform image from distinct input features. Second, the non-convergence problem whereby the gradient descent optimizer fails to reach a Nash equilibrium. Thirdly, the vanishing gradient problem whereby unstable training behavior occurs due to the discriminator achieving optimal classification performance resulting in no meaningful feedback being provided to the generator. These problems result in the production of synthetic imagery that is blurry, unrealistic, and less diverse. To date, there has been no survey article outlining the impact of these technical challenges in the context of the biomedical imagery domain. This work presents a review and taxonomy based on solutions to the training problems of GANs in the biomedical imaging domain. This survey highlights important challenges and outlines future research directions about the training of GANs in the domain of biomedical imagery.","<method>deep learning</method>, <method>Generative Adversarial Networks (GANs)</method>, <method>generator</method>, <method>discriminator</method>, <method>gradient descent optimizer</method>",<method>deep learning</method><method>Generative Adversarial Networks (GANs)</method><method>discriminator</method><method>gradient descent optimizer</method>
2024,https://openalex.org/W4392017386,Biology,Vegetable disease detection using an improved YOLOv8 algorithm in the greenhouse plant environment,"Abstract This study introduces YOLOv8n-vegetable, a model designed to address challenges related to imprecise detection of vegetable diseases in greenhouse plant environment using existing network models. The model incorporates several improvements and optimizations to enhance its effectiveness. Firstly, a novel C2fGhost module replaces partial C2f. with GhostConv based on Ghost lightweight convolution, reducing the model’s parameters and improving detection performance. Second, the Occlusion Perception Attention Module (OAM) is integrated into the Neck section to better preserve feature information after fusion, enhancing vegetable disease detection in greenhouse settings. To address challenges associated with detecting small-sized objects and the depletion of semantic knowledge due to varying scales, an additional layer for detecting small-sized objects is included. This layer improves the amalgamation of extensive and basic semantic knowledge, thereby enhancing overall detection accuracy. Finally, the HIoU boundary loss function is introduced, leading to improved convergence speed and regression accuracy. These improvement strategies were validated through experiments using a self-built vegetable disease detection dataset in a greenhouse environment. Multiple experimental comparisons have demonstrated the model's effectiveness, achieving the objectives of improving detection speed while maintaining accuracy and real-time detection capability. According to experimental findings, the enhanced model exhibited a 6.46% rise in mean average precision (mAP) over the original model on the self-built vegetable disease detection dataset under greenhouse conditions. Additionally, the parameter quantity and model size decreased by 0.16G and 0.21 MB, respectively. The proposed model demonstrates significant advancements over the original algorithm and exhibits strong competitiveness when compared with other advanced object detection models. The lightweight and fast detection of vegetable diseases offered by the proposed model presents promising applications in vegetable disease detection tasks.","<method>YOLOv8n-vegetable</method>, <method>C2fGhost module</method>, <method>GhostConv</method>, <method>Occlusion Perception Attention Module (OAM)</method>, <method>HIoU boundary loss function</method>",No methods remaining
2024,https://openalex.org/W4393055891,Biology,A new intelligently optimized model reference adaptive controller using GA and WOA-based MPPT techniques for photovoltaic systems,"Recently, the integration of renewable energy sources, specifically photovoltaic (PV) systems, into power networks has grown in significance for sustainable energy generation. Researchers have investigated different control algorithms for maximum power point tracking (MPPT) to enhance the efficiency of PV systems. This article presents an innovative method to address the problem of maximum power point tracking in photovoltaic systems amidst swiftly changing weather conditions. MPPT techniques supply maximum power to the load during irradiance fluctuations and ambient temperatures. A novel optimal model reference adaptive controller is developed and designed based on the MIT rule to seek global maximum power without ripples rapidly. The suggested controller is also optimized through two popular meta-heuristic algorithms: The genetic algorithm (GA) and the whale optimization algorithm (WOA). These meta-heuristic approaches have been exploited to overcome the difficulty of selecting the adaptation gain of the MRAC controller. The reference voltage for MPPT is generated in the study through an adaptive neuro-fuzzy inference system. The suggested controller's performance is tested via MATLAB/Simulink software under varying temperature and radiation circumstances. Simulation is carried out using a Soltech 1sth-215-p module coupled to a boost converter, which powers a resistive load. Furthermore, to emphasize the recommended algorithm's performance, a comparative study was done between the optimal MRAC using GA and WOA and the conventional incremental conductance (INC) method.","<method>genetic algorithm (GA)</method>, <method>whale optimization algorithm (WOA)</method>, <method>adaptive neuro-fuzzy inference system</method>",<method>genetic algorithm (GA)</method><method>whale optimization algorithm (WOA)</method><method>adaptive neuro-fuzzy inference system</method>
2024,https://openalex.org/W4399144385,Biology,Assessment of technical water quality in mining based on machine learning methods,"Introduction. Mining requires water treatment and wastewater processing, abstraction and discharge during mining increases consumption several times. Since water consumption in mining and processing is usually associated with domestic, industrial and technical needs, the need for water supply systems required for water treatment increases. Water from different sources can be used for treatment: incoming water, process and reused water, and wastewater. But the water obtained from any of the sources must meet all the norms and requirements. Water quality is determined by physical, chemical and bacteriological properties. The main directions for improving water consumption by mining enterprises are to reduce the consumption of drinking water from rivers, lakes and municipal water supply, as well as to expand the use of mine and quarry water for domestic and technical needs. Materials and methods. As training data for training the neural network, a dataset that includes water quality data obtained from fresh water sources was selected for the methods work, and using machine learning, develops a model that predicts whether the water is suitable for technical use in mines. This dataset includes 2293 values (samples) as well as 9 attributes. Correlation, neural network, and decision tree methods were used to build the models in this study. Results. Various machine learning methods (neural network and decision trees) were used to build a predictive model to assess the quality of water that would be suitable for use in the mining industry for technical purposes. With the help of the built models were processed data obtained from public sources, when analyzing which it was found that the method of decision trees was more accurate. The constructed model, for determining dependencies, thus, has high accuracy (small error). To increase the practical significance of the study, a number of transformations of the initial data set were carried out, in particular, an experiment with the division of attributes into groups of importance, in relation to the data, taking into account the subject area. The results obtained made it clear that checking only for hazardous impurities does not guarantee the suitability of water, but almost completely excludes (low significance factor) samples with impurities that do not meet the requirements, and the model can have practical significance. Allocation of the group for rapid quality determination, showed that for the express test, in an emergency situation or under time constraints, the possibility of practical use of the obtained model, has a justification, due to the small error. In general, the conducted experiments have shown that when taking into account the costs (total) for data collection, it makes sense to use models, taking into account the reduction of collected data, on the parameters (factors) of technical water. Discussion. In general, on the basis of the conducted research, we can talk about the successful application of machine learning methods in determining the suitability of technical water in the mining industry. During the experiments, the decision tree method performed particularly well, with the lowest error values. In addition, further work can be carried out to reduce the error in the models, in particular, by possibly increasing the number of attributes, as well as more fine-tuning of the applied machine learning methods. Conclusions. The authors conclude that machine learning techniques can be successfully integrated to determine the quality and suitability of process water in the mining industry in today’s world. Resume. The paper compares machine learning methods such as decision trees and neural network method. The comparative analysis of these methods and their quality of information processing is shown on the example of a set of data on water quality in the mining industry. With the help of built models were processed data obtained from open sources, when analyzing which it was found that the method of decision trees was more accurate. The constructed model for determining dependencies has high accuracy (small error). Suggestions for practical applications and future research directions. This study can form the basis for research in this or related fields to conduct further studies on the reliability and accuracy of using machine learning to predict the quality of water used in the mining industry. Continued work in the above direction may be the rationale for wider use of the above methods to improve various meaningful production performance in this or related areas.","<method>neural network</method>, <method>decision tree</method>",<method>neural network</method><method>decision tree</method>
2024,https://openalex.org/W4401490202,Biology,Cultural dimensions and sustainability disclosure in the banking sector: Insights from a qualitative comparative analysis approach,"Abstract This study adopts an innovative, holistic research approach based on fuzzy set qualitative comparative analysis (fs‐QCA) to deeply delve into national cultural dimensions' role in affecting banks' sustainability disclosure practices in the Eastern European (EE) region. Accordingly, this study aims to identify whether one or more configurations of cultural dimensions derived from Hofstede's national culture framework are conducive to higher levels of sustainability disclosure, using a sample including the five largest banks in each country of the ‘Bucharest Nine’ (B9) area over 2018–2022 period. Results evidence that sustainability disclosure patterns are not homogeneous among the banks operating in B9 countries. After the introduction of Directive 95/2014/EU, banks in some countries maintained relatively constant levels of sustainability disclosure, while others experienced steady growth rates. No cultural dimension alone would likely determine higher sustainability disclosure levels among B9 banks, confirming that normative pressures influencing EE banks' sustainability disclosure practices result from a combination of more cultural facets. In particular, fs‐QCA highlights a bundle of cultural dimension configurations that mould stakeholders' expectations in investigated countries, exerting pressures on banks to enhance their transparency on sustainability issues. The presence of power distance recurs in most configurations as a factor enabling higher sustainability disclosure levels. On the other hand, in most cases, the presence of uncertainty avoidance and long‐term orientation is conducive to higher banks' sustainability and transparency.",<method>fuzzy set qualitative comparative analysis (fs‐QCA)</method>,No methods remaining
2024,https://openalex.org/W4390483836,Biology,Ranking Factors Affecting Sustainable Competitive Advantage from The Business Intelligence Perspective: Using Content Analysis And F-TOPSIS,"Sustainable competitive advantage, as a key factor in business success, ensures that the company is able to dominate the market with differentiated products and services over a long period of time. This advantage is especially achieved through business intelligence, since smart decisions, leveraging meaningful data and analytics, and continuous process improvement help the company maintain this advantage and experience sustainable growth. The aim of this study is to rank the factors influencing sustainable competitive advantage from a business intelligence standpoint. The research methodology consists of two stages: qualitative and quantitative. In the first step, content analysis was performed to extract indicators from previous studies. In the second step, indicators were ranked using the F-TOPSIS method. Factors affecting sustainable competitive advantage from the business intelligence viewpoint were categorized into 5 criteria, including 27 sub-criteria. The 5 main criteria are customer relationship management, smart marketing, soft and hard organizational factors, and the mental image of the product, respectively. In the second step, the sub-criteria in each criterion were ranked. In customer relationship management, the most important sub-criterion is effective interaction with customers. In smart marketing, the most important sub-criterion is feedback and continuous improvement. Among the soft and hard organizational factors, the most important sub-criteria are support from senior management and technology and infrastructure. In the mental image of the product, the most important sub-criterion is social responsibility.",<method>F-TOPSIS</method>,No methods remaining
2024,https://openalex.org/W4391093770,Biology,A Convolutional Neural Network approach for image-based anomaly detection in smart agriculture,"The recent technological advances and their applications to agriculture provide leverage for the new paradigm of smart agriculture. Remote sensing applications can help optimize resources, making agriculture more ecological, increasing productivity and helping farmers to anticipate events that could not otherwise be avoided. Considering that losses caused by anomalies such as diseases, weeds and pests account for 20-40 % of overall agricultural productivity, a successful research effort in this area would be a breakthrough for agriculture. In this paper, we propose a methodology with which to discover and classify anomalies in images of crops, taken from a wide range of distances, using different Convolutional Neural Network architectures. This methodology also deals with several difficulties that usually appear in this kind of problems, such as class imbalance, the insufficient and small variety of images, overtraining or lack of models generalisation. We have implemented four convolutional neural network architectures in a high-performance computing environment, and propose a methodology based on data augmentation with the addition of Gaussian noise to the images to solve the above problems. Our approach was tested using two well-established open datasets that are unalike: DeepWeeds, which provides a classification of 8 weed species native to Australia using images that were taken at a distance of 1 m, and Agriculture-Vision, which classifies 6 types of crop anomalies using multispectral satellite imagery. Our methodology attained accuracies of 98 % and 95.3% respectively, improving the state-of-the-art by several points. In order to ease reproducibility and model selection, we have provided a comparison in terms of computational time and other metrics, thus enabling the choice between architectures to be made according to the resources available. The complete code is available in an open repository in order to encourage reproducibility and promote scientific advances in sustainable agriculture.","<method>Convolutional Neural Network architectures</method>, <method>data augmentation with the addition of Gaussian noise</method>",<method>Convolutional Neural Network architectures</method><method>data augmentation with the addition of Gaussian noise</method>
2024,https://openalex.org/W4391612257,Biology,Machine learning for the management of biochar yield and properties of biomass sources for sustainable energy,"Abstract Biochar is emerging as a potential solution for biomass conversion to meet the ever increasing demand for sustainable energy. Efficient management systems are needed in order to exploit fully the potential of biochar. Modern machine learning (ML) techniques, and in particular ensemble approaches and explainable AI methods, are valuable for forecasting the properties and efficiency of biochar properly. Machine‐learning‐based forecasts, optimization, and feature selection are critical for improving biomass management techniques. In this research, we explore the influences of these techniques on the accurate forecasting of biochar yield and properties for a range of biomass sources. We emphasize the importance of the interpretability of a model, as this improves human comprehension and trust in ML predictions. Sensitivity analysis is shown to be an effective technique for finding crucial biomass characteristics that influence the synthesis of biochar. Precision prognostics have far‐reaching ramifications, influencing industries such as biomass logistics, conversion technologies, and the successful use of biomass as renewable energy. These advances can make a substantial contribution to a greener future and can encourage the development of a circular biobased economy. This work emphasizes the importance of using sophisticated data‐driven methodologies such as ML in biochar synthesis, to usher in ecologically friendly energy solutions. These breakthroughs hold the key to a more sustainable and environmentally friendly future.","<method>ensemble approaches</method>, <method>explainable AI methods</method>, <method>machine-learning-based forecasts</method>, <method>optimization</method>, <method>feature selection</method>, <method>sensitivity analysis</method>",<method>ensemble approaches</method><method>feature selection</method>
2024,https://openalex.org/W4391878291,Biology,Effective lung nodule detection using deep CNN with dual attention mechanisms,"Abstract Novel methods are required to enhance lung cancer detection, which has overtaken other cancer-related causes of death as the major cause of cancer-related mortality. Radiologists have long-standing methods for locating lung nodules in patients with lung cancer, such as computed tomography (CT) scans. Radiologists must manually review a significant amount of CT scan pictures, which makes the process time-consuming and prone to human error. Computer-aided diagnosis (CAD) systems have been created to help radiologists with their evaluations in order to overcome these difficulties. These systems make use of cutting-edge deep learning architectures. These CAD systems are designed to improve lung nodule diagnosis efficiency and accuracy. In this study, a bespoke convolutional neural network (CNN) with a dual attention mechanism was created, which was especially crafted to concentrate on the most important elements in images of lung nodules. The CNN model extracts informative features from the images, while the attention module incorporates both channel attention and spatial attention mechanisms to selectively highlight significant features. After the attention module, global average pooling is applied to summarize the spatial information. To evaluate the performance of the proposed model, extensive experiments were conducted using benchmark dataset of lung nodules. The results of these experiments demonstrated that our model surpasses recent models and achieves state-of-the-art accuracy in lung nodule detection and classification tasks.","<method>convolutional neural network (CNN)</method>, <method>dual attention mechanism</method>, <method>channel attention</method>, <method>spatial attention</method>, <method>global average pooling</method>",<method>convolutional neural network (CNN)</method><method>dual attention mechanism</method><method>channel attention</method><method>spatial attention</method><method>global average pooling</method>
2024,https://openalex.org/W4392432727,Biology,Plant disease recognition in a low data scenario using few-shot learning,"Plant disease is one of the major problems in agriculture. Diseases damage plants, reduce yields and lower the quality of the produce. Traditional approaches to detecting plant diseases are usually based on visual inspection and laboratory testing, which can be expensive and time-consuming. They require trained plant pathologists as well as specialised equipment. Several studies demonstrate that artificial intelligence (AI) methods can produce promising results. However, AI methods are generally data-hungry and require large annotated datasets, and the collection and annotation of such datasets can be a limiting factor. It often appears that only a small amount of data is available for certain disease types. Whereas the performance of typical AI methods drops significantly when they are trained with inadequate data. This paper proposes a novel few-shot learning (FSL) method to detect plant diseases and alleviate the data scarcity problem. The proposed method uses as few as five images per class in the machine learning process. Our method is based on a state-of-the-art FSL pipeline called pre-training, meta-learning, and fine-tuning (PMF), integrated with a novel feature attention (FA) module; we call the overall method PMF+FA. The FA module emphasises the discriminative parts in the image and reduces the impact of complicated backgrounds and undesired objects. We used ResNet50 and Vision Transformers (ViT) as the feature learner. Two publicly available plant disease datasets were repurposed to meet the FSL requirements. We thoroughly evaluated the proposed method on the PlantDoc dataset, which contains disease samples in field environments with complex backgrounds and unwanted objects. The PMF+FA method with ViT achieved an average accuracy of 90.12% in disease recognition. The results demonstrate that the PMF+FA pipeline consistently outperforms the baseline PMF. The results also highlight that the method using ViT generates better results than ResNet50 for diagnosing complex data. ViT and ResNet50 implementations are computationally efficient, taking 1.11 and 0.57 ms on average per image to evaluate the test set respectively. The high throughput and high-quality performance with only a small training dataset indicate that the proposed technique can be used for real-time disease detection in digital farming systems.","<method>few-shot learning (FSL)</method>, <method>pre-training, meta-learning, and fine-tuning (PMF)</method>, <method>feature attention (FA) module</method>, <method>ResNet50</method>, <method>Vision Transformers (ViT)</method>",<method>few-shot learning (FSL)</method><method>ResNet50</method><method>Vision Transformers (ViT)</method>
2024,https://openalex.org/W4394808249,Biology,An ensemble penalized regression method for multi-ancestry polygenic risk prediction,"Abstract Great efforts are being made to develop advanced polygenic risk scores (PRS) to improve the prediction of complex traits and diseases. However, most existing PRS are primarily trained on European ancestry populations, limiting their transferability to non-European populations. In this article, we propose a novel method for generating multi-ancestry Polygenic Risk scOres based on enSemble of PEnalized Regression models (PROSPER). PROSPER integrates genome-wide association studies (GWAS) summary statistics from diverse populations to develop ancestry-specific PRS with improved predictive power for minority populations. The method uses a combination of $${{{{{{\mathscr{L}}}}}}}_{1}$$ <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""> <mml:msub> <mml:mrow> <mml:mi>L</mml:mi> </mml:mrow> <mml:mrow> <mml:mn>1</mml:mn> </mml:mrow> </mml:msub> </mml:math> (lasso) and $${{{{{{\mathscr{L}}}}}}}_{2}$$ <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""> <mml:msub> <mml:mrow> <mml:mi>L</mml:mi> </mml:mrow> <mml:mrow> <mml:mn>2</mml:mn> </mml:mrow> </mml:msub> </mml:math> (ridge) penalty functions, a parsimonious specification of the penalty parameters across populations, and an ensemble step to combine PRS generated across different penalty parameters. We evaluate the performance of PROSPER and other existing methods on large-scale simulated and real datasets, including those from 23andMe Inc., the Global Lipids Genetics Consortium, and All of Us. Results show that PROSPER can substantially improve multi-ancestry polygenic prediction compared to alternative methods across a wide variety of genetic architectures. In real data analyses, for example, PROSPER increased out-of-sample prediction R 2 for continuous traits by an average of 70% compared to a state-of-the-art Bayesian method (PRS-CSx) in the African ancestry population. Further, PROSPER is computationally highly scalable for the analysis of large SNP contents and many diverse populations.","<method>lasso</method>, <method>ridge</method>, <method>ensemble</method>, <method>Bayesian method (PRS-CSx)</method>",<method>lasso</method><method>ridge</method><method>ensemble</method>
2024,https://openalex.org/W4399651788,Biology,Semantic segmentation of microbial alterations based on SegFormer,"Introduction Precise semantic segmentation of microbial alterations is paramount for their evaluation and treatment. This study focuses on harnessing the SegFormer segmentation model for precise semantic segmentation of strawberry diseases, aiming to improve disease detection accuracy under natural acquisition conditions. Methods Three distinct Mix Transformer encoders - MiT-B0, MiT-B3, and MiT-B5 - were thoroughly analyzed to enhance disease detection, targeting diseases such as Angular leaf spot, Anthracnose rot, Blossom blight, Gray mold, Leaf spot, Powdery mildew on fruit, and Powdery mildew on leaves. The dataset consisted of 2,450 raw images, expanded to 4,574 augmented images. The Segment Anything Model integrated into the Roboflow annotation tool facilitated efficient annotation and dataset preparation. Results The results reveal that MiT-B0 demonstrates balanced but slightly overfitting behavior, MiT-B3 adapts rapidly with consistent training and validation performance, and MiT-B5 offers efficient learning with occasional fluctuations, providing robust performance. MiT-B3 and MiT-B5 consistently outperformed MiT-B0 across disease types, with MiT-B5 achieving the most precise segmentation in general. Discussion The findings provide key insights for researchers to select the most suitable encoder for disease detection applications, propelling the field forward for further investigation. The success in strawberry disease analysis suggests potential for extending this approach to other crops and diseases, paving the way for future research and interdisciplinary collaboration.","<method>SegFormer segmentation model</method>, <method>Mix Transformer encoders - MiT-B0</method>, <method>Mix Transformer encoders - MiT-B3</method>, <method>Mix Transformer encoders - MiT-B5</method>, <method>Segment Anything Model</method>",<method>SegFormer segmentation model</method><method>Mix Transformer encoders - MiT-B0</method><method>Mix Transformer encoders - MiT-B3</method><method>Mix Transformer encoders - MiT-B5</method><method>Segment Anything Model</method>
2024,https://openalex.org/W4390590855,Biology,A Survey of Text Classification With Transformers: How Wide? How Large? How Long? How Accurate? How Expensive? How Safe?,"Text classification is a basic task in natural language processing (NLP) with applications from sentiment analysis to question-answering with chat bots. In recent years, transformer-based models have emerged as the prevailing framework in NLP, demonstrating excellent results across many benchmarks. This paper recommends an expanded taxonomy of applications and provides a review of the performance of different models across these applications. The use of traditional research techniques plus co-citation and bibliographic coupling provides a comprehensive view of the current and past research in this area. The study begins by providing an overview of the history of transformer-based models with an emphasis on recent large language models (LLM). Next, uni-modal (text only) inputs and the emerging area of multi-modal classification are discussed to provide a comparison of current and emerging research in this area. Gaps are highlighted in the use of multi-modal text/numeric/columnar data and recommendations for future research are provided. Finally, the length of text input variables (tokens) is reviewed to explore the evolution from short-text to longer document applications. Furthermore, the accuracy on 358 datasets across 20 applications is reviewed and unexpected results emerge which show that LLMs are not always the most accurate or least expensive option. In addition to model performance, the safety implications of transformer-based models are reviewed, and a summary of issues related to ethics, bias, social implications, and copyright are explored.","<method>transformer-based models</method>, <method>large language models (LLM)</method>",<method>transformer-based models</method>
2024,https://openalex.org/W4391289138,Biology,"A stacking ANN ensemble model of ML models for stream water quality prediction of Godavari River Basin, India","The importance of water quality models has increased as their inputs are critical to the development of risk assessment framework for environmental management and monitoring of rivers. However, with the advent of a plethora of recent advances in ML algorithms better predictions are possible. This study proposes a causal and effect model by considering climatological such as temperature and precipitation along with geospatial information related to the agricultural land use factor (ALUF), the forest land use factor (FLUF), the grassland usage factor (GLUF), the shrub land use factor (SLUF), and the urban land use factor (ULUF). All these factors are included in the input data, whereas four Stream Water Quality parameters (SWQPs) such as Electrical Conductivity (EC), Biochemical Oxygen Demand (BOD), Nitrate, and Dissolved Oxygen (DO) from 2019 to 2021 are taken as outputs to predict the Godavari River Basin water quality. In the preliminary investigation, out of these four SWQPs, nitrate's coefficient of variation (CV) is high, revealing a close association with climate parameters and land use practices across the sampling stations. In the authors' earlier study, a model using a single-layer Feed-Forward Neural Network (FFNN) showed improved performance in predicting cause and effect factors linked to water quality metrics. To achieve better prediction, a stacked ANN meta-model and nine conventional machine learning (ML) models, including Extreme Gradient Boosting (XGB), Extra Trees (ET), Bagging (BG), Random Forest (RF), AdaBoost or Adaptive Boosting (ADB), Decision Tree (DT), Highest Gradient Boosting (HGB), Light Gradient Boosting Method (LGBM), and Gradient Boosting (GB), were compared in this study. According to the study's findings, Bagging and Boosting models outperformed stand-alone earlier FFNN for the same dataset and showed superior predictive capabilities in terms of accuracy in forecasting the variable of interest. For instance, during testing, the coefficient of determination (R2) of Biochemical Oxygen Demand (BOD) increased from 0.72 to 0.87. Furthermore, a stacked Artificial Neural Network (ANN) meta model that was reinforced using Extreme Gradient Boosting (XGB), Random Forest (RF), and Extra Trees (ET) as base models performed better than the individual ML models (from R2 = 0.87 to 0.91 for BOD in testing). By using this new framework, the effort for hyperparameter tuning can be minimized.","<method>Feed-Forward Neural Network (FFNN)</method>, <method>stacked ANN meta-model</method>, <method>Extreme Gradient Boosting (XGB)</method>, <method>Extra Trees (ET)</method>, <method>Bagging (BG)</method>, <method>Random Forest (RF)</method>, <method>AdaBoost or Adaptive Boosting (ADB)</method>, <method>Decision Tree (DT)</method>, <method>Highest Gradient Boosting (HGB)</method>, <method>Light Gradient Boosting Method (LGBM)</method>, <method>Gradient Boosting (GB)</method>, <method>stacked Artificial Neural Network (ANN) meta model</method>",<method>Feed-Forward Neural Network (FFNN)</method><method>stacked ANN meta-model</method><method>Extreme Gradient Boosting (XGB)</method><method>Extra Trees (ET)</method><method>Bagging (BG)</method><method>Random Forest (RF)</method><method>AdaBoost or Adaptive Boosting (ADB)</method><method>Decision Tree (DT)</method><method>Light Gradient Boosting Method (LGBM)</method><method>Gradient Boosting (GB)</method><method>stacked Artificial Neural Network (ANN) meta model</method>
2024,https://openalex.org/W4391392820,Biology,Advancements in Imaging Sensors and AI for Plant Stress Detection: A Systematic Literature Review,"Integrating imaging sensors and artificial intelligence (AI) have contributed to detecting plant stress symptoms, yet data analysis remains a key challenge. Data challenges include standardized data collection, analysis protocols, selection of imaging sensors and AI algorithms, and finally, data sharing. Here, we present a systematic literature review (SLR) scrutinizing plant imaging and AI for identifying stress responses. We performed a scoping review using specific keywords, namely abiotic and biotic stress, machine learning, plant imaging and deep learning. Next, we used programmable bots to retrieve relevant papers published since 2006. In total, 2,704 papers from 4 databases (Springer, ScienceDirect, PubMed, and Web of Science) were found, accomplished by using a second layer of keywords (e.g., hyperspectral imaging and supervised learning). To bypass the limitations of search engines, we selected OneSearch to unify keywords. We carefully reviewed 262 studies, summarizing key trends in AI algorithms and imaging sensors. We demonstrated that the increased availability of open-source imaging repositories such as PlantVillage or Kaggle has strongly contributed to a widespread shift to deep learning, requiring large datasets to train in stress symptom interpretation. Our review presents current trends in AI-applied algorithms to develop effective methods for plant stress detection using image-based phenotyping. For example, regression algorithms have seen substantial use since 2021. Ultimately, we offer an overview of the course ahead for AI and imaging technologies to predict stress responses. Altogether, this SLR highlights the potential of AI imaging in both biotic and abiotic stress detection to overcome challenges in plant data analysis.","<method>machine learning</method>, <method>deep learning</method>, <method>supervised learning</method>, <method>regression algorithms</method>",<method>machine learning</method><method>deep learning</method><method>supervised learning</method><method>regression algorithms</method>
2024,https://openalex.org/W4392783914,Biology,CAR-Toner: an AI-driven approach for CAR tonic signaling prediction and optimization,"2][3] Our previous work has elucidated that positively charged patches (PCPs) on the surface of the CAR antigenbinding domain facilitate CAR clustering, thereby triggering CAR tonic signals.To quantify these PCPs, which are indicative of CAR tonic signaling, we previously developed a bioinformatic method to determine the PCP score. 1 This calculation method starts with constructing three-dimensional (3D) homology models for CAR's single-chain variable fragments (scFvs) using the SWISS homology modeler.Subsequently, the BindUP web server is used to determine the total count of residues within the top three largest patches containing continuous positively charged residues on the surface of CAR scFv.However, this PCP score calculation method has several limitations: 1. reliance on two external servers; 2. each calculation taking a few days, significantly hindering efficiency; 3. lack of batch calculation capability; 4. no optimization strategies provided for finetuning PCP scores.Given these constraints, we aimed to develop an artificial intelligence (AI)-based PCP score calculator and optimizer to overcome these bottlenecks.Protein databases, structural biology, and advanced deep learning models are all integrated into our AI-based PCP score calculator (Fig. 1a).A comprehensive protein structure database consisting of over 170,000 entries was established by extracting 3D structural information from the Protein Data Bank (PDB) and AlphaFold predictions, followed by stringent quality control procedures.We further developed an in-house algorithm tailored for calculating PCP scores based on the obtained 3D structure information (Supplementary Information), subsequently generating a dataset comprising approximately 170,000 protein sequences along with their associated PCP scores.For model training and evaluation, 70% of the data are allocated as the training dataset, while the remaining 30% serve as the test dataset.The ESM2 model, developed by the FAIR (Meta Fundamental AI Research Protein Team), is utilized for fine-tuning tasks related to PCP prediction. 4,5SM2 is a transformer-based language model using an attention mechanism to learn interaction patterns between pairs of amino acids in the input sequence.Pre-trained on over 60 million protein sequences from the UniProt Reference Clusters (UniRef) database, ESM2 demonstrates strong adaptability to downstream protein structure-related tasks. 5The ESM2-8M model was used to fine-tune the training dataset.Following updating parameters, the ESM2 model was transformed into the PCP-AI prediction model, referred to as CAR-Tonic Signal Tuner (abbreviated as CAR-Toner; http://cartfitness.slst.shanghaitech.edu.cn/CAR-fitness/).This model encompasses three key functionalities: proficient PCP calculation for individual proteins, streamlined batch processing, and an integrated optimization strategy for refining PCP scores (Fig. 1b).","<method>deep learning models</method>, <method>ESM2 model</method>, <method>transformer-based language model using an attention mechanism</method>, <method>fine-tuning</method>",<method>ESM2 model</method><method>transformer-based language model using an attention mechanism</method><method>fine-tuning</method>
2024,https://openalex.org/W4390708138,Biology,Accuracy of GPT-4 in histopathological image detection and classification of colorectal adenomas,"Aims To evaluate the accuracy of Chat Generative Pre-trained Transformer (ChatGPT) powered by GPT-4 in histopathological image detection and classification of colorectal adenomas using the diagnostic consensus provided by pathologists as a reference standard. Methods A study was conducted with 100 colorectal polyp photomicrographs, comprising an equal number of adenomas and non-adenomas, classified by two pathologists. These images were analysed by classic GPT-4 for 1 time in October 2023 and custom GPT-4 for 20 times in December 2023. GPT-4’s responses were compared against the reference standard through statistical measures to evaluate its proficiency in histopathological diagnosis, with the pathologists further assessing the model’s descriptive accuracy. Results GPT-4 demonstrated a median sensitivity of 74% and specificity of 36% for adenoma detection. The median accuracy of polyp classification varied, ranging from 16% for non-specific changes to 36% for tubular adenomas. Its diagnostic consistency, indicated by low kappa values ranging from 0.06 to 0.11, suggested only poor to slight agreement. All of the microscopic descriptions corresponded with their diagnoses. GPT-4 also commented about the limitations in its diagnoses (eg, slide diagnosis best done by pathologists, the inadequacy of single-image diagnostic conclusions, the need for clinical data and a higher magnification view). Conclusions GPT-4 showed high sensitivity but low specificity in detecting adenomas and varied accuracy for polyp classification. However, its diagnostic consistency was low. This artificial intelligence tool acknowledged its diagnostic limitations, emphasising the need for a pathologist’s expertise and additional clinical context.","<method>Chat Generative Pre-trained Transformer (ChatGPT) powered by GPT-4</method>, <method>classic GPT-4</method>, <method>custom GPT-4</method>",<method>Chat Generative Pre-trained Transformer (ChatGPT) powered by GPT-4</method>
2024,https://openalex.org/W4390870882,Biology,A domain adaptation approach to damage classification with an application to bridge monitoring,"Data-driven machine-learning algorithms generally suffer from a lack of labelled health-state data, mainly those referring to damage conditions. To address such an issue, population-based structural health monitoring seeks to enrich the original dataset by transferring knowledge from a population of monitored structures. Within this context, this paper presents a transfer learning approach, based on domain adaptation, to leverage information from completely-labelled bridge structure data to accurately predict new instances of an unknown target domain. Since intrinsic structural differences may cause distribution shifts, domain adaptation attempts to minimise the distance between the domains and to learn a mapping within a shared feature space. Specifically, the methodology involves the long-term acquisition of natural frequencies from several structural scenarios. Such damage-sensitive features are then aligned via domain adaptation so that a machine-learning algorithm can effectively utilise the labelled source domain data and generalise well to the unlabelled target-domain data. The described procedure is applied to two case studies, including the Z24 and the S101 benchmark bridges and their finite element models, respectively. The results demonstrate the successful exchange of health-state labels to identify the damage class within a population of bridges equipped with SHM systems, showing potential to reduce computational efforts and to deal with scarce or poor data sets in application to bridge network monitoring.","<method>transfer learning</method>, <method>domain adaptation</method>, <method>machine-learning algorithm</method>",<method>transfer learning</method><method>domain adaptation</method>
2024,https://openalex.org/W4391164184,Biology,Discovering Consensus Regions for Interpretable Identification of RNA N6-Methyladenosine Modification Sites via Graph Contrastive Clustering,"As a pivotal post-transcriptional modification of RNA, N6-methyladenosine (m6A) has a substantial influence on gene expression modulation and cellular fate determination. Although a variety of computational models have been developed to accurately identify potential m6A modification sites, few of them are capable of interpreting the identification process with insights gained from consensus knowledge. To overcome this problem, we propose a deep learning model, namely M6A-DCR, by discovering consensus regions for interpretable identification of m6A modification sites. In particular, M6A-DCR first constructs an instance graph for each RNA sequence by integrating specific positions and types of nucleotides. The discovery of consensus regions is then formulated as a graph clustering problem in light of aggregating all instance graphs. After that, M6A-DCR adopts a motif-aware graph reconstruction optimization process to learn high-quality embeddings of input RNA sequences, thus achieving the identification of m6A modification sites in an end-to-end manner. Experimental results demonstrate the superior performance of M6A-DCR by comparing it with several state-of-the-art identification models. The consideration of consensus regions empowers our model to make interpretable predictions at the motif level. The analysis of cross validation through different species and tissues further verifies the consistency between the identification results of M6A-DCR and the evolutionary relationships among species","<method>deep learning model</method>, <method>graph clustering</method>, <method>motif-aware graph reconstruction optimization</method>",<method>deep learning model</method><method>graph clustering</method>
2024,https://openalex.org/W4392356867,Biology,The SAFE procedure: a practical stopping heuristic for active learning-based screening in systematic reviews and meta-analyses,"Abstract Active learning has become an increasingly popular method for screening large amounts of data in systematic reviews and meta-analyses. The active learning process continually improves its predictions on the remaining unlabeled records, with the goal of identifying all relevant records as early as possible. However, determining the optimal point at which to stop the active learning process is a challenge. The cost of additional labeling of records by the reviewer must be balanced against the cost of erroneous exclusions. This paper introduces the SAFE procedure, a practical and conservative set of stopping heuristics that offers a clear guideline for determining when to end the active learning process in screening software like ASReview. The eclectic mix of stopping heuristics helps to minimize the risk of missing relevant papers in the screening process. The proposed stopping heuristic balances the costs of continued screening with the risk of missing relevant records, providing a practical solution for reviewers to make informed decisions on when to stop screening. Although active learning can significantly enhance the quality and efficiency of screening, this method may be more applicable to certain types of datasets and problems. Ultimately, the decision to stop the active learning process depends on careful consideration of the trade-off between the costs of additional record labeling against the potential errors of the current model for the specific dataset and context.",<method>active learning</method>,<method>active learning</method>
2024,https://openalex.org/W4392661577,Biology,"Machine learning models for gully erosion susceptibility assessment in the Tensift catchment, Haouz Plain, Morocco for sustainable development","Gully erosion is a widespread environmental danger, threatening global socio-economic stability and sustainable development. This study comprehensively applied seven machine learning (ML) models including SVM, KNN, RF, XGBoost, ANN, DT, and LR, and evaluated gully erosion susceptibility in the Tensift catchment and predict it within the Haouz plain, Morocco. To ensure the reliability of the findings, the study employed a robust combination of gully erosion inventory, sentinel images, and Digital Surface Model. Eighteen predictors, encompassing topographical, geomorphological, environmental, and hydrological factors, were selected after multicollinearity analyses. The gully erosion susceptibility of the study revealed that approximately 28.18% of the Tensift catchment is at a very high risk of erosion. Furthermore, 15.13% and 31.28% of the catchment are categorized as low and very low respectively. These findings extend to the Haouz plain, where 7.84% of the surface area are very highly risking erosion, while 18.25% and 55.18% are characterized as low and very low risk areas. To gauge the performance of the ML models, an array of metrics including specificity, precision, sensitivity, and accuracy were employed. The study highlights XGBoost and KNN as the most promising models, achieving AUC ROC values of 0.96 and 0.93 in the test phase. The remaining models namely RF (AUC ROC = 0.89), LR (AUC ROC = 0.80), SVM (AUC ROC = 0.81), DT (AUC ROC = 0.86), and ANN (AUC ROC = 0.78), also displayed commendable performance. The novelty of this research is its innovative approach to combat gully erosion through cutting edge ML models, offering practical solutions for watershed conservation, sustainable management, and the prevention of land degradation. These insights are invaluable for addressing the challenges posed by gully erosion within the region, and beyond its geographical boundaries and can be used for defining appropriate mitigation strategies at local to national scale.","<method>SVM</method>, <method>KNN</method>, <method>RF</method>, <method>XGBoost</method>, <method>ANN</method>, <method>DT</method>, <method>LR</method>",<method>SVM</method><method>KNN</method><method>RF</method><method>XGBoost</method><method>ANN</method><method>DT</method><method>LR</method>
2024,https://openalex.org/W4390703358,Biology,A Deep Bidirectional LSTM Model Enhanced by Transfer-Learning-Based Feature Extraction for Dynamic Human Activity Recognition,"Dynamic human activity recognition (HAR) is a domain of study that is currently receiving considerable attention within the fields of computer vision and pattern recognition. The growing need for artificial-intelligence (AI)-driven systems to evaluate human behaviour and bolster security underscores the timeliness of this research. Despite the strides made by numerous researchers in developing dynamic HAR frameworks utilizing diverse pre-trained architectures for feature extraction and classification, persisting challenges include suboptimal performance accuracy and the computational intricacies inherent in existing systems. These challenges arise due to the vast video-based datasets and the inherent similarity in the data. To address these challenges, we propose an innovative, dynamic HAR technique employing a deep-learning-based, deep bidirectional long short-term memory (Deep BiLSTM) model facilitated by a pre-trained transfer-learning-based feature-extraction approach. Our approach begins with the utilization of Convolutional Neural Network (CNN) models, specifically MobileNetV2, for extracting deep-level features from video frames. Subsequently, these features are fed into an optimized deep bidirectional long short-term memory (Deep BiLSTM) network to discern dependencies and process data, enabling optimal predictions. During the testing phase, an iterative fine-tuning procedure is introduced to update the high parameters of the trained model, ensuring adaptability to varying scenarios. The proposed model’s efficacy was rigorously evaluated using three benchmark datasets, namely UCF11, UCF Sport, and JHMDB, achieving notable accuracies of 99.20%, 93.3%, and 76.30%, respectively. This high-performance accuracy substantiates the superiority of our proposed model, signaling a promising advancement in the domain of activity recognition.","<method>deep bidirectional long short-term memory (Deep BiLSTM)</method>, <method>pre-trained transfer-learning-based feature-extraction approach</method>, <method>Convolutional Neural Network (CNN)</method>, <method>MobileNetV2</method>",<method>deep bidirectional long short-term memory (Deep BiLSTM)</method><method>pre-trained transfer-learning-based feature-extraction approach</method><method>Convolutional Neural Network (CNN)</method><method>MobileNetV2</method>
2024,https://openalex.org/W4390881001,Biology,A multimodal graph neural network framework for cancer molecular subtype classification,"Abstract Background The recent development of high-throughput sequencing has created a large collection of multi-omics data, which enables researchers to better investigate cancer molecular profiles and cancer taxonomy based on molecular subtypes. Integrating multi-omics data has been proven to be effective for building more precise classification models. Most current multi-omics integrative models use either an early fusion in the form of concatenation or late fusion with a separate feature extractor for each omic, which are mainly based on deep neural networks. Due to the nature of biological systems, graphs are a better structural representation of bio-medical data. Although few graph neural network (GNN) based multi-omics integrative methods have been proposed, they suffer from three common disadvantages. One is most of them use only one type of connection, either inter-omics or intra-omic connection; second, they only consider one kind of GNN layer, either graph convolution network (GCN) or graph attention network (GAT); and third, most of these methods have not been tested on a more complex classification task, such as cancer molecular subtypes. Results In this study, we propose a novel end-to-end multi-omics GNN framework for accurate and robust cancer subtype classification. The proposed model utilizes multi-omics data in the form of heterogeneous multi-layer graphs, which combine both inter-omics and intra-omic connections from established biological knowledge. The proposed model incorporates learned graph features and global genome features for accurate classification. We tested the proposed model on the Cancer Genome Atlas (TCGA) Pan-cancer dataset and TCGA breast invasive carcinoma (BRCA) dataset for molecular subtype and cancer subtype classification, respectively. The proposed model shows superior performance compared to four current state-of-the-art baseline models in terms of accuracy, F1 score, precision, and recall. The comparative analysis of GAT-based models and GCN-based models reveals that GAT-based models are preferred for smaller graphs with less information and GCN-based models are preferred for larger graphs with extra information.","<method>deep neural networks</method>, <method>graph neural network (GNN)</method>, <method>graph convolution network (GCN)</method>, <method>graph attention network (GAT)</method>",<method>deep neural networks</method><method>graph neural network (GNN)</method><method>graph convolution network (GCN)</method><method>graph attention network (GAT)</method>
2024,https://openalex.org/W4392450360,Biology,Geographically weighted machine learning for modeling spatial heterogeneity in traffic crash frequency and determinants in US,"Spatial analyses of traffic crashes have drawn much interest due to the nature of the spatial dependence and spatial heterogeneity in the crash data. This study makes the best of Geographically Weighted Random Forest (GW-RF) model to explore the local associations between crash frequency and various influencing factors in the US, including road network attributes, socio-economic characteristics, and land use factors collected from multiple data sources. Special emphasis is put on modeling the spatial heterogeneity in the effects of a factor on crash frequency in different geographical areas in a data-driven way. The GW-RF model outperforms global models (e.g. Random Forest) and conventional geographically weighted regression, demonstrating superior predictive accuracy and elucidating spatial variations. The GW-RF model reveals spatial distinctions in the effects of certain factors on crash frequency. For example, the importance of intersection density varies significantly across regions, with high significance in the southern and northeastern areas. Low-grade road density emerges as influential in specific cities. The findings highlight the significance of different factors in influencing crash frequency across zones. Road network factors, particularly intersection density, exhibit high importance universally, while socioeconomic variables demonstrate moderate effects. Interestingly, land use variables show relatively lower importance. The outcomes could help to allocate resources and implement tailored interventions to reduce the likelihood of crashes.","<method>Geographically Weighted Random Forest (GW-RF)</method>, <method>Random Forest</method>, <method>geographically weighted regression</method>",<method>Geographically Weighted Random Forest (GW-RF)</method><method>Random Forest</method>
2024,https://openalex.org/W4399649641,Biology,An artificial intelligence-assisted microfluidic colorimetric wearable sensor system for monitoring of key tear biomarkers,"Abstract The precise, simultaneous, and rapid detection of essential biomarkers in human tears is imperative for monitoring both ocular and systemic health. The utilization of a wearable colorimetric biochemical sensor exhibits potential in achieving swift and concurrent detection of pivotal biomarkers in tears. Nevertheless, challenges arise in the collection, interpretation, and sharing of data from the colorimetric sensor, thereby restricting the practical implementation of this technology. To overcome these challenges, this research introduces an artificial intelligence-assisted wearable microfluidic colorimetric sensor system (AI-WMCS) for rapid, non-invasive, and simultaneous detection of key biomarkers in human tears, including vitamin C, H + (pH), Ca 2+ , and proteins. The sensor consists of a flexible microfluidic epidermal patch that collects tears and facilitates the colorimetric reaction, and a deep-learning neural network-based cloud server data analysis system (CSDAS) embedded in a smartphone enabling color data acquisition, interpretation, auto-correction, and display. To enhance accuracy, a well-trained multichannel convolutional recurrent neural network (CNN-GRU) corrects errors in the interpreted concentration data caused by varying pH and color temperature in different measurements. The test set determination coefficients (R 2 ) of 1D-CNN-GRU for predicting pH and 3D-CNN-GRU for predicting the other three biomarkers were as high as 0.998 and 0.994, respectively. This correction significantly improves the accuracy of the predicted concentration, enabling accurate, simultaneous, and quick detection of four critical tear biomarkers using only minute amounts of tears ( ~ 20 μL). This research demonstrates the powerful integration of a flexible microfluidic colorimetric biosensor and deep-learning algorithm, which holds immense potential to revolutionize the fields of health monitoring.","<method>deep-learning neural network-based cloud server data analysis system (CSDAS)</method>, <method>multichannel convolutional recurrent neural network (CNN-GRU)</method>, <method>1D-CNN-GRU</method>, <method>3D-CNN-GRU</method>",<method>multichannel convolutional recurrent neural network (CNN-GRU)</method><method>1D-CNN-GRU</method><method>3D-CNN-GRU</method>
2024,https://openalex.org/W4391071022,Biology,Weaving a greener future: The impact of green human resources management and green supply chain management on sustainable performance in Bangladesh's textile industry,"The purpose of this study is to investigate the impact of Green Human Resource Management (GHRM) and Green Supply Chain Management (GSCM) on the sustainable performance of the Bangladeshi textile sector. Specifically, the study focuses on environmental and employee-related aspects. Additionally, we examine how environmental performance and employee performance mediate the relationship between GHRM and GSCM. This study draws upon data collected from 450 employees across various textile enterprises in Bangladesh. Structural Equation Modeling is employed using the Amos 24 software to analyze the relationships and interactions among these variables. These findings demonstrate that using environmentally sustainable practices in human resource management and supply chain management results in enhanced sustainability. The study indicates that environmental performance significantly influences the relationship between GHRM and GSCM regarding sustainable performance. The study findings indicate that firms operating in the textile industry should implement GHRM and GSCM practices to enhance their sustainability performance. Additionally, it is recommended that these organizations prioritize the well-being and engagement of their employees. Implementing such a strategy can bolster the organization's comprehensive sustainability initiatives and raise its standing among stakeholders. This study contributes to the expanding body of literature on textile sustainability by investigating the mediating role of employee and environmental performance. It emphasizes the significance of GHRM and GSCM techniques in improving sustainable performance. The findings provide valuable insights for firms seeking to develop more effective sustainability initiatives.",<method>Structural Equation Modeling</method>,No methods remaining
2024,https://openalex.org/W4391243967,Biology,Reviews and syntheses: Remotely sensed optical time series for monitoring vegetation productivity,"Abstract. Vegetation productivity is a critical indicator of global ecosystem health and is impacted by human activities and climate change. A wide range of optical sensing platforms, from ground-based to airborne and satellite, provide spatially continuous information on terrestrial vegetation status and functioning. As optical Earth observation (EO) data are usually routinely acquired, vegetation can be monitored repeatedly over time, reflecting seasonal vegetation patterns and trends in vegetation productivity metrics. Such metrics include gross primary productivity, net primary productivity, biomass, or yield. To summarize current knowledge, in this paper we systematically reviewed time series (TS) literature for assessing state-of-the-art vegetation productivity monitoring approaches for different ecosystems based on optical remote sensing (RS) data. As the integration of solar-induced fluorescence (SIF) data in vegetation productivity processing chains has emerged as a promising source, we also include this relatively recent sensor modality. We define three methodological categories to derive productivity metrics from remotely sensed TS of vegetation indices or quantitative traits: (i) trend analysis and anomaly detection, (ii) land surface phenology, and (iii) integration and assimilation of TS-derived metrics into statistical and process-based dynamic vegetation models (DVMs). Although the majority of used TS data streams originate from data acquired from satellite platforms, TS data from aircraft and unoccupied aerial vehicles have found their way into productivity monitoring studies. To facilitate processing, we provide a list of common toolboxes for inferring productivity metrics and information from TS data. We further discuss validation strategies of the RS data derived productivity metrics: (1) using in situ measured data, such as yield; (2) sensor networks of distinct sensors, including spectroradiometers, flux towers, or phenological cameras; and (3) inter-comparison of different productivity metrics. Finally, we address current challenges and propose a conceptual framework for productivity metrics derivation, including fully integrated DVMs and radiative transfer models here labelled as “Digital Twin”. This novel framework meets the requirements of multiple ecosystems and enables both an improved understanding of vegetation temporal dynamics in response to climate and environmental drivers and enhances the accuracy of vegetation productivity monitoring.","<method>trend analysis and anomaly detection</method>, <method>land surface phenology</method>, <method>integration and assimilation of time series-derived metrics into statistical and process-based dynamic vegetation models (DVMs)</method>, <method>fully integrated dynamic vegetation models (DVMs) and radiative transfer models (“Digital Twin” framework)</method>",No methods remaining
2024,https://openalex.org/W4391665000,Biology,A comprehensive review of critical analysis of biodegradable waste PCM for thermal energy storage systems using machine learning and deep learning to predict dynamic behavior,"This article explores the use of phase change materials (PCMs) derived from waste, in energy storage systems. It emphasizes the potential of these PCMs in addressing concerns related to fossil fuel usage and environmental impact. This article also highlights the aspects of these PCMs including reduced reliance on renewable resources minimized greenhouse gas emissions and waste reduction. The study also discusses approaches such as integrating nanotechnology to enhance thermal conductivity and utilizing machine learning and deep learning techniques for predicting dynamic behavior. The article provides an overall view of research on biodegradable waste-based PCMs and how they can play a promising role in achieving energy-efficient and sustainable thermal storage systems. However, specific conclusions drawn from the presented results are not explicitly outlined, leaving room, for investigation and exploration in this evolving field. Artificial neural network (ANN) predictive models for thermal energy storage devices perform differently. With a 4% adjusted mean absolute error, the Gaussian radial basis function kernel Support Vector Regression (SVR) model captured heat-related charging and discharging issues. The ANN model predicted finned tube heat and heat flux better than the numerical model. SVM models outperformed ANN and ANFIS in some datasets. Material property predictions favored gradient boosting, but Linear Regression and SVR models performed better, emphasizing application- and dataset-specific model selection. These predictive models provide insights into the complex thermal performance of building structures, aiding in the design and operation of energy-efficient systems. Biodegradable waste-based PCMs' sustainability includes carbon footprint, waste reduction, biodegradability, and circular economy alignment. Nanotechnology, machine learning, and deep learning improve thermal conductivity and prediction. Circular economy principles include waste reduction and carbon footprint reduction. Specific results-based conclusions are not stated. Presenting a comprehensive overview of current research highlights biodegradable waste-based PCMs' potential for energy-efficient and sustainable thermal storage systems.","<method>machine learning</method>, <method>deep learning</method>, <method>Artificial neural network (ANN)</method>, <method>Gaussian radial basis function kernel Support Vector Regression (SVR)</method>, <method>Support Vector Machine (SVM)</method>, <method>Adaptive Neuro-Fuzzy Inference System (ANFIS)</method>, <method>gradient boosting</method>, <method>Linear Regression</method>",<method>machine learning</method><method>deep learning</method><method>Artificial neural network (ANN)</method><method>Gaussian radial basis function kernel Support Vector Regression (SVR)</method><method>Support Vector Machine (SVM)</method><method>Adaptive Neuro-Fuzzy Inference System (ANFIS)</method><method>gradient boosting</method><method>Linear Regression</method>
2024,https://openalex.org/W4392112102,Biology,Coupling Deep Learning and Physically Based Hydrological Models for Monthly Streamflow Predictions,"Abstract This study proposes a new hybrid model for monthly streamflow predictions by coupling a physically based distributed hydrological model with a deep learning (DL) model. Specifically, a simplified hydrological model is first developed by optimally selecting grid cells from a distributed hydrological model according to their soil moisture characteristics. It is then driven by bias corrected general circulation model (GCM) predictions to generate soil moistures for the forecasting months. Finally, model‐simulated soil moisture along with other predictors from multiple sources are used as inputs of the DL model to predict future monthly streamflows. The proposed hybrid model, using the simplified Variable Infiltration Capacity (VIC) as the hydrological model and the combination of Convolutional Neural Network and Gated Recurrent Unit (CNN‐GRU) as the DL model, is applied to predict 1‐, 3‐, and 6‐month ahead reservoir inflows for the Danjiangkou Reservoir in China. The results show that the hybrid model consistently performs better than VIC and CNN‐GRU models with great improvement in Kling‐Gupta efficiency (KGE) values for lead times up to 6 months. Additional tests indicate that hybrid models based on CNN‐GRU outperform those based on LASSO, XGBoost, CNN, and GRU models. Moreover, compared with the distributed hydrological model, the hybrid model greatly reduces the computation burden of rolling prediction. It also saves decision‐makers the time and effort of trying different combinations of predictors, which is indispensable when building DL models. Overall, the new hybrid model demonstrates great potential for monthly streamflow prediction where training data are limited.","<method>deep learning (DL) model</method>, <method>Convolutional Neural Network (CNN)</method>, <method>Gated Recurrent Unit (GRU)</method>, <method>CNN-GRU</method>, <method>LASSO</method>, <method>XGBoost</method>, <method>CNN</method>, <method>GRU</method>",<method>Convolutional Neural Network (CNN)</method><method>Gated Recurrent Unit (GRU)</method><method>CNN-GRU</method><method>LASSO</method><method>XGBoost</method><method>CNN</method><method>GRU</method>
2024,https://openalex.org/W4392124217,Biology,A structural equation modeling framework for exploring the industry 5.0 and sustainable supply chain determinants,"Sustainable Supply Chain and Industry 5.0 are two important concepts reshaping how businesses operate in the modern world. Together, these two concepts drive the advancement of a highly sustainable and robust worldwide economy. Companies are now becoming more sustainable in supply chain management, using technologies like blockchain and co-bots to track the origin of goods, ensure ethical and sustainable sourcing, and work with humans safely and effectively. This study develops a theoretical model highlighting the determinants of Industry 5.0, Sustainable Supply Chain Practices, by combining theoretical frameworks from the manufacturing, supply chain, and information systems literature. The study's analytic sample comprises 342 responses collected from professionals working in the electronics industry's supply chain. Hypotheses were constructed employing deductive reasoning, leveraging insights gleaned from prior research. The study is conducted utilizing the Structural Equation Modeling (SEM) to substantiate the presumed connections among various constructs, namely, Industry 5.0 innovations, Sustainable Supply Chain Practices (SSCP), Sustainable Supply Chain Performance (SCP), and Supply Chain Risks (SCR). The Structural Equation Modeling analysis results show a direct impact of Industry 5.0 technologies through Sustainable Supply Chain Practices can enhance Supply Chain Performance and mitigate Supply Chain Risks. Combining the two paradigms can foster the development of new business models that prioritize sustainability and contribute to a more equitable and environmentally friendly economy that brings positive change for both businesses and society.",<method>Structural Equation Modeling (SEM)</method>,No methods remaining
2024,https://openalex.org/W4400061043,Biology,MTMol-GPT: De novo multi-target molecular generation with transformer-based generative adversarial imitation learning,"De novo drug design is crucial in advancing drug discovery, which aims to generate new drugs with specific pharmacological properties. Recently, deep generative models have achieved inspiring progress in generating drug-like compounds. However, the models prioritize a single target drug generation for pharmacological intervention, neglecting the complicated inherent mechanisms of diseases, and influenced by multiple factors. Consequently, developing novel multi-target drugs that simultaneously target specific targets can enhance anti-tumor efficacy and address issues related to resistance mechanisms. To address this issue and inspired by Generative Pre-trained Transformers (GPT) models, we propose an upgraded GPT model with generative adversarial imitation learning for multi-target molecular generation called MTMol-GPT. The multi-target molecular generator employs a dual discriminator model using the Inverse Reinforcement Learning (IRL) method for a concurrently multi-target molecular generation. Extensive results show that MTMol-GPT generates various valid, novel, and effective multi-target molecules for various complex diseases, demonstrating robustness and generalization capability. In addition, molecular docking and pharmacophore mapping experiments demonstrate the drug-likeness properties and effectiveness of generated molecules potentially improve neuropsychiatric interventions. Furthermore, our model’s generalizability is exemplified by a case study focusing on the multi-targeted drug design for breast cancer. As a broadly applicable solution for multiple targets, MTMol-GPT provides new insight into future directions to enhance potential complex disease therapeutics by generating high-quality multi-target molecules in drug discovery.","<method>Generative Pre-trained Transformers (GPT)</method>, <method>generative adversarial imitation learning</method>, <method>Inverse Reinforcement Learning (IRL)</method>",<method>Generative Pre-trained Transformers (GPT)</method><method>generative adversarial imitation learning</method><method>Inverse Reinforcement Learning (IRL)</method>
2024,https://openalex.org/W4401209403,Biology,AI-Driven Deep Learning Techniques in Protein Structure Prediction,"Protein structure prediction is important for understanding their function and behavior. This review study presents a comprehensive review of the computational models used in predicting protein structure. It covers the progression from established protein modeling to state-of-the-art artificial intelligence (AI) frameworks. The paper will start with a brief introduction to protein structures, protein modeling, and AI. The section on established protein modeling will discuss homology modeling, ab initio modeling, and threading. The next section is deep learning-based models. It introduces some state-of-the-art AI models, such as AlphaFold (AlphaFold, AlphaFold2, AlphaFold3), RoseTTAFold, ProteinBERT, etc. This section also discusses how AI techniques have been integrated into established frameworks like Swiss-Model, Rosetta, and I-TASSER. The model performance is compared using the rankings of CASP14 (Critical Assessment of Structure Prediction) and CASP15. CASP16 is ongoing, and its results are not included in this review. Continuous Automated Model EvaluatiOn (CAMEO) complements the biennial CASP experiment. Template modeling score (TM-score), global distance test total score (GDT_TS), and Local Distance Difference Test (lDDT) score are discussed too. This paper then acknowledges the ongoing difficulties in predicting protein structure and emphasizes the necessity of additional searches like dynamic protein behavior, conformational changes, and protein-protein interactions. In the application section, this paper introduces some applications in various fields like drug design, industry, education, and novel protein development. In summary, this paper provides a comprehensive overview of the latest advancements in established protein modeling and deep learning-based models for protein structure predictions. It emphasizes the significant advancements achieved by AI and identifies potential areas for further investigation.","<method>homology modeling</method>, <method>ab initio modeling</method>, <method>threading</method>, <method>AlphaFold</method>, <method>AlphaFold2</method>, <method>AlphaFold3</method>, <method>RoseTTAFold</method>, <method>ProteinBERT</method>",<method>AlphaFold</method><method>AlphaFold2</method><method>RoseTTAFold</method><method>ProteinBERT</method>
2024,https://openalex.org/W4390660035,Biology,An Empirical Study on Correlations Between Deep Neural Network Fairness and Neuron Coverage Criteria,"Recently, with the widespread use of deep neural networks (DNNs) in high-stakes decision-making systems (such as fraud detection and prison sentencing), concerns have arisen about the fairness of DNNs in terms of the potential negative impact they may have on individuals and society. Therefore, fairness testing has become an important research topic in DNN testing. At the same time, the neural network coverage criteria (such as criteria based on neuronal activation) is considered as an adequacy test for DNN white-box testing. It is implicitly assumed that improving the coverage can enhance the quality of test suites. Nevertheless, the correlation between DNN fairness (a test property) and coverage criteria (a test method) has not been adequately explored. To address this issue, we conducted a systematic empirical study on seven coverage criteria, six fairness metrics, three fairness testing techniques, and five bias mitigation methods on five DNN models and nine fairness datasets to assess the correlation between coverage criteria and DNN fairness. Our study achieved the following findings: 1) with the increase in the size of the test suite, some of the coverage and fairness metrics changed significantly, as the size of the test suite increased; 2) the statistical correlation between coverage criteria and DNN fairness is limited; and 3) after bias mitigation for improving the fairness of DNN, the change pattern in coverage criteria is different; 4) Models debiased by different bias mitigation methods have a lower correlation between coverage and fairness compared to the original models. Our findings cast doubt on the validity of coverage criteria concerning DNN fairness (i.e., increasing the coverage may even have a negative impact on the fairness of DNNs). Therefore, we warn DNN testers against blindly pursuing higher coverage of coverage criteria at the cost of test properties of DNNs (such as fairness).","<method>deep neural networks (DNNs)</method>, <method>neural network coverage criteria</method>, <method>fairness testing techniques</method>, <method>bias mitigation methods</method>",<method>deep neural networks (DNNs)</method><method>bias mitigation methods</method>
2024,https://openalex.org/W4391097037,Biology,An Early and Smart Detection of Corn Plant Leaf Diseases Using IoT and Deep Learning Multi-Models,"Plant leaf diseases have various causes, leading to severe disorders. The early and accurate detection and classification of these diseases are fundamental for fostering healthy crop production. In recent years, smart agricultural systems have garnered significant attention due to their capability to enhance efficiency by deploying sensor networks and Internet of Things (IoT) devices that collect and analyze environmental data. However, traditional plant disease detection methods are manual, time-consuming, and often need help handling the data's complexity and dynamism. These manual methods do not use heterogeneous data to make better decisions. Corn holds significant importance yet it faces numerous diseases that include main three diseases such as blight, common rust, and grey leaf spot. The advancement of computer technology has led to a pivotal focus on corn leaf diseases classification application based on deep learning. Convolutional Neural Networks (CNNs) have revealed remarkable achievements within Precision Agriculture (PA) due to their ability to enhance information. To this end, this work introduces a CNN-based architecture, the Multi-Model Fusion Network (MMF-Net). Its primary objective is to classify diseases within the realm of PA. MMF-Net integrates multi-contextual features using RL-block and PL-blocks 1 & 2, thus effectively combining different model streams trained on heterogeneous data. The RL-block uses spatial range to process coarse grained images to convolve the local context, while PL-block 1 extracts fine-grained global context by expanding the perceptual area of images. PL-block 2 deals with real-life environmental parameters as features. The extracted features are syndicated using multiple classifiers that ensemble three individual blocks at the decision level to improve the accuracy. After fusion, it uses adaptively the majority voting scheme to generate the final decision probability score of the base model. Multiple experiments are conducted involving the corn leaf diseases dataset and a real-life numerical dataset, generating an impressive 99.23% accuracy in the classification of corn leaf diseases. Overall, MMF-Net provides a promising and smart solution to identify plant leaf diseases in PA effectively.","<method>Convolutional Neural Networks (CNNs)</method>, <method>Multi-Model Fusion Network (MMF-Net)</method>, <method>RL-block</method>, <method>PL-block 1</method>, <method>PL-block 2</method>, <method>multiple classifiers ensemble</method>, <method>majority voting scheme</method>",<method>Convolutional Neural Networks (CNNs)</method><method>multiple classifiers ensemble</method>
2024,https://openalex.org/W4391708122,Biology,Application of machine learning approaches in supporting irrigation decision making: A review,"Irrigation decision-making has evolved from solely depending on farmers' decisions taken based on the visual analysis of field conditions to making decisions based on crop water need predictions generated using machine learning (ML) techniques. This paper reviews ML related articles to discuss how ML has been used to enhance irrigation decision making. We reviewed 16 studies that used ML approaches for irrigation scheduling prediction and decision-making focusing on the input features, algorithms used and their applicability in real world conditions. ML performances in terms of accuracy, water conservation compared to fixed or threshold-based methods are discussed along with modeling performances. Informed by the 16 research studies, we assessed constraints to the adoption of ML in irrigation decision making at field scale, which include limited data availability coupled with data sharing constraints, and a lack of uncertainty quantification as well as the need for physics informed ML based irrigation scheduling models. To address these limitations, we discussed approaches in future research such as integrating process-based models with ML, incorporating expert knowledge into the modeling procedure, and making data and tools Findable, Accessible, Interoperable, and Reusable (FAIR). These approaches will improve ML modeling outcomes and boost the availability of farm-related data and tools for FAIRer data-driven applications of irrigation modeling.","<method>machine learning (ML) techniques</method>, <method>ML approaches</method>, <method>process-based models integrated with ML</method>, <method>physics informed ML based irrigation scheduling models</method>",No methods remaining
2024,https://openalex.org/W4392359418,Biology,Construction and optimization of watershed-scale ecological network based on complex network method: A case study of Erhai Lake Basin in China,"The ecological network construction and optimization are of great significance in ensuring regional ecological security and optimizing the ecological space of the national territory, therefore constructing the ecological spatial network and proposing optimization countermeasures are conducive to enhancing regional ecological stability. However, current research on ecological networks ignores the ecospatial community structure and the topology characteristics of ecological networks, and lacks a systematic optimization framework. The research scope of the ecological network primarily concentrates on urban administrative units, with less emphasis on the geographic scale of watersheds. This approach is not conducive to the comprehensive management of all elements of ecosystems. Therefore, this research took Erhai Lake Basin as an object, adopted Morphological Spatial Pattern Analysis (MSPA) and landscape connectivity to extract ecological sources, simulate corridors and identify the weak points through the model of Minimum Cumulative Resistance (MCR) and gravity model, constructed the ecological network of Erhai Lake Basin, topologized the ecological network by using the Gephi platform. Based on the results of the analysis of complex network indicators, the optimization strategy of increasing edges was proposed. Priority conservation areas were further identified, an ecological security pattern was designed, and an ecological restoration strategy was planned. Results show that 28 ecological sources, 378 potential ecological corridors, 48 important ecological corridors and 86 ecological weak points formed the complex ecological network in Erhai Lake Basin. The network had clear clustering characteristics and instability, with a high degree concentration in the northeast and uneven betweenness centrality, especially higher in the east. Through topology analysis, 12 increased edge nodes were identified, 9 increased edges were simulated, and 26 weak points were added, significantly improving the network robustness. Based on the ecological security pattern, the restoration strategy with strict control around the lake, conservation of barrier belts and management of priority areas were designed. This study implemented increased edge optimization based on complex network analysis to enhance the stability of the network, which provides a theoretical basis for the optimization of the spatial pattern of Erhai Lake Basin, and is a useful exploration of the ecologically fragile watersheds to protect the environment and achieve high-quality sustainable development.","<method>Morphological Spatial Pattern Analysis (MSPA)</method>, <method>Minimum Cumulative Resistance (MCR) model</method>, <method>gravity model</method>, <method>complex network analysis</method>",No methods remaining
2024,https://openalex.org/W4392404413,Biology,Investigating the Impact of Train / Test Split Ratio on the Performance of Pre-Trained Models with Custom Datasets,"The proper allocation of data between training and testing is a critical factor influencing the performance of deep learning models, especially those built upon pre-trained architectures. Having the suitable training set size is an important factor for the classification model’s generalization performance. The main goal of this study is to find the appropriate training set size for three pre-trained networks using different custom datasets. For this aim, the study presented in this paper explores the effect of varying the train / test split ratio on the performance of three popular pre-trained models, namely MobileNetV2, ResNet50v2 and VGG19, with a focus on image classification task. In this work, three balanced datasets never seen by the models have been used, each containing 1000 images divided into two classes. The train / test split ratios used for this study are: 60-40, 70-30, 80-20 and 90-10. The focus was on the critical metrics of sensitivity, specificity and overall accuracy to evaluate the performance of the classifiers under the different ratios. Experimental results show that, the performance of the classifiers is affected by varying the training / testing split ratio for the three custom datasets. Moreover, with the three pre-trained models, using more than 70% of the dataset images for the training task gives better performance.","<method>MobileNetV2</method>, <method>ResNet50v2</method>, <method>VGG19</method>",<method>MobileNetV2</method><method>ResNet50v2</method><method>VGG19</method>
2024,https://openalex.org/W4393044095,Biology,"Comparative performance analysis of Boruta, SHAP, and Borutashap for disease diagnosis: A study with multiple machine learning algorithms","Interpretable machine learning models are instrumental in disease diagnosis and clinical decision-making, shedding light on relevant features. Notably, Boruta, SHAP (SHapley Additive exPlanations), and BorutaShap were employed for feature selection, each contributing to the identification of crucial features. These selected features were then utilized to train six machine learning algorithms, including LR, SVM, ETC, AdaBoost, RF, and LR, using diverse medical datasets obtained from public sources after rigorous preprocessing. The performance of each feature selection technique was evaluated across multiple ML models, assessing accuracy, precision, recall, and F1-score metrics. Among these, SHAP showcased superior performance, achieving average accuracies of 80.17%, 85.13%, 90.00%, and 99.55% across diabetes, cardiovascular, statlog, and thyroid disease datasets, respectively. Notably, the LGBM emerged as the most effective algorithm, boasting an average accuracy of 91.00% for most disease states. Moreover, SHAP enhanced the interpretability of the models, providing valuable insights into the underlying mechanisms driving disease diagnosis. This comprehensive study contributes significant insights into feature selection techniques and machine learning algorithms for disease diagnosis, benefiting researchers and practitioners in the medical field. Further exploration of feature selection methods and algorithms holds promise for advancing disease diagnosis methodologies, paving the way for more accurate and interpretable diagnostic models.","<method>Boruta</method>, <method>SHAP (SHapley Additive exPlanations)</method>, <method>BorutaShap</method>, <method>LR</method>, <method>SVM</method>, <method>ETC</method>, <method>AdaBoost</method>, <method>RF</method>, <method>LGBM</method>",<method>Boruta</method><method>SHAP (SHapley Additive exPlanations)</method><method>LR</method><method>SVM</method><method>AdaBoost</method><method>RF</method><method>LGBM</method>
2024,https://openalex.org/W4395479913,Biology,Machinability investigation of natural fibers reinforced polymer matrix composite under drilling: Leveraging machine learning in bioengineering applications,"The growing demand for fiber-reinforced polymer (FRP) in industrial applications has prompted the exploration of natural fiber-based composites as a viable alternative to synthetic fibers. Using jute–rattan fiber-reinforced composite offers the potential for environmentally sustainable waste material decomposition and cost reduction compared to conventional fiber materials. This article focuses on the impact of different machining constraints on surface roughness and delamination during the drilling process of the jute–rattan FRP composite. Inspired by this unexplored research area, this article emphasizes the influence of various machining constraints on surface roughness and delamination in drilling jute–rattan FRP composite. Response surface methodology designs the experiment using drill bit material, spindle speed, and feed rate as input variables to measure surface roughness and delamination factors. The technique of order of preference by similarity to the ideal solution method is used to optimize the machining parameters, and for predicting surface roughness and delamination, two machine learning-based models named random forest (RF) and support vector machine (SVM) are utilized. To evaluate the accuracy of the predicted values, the correlation coefficient (R2), mean absolute percentage error, and mean squared error were used. RF performed better in comparison with SVM, with a higher value of R2 for both testing and training datasets, which is 0.997, 0.981, and 0.985 for surface roughness, entry delamination, and exit delamination, respectively. Hence, this study presents an innovative methodology for predicting surface roughness and delamination through machine learning techniques.","<method>random forest (RF)</method>, <method>support vector machine (SVM)</method>",<method>random forest (RF)</method><method>support vector machine (SVM)</method>
2024,https://openalex.org/W4403158403,Biology,Artificial intelligence alphafold model for molecular biology and drug discovery: a machine-learning-driven informatics investigation,"AlphaFold model has reshaped biological research. However, vast unstructured data in the entire AlphaFold field requires further analysis to fully understand the current research landscape and guide future exploration. Thus, this scientometric analysis aimed to identify critical research clusters, track emerging trends, and highlight underexplored areas in this field by utilizing machine-learning-driven informatics methods. Quantitative statistical analysis reveals that the AlphaFold field is enjoying an astonishing development trend (Annual Growth Rate = 180.13%) and global collaboration (International Co-authorship = 33.33%). Unsupervised clustering algorithm, time series tracking, and global impact assessment point out that Cluster 3 (Artificial Intelligence-Powered Advancements in AlphaFold for Structural Biology) has the greatest influence (Average Citation = 48.36 ± 184.98). Additionally, regression curve and hotspot burst analysis highlight ""structure prediction"" (s = 12.40, R2 = 0.9480, p = 0.0051), ""artificial intelligence"" (s = 5.00, R2 = 0.8096, p = 0.0375), ""drug discovery"" (s = 1.90, R2 = 0.7987, p = 0.0409), and ""molecular dynamics"" (s = 2.40, R2 = 0.8000, p = 0.0405) as core hotspots driving the research frontier. More importantly, the Walktrap algorithm further reveals that ""structure prediction, artificial intelligence, molecular dynamics"" (Relevance Percentage[RP] = 100%, Development Percentage[DP] = 25.0%), ""sars-cov-2, covid-19, vaccine design"" (RP = 97.8%, DP = 37.5%), and ""homology modeling, virtual screening, membrane protein"" (RP = 89.9%, DP = 26.1%) are closely intertwined with the AlphaFold model but remain underexplored, which implies a broad exploration space. In conclusion, through the machine-learning-driven informatics methods, this scientometric analysis offers an objective and comprehensive overview of global AlphaFold research, identifying critical research clusters and hotspots while prospectively pointing out underexplored critical areas.","<method>unsupervised clustering algorithm</method>, <method>Walktrap algorithm</method>",<method>unsupervised clustering algorithm</method>
2024,https://openalex.org/W4391202196,Biology,Screening of miRNAs as prognostic biomarkers and their associated hub targets across Hepatocellular carcinoma using survival-based bioinformatics approach,"The hepatocellular carcinoma (HCC) incident rate is gradually increasing yearly despite all the research and efforts taken by scientific communities and governing bodies. Approximately 90% of all liver cancer cases belong to HCC. Usually, HCC patients approach the treatment in the late stages of this malignancy which becomes the primary cause of high mortality rate. The knowledge about molecular pathogenesis of HCC is limited and needs more attention from researchers to identify the driver genes and miRNAs, which causes to translate this information into clinical practice. Therefore, the key regulators identification of miRNA-mRNA regulatory network is essential to identify HCC-associated genes. We extracted microRNA (miRNA) and messenger RNA (mRNA) expression datasets of normal and tumor HCC patient samples from UCSC Xena followed by identifying differentially expressed genes (DEGs) and differentially expressed miRNAs (DEMs). Univariate and multivariate cox-proportional hazard models were utilized to identify DEMs having significant association with overall survival (OS). Kaplan-Meier (KM) plotter was used to validate the presence of prognostic DEMs. A risk-score model was used to evaluate the effectiveness of KM-plotter validated DEMs combination on risk of samples. Target DEGs of prognostic miRNAs were identified via sources such as miRTargetLink and miRWalk followed by their validation in an external microarray cohort and enrichment analysis. 562 DEGs and 388 DEMs were identified followed by seven prognostic miRNAs (i.e., miR-19a, miR-19b, miR-30d-5p, miR-424-5p, miR-3677-5p, miR-3913-5p, miR-7705) post univariate, multivariate, risk-score model evaluation and KM-plotter analyses. ANLN, MRO, CPEB3 were their targets and were also validated in GSE84005 dataset. The findings of this study decipher that most significant miRNAs and their identified target genes have association with apoptosis, inflammation, cell cycle regulation and cancer-related pathways, which appear to contribute to HCC pathogenesis and therefore, the discovery of new targets.","<method>univariate cox-proportional hazard model</method>, <method>multivariate cox-proportional hazard model</method>, <method>Kaplan-Meier (KM) plotter</method>, <method>risk-score model</method>",No methods remaining
2024,https://openalex.org/W4392499245,Biology,Exploring the role of skin temperature in thermal sensation and thermal comfort: A comprehensive review,"The role of skin temperature as a determinant of human thermal sensation and comfort has gained increasing recognition, prompting a need for a systematic review. This review examines the relationship between skin temperature and thermal sensation, synthesizing insights from 172 studies published since 2000. It uniquely focuses on the indispensable roles of local and mean skin temperatures, a perspective not comprehensively explored in previous literature. The review reveals that the most common measurement points for skin temperature are the face and hands, attributed to their higher thermal sensitivity and the practical ease of measurement. It establishes a clear linear relationship between mean skin temperature and user thermal sensation, though affected by the choice of measurement locations and number of points. A notable finding is the varying impact of local skin temperature on overall thermal sensation in changing environments, with local heating less influential than cooling. The review also uncovers significant demographic variations in thermal sensation, strongly influenced by differing skin temperatures across age groups, genders, and climatic regions. For example, elderly populations exhibit a decreased temperature sensitivity, especially towards warmth. Gender differences are also significant, with females experiencing higher skin temperatures in warmer environments and lower in colder ones. Machine learning (ML)-based methods, especially classification tree-based and support vector machine (SVM) techniques, dominate in predicting thermal sensation and comfort, leveraging skin temperature data. While ML methods are prevalent, statistical regression-based approaches offer valuable empirical insights. Thermo-physiological model-based methods provide reliable results by incorporating detailed skin temperature dynamics. The review identifies a gap in understanding how gender, age, and regional differences influence thermal comfort in diverse environments. The study recommends conducting more nuanced experiments to dissect the impact of these factors and proposes the integration of individual demographic variables into ML models to personalize thermal comfort predictions.","<method>classification tree-based</method>, <method>support vector machine (SVM)</method>, <method>statistical regression-based approaches</method>, <method>thermo-physiological model-based methods</method>",<method>support vector machine (SVM)</method><method>statistical regression-based approaches</method>
2024,https://openalex.org/W4393380917,Biology,Motif-Aware miRNA-Disease Association Prediction via Hierarchical Attention Network,"As post-transcriptional regulators of gene expression, micro-ribonucleic acids (miRNAs) are regarded as potential biomarkers for a variety of diseases. Hence, the prediction of miRNA-disease associations (MDAs) is of great significance for an in-depth understanding of disease pathogenesis and progression. Existing prediction models are mainly concentrated on incorporating different sources of biological information to perform the MDA prediction task while failing to consider the fully potential utility of MDA network information at the motif-level. To overcome this problem, we propose a novel motif-aware MDA prediction model, namely MotifMDA, by fusing a variety of high- and low-order structural information. In particular, we first design several motifs of interest considering their ability to characterize how miRNAs are associated with diseases through different network structural patterns. Then, MotifMDA adopts a two-layer hierarchical attention to identify novel MDAs. Specifically, the first attention layer learns high-order motif preferences based on their occurrences in the given MDA network, while the second one learns the final embeddings of miRNAs and diseases through coupling high- and low-order preferences. Experimental results on two benchmark datasets have demonstrated the superior performance of MotifMDA over several state-of-the-art prediction models. This strongly indicates that accurate MDA prediction can be achieved by relying solely on MDA network information. Furthermore, our case studies indicate that the incorporation of motif-level structure information allows MotifMDA to discover novel MDAs from different perspectives. The data and codes are available at <uri xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">https://github.com/stevejobws/MotifMDA.</uri>","<method>motif-aware MDA prediction model (MotifMDA)</method>, <method>two-layer hierarchical attention</method>",<method>two-layer hierarchical attention</method>
2024,https://openalex.org/W4394011823,Biology,"Artificial intelligence in lung cancer screening: Detection, classification, prediction, and prognosis","Abstract Background The exceptional capabilities of artificial intelligence (AI) in extracting image information and processing complex models have led to its recognition across various medical fields. With the continuous evolution of AI technologies based on deep learning, particularly the advent of convolutional neural networks (CNNs), AI presents an expanded horizon of applications in lung cancer screening, including lung segmentation, nodule detection, false‐positive reduction, nodule classification, and prognosis. Methodology This review initially analyzes the current status of AI technologies. It then explores the applications of AI in lung cancer screening, including lung segmentation, nodule detection, and classification, and assesses the potential of AI in enhancing the sensitivity of nodule detection and reducing false‐positive rates. Finally, it addresses the challenges and future directions of AI in lung cancer screening. Results AI holds substantial prospects in lung cancer screening. It demonstrates significant potential in improving nodule detection sensitivity, reducing false‐positive rates, and classifying nodules, while also showing value in predicting nodule growth and pathological/genetic typing. Conclusions AI offers a promising supportive approach to lung cancer screening, presenting considerable potential in enhancing nodule detection sensitivity, reducing false‐positive rates, and classifying nodules. However, the universality and interpretability of AI results need further enhancement. Future research should focus on the large‐scale validation of new deep learning‐based algorithms and multi‐center studies to improve the efficacy of AI in lung cancer screening.","<method>artificial intelligence (AI)</method>, <method>deep learning</method>, <method>convolutional neural networks (CNNs)</method>",<method>deep learning</method><method>convolutional neural networks (CNNs)</method>
2024,https://openalex.org/W4394753955,Biology,Distributed Hydrological Modeling With Physics‐Encoded Deep Learning: A General Framework and Its Application in the Amazon,"Abstract While deep learning (DL) models exhibit superior simulation accuracy over traditional distributed hydrological models (DHMs), their main limitations lie in opacity and the absence of underlying physical mechanisms. The pursuit of synergies between DL and DHMs is an engaging research domain, yet a definitive roadmap remains elusive. In this study, a novel framework that seamlessly integrates a process‐based hydrological model encoded as a neural network (NN), an additional NN for mapping spatially distributed and physically meaningful parameters from watershed attributes, and NN‐based replacement models representing inadequately understood processes is developed. Multi‐source observations are used as training data, and the framework is fully differentiable, enabling fast parameter tuning by backpropagation. A hybrid DL model of the Amazon Basin (∼6 × 10 6 km 2 ) was established based on the framework, and HydroPy, a global‐scale DHM, was encoded as its physical backbone. Trained simultaneously with streamflow observations and Gravity Recovery and Climate Experiment satellite data, the hybrid model yielded median Nash‐Sutcliffe efficiencies of 0.83 and 0.77 for dynamic and distributed simulations of streamflow and total water storage, respectively, 41% and 35% higher than those of the original HydroPy model. Replacing the original Penman‒Monteith formulation in HydroPy with a replacement NN produces more plausible potential evapotranspiration (PET) estimates, and unravels the spatial pattern of PET in this giant basin. The NN used for parameterization was interpreted to identify the factors controlling the spatial variability in key parameters. Overall, this study lays out a feasible technical roadmap for distributed hydrological modeling in the big data era.","<method>deep learning (DL) models</method>, <method>neural network (NN)</method>, <method>NN-based replacement models</method>, <method>backpropagation</method>, <method>hybrid DL model</method>",<method>deep learning (DL) models</method><method>neural network (NN)</method><method>NN-based replacement models</method><method>backpropagation</method>
2024,https://openalex.org/W4395069357,Biology,Characterizing land use/land cover change dynamics by an enhanced random forest machine learning model: a Google Earth Engine implementation,"Abstract Land use and land cover (LULC) analysis is crucial for understanding societal development and assessing changes during the Anthropocene era. Conventional LULC mapping faces challenges in capturing changes under cloud cover and limited ground truth data. To enhance the accuracy and comprehensiveness of the descriptions of LULC changes, this investigation employed a combination of advanced techniques. Specifically, multitemporal 30 m resolution Landsat-8 satellite imagery was utilized, in addition to the cloud computing capabilities of the Google Earth Engine (GEE) platform. Additionally, the study incorporated the random forest (RF) algorithm. This study aimed to generate continuous LULC maps for 2014 and 2020 for the Shrirampur area of Maharashtra, India. A novel multiple composite RF approach based on LULC classification was utilized to generate the final LULC classification maps utilizing the RF-50 and RF-100 tree models. Both RF models utilized seven input bands (B1 to B7) as the dataset for LULC classification. By incorporating these bands, the models were able to influence the spectral information captured by each band to classify the LULC categories accurately. The inclusion of multiple bands enhanced the discrimination capabilities of the classifiers, increasing the comprehensiveness of the assessment of the LULC classes. The analysis indicated that RF-100 exhibited higher training and validation/testing accuracy for 2014 and 2020 (0.99 and 0.79/0.80, respectively). The study further revealed that agricultural land, built-up land, and water bodies have changed adequately and have undergone substantial variation among the LULC classes in the study area. Overall, this research provides novel insights into the application of machine learning (ML) models for LULC mapping and emphasizes the importance of selecting the optimal tree combination for enhancing the accuracy and reliability of LULC maps based on the GEE and different RF tree models. The present investigation further enabled the interpretation of pixel-level LULC interactions while improving image classification accuracy and suggested the best models for the classification of LULC maps through the identification of changes in LULC classes.","<method>random forest (RF) algorithm</method>, <method>multiple composite RF approach</method>, <method>RF-50 tree model</method>, <method>RF-100 tree model</method>",<method>random forest (RF) algorithm</method>
2024,https://openalex.org/W4395954533,Biology,DeepKEGG: a multi-omics data integration framework with biological insights for cancer recurrence prediction and biomarker discovery,"Abstract Deep learning-based multi-omics data integration methods have the capability to reveal the mechanisms of cancer development, discover cancer biomarkers and identify pathogenic targets. However, current methods ignore the potential correlations between samples in integrating multi-omics data. In addition, providing accurate biological explanations still poses significant challenges due to the complexity of deep learning models. Therefore, there is an urgent need for a deep learning-based multi-omics integration method to explore the potential correlations between samples and provide model interpretability. Herein, we propose a novel interpretable multi-omics data integration method (DeepKEGG) for cancer recurrence prediction and biomarker discovery. In DeepKEGG, a biological hierarchical module is designed for local connections of neuron nodes and model interpretability based on the biological relationship between genes/miRNAs and pathways. In addition, a pathway self-attention module is constructed to explore the correlation between different samples and generate the potential pathway feature representation for enhancing the prediction performance of the model. Lastly, an attribution-based feature importance calculation method is utilized to discover biomarkers related to cancer recurrence and provide a biological interpretation of the model. Experimental results demonstrate that DeepKEGG outperforms other state-of-the-art methods in 5-fold cross validation. Furthermore, case studies also indicate that DeepKEGG serves as an effective tool for biomarker discovery. The code is available at https://github.com/lanbiolab/DeepKEGG.","<method>deep learning-based multi-omics data integration methods</method>, <method>DeepKEGG</method>, <method>biological hierarchical module</method>, <method>pathway self-attention module</method>, <method>attribution-based feature importance calculation method</method>",<method>deep learning-based multi-omics data integration methods</method><method>attribution-based feature importance calculation method</method>
2024,https://openalex.org/W4400724905,Biology,Hyperspectral Image Analysis and Machine Learning Techniques for Crop Disease Detection and Identification: A Review,"Originally, the use of hyperspectral images was for military applications, but their use has been extended to precision agriculture. In particular, they are used for activities related to crop classification or disease detection, combining these hyperspectral images with machine learning techniques and algorithms. The study of hyperspectral images has a wide range of wavelengths for observation. These wavelengths allow for monitoring agricultural crops such as cereals, oilseeds, vegetables, and fruits, and other applications. In the ranges of these wavelengths, crop conditions such as maturity index and nutrient status, or the early detection of some diseases that cause losses in crops, can be studied and diagnosed. Therefore, this article proposes a technical review of the main applications of hyperspectral images in agricultural crops and perspectives and challenges that combine artificial intelligence algorithms such as machine learning and deep learning in the classification and detection of diseases of crops such as cereals, oilseeds, fruits, and vegetables. A systematic review of the scientific literature was carried out using a 10-year observation window to determine the evolution of the integration of these technological tools that support sustainable agriculture; among the findings, information on the most documented crops is highlighted, among which are some cereals and citrus fruits due to their high demand and large cultivation areas, as well as information on the main fruits and vegetables that are integrating these technologies. Also, the main artificial intelligence algorithms that are being worked on are summarized and classified, as well as the wavelength ranges for the prediction, disease detection, and analysis of other tasks of physiological characteristics used for sustainable production. This review can be useful as a reference for future research, based mainly on detection, classification, and other tasks in agricultural crops and decision making, to implement the most appropriate artificial intelligence algorithms.","<method>machine learning</method>, <method>deep learning</method>, <method>artificial intelligence algorithms</method>",<method>machine learning</method><method>deep learning</method>
2024,https://openalex.org/W4403248109,Biology,Optimizing cancer classification: a hybrid RDO-XGBoost approach for feature selection and predictive insights,"The identification of relevant biomarkers from high-dimensional cancer data remains a significant challenge due to the complexity and heterogeneity inherent in various cancer types. Conventional feature selection methods often struggle to effectively navigate the vast solution space while maintaining high predictive accuracy. In response to these challenges, we introduce a novel feature selection approach that integrates Random Drift Optimization (RDO) with XGBoost, specifically designed to enhance the performance of cancer classification tasks. Our proposed framework not only improves classification accuracy but also offers valuable insights into the underlying biological mechanisms driving cancer progression. Through comprehensive experiments conducted on real-world cancer datasets, including Central Nervous System (CNS), Leukemia, Breast, and Ovarian cancers, we demonstrate the efficacy of our method in identifying a smaller subset of unique and relevant genes. This selection results in significantly improved classification efficiency and accuracy. When compared with popular classifiers such as Support Vector Machine, K-Nearest Neighbor, and Naive Bayes, our approach consistently outperforms these models in terms of both accuracy and F-measure metrics. For instance, our framework achieved an accuracy of 97.24% in the CNS dataset, 99.14% in Leukemia, 95.21% in Ovarian, and 87.62% in Breast cancer, showcasing its robustness and effectiveness across different types of cancer data. These results underline the potential of our RDO-XGBoost framework as a promising solution for feature selection in cancer data analysis, offering enhanced predictive performance and valuable biological insights.","<method>Random Drift Optimization (RDO)</method>, <method>XGBoost</method>, <method>Support Vector Machine</method>, <method>K-Nearest Neighbor</method>, <method>Naive Bayes</method>",<method>XGBoost</method><method>Support Vector Machine</method><method>K-Nearest Neighbor</method><method>Naive Bayes</method>
2024,https://openalex.org/W4390604872,Biology,Cross-Domain Class Incremental Broad Network for Continuous Diagnosis of Rotating Machinery Faults Under Variable Operating Conditions,"Machine learning models have been widely successful in the field of intelligent fault diagnosis. Most of the existing machine learning models are deployed in static environments and rely on precollected datasets for offline training, which makes it impossible to update the models further once they are established. However, in the open and dynamic environment in reality, there is always incoming data in the form of streams, including new categories of data that are constantly generated over time. In addition, the operating conditions of mechanical equipment are time-varying, which results in continuous stream data that are nonindependently and homogeneously distributed. In industrial applications, the diagnosis problem of nonindependent and identically distributed continuous streaming data is referred to as the cross-domain class incremental diagnosis problem. To address the cross-domain class incremental problem, a novel cross-domain class incremental broad network (CDCIBN) is proposed. Specifically, to solve the nonindependent identically distributed problem, a novel domain-adaptation learning loss function is first designed, which enables the conventional broad network to handle the category increment task well. Then, a cross-domain class incremental learning mechanism is designed, which learns new categories while retaining the knowledge of old categories well enough without replaying old category data. The effectiveness of the proposed method is evaluated through multiple mechanical failure increment cases. Experimental analysis demonstrates that the designed CDCIBN has significant advantages in the variable working condition class incremental application.","<method>cross-domain class incremental broad network (CDCIBN)</method>, <method>domain-adaptation learning loss function</method>, <method>cross-domain class incremental learning mechanism</method>",<method>cross-domain class incremental learning mechanism</method>
2024,https://openalex.org/W4390686423,Biology,Real-life data-driven model predictive control for building energy systems comparing different machine learning models,"By considering forecasts and exploiting storage effects, model predictive control can achieve significant energy and cost savings in the building sector. However, due to the high individual modeling effort, model predictive control lacks practical applicability. For that reason, data-driven process models, approximating the system behavior based on measurements, have become increasingly popular in recent years. Still, scientific literature lacks consent about the most promising model types and efficient workflows to integrate different machine learning models into a model predictive controller. With this work, we present a workflow to provide efficient model predictive controllers based on measurement data automatically. The main idea is to translate different machine learning models into optimization syntax to enable efficient optimization with full access to gradients. We currently consider artificial neural networks, gaussian process regression, and simple linear regression process models. We use a generic model ontology to automatize the controller generation further and test the methodology on two real-life use cases. The first use case is the application of five office rooms with smart thermostat valves. The second use case is a test hall with an air handling unit and a concrete core activation. Using only two days of initial training data, we deploy controllers based on the different model types for six weeks in the offices and apply online learning to improve the models continuously. We observe only minor differences in controller performance despite the artificial neural networks showing the highest prediction accuracy. The second use case shows that the simple linear models require less controller tuning effort. Thus, for practical applications, we recommend linear regression models.","<method>model predictive control</method>, <method>artificial neural networks</method>, <method>gaussian process regression</method>, <method>linear regression</method>",<method>artificial neural networks</method><method>gaussian process regression</method><method>linear regression</method>
2024,https://openalex.org/W4391684052,Biology,Enhancing MPPT performance for partially shaded photovoltaic arrays through backstepping control with Genetic Algorithm-optimized gains,"As the significance and complexity of solar panel performance, particularly at their maximum power point (MPP), continue to grow, there is a demand for improved monitoring systems. The presence of variable weather conditions in Maroua, including potential partial shadowing caused by cloud cover or urban buildings, poses challenges to the efficiency of solar systems. This study introduces a new approach to tracking the Global Maximum Power Point (GMPP) in photovoltaic systems within the context of solar research conducted in Cameroon. The system utilizes Genetic Algorithm (GA) and Backstepping Controller (BSC) methodologies. The Backstepping Controller (BSC) dynamically adjusts the duty cycle of the Single Ended Primary Inductor Converter (SEPIC) to align with the reference voltage of the Genetic Algorithm (GA) in Maroua's dynamic environment. This environment, characterized by intermittent sunlight and the impact of local factors and urban shadowing, affects the production of energy. The Genetic Algorithm is employed to enhance the efficiency of BSC gains in Maroua's solar environment. This optimization technique expedites the tracking process and minimizes oscillations in the GMPP. The adaptability of the learning algorithm to specific conditions improves energy generation, even in the challenging environment of Maroua. This study introduces a novel approach to enhance the efficiency of photovoltaic systems in Maroua, Cameroon, by tailoring them to the specific solar dynamics of the region. In terms of performance, our approach surpasses the INC-BSC, P&O-BSC, GA-BSC, and PSO-BSC methodologies. In practice, the stabilization period following shadowing typically requires fewer than three iterations. Additionally, our Maximum Power Point Tracking (MPPT) technology is based on the Global Maximum Power Point (GMPP) methodology, contrasting with alternative technologies that prioritize the Local Maximum Power Point (LMPP). This differentiation is particularly relevant in areas with partial shading, such as Maroua, where the use of LMPP-based technologies can result in power losses. The proposed method demonstrates significant performance by achieving a minimum 33% reduction in power losses.","<method>Genetic Algorithm (GA)</method>, <method>Backstepping Controller (BSC)</method>, <method>INC-BSC</method>, <method>P&O-BSC</method>, <method>GA-BSC</method>, <method>PSO-BSC</method>",<method>Genetic Algorithm (GA)</method>
2024,https://openalex.org/W4391995887,Biology,"funspace: An R package to build, analyse and plot functional trait spaces","Abstract Aim Functional trait space analyses are pivotal to describe and compare organisms' functional diversity across the tree of life. Yet, there is no single application that streamlines the many sometimes‐troublesome steps needed to build and analyse functional trait spaces. Innovation To fill this gap, we propose funspace , an R package to easily handle bivariate and multivariate functional trait space analyses. The six functions that constitute the package can be grouped in three modules: ‘Building and exploring’, ‘Mapping’ and ‘Plotting’. The building and exploring module defines the main features of a functional trait space (e.g. functional diversity metrics) by leveraging kernel density‐based methods. The mapping module uses general additive models to map how a target variable distributes within a trait space. The plotting module provides many options for creating flexible and publication‐ready figures representing the outputs obtained from previous modules. We provide a worked example to demonstrate a complete funspace workflow. Main Conclusions funspace will provide researchers working with functional traits across the tree of life with a new tool to easily explore: (i) the main features of any functional trait space, (ii) the relationship between a functional trait space and any other biological or non‐biological factor that might contribute to shaping species' functional diversity.","<method>kernel density-based methods</method>, <method>general additive models</method>",<method>kernel density-based methods</method><method>general additive models</method>
2024,https://openalex.org/W4392111029,Biology,GAM-MDR: probing miRNA–drug resistance using a graph autoencoder based on random path masking,"Abstract MicroRNAs (miRNAs) are found ubiquitously in biological cells and play a pivotal role in regulating the expression of numerous target genes. Therapies centered around miRNAs are emerging as a promising strategy for disease treatment, aiming to intervene in disease progression by modulating abnormal miRNA expressions. The accurate prediction of miRNA–drug resistance (MDR) is crucial for the success of miRNA therapies. Computational models based on deep learning have demonstrated exceptional performance in predicting potential MDRs. However, their effectiveness can be compromised by errors in the data acquisition process, leading to inaccurate node representations. To address this challenge, we introduce the GAM-MDR model, which combines the graph autoencoder (GAE) with random path masking techniques to precisely predict potential MDRs. The reliability and effectiveness of the GAM-MDR model are mainly reflected in two aspects. Firstly, it efficiently extracts the representations of miRNA and drug nodes in the miRNA–drug network. Secondly, our designed random path masking strategy efficiently reconstructs critical paths in the network, thereby reducing the adverse impact of noisy data. To our knowledge, this is the first time that a random path masking strategy has been integrated into a GAE to infer MDRs. Our method was subjected to multiple validations on public datasets and yielded promising results. We are optimistic that our model could offer valuable insights for miRNA therapeutic strategies and deepen the understanding of the regulatory mechanisms of miRNAs. Our data and code are publicly available at GitHub:https://github.com/ZZCrazy00/GAM-MDR.","<method>deep learning</method>, <method>graph autoencoder (GAE)</method>, <method>random path masking</method>",<method>deep learning</method><method>graph autoencoder (GAE)</method>
2024,https://openalex.org/W4399442306,Biology,Integrative analysis of AI-driven optimization in HIV treatment regimens,"The integration of artificial intelligence (AI) into HIV treatment regimens has revolutionized the approach to personalized care and optimization strategies. This study presents an in-depth analysis of the role of AI in transforming HIV treatment, focusing on its ability to tailor therapy to individual patient needs and enhance treatment outcomes. AI-driven optimization in HIV treatment involves the utilization of advanced algorithms and computational techniques to analyze vast amounts of patient data, including genetic information, viral load measurements, and treatment history. By harnessing the power of machine learning and predictive analytics, AI algorithms can identify patterns and trends in patient data that may not be readily apparent to human clinicians. One of the key benefits of AI-driven optimization is its ability to personalize treatment regimens based on individual patient characteristics and disease progression. By considering factors such as drug resistance profiles, comorbidities, and lifestyle factors, AI algorithms can recommend the most effective and well-tolerated treatment options for each patient, leading to improved adherence and clinical outcomes. Furthermore, AI enables continuous monitoring and adjustment of treatment regimens in real time, allowing healthcare providers to respond rapidly to changes in patient status and evolving viral dynamics. This proactive approach to HIV management can help prevent treatment failure and the development of drug resistance, ultimately leading to better long-term outcomes for patients. Despite its transformative potential, AI-driven optimization in HIV treatment is not without challenges. Ethical considerations, data privacy concerns, and the need for robust validation and regulatory oversight are all important factors that must be addressed to ensure the safe and effective implementation of AI algorithms in clinical practice. In conclusion, the integrative analysis presented in this study underscores the significant impact of AI-driven optimization on the personalization and optimization of HIV treatment regimens. By leveraging AI technologies, healthcare providers can tailor treatment approaches to individual patient needs, leading to improved outcomes and quality of life for people living with HIV. Keywords: Integrative Analysis, AI- Driven, Optimization, HIV Treatment, Regimens.","<method>machine learning</method>, <method>predictive analytics</method>",<method>machine learning</method>
2024,https://openalex.org/W4401415934,Biology,Short-Term Load Forecasting: A Comprehensive Review and Simulation Study With CNN-LSTM Hybrids Approach,"Short-term load forecasting (STLF) is vital in effectively managing the reserve requirement in modern power grids. Subsequently, it supports the grid operator in making effective and economical decisions during the power balancing operation. Therefore, this study comprehensively reviews STLF methods, including time series analysis, regression-based frameworks, artificial neural networks (ANNs), and hybrid models that employ different forecasting approaches. Detailed mathematical and graphical analyses and a comparative evaluation of these methods are provided, highlighting their advantages and disadvantages. Further, the study proposes a hybrid CNN-LSTM model comprised of Convolutional neural networks (CNN) for feature extraction of high dimensional data and Long short-term memory (LSTM) networks to boost the model's efficiency for temporal sequence prediction. This study assessed the model using a comprehensive dataset from Pakistan's NTDC national grid. The analysis revealed superior performance in short-term load prediction, achieving enhanced accuracy. For single-step forecasting, the model yielded an RMSE of 538.71, MAE of 371.97, and MAPE of 2.72. In 24-hour forecasting, it achieved an RMSE of 951.94, MAE of 656.35, and MAPE of 4.72 on the NTDC dataset. Moreover, the model has outperformed previous models in comparison using the AEP dataset, demonstrating its superiority in enhancing reserve management and balancing supply and demand in modern electricity networks.","<method>time series analysis</method>, <method>regression-based frameworks</method>, <method>artificial neural networks (ANNs)</method>, <method>hybrid models</method>, <method>Convolutional neural networks (CNN)</method>, <method>Long short-term memory (LSTM) networks</method>, <method>hybrid CNN-LSTM model</method>",<method>regression-based frameworks</method><method>artificial neural networks (ANNs)</method><method>hybrid models</method><method>Convolutional neural networks (CNN)</method><method>Long short-term memory (LSTM) networks</method><method>hybrid CNN-LSTM model</method>
2024,https://openalex.org/W4402137675,Biology,A comprehensive review of model compression techniques in machine learning,"Abstract This paper critically examines model compression techniques within the machine learning (ML) domain, emphasizing their role in enhancing model efficiency for deployment in resource-constrained environments, such as mobile devices, edge computing, and Internet of Things (IoT) systems. By systematically exploring compression techniques and lightweight design architectures, it is provided a comprehensive understanding of their operational contexts and effectiveness. The synthesis of these strategies reveals a dynamic interplay between model performance and computational demand, highlighting the balance required for optimal application. As machine learning (ML) models grow increasingly complex and data-intensive, the demand for computational resources and memory has surged accordingly. This escalation presents significant challenges for the deployment of artificial intelligence (AI) systems in real-world applications, particularly where hardware capabilities are limited. Therefore, model compression techniques are not merely advantageous but essential for ensuring that these models can be utilized across various domains, maintaining high performance without prohibitive resource requirements. Furthermore, this review underscores the importance of model compression in sustainable artificial intelligence (AI) development. The introduction of hybrid methods, which combine multiple compression techniques, promises to deliver superior performance and efficiency. Additionally, the development of intelligent frameworks capable of selecting the most appropriate compression strategy based on specific application needs is crucial for advancing the field. The practical examples and engineering applications discussed demonstrate the real-world impact of these techniques. By optimizing the balance between model complexity and computational efficiency, model compression ensures that the advancements in AI technology remain sustainable and widely applicable. This comprehensive review thus contributes to the academic discourse and guides innovative solutions for efficient and responsible machine learning practices, paving the way for future advancements in the field. Graphical abstract","<method>model compression techniques</method>, <method>lightweight design architectures</method>, <method>hybrid methods</method>",<method>model compression techniques</method><method>hybrid methods</method>
2024,https://openalex.org/W4390821680,Biology,Application of deep learning to fault diagnosis of rotating machineries,"Abstract Deep learning (DL) has attained remarkable achievements in diagnosing faults for rotary machineries. Capitalizing on the formidable learning capacity of DL, it has the potential to automate human labor and augment the efficiency of fault diagnosis in rotary machinery. These advantages have engendered escalating interest over the past decade. Although recent reviews of the literature have encapsulated the utilization of DL in diagnosing faults in rotating machinery, they no longer encompass the introduction of novel methodologies and emerging directions as DL methodologies continually evolve. Moreover, in practical application, novel issues and trajectories perpetually manifest, demanding a comprehensive exegesis. To rectify this lacuna, this article amalgamates current research trends and avant-garde methodologies while systematizing the utilization of anterior DL techniques. The evolution and extant status of DL in diagnosing faults for rotary machinery were delineated, with the intent of providing orientation for prospective research. Over the bygone decade, archetypal DL theory has empowered the diagnosis of faults in rotating machinery by directly establishing the nexus between mechanical data and fault conditions. In recent years, meta learning methods aimed at solving small sample scenarios and large model transformers aimed at mining big data features have both received widespread attention and development in the field of fault diagnosis of rotating machinery equipment. Although excellent results have been achieved in these two directions, there is no review and summary article yet, so it is necessary to update the review literature in the field of fault diagnosis of rotating machinery equipment. Lastly, predicated on a survey of the literature and the current developmental landscape, the challenges and prospective orientations of DL in rotary machinery fault diagnosis are presented.","<method>deep learning (DL)</method>, <method>meta learning methods</method>, <method>large model transformers</method>",<method>deep learning (DL)</method><method>meta learning methods</method>
2024,https://openalex.org/W4390970205,Biology,Empowering Cyberattack Identification in IoHT Networks With Neighborhood-Component-Based Improvised Long Short-Term Memory,"Cybersecurity has become an inevitable concern in the healthcare industry due to the rapid growth of the Internet of Health Things (IoHT). The IoHT is revolutionizing healthcare by enabling remote access to hospital equipment, real-time patient monitoring, and urgent alerts to patients and hospitals. However, the convenience of these systems also makes them vulnerable to cyberattacks, with hackers seeking to disrupt health services or extort money through ransomware attacks. Efficiently detecting multiple threats is a challenging task because IoHT generates large temporal data and system log information. In this paper, we propose time series classification models for the identification of potential cyberattacks in IoHT networks. First, we introduce Neighborhood Component Analysis (NCA) with modifications of the regularization parameter to select the vital input features. With the selected features, we propose two LSTM-based models: Directed Acyclic Graph-based Long Short-Term Memory (DAG-LSTM) and Projected Layer-based Long Short-Term Memory (PL-LSTM) for detecting cyberattacks. We evaluate the existing time series classification models (i.e., GRU, LSTM, and Bi-LSTM) and proposed models (i.e., DAG-LSTM and PL-LSTM) using real-world IoHT data. We also validate the models by applying a non-parametric statistical test, Friedman test. Our evaluation results show that the proposed DAG-LSTM achieves the highest accuracy with 99.89% training and 92.04% an average testing accuracy.","<method>Neighborhood Component Analysis (NCA)</method>, <method>Directed Acyclic Graph-based Long Short-Term Memory (DAG-LSTM)</method>, <method>Projected Layer-based Long Short-Term Memory (PL-LSTM)</method>, <method>Gated Recurrent Unit (GRU)</method>, <method>Long Short-Term Memory (LSTM)</method>, <method>Bidirectional Long Short-Term Memory (Bi-LSTM)</method>",<method>Neighborhood Component Analysis (NCA)</method><method>Directed Acyclic Graph-based Long Short-Term Memory (DAG-LSTM)</method><method>Gated Recurrent Unit (GRU)</method><method>Long Short-Term Memory (LSTM)</method><method>Bidirectional Long Short-Term Memory (Bi-LSTM)</method>
2024,https://openalex.org/W4391451930,Biology,Advancing real-time plant disease detection: A lightweight deep learning approach and novel dataset for pigeon pea crop,"Plant disease detection and early disease treatment are essential for sustainable crop production. Computer vision for crop science is overgrowing with the advancement in deep learning. Real time plant disease detection poses a challenge due to the unpredictable spread of diseases within the plant, environmental factors, and the scarcity of real field datasets. The proposed work systematically addresses these issues through three key components: (a) Collaboratively generating the novel pigeon pea image dataset from agricultural fields, in partnership with 20 Agricultural Research Centers (ARS) and governmental agencies spanning 18 Indian states. (b) The design of lightweight and high-performance models for real-time plant disease detection in resource-constrained devices. (c) The extraction of multiscale feature of plant diseases using Multi-kernel Depthwise separable Convolutions. The proposed lightweight Lite-MDC architecture uses the Multi-kernel Depthwise separable Convolutions (MDsConv). The MDsConv module captures spatial features across various scales while maintaining a lightweight design. It effectively extract multi-scale information to characterize plant diseases, accommodating their diverse scale. Proposed architectural approach significantly reduces computational complexity, employing only 2.2 million parameters, which is a 62% reduction compared to the standard VGG16 architecture. The proposed method outperforms the state-of-the-art networks such as InceptionV3, VGG16, ResNet50, DenseNet, MobileNet, MobileNetV3, NASNet, and EfficieNetB0 on the proposed pigeon pea dataset with 94.14% accuracy. Notably, the method achieves a 34 Frames Per Second (FPS) inference on an NVIDIA P100 GPU. Furthermore, its performance is validated across publicly available datasets, including the plant village dataset, Cassava, and apple leaf datasets, yielding 99.78%, 86.4%, and 97.2% accuracy, respectively. The Lite-MDC model exhibits the potential for real-time plant disease detection on resource-constrained edge devices such as Agriculture robots and drones.","<method>Multi-kernel Depthwise separable Convolutions (MDsConv)</method>, <method>Lite-MDC architecture</method>, <method>InceptionV3</method>, <method>VGG16</method>, <method>ResNet50</method>, <method>DenseNet</method>, <method>MobileNet</method>, <method>MobileNetV3</method>, <method>NASNet</method>, <method>EfficientNetB0</method>",<method>InceptionV3</method><method>VGG16</method><method>ResNet50</method><method>DenseNet</method><method>MobileNet</method><method>MobileNetV3</method><method>NASNet</method><method>EfficientNetB0</method>
2024,https://openalex.org/W4391456824,Biology,Deep Learning-Based Mask Identification System Using ResNet Transfer Learning Architecture,"Recently, the coronavirus disease 2019 has shown excellent attention in the global community regarding health and the economy.World Health Organization (WHO) and many others advised controlling Corona Virus Disease in 2019.The limited treatment resources, medical resources, and unawareness of immunity is an essential horizon to unfold.Among all resources, wearing a mask is the primary non-pharmaceutical intervention to stop the spreading of the virus caused by Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) droplets.All countries made masks mandatory to prevent infection.For such enforcement, automatic and effective face detection systems are crucial.This study presents a face mask identification approach for static photos and real-time movies that distinguishes between images with and without masks.To contribute to society, we worked on mask detection of an individual to adhere to the rule and provide awareness to the public or organization.The paper aims to get detection accuracy using transfer learning from Residual Neural Network 50 (ResNet-50) architecture and works on detection localization.The experiment is tested with other popular pre-trained models such as Deep Convolutional Neural Networks (AlexNet), Residual Neural Networks (ResNet), and Visual Geometry Group Networks (VGG-Net) advanced architecture.The proposed system generates an accuracy of 98.4% when modeled using Residual Neural Network 50 (ResNet-50).Also, the precision and recall values are proved as better when compared to the existing models.This outstanding work also can be used in video surveillance applications.","<method>transfer learning</method>, <method>Residual Neural Network 50 (ResNet-50)</method>, <method>Deep Convolutional Neural Networks (AlexNet)</method>, <method>Residual Neural Networks (ResNet)</method>, <method>Visual Geometry Group Networks (VGG-Net)</method>",<method>transfer learning</method><method>Residual Neural Network 50 (ResNet-50)</method><method>Deep Convolutional Neural Networks (AlexNet)</method><method>Residual Neural Networks (ResNet)</method><method>Visual Geometry Group Networks (VGG-Net)</method>
2024,https://openalex.org/W4391509831,Biology,A hyperspectral deep learning attention model for predicting lettuce chlorophyll content,"Abstract Background The phenotypic traits of leaves are the direct reflection of the agronomic traits in the growth process of leafy vegetables, which plays a vital role in the selection of high-quality leafy vegetable varieties. The current image-based phenotypic traits extraction research mainly focuses on the morphological and structural traits of plants or leaves, and there are few studies on the phenotypes of physiological traits of leaves. The current research has developed a deep learning model aimed at predicting the total chlorophyll of greenhouse lettuce directly from the full spectrum of hyperspectral images. Results A CNN-based one-dimensional deep learning model with spectral attention module was utilized for the estimate of the total chlorophyll of greenhouse lettuce from the full spectrum of hyperspectral images. Experimental results demonstrate that the deep neural network with spectral attention module outperformed the existing standard approaches, including partial least squares regression (PLSR) and random forest (RF), with an average R 2 of 0.746 and an average RMSE of 2.018. Conclusions This study unveils the capability of leveraging deep attention networks and hyperspectral imaging for estimating lettuce chlorophyll levels. This approach offers a convenient, non-destructive, and effective estimation method for the automatic monitoring and production management of leafy vegetables.","<method>CNN-based one-dimensional deep learning model with spectral attention module</method>, <method>partial least squares regression (PLSR)</method>, <method>random forest (RF)</method>",<method>CNN-based one-dimensional deep learning model with spectral attention module</method><method>partial least squares regression (PLSR)</method><method>random forest (RF)</method>
2024,https://openalex.org/W4402061574,Biology,Abstractive Text Summarization Using GAN,"In the field of natural language processing, the task of writing long concepts into short expressions has attracted attention due to its ability to simplify the processing and understanding of information. While traditional transcription techniques are effective to some extent, they often fail to capture the essence and nuances of the original texts. This article explores a new approach to collecting abstract data using artificial neural networks (GANs), a class of deep learning models known for their ability to create patterns of real information. We describe the fundamentals of text collection through a comprehensive review of existing literature and methods and highlight the complexity of GAN-based text. Our goal is to transform complex text into context and meaning by combining the power of GANs with natural language understanding. We detail the design and training of an adaptive GAN model for the text recognition task. We also conduct various experiments and evaluations using established metrics such as ROUGE and BLEU scores to evaluate the effectiveness and efficiency of our approach. The results show that GANs can be used to improve the quality and consistency of generated content, data storage, data analysis paper, etc. It shows its promise in paving the way for advanced applications in fields. Through this research, we aim to contribute to the continued evolution of writing technology, providing insights and innovations that support the field to a new level of well-done.","<method>artificial neural networks (GANs)</method>, <method>GAN-based text</method>, <method>adaptive GAN model</method>",No methods remaining
2024,https://openalex.org/W2986574354,Biology,African Journal of Environmental Science and Technology,"The aim of the present study is to test ESA's Sentinel-2 (S2) satellites (S2A and S2B) for an efficient quantification of land cover (LC) and forest compositions in a tropical environment southwest of Mount Kenya.Furthermore, outcome of the research is used to validate ESA's S2 prototype LC 20 m map of Africa that was produced in 2016.A decision tree that is based on significant altitudinal ranges was used to discriminate four natural tree compositions that occur within the investigation area.In addition, the classification process was supported by Google Earth images, and land use (LU) data that were provided by the local Kenyan Forest Service (KFS).Final classification products include four LC classes and five subclasses of forest (four natural forest subclasses plus one non-natural forest class).Results of the Jeffries-Matusita (JM) distance test show significant differences in spectral separability between all classes.Furthermore, the study identifies spectral signatures and significant wavelengths for a classification of all LC classes and forest subclasses where wavelengths of SWIR and the rededge domain show highest importance for the discrimination of tree compositions.Finally, considerable differences can be seen between the utilized multi-temporal classification set (total of 39 bands from three acquisition dates) and ESA's S2 prototype LC 20 m map of Africa 2016.A visual comparison of ESA's prototype map within the investigation area indicates an overrepresentation of tree cover areas (as confirmed in previous studies) and also an underrepresentation of water.",<method>decision tree</method>,<method>decision tree</method>
2024,https://openalex.org/W4392173735,Biology,"A Comprehensive Survey of Continual Learning: Theory, Method and Application","To cope with real-world dynamics, an intelligent system needs to incrementally acquire, update, accumulate, and exploit knowledge throughout its lifetime. This ability, known as continual learning, provides a foundation for AI systems to develop themselves adaptively. In a general sense, continual learning is explicitly limited by catastrophic forgetting, where learning a new task usually results in a dramatic performance drop of the old tasks. Beyond this, increasingly numerous advances have emerged in recent years that largely extend the understanding and application of continual learning. The growing and widespread interest in this direction demonstrates its realistic significance as well as complexity. In this work, we present a comprehensive survey of continual learning, seeking to bridge the basic settings, theoretical foundations, representative methods, and practical applications. Based on existing theoretical and empirical results, we summarize the general objectives of continual learning as ensuring a proper stability-plasticity trade-off and an adequate intra/inter-task generalizability in the context of resource efficiency. Then we provide a state-of-the-art and elaborated taxonomy, extensively analyzing how representative strategies address continual learning, and how they are adapted to particular challenges in various applications. Through an in-depth discussion of promising directions, we believe that such a holistic perspective can greatly facilitate subsequent exploration in this field and beyond.",<method>continual learning</method>,<method>continual learning</method>
2024,https://openalex.org/W4390658983,Biology,Rapid single-particle chemical imaging of nanoplastics by SRS microscopy,"Plastics are now omnipresent in our daily lives. The existence of microplastics (1 µm to 5 mm in length) and possibly even nanoplastics (<1 μm) has recently raised health concerns. In particular, nanoplastics are believed to be more toxic since their smaller size renders them much more amenable, compared to microplastics, to enter the human body. However, detecting nanoplastics imposes tremendous analytical challenges on both the nano-level sensitivity and the plastic-identifying specificity, leading to a knowledge gap in this mysterious nanoworld surrounding us. To address these challenges, we developed a hyperspectral stimulated Raman scattering (SRS) imaging platform with an automated plastic identification algorithm that allows micro-nano plastic analysis at the single-particle level with high chemical specificity and throughput. We first validated the sensitivity enhancement of the narrow band of SRS to enable high-speed single nanoplastic detection below 100 nm. We then devised a data-driven spectral matching algorithm to address spectral identification challenges imposed by sensitive narrow-band hyperspectral imaging and achieve robust determination of common plastic polymers. With the established technique, we studied the micro-nano plastics from bottled water as a model system. We successfully detected and identified nanoplastics from major plastic types. Micro-nano plastics concentrations were estimated to be about 2.4 ± 1.3 × 10","<method>automated plastic identification algorithm</method>, <method>data-driven spectral matching algorithm</method>",No methods remaining
2024,https://openalex.org/W4391069573,Biology,ChatGPT in healthcare: A taxonomy and systematic review,"The recent release of ChatGPT, a chat bot research project/product of natural language processing (NLP) by OpenAI, stirs up a sensation among both the general public and medical professionals, amassing a phenomenally large user base in a short time. This is a typical example of the 'productization' of cutting-edge technologies, which allows the general public without a technical background to gain firsthand experience in artificial intelligence (AI), similar to the AI hype created by AlphaGo (DeepMind Technologies, UK) and self-driving cars (Google, Tesla, etc.). However, it is crucial, especially for healthcare researchers, to remain prudent amidst the hype. This work provides a systematic review of existing publications on the use of ChatGPT in healthcare, elucidating the 'status quo' of ChatGPT in medical applications, for general readers, healthcare professionals as well as NLP scientists. The large biomedical literature database PubMed is used to retrieve published works on this topic using the keyword 'ChatGPT'. An inclusion criterion and a taxonomy are further proposed to filter the search results and categorize the selected publications, respectively. It is found through the review that the current release of ChatGPT has achieved only moderate or 'passing' performance in a variety of tests, and is unreliable for actual clinical deployment, since it is not intended for clinical applications by design. We conclude that specialized NLP models trained on (bio)medical datasets still represent the right direction to pursue for critical clinical applications.","<method>ChatGPT</method>, <method>natural language processing (NLP)</method>, <method>specialized NLP models trained on (bio)medical datasets</method>",No methods remaining
2024,https://openalex.org/W4390919701,Biology,Chatbots and Large Language Models in Radiology: A Practical Primer for Clinical and Research Applications,"Although chatbots have existed for decades, the emergence of transformer-based large language models (LLMs) has captivated the world through the most recent wave of artificial intelligence chatbots, including ChatGPT. Transformers are a type of neural network architecture that enables better contextual understanding of language and efficient training on massive amounts of unlabeled data, such as unstructured text from the internet. As LLMs have increased in size, their improved performance and emergent abilities have revolutionized natural language processing. Since language is integral to human thought, applications based on LLMs have transformative potential in many industries. In fact, LLM-based chatbots have demonstrated human-level performance on many professional benchmarks, including in radiology. LLMs offer numerous clinical and research applications in radiology, several of which have been explored in the literature with encouraging results. Multimodal LLMs can simultaneously interpret text and images to generate reports, closely mimicking current diagnostic pathways in radiology. Thus, from requisition to report, LLMs have the opportunity to positively impact nearly every step of the radiology journey. Yet, these impressive models are not without limitations. This article reviews the limitations of LLMs and mitigation strategies, as well as potential uses of LLMs, including multimodal models. Also reviewed are existing LLM-based applications that can enhance efficiency in supervised settings.","<method>transformer-based large language models (LLMs)</method>, <method>Transformers</method>, <method>Multimodal LLMs</method>",<method>transformer-based large language models (LLMs)</method><method>Transformers</method><method>Multimodal LLMs</method>
2024,https://openalex.org/W4399528455,Biology,Bias and Fairness in Large Language Models: A Survey,"Abstract Rapid advancements of large language models (LLMs) have enabled the processing, understanding, and generation of human-like text, with increasing integration into systems that touch our social sphere. Despite this success, these models can learn, perpetuate, and amplify harmful social biases. In this article, we present a comprehensive survey of bias evaluation and mitigation techniques for LLMs. We first consolidate, formalize, and expand notions of social bias and fairness in natural language processing, defining distinct facets of harm and introducing several desiderata to operationalize fairness for LLMs. We then unify the literature by proposing three intuitive taxonomies, two for bias evaluation, namely, metrics and datasets, and one for mitigation. Our first taxonomy of metrics for bias evaluation disambiguates the relationship between metrics and evaluation datasets, and organizes metrics by the different levels at which they operate in a model: embeddings, probabilities, and generated text. Our second taxonomy of datasets for bias evaluation categorizes datasets by their structure as counterfactual inputs or prompts, and identifies the targeted harms and social groups; we also release a consolidation of publicly available datasets for improved access. Our third taxonomy of techniques for bias mitigation classifies methods by their intervention during pre-processing, in-training, intra-processing, and post-processing, with granular subcategories that elucidate research trends. Finally, we identify open problems and challenges for future work. Synthesizing a wide range of recent research, we aim to provide a clear guide of the existing literature that empowers researchers and practitioners to better understand and prevent the propagation of bias in LLMs.","<method>bias evaluation metrics</method>, <method>bias evaluation datasets</method>, <method>bias mitigation techniques</method>, <method>pre-processing intervention</method>, <method>in-training intervention</method>, <method>intra-processing intervention</method>, <method>post-processing intervention</method>",No methods remaining
2024,https://openalex.org/W9567271,Biology,Fingerprint Based Gender Classification,"Male-female classification from a fingerprint is an important step in forensic science, anthropological and medical studies to reduce the efforts required for searching a person.The aim of this research is to establish a relationship between gender and the fingerprint using some special features such as ridge density, ridge thickness to valley thickness ratio (RTVTR) and ridge width.showed that male-female classification can be done correctly up to 88.5% based on white lines count, RTVTR & ridge count using Neural Network as Classifier.We have used RTVTR, ridge width and ridge density for classification and SVM as classifier.We have found male-female can be correctly classified up to 91%.Gender classification plays an active role in several applications such as biometrics, criminology, surveillance, human computer interaction, commercial profiling.Though biometric traits such as face, gait, iris and hand shape are used for gender classification in the past, majority of the work is based on face as it contains more prominent features than others.In this paper we have analyzed fingerprints for gender classification with a hope that it has great potential for future research.We have employed a three convolutional layer CNN with rectified linear and activation functions on NIST database which contains a set of 4000 images and achieved 99% accuracy.Performance of the proposed system demonstrated that fingerprints contains vital features to discriminate gender of a person.Humans have distinctive and unique traits which can be used to distinguish them thus, acting as a form of identification.Biometrics identify people by measuring some aspect of individual's anatomy or physiology such as hand geometry or fingerprint which consists of a pattern of interleaved ridges and valleys.The year 2015 election in Nigeria was greeted by some petitions including under-aged voters.The need for an age and gender detector system is a major concern for organizations at all levels where integrity of information cannot be compromised.This work developed a system that determines human age-range and gender using fingerprint analysis trained with Back Propagation Neural Network (for gender classification) and DWT+PCA (for age classification).A total of 280 fingerprint samples of people with various age and gender were collected.140 of these samples were used for training the system""s Database; 70 males and 70 females respectively.This was done for age groups 1-10, 11-20, 21-30, 31-40, 41-50, 51-60 and 61-70 accordingly.In order to determine the gender of an individual, the Ridge Thickness Valley Thickness Ratio (RTVTR) of the person was put into consideration.Result showed 80.00 % classification accuracy for females and 72.86 % for males while 115 subjects out of 140 (82.14%)were correctly classified in age.","<method>Neural Network</method>, <method>SVM</method>, <method>CNN</method>, <method>Back Propagation Neural Network</method>, <method>DWT+PCA</method>",<method>Neural Network</method><method>SVM</method><method>CNN</method><method>Back Propagation Neural Network</method>
2024,https://openalex.org/W4392193191,Biology,Challenges and barriers of using large language models (LLM) such as ChatGPT for diagnostic medicine with a focus on digital pathology – a recent scoping review,"Abstract Background The integration of large language models (LLMs) like ChatGPT in diagnostic medicine, with a focus on digital pathology, has garnered significant attention. However, understanding the challenges and barriers associated with the use of LLMs in this context is crucial for their successful implementation. Methods A scoping review was conducted to explore the challenges and barriers of using LLMs, in diagnostic medicine with a focus on digital pathology. A comprehensive search was conducted using electronic databases, including PubMed and Google Scholar, for relevant articles published within the past four years. The selected articles were critically analyzed to identify and summarize the challenges and barriers reported in the literature. Results The scoping review identified several challenges and barriers associated with the use of LLMs in diagnostic medicine. These included limitations in contextual understanding and interpretability, biases in training data, ethical considerations, impact on healthcare professionals, and regulatory concerns. Contextual understanding and interpretability challenges arise due to the lack of true understanding of medical concepts and lack of these models being explicitly trained on medical records selected by trained professionals, and the black-box nature of LLMs. Biases in training data pose a risk of perpetuating disparities and inaccuracies in diagnoses. Ethical considerations include patient privacy, data security, and responsible AI use. The integration of LLMs may impact healthcare professionals’ autonomy and decision-making abilities. Regulatory concerns surround the need for guidelines and frameworks to ensure safe and ethical implementation. Conclusion The scoping review highlights the challenges and barriers of using LLMs in diagnostic medicine with a focus on digital pathology. Understanding these challenges is essential for addressing the limitations and developing strategies to overcome barriers. It is critical for health professionals to be involved in the selection of data and fine tuning of the models. Further research, validation, and collaboration between AI developers, healthcare professionals, and regulatory bodies are necessary to ensure the responsible and effective integration of LLMs in diagnostic medicine.",<method>large language models (LLMs)</method>,No methods remaining
2024,https://openalex.org/W4392872715,Biology,GLC_FCS30D: the first global 30 m land-cover dynamics monitoring product with a fine classification system for the period from 1985 to 2022 generated using dense-time-series Landsat imagery and the continuous change-detection method,"Abstract. Land-cover change has been identified as an important cause or driving force of global climate change and is a significant research topic. Over the past few decades, global land-cover mapping has progressed; however, long-time-series global land-cover-change monitoring data are still sparse, especially those at 30 m resolution. In this study, we describe GLC_FCS30D, a novel global 30 m land-cover dynamics monitoring dataset containing 35 land-cover subcategories and covering the period 1985–2022 in 26 time steps (maps were updated every 5 years before 2000 and annually after 2000). GLC_FCS30D has been developed using continuous change detection and all available Landsat imagery based on the Google Earth Engine platform. Specifically, we first take advantage of the continuous change-detection model and the full time series of Landsat observations to capture the time points of changed pixels and identify the temporally stable areas. Then, we apply a spatiotemporal refinement method to derive the globally distributed and high-confidence training samples from these temporally stable areas. Next, local adaptive classification models are used to update the land-cover information for the changed pixels, and a temporal-consistency optimization algorithm is adopted to improve their temporal stability and suppress some false changes. Further, the GLC_FCS30D product is validated using 84 526 globally distributed validation samples from 2020. It achieves an overall accuracy of 80.88 % (±0.27 %) for the basic classification system (10 major land-cover types) and 73.04 % (±0.30 %) for the LCCS (Land Cover Classification System) level-1 validation system (17 LCCS land-cover types). Meanwhile, two third-party time-series datasets used for validation from the United States and Europe Union are also collected for analyzing accuracy variations, and the results show that GLC_FCS30D offers significant stability in terms of variation across the accuracy time series and achieves mean accuracies of 79.50 % (±0.50 %) and 81.91 % (±0.09 %) over the two regions. Lastly, we draw conclusions about the global land-cover-change information from the GLC_FCS30D dataset; namely, that forest and cropland variations have dominated global land-cover change over past 37 years, the net loss of forests reached about 2.5 million km2, and the net gain in cropland area is approximately 1.3 million km2. Therefore, the novel dataset GLC_FCS30D is an accurate land-cover-dynamics time-series monitoring product that benefits from its diverse classification system, high spatial resolution, and long time span (1985–2022); thus, it will effectively support global climate change research and promote sustainable development analysis. The GLC_FCS30D dataset is available via https://doi.org/10.5281/zenodo.8239305 (Liu et al., 2023).","<method>continuous change-detection model</method>, <method>spatiotemporal refinement method</method>, <method>local adaptive classification models</method>, <method>temporal-consistency optimization algorithm</method>",No methods remaining
2024,https://openalex.org/W4392714200,Biology,Genomic selection in plant breeding: Key factors shaping two decades of progress,"Genomic selection, the application of genomic prediction (GP) models to select candidate individuals, has significantly advanced in the past two decades, effectively accelerating genetic gains in plant breeding.This article provides a holistic overview of key factors that have influenced GP in plant breeding during this period.We delved into the pivotal roles of training population size and genetic diversity, and their relationship with the breeding population, in determining GP accuracy.Special emphasis was placed on optimizing training population size.We explored its benefits and the associated diminishing returns beyond an optimum size.This was done while considering the balance between resource allocation and maximizing prediction accuracy through current optimization algorithms.The density and distribution of single-nucleotide polymorphisms, level of linkage disequilibrium, genetic complexity, trait heritability, statistical machine-learning methods, and non-additive effects are the other vital factors.Using wheat, maize, and potato as examples, we summarize the effect of these factors on the accuracy of GP for various traits.The search for high accuracy in GP-theoretically reaching one when using the Pearson's correlation as a metric-is an active research area as yet far from optimal for various traits.We hypothesize that with ultra-high sizes of genotypic and phenotypic datasets, effective training population optimization methods and support from other omics approaches (transcriptomics, metabolomics and proteomics) coupled with deep-learning algorithms could overcome the boundaries of current limitations to achieve the highest possible prediction accuracy, making genomic selection an effective tool in plant breeding.","<method>genomic prediction (GP) models</method>, <method>statistical machine-learning methods</method>, <method>optimization algorithms</method>, <method>deep-learning algorithms</method>",<method>statistical machine-learning methods</method>
2024,https://openalex.org/W4391559729,Biology,FFCA-YOLO for Small Object Detection in Remote Sensing Images,"Issues such as insufficient feature representation and background confusion make detection tasks for small object in remote sensing arduous. Particularly when the algorithm will be deployed on board for real-time processing, which requires extensive optimization of accuracy and speed under limited computing resources. To tackle these problems, an efficient detector called FFCA-YOLO(Feature enhancement, Fusion and Context Aware YOLO) is proposed in this paper. FFCA-YOLO includes three innovative lightweight and plug-and-play modules: feature enhancement module(FEM), feature fusion module(FFM) and spatial context aware module(SCAM). These three modules improve the network capabilities of local area awareness, multi-scale feature fusion and global association cross channels and space, respectively, while trying to avoid increasing complexity as possible. Thus the weak feature representations of small objects are enhanced and the confusable backgrounds are suppressed. Two public remote sensing datasets(VEDAI and AI-TOD) for small object detection and one self-built dataset(USOD) are used to validate the effectiveness of FFCA-YOLO. The accuracy of FFCA-YOLO reaches 0.748, 0.617 and 0.909(in terms of mAP <sub xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">50</sub> ) that exceeds several benchmark models and state-of-the-art methods. Meanwhile, the robustness of FFCA-YOLO is also validated under different simulated degradation conditions. Moreover, to further reduce computational resource consumption while ensuring efficiency, a lite version of FFCA-YOLO(L-FFCA-YOLO) is optimized by reconstructing the backbone and neck of FFCA-YOLO based on partial convolution. L-FFCA-YOLO has faster speed, smaller parameter scale, lower computing power requirement but little accuracy loss compared with FFCA-YOLO. The source code will be available at https://github.com/yemu1138178251/FFCA-YOLO.","<method>FFCA-YOLO (Feature enhancement, Fusion and Context Aware YOLO)</method>, <method>feature enhancement module (FEM)</method>, <method>feature fusion module (FFM)</method>, <method>spatial context aware module (SCAM)</method>, <method>L-FFCA-YOLO (lite version of FFCA-YOLO optimized by partial convolution)</method>",No methods remaining
2024,https://openalex.org/W4391968719,Biology,Artificial intelligence and IoT driven technologies for environmental pollution monitoring and management,"Detecting hazardous substances in the environment is crucial for protecting human wellbeing and ecosystems. As technology continues to advance, artificial intelligence (AI) has emerged as a promising tool for creating sensors that can effectively detect and analyze these hazardous substances. The increasing advancements in information technology have led to a growing interest in utilizing this technology for environmental pollution detection. AI-driven sensor systems, AI and Internet of Things (IoT) can be efficiently used for environmental monitoring, such as those for detecting air pollutants, water contaminants, and soil toxins. With the increasing concerns about the detrimental impact of legacy and emerging hazardous substances on ecosystems and human health, it is necessary to develop advanced monitoring systems that can efficiently detect, analyze, and respond to potential risks. Therefore, this review aims to explore recent advancements in using AI, sensors and IOTs for environmental pollution monitoring, taking into account the complexities of predicting and tracking pollution changes due to the dynamic nature of the environment. Integrating machine learning (ML) methods has the potential to revolutionize environmental science, but it also poses challenges. Important considerations include balancing model performance and interpretability, understanding ML model requirements, selecting appropriate models, and addressing concerns related to data sharing. Through examining these issues, this study seeks to highlight the latest trends in leveraging AI and IOT for environmental pollution monitoring.","<method>artificial intelligence (AI)</method>, <method>machine learning (ML) methods</method>",No methods remaining
2024,https://openalex.org/W4392754729,Biology,"Revolutionizing agriculture with artificial intelligence: plant disease detection methods, applications, and their limitations","Accurate and rapid plant disease detection is critical for enhancing long-term agricultural yield. Disease infection poses the most significant challenge in crop production, potentially leading to economic losses. Viruses, fungi, bacteria, and other infectious organisms can affect numerous plant parts, including roots, stems, and leaves. Traditional techniques for plant disease detection are time-consuming, require expertise, and are resource-intensive. Therefore, automated leaf disease diagnosis using artificial intelligence (AI) with Internet of Things (IoT) sensors methodologies are considered for the analysis and detection. This research examines four crop diseases: tomato, chilli, potato, and cucumber. It also highlights the most prevalent diseases and infections in these four types of vegetables, along with their symptoms. This review provides detailed predetermined steps to predict plant diseases using AI. Predetermined steps include image acquisition, preprocessing, segmentation, feature selection, and classification. Machine learning (ML) and deep understanding (DL) detection models are discussed. A comprehensive examination of various existing ML and DL-based studies to detect the disease of the following four crops is discussed, including the datasets used to evaluate these studies. We also provided the list of plant disease detection datasets. Finally, different ML and DL application problems are identified and discussed, along with future research prospects, by combining AI with IoT platforms like smart drones for field-based disease detection and monitoring. This work will help other practitioners in surveying different plant disease detection strategies and the limits of present systems.","<method>artificial intelligence (AI)</method>, <method>machine learning (ML)</method>, <method>deep learning (DL)</method>",<method>machine learning (ML)</method><method>deep learning (DL)</method>
2024,https://openalex.org/W4390946589,Biology,Deep-STP: a deep learning-based approach to predict snake toxin proteins by using word embeddings,"Snake venom contains many toxic proteins that can destroy the circulatory system or nervous system of prey. Studies have found that these snake venom proteins have the potential to treat cardiovascular and nervous system diseases. Therefore, the study of snake venom protein is conducive to the development of related drugs. The research technologies based on traditional biochemistry can accurately identify these proteins, but the experimental cost is high and the time is long. Artificial intelligence technology provides a new means and strategy for large-scale screening of snake venom proteins from the perspective of computing. In this paper, we developed a sequence-based computational method to recognize snake toxin proteins. Specially, we utilized three different feature descriptors, namely g-gap , natural vector and word 2 vector, to encode snake toxin protein sequences. The analysis of variance (ANOVA), gradient-boost decision tree algorithm (GBDT) combined with incremental feature selection (IFS) were used to optimize the features, and then the optimized features were input into the deep learning model for model training. The results show that our model can achieve a prediction performance with an accuracy of 82.00% in 10-fold cross-validation. The model is further verified on independent data, and the accuracy rate reaches to 81.14%, which demonstrated that our model has excellent prediction performance and robustness.","<method>gradient-boost decision tree algorithm (GBDT)</method>, <method>incremental feature selection (IFS)</method>, <method>deep learning model</method>",<method>gradient-boost decision tree algorithm (GBDT)</method><method>incremental feature selection (IFS)</method><method>deep learning model</method>
2024,https://openalex.org/W4400118952,Biology,When large language models meet personalization: perspectives of challenges and opportunities,"Abstract The advent of large language models marks a revolutionary breakthrough in artificial intelligence. With the unprecedented scale of training and model parameters, the capability of large language models has been dramatically improved, leading to human-like performances in understanding, language synthesizing, common-sense reasoning, etc. Such a major leap forward in general AI capacity will fundamentally change the pattern of how personalization is conducted. For one thing, it will reform the way of interaction between humans and personalization systems. Instead of being a passive medium of information filtering, like conventional recommender systems and search engines, large language models present the foundation for active user engagement. On top of such a new foundation, users’ requests can be proactively explored, and users’ required information can be delivered in a natural, interactable, and explainable way. For another thing, it will also considerably expand the scope of personalization, making it grow from the sole function of collecting personalized information to the compound function of providing personalized services. By leveraging large language models as a general-purpose interface, the personalization systems may compile user’s requests into plans, calls the functions of external tools (e.g., search engines, calculators, service APIs, etc.) to execute the plans, and integrate the tools’ outputs to complete the end-to-end personalization tasks. Today, large language models are still being rapidly developed, whereas the application in personalization is largely unexplored. Therefore, we consider it to be right the time to review the challenges in personalization and the opportunities to address them with large language models. In particular, we dedicate this perspective paper to the discussion of the following aspects: the development and challenges for the existing personalization system, the newly emerged capabilities of large language models, and the potential ways of making use of large language models for personalization.",<method>large language models</method>,No methods remaining
2024,https://openalex.org/W4391075306,Biology,Conumee 2.0: enhanced copy-number variation analysis from DNA methylation arrays for humans and mice,"Abstract Motivation Copy-number variations (CNVs) are common genetic alterations in cancer and their detection may impact tumor classification and therapeutic decisions. However, detection of clinically relevant large and focal CNVs remains challenging when sample material or resources are limited. This has motivated us to create a software tool to infer CNVs from DNA methylation arrays which are often generated as part of clinical routines and in research settings. Results We present our R package, conumee 2.0, that combines tangent normalization, an adjustable genomic binning heuristic, and weighted circular binary segmentation to utilize DNA methylation arrays for CNV analysis and mitigate technical biases and batch effects. Segmentation results were validated in a lung squamous cell carcinoma dataset from TCGA (n = 367 samples) by comparison to segmentations derived from genotyping arrays (Pearson’s correlation coefficient of 0.91). We further introduce a segmented block bootstrapping approach to detect focal alternations that achieved 60.9% sensitivity and 98.6% specificity for deletions affecting CDKN2A/B (60.0% and 96.9% for RB1, respectively) in a low-grade glioma cohort from TCGA (n = 239 samples). Finally, our tool provides functionality to detect and summarize CNVs across large sample cohorts. Availability and implementation Conumee 2.0 is available under open-source license at: https://github.com/hovestadtlab/conumee2.","<method>tangent normalization</method>, <method>adjustable genomic binning heuristic</method>, <method>weighted circular binary segmentation</method>, <method>segmented block bootstrapping</method>",No methods remaining
2024,https://openalex.org/W4392791588,Biology,Can large language models replace humans in systematic reviews? Evaluating <scp>GPT</scp>‐4's efficacy in screening and extracting data from peer‐reviewed and grey literature in multiple languages,"Systematic reviews are vital for guiding practice, research and policy, although they are often slow and labour-intensive. Large language models (LLMs) could speed up and automate systematic reviews, but their performance in such tasks has yet to be comprehensively evaluated against humans, and no study has tested Generative Pre-Trained Transformer (GPT)-4, the biggest LLM so far. This pre-registered study uses a ""human-out-of-the-loop"" approach to evaluate GPT-4's capability in title/abstract screening, full-text review and data extraction across various literature types and languages. Although GPT-4 had accuracy on par with human performance in some tasks, results were skewed by chance agreement and dataset imbalance. Adjusting for these caused performance scores to drop across all stages: for data extraction, performance was moderate, and for screening, it ranged from none in highly balanced literature datasets (~1:1) to moderate in those datasets where the ratio of inclusion to exclusion in studies was imbalanced (~1:3). When screening full-text literature using highly reliable prompts, GPT-4's performance was more robust, reaching ""human-like"" levels. Although our findings indicate that, currently, substantial caution should be exercised if LLMs are being used to conduct systematic reviews, they also offer preliminary evidence that, for certain review tasks delivered under specific conditions, LLMs can rival human performance.","<method>Large language models (LLMs)</method>, <method>Generative Pre-Trained Transformer (GPT)-4</method>",<method>Generative Pre-Trained Transformer (GPT)-4</method>
2024,https://openalex.org/W4390782971,Biology,MemBrain v2: an end-to-end tool for the analysis of membranes in cryo-electron tomography,"A bstract MemBrain v2 is a deep learning-enabled program aimed at the efficient analysis of membranes in cryo-electron tomography (cryo-ET). The final v2 release of MemBrain will comprise three main modules: 1) MemBrain-seg, which provides automated membrane segmentation, 2) MemBrain-pick, which provides automated picking of particles along segmented membranes, and 3) MemBrain-stats, which provides quantitative statistics of particle distributions and membrane morphometrics. This initial version of the manuscript is focused on the beta release of MemBrain-seg, which combines iterative training with diverse data and specialized Fourier-based data augmentations. These augmentations are specifically designed to enhance the tool’s adaptability to a variety of tomographic data and address common challenges in cryo-ET analysis. A key feature of MemBrain-seg is the implementation of the Surface-Dice loss function, which improves the network’s focus on membrane connectivity and allows for the effective incorporation of manual annotations from different sources. This function is beneficial in handling the variability inherent in membrane structures and annotations. Our ongoing collaboration with the cryo-ET community plays an important role in continually improving MemBrain v2 with a wide array of training data. This collaborative approach ensures that MemBrain v2 remains attuned to the field’s needs, enhancing its robustness and generalizability across different types of tomographic data. The current version of MemBrain-seg is available at https://github.com/teamtomo/membrain-seg , and the predecessor of MemBrain-pick (also called MemBrain v1) is deposited at https://github.com/CellArchLab/MemBrain . This preprint will be updated concomitantly with the code until the three integrated modules of MemBrain v2 are complete.","<method>deep learning</method>, <method>iterative training</method>, <method>Fourier-based data augmentations</method>, <method>Surface-Dice loss function</method>",<method>deep learning</method><method>Surface-Dice loss function</method>
2024,https://openalex.org/W4395055639,Biology,Foundation Models for Generalist Geospatial Artificial Intelligence,"Much of the progress in the development of highly adaptable and reusable artificial intelligence (AI) models is expected to have a profound impact on Earth science and remote sensing. Foundation models are pre-trained on large unlabeled datasets through self-supervision, and then fine-tuned for various downstream tasks with small labeled datasets. There is an increasing interest within the scientific community to investigate how to effectively build generalist AI models that exploit multi-sensor data in Earth observation applications. This paper introduces a first-of-its-kind framework for efficient pre-training and fine-tuning of foundational models on extensive geospatial data. We have utilized this framework to create Prithvi, a transformer-based geospatial foundational model pre-trained on more than 1 TB of multispectral satellite imagery from the Harmonized Landsat Sentinel-2 (HLS) dataset. Our study demonstrates the efficacy of our framework in successfully fine-tuning Prithvi to a range of Earth observation applications not previously analyzed by foundation models. Applications for which results are presented in this paper include multi-temporal cloud gap imputation, flood mapping, wildfire scar segmentation, and multi-temporal crop segmentation. We assessed the effect of Prithvi's pre-trained weights on downstream tasks and compared learning curves for (1) fine-tuning the entire model, (2) fine-tuning solely the decoder for the downstream task, and (3) training the model without utilizing Prithvi's pre-trained weights. Our experiments showed that the pre-trained model accelerates the fine-tuning process compared to leveraging randomly initialized weights. In addition, pre-trained Prithvi compared well against the state-of-the-art on downstream tasks; e.g., the model outperformed a conditional GAN model in multi-temporal cloud imputation by up to 5pp (or 5.7%) in the structural similarity index. Further, given the cost and time required for collecting labeled training data, we gradually reduced the quantity of available labeled data for refining the model to evaluate data efficiency. We found that labeled training data can be decreased substantially without affecting the model's accuracy. The pre-trained 100 million parameter model and corresponding fine-tuning workflows have been released publicly as open source contributions to the global Earth sciences community through Hugging Face","<method>foundation models</method>, <method>self-supervision</method>, <method>fine-tuning</method>, <method>transformer-based model</method>, <method>conditional GAN model</method>",<method>foundation models</method><method>self-supervision</method><method>fine-tuning</method><method>transformer-based model</method><method>conditional GAN model</method>
2024,https://openalex.org/W4404856766,Biology,Face mask identification with enhanced cuckoo optimization and deep learning-based faster regional neural network,"Abstract A mask identification and social distance monitoring system using Unmanned Aerial Vehicles (UAV) in the outdoors has been proposed for a health establishment. The above approach performed surveillance of the surrounding area using cameras installed in UAVs and internet of things technologies, and the captured images seem useful for tracking the entire environment. However, innate images from unmanned aerial vehicles show an adaptable visual effect in an uncontrolled environment, making face-mask detection and recognition harder. The UAV picture first had to be converted to grayscale, then its contrast was amplified. Image contrast was improved using Optimum Wavelet-Based Masking and the Enhanced Cuckoo Methodology (ECM). According to the contrast-enhanced image, Gabor-Transform (GT) and Stroke Width Transform (SWT) methods are used to derive attributes that help categorise mask-wearers and non-mask-wearers. Using the retrieved attributes, a Weighted Naive Bayes Classification (WNBC) detected masks in the images. Additionally, a deep neural network-based, the faster Region-Based Convolutional Neural Networks (R-CNN) algorithm combined with Adaptive Galactic Swarm Optimization (AGSO) is being used to identify appropriate and incorrect face mask wear in images, as well as to monitor social distancing among individuals in crowded areas. When the system recognises unmasked individuals, it sends their information to the doctor and the nearby police station. One unmanned aerial vehicle’s automated system alert people via speakers, ensuring social spacing. The problem involves a large percentage of appropriate and incorrect face mask wear using data from GitHub and Kaggle, including a training repository of 16,000 images and a testing data set of 12,751 images. To enhance the performance of the model’s learning, the methodology of 10-fold cross-validation will be used. Precision, recall, F1-score, and speed are then measured to determine the efficacy of the suggested approach.","<method>Optimum Wavelet-Based Masking</method>, <method>Enhanced Cuckoo Methodology (ECM)</method>, <method>Gabor-Transform (GT)</method>, <method>Stroke Width Transform (SWT)</method>, <method>Weighted Naive Bayes Classification (WNBC)</method>, <method>faster Region-Based Convolutional Neural Networks (R-CNN)</method>, <method>Adaptive Galactic Swarm Optimization (AGSO)</method>, <method>10-fold cross-validation</method>",<method>Weighted Naive Bayes Classification (WNBC)</method><method>faster Region-Based Convolutional Neural Networks (R-CNN)</method>
2024,https://openalex.org/W4399777548,Biology,Feature reduction for hepatocellular carcinoma prediction using machine learning algorithms,"Abstract Hepatocellular carcinoma (HCC) is a highly prevalent form of liver cancer that necessitates accurate prediction models for early diagnosis and effective treatment. Machine learning algorithms have demonstrated promising results in various medical domains, including cancer prediction. In this study, we propose a comprehensive approach for HCC prediction by comparing the performance of different machine learning algorithms before and after applying feature reduction methods. We employ popular feature reduction techniques, such as weighting features, hidden features correlation, feature selection, and optimized selection, to extract a reduced feature subset that captures the most relevant information related to HCC. Subsequently, we apply multiple algorithms, including Naive Bayes, support vector machines (SVM), Neural Networks, Decision Tree, and K nearest neighbors (KNN), to both the original high-dimensional dataset and the reduced feature set. By comparing the predictive accuracy, precision, F Score, recall, and execution time of each algorithm, we assess the effectiveness of feature reduction in enhancing the performance of HCC prediction models. Our experimental results, obtained using a comprehensive dataset comprising clinical features of HCC patients, demonstrate that feature reduction significantly improves the performance of all examined algorithms. Notably, the reduced feature set consistently outperforms the original high-dimensional dataset in terms of prediction accuracy and execution time. After applying feature reduction techniques, the employed algorithms, namely decision trees, Naive Bayes, KNN, neural networks, and SVM achieved accuracies of 96%, 97.33%, 94.67%, 96%, and 96.00%, respectively.","<method>Naive Bayes</method>, <method>support vector machines (SVM)</method>, <method>Neural Networks</method>, <method>Decision Tree</method>, <method>K nearest neighbors (KNN)</method>",<method>Naive Bayes</method><method>support vector machines (SVM)</method><method>Neural Networks</method><method>Decision Tree</method><method>K nearest neighbors (KNN)</method>
2024,https://openalex.org/W4391572037,Biology,Machine Learning Applications in Healthcare: Current Trends and Future Prospects,"The integration of machine learning (ML) in healthcare has witnessed remarkable advancements, transforming the landscape of medical diagnosis, treatment, and overall patient care. This article provides a comprehensive review of the current trends and future prospects of machine learning applications in the healthcare domain.The current landscape is characterized by the utilization of ML algorithms for disease diagnosis and risk prediction, personalized treatment plans, and efficient healthcare resource management. Notable applications include image recognition for radiology and pathology, predictive analytics for disease prognosis, and the development of precision medicine tailored to individual patient profiles.This review explores the evolving role of ML in improving patient outcomes, enhancing clinical decision-making, and optimizing healthcare workflows. It delves into the challenges faced in integrating ML into existing healthcare systems, such as data privacy concerns, interpretability of complex models, and the need for robust validation processes.Additionally, the article discusses future prospects and emerging trends in ML healthcare applications, including the potential for predictive analytics to preemptively identify health issues, the integration of wearable devices and remote monitoring for continuous patient care, and the intersection of ML with genomics for personalized medicine.The overarching goal of this article is to provide healthcare professionals, researchers, and policymakers with insights into the current state of ML applications in healthcare, along with an outlook on the transformative potential that machine learning holds for the future of healthcare delivery and patient outcomes.","<method>machine learning (ML) algorithms</method>, <method>image recognition</method>, <method>predictive analytics</method>",No methods remaining
2024,https://openalex.org/W4399694730,Biology,RCSB protein Data Bank: exploring protein 3D similarities via comprehensive structural alignments,"Abstract Motivation Tools for pairwise alignments between 3D structures of proteins are of fundamental importance for structural biology and bioinformatics, enabling visual exploration of evolutionary and functional relationships. However, the absence of a user-friendly, browser-based tool for creating alignments and visualizing them at both 1D sequence and 3D structural levels makes this process unnecessarily cumbersome. Results We introduce a novel pairwise structure alignment tool (rcsb.org/alignment) that seamlessly integrates into the RCSB Protein Data Bank (RCSB PDB) research-focused RCSB.org web portal. Our tool and its underlying application programming interface (alignment.rcsb.org) empowers users to align several protein chains with a reference structure by providing access to established alignment algorithms (FATCAT, CE, TM-align, or Smith–Waterman 3D). The user-friendly interface simplifies parameter setup and input selection. Within seconds, our tool enables visualization of results in both sequence (1D) and structural (3D) perspectives through the RCSB PDB RCSB.org Sequence Annotations viewer and Mol* 3D viewer, respectively. Users can effortlessly compare structures deposited in the PDB archive alongside more than a million incorporated Computed Structure Models coming from the ModelArchive and AlphaFold DB. Moreover, this tool can be used to align custom structure data by providing a link/URL or uploading atomic coordinate files directly. Importantly, alignment results can be bookmarked and shared with collaborators. By bridging the gap between 1D sequence and 3D structures of proteins, our tool facilitates deeper understanding of complex evolutionary relationships among proteins through comprehensive sequence and structural analyses. Availability and implementation The alignment tool is part of the RCSB PDB research-focused RCSB.org web portal and available at rcsb.org/alignment. Programmatic access is available via alignment.rcsb.org. Frontend code has been published at github.com/rcsb/rcsb-pecos-app. Visualization is powered by the open-source Mol* viewer (github.com/molstar/molstar and github.com/molstar/rcsb-molstar) plus the Sequence Annotations in 3D Viewer (github.com/rcsb/rcsb-saguaro-3d).","<method>FATCAT</method>, <method>CE</method>, <method>TM-align</method>, <method>Smith–Waterman 3D</method>",No methods remaining
2024,https://openalex.org/W4392303127,Biology,Recent advancements and challenges of NLP-based sentiment analysis: A state-of-the-art review,"Sentiment analysis is a method within natural language processing that evaluates and identifies the emotional tone or mood conveyed in textual data. Scrutinizing words and phrases categorizes them into positive, negative, or neutral sentiments. The significance of sentiment analysis lies in its capacity to derive valuable insights from extensive textual data, empowering businesses to grasp customer sentiments, make informed choices, and enhance their offerings. For the further advancement of sentiment analysis, gaining a deep understanding of its algorithms, applications, current performance, and challenges is imperative. Therefore, in this extensive survey, we began exploring the vast array of application domains for sentiment analysis, scrutinizing them within the context of existing research. We then delved into prevalent pre-processing techniques, datasets, and evaluation metrics to enhance comprehension. We also explored Machine Learning, Deep Learning, Large Language Models and Pre-trained models in sentiment analysis, providing insights into their advantages and drawbacks. Subsequently, we precisely reviewed the experimental results and limitations of recent state-of-the-art articles. Finally, we discussed the diverse challenges encountered in sentiment analysis and proposed future research directions to mitigate these concerns. This extensive review provides a complete understanding of sentiment analysis, covering its models, application domains, results analysis, challenges, and research directions.","<method>Machine Learning</method>, <method>Deep Learning</method>, <method>Large Language Models</method>, <method>Pre-trained models</method>",<method>Machine Learning</method><method>Deep Learning</method>
2024,https://openalex.org/W4393072087,Biology,FI-NPI: Exploring Optimal Control in Parallel Platform Systems,"Typically, the current and speed loop closure of servo motor of the parallel platform is accomplished with incremental PI regulation. The control method has strong robustness, but the parameter tuning process is cumbersome, and it is difficult to achieve the optimal control state. In order to further optimize the performance, this paper proposes a double-loop control structure based on fuzzy integral and neuron proportional integral (FI-NPI). The structure makes full use of the control advantages of the fuzzy controller and integrator to improve the performance of speed closed-loop control. And through the feedforward branch, the speed error is used as the teacher signal for neuron supervised learning, which improves the effect of current closed-loop control. Through comparative simulation experiments, this paper verifies that the FI-NPI controller has a faster dynamic response speed than the traditional PI controller. Finally, in this paper, the FI-NPI controller is implemented in C language in the servo-driven lower computer, and the speed closed-loop test of the BLDC motor is carried out. The experimental results show that the FI-NPI double-loop controller is better than the traditional double-PI controller in performance indicators such as convergence rate and RMSE, which confirms that the FI-NPI double-loop controller is more suitable for BLDC servo control.","<method>fuzzy integral</method>, <method>neuron proportional integral (FI-NPI)</method>, <method>neuron supervised learning</method>",<method>fuzzy integral</method>
2024,https://openalex.org/W4391019749,Biology,CIFAKE: Image Classification and Explainable Identification of AI-Generated Synthetic Images,"Recent advances in synthetic data have enabled the generation of images with such high quality that human beings cannot tell the difference between real-life photographs and Artificial Intelligence (AI) generated images. Given the critical necessity of data reliability and authentication, this article proposes to enhance our ability to recognise AI-generated images through computer vision. Initially, a synthetic dataset is generated that mirrors the ten classes of the already available CIFAR-10 dataset with latent diffusion, providing a contrasting set of images for comparison to real photographs. The model is capable of generating complex visual attributes, such as photorealistic reflections in water. The two sets of data present as a binary classification problem with regard to whether the photograph is real or generated by AI. This study then proposes the use of a Convolutional Neural Network (CNN) to classify the images into two categories; Real or Fake. Following hyperparameter tuning and the training of 36 individual network topologies, the optimal approach could correctly classify the images with 92.98% accuracy. Finally, this study implements explainable AI via Gradient Class Activation Mapping to explore which features within the images are useful for classification. Interpretation reveals interesting concepts within the image, in particular, noting that the actual entity itself does not hold useful information for classification; instead, the model focuses on small visual imperfections in the background of the images. The complete dataset engineered for this study, referred to as the CIFAKE dataset, is made publicly available to the research community for future work.","<method>latent diffusion</method>, <method>Convolutional Neural Network (CNN)</method>, <method>hyperparameter tuning</method>, <method>Gradient Class Activation Mapping</method>",<method>latent diffusion</method><method>Convolutional Neural Network (CNN)</method><method>Gradient Class Activation Mapping</method>
2024,https://openalex.org/W4391750982,Biology,Elk herd optimizer: a novel nature-inspired metaheuristic algorithm,"Abstract This paper proposes a novel nature-inspired swarm-based optimization algorithm called elk herd optimizer (EHO). It is inspired by the breeding process of the elk herd. Elks have two main breeding seasons: rutting and calving. In the rutting season, the elk herd splits into different families of various sizes. This division is based on fighting for dominance between bulls, where the stronger bull can form a family with large numbers of harems. In the calving season, each family breeds new calves from its bull and harems. This inspiration is set in an optimization context where the optimization loop consists of three operators: rutting season, calving season, and selection season. During the selection season, all families are merged, including bulls, harems, and calves. The fittest elk herd will be selected for use in the upcoming rutting and calving seasons. In simple words, EHO divides the population into a set of groups, each with one leader and several followers in the rutting season. The number of followers is determined based on the fitness value of its leader group. Each group will generate new solutions based on its leader and followers in the calving season. The members of all groups including leaders, followers, and new solutions are combined and the fittest population is selected in the selection season. The performance of EHO is assessed using 29 benchmark optimization problems utilized in the CEC-2017 special sessions on real-parameter optimization and four traditional real-world engineering design problems. The comparative results were conducted against ten well-established metaheuristic algorithms and showed that the proposed EHO yielded the best results for almost all the benchmark functions used. Statistical testing using Friedman’s test post-hocked by Holm’s test function confirms the superiority of the proposed EHO when compared to other methods. In a nutshell, EHO is an efficient nature-inspired swarm-based optimization algorithm that can be used to tackle several optimization problems.","<method>elk herd optimizer (EHO)</method>, <method>metaheuristic algorithms</method>",No methods remaining
2024,https://openalex.org/W4399039179,Biology,Distributed Event-Triggered Output-Feedback Time-Varying Formation Fault-Tolerant Control for Nonlinear Multi-Agent Systems,"This paper studies the event-triggered time-varying formation control problem for nonlinear multi-agent systems with actuator faults. Based on the neural network approximation technique, a neural observer is constructed to estimate the unmeasured states of systems. Then, a distributed adaptive event-triggered time-varying formation control manner is proposed utilizing the intermittent estimated states information from the agent and its neighbors. To overcome the problem that estimated states triggering leads to virtual control laws is non-differentiable, a distributed continuous control scheme under regular output-feedback is designed firstly, upon which a distributed event-triggered controller is constructed by replacing estimated states with intermittent estimated ones. It is shown that the designed event-triggered output-feedback time-varying formation fault-tolerant controller can compensate for actuator faults, and all signals in closed-loop systems are semi-globally uniformly ultimately bounded. Finally, simulation results of a practical example are given to verify the effectiveness of the proposed control manner. <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">Note to Practitioners</i> —Formation control has broad application prospects in modern military and civilian fields, such as combat aircraft flying formation, satellite formation, autonomous vehicle formation, etc. In formation control systems, when agents occur actuator faults, it may break the original formation and even cause collision between agents. As a result, the security of formation control systems is facing great challenges in practical engineering applications. On the other hand, communication bandwidth is limited in practical engineering systems, and how to make systems quickly form formation under the limited communication bandwidth has become a key topic. Inspired by the above discussions, a distributed state-triggered output-feedback time-varying formation fault-tolerant control scheme is designed in this paper, in which actuator faults are compensated by using adaptive technology. Meanwhile, to sufficiently save the usage of system communication resources, a dual-channel event-triggered mechanism is designed.","<method>neural network approximation technique</method>, <method>neural observer</method>, <method>distributed adaptive event-triggered time-varying formation control</method>, <method>distributed continuous control scheme under regular output-feedback</method>, <method>distributed event-triggered controller</method>, <method>distributed state-triggered output-feedback time-varying formation fault-tolerant control scheme</method>, <method>adaptive technology</method>, <method>dual-channel event-triggered mechanism</method>",No methods remaining
2024,https://openalex.org/W4395050972,Biology,Optimization of hepatological clinical guidelines interpretation by large language models: a retrieval augmented generation-based framework,"Abstract Large language models (LLMs) can potentially transform healthcare, particularly in providing the right information to the right provider at the right time in the hospital workflow. This study investigates the integration of LLMs into healthcare, specifically focusing on improving clinical decision support systems (CDSSs) through accurate interpretation of medical guidelines for chronic Hepatitis C Virus infection management. Utilizing OpenAI’s GPT-4 Turbo model, we developed a customized LLM framework that incorporates retrieval augmented generation (RAG) and prompt engineering. Our framework involved guideline conversion into the best-structured format that can be efficiently processed by LLMs to provide the most accurate output. An ablation study was conducted to evaluate the impact of different formatting and learning strategies on the LLM’s answer generation accuracy. The baseline GPT-4 Turbo model’s performance was compared against five experimental setups with increasing levels of complexity: inclusion of in-context guidelines, guideline reformatting, and implementation of few-shot learning. Our primary outcome was the qualitative assessment of accuracy based on expert review, while secondary outcomes included the quantitative measurement of similarity of LLM-generated responses to expert-provided answers using text-similarity scores. The results showed a significant improvement in accuracy from 43 to 99% ( p &lt; 0.001), when guidelines were provided as context in a coherent corpus of text and non-text sources were converted into text. In addition, few-shot learning did not seem to improve overall accuracy. The study highlights that structured guideline reformatting and advanced prompt engineering (data quality vs. data quantity) can enhance the efficacy of LLM integrations to CDSSs for guideline delivery.","<method>Large language models (LLMs)</method>, <method>OpenAI’s GPT-4 Turbo model</method>, <method>retrieval augmented generation (RAG)</method>, <method>prompt engineering</method>, <method>few-shot learning</method>",<method>OpenAI’s GPT-4 Turbo model</method><method>retrieval augmented generation (RAG)</method><method>few-shot learning</method>
2024,https://openalex.org/W4399885374,Biology,Survival Prediction Across Diverse Cancer Types Using Neural Networks,"Gastric cancer and Colon adenocarcinoma represent widespread and challenging malignancies with high mortality rates and complex treatment landscapes. In response to the critical need for accurate prognosis in cancer patients, the medical community has embraced the 5-year survival rate as a vital metric for estimating patient outcomes. This study introduces a pioneering approach to enhance survival prediction models for gastric and Colon adenocarcinoma patients. Leveraging advanced image analysis techniques, we sliced whole slide images (WSI) of these cancers, extracting comprehensive features to capture nuanced tumor characteristics. Subsequently, we constructed patient-level graphs, encapsulating intricate spatial relationships within tumor tissues. These graphs served as inputs for a sophisticated 4-layer graph convolutional neural network (GCN), designed to exploit the inherent connectivity of the data for comprehensive analysis and prediction. By integrating patients' total survival time and survival status, we computed C-index values for gastric cancer and Colon adenocarcinoma, yielding 0.57 and 0.64, respectively. Significantly surpassing previous convolutional neural network models, these results underscore the efficacy of our approach in accurately predicting patient survival outcomes. This research holds profound implications for both the medical and AI communities, offering insights into cancer biology and progression while advancing personalized treatment strategies. Ultimately, our study represents a significant stride in leveraging AI-driven methodologies to revolutionize cancer prognosis and improve patient outcomes on a global scale.","<method>graph convolutional neural network (GCN)</method>, <method>convolutional neural network</method>",<method>graph convolutional neural network (GCN)</method><method>convolutional neural network</method>
2024,https://openalex.org/W4391216149,Biology,"Benchmarking Micro-Action Recognition: Dataset, Methods, and Applications","Micro-action is an imperceptible non-verbal behaviour characterised by low-intensity movement. It offers insights into the feelings and intentions of individuals and is important for human-oriented applications such as emotion recognition and psychological assessment. However, the identification, differentiation, and understanding of micro-actions pose challenges due to the imperceptible and inaccessible nature of these subtle human behaviors in everyday life. In this study, we innovatively collect a new micro-action dataset designated as Micro-action-52 (MA-52), and propose a benchmark named micro-action network (MANet) for micro-action recognition (MAR) task. Uniquely, MA-52 provides the whole-body perspective including gestures, upper- and lower-limb movements, attempting to reveal comprehensive micro-action cues. In detail, MA-52 contains 52 micro-action categories along with seven body part labels, and encompasses a full array of realistic and natural micro-actions, accounting for 205 participants and 22,422 video instances collated from the psychological interviews. Based on the proposed dataset, we assess MANet and other nine prevalent action recognition methods. MANet incorporates squeeze-and-excitation (SE) and temporal shift module (TSM) into the ResNet architecture for modeling the spatiotemporal characteristics of micro-actions. Then a joint-embedding loss is designed for semantic matching between video and action labels; the loss is used to better distinguish between visually similar yet distinct micro-action categories. The extended application in emotion recognition has demonstrated one of the important values of our proposed dataset and method. In the future, further exploration of human behaviour, emotion, and psychological assessment will be conducted in depth. The dataset and source code are released at https://github.com/VUT-HFUT/Micro-Action.","<method>micro-action network (MANet)</method>, <method>squeeze-and-excitation (SE)</method>, <method>temporal shift module (TSM)</method>, <method>ResNet architecture</method>, <method>joint-embedding loss</method>, <method>prevalent action recognition methods</method>",<method>squeeze-and-excitation (SE)</method><method>temporal shift module (TSM)</method><method>ResNet architecture</method><method>joint-embedding loss</method>
2024,https://openalex.org/W4390652362,Biology,A comprehensive review of the development of land use regression approaches for modeling spatiotemporal variations of ambient air pollution: A perspective from 2011 to 2023,"Land use regression (LUR) models are widely used in epidemiological and environmental studies to estimate humans' exposure to air pollution within urban areas. However, the early models, developed using linear regressions and data from fixed monitoring stations and passive sampling, were primarily designed to model traditional and criteria air pollutants and had limitations in capturing high-resolution spatiotemporal variations of air pollution. Over the past decade, there has been a notable development of multi-source observations from low-cost monitors, mobile monitoring, and satellites, in conjunction with the integration of advanced statistical methods and spatially and temporally dynamic predictors, which have facilitated significant expansion and advancement of LUR approaches. This paper reviews and synthesizes the recent advances in LUR approaches from the perspectives of the changes in air quality data acquisition, novel predictor variables, advances in model-developing approaches, improvements in validation methods, model transferability, and modeling software as reported in 155 LUR studies published between 2011 and 2023. We demonstrate that these developments have enabled LUR models to be developed for larger study areas and encompass a wider range of criteria and unregulated air pollutants. LUR models in the conventional spatial structure have been complemented by more complex spatiotemporal structures. Compared with linear models, advanced statistical methods yield better predictions when handling data with complex relationships and interactions. Finally, this study explores new developments, identifies potential pathways for further breakthroughs in LUR methodologies, and proposes future research directions. In this context, LUR approaches have the potential to make a significant contribution to future efforts to model the patterns of long- and short-term exposure of urban populations to air pollution.","<method>linear regressions</method>, <method>advanced statistical methods</method>",No methods remaining
2024,https://openalex.org/W4400659510,Biology,Aspect-based drug review classification through a hybrid model with ant colony optimization using deep learning,"Abstract The task of aspect-level sentiment analysis is intricately designed to determine the sentiment polarity directed towards a specific target within a sentence. With the increasing availability of online reviews and the growing importance of healthcare decisions, analyzing drug reviews has become a critical task. Traditional sentiment analysis, which categorizes a whole review as positive, negative, or neutral, provides limited insights for consumers and healthcare professionals. Aspect-based sentiment analysis (ABSA) aims to overcome these limitations by identifying and evaluating the sentiment associated with specific aspects or attributes of drugs mentioned in the reviews. Various fields, including business, politics, and medicine, have been explored in the context of sentiment analysis. Automation of online user reviews allows pharmaceutical companies to assess large amounts of user feedback. This helps extract pharmacological efficacy and side effect insights. The data collected could improve pharmacovigilance. Reviewing user comments can provide valuable data that can be used to improve drug safety and efficacy monitoring procedures. This improves pharmacovigilance processes, improving pharmaceutical outcomes understanding and corporate decision-making. Therefore, we propose a pre-trained RoBERTa with a Bi-LSTM model to categorise drug reviews from online sources and pre-process the text data. Ant Colony Optimization can be used in feature selection for ABSA, helping to identify the most relevant aspects and sentiments. Further, RoBERTa is fine-tuned to perform ABSA on the dataset, enabling the system to categorize aspects and determine the associated sentiment. The outcomes reveal that the suggested framework has achieved higher accuracy (96.78%) and F1 score (98.29%) on druglib.com, and 95.02% on the drugs.com dataset, than several prior state-of-the-art methods.","<method>pre-trained RoBERTa</method>, <method>Bi-LSTM model</method>, <method>Ant Colony Optimization</method>, <method>fine-tuned RoBERTa</method>",<method>pre-trained RoBERTa</method><method>Bi-LSTM model</method><method>fine-tuned RoBERTa</method>
2024,https://openalex.org/W4390494339,Biology,"A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection in Industrial Time Series: Methods, Applications, and Directions","Automating the monitoring of industrial processes has the potential to enhance efficiency and optimize quality by promptly detecting abnormal events and thus facilitating timely interventions. Deep learning, with its capacity to discern non-trivial patterns within large datasets, plays a pivotal role in this process. Standard deep learning methods are suitable to solve a specific task given a specific type of data. During training, deep learning demands large volumes of labeled data. However, due to the dynamic nature of the industrial processes and environment, it is impractical to acquire large-scale labeled data for standard deep learning training for every slightly different case anew. Deep transfer learning offers a solution to this problem. By leveraging knowledge from related tasks and accounting for variations in data distributions, the transfer learning framework solves new tasks with little or even no additional labeled data. The approach bypasses the need to retrain a model from scratch for every new setup and dramatically reduces the labeled data requirement. This survey first provides an in-depth review of deep transfer learning, examining the problem settings of transfer learning and classifying the prevailing deep transfer learning methods. Moreover, we delve into applications of deep transfer learning in the context of a broad spectrum of time series anomaly detection tasks prevalent in primary industrial domains, e.g., manufacturing process monitoring, predictive maintenance, energy management, and infrastructure facility monitoring. We discuss the challenges and limitations of deep transfer learning in industrial contexts and conclude the survey with practical directions and actionable suggestions to address the need to leverage diverse time series data for anomaly detection in an increasingly dynamic production environment.","<method>deep learning</method>, <method>standard deep learning methods</method>, <method>deep transfer learning</method>, <method>transfer learning framework</method>",<method>deep learning</method><method>deep transfer learning</method><method>transfer learning framework</method>
2024,https://openalex.org/W4399326707,Biology,Enhancing precision agriculture: A comprehensive review of machine learning and AI vision applications in all-terrain vehicle for farm automation,"The automation of all-terrain vehicles (ATVs) through the integration of advanced technologies such as machine learning (ML) and artificial intelligence (AI) vision has significantly changed precision agriculture. This paper aims to analyse and develop trends to provide comprehensive knowledge of the current state of ATV-based precision agriculture and the future possibilities of ML and AI. A bibliometric analysis was conducted through network diagram with keywords taken from previous publications in the domain. This review comprehensively analyses the potential of machine learning and artificial intelligence in transforming farming operations through the automation of tasks and the deployment of all-terrain vehicles. The research extensively analyses how machine learning methods have influenced several aspects of agricultural activities, such as planting, harvesting, spraying, weeding, crop monitoring, and others. AI vision systems are being researched for their ability to enhance precise and prompt decision-making in ATV-driven agricultural automation. These technologies have been thoroughly tested to show how they can improve crop yield, reducing overall investment, and make farming more efficient. Examples include machine learning-based seeding accuracy, AI-enabled crop health monitoring, and the use of AI vision for accurate pesticide application. The assessment examines challenges such as data privacy problems and scalability constraints, along with potential advancements and future prospects in the field. This will assist researchers and practitioners in making well-informed judgments regarding farming practices that are efficient, sustainable, and technologically robust.","<method>machine learning</method>, <method>artificial intelligence vision</method>, <method>machine learning methods</method>, <method>AI vision systems</method>, <method>machine learning-based seeding accuracy</method>, <method>AI-enabled crop health monitoring</method>, <method>AI vision for accurate pesticide application</method>",<method>machine learning</method>
2024,https://openalex.org/W4394579747,Biology,An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing: Algorithm Development and Validation Study,"Background Large language models (LLMs) have shown remarkable capabilities in natural language processing (NLP), especially in domains where labeled data are scarce or expensive, such as the clinical domain. However, to unlock the clinical knowledge hidden in these LLMs, we need to design effective prompts that can guide them to perform specific clinical NLP tasks without any task-specific training data. This is known as in-context learning, which is an art and science that requires understanding the strengths and weaknesses of different LLMs and prompt engineering approaches. Objective The objective of this study is to assess the effectiveness of various prompt engineering techniques, including 2 newly introduced types—heuristic and ensemble prompts, for zero-shot and few-shot clinical information extraction using pretrained language models. Methods This comprehensive experimental study evaluated different prompt types (simple prefix, simple cloze, chain of thought, anticipatory, heuristic, and ensemble) across 5 clinical NLP tasks: clinical sense disambiguation, biomedical evidence extraction, coreference resolution, medication status extraction, and medication attribute extraction. The performance of these prompts was assessed using 3 state-of-the-art language models: GPT-3.5 (OpenAI), Gemini (Google), and LLaMA-2 (Meta). The study contrasted zero-shot with few-shot prompting and explored the effectiveness of ensemble approaches. Results The study revealed that task-specific prompt tailoring is vital for the high performance of LLMs for zero-shot clinical NLP. In clinical sense disambiguation, GPT-3.5 achieved an accuracy of 0.96 with heuristic prompts and 0.94 in biomedical evidence extraction. Heuristic prompts, alongside chain of thought prompts, were highly effective across tasks. Few-shot prompting improved performance in complex scenarios, and ensemble approaches capitalized on multiple prompt strengths. GPT-3.5 consistently outperformed Gemini and LLaMA-2 across tasks and prompt types. Conclusions This study provides a rigorous evaluation of prompt engineering methodologies and introduces innovative techniques for clinical information extraction, demonstrating the potential of in-context learning in the clinical domain. These findings offer clear guidelines for future prompt-based clinical NLP research, facilitating engagement by non-NLP experts in clinical NLP advancements. To the best of our knowledge, this is one of the first works on the empirical evaluation of different prompt engineering approaches for clinical NLP in this era of generative artificial intelligence, and we hope that it will inspire and inform future research in this area.","<method>in-context learning</method>, <method>prompt engineering</method>, <method>heuristic prompts</method>, <method>ensemble prompts</method>, <method>simple prefix prompts</method>, <method>simple cloze prompts</method>, <method>chain of thought prompts</method>, <method>anticipatory prompts</method>, <method>ensemble approaches</method>, <method>zero-shot prompting</method>, <method>few-shot prompting</method>",<method>in-context learning</method><method>ensemble approaches</method><method>zero-shot prompting</method><method>few-shot prompting</method>
2024,https://openalex.org/W4397001018,Biology,A systematic review of hyperspectral imaging in precision agriculture: Analysis of its current state and future prospects,"Hyperspectral sensor adaptability in precision agriculture to digital images is still at its nascent stage. Hyperspectral imaging (HSI) is data rich in solving agricultural problems like disease detection, weed detection, stress detection, crop monitoring, nutrient application, soil mineralogy, yield estimation, and sorting applications. With modern precision agriculture, the challenge now is to bring these applications to the field for real-time solutions, where machines are enabled to conduct analyses without expert supervision and communicate the results to users for better management of farmlands; a necessary step to gain complete autonomy in agricultural farmlands. Significant advancements in HSI technology for precision agriculture are required to fully realize its potential. As a wide-ranging collection of the status of HSI and analysis in precision agriculture is lacking, this review endeavors to provide a comprehensive overview of the recent advancements and trends of HSI in precision agriculture for real-time applications. In this study, a systematic review of 163 scientific articles published over the past twenty years (2003–2023) was conducted. Of these, 97 were selected for further analysis based on their relevance to the topic at hand. Topics include conventional data preprocessing techniques, hyperspectral data acquisition, data compression methods, and segmentation methods. The hardware implementation of field-programmable gate arrays (FPGAs) and graphics processing units (GPUs) for high-speed data processing and application of machine learning and deep learning technologies were explored. This review highlights the potential of HSI as a powerful tool for precision agriculture, particularly in real-time applications, discusses limitations, and provides insights into future research directions.","<method>machine learning</method>, <method>deep learning</method>",<method>machine learning</method><method>deep learning</method>
2024,https://openalex.org/W4390597725,Biology,Critical review on water quality analysis using IoT and machine learning models,"Water quality and its management are the most precise concerns confronting humanity globally. This article evaluates the various sensors used for water quality monitoring and focuses on the water quality index considering the multiple physical, chemical, and biological parameters. A Review of Internet of Things (IoT) research for water quality monitoring and analysis, sensors used for water quality can help remote monitoring of the water quality parameters using various IoT-based sensors that convey the assembled estimations utilizing Low-Power Wide Area Network innovations. Overall, the IoT system was 95 % accurate in measuring pH, Turbidity, TDS, and Temperature, while the traditional method was only 85 % accurate. Also, this study reviewed the different A.I. techniques used to assess water quality, including conventional machine learning techniques, Support Vector Machines, Deep Neural Networks, and K-nearest neighbors. Compared to traditional methods, machine learning and deep learning can significantly increase the accuracy of measurements of groundwater quality. However, various variables, such as the caliber of the training data, the water quality metrics' complexity, and the monitoring frequency, will affect the accuracy. The geographical information system (GIS) is used for spatial data analysis and managing water resources. The quality of its data is also reviewed in the paper. Based on these analyses, the study has forecasted the future sensors, Geospatial Technology, and machine learning techniques for water quality monitoring and analysis.","<method>conventional machine learning techniques</method>, <method>Support Vector Machines</method>, <method>Deep Neural Networks</method>, <method>K-nearest neighbors</method>",<method>Support Vector Machines</method><method>Deep Neural Networks</method><method>K-nearest neighbors</method>
2024,https://openalex.org/W4390604402,Biology,A novel and dynamic land use/cover change research framework based on an improved PLUS model and a fuzzy multiobjective programming model,"Spatial reconstruction and scenario simulation of historical processes and future trends of land use/cover change (LUCC) can help to reveal the historical background of land conversion and the spatial distribution of future land. Moreover, there is a close relationship between the spatiotemporal dynamics of land use/cover and changes in different ecosystem services (ESs). Using this relationship to simulate future land use scenarios is important. In this study, an LUCC dynamic analysis framework (LSTM-PLUS-FMOP) was constructed based on a deep learning time series forecasting model (LSTM), a parallelized urban land use simulation (PLUS) model and a fuzzy multiobjective programming (FMOP) model. The PLUS model was used to analyze the driving mechanism of land expansion and explore the land conversion pattern. In addition, three land conversion scenarios were established: natural land expansion (NLE), economic development priority (EDP) and regional sustainable development (RSD). The FMOP model and the relationship between LUCC and ES were used to perform a spatial simulation of land conversion. The uncertainty parameters in the model were treated by intuitionistic fuzzy numbers (IFSs). This study applied the constructed framework to the Yellow River Basin of Shaanxi Province (YRB-SX). The results showed that (1) from 2000 to 2020, the cropland area of the YRB-SX continuously decreased by 12.67 × 104 ha, while the built-up area continuously increased by 28.25 × 104 ha. The net reduction in woodland and grassland area was 13.90 × 104 ha. (2) The relative error range of land prediction using the LSTM model was 0.0003– 0.0042. This model had better accuracy than the Markov chain prediction model. (3) The cropland area decreased by 0.26% (NLE), 0.85% (EDP) and 1.68% (RSD) under the three scenarios. The built-up area increased by 25.01%, 32.76% and 14.72%, respectively. The RSD scenario followed the principles of ecological protection and spatial constraints, which mitigated the degradation of the ecosystem to some extent. This coupled simulation framework will help to obtain land allocation schemes that meet the requirements of ecological protection and provide solutions for rational land management.","<method>LSTM</method>, <method>PLUS model</method>, <method>fuzzy multiobjective programming (FMOP) model</method>",<method>LSTM</method>
2024,https://openalex.org/W4391168980,Biology,Utilizing Hybrid Machine Learning and Soft Computing Techniques for Landslide Susceptibility Mapping in a Drainage Basin,"The hydrological system of thebasin of Lake Urmia is complex, deriving its supply from a network comprising 13 perennial rivers, along withnumerous small springs and direct precipitation onto the lake’s surface. Among these contributors, approximately half of the inflow is attributed to the Zarrineh River and the Simineh River. Remarkably, Lake Urmia lacks a natural outlet, with its water loss occurring solely through evaporation processes. This study employed a comprehensive methodology integrating ground surveys, remote sensing analyses, and meticulous documentation of historical landslides within the basin as primary information sources. Through this investigative approach, we preciselyidentified and geolocated a total of 512 historical landslide occurrences across the Urmia Lake drainage basin, leveraging GPS technology for precision. Thisarticle introduces a suite of hybrid machine learning predictive models, such as support-vector machine (SVM), random forest (RF), decision trees (DT), logistic regression (LR), fuzzy logic (FL), and the technique for order of preference by similarity to the ideal solution (TOPSIS). These models were strategically deployed to assess landslide susceptibility within the region. The outcomes of the landslide susceptibility assessment reveal that the main high susceptible zones for landslide occurrence are concentrated in the northwestern, northern, northeastern, and some southern and southeastern areas of the region. Moreover, when considering the implementation of predictions using different algorithms, it became evident that SVM exhibited superior performance regardingboth accuracy (0.89) and precision (0.89), followed by RF, with and accuracy of 0.83 and a precision of 0.83. However, it is noteworthy that TOPSIS yielded the lowest accuracy value among the algorithms assessed.","<method>support-vector machine (SVM)</method>, <method>random forest (RF)</method>, <method>decision trees (DT)</method>, <method>logistic regression (LR)</method>, <method>fuzzy logic (FL)</method>, <method>technique for order of preference by similarity to the ideal solution (TOPSIS)</method>",<method>support-vector machine (SVM)</method><method>random forest (RF)</method><method>decision trees (DT)</method><method>logistic regression (LR)</method>
2024,https://openalex.org/W4391831565,Biology,Comparison of Random Forest and XGBoost Classifiers Using Integrated Optical and SAR Features for Mapping Urban Impervious Surface,"The integration of optical and SAR datasets through ensemble machine learning models shows promising results in urban remote sensing applications. The integration of multi-sensor datasets enhances the accuracy of information extraction. This research presents a comparison of two ensemble machine learning classifiers (random forest and extreme gradient boost (XGBoost)) classifiers using an integration of optical and SAR features and simple layer stacking (SLS) techniques. Therefore, Sentinel-1 (SAR) and Landsat 8 (optical) datasets were used with SAR textures and enhanced modified indices to extract features for the year 2023. The classification process utilized two machine learning algorithms, random forest and XGBoost, for urban impervious surface extraction. The study focused on three significant East Asian cities with diverse urban dynamics: Jakarta, Manila, and Seoul. This research proposed a novel index called the Normalized Blue Water Index (NBWI), which distinguishes water from other features and was utilized as an optical feature. Results showed an overall accuracy of 81% for UIS classification using XGBoost and 77% with RF while classifying land use land cover into four major classes (water, vegetation, bare soil, and urban impervious). However, the proposed framework with the XGBoost classifier outperformed the RF algorithm and Dynamic World (DW) data product and comparatively showed higher classification accuracy. Still, all three results show poor separability with bare soil class compared to ground truth data. XGBoost outperformed random forest and Dynamic World in classification accuracy, highlighting its potential use in urban remote sensing applications.","<method>ensemble machine learning models</method>, <method>random forest</method>, <method>extreme gradient boost (XGBoost)</method>, <method>simple layer stacking (SLS)</method>",<method>ensemble machine learning models</method><method>random forest</method><method>extreme gradient boost (XGBoost)</method>
2024,https://openalex.org/W4390669592,Biology,Enhancing plasticity in optoelectronic artificial synapses: A pathway to efficient neuromorphic computing,"The continuous growth in artificial intelligence and high-performance computing has necessitated the development of efficient optoelectronic artificial synapses crucial for neuromorphic computing (NC). Ga2O3 is an emerging wide-bandgap semiconductor with high deep ultraviolet absorption, tunable persistent photoconductivity, and excellent stability toward electric fields, making it a promising component for optoelectronic artificial synapses. Currently reported Ga2O3 optoelectronic artificial synapses often suffer from complex fabrication processes and potential room for improvement due to plasticity. To address the issue of low device plasticity and practical application scenarios, we present an amorphous Ga2O3 (α-GaOx) flexible optoelectronic artificial synapse. This synapse modulates light stimulus signals using electron/oxygen vacancies and optical stimulation and operates as a visual storage device for information processing. We investigate the improvement of the optoelectronic synapses' plasticity by controlling the number of oxygen vacancies via a plasma treatment method and demonstrate its effective application in a three-layer backpropagation neural network for handwritten digit classification. Under the same stimulus conditions, the synaptic weight of samples treated with Ar plasma exhibits a higher rate of change, with the current levels increasing by 2–3 orders of magnitude, achieving greater plasticity. The improved optoelectronic synapses achieved an accuracy of 93.34%/94%, demonstrating their potential as efficient computing solutions and insights for future applications in NC chips.",<method>backpropagation neural network</method>,<method>backpropagation neural network</method>
2024,https://openalex.org/W4392763392,Biology,ANYmal parkour: Learning agile navigation for quadrupedal robots,"Performing agile navigation with four-legged robots is a challenging task because of the highly dynamic motions, contacts with various parts of the robot, and the limited field of view of the perception sensors. Here, we propose a fully learned approach to training such robots and conquer scenarios that are reminiscent of parkour challenges. The method involves training advanced locomotion skills for several types of obstacles, such as walking, jumping, climbing, and crouching, and then using a high-level policy to select and control those skills across the terrain. Thanks to our hierarchical formulation, the navigation policy is aware of the capabilities of each skill, and it will adapt its behavior depending on the scenario at hand. In addition, a perception module was trained to reconstruct obstacles from highly occluded and noisy sensory data and endows the pipeline with scene understanding. Compared with previous attempts, our method can plan a path for challenging scenarios without expert demonstration, offline computation, a priori knowledge of the environment, or taking contacts explicitly into account. Although these modules were trained from simulated data only, our real-world experiments demonstrate successful transfer on hardware, where the robot navigated and crossed consecutive challenging obstacles with speeds of up to 2 meters per second.","<method>fully learned approach</method>, <method>training advanced locomotion skills</method>, <method>high-level policy to select and control skills</method>, <method>hierarchical formulation</method>, <method>perception module trained to reconstruct obstacles from sensory data</method>",No methods remaining
2024,https://openalex.org/W4393201659,Biology,Garlic Origin Traceability and Identification Based on Fusion of Multi-Source Heterogeneous Spectral Information,"The chemical composition and nutritional content of garlic are greatly impacted by its production location, leading to distinct flavor profiles and functional properties among garlic varieties from diverse origins. Consequently, these variations determine the preference and acceptance among diverse consumer groups. In this study, purple-skinned garlic samples were collected from five regions in China: Yunnan, Shandong, Henan, Anhui, and Jiangsu Provinces. Mid-infrared spectroscopy and ultraviolet spectroscopy were utilized to analyze the components of garlic cells. Three preprocessing methods, including Multiple Scattering Correction (MSC), Savitzky–Golay Smoothing (SG Smoothing), and Standard Normalized Variate (SNV), were applied to reduce the background noise of spectroscopy data. Following variable feature extraction by Genetic Algorithm (GA), a variety of machine learning algorithms, including XGboost, Support Vector Classification (SVC), Random Forest (RF), and Artificial Neural Network (ANN), were used according to the fusion of spectral data to obtain the best processing results. The results showed that the best-performing model for ultraviolet spectroscopy data was SNV-GA-ANN, with an accuracy of 99.73%. The best-performing model for mid-infrared spectroscopy data was SNV-GA-RF, with an accuracy of 97.34%. After the fusion of ultraviolet and mid-infrared spectroscopy data, the SNV-GA-SVC, SNV-GA-RF, SNV-GA-ANN, and SNV-GA-XGboost models achieved 100% accuracy in both training and test sets. Although there were some differences in the accuracy of the four models under different preprocessing methods, the fusion of ultraviolet and mid-infrared spectroscopy data yielded the best outcomes, with an accuracy of 100%. Overall, the combination of ultraviolet and mid-infrared spectroscopy data fusion and chemometrics established in this study provides a theoretical foundation for identifying the origin of garlic, as well as that of other agricultural products.","<method>Genetic Algorithm (GA)</method>, <method>XGboost</method>, <method>Support Vector Classification (SVC)</method>, <method>Random Forest (RF)</method>, <method>Artificial Neural Network (ANN)</method>",<method>Genetic Algorithm (GA)</method><method>XGboost</method><method>Support Vector Classification (SVC)</method><method>Random Forest (RF)</method><method>Artificial Neural Network (ANN)</method>
2024,https://openalex.org/W4391037822,Biology,Estimating compressive strength of concrete containing rice husk ash using interpretable machine learning-based models,"The construction sector is a major contributor to global greenhouse gas emissions. Using recycled and waste materials in concrete is a practical solution to address environmental challenges. Currently, agricultural waste is widely used as a substitute for cement in the production of eco-friendly concrete. However, traditional methods for assessing the strength of such materials are both expensive and time-consuming. Therefore, this study uses machine learning techniques to develop prediction models for the compressive strength (CS) of rice husk ash (RHA) concrete. The ML techniques used in the present study include random forest (RF), light gradient boosting machine (LightGBM), ridge regression, and extreme gradient boosting (XGBoost). A total of 348 values of CS were collected from the experimental studies, and five characteristics of RHA concrete were taken as input variables. For the performance assessment of the models, multiple statistical metrics were used. During the training phase, the correlation coefficients (R) obtained for ridge regression, RF, XGBoost, and LightGBM were 0.943, 0.981, 0.985, and 0.996, respectively. In the testing set, these values demonstrated even higher performance, with correlation coefficients of 0.971, 0.993, 0.992, and 0.998 for ridge regression, RF, XGBoost, and LightGBM, respectively. The statistical analysis revealed that the LightGBM model outperformed other models, whereas the ridge regression model exhibited comparatively lower accuracy. SHapley Additive exPlanation (SHAP) method was employed for the interpretability of the developed model. The SHAP analysis revealed that water-to-cement is a controlling parameter in estimating the CS of RHA concrete. In conclusion, this study provides valuable guidance for builders and researchers to estimate the CS of RHA concrete. However, it is suggested that more input variables be incorporated and hybrid models utilized to further enhance the reliability and precision of the models.","<method>random forest (RF)</method>, <method>light gradient boosting machine (LightGBM)</method>, <method>ridge regression</method>, <method>extreme gradient boosting (XGBoost)</method>, <method>SHapley Additive exPlanation (SHAP)</method>",<method>random forest (RF)</method><method>light gradient boosting machine (LightGBM)</method><method>ridge regression</method><method>extreme gradient boosting (XGBoost)</method><method>SHapley Additive exPlanation (SHAP)</method>
2024,https://openalex.org/W4393012885,Biology,Improving Thyroid Disorder Diagnosis via Ensemble Stacking and Bidirectional Feature Selection,"Thyroid disorders represent a significant global health challenge with hypothyroidism and hyperthyroidism as two common conditions arising from dysfunction in the thyroid gland.Accurate and timely diagnosis of these disorders is crucial for effective treatment and patient care.This research introduces a comprehensive approach to improve the accuracy of thyroid disorder diagnosis through the integration of ensemble stacking and advanced feature selection techniques.Sequential forward feature selection, sequential backward feature elimination, and bidirectional feature elimination are investigated in this study.In ensemble learning, random forest, adaptive boosting, and bagging classifiers are employed.The effectiveness of these techniques is evaluated using two different datasets obtained from the University of California Irvine-Machine Learning Repository, both of which undergo preprocessing steps, including outlier removal, addressing missing data, data cleansing, and feature reduction.Extensive experimentation demonstrates the remarkable success of proposed ensemble stacking and bidirectional feature elimination achieving 100% and 99.86% accuracy in identifying hyperthyroidism and hypothyroidism, respectively.Beyond enhancing detection accuracy, the ensemble stacking model also demonstrated a streamlined computational complexity which is pivotal for practical medical applications.It significantly outperformed existing studies with similar objectives underscoring the viability and effectiveness of the proposed scheme.This research offers an innovative perspective and sets the platform for improved thyroid disorder diagnosis with broader implications for healthcare and patient well-being.","<method>ensemble stacking</method>, <method>sequential forward feature selection</method>, <method>sequential backward feature elimination</method>, <method>bidirectional feature elimination</method>, <method>random forest</method>, <method>adaptive boosting</method>, <method>bagging classifiers</method>",<method>ensemble stacking</method><method>sequential forward feature selection</method><method>sequential backward feature elimination</method><method>random forest</method><method>adaptive boosting</method><method>bagging classifiers</method>
2024,https://openalex.org/W4396877909,Biology,The Capacity and Robustness Trade-off: Revisiting the Channel Independent Strategy for Multivariate Time Series Forecasting,"Multivariate time series data comprises various channels of variables. The multivariate forecasting models need to capture the relationship between the channels to accurately predict future values. However, recently, there has been an emergence of methods that employ the Channel Independent (CI) strategy. These methods view multivariate time series data as separate univariate time series and disregard the correlation between channels. Surprisingly, our empirical results have shown that models trained with the CI strategy outperform those trained with the Channel Dependent (CD) strategy, usually by a significant margin. Nevertheless, the reasons behind this phenomenon have not yet been thoroughly explored in the literature. This paper provides comprehensive empirical and theoretical analyses of the characteristics of multivariate time series datasets and the CI/CD strategy. Our results conclude that the CD approach has higher capacity but often lacks robustness to accurately predict distributionally drifted time series. In contrast, the CI approach trades capacity for robust prediction. Practical measures inspired by these analyses are proposed to address the capacity and robustness dilemma, including a modified CD method called Predict Residuals with Regularization (PRReg) that can surpass the CI strategy. We hope our findings can raise awareness among researchers about the characteristics of multivariate time series and inspire the construction of better forecasting models.","<method>Channel Independent (CI) strategy</method>, <method>Channel Dependent (CD) strategy</method>, <method>Predict Residuals with Regularization (PRReg)</method>",No methods remaining
2024,https://openalex.org/W4391558635,Biology,Large Language Models are Few-Shot Summarizers: Multi-Intent Comment Generation via In-Context Learning,"Code comment generation aims at generating natural language descriptions for a code snippet to facilitate developers' program comprehension activities. Despite being studied for a long time, a bottleneck for existing approaches is that given a code snippet, they can only generate one comment while developers usually need to know information from diverse perspectives such as what is the functionality of this code snippet and how to use it. To tackle this limitation, this study empirically investigates the feasibility of utilizing large language models (LLMs) to generate comments that can fulfill developers' diverse intents. Our intuition is based on the facts that (1) the code and its pairwise comment are used during the pre-training process of LLMs to build the semantic connection between the natural language and programming language, and (2) comments in the real-world projects, which are collected for the pre-training, usually contain different developers' intents. We thus postulate that the LLMs can already understand the code from different perspectives after the pre-training. Indeed, experiments on two large-scale datasets demonstrate the rationale of our insights: by adopting the in-context learning paradigm and giving adequate prompts to the LLM (e.g., providing it with ten or more examples), the LLM can significantly outperform a state-of-the-art supervised learning approach on generating comments with multiple intents. Results also show that customized strategies for constructing the prompts and post-processing strategies for reranking the results can both boost the LLM's performances, which shed light on future research directions for using LLMs to achieve comment generation.","<method>large language models (LLMs)</method>, <method>in-context learning paradigm</method>, <method>supervised learning approach</method>",<method>in-context learning paradigm</method><method>supervised learning approach</method>
2024,https://openalex.org/W4390738897,Biology,Enhancing crop recommendation systems with explainable artificial intelligence: a study on agricultural decision-making,"Abstract Crop Recommendation Systems are invaluable tools for farmers, assisting them in making informed decisions about crop selection to optimize yields. These systems leverage a wealth of data, including soil characteristics, historical crop performance, and prevailing weather patterns, to provide personalized recommendations. In response to the growing demand for transparency and interpretability in agricultural decision-making, this study introduces XAI-CROP an innovative algorithm that harnesses eXplainable artificial intelligence (XAI) principles. The fundamental objective of XAI-CROP is to empower farmers with comprehensible insights into the recommendation process, surpassing the opaque nature of conventional machine learning models. The study rigorously compares XAI-CROP with prominent machine learning models, including Gradient Boosting (GB), Decision Tree (DT), Random Forest (RF), Gaussian Naïve Bayes (GNB), and Multimodal Naïve Bayes (MNB). Performance evaluation employs three essential metrics: Mean Squared Error (MSE), Mean Absolute Error (MAE), and R-squared (R2). The empirical results unequivocally establish the superior performance of XAI-CROP. It achieves an impressively low MSE of 0.9412, indicating highly accurate crop yield predictions. Moreover, with an MAE of 0.9874, XAI-CROP consistently maintains errors below the critical threshold of 1, reinforcing its reliability. The robust R 2 value of 0.94152 underscores XAI-CROP's ability to explain 94.15% of the data's variability, highlighting its interpretability and explanatory power.","<method>XAI-CROP</method>, <method>Gradient Boosting (GB)</method>, <method>Decision Tree (DT)</method>, <method>Random Forest (RF)</method>, <method>Gaussian Naïve Bayes (GNB)</method>, <method>Multimodal Naïve Bayes (MNB)</method>",<method>Gradient Boosting (GB)</method><method>Decision Tree (DT)</method><method>Random Forest (RF)</method><method>Gaussian Naïve Bayes (GNB)</method>
2024,https://openalex.org/W4391177783,Biology,"Making food systems more resilient to food safety risks by including artificial intelligence, big data, and internet of things into food safety early warning and emerging risk identification tools","Abstract To enhance the resilience of food systems to food safety risks, it is vitally important for national authorities and international organizations to be able to identify emerging food safety risks and to provide early warning signals in a timely manner. This review provides an overview of existing and experimental applications of artificial intelligence (AI), big data, and internet of things as part of early warning and emerging risk identification tools and methods in the food safety domain. There is an ongoing rapid development of systems fed by numerous, real‐time, and diverse data with the aim of early warning and identification of emerging food safety risks. The suitability of big data and AI to support such systems is illustrated by two cases in which climate change drives the emergence of risks, namely, harmful algal blooms affecting seafood and fungal growth and mycotoxin formation in crops. Automation and machine learning are crucial for the development of future real‐time food safety risk early warning systems. Although these developments increase the feasibility and effectiveness of prospective early warning and emerging risk identification tools, their implementation may prove challenging, particularly for low‐ and middle‐income countries due to low connectivity and data availability. It is advocated to overcome these challenges by improving the capability and capacity of national authorities, as well as by enhancing their collaboration with the private sector and international organizations.","<method>artificial intelligence (AI)</method>, <method>machine learning</method>",<method>machine learning</method>
2024,https://openalex.org/W4391783116,Biology,Assessing water quality of an ecologically critical urban canal incorporating machine learning approaches,"This study assessed water quality (WQ) in Tongi Canal, an ecologically critical and economically important urban canal in Bangladesh. The researchers employed the Root Mean Square Water Quality Index (RMS-WQI) model, utilizing seven WQ indicators, including temperature, dissolve oxygen, electrical conductivity, lead, cadmium, and iron to calculate the water quality index (WQI) score. The results showed that most of the water sampling locations showed poor WQ, with many indicators violating Bangladesh's environmental conservation regulations. This study employed eight machine learning algorithms, where the Gaussian process regression (GPR) model demonstrated superior performance (training RMSE = 1.77, testing RMSE = 0.0006) in predicting WQI scores. To validate the GPR model's performance, several performance measures, including the coefficient of determination (R2), the Nash-Sutcliffe efficiency (NSE), the model efficiency factor (MEF), Z statistics, and Taylor diagram analysis, were employed. The GPR model exhibited higher sensitivity (R2 = 1.0) and efficiency (NSE = 1.0, MEF = 0.0) in predicting WQ. The analysis of model uncertainty (standard uncertainty = 7.08 ± 0.9025; expanded uncertainty = 7.08 ± 1.846) indicates that the RMS-WQI model holds potential for assessing the WQ of inland waterbodies. These findings indicate that the RMS-WQI model could be an effective approach for assessing inland waters across Bangladesh. The study's results showed that most of the WQ indicators did not meet the recommended guidelines, indicating that the water in the Tongi Canal is unsafe and unsuitable for various purposes. The study's implications extend beyond the Tongi Canal and could contribute to WQ management initiatives across Bangladesh.",<method>Gaussian process regression (GPR)</method>,<method>Gaussian process regression (GPR)</method>
2024,https://openalex.org/W4400748541,Biology,Comparing YOLOv8 and Mask R-CNN for instance segmentation in complex orchard environments,"Instance segmentation, an important image processing operation for automation in agriculture, is used to precisely delineate individual objects of interest within images, which provides foundational information for various automated or robotic tasks such as selective harvesting and precision pruning. This study compares the one-stage YOLOv8 and the two-stage Mask R-CNN machine learning models for instance segmentation under varying orchard conditions across two datasets. Dataset 1, collected in dormant season, includes images of dormant apple trees, which were used to train multi-object segmentation models delineating tree branches and trunks. Dataset 2, collected in the early growing season, includes images of apple tree canopies with green foliage and immature (green) apples (also called fruitlet), which were used to train single-object segmentation models delineating only immature green apples. The results showed that YOLOv8 performed better than Mask R-CNN, achieving good precision and near-perfect recall across both datasets at a confidence threshold of 0.5. Specifically, for Dataset 1, YOLOv8 achieved a precision of 0.90 and a recall of 0.95 for all classes. In comparison, Mask R-CNN demonstrated a precision of 0.81 and a recall of 0.81 for the same dataset. With Dataset 2, YOLOv8 achieved a precision of 0.93 and a recall of 0.97. Mask R-CNN, in this single-class scenario, achieved a precision of 0.85 and a recall of 0.88. Additionally, the inference times for YOLOv8 were 10.9 ms for multi-class segmentation (Dataset 1) and 7.8 ms for single-class segmentation (Dataset 2), compared to 15.6 ms and 12.8 ms achieved by Mask R-CNN's, respectively. These findings show YOLOv8's superior accuracy and efficiency in machine learning applications compared to two-stage models, specifically Mask-R-CNN, which suggests its suitability in developing smart and automated orchard operations, particularly when real-time applications are necessary in such cases as robotic harvesting and robotic immature green fruit thinning.","<method>YOLOv8</method>, <method>Mask R-CNN</method>",<method>YOLOv8</method><method>Mask R-CNN</method>
2024,https://openalex.org/W4401691402,Biology,Optimal truss design with MOHO: A multi-objective optimization perspective,"This research article presents the Multi-Objective Hippopotamus Optimizer (MOHO), a unique approach that excels in tackling complex structural optimization problems. The Hippopotamus Optimizer (HO) is a novel approach in meta-heuristic methodology that draws inspiration from the natural behaviour of hippos. The HO is built upon a trinary-phase model that incorporates mathematical representations of crucial aspects of Hippo's behaviour, including their movements in aquatic environments, defense mechanisms against predators, and avoidance strategies. This conceptual framework forms the basis for developing the multi-objective (MO) variant MOHO, which was applied to optimize five well-known truss structures. Balancing safety precautions and size constraints concerning stresses on individual sections and constituent parts, these problems also involved competing objectives, such as reducing the weight of the structure and the maximum nodal displacement. The findings of six popular optimization methods were used to compare the results. Four industry-standard performance measures were used for this comparison and qualitative examination of the finest Pareto-front plots generated by each algorithm. The average values obtained by the Friedman rank test and comparison analysis unequivocally showed that MOHO outperformed other methods in resolving significant structure optimization problems quickly. In addition to finding and preserving more Pareto-optimal sets, the recommended algorithm produced excellent convergence and variance in the objective and decision fields. MOHO demonstrated its potential for navigating competing objectives through diversity analysis. Additionally, the swarm plots effectively visualize MOHO's solution distribution of MOHO across iterations, highlighting its superior convergence behaviour. Consequently, MOHO exhibits promise as a valuable method for tackling complex multi-objective structure optimization issues.","<method>Multi-Objective Hippopotamus Optimizer (MOHO)</method>, <method>Hippopotamus Optimizer (HO)</method>",No methods remaining
2024,https://openalex.org/W4390659289,Biology,Cognition-Driven Structural Prior for Instance-Dependent Label Transition Matrix Estimation,"The label transition matrix has emerged as a widely accepted method for mitigating label noise in machine learning. In recent years, numerous studies have centered on leveraging deep neural networks to estimate the label transition matrix for individual instances within the context of instance-dependent noise. However, these methods suffer from low search efficiency due to the large space of feasible solutions. Behind this drawback, we have explored that the real murderer lies in the invalid class transitions, that is, the actual transition probability between certain classes is zero but is estimated to have a certain value. To mask the <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">invalid class transitions</i> , we introduced a human-cognition-assisted method with structural information from human cognition. Specifically, we introduce a structured transition matrix network ( <bold xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">STMN</b> ) designed with an adversarial learning process to balance instance features and prior information from human cognition. The proposed method offers two advantages: 1) better estimation effectiveness is obtained by sparing the transition matrix and 2) better estimation accuracy is obtained with the assistance of human cognition. By exploiting these two advantages, our method parametrically estimates a sparse label transition matrix, effectively converting noisy labels into true labels. The efficiency and superiority of our proposed method are substantiated through comprehensive comparisons with state-of-the-art methods on three synthetic datasets and a real-world dataset. Our code will be available at https://github.com/WheatCao/STMN-Pytorch.","<method>label transition matrix</method>, <method>deep neural networks</method>, <method>structured transition matrix network (STMN)</method>, <method>adversarial learning process</method>",<method>deep neural networks</method><method>adversarial learning process</method>
2024,https://openalex.org/W4392980686,Biology,Data-driven evolution of water quality models: An in-depth investigation of innovative outlier detection approaches-A case study of Irish Water Quality Index (IEWQI) model,"Recently, there has been a significant advancement in the water quality index (WQI) models utilizing data-driven approaches, especially those integrating machine learning and artificial intelligence (ML/AI) technology. Although, several recent studies have revealed that the data-driven model has produced inconsistent results due to the data outliers, which significantly impact model reliability and accuracy. The present study was carried out to assess the impact of data outliers on a recently developed Irish Water Quality Index (IEWQI) model, which relies on data-driven techniques. To the author's best knowledge, there has been no systematic framework for evaluating the influence of data outliers on such models. For the purposes of assessing the outlier impact of the data outliers on the water quality (WQ) model, this was the first initiative in research to introduce a comprehensive approach that combines machine learning with advanced statistical techniques. The proposed framework was implemented in Cork Harbour, Ireland, to evaluate the IEWQI model's sensitivity to outliers in input indicators to assess the water quality. In order to detect the data outlier, the study utilized two widely used ML techniques, including Isolation Forest (IF) and Kernel Density Estimation (KDE) within the dataset, for predicting WQ with and without these outliers. For validating the ML results, the study used five commonly used statistical measures. The performance metric (R2) indicates that the model performance improved slightly (R2 increased from 0.92 to 0.95) in predicting WQ after removing the data outlier from the input. But the IEWQI scores revealed that there were no statistically significant differences among the actual values, predictions with outliers, and predictions without outliers, with a 95% confidence interval at p < 0.05. The results of model uncertainty also revealed that the model contributed <1% uncertainty to the final assessment results for using both datasets (with and without outliers). In addition, all statistical measures indicated that the ML techniques provided reliable results that can be utilized for detecting outliers and their impacts on the IEWQI model. The findings of the research reveal that although the data outliers had no significant impact on the IEWQI model architecture, they had moderate impacts on the rating schemes' of the model. This finding indicated that detecting the data outliers could improve the accuracy of the IEWQI model in rating WQ as well as be helpful in mitigating the model eclipsing problem. In addition, the results of the research provide evidence of how the data outliers influenced the data-driven model in predicting WQ and reliability, particularly since the study confirmed that the IEWQI model's could be effective for accurately rating WQ despite the presence of the data outliers in the input. It could occur due to the spatio-temporal variability inherent in WQ indicators. However, the research assesses the influence of data input outliers on the IEWQI model and underscores important areas for future investigation. These areas include expanding temporal analysis using multi-year data, examining spatial outlier patterns, and evaluating detection methods. Moreover, it is essential to explore the real-world impacts of revised rating categories, involve stakeholders in outlier management, and fine-tune model parameters. Analysing model performance across varying temporal and spatial resolutions and incorporating additional environmental data can significantly enhance the accuracy of WQ assessment. Consequently, this study offers valuable insights to strengthen the IEWQI model's robustness and provides avenues for enhancing its utility in broader WQ assessment applications. Moreover, the study successfully adopted the framework for evaluating how data input outliers affect the data-driven model, such as the IEWQI model. The current study has been carried out in Cork Harbour for only a single year of WQ data. The framework should be tested across various domains for evaluating the response of the IEWQI model's in terms of the spatio-temporal resolution of the domain. Nevertheless, the study recommended that future research should be conducted to adjust or revise the IEWQI model's rating schemes and investigate the practical effects of data outliers on updated rating categories. However, the study provides potential recommendations for enhancing the IEWQI model's adaptability and reveals its effectiveness in expanding its applicability in more general WQ assessment scenarios.","<method>Isolation Forest (IF)</method>, <method>Kernel Density Estimation (KDE)</method>",<method>Isolation Forest (IF)</method>
2024,https://openalex.org/W4396707011,Biology,DeepAVP-TPPred: identification of antiviral peptides using transformed image-based localized descriptors and binary tree growth algorithm,"Abstract Motivation Despite the extensive manufacturing of antiviral drugs and vaccination, viral infections continue to be a major human ailment. Antiviral peptides (AVPs) have emerged as potential candidates in the pursuit of novel antiviral drugs. These peptides show vigorous antiviral activity against a diverse range of viruses by targeting different phases of the viral life cycle. Therefore, the accurate prediction of AVPs is an essential yet challenging task. Lately, many machine learning-based approaches have developed for this purpose; however, their limited capabilities in terms of feature engineering, accuracy, and generalization make these methods restricted. Results In the present study, we aim to develop an efficient machine learning-based approach for the identification of AVPs, referred to as DeepAVP-TPPred, to address the aforementioned problems. First, we extract two new transformed feature sets using our designed image-based feature extraction algorithms and integrate them with an evolutionary information-based feature. Next, these feature sets were optimized using a novel feature selection approach called binary tree growth Algorithm. Finally, the optimal feature space from the training dataset was fed to the deep neural network to build the final classification model. The proposed model DeepAVP-TPPred was tested using stringent 5-fold cross-validation and two independent dataset testing methods, which achieved the maximum performance and showed enhanced efficiency over existing predictors in terms of both accuracy and generalization capabilities. Availability and implementation https://github.com/MateeullahKhan/DeepAVP-TPPred.","<method>machine learning-based approaches</method>, <method>image-based feature extraction algorithms</method>, <method>binary tree growth Algorithm</method>, <method>deep neural network</method>",<method>deep neural network</method>
2024,https://openalex.org/W4391235397,Biology,Real-Time Plant Disease Dataset Development and Detection of Plant Disease Using Deep Learning,"Agriculture plays a significant role in meeting food needs and providing food security for the increasingly growing global population, which has increased by 0.88% since 2022. Plant diseases can reduce food production and affect food security. Worldwide crop loss due to plant disease is estimated to be around 14.1%. The lack of proper identification of plant disease at the early stages of infection can result in inappropriate disease control measures. Therefore, the automatic identification and diagnosis of plant diseases are highly recommended. Lack of availability of large amounts of data that are not processed to a large extent is one of the main challenges in plant disease diagnosis. In the current manuscript, we developed datasets for food grains specifically for rice, wheat, and maize to address the identified challenges. The developed datasets consider the common diseases (two bacterial diseases and two fungal diseases of rice, four fungal diseases of maize, and four fungal diseases of wheat) that affect crop yields and cause damage to the whole plant. The datasets developed were applied to eight fine-tuned deep learning models with the same training hyperparameters. The experimental results based on eight fine-tuned deep learning models show that, while recognizing maize leaf diseases, the models Xception and MobileNet performed best with a testing accuracy of 0.9580 and 0.9464 respectively. Similarly, while recognizing the wheat leaf diseases, the models MobileNetV2 and MobileNet performed best with a testing accuracy of 0.9632 and 0.9628 respectively. The Xception and Inception V3 models performed best, with a testing accuracy of 0.9728 and 0.9620, respectively, for recognizing rice leaf diseases. The research also proposes a new convolutional neural network (CNN) model trained from scratch on all three food grain datasets developed. The proposed model performs well and shows a testing accuracy of 0.9704, 0.9706, and 0.9808 respectively on the maize, rice, and wheat datasets.","<method>fine-tuned deep learning models</method>, <method>Xception</method>, <method>MobileNet</method>, <method>MobileNetV2</method>, <method>Inception V3</method>, <method>convolutional neural network (CNN) model trained from scratch</method>",<method>fine-tuned deep learning models</method><method>Xception</method><method>MobileNet</method><method>MobileNetV2</method><method>Inception V3</method><method>convolutional neural network (CNN) model trained from scratch</method>
2024,https://openalex.org/W4396494945,Biology,Vision–language foundation model for echocardiogram interpretation,"Abstract The development of robust artificial intelligence models for echocardiography has been limited by the availability of annotated clinical data. Here, to address this challenge and improve the performance of cardiac imaging models, we developed EchoCLIP, a vision–language foundation model for echocardiography, that learns the relationship between cardiac ultrasound images and the interpretations of expert cardiologists across a wide range of patients and indications for imaging. After training on 1,032,975 cardiac ultrasound videos and corresponding expert text, EchoCLIP performs well on a diverse range of benchmarks for cardiac image interpretation, despite not having been explicitly trained for individual interpretation tasks. EchoCLIP can assess cardiac function (mean absolute error of 7.1% when predicting left ventricular ejection fraction in an external validation dataset) and identify implanted intracardiac devices (area under the curve (AUC) of 0.84, 0.92 and 0.97 for pacemakers, percutaneous mitral valve repair and artificial aortic valves, respectively). We also developed a long-context variant (EchoCLIP-R) using a custom tokenizer based on common echocardiography concepts. EchoCLIP-R accurately identified unique patients across multiple videos (AUC of 0.86), identified clinical transitions such as heart transplants (AUC of 0.79) and cardiac surgery (AUC 0.77) and enabled robust image-to-text search (mean cross-modal retrieval rank in the top 1% of candidate text reports). These capabilities represent a substantial step toward understanding and applying foundation models in cardiovascular imaging for preliminary interpretation of echocardiographic findings.","<method>vision–language foundation model</method>, <method>EchoCLIP</method>, <method>EchoCLIP-R</method>, <method>custom tokenizer</method>",<method>vision–language foundation model</method>
2024,https://openalex.org/W4398780590,Biology,Greater cane rat algorithm (GCRA): A nature-inspired metaheuristic for optimization problems,"This paper introduces a new metaheuristic technique known as the Greater Cane Rat Algorithm (GCRA) for addressing optimization problems. The optimization process of GCRA is inspired by the intelligent foraging behaviors of greater cane rats during and off mating season. Being highly nocturnal, they are intelligible enough to leave trails as they forage through reeds and grass. Such trails would subsequently lead to food and water sources and shelter. The exploration phase is achieved when they leave the different shelters scattered around their territory to forage and leave trails. It is presumed that the alpha male maintains knowledge about these routes, and as a result, other rats modify their location according to this information. Also, the males are aware of the breeding season and separate themselves from the group. The assumption is that once the group is separated during this season, the foraging activities are concentrated within areas of abundant food sources, which aids the exploitation. Hence, the smart foraging paths and behaviors during the mating season are mathematically represented to realize the design of the GCR algorithm and carry out the optimization tasks. The performance of GCRA is tested using twenty-two classical benchmark functions, ten CEC 2020 complex functions, and the CEC 2011 real-world continuous benchmark problems. To further test the performance of the proposed algorithm, six classic problems in the engineering domain were used. Furthermore, a thorough analysis of computational and convergence results is presented to shed light on the efficacy and stability levels of GCRA. The statistical significance of the results is compared with ten state-of-the-art algorithms using Friedman's and Wilcoxon's signed rank tests. These findings show that GCRA produced optimal or nearly optimal solutions and evaded the trap of local minima, distinguishing it from the rival optimization algorithms employed to tackle similar problems. The GCRA optimizer source code is publicly available at: https://www.mathworks.com/matlabcentral/fileexchange/165241-greater-cane-rat-algorithm-gcra",<method>Greater Cane Rat Algorithm (GCRA)</method>,No methods remaining
2024,https://openalex.org/W4391089359,Biology,Groundwater level prediction using an improved SVR model integrated with hybrid particle swarm optimization and firefly algorithm,"The demand for water resources has increased due to rapid increase of metropolitan areas brought on by growth in population and industrialisation. In addition, the groundwater recharge is being afftected by shifting land use pattern caused by urban development. Using precise and trustworthy estimates of groundwater level is vital for the sustainable groundwater resources management in the face of changing climatic circumstances. In this context, machine learning (ML) methods offer a new and promising approach for accurately forecasting long-term changes in the groundwater level (GWL) without computational effort of developing a comprehensive flow model. In order to simulate GWL, five data-driven (DD) models, including the hybridization of support vector regression (SVR) with two optimisation algorithms i.e., firefly algorithm and particle swarm optimisation (FFAPSO), SVR-FFA, SVR-PSO, SVR and Multilayer perception (MLP), have been examined in the present study. Spatial clustering was utilised to choose four observation wells within Cuttack district in order to study and assess the water levels. Six scenarios were created by incorporating numerous variables, such as GWL in the previous months, evapotranspiration, temperature, precipitation, and river discharge. The goal was to identify the variables that were most efficient in predicting GWL. The SVR-FFAPSO model performs best in GWL forecasting for Khuntuni station, according to the quantitative analysis with correlation coefficient (R) = 0.9978, Nash–Sutcliffe efficiency (NSE) = 0.9933, mean absolute error (MAE) = 0.00025 (m), root mean squared error (RMSE) = 0.00775 (m) during the training phase. It is advised that groundwater monitoring network and data collecting system are strengthen in India for ensuring effective modelling of long-term management of groundwater resources.","<method>support vector regression (SVR)</method>, <method>firefly algorithm</method>, <method>particle swarm optimisation (PSO)</method>, <method>SVR-FFA</method>, <method>SVR-PSO</method>, <method>Multilayer perception (MLP)</method>",<method>support vector regression (SVR)</method><method>firefly algorithm</method><method>SVR-PSO</method>
2024,https://openalex.org/W4391145008,Biology,Assessing ChatGPT’s Mastery of Bloom’s Taxonomy Using Psychosomatic Medicine Exam Questions: Mixed-Methods Study,"Background Large language models such as GPT-4 (Generative Pre-trained Transformer 4) are being increasingly used in medicine and medical education. However, these models are prone to “hallucinations” (ie, outputs that seem convincing while being factually incorrect). It is currently unknown how these errors by large language models relate to the different cognitive levels defined in Bloom’s taxonomy. Objective This study aims to explore how GPT-4 performs in terms of Bloom’s taxonomy using psychosomatic medicine exam questions. Methods We used a large data set of psychosomatic medicine multiple-choice questions (N=307) with real-world results derived from medical school exams. GPT-4 answered the multiple-choice questions using 2 distinct prompt versions: detailed and short. The answers were analyzed using a quantitative approach and a qualitative approach. Focusing on incorrectly answered questions, we categorized reasoning errors according to the hierarchical framework of Bloom’s taxonomy. Results GPT-4’s performance in answering exam questions yielded a high success rate: 93% (284/307) for the detailed prompt and 91% (278/307) for the short prompt. Questions answered correctly by GPT-4 had a statistically significant higher difficulty than questions answered incorrectly (P=.002 for the detailed prompt and P&lt;.001 for the short prompt). Independent of the prompt, GPT-4’s lowest exam performance was 78.9% (15/19), thereby always surpassing the “pass” threshold. Our qualitative analysis of incorrect answers, based on Bloom’s taxonomy, showed that errors were primarily in the “remember” (29/68) and “understand” (23/68) cognitive levels; specific issues arose in recalling details, understanding conceptual relationships, and adhering to standardized guidelines. Conclusions GPT-4 demonstrated a remarkable success rate when confronted with psychosomatic medicine multiple-choice exam questions, aligning with previous findings. When evaluated through Bloom’s taxonomy, our data revealed that GPT-4 occasionally ignored specific facts (remember), provided illogical reasoning (understand), or failed to apply concepts to a new situation (apply). These errors, which were confidently presented, could be attributed to inherent model biases and the tendency to generate outputs that maximize likelihood.","<method>large language models</method>, <method>GPT-4 (Generative Pre-trained Transformer 4)</method>",<method>GPT-4 (Generative Pre-trained Transformer 4)</method>
2024,https://openalex.org/W4391855187,Biology,Machine learning-assisted in-situ adaptive strategies for the control of defects and anomalies in metal additive manufacturing,"In metal additive manufacturing (AM), the material microstructure and part geometry are formed incrementally. Consequently, the resulting part could be defect- and anomaly-free if sufficient care is taken to deposit each layer under optimal process conditions. Conventional closed-loop control (CLC) engineering solutions which sought to achieve this were deterministic and rule-based, thus resulting in limited success in the stochastic environment experienced in the highly dynamic AM process. On the other hand, emerging machine learning (ML) based strategies are better suited to providing the robustness, scope, flexibility, and scalability required for process control in an uncertain environment. Offline ML models that help optimise AM process parameters before a build begins and online ML models that efficiently processed in-situ sensory data to detect and diagnose flaws in real-time (or near-real-time) have been developed. However, ML models that enable a process to take evasive or corrective actions in relation to flaws via on the fly decision-making are only emerging. These models must possess prognostic capabilities to provide context-sensitive recommendations for in-situ process control based on real-time diagnostics. In this article, we pinpoint the shortcomings in traditional CLC strategies, and provide a framework for defect and anomaly control through ML-assisted CLC in AM. We discuss flaws in terms of their causes, in-situ detectability, and controllability, and examine their management under three scenarios: avoidance, mitigation, and repair. Then, we summarise the research into ML models developed for offline optimisation and in-situ diagnosis before initiating a detailed conversation on the implementation of ML-assisted in-situ process control. We found that researchers favoured reinforcement learning approaches or inverse ML models for making rapid, situation-aware control decisions. We also observed that, to-date, the defects addressed were those that may be quantified relatively easily autonomously, and that mitigation (rather than avoidance or repair) was the aim of ML-assisted in-situ control strategies. Additionally, we highlight the various technologies that must seamlessly combine to advance the field of autonomous in-situ control so that it becomes a reality in industrial settings. Finally, we raise awareness of seldom discussed, yet highly pertinent, topics relevant to adaptive control. Our work closes a significant gap in the current AM literature by broaching wide-ranging discussions on matters relevant to in-situ adaptive control in AM.","<method>machine learning (ML) based strategies</method>, <method>offline ML models</method>, <method>online ML models</method>, <method>reinforcement learning approaches</method>, <method>inverse ML models</method>",<method>online ML models</method><method>reinforcement learning approaches</method>
2024,https://openalex.org/W4392640075,Biology,Performance assessment of machine learning algorithms for mapping of land use/land cover using remote sensing data,"The rapid increase in population accelerates the rate of change of Land use/Land cover (LULC) in various parts of the world. This phenomenon caused a huge strain for natural resources. Hence, continues monitoring of LULC changes gained a significant importance for management of natural resources and assessing the climate change impacts. Recently, application of machine learning algorithms on RS (remote sensing) data for rapid and accurate mapping of LULC gained significant importance due to growing need of LULC estimation for ecosystem services, natural resource management and environmental management. Hence, it is crucial to access and compare the performance of different machine learning classifiers for accurate mapping of LULC. The primary objective of this study was to compare the performance of CART (Classification and Regression Tree), RF (Random Forest) and SVM (Support Vector Machine) for LULC estimation by processing RS data on Google Earth Engine (GEE). In total four classes of LULC (Water Bodies, Vegetation Cover, Urban Land and Barren Land) for city of Lahore were extracted using satellite images from Landsat-7, Landsat-8 and Landsat-9 for years 2008, 2015 and 2022, respectively. According to results, RF is the best performing classifier with maximum overall accuracy of 95.2% and highest Kappa coefficient value of 0.87, SVM achieved maximum accuracy of 89.8% with highest Kappa of 0.84 and CART showed maximum overall accuracy of 89.7% with Kappa value of 0.79. Results from this study can give assistance for decision makers, planners and RS experts to choose a suitable machine learning algorithm for LULC classification in an unplanned urbanized city like Lahore.","<method>Classification and Regression Tree (CART)</method>, <method>Random Forest (RF)</method>, <method>Support Vector Machine (SVM)</method>",<method>Classification and Regression Tree (CART)</method><method>Random Forest (RF)</method><method>Support Vector Machine (SVM)</method>
2024,https://openalex.org/W4390480832,Biology,Joint Optimization Risk Factor and Energy Consumption in IoT Networks With TinyML-Enabled Internet of UAVs,"The high mobility of Internet of Unmanned Aerial Vehicles (IUAVs) has attracted attention in the field of data collection. With the rapid development of the Internet of Things (IoT), more and more data are generated by IoT networks. IUAV-aided IoT networks can efficiently collect data in specific areas, which is of great significance in disaster relief. In the data collection task, it is necessary to plan the flight trajectory for the data collector—IUAV, so that the IUAV can collect data efficiently. However, existing research basically only considers the efficiency of data collection by IUAVs, but rarely considers the safety of IUAVs during flight. Therefore, this paper proposes an IUAV trajectory planning algorithm that integrates energy efficiency and safety using local search to address the issues mentioned above. At the same time, a Tiny Machine Learning (TinyML) algorithm is designed to assist the IUAV in making real-time decisions during flight. First, we build a general mathematical model that describes the risk in a particular region. Then consider guiding the IUAV to a safer trajectory by introducing virtual nodes in the flight trajectory. Furthermore, we designed a local search algorithm for the three tasks of IUAV access sequence, IoT Networks cluster heads selection and virtual nodes selection, and solved them through iterative optimization. We also consider the unreachable situation of the virtual nodes and use TinyML technology to help the IUAV adjust the position of the virtual nodes in real time in case of an emergency.In the end, an IUAV trajectory is obtained that can efficiently collect IoT networks' data and fly safely. We have conducted a large number of simulation experiments to demonstrate the efficiency of the proposed algorithm compared to the baseline algorithm.","<method>Tiny Machine Learning (TinyML)</method>, <method>local search algorithm</method>",<method>Tiny Machine Learning (TinyML)</method>
2024,https://openalex.org/W4390754233,Biology,Groundwater Quality Assessment and Irrigation Water Quality Index Prediction Using Machine Learning Algorithms,"The evaluation of groundwater quality is crucial for irrigation purposes; however, due to financial constraints in developing countries, such evaluations suffer from insufficient sampling frequency, hindering comprehensive assessments. Therefore, associated with machine learning approaches and the irrigation water quality index (IWQI), this research aims to evaluate the groundwater quality in Naama, a region in southwest Algeria. Hydrochemical parameters (cations, anions, pH, and EC), qualitative indices (SAR,RSC,Na%,MH,and PI), as well as geospatial representations were used to determine the groundwater’s suitability for irrigation in the study area. In addition, efficient machine learning approaches for forecasting IWQI utilizing Extreme Gradient Boosting (XGBoost), Support vector regression (SVR), and K-Nearest Neighbours (KNN) models were implemented. In this research, 166 groundwater samples were used to calculate the irrigation index. The results showed that 42.18% of them were of excellent quality, 34.34% were of very good quality, 6.63% were good quality, 9.64% were satisfactory, and 4.21% were considered unsuitable for irrigation. On the other hand, results indicate that XGBoost excels in accuracy and stability, with a low RMSE (of 2.8272 and a high R of 0.9834. SVR with only four inputs (Ca2+, Mg2+, Na+, and K) demonstrates a notable predictive capability with a low RMSE of 2.6925 and a high R of 0.98738, while KNN showcases robust performance. The distinctions between these models have important implications for making informed decisions in agricultural water management and resource allocation within the region.","<method>Extreme Gradient Boosting (XGBoost)</method>, <method>Support Vector Regression (SVR)</method>, <method>K-Nearest Neighbours (KNN)</method>",<method>Extreme Gradient Boosting (XGBoost)</method><method>Support Vector Regression (SVR)</method><method>K-Nearest Neighbours (KNN)</method>
2024,https://openalex.org/W4391347933,Biology,CCL-DTI: contributing the contrastive loss in drug–target interaction prediction,"Abstract Background The Drug–Target Interaction (DTI) prediction uses a drug molecule and a protein sequence as inputs to predict the binding affinity value. In recent years, deep learning-based models have gotten more attention. These methods have two modules: the feature extraction module and the task prediction module. In most deep learning-based approaches, a simple task prediction loss (i.e., categorical cross entropy for the classification task and mean squared error for the regression task) is used to learn the model. In machine learning, contrastive-based loss functions are developed to learn more discriminative feature space. In a deep learning-based model, extracting more discriminative feature space leads to performance improvement for the task prediction module. Results In this paper, we have used multimodal knowledge as input and proposed an attention-based fusion technique to combine this knowledge. Also, we investigate how utilizing contrastive loss function along the task prediction loss could help the approach to learn a more powerful model. Four contrastive loss functions are considered: (1) max-margin contrastive loss function, (2) triplet loss function, (3) Multi-class N-pair Loss Objective, and (4) NT-Xent loss function. The proposed model is evaluated using four well-known datasets: Wang et al. dataset, Luo's dataset, Davis, and KIBA datasets. Conclusions Accordingly, after reviewing the state-of-the-art methods, we developed a multimodal feature extraction network by combining protein sequences and drug molecules, along with protein–protein interaction networks and drug–drug interaction networks. The results show it performs significantly better than the comparable state-of-the-art approaches.","<method>deep learning-based models</method>, <method>attention-based fusion technique</method>, <method>contrastive loss function</method>, <method>max-margin contrastive loss function</method>, <method>triplet loss function</method>, <method>Multi-class N-pair Loss Objective</method>, <method>NT-Xent loss function</method>, <method>multimodal feature extraction network</method>",<method>contrastive loss function</method><method>max-margin contrastive loss function</method><method>triplet loss function</method><method>Multi-class N-pair Loss Objective</method><method>NT-Xent loss function</method>
2024,https://openalex.org/W4391248672,Biology,Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning,"Recent development in computing power has resulted in performance improvements on holistic(none-occluded) person Re-Identification (ReID) tasks. Nevertheless, the precision of the recent research will diminish when a pedestrian is obstructed by obstacles. Within the realm of 2D space, the loss of information from obstructed objects continues to pose significant challenges in the context of person ReID. Person is a 3D non-grid object, and thus semantic representation learning in only 2D space limits the understanding of occluded person. In the present work, we propose a network based on 3D multi-view learning, allowing it to acquire geometric and shape details of an occluded pedestrian from 3D space. Simultaneously, it capitalizes on advancements in 2D-based networks to extract semantic representations from 3D multi-views. Specifically, the surface random selection strategy is proposed to convert images of 2D RGB into 3D multi-views. Using this strategy, we build four extensive 3D multi-view data collections for person ReID. After that, Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning(MV-3DSReID), is proposed for identifying the person by learning person geometry and structure representation from the groups of multi-view images. In comparison to alternative data formats (e.g., 2D RGB, 3D point cloud), multi-view images complement each other's detailed features of the 3D object by adjusting rendering viewpoints, thus facilitating a more comprehensive understanding of the person for both holistic and occluded ReID situations. Experiments on occluded and holistic ReID tasks demonstrate performance levels comparable to state-of-the-art methods, validating the effectiveness of our proposed approach in tackling challenges related to occlusion. The code is available at https://github.com/hangjiaqi1/MV-TransReID.","<method>3D multi-view learning</method>, <method>2D-based networks</method>, <method>surface random selection strategy</method>, <method>Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning (MV-3DSReID)</method>",<method>3D multi-view learning</method>
2024,https://openalex.org/W4394685122,Biology,Sequence Training and Data Shuffling to Enhance the Accuracy of Recurrent Neural Network Based Battery Voltage Models,"&lt;div class=""section abstract""&gt;&lt;div class=""htmlview paragraph""&gt;Battery terminal voltage modelling is crucial for various applications, including electric vehicles, renewable energy systems, and portable electronics. Terminal voltage models are used to determine how a battery will respond under load and can be used to calculate run-time, power capability, and heat generation and as a component of state estimation approaches, such as for state of charge. Previous studies have shown better voltage modelling accuracy for long short-term memory (LSTM) recurrent neural networks than other traditional methods (e.g., equivalent circuit and electrochemical models). This study presents two new approaches – sequence training and data shuffling – to improve LSTM battery voltage models further, making them an even better candidate for the high-accuracy modelling of lithium-ion batteries. Because the LSTM memory captures information from past time steps, it must typically be trained using one series of continuous data. Instead, the proposed sequence training approach feeds a fixed window of prior data (e.g., 100 seconds) into the LSTM at each time step to initialize the memory states properly and then only uses the output at the current time step. With this method, the LSTM just requires the prior data window to be continuous, thereby allowing the handling of discontinuities. This also means that during the training process, the data can be shuffled randomly, enabling mini-batches to speed up the training significantly. When these approaches were applied, LSTM voltage estimation error was reduced by 22%, from 28.5 mV to 22.3 mV RMS error over four drive cycles and temperatures from -20 to 25°C.&lt;/div&gt;&lt;/div&gt;","<method>long short-term memory (LSTM) recurrent neural networks</method>, <method>sequence training</method>, <method>data shuffling</method>",<method>long short-term memory (LSTM) recurrent neural networks</method><method>sequence training</method>
2024,https://openalex.org/W4401844424,Biology,AlphaFold predictions of fold-switched conformations are driven by structure memorization,"Abstract Recent work suggests that AlphaFold (AF)–a deep learning-based model that can accurately infer protein structure from sequence–may discern important features of folded protein energy landscapes, defined by the diversity and frequency of different conformations in the folded state. Here, we test the limits of its predictive power on fold-switching proteins, which assume two structures with regions of distinct secondary and/or tertiary structure. We find that (1) AF is a weak predictor of fold switching and (2) some of its successes result from memorization of training-set structures rather than learned protein energetics. Combining &gt;280,000 models from several implementations of AF2 and AF3, a 35% success rate was achieved for fold switchers likely in AF’s training sets. AF2’s confidence metrics selected against models consistent with experimentally determined fold-switching structures and failed to discriminate between low and high energy conformations. Further, AF captured only one out of seven experimentally confirmed fold switchers outside of its training sets despite extensive sampling of an additional ~280,000 models. Several observations indicate that AF2 has memorized structural information during training, and AF3 misassigns coevolutionary restraints. These limitations constrain the scope of successful predictions, highlighting the need for physically based methods that readily predict multiple protein conformations.","<method>AlphaFold (AF)</method>, <method>AF2</method>, <method>AF3</method>",<method>AlphaFold (AF)</method><method>AF2</method>
2024,https://openalex.org/W4391482136,Biology,A comprehensive analysis of the emerging modern trends in research on photovoltaic systems and desalination in the era of artificial intelligence and machine learning,"Integration of photovoltaic (PV) systems, desalination technologies, and Artificial Intelligence (AI) combined with Machine Learning (ML) has introduced a new era of remarkable research and innovation. This review article thoroughly examines the recent advancements in the field, focusing on the interplay between PV systems and water desalination within the framework of AI and ML applications, along with it analyses current research to identify significant patterns, obstacles, and prospects in this interdisciplinary field. Furthermore, review examines the incorporation of AI and ML methods in improving the performance of PV systems. This includes raising their efficiency, implementing predictive maintenance strategies, and enabling real-time monitoring. It also explores the transformative influence of intelligent algorithms on desalination techniques, specifically addressing concerns pertaining to energy usage, scalability, and environmental sustainability. This article provides a thorough analysis of the current literature, identifying areas where research is lacking and suggesting potential future avenues for investigation. These advancements have resulted in increased efficiency, decreased expenses, and improved sustainability of PV system. By utilizing artificial intelligence technologies, freshwater productivity can increase by 10 % and efficiency. This review offers significant and informative perspectives for researchers, engineers, and policymakers involved in renewable energy and water technology. It sheds light on the latest advancements in photovoltaic systems and desalination, which are facilitated by AI and ML. The review aims to guide towards a more sustainable and technologically advanced future.","<method>Artificial Intelligence (AI)</method>, <method>Machine Learning (ML)</method>, <method>predictive maintenance strategies</method>, <method>intelligent algorithms</method>",<method>Machine Learning (ML)</method>
2024,https://openalex.org/W4392077419,Biology,Selection of sustainable food suppliers using the Pythagorean fuzzy CRITIC-MARCOS method,"Sustainable food supplier selection (SFSS) can be handled as an uncertain decision-making issue. The Pythagorean fuzzy set (PFS), a type of non-standard fuzzy set, offers an expanded description space for articulating fuzzy and uncertain data. Accordingly, this paper proposes a Pythagorean fuzzy synthetic decision method-based selection framework for solving the SFSS problem within a subjective context. Then, the weighted distance measures for the PFS are introduced to derive the importance degrees of the experts, which can provide a more objective decision result. Then, an information fusion method with a PFS-weighted power average (WPA) operator is introduced to form a group decision matrix competent to accommodate the deviation effect. Next, an extended PF-measurement of alternatives and ranking according to compromise solution (MARCOS) method integrating PF-criteria importance through inter-criteria correlation (CRITIC) is presented to calculate the priority of each supplier, which can capture the inter-correlations between criteria. Finally, a numerical example of SFSS is implemented to show the application of the proposed synthetic decision approach. Subsequently, the sensitivity analysis of distance parameters and comparison analysis among different SFSS approaches were conducted to test the rationality and advantages of the proposed framework for resolving the SFSS problem. The results show that the reported method can provide a practical way to resolve the SFSS problems with uncertain data.","<method>Pythagorean fuzzy synthetic decision method</method>, <method>weighted distance measures for the Pythagorean fuzzy set (PFS)</method>, <method>information fusion method with a PFS-weighted power average (WPA) operator</method>, <method>extended PF-measurement of alternatives and ranking according to compromise solution (MARCOS) method integrating PF-criteria importance through inter-criteria correlation (CRITIC)</method>",No methods remaining
2024,https://openalex.org/W4391796054,Biology,Optical remote sensing of crop biophysical and biochemical parameters: An overview of advances in sensor technologies and machine learning algorithms for precision agriculture,"This paper provides an overview of the recent developments in remote sensing technology and machine learning algorithms for estimating important biophysical and biochemical parameters for precision farming. The objectives are (i) to provide an overview of recent advances in remotely sensed retrieval of biophysical and biochemical parameters brought by the developments in sensor technologies and robust machine learning algorithms and (ii) to identify the sources of uncertainty in retrieving biophysical and biochemical parameters and implications for precision agriculture. The review revealed that developments in crop biophysical and biochemical parameters retrieval techniques were mainly driven by announcements and the availability of new sensors. Two ground-breaking events can be identified, i.e., the availability of Sentinel-2 and the SuperDove constellation. The two provide high temporal-high spatial resolution data relevant for site-specific management and super-spectral configuration, enabling retrieval of crop growth and health parameters. The free availability of Sentinel-2 triggered the testing of its spectral configurations and upscaling of retrieval approaches using simulated data from field spectrometers and airborne hyperspectral sensors. SuperDoves will likely reduce the cost of very high-resolution data while providing unprecedented capabilities for detailed, accurate and frequent characterisation of field variability. Studies showed that the red-edge bands and hybrid models coupling Radiative Transfer Model (RTM) and machine learning regression algorithms (MLRA) are promising for operational and accurate monitoring of stress-related crop parameters to aid time-sensitive agronomic decisions. However, such models were tested in Mediterranean climates and performed poorly in African semi-arid areas and China's temperate continental semi-humid monsoon climates. Therefore, locally-calibrated RTM models incorporating crop-type maps and other spatio-temporal constraints may reduce uncertainties when adapted to data-scarce regions. Generally, permanent experimental sites and a lack of systematic calibration data on various crops are some limiting factors to using remote sensing technologies for PA in Sub-Saharan Africa. Other complexities arise from farm configurations, such as small field sizes and mixed cropping practices. Therefore, future studies should develop generic, scalable and transferable models, especially within under-studied areas.",<method>machine learning regression algorithms (MLRA)</method>,No methods remaining
2024,https://openalex.org/W4394822945,Biology,A Critical Review of Artificial Intelligence Based Approaches in Intrusion Detection: A Comprehensive Analysis,"Intrusion detection (ID) is critical in securing computer networks against various malicious attacks. Recent advancements in machine learning (ML), deep learning (DL), federated learning (FL), and explainable artificial intelligence (XAI) have drawn significant attention as potential approaches for ID. DL-based approaches have shown impressive performance in ID by automatically learning relevant features from data but require significant labelled data and computational resources to train complex models. ML-based approaches require fewer computational resources and labelled data, but their ability to generalize to unseen data is limited. FL is a relatively new approach that enables multiple entities to train a model collectively without exchanging their data, providing privacy and security benefits, making it an attractive option for ID. However, FL-based approaches require more communication resources and additional computation to aggregate models from different entities. XAI is critical for understanding how AI models make decisions, improving interpretability and transparency. While existing literature has explored the strengths and weaknesses of DL, ML, FL, and XAI-based approaches for ID, a significant gap exists in providing a comprehensive analysis of the specific use cases and scenarios where each approach is most suitable. This paper seeks to fill this void by delivering an in-depth review that not only highlights strengths and weaknesses but also offers guidance for selecting the appropriate approach based on the unique ID context and available resources. The selection of an appropriate approach depends on the specific use case, and this work provides insights into which method is best suited for various network sizes, data availability, privacy, and security concerns, thus aiding practitioners in making informed decisions for their ID needs.","<method>machine learning (ML)</method>, <method>deep learning (DL)</method>, <method>federated learning (FL)</method>, <method>explainable artificial intelligence (XAI)</method>",<method>machine learning (ML)</method><method>deep learning (DL)</method><method>federated learning (FL)</method>
2024,https://openalex.org/W4399052867,Biology,Generative artificial intelligence in manufacturing: opportunities for actualizing Industry 5.0 sustainability goals,"Purpose This study offers practical insights into how generative artificial intelligence (AI) can enhance responsible manufacturing within the context of Industry 5.0. It explores how manufacturers can strategically maximize the potential benefits of generative AI through a synergistic approach. Design/methodology/approach The study developed a strategic roadmap by employing a mixed qualitative-quantitative research method involving case studies, interviews and interpretive structural modeling (ISM). This roadmap visualizes and elucidates the mechanisms through which generative AI can contribute to advancing the sustainability goals of Industry 5.0. Findings Generative AI has demonstrated the capability to promote various sustainability objectives within Industry 5.0 through ten distinct functions. These multifaceted functions address multiple facets of manufacturing, ranging from providing data-driven production insights to enhancing the resilience of manufacturing operations. Practical implications While each identified generative AI function independently contributes to responsible manufacturing under Industry 5.0, leveraging them individually is a viable strategy. However, they synergistically enhance each other when systematically employed in a specific order. Manufacturers are advised to strategically leverage these functions, drawing on their complementarities to maximize their benefits. Originality/value This study pioneers by providing early practical insights into how generative AI enhances the sustainability performance of manufacturers within the Industry 5.0 framework. The proposed strategic roadmap suggests prioritization orders, guiding manufacturers in decision-making processes regarding where and for what purpose to integrate generative AI.",<method>generative artificial intelligence (generative AI)</method>,<method>generative artificial intelligence (generative AI)</method>
2024,https://openalex.org/W4399802093,Biology,Fractional order PID controller for load frequency control in a deregulated hybrid power system using Aquila Optimization,"This paper presents an innovative approach for automatic generation control for power system under a deregulated setting. The main objective of this work is to optimally tune the parameters of the fractional-order controller using the newly developed Aquila Optimizer (AO) to enhance system performance. A test system comprising a thermal power plant, a hydroelectric system, a gas turbine-based power plant, and wind energy sources is examined under deregulated environment. The study emphasizes the minimization of frequency variations, tie line deviations, and area control errors during diverse operational shifts. The proposed control strategy explores the response of generators in a hybrid deregulated power system, emphasizing the critical role of properly tuned Fractional Order Proportional-Integral-Derivative (FOPID) controllers in ensuring system stability. The potential and effectiveness of the proposed algorithm are compared with particle swarm optimization (PSO) and whale optimization algorithm (WOA) based controller performance for the same test system. The objective function for optimization is set as the minimization of the integral time and absolute error (ITAE) performance index. Furthermore, the efficacy of the proposed technique is compared with the Unified Power Flow Controller (UPFC) and its superiority is validated. Performance evaluation of the hybrid power system is conducted under Poolco agreement, bilateral agreement, and varying operating conditions. Comparative assessments reveal the superiority of the AO-driven FOPID over other techniques, demonstrating improved system metrics, including frequencies across different areas, tie-line power variations, and generator outputs.","<method>Aquila Optimizer (AO)</method>, <method>Fractional Order Proportional-Integral-Derivative (FOPID) controllers</method>, <method>particle swarm optimization (PSO)</method>, <method>whale optimization algorithm (WOA)</method>",<method>Aquila Optimizer (AO)</method><method>whale optimization algorithm (WOA)</method>
2024,https://openalex.org/W4399857583,Biology,Integrating artificial intelligence to assess emotions in learning environments: a systematic literature review,"Introduction Artificial Intelligence (AI) is transforming multiple sectors within our society, including education. In this context, emotions play a fundamental role in the teaching-learning process given that they influence academic performance, motivation, information retention, and student well-being. Thus, the integration of AI in emotional assessment within educational environments offers several advantages that can transform how we understand and address the socio-emotional development of students. However, there remains a lack of comprehensive approach that systematizes advancements, challenges, and opportunities in this field. Aim This systematic literature review aims to explore how artificial intelligence (AI) is used to evaluate emotions within educational settings. We provide a comprehensive overview of the current state of research, focusing on advancements, challenges, and opportunities in the domain of AI-driven emotional assessment within educational settings. Method The review involved a search across the following academic databases: Pubmed, Web of Science, PsycINFO and Scopus. Forty-one articles were selected that meet the established inclusion criteria. These articles were analyzed to extract key insights related to the integration of AI and emotional assessment within educational environments. Results The findings reveal a variety of AI-driven approaches that were developed to capture and analyze students’ emotional states during learning activities. The findings are summarized in four fundamental topics: (1) emotion recognition in education, (2) technology integration and learning outcomes, (3) special education and assistive technology, (4) affective computing. Among the key AI techniques employed are machine learning and facial recognition, which are used to assess emotions. These approaches demonstrate promising potential in enhancing pedagogical strategies and creating adaptive learning environments that cater to individual emotional needs. The review identified emerging factors that, while important, require further investigation to understand their relationships and implications fully. These elements could significantly enhance the use of AI in assessing emotions within educational settings. Specifically, we are referring to: (1) federated learning, (2) convolutional neural network (CNN), (3) recurrent neural network (RNN), (4) facial expression databases, and (5) ethics in the development of intelligent systems. Conclusion This systematic literature review showcases the significance of AI in revolutionizing educational practices through emotion assessment. While advancements are evident, challenges related to accuracy, privacy, and cross-cultural validity were also identified. The synthesis of existing research highlights the need for further research into refining AI models for emotion recognition and emphasizes the importance of ethical considerations in implementing AI technologies within educational contexts.","<method>machine learning</method>, <method>facial recognition</method>, <method>federated learning</method>, <method>convolutional neural network (CNN)</method>, <method>recurrent neural network (RNN)</method>",<method>machine learning</method><method>federated learning</method><method>convolutional neural network (CNN)</method><method>recurrent neural network (RNN)</method>
2024,https://openalex.org/W4401163187,Biology,Monthly climate prediction using deep convolutional neural network and long short-term memory,"Climate change affects plant growth, food production, ecosystems, sustainable socio-economic development, and human health. The different artificial intelligence models are proposed to simulate climate parameters of Jinan city in China, include artificial neural network (ANN), recurrent NN (RNN), long short-term memory neural network (LSTM), deep convolutional NN (CNN), and CNN-LSTM. These models are used to forecast six climatic factors on a monthly ahead. The climate data for 72 years (1 January 1951–31 December 2022) used in this study include monthly average atmospheric temperature, extreme minimum atmospheric temperature, extreme maximum atmospheric temperature, precipitation, average relative humidity, and sunlight hours. The time series of 12 month delayed data are used as input signals to the models. The efficiency of the proposed models are examined utilizing diverse evaluation criteria namely mean absolute error, root mean square error (RMSE), and correlation coefficient (R). The modeling result inherits that the proposed hybrid CNN-LSTM model achieves a greater accuracy than other compared models. The hybrid CNN-LSTM model significantly reduces the forecasting error compared to the models for the one month time step ahead. For instance, the RMSE values of the ANN, RNN, LSTM, CNN, and CNN-LSTM models for monthly average atmospheric temperature in the forecasting stage are 2.0669, 1.4416, 1.3482, 0.8015 and 0.6292 °C, respectively. The findings of climate simulations shows the potential of CNN-LSTM models to improve climate forecasting. Climate prediction will contribute to meteorological disaster prevention and reduction, as well as flood control and drought resistance.","<method>artificial neural network (ANN)</method>, <method>recurrent NN (RNN)</method>, <method>long short-term memory neural network (LSTM)</method>, <method>deep convolutional NN (CNN)</method>, <method>CNN-LSTM</method>",<method>artificial neural network (ANN)</method><method>recurrent NN (RNN)</method><method>long short-term memory neural network (LSTM)</method><method>deep convolutional NN (CNN)</method><method>CNN-LSTM</method>
2024,https://openalex.org/W4390940873,Biology,Pattern recognition in the nucleation kinetics of non-equilibrium self-assembly,"Abstract Inspired by biology’s most sophisticated computer, the brain, neural networks constitute a profound reformulation of computational principles 1–3 . Analogous high-dimensional, highly interconnected computational architectures also arise within information-processing molecular systems inside living cells, such as signal transduction cascades and genetic regulatory networks 4–7 . Might collective modes analogous to neural computation be found more broadly in other physical and chemical processes, even those that ostensibly play non-information-processing roles? Here we examine nucleation during self-assembly of multicomponent structures, showing that high-dimensional patterns of concentrations can be discriminated and classified in a manner similar to neural network computation. Specifically, we design a set of 917 DNA tiles that can self-assemble in three alternative ways such that competitive nucleation depends sensitively on the extent of colocalization of high-concentration tiles within the three structures. The system was trained in silico to classify a set of 18 grayscale 30 × 30 pixel images into three categories. Experimentally, fluorescence and atomic force microscopy measurements during and after a 150 hour anneal established that all trained images were correctly classified, whereas a test set of image variations probed the robustness of the results. Although slow compared to previous biochemical neural networks, our approach is compact, robust and scalable. Our findings suggest that ubiquitous physical phenomena, such as nucleation, may hold powerful information-processing capabilities when they occur within high-dimensional multicomponent systems.",<method>neural networks</method>,<method>neural networks</method>
2024,https://openalex.org/W4391341367,Biology,Automated Tool Support for Glaucoma Identification With Explainability Using Fundus Images,"Glaucoma is a progressive eye condition that causes irreversible vision loss due to damage to the optic nerve. Recent developments in deep learning and the accessibility of computing resources have provided tool support for automated glaucoma diagnosis. Despite deep learning's advances in disease diagnosis using medical images, generic convolutional neural networks are still not widely used in medical practices due to the limited trustworthiness of these models. Although deep learning-based glaucoma classification has gained popularity in recent years, only a few of them have addressed the explainability and interpretability of the models, which increases confidence in using such applications. This study presents state-of-the-art deep learning techniques to segment and classify fundus images to predict glaucoma conditions and applies visualization techniques to explain the results to ease understandability. Our predictions are based on U-Net with attention mechanisms with ResNet50 for the segmentation process and a modified Inception V3 architecture for the classification. Attention U-Net with modified ResNet50 backbone obtained 99.58% and 98.05% accuracies for optic disc segmentation and optic cup segmentation, respectively for the RIM-ONE dataset. Additionally, we generate heatmaps that highlight the regions that impacted the glaucoma diagnosis using both Gradient-weighted Class Activation Mapping (Grad-CAM) and Grad-CAM++. Our model that classifies the segmented images achieves accuracy, sensitivity, and specificity values of 98.97%, 99.42%, and 95.59%, respectively, with the RIM-ONE dataset. This model can be used as a support tool for automated glaucoma identification using fundus images.","<method>U-Net with attention mechanisms</method>, <method>ResNet50</method>, <method>modified Inception V3 architecture</method>, <method>Attention U-Net with modified ResNet50 backbone</method>, <method>Gradient-weighted Class Activation Mapping (Grad-CAM)</method>, <method>Grad-CAM++</method>",<method>U-Net with attention mechanisms</method><method>ResNet50</method><method>modified Inception V3 architecture</method><method>Attention U-Net with modified ResNet50 backbone</method><method>Gradient-weighted Class Activation Mapping (Grad-CAM)</method><method>Grad-CAM++</method>
2024,https://openalex.org/W4391610180,Biology,"Generative artificial intelligence in drug discovery: basic framework, recent advances, challenges, and opportunities","There are two main ways to discover or design small drug molecules. The first involves fine-tuning existing molecules or commercially successful drugs through quantitative structure-activity relationships and virtual screening. The second approach involves generating new molecules through de novo drug design or inverse quantitative structure-activity relationship. Both methods aim to get a drug molecule with the best pharmacokinetic and pharmacodynamic profiles. However, bringing a new drug to market is an expensive and time-consuming endeavor, with the average cost being estimated at around $2.5 billion. One of the biggest challenges is screening the vast number of potential drug candidates to find one that is both safe and effective. The development of artificial intelligence in recent years has been phenomenal, ushering in a revolution in many fields. The field of pharmaceutical sciences has also significantly benefited from multiple applications of artificial intelligence, especially drug discovery projects. Artificial intelligence models are finding use in molecular property prediction, molecule generation, virtual screening, synthesis planning, repurposing, among others. Lately, generative artificial intelligence has gained popularity across domains for its ability to generate entirely new data, such as images, sentences, audios, videos, novel chemical molecules, etc. Generative artificial intelligence has also delivered promising results in drug discovery and development. This review article delves into the fundamentals and framework of various generative artificial intelligence models in the context of drug discovery via de novo drug design approach. Various basic and advanced models have been discussed, along with their recent applications. The review also explores recent examples and advances in the generative artificial intelligence approach, as well as the challenges and ongoing efforts to fully harness the potential of generative artificial intelligence in generating novel drug molecules in a faster and more affordable manner. Some clinical-level assets generated form generative artificial intelligence have also been discussed in this review to show the ever-increasing application of artificial intelligence in drug discovery through commercial partnerships.","<method>quantitative structure-activity relationships</method>, <method>virtual screening</method>, <method>de novo drug design</method>, <method>inverse quantitative structure-activity relationship</method>, <method>artificial intelligence models</method>, <method>molecular property prediction</method>, <method>molecule generation</method>, <method>virtual screening</method>, <method>synthesis planning</method>, <method>repurposing</method>, <method>generative artificial intelligence</method>",<method>inverse quantitative structure-activity relationship</method>
2024,https://openalex.org/W4391923223,Biology,Improved random forest algorithms for increasing the accuracy of forest aboveground biomass estimation using Sentinel-2 imagery,"A simpler, unbiased, and comprehensive random forest (RF) model is needed to improve the accuracy of aboveground biomass (AGB) estimation. In this study, data were obtained from 128 sample plots of Pinus yunnanensis forest located in Chuxiong prefecture, Yunnan province, China. Sentinel-2 imagery data were applied to extract the important predictors of forest AGB, which were screened using the Boruta algorithm. We compared the fitting performance of two modified random forest models − regularized random forest (RRF) and quantile random forest (QRF) − with the random forest model. Moreover, we combined the smallest mean error of each quantile model as the best QRF (QRFb). The result showed: (1) Window sizes of 3 × 3 pixels and 5 × 5 pixels demonstrated greater sensitivity and suitability for estimating AGB than the 7 × 7 pixels window size. Enhanced vegetation indices derived from Red Edge 1 (B5) and Near-Infrared bands (B8A) were strongly correlated with AGB, indicating the heightened sensitivity of B5 and B8A bands to biomass and their potential in AGB estimation. (2) The RRF model outperformed both the standard RF and QRF in fitting performance, with an R2 of 0.56 and RMSE 57.14 Mg/ha. (3) The QRFb model exhibited the highest R2 of 0.88 and lowest RMSE of 29.56 Mg/ha, significantly reducing overestimation and underestimation issues. The modified RF regression supplies new insights into improving forest AGB estimation, which will be helpful for future research addressing carbon cycling.","<method>random forest (RF)</method>, <method>Boruta algorithm</method>, <method>regularized random forest (RRF)</method>, <method>quantile random forest (QRF)</method>",<method>random forest (RF)</method><method>Boruta algorithm</method><method>regularized random forest (RRF)</method><method>quantile random forest (QRF)</method>
2024,https://openalex.org/W4401384485,Biology,GAN based augmentation using a hybrid loss function for dermoscopy images,"Dermatology is the most appropriate field to utilize pattern recognition-based automated techniques for objective, accurate, and rapid diagnosis because diagnosis mainly relies on visual examinations of skin lesions. Recent approaches utilizing deep learning techniques have shown remarkable results in this field. However, they necessitate a substantial quantity of images and the availability of dermoscopy images is often limited. Also, even if enough images are available, their labeling requires expert knowledge and is time-consuming. To overcome these issues, an efficient augmentation approach is needed to expand training datasets from input images. Therefore, in this work, a generative adversarial network has been developed using a new hybrid loss function constructed with traditional loss functions to enhance the generation power of the architecture. Also, the effect of the proposed approach and different generative network-based augmentations, which have been used with dermoscopy images in the literature, on the classification of skin lesions has been investigated. Therefore, the main contributions of this work are: (i) introducing a new generative model for the augmentation of dermoscopy images; (ii) presenting the effect of the proposed model on the classification of the images; (iii) comparative evaluations of the effectiveness of different generative network-based augmentations in the classification of seven forms of skin lesions. The classification accuracy when the proposed augmentation is used is 93.12%, which is higher than its counterparts. Experimental results indicate the significance of augmentation techniques in the classification of skin lesions and the efficiency of the proposed structure in improving the classification accuracy.","<method>deep learning techniques</method>, <method>generative adversarial network</method>, <method>generative network-based augmentations</method>",<method>generative adversarial network</method>
2024,https://openalex.org/W4391097085,Biology,Lightweight Context-Aware Network Using Partial-Channel Transformation for Real-Time Semantic Segmentation,"Optimizing the computational efficiency of the artificial neural networks is crucial for resource-constrained platforms like autonomous driving systems. To address this challenge, we proposed a Lightweight Context-aware Network (LCNet) that accelerates semantic segmentation while maintaining a favorable trade-off between inference speed and segmentation accuracy in this paper. The proposed LCNet introduces a partial-channel transformation (PCT) strategy to minimize computing latency and hardware requirements of the basic unit. Within the PCT block, a three-branch context aggregation (TCA) module expands the feature receptive fields, capturing multiscale contextual information. Additionally, a dual-attention-guided decoder (DD) recovers spatial details and enhances pixel prediction accuracy. Extensive experiments on three benchmarks demonstrate the effectiveness and efficiency of the proposed LCNet model. Remarkably, a smaller model LCNet <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> <tex-math notation=""LaTeX"">$_{3\_7}$</tex-math> </inline-formula> achieves 73.8% mIoU with only 0.51 million parameters, with an impressive inference speed of <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> <tex-math notation=""LaTeX"">$\sim$</tex-math> </inline-formula> 142.5 fps and <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> <tex-math notation=""LaTeX"">$\sim$</tex-math> </inline-formula> 9 fps using a single RTX 3090 GPU and Jetson Xavier NX, respectively, on the Cityscapes test set at <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> <tex-math notation=""LaTeX"">$1024\times 1024$</tex-math> </inline-formula> resolution. A more accurate version of the LCNet <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> <tex-math notation=""LaTeX"">$_{3\_11}$</tex-math> </inline-formula> can achieve 75.8% mIoU with 0.74 million parameters at <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> <tex-math notation=""LaTeX"">$\sim$</tex-math> </inline-formula> 117 fps inference speed on Cityscapes at the same resolution. Much faster inference speed can be achieved at smaller image resolutions. LCNet strikes a great balance between computational efficiency and prediction capability for mobile application scenarios. The code is available at https://github.com/lztjy/LCNet.","<method>Lightweight Context-aware Network (LCNet)</method>, <method>partial-channel transformation (PCT) strategy</method>, <method>three-branch context aggregation (TCA) module</method>, <method>dual-attention-guided decoder (DD)</method>",No methods remaining
2024,https://openalex.org/W4391317367,Biology,Automated localization of mandibular landmarks in the construction of mandibular median sagittal plane,"Abstract Objective To use deep learning to segment the mandible and identify three-dimensional (3D) anatomical landmarks from cone-beam computed tomography (CBCT) images, the planes constructed from the mandibular midline landmarks were compared and analyzed to find the best mandibular midsagittal plane (MMSP). Methods A total of 400 participants were randomly divided into a training group ( n = 360) and a validation group ( n = 40). Normal individuals were used as the test group ( n = 50). The PointRend deep learning mechanism segmented the mandible from CBCT images and accurately identified 27 anatomic landmarks via PoseNet. 3D coordinates of 5 central landmarks and 2 pairs of side landmarks were obtained for the test group. Every 35 combinations of 3 midline landmarks were screened using the template mapping technique. The asymmetry index (AI) was calculated for each of the 35 mirror planes. The template mapping technique plane was used as the reference plane; the top four planes with the smallest AIs were compared through distance, volume difference, and similarity index to find the plane with the fewest errors. Results The mandible was segmented automatically in 10 ± 1.5 s with a 0.98 Dice similarity coefficient. The mean landmark localization error for the 27 landmarks was 1.04 ± 0.28 mm. MMSP should use the plane made by B (supramentale), Gn (gnathion), and F (mandibular foramen). The average AI grade was 1.6 (min–max: 0.59–3.61). There was no significant difference in distance or volume ( P &gt; 0.05); however, the similarity index was significantly different ( P &lt; 0.01). Conclusion Deep learning can automatically segment the mandible, identify anatomic landmarks, and address medicinal demands in people without mandibular deformities. The most accurate MMSP was the B-Gn-F plane.","<method>PointRend deep learning mechanism</method>, <method>PoseNet</method>",<method>PointRend deep learning mechanism</method><method>PoseNet</method>
2024,https://openalex.org/W4391515422,Biology,Predicting transient wind loads on tall buildings in three-dimensional spatial coordinates using machine learning,"Machine learning (ML) as a subset of artificial intelligence (AI), has gained significant attention in wind engineering applications over the past decade. Wind load predictions for tall buildings using ML studies presented in literature have always been limited to static pressure measurements or time history measurements without considering the spatial coordinates system. To design wind-sensitive tall buildings, ML models must be capable of estimating transient wind flow quantities along with its spatial distribution. Thus, in this study, for the first time, the authors used ML to model the transient wind pressure on a tall building using a three-dimensional (3D) spatial coordinates system. A series of Boundary Layer Wind Tunnel tests were performed to obtain the transient pressure readings on building surfaces, which were used to validate the Computational Fluid Dynamics (CFD) models. Turbulence was modelled using large eddy simulations and the data obtained through CFD simulations were utilised to generate the ML models. The popular Extreme Gradient Boosting (XGBoost) model was selected as the ML model due to its capability of efficient data handling. The trained XGBoost model accurately predicted the transient wind pressure throughout the flow time. The XGBoost model has captured the extreme values well, closely following the flow patterns. In addition, special flow features like flow separation, reattachment, and steep pressure gradients have been well captured over the corresponding surfaces. Therefore, this study showcases the ability to use ML to predict pressures on tall buildings, capturing all key flow features time-efficiently.",<method>Extreme Gradient Boosting (XGBoost)</method>,<method>Extreme Gradient Boosting (XGBoost)</method>
2024,https://openalex.org/W4391693196,Biology,Predicting DNA structure using a deep learning method,"Understanding the mechanisms of protein-DNA binding is critical in comprehending gene regulation. Three-dimensional DNA structure, also described as DNA shape, plays a key role in these mechanisms. In this study, we present a deep learning-based method, Deep DNAshape, that fundamentally changes the current k-mer based high-throughput prediction of DNA shape features by accurately accounting for the influence of extended flanking regions, without the need for extensive molecular simulations or structural biology experiments. By using the Deep DNAshape method, DNA structural features can be predicted for any length and number of DNA sequences in a high-throughput manner, providing an understanding of the effects of flanking regions on DNA structure in a target region of a sequence. The Deep DNAshape method provides access to the influence of distant flanking regions on a region of interest. Our findings reveal that DNA shape readout mechanisms of a core target are quantitatively affected by flanking regions, including extended flanking regions, providing valuable insights into the detailed structural readout mechanisms of protein-DNA binding. Furthermore, when incorporated in machine learning models, the features generated by Deep DNAshape improve the model prediction accuracy. Collectively, Deep DNAshape can serve as versatile and powerful tool for diverse DNA structure-related studies.","<method>deep learning-based method</method>, <method>machine learning models</method>",No methods remaining
2024,https://openalex.org/W4391943312,Biology,"Machine Learning and Deep Learning in Synthetic Biology: Key Architectures, Applications, and Challenges","Machine learning (ML), particularly deep learning (DL), has made rapid and substantial progress in synthetic biology in recent years. Biotechnological applications of biosystems, including pathways, enzymes, and whole cells, are being probed frequently with time. The intricacy and interconnectedness of biosystems make it challenging to design them with the desired properties. ML and DL have a synergy with synthetic biology. Synthetic biology can be employed to produce large data sets for training models (for instance, by utilizing DNA synthesis), and ML/DL models can be employed to inform design (for example, by generating new parts or advising unrivaled experiments to perform). This potential has recently been brought to light by research at the intersection of engineering biology and ML/DL through achievements like the design of novel biological components, best experimental design, automated analysis of microscopy data, protein structure prediction, and biomolecular implementations of ANNs (Artificial Neural Networks). I have divided this review into three sections. In the first section, I describe predictive potential and basics of ML along with myriad applications in synthetic biology, especially in engineering cells, activity of proteins, and metabolic pathways. In the second section, I describe fundamental DL architectures and their applications in synthetic biology. Finally, I describe different challenges causing hurdles in the progress of ML/DL and synthetic biology along with their solutions.","<method>machine learning (ML)</method>, <method>deep learning (DL)</method>, <method>Artificial Neural Networks (ANNs)</method>",<method>machine learning (ML)</method><method>deep learning (DL)</method><method>Artificial Neural Networks (ANNs)</method>
2024,https://openalex.org/W4391997375,Biology,A machine learning approach to predict the efficiency of corrosion inhibition by natural product-based organic inhibitors,"Abstract This paper presents a quantitative structure–property relationship (QSPR)-based machine learning (ML) framework designed for predicting corrosion inhibition efficiency (CIE) values in natural organic inhibitor compounds. The modeling dataset comprises 50 natural organic compounds, with 11 quantum chemical properties (QCP) serving as input features, and the target variable being the corrosion inhibition efficiency (CIE) value. To enhance the predictive accuracy of the ML model, the kernel density estimation (KDE) function is employed to generate virtual samples during the training process, with the overarching goal of refining the precision of the ML model. Three distinct models, namely random forest (RF), gradient boosting (GB), and k-nearest neighbor (KNN), are tested in the study. The results demonstrate a noteworthy enhancement in the prediction performance of the models, attributable to the incorporation of virtual samples that effectively improve the correlation between input features and target values. Consequently, the accuracy of the predicted CIE values is significantly augmented, aligning more closely with the actual CIE values. Performance improvements were evident across all models after the incorporation of virtual samples. The GB, RF, and KNN models exhibited increments in R 2 values from 0.557 to 0.996, 0.522 to 0.999, and 0.415 to 0.994, respectively, concomitant with the introduction of 500 virtual samples. Additionally, each model demonstrated a notable reduction in RMSE values, transitioning from 1.41 to 0.19, 1.27 to 0.10, and 1.22 to 0.16, respectively. While the GB model initially outperformed others before the addition of virtual samples, the performance of the model exhibited fluctuation as the number of virtual samples varied. This behavior suggests that the KDE function provides a certain level of resilience against model variations. The proposed approach contributes to the effective design and exploration of corrosion inhibitor candidates, offering a reliable and accurate predictive tool that bridges the gap between theoretical studies and experimental synthesis.","<method>random forest (RF)</method>, <method>gradient boosting (GB)</method>, <method>k-nearest neighbor (KNN)</method>, <method>kernel density estimation (KDE)</method>",<method>random forest (RF)</method><method>gradient boosting (GB)</method><method>k-nearest neighbor (KNN)</method>
2024,https://openalex.org/W4393905353,Biology,Theranostics and artificial intelligence: new frontiers in personalized medicine,"The field of theranostics is rapidly advancing, driven by the goals of enhancing patient care. Recent breakthroughs in artificial intelligence (AI) and its innovative theranostic applications have marked a critical step forward in nuclear medicine, leading to a significant paradigm shift in precision oncology. For instance, AI-assisted tumor characterization, including automated image interpretation, tumor segmentation, feature identification, and prediction of high-risk lesions, improves diagnostic processes, offering a precise and detailed evaluation. With a comprehensive assessment tailored to an individual's unique clinical profile, AI algorithms promise to enhance patient risk classification, thereby benefiting the alignment of patient needs with the most appropriate treatment plans. By uncovering potential factors unseeable to the human eye, such as intrinsic variations in tumor radiosensitivity or molecular profile, AI software has the potential to revolutionize the prediction of response heterogeneity. For accurate and efficient dosimetry calculations, AI technology offers significant advantages by providing customized phantoms and streamlining complex mathematical algorithms, making personalized dosimetry feasible and accessible in busy clinical settings. AI tools have the potential to be leveraged to predict and mitigate treatment-related adverse events, allowing early interventions. Additionally, generative AI can be utilized to find new targets for developing novel radiopharmaceuticals and facilitate drug discovery. However, while there is immense potential and notable interest in the role of AI in theranostics, these technologies do not lack limitations and challenges. There remains still much to be explored and understood. In this study, we investigate the current applications of AI in theranostics and seek to broaden the horizons for future research and innovation.","<method>AI-assisted tumor characterization</method>, <method>automated image interpretation</method>, <method>tumor segmentation</method>, <method>feature identification</method>, <method>prediction of high-risk lesions</method>, <method>AI algorithms for patient risk classification</method>, <method>AI software for prediction of response heterogeneity</method>, <method>AI technology for dosimetry calculations</method>, <method>AI tools to predict and mitigate treatment-related adverse events</method>, <method>generative AI for novel radiopharmaceutical target discovery and drug development</method>",No methods remaining
2024,https://openalex.org/W4395037579,Biology,Assessing ChatGPT 4.0’s test performance and clinical diagnostic accuracy on USMLE STEP 2 CK and clinical case reports,"Abstract While there is data assessing the test performance of artificial intelligence (AI) chatbots, including the Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0), there is scarce data on its diagnostic accuracy of clinical cases. We assessed the large language model (LLM), ChatGPT 4.0, on its ability to answer questions from the United States Medical Licensing Exam (USMLE) Step 2, as well as its ability to generate a differential diagnosis based on corresponding clinical vignettes from published case reports. A total of 109 Step 2 Clinical Knowledge (CK) practice questions were inputted into both ChatGPT 3.5 and ChatGPT 4.0, asking ChatGPT to pick the correct answer. Compared to its previous version, ChatGPT 3.5, we found improved accuracy of ChatGPT 4.0 when answering these questions, from 47.7 to 87.2% ( p = 0.035) respectively. Utilizing the topics tested on Step 2 CK questions, we additionally found 63 corresponding published case report vignettes and asked ChatGPT 4.0 to come up with its top three differential diagnosis. ChatGPT 4.0 accurately created a shortlist of differential diagnoses in 74.6% of the 63 case reports (74.6%). We analyzed ChatGPT 4.0’s confidence in its diagnosis by asking it to rank its top three differentials from most to least likely. Out of the 47 correct diagnoses, 33 were the first (70.2%) on the differential diagnosis list, 11 were second (23.4%), and three were third (6.4%). Our study shows the continued iterative improvement in ChatGPT’s ability to answer standardized USMLE questions accurately and provides insights into ChatGPT’s clinical diagnostic accuracy.","<method>Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0)</method>, <method>ChatGPT 3.5</method>, <method>large language model (LLM)</method>",<method>Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0)</method><method>large language model (LLM)</method>
2024,https://openalex.org/W4399173789,Biology,Utilizing Deep Learning and the Internet of Things to Monitor the Health of Aquatic Ecosystems to Conserve Biodiversity,"The decline in water conditions contributes to the crisis in clean water biodiversity. The interactions between water conditions indicators and the correlations among these variables and taxonomic groupings are intricate in their impact on biodiversity. However, since there are just a few kinds of Internet of Things (IoT) that are accessible to purchase, many chemical and biological measurements still need laboratory studies. The newest progress in Deep Learning and the IoT allows for the use of this method in the real-time surveillance of water quality, therefore contributing to preserving biodiversity. This paper presents a thorough examination of the scientific literature about the water quality factors that have a significant influence on the variety of freshwater ecosystems. It selected the ten most crucial water quality criteria. The connections between the quantifiable and valuable aspects of the IoT are assessed using a Generalized Regression-based Neural Networks (G-RNN) framework and a multi-variational polynomial regression framework. These models depend on historical data from the monitoring of water quality. The projected findings in an urbanized river were validated using a combination of traditional field water testing, in-lab studies, and the created IoT-depend water condition management system. The G-RNN effectively differentiates abnormal increases in variables from typical scenarios. The assessment coefficients for the system for degree 8 are as follows: 0.87, 0.73, 0.89, and 0.79 for N-O3-N, BO-D5, P-O4, and N-H3-N. The suggested methods and prototypes were verified against laboratory findings to assess their efficacy and effectiveness. The general efficacy was deemed suitable, with most forecasting mistakes smaller than 0.3 mg/L. This validation offers valuable insights into IoT methods' usage in pollutants released observation and additional water quality regulating usage, specifically for freshwater biodiversity preservation.","<method>Generalized Regression-based Neural Networks (G-RNN)</method>, <method>multi-variational polynomial regression framework</method>",No methods remaining
2024,https://openalex.org/W4401593044,Biology,Overcoming the Limits of Cross-Sensitivity: Pattern Recognition Methods for Chemiresistive Gas Sensor Array,"Abstract As information acquisition terminals for artificial olfaction, chemiresistive gas sensors are often troubled by their cross-sensitivity, and reducing their cross-response to ambient gases has always been a difficult and important point in the gas sensing area. Pattern recognition based on sensor array is the most conspicuous way to overcome the cross-sensitivity of gas sensors. It is crucial to choose an appropriate pattern recognition method for enhancing data analysis, reducing errors and improving system reliability, obtaining better classification or gas concentration prediction results. In this review, we analyze the sensing mechanism of cross-sensitivity for chemiresistive gas sensors. We further examine the types, working principles, characteristics, and applicable gas detection range of pattern recognition algorithms utilized in gas-sensing arrays. Additionally, we report, summarize, and evaluate the outstanding and novel advancements in pattern recognition methods for gas identification. At the same time, this work showcases the recent advancements in utilizing these methods for gas identification, particularly within three crucial domains: ensuring food safety, monitoring the environment, and aiding in medical diagnosis. In conclusion, this study anticipates future research prospects by considering the existing landscape and challenges. It is hoped that this work will make a positive contribution towards mitigating cross-sensitivity in gas-sensitive devices and offer valuable insights for algorithm selection in gas recognition applications.",<method>pattern recognition</method>,No methods remaining
2024,https://openalex.org/W4390492164,Biology,Efficient Camouflaged Object Detection Network Based on Global Localization Perception and Local Guidance Refinement,"Camouflaged Object Detection (COD) is a challenging visual task due to its complex contour, diverse scales, and high similarity to the background. Existing COD methods encounter two predicaments: One is that they are prone to falling into local perception, resulting in inaccurate object localization; Another issue is the difficulty in achieving precise object segmentation due to a lack of detailed information. In addition, most COD methods typically require larger parameter amounts and higher computational complexity in pursuit of better performance. To this end, we propose a global localization perception and local guidance refinement network (PRNet), that simultaneously addresses performance and computational costs. Through effective aggregation and use of semantic and details information, the PRNet can achieve accurate localization and refined segmentation of camouflaged objects. Specifically, with the help of a Cascaded Attention Perceptron (CAP) designed, we can effectively integrate and perceive multi-scale information to localize camouflaged objects. We also design a Guided Refinement Decoder (GRD) in a top-down manner to extract context information and aggregate details to further refine camouflaged prediction results. Extensive experimental results demonstrate that our PRNet outperforms 12 state-of-the-art models on 4 challenging datasets. Meanwhile, the PRNet has a smaller number of parameters (12.74M), lower computational complexity (10.24G), and real-time inference speed (105FPS). Source codes are available at https://github.com/hu-xh/PRNet.","<method>global localization perception and local guidance refinement network (PRNet)</method>, <method>Cascaded Attention Perceptron (CAP)</method>, <method>Guided Refinement Decoder (GRD)</method>",No methods remaining
2024,https://openalex.org/W4390501772,Biology,Remote sensing based forest cover classification using machine learning,"Abstract Pakistan falls significantly below the recommended forest coverage level of 20 to 30 percent of total area, with less than 6 percent of its land under forest cover. This deficiency is primarily attributed to illicit deforestation for wood and charcoal, coupled with a failure to embrace advanced techniques for forest estimation, monitoring, and supervision. Remote sensing techniques leveraging Sentinel-2 satellite images were employed. Both single-layer stacked images and temporal layer stacked images from various dates were utilized for forest classification. The application of an artificial neural network (ANN) supervised classification algorithm yielded notable results. Using a single-layer stacked image from Sentinel-2, an impressive 91.37% training overall accuracy and 0.865 kappa coefficient were achieved, along with 93.77% testing overall accuracy and a 0.902 kappa coefficient. Furthermore, the temporal layer stacked image approach demonstrated even better results. This method yielded 98.07% overall training accuracy, 97.75% overall testing accuracy, and kappa coefficients of 0.970 and 0.965, respectively. The random forest (RF) algorithm, when applied, achieved 99.12% overall training accuracy, 92.90% testing accuracy, and kappa coefficients of 0.986 and 0.882. Notably, with the temporal layer stacked image of the Sentinel-2 satellite, the RF algorithm reached exceptional performance with 99.79% training accuracy, 96.98% validation accuracy, and kappa coefficients of 0.996 and 0.954. In terms of forest cover estimation, the ANN algorithm identified 31.07% total forest coverage in the District Abbottabad region. In comparison, the RF algorithm recorded a slightly higher 31.17% of the total forested area. This research highlights the potential of advanced remote sensing techniques and machine learning algorithms in improving forest cover assessment and monitoring strategies.","<method>artificial neural network (ANN) supervised classification algorithm</method>, <method>random forest (RF) algorithm</method>",<method>artificial neural network (ANN) supervised classification algorithm</method><method>random forest (RF) algorithm</method>
2024,https://openalex.org/W4390588870,Biology,Machine learning-driven optimization of enterprise resource planning (ERP) systems: a comprehensive review,"Abstract In the dynamic and changing realm of technology and business operations, staying abreast of recent trends is paramount. This review evaluates the progress in the development of the integration of machine learning (ML) with enterprise resource planning (ERP) systems, revealing the impact of these trends on the ERP optimization. In recent years, there has been a significant advancement in the integration of ML technology within ERP environments. ML algorithms characterized by their ability to extract intricate patterns from vast datasets are being harnessed to enable ERP systems to make more accurate predictions and data-driven decisions. Therefore, ML enables ERP systems to adapt dynamically based on real-time insights, resulting in enhanced efficiency and adaptability. Furthermore, organizations are increasingly looking for artificial intelligence (AI) solutions as they actually try to make ML models within ERP clear and comprehensible for stakeholders. These solutions enable ERP systems to process and act on data as it flows in, due to the utilization of ML models, which enables enterprises to react effectively to changing circumstances. The rapid insights and useful intelligence offered by this trend have had a significant impact across industries. IoT (Internet of Things) and ML integration with ERP are continuously gaining significance. These algorithms allow for the creation of adaptable strategies supported by ongoing learning and data-driven optimization, which has a number of benefits for ERP system optimization. In addition, the Industrial Internet of Things (IIoT) was investigated in this review to provide the state-of-the-art and emerging challenges due to ML integration. This review provides a comprehensive analysis of the integration of machine learning algorithms across several ERP applications by conducting an extensive literature assessment of recent publications. By synthesizing the latest research findings, this comprehensive review provides an in-depth analysis of the cutting-edge techniques and recent advancements in the context of machine learning (ML)-driven optimization of enterprise resource planning (ERP) systems. It not only provides an insight into the methodology and impact of the state-of-the-art but also offers valuable insights into where the future of ML in ERP may lead, propelling ERP systems into a new era of intelligence, efficiency, and innovation.",<method>machine learning (ML) algorithms</method>,No methods remaining
2024,https://openalex.org/W4390660406,Biology,Improving River Routing Using a Differentiable Muskingum‐Cunge Model and Physics‐Informed Machine Learning,"Abstract Recently, rainfall‐runoff simulations in small headwater basins have been improved by methodological advances such as deep neural networks (NNs) and hybrid physics‐NN models—particularly, a genre called differentiable modeling that intermingles NNs with physics to learn relationships between variables. However, hydrologic routing simulations, necessary for simulating floods in stem rivers downstream of large heterogeneous basins, had not yet benefited from these advances and it was unclear if the routing process could be improved via coupled NNs. We present a novel differentiable routing method ( δ MC‐Juniata‐hydroDL2) that mimics the classical Muskingum‐Cunge routing model over a river network but embeds an NN to infer parameterizations for Manning's roughness ( n ) and channel geometries from raw reach‐scale attributes like catchment areas and sinuosity. The NN was trained solely on downstream hydrographs. Synthetic experiments show that while the channel geometry parameter was unidentifiable, n can be identified with moderate precision. With real‐world data, the trained differentiable routing model produced more accurate long‐term routing results for both the training gage and untrained inner gages for larger subbasins (&gt;2,000 km 2 ) than either a machine learning model assuming homogeneity, or simply using the sum of runoff from subbasins. The n parameterization trained on short periods gave high performance in other periods, despite significant errors in runoff inputs. The learned n pattern was consistent with literature expectations, demonstrating the framework's potential for knowledge discovery, but the absolute values can vary depending on training periods. The trained n parameterization can be coupled with traditional models to improve national‐scale hydrologic flood simulations.","<method>deep neural networks (NNs)</method>, <method>hybrid physics‐NN models</method>, <method>differentiable modeling</method>, <method>differentiable routing method (δ MC‐Juniata‐hydroDL2)</method>, <method>machine learning model assuming homogeneity</method>",<method>deep neural networks (NNs)</method><method>hybrid physics‐NN models</method><method>differentiable modeling</method>
2024,https://openalex.org/W4390954471,Biology,Traffic Sign Detection and Recognition Using YOLO Object Detection Algorithm: A Systematic Review,"Context: YOLO (You Look Only Once) is an algorithm based on deep neural networks with real-time object detection capabilities. This state-of-the-art technology is widely available, mainly due to its speed and precision. Since its conception, YOLO has been applied to detect and recognize traffic signs, pedestrians, traffic lights, vehicles, and so on. Objective: The goal of this research is to systematically analyze the YOLO object detection algorithm, applied to traffic sign detection and recognition systems, from five relevant aspects of this technology: applications, datasets, metrics, hardware, and challenges. Method: This study performs a systematic literature review (SLR) of studies on traffic sign detection and recognition using YOLO published in the years 2016–2022. Results: The search found 115 primary studies relevant to the goal of this research. After analyzing these investigations, the following relevant results were obtained. The most common applications of YOLO in this field are vehicular security and intelligent and autonomous vehicles. The majority of the sign datasets used to train, test, and validate YOLO-based systems are publicly available, with an emphasis on datasets from Germany and China. It has also been discovered that most works present sophisticated detection, classification, and processing speed metrics for traffic sign detection and recognition systems by using the different versions of YOLO. In addition, the most popular desktop data processing hardwares are Nvidia RTX 2080 and Titan Tesla V100 and, in the case of embedded or mobile GPU platforms, Jetson Xavier NX. Finally, seven relevant challenges that these systems face when operating in real road conditions have been identified. With this in mind, research has been reclassified to address these challenges in each case. Conclusions: This SLR is the most relevant and current work in the field of technology development applied to the detection and recognition of traffic signs using YOLO. In addition, insights are provided about future work that could be conducted to improve the field.",<method>YOLO (You Only Look Once)</method>,<method>YOLO (You Only Look Once)</method>
2024,https://openalex.org/W4392015292,Biology,Avoiding fusion plasma tearing instability with deep reinforcement learning,"Abstract For stable and efficient fusion energy production using a tokamak reactor, it is essential to maintain a high-pressure hydrogenic plasma without plasma disruption. Therefore, it is necessary to actively control the tokamak based on the observed plasma state, to manoeuvre high-pressure plasma while avoiding tearing instability, the leading cause of disruptions. This presents an obstacle-avoidance problem for which artificial intelligence based on reinforcement learning has recently shown remarkable performance 1–4 . However, the obstacle here, the tearing instability, is difficult to forecast and is highly prone to terminating plasma operations, especially in the ITER baseline scenario. Previously, we developed a multimodal dynamic model that estimates the likelihood of future tearing instability based on signals from multiple diagnostics and actuators 5 . Here we harness this dynamic model as a training environment for reinforcement-learning artificial intelligence, facilitating automated instability prevention. We demonstrate artificial intelligence control to lower the possibility of disruptive tearing instabilities in DIII-D 6 , the largest magnetic fusion facility in the United States. The controller maintained the tearing likelihood under a given threshold, even under relatively unfavourable conditions of low safety factor and low torque. In particular, it allowed the plasma to actively track the stable path within the time-varying operational space while maintaining H-mode performance, which was challenging with traditional preprogrammed control. This controller paves the path to developing stable high-performance operational scenarios for future use in ITER.","<method>reinforcement learning</method>, <method>multimodal dynamic model</method>",<method>reinforcement learning</method>
2024,https://openalex.org/W4393094733,Biology,Advancing entity recognition in biomedicine via instruction tuning of large language models,"Abstract Motivation Large Language Models (LLMs) have the potential to revolutionize the field of Natural Language Processing, excelling not only in text generation and reasoning tasks but also in their ability for zero/few-shot learning, swiftly adapting to new tasks with minimal fine-tuning. LLMs have also demonstrated great promise in biomedical and healthcare applications. However, when it comes to Named Entity Recognition (NER), particularly within the biomedical domain, LLMs fall short of the effectiveness exhibited by fine-tuned domain-specific models. One key reason is that NER is typically conceptualized as a sequence labeling task, whereas LLMs are optimized for text generation and reasoning tasks. Results We developed an instruction-based learning paradigm that transforms biomedical NER from a sequence labeling task into a generation task. This paradigm is end-to-end and streamlines the training and evaluation process by automatically repurposing pre-existing biomedical NER datasets. We further developed BioNER-LLaMA using the proposed paradigm with LLaMA-7B as the foundational LLM. We conducted extensive testing on BioNER-LLaMA across three widely recognized biomedical NER datasets, consisting of entities related to diseases, chemicals, and genes. The results revealed that BioNER-LLaMA consistently achieved higher F1-scores ranging from 5% to 30% compared to the few-shot learning capabilities of GPT-4 on datasets with different biomedical entities. We show that a general-domain LLM can match the performance of rigorously fine-tuned PubMedBERT models and PMC-LLaMA, biomedical-specific language model. Our findings underscore the potential of our proposed paradigm in developing general-domain LLMs that can rival SOTA performances in multi-task, multi-domain scenarios in biomedical and health applications. Availability and implementation Datasets and other resources are available at https://github.com/BIDS-Xu-Lab/BioNER-LLaMA.","<method>instruction-based learning paradigm</method>, <method>few-shot learning</method>, <method>fine-tuned domain-specific models</method>, <method>LLaMA-7B</method>, <method>BioNER-LLaMA</method>, <method>GPT-4 few-shot learning</method>, <method>PubMedBERT fine-tuning</method>, <method>PMC-LLaMA biomedical-specific language model</method>",<method>few-shot learning</method><method>LLaMA-7B</method><method>GPT-4 few-shot learning</method><method>PubMedBERT fine-tuning</method>
2024,https://openalex.org/W4393306481,Biology,Reliable water quality prediction and parametric analysis using explainable AI models,"Abstract The consumption of water constitutes the physical health of most of the living species and hence management of its purity and quality is extremely essential as contaminated water has to potential to create adverse health and environmental consequences. This creates the dire necessity to measure, control and monitor the quality of water. The primary contaminant present in water is Total Dissolved Solids (TDS), which is hard to filter out. There are various substances apart from mere solids such as potassium, sodium, chlorides, lead, nitrate, cadmium, arsenic and other pollutants. The proposed work aims to provide the automation of water quality estimation through Artificial Intelligence and uses Explainable Artificial Intelligence (XAI) for the explanation of the most significant parameters contributing towards the potability of water and the estimation of the impurities. XAI has the transparency and justifiability as a white-box model since the Machine Learning (ML) model is black-box and unable to describe the reasoning behind the ML classification. The proposed work uses various ML models such as Logistic Regression, Support Vector Machine (SVM), Gaussian Naive Bayes, Decision Tree (DT) and Random Forest (RF) to classify whether the water is drinkable. The various representations of XAI such as force plot, test patch, summary plot, dependency plot and decision plot generated in SHAPELY explainer explain the significant features, prediction score, feature importance and justification behind the water quality estimation. The RF classifier is selected for the explanation and yields optimum Accuracy and F1-Score of 0.9999, with Precision and Re-call of 0.9997 and 0.998 respectively. Thus, the work is an exploratory analysis of the estimation and management of water quality with indicators associated with their significance. This work is an emerging research at present with a vision of addressing the water quality for the future as well.","<method>Artificial Intelligence</method>, <method>Explainable Artificial Intelligence (XAI)</method>, <method>Logistic Regression</method>, <method>Support Vector Machine (SVM)</method>, <method>Gaussian Naive Bayes</method>, <method>Decision Tree (DT)</method>, <method>Random Forest (RF)</method>",<method>Logistic Regression</method><method>Support Vector Machine (SVM)</method><method>Gaussian Naive Bayes</method><method>Decision Tree (DT)</method><method>Random Forest (RF)</method>
2024,https://openalex.org/W4399319394,Biology,Multi-task aquatic toxicity prediction model based on multi-level features fusion,"With the escalating menace of organic compounds in environmental pollution imperiling the survival of aquatic organisms, the investigation of organic compound toxicity across diverse aquatic species assumes paramount significance for environmental protection. Understanding how different species respond to these compounds helps assess the potential ecological impact of pollution on aquatic ecosystems as a whole. Compared with traditional experimental methods, deep learning methods have higher accuracy in predicting aquatic toxicity, faster data processing speed and better generalization ability. This article presents ATFPGT-multi, an advanced multi-task deep neural network prediction model for organic toxicity. The model integrates molecular fingerprints and molecule graphs to characterize molecules, enabling the simultaneous prediction of acute toxicity for the same organic compound across four distinct fish species. Furthermore, to validate the advantages of multi-task learning, we independently construct prediction models, named ATFPGT-single, for each fish species. We employ cross-validation in our experiments to assess the performance and generalization ability of ATFPGT-multi. The experimental results indicate, first, that ATFPGT-multi outperforms ATFPGT-single on four fish datasets with AUC improvements of 9.8%, 4%, 4.8%, and 8.2%, respectively, demonstrating the superiority of multi-task learning over single-task learning. Furthermore, in comparison with previous algorithms, ATFPGT-multi outperforms comparative methods, emphasizing that our approach exhibits higher accuracy and reliability in predicting aquatic toxicity. Moreover, ATFPGT-multi utilizes attention scores to identify molecular fragments associated with fish toxicity in organic molecules, as demonstrated by two organic molecule examples in the main text, demonstrating the interpretability of ATFPGT-multi. In summary, ATFPGT-multi provides important support and reference for the further development of aquatic toxicity assessment. All of codes and datasets are freely available online at https://github.com/zhaoqi106/ATFPGT-multi.","<method>deep learning methods</method>, <method>multi-task deep neural network prediction model</method>, <method>multi-task learning</method>, <method>single-task learning</method>, <method>cross-validation</method>",<method>deep learning methods</method><method>multi-task deep neural network prediction model</method><method>multi-task learning</method><method>single-task learning</method>
2024,https://openalex.org/W4391321561,Biology,A survey on training challenges in generative adversarial networks for biomedical image analysis,"Abstract In biomedical image analysis, the applicability of deep learning methods is directly impacted by the quantity of image data available. This is due to deep learning models requiring large image datasets to provide high-level performance. Generative Adversarial Networks (GANs) have been widely utilized to address data limitations through the generation of synthetic biomedical images. GANs consist of two models. The generator, a model that learns how to produce synthetic images based on the feedback it receives. The discriminator, a model that classifies an image as synthetic or real and provides feedback to the generator. Throughout the training process, a GAN can experience several technical challenges that impede the generation of suitable synthetic imagery. First, the mode collapse problem whereby the generator either produces an identical image or produces a uniform image from distinct input features. Second, the non-convergence problem whereby the gradient descent optimizer fails to reach a Nash equilibrium. Thirdly, the vanishing gradient problem whereby unstable training behavior occurs due to the discriminator achieving optimal classification performance resulting in no meaningful feedback being provided to the generator. These problems result in the production of synthetic imagery that is blurry, unrealistic, and less diverse. To date, there has been no survey article outlining the impact of these technical challenges in the context of the biomedical imagery domain. This work presents a review and taxonomy based on solutions to the training problems of GANs in the biomedical imaging domain. This survey highlights important challenges and outlines future research directions about the training of GANs in the domain of biomedical imagery.","<method>deep learning</method>, <method>Generative Adversarial Networks (GANs)</method>, <method>generator</method>, <method>discriminator</method>, <method>gradient descent optimizer</method>",<method>deep learning</method><method>Generative Adversarial Networks (GANs)</method><method>discriminator</method><method>gradient descent optimizer</method>
2024,https://openalex.org/W4390609372,Psychology,Investigation of the moderation effect of gender and study level on the acceptance and use of generative <scp>AI</scp> by higher education students: Comparative evidence from Poland and Egypt,"Abstract This study delves into the implications of incorporating AI tools, specifically ChatGPT, in higher education contexts. With a primary focus on understanding the acceptance and utilization of ChatGPT among university students, the research utilizes the Unified Theory of Acceptance and Use of Technology (UTAUT) as the guiding framework. The investigation probes into four crucial constructs of UTAUT—performance expectancy, effort expectancy, social influence and facilitating conditions—to understand their impact on the intent and actual use behaviour of students. The study relies on data collected from six universities in two countries and assessed through descriptive statistics and structural equation modelling techniques, and also takes into account participants' gender and study level. The key findings show that performance expectancy, effort expectancy, and social influence significantly influence behavioural intention. Furthermore, behavioural intention, when considered alongside facilitating conditions, influences actual use behaviour. This research also explores the moderating impact of gender and study level on the relationships among these variables. The results not only augment our comprehension of technology acceptance in the context of AI tools but also provide valuable input for formulating strategies that promote effective incorporation of ChatGPT in higher education. The study underscores the need for effective awareness initiatives, bespoke training programmes, and intuitive tool designs to bolster students' perceptions and foster the wider adoption of AI tools in education. Practitioner notes What is already known about this topic ChatGPT is a tool that is quickly gaining worldwide recognition. ChatGPT helps with writing essays and solving assignments. ChatGPT raises ethical concerns about authorship, plagiarism and ethics. What this paper adds This study explores students' acceptance of ChatGPT as an aid in their education, which has not been studied previously. We used the extended Unified Technology Acceptance and Use of Technology theory to test what factors mostly influence the use of ChatGPT by students. We conducted a multiple study in Poland and Egypt based on sampling strategy from six universities. Implications for practice and/or policy ChatGPT is a global game changer and should be incorporated into study programmes. The limitations of ChatGPT should be well explained and known since it is prone to making mistakes. Higher education teachers should be aware of ChatGPT's capabilities.",<method>structural equation modelling</method>,No methods remaining
2024,https://openalex.org/W4399450035,Psychology,Power Hungry Processing: Watts Driving the Cost of AI Deployment?,"Recent years have seen a surge in the popularity of commercial AI products based on generative, multi-purpose AI systems promising a unified approach to building machine learning (ML) models into technology. However, this ambition of ""generality"" comes at a steep cost to the environment, given the amount of energy these systems require and the amount of carbon that they emit. In this work, we propose the first systematic comparison of the ongoing inference cost of various categories of ML systems, covering both task-specific (i.e. finetuned models that carry out a single task) and 'general-purpose' models, (i.e. those trained for multiple tasks). We measure deployment cost as the amount of energy and carbon required to perform 1,000 inferences on representative benchmark dataset using these models. We find that multi-purpose, generative architectures are orders of magnitude more expensive than task-specific systems for a variety of tasks, even when controlling for the number of model parameters. We conclude with a discussion around the current trend of deploying multi-purpose generative ML systems, and caution that their utility should be more intentionally weighed against increased costs in terms of energy and emissions. All the data from our study can be accessed via an interactive demo to carry out further exploration and analysis.","<method>finetuned models</method>, <method>multi-purpose generative architectures</method>",No methods remaining
2024,https://openalex.org/W4392791588,Psychology,Can large language models replace humans in systematic reviews? Evaluating <scp>GPT</scp>‐4's efficacy in screening and extracting data from peer‐reviewed and grey literature in multiple languages,"Systematic reviews are vital for guiding practice, research and policy, although they are often slow and labour-intensive. Large language models (LLMs) could speed up and automate systematic reviews, but their performance in such tasks has yet to be comprehensively evaluated against humans, and no study has tested Generative Pre-Trained Transformer (GPT)-4, the biggest LLM so far. This pre-registered study uses a ""human-out-of-the-loop"" approach to evaluate GPT-4's capability in title/abstract screening, full-text review and data extraction across various literature types and languages. Although GPT-4 had accuracy on par with human performance in some tasks, results were skewed by chance agreement and dataset imbalance. Adjusting for these caused performance scores to drop across all stages: for data extraction, performance was moderate, and for screening, it ranged from none in highly balanced literature datasets (~1:1) to moderate in those datasets where the ratio of inclusion to exclusion in studies was imbalanced (~1:3). When screening full-text literature using highly reliable prompts, GPT-4's performance was more robust, reaching ""human-like"" levels. Although our findings indicate that, currently, substantial caution should be exercised if LLMs are being used to conduct systematic reviews, they also offer preliminary evidence that, for certain review tasks delivered under specific conditions, LLMs can rival human performance.","<method>Large language models (LLMs)</method>, <method>Generative Pre-Trained Transformer (GPT)-4</method>",<method>Generative Pre-Trained Transformer (GPT)-4</method>
2024,https://openalex.org/W4394884079,Psychology,TRANSFORMING FINTECH FRAUD DETECTION WITH ADVANCED ARTIFICIAL INTELLIGENCE ALGORITHMS,"The rapid evolution of financial technology (fintech) platforms has exponentially increased the volume and sophistication of financial transactions, concurrently elevating the risk and complexity of fraudulent activities. This necessitates a paradigm shift in fraud detection methodologies towards more agile, accurate, and predictive solutions. This paper presents a comprehensive study on the transformative potential of advanced Artificial Intelligence (AI) algorithms in enhancing fintech fraud detection mechanisms. By leveraging cutting-edge AI techniques including deep learning, machine learning, and natural language processing, this research aims to develop a robust fraud detection framework capable of identifying, analyzing, and preventing fraudulent transactions in real-time.&#x0D; Our methodology encompasses the deployment of several AI algorithms on extensive datasets comprising genuine and fraudulent financial transactions. Through a comparative analysis, we identify the most effective algorithms in terms of accuracy, efficiency, and scalability. Key findings reveal that deep learning models, particularly those employing neural networks, outperform traditional machine learning models in detecting complex and nuanced fraudulent activities. Furthermore, the integration of natural language processing enables the extraction and analysis of unstructured data, significantly enhancing the detection capabilities.&#x0D; Conclusively, this paper underscores the critical role of advanced AI algorithms in revolutionizing fintech fraud detection. It highlights the superior performance of AI-based models over conventional methods, offering fintech platforms a more dynamic and predictive approach to fraud prevention. This research not only contributes to the academic discourse on financial security but also provides practical insights for fintech companies striving to safeguard their operations against fraud.&#x0D; Keywords: Artificial Intelligence, Fintech, Fraud Detection, Ethical Ai, Regulatory Compliance, Data Privacy, Algorithmic Bias, Predictive Analytics, Blockchain Technology, Quantum Computing, Interdisciplinary Collaboration, Innovation, Transparency, Accountability, Continuous Learning, Ethical Principles, Real-Time Processing, Financial Sector.","<method>deep learning</method>, <method>machine learning</method>, <method>natural language processing</method>, <method>neural networks</method>",<method>deep learning</method><method>machine learning</method><method>neural networks</method>
2024,https://openalex.org/W4392202731,Psychology,Applying large language models and chain-of-thought for automatic scoring,"This study investigates the application of large language models (LLMs), specifically GPT-3.5 and GPT-4, with Chain-of-Though (CoT) in the automatic scoring of student-written responses to science assessments. We focused on overcoming the challenges of accessibility, technical complexity, and lack of explainability that have previously limited the use of artificial intelligence-based automatic scoring tools among researchers and educators. With a testing dataset comprising six assessment tasks (three binomial and three trinomial) with 1650 student responses, we employed six prompt engineering strategies to automatically score student responses. The six strategies combined zero-shot or few-shot learning with CoT, either alone or alongside item stem and scoring rubrics, developed based on a novel approach, WRVRT (prompt writing, reviewing, validating, revising, and testing). Results indicated that few-shot (acc = 0.67) outperformed zero-shot learning (acc = 0.60), with 12.6% increase. CoT, when used without item stem and scoring rubrics, did not significantly affect scoring accuracy (acc = 0.60). However, CoT prompting paired with contextual item stems and rubrics proved to be a significant contributor to scoring accuracy (13.44% increase for zero-shot; 3.7% increase for few-shot). We found a more balanced accuracy across different proficiency categories when CoT was used with a scoring rubric, highlighting the importance of domain-specific reasoning in enhancing the effectiveness of LLMs in scoring tasks. We also found that GPT-4 demonstrated superior performance over GPT -3.5 in various scoring tasks when combined with the single-call greedy sampling or ensemble voting nucleus sampling strategy, showing 8.64% difference. Particularly, the single-call greedy sampling strategy with GPT-4 outperformed other approaches. This study also demonstrates the potential of LLMs in facilitating explainable and interpretable automatic scoring, emphasizing that CoT enhances accuracy and transparency, particularly when used with item stem and scoring rubrics.","<method>large language models (LLMs)</method>, <method>GPT-3.5</method>, <method>GPT-4</method>, <method>Chain-of-Thought (CoT)</method>, <method>zero-shot learning</method>, <method>few-shot learning</method>, <method>prompt engineering strategies</method>, <method>WRVRT (prompt writing, reviewing, validating, revising, and testing)</method>, <method>single-call greedy sampling strategy</method>, <method>ensemble voting nucleus sampling strategy</method>",<method>GPT-3.5</method><method>GPT-4</method><method>Chain-of-Thought (CoT)</method><method>zero-shot learning</method><method>few-shot learning</method>
2024,https://openalex.org/W4391103530,Psychology,Transformative Breast Cancer Diagnosis using CNNs with Optimized ReduceLROnPlateau and Early Stopping Enhancements,"Abstract Breast cancer stands as a paramount public health concern worldwide, underscoring an imperative necessity within the research sphere for precision-driven and efficacious methodologies facilitating accurate detection. The existing diagnostic approaches in breast cancer often suffer from limitations in accuracy and efficiency, leading to delayed detection and subsequent challenges in personalized treatment planning. The primary focus of this research is to overcome these shortcomings by harnessing the power of advanced deep learning techniques, thereby revolutionizing the precision and reliability of breast cancer classification. This research addresses the critical need for improved breast cancer diagnostics by introducing a novel Convolutional Neural Network (CNN) model integrated with an Early Stopping callback and ReduceLROnPlateau callback. By enhancing the precision and reliability of breast cancer classification, the study aims to overcome the limitations of existing diagnostic methods, ultimately leading to better patient outcomes and reduced mortality rates. The comprehensive methodology includes diverse datasets, meticulous image preprocessing, robust model training, and validation strategies, emphasizing the model's adaptability and reliability in varied clinical contexts. The findings showcase the CNN model's exceptional performance, achieving a 95.2% accuracy rate in distinguishing cancerous and non-cancerous breast tissue in the integrated dataset, thereby demonstrating its potential for enhancing clinical decision-making and fostering the development of AI-driven diagnostic solutions.","<method>Convolutional Neural Network (CNN)</method>, <method>Early Stopping callback</method>, <method>ReduceLROnPlateau callback</method>",<method>Convolutional Neural Network (CNN)</method><method>Early Stopping callback</method>
2024,https://openalex.org/W4392166859,Psychology,"Towards a New Conceptual Model of AI-Enhanced Learning for College Students: The Roles of Artificial Intelligence Capabilities, General Self-Efficacy, Learning Motivation, and Critical Thinking Awareness","In the aftermath of the COVID-19 pandemic, college students have faced various challenges that could negatively impact their critical thinking abilities due to disruptions to education, increased stress and anxiety, less social interaction, and the advancement of distance learning relying more heavily on digital tools. With the increasing integration of AI technology across sectors, higher education institutions have deployed various AI capabilities for intelligent campuses and modernized teaching. However, how to fully utilize AI capabilities to promote students’ thinking awareness on learning effectiveness is still not clear, as critical thinking is an essential skill set holding significant implications for college students’ development. This research adopts the resource-based theory (RBT) to conceptualize the university as a unified entity of artificial intelligence (AI) resources. It aims to investigate whether AI capabilities can foster critical thinking awareness among students by enhancing general self-efficacy and learning motivation. In particular, it examines the causal relationships between AI capabilities, general self-efficacy, motivation and critical thinking awareness. Primary data was collected through a questionnaire administered to 637 college students. Structural equation modeling was employed to test hypotheses pertaining to causality. The results showed that AI capabilities could indirectly enhance students’ critical thinking awareness by strengthening general self-efficacy and learning motivation, but the effect on critical thinking awareness was not significant. Meanwhile, general self-efficacy significantly affected the formation of learning motivation and critical thinking awareness. This indicates that AI capabilities are able to reshape the cognitive learning process, but its direct influence on thinking awareness needs to be viewed with caution. This study explored the role of AI capabilities in education from the perspective of organizational capabilities. It not only proves how AI facilitates cognition, but also discovered the important mediating role of general self-efficacy and motivation in this process. This finding explains the inherent connections between the mechanism links. Furthermore, the study expands research on AI capabilities research from the technical level to the educational field. It provides a comprehensive and in-depth theoretical explanation theoretically, guiding the practice and application of AI in education. The study is of positive significance for understanding the need for the future development of the cultivation of critical thinking awareness talents needed for future development through AI capabilities in education.",<method>Structural equation modeling</method>,No methods remaining
2024,https://openalex.org/W4394681533,Psychology,REVIEWING THE IMPACT OF HEALTH INFORMATION TECHNOLOGY ON HEALTHCARE MANAGEMENT EFFICIENCY,"This research paper explores the intricate relationship between Health Information Technology (HIT) and healthcare management efficiency, investigating current trends, emerging technologies, and their potential implications. The study encompasses a thorough literature review, highlighting the impact of HIT on operational and clinical aspects of healthcare delivery. Key findings reveal the transformative role of technology in streamlining administrative processes, improving communication, and enhancing overall patient care. Ethical considerations, patient privacy, and regulation compliance are crucial factors in successfully implementing HIT. Looking towards the future, the paper anticipates the integration of emerging technologies such as Artificial Intelligence, Blockchain, and the Internet of Things, signalling a paradigm shift in healthcare management. While acknowledging the potential benefits, the research also underscores the importance of ethical frameworks, transparency, and user-centred design in adopting these technologies. The study concludes with reflections on the limitations of the research, suggesting avenues for future exploration. Recommendations emphasize the need for ongoing research, longitudinal studies, and a global perspective to ensure healthcare organizations effectively leverage technology while maintaining ethical standards. The findings of this research carry implications for healthcare practitioners, policymakers, and technology innovators, encouraging a strategic and ethical approach to the ever-evolving landscape of health information technology.&#x0D; Keywords: Health Information Technology, Healthcare Management Efficiency, Emerging Technologies, Ethical Considerations, Patient Privacy.",<method>Artificial Intelligence</method>,No methods remaining
2024,https://openalex.org/W4402780379,Psychology,Investigating Spatial Effects through Machine Learning and Leveraging Explainable AI for Child Malnutrition in Pakistan,"While socioeconomic gradients in regional health inequalities are firmly established, the synergistic interactions between socioeconomic deprivation and climate vulnerability within convenient proximity and neighbourhood locations with health disparities remain poorly explored and thus require deep understanding within a regional context. Furthermore, disregarding the importance of spatial spillover effects and nonlinear effects of covariates on childhood stunting are inevitable in dealing with an enduring issue of regional health inequalities. The present study aims to investigate the spatial inequalities in childhood stunting at the district level in Pakistan and validate the importance of spatial lag in predicting childhood stunting. Furthermore, it examines the presence of any nonlinear relationships among the selected independent features with childhood stunting. The study utilized data related to socioeconomic features from MICS 2017–2018 and climatic data from Integrated Contextual Analysis. A multi-model approach was employed to address the research questions, which included Ordinary Least Squares Regression (OLS), various Spatial Models, Machine Learning Algorithms and Explainable Artificial Intelligence methods. Firstly, OLS was used to analyse and test the linear relationships among selected variables. Secondly, Spatial Durbin Error Model (SDEM) was used to detect and capture the impact of spatial spillover on childhood stunting. Third, XGBoost and Random Forest machine learning algorithms were employed to examine and validate the importance of the spatial lag component. Finally, EXAI methods such as SHapley were utilized to identify potential nonlinear relationships. The study found a clear pattern of spatial clustering and geographical disparities in childhood stunting, with multidimensional poverty, high climate vulnerability and early marriage worsening childhood stunting. In contrast, low climate vulnerability, high exposure to mass media and high women’s literacy were found to reduce childhood stunting. The use of machine learning algorithms, specifically XGBoost and Random Forest, highlighted the significant role played by the average value in the neighbourhood in predicting childhood stunting in nearby districts, confirming that the spatial spillover effect is not bounded by geographical boundaries. Furthermore, EXAI methods such as partial dependency plot reveal the existence of a nonlinear relationship between multidimensional poverty and childhood stunting. The study’s findings provide valuable insights into the spatial distribution of childhood stunting in Pakistan, emphasizing the importance of considering spatial effects in predicting childhood stunting. Individual and household-level factors such as exposure to mass media and women’s literacy have shown positive implications for childhood stunting. It further provides a justification for the usage of EXAI methods to draw better insights and propose customised intervention policies accordingly.","<method>Ordinary Least Squares Regression (OLS)</method>, <method>Spatial Durbin Error Model (SDEM)</method>, <method>XGBoost</method>, <method>Random Forest</method>, <method>Explainable Artificial Intelligence (EXAI) methods</method>, <method>SHapley</method>, <method>partial dependency plot</method>",<method>XGBoost</method><method>Random Forest</method><method>partial dependency plot</method>
2024,https://openalex.org/W4390659289,Psychology,Cognition-Driven Structural Prior for Instance-Dependent Label Transition Matrix Estimation,"The label transition matrix has emerged as a widely accepted method for mitigating label noise in machine learning. In recent years, numerous studies have centered on leveraging deep neural networks to estimate the label transition matrix for individual instances within the context of instance-dependent noise. However, these methods suffer from low search efficiency due to the large space of feasible solutions. Behind this drawback, we have explored that the real murderer lies in the invalid class transitions, that is, the actual transition probability between certain classes is zero but is estimated to have a certain value. To mask the <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">invalid class transitions</i> , we introduced a human-cognition-assisted method with structural information from human cognition. Specifically, we introduce a structured transition matrix network ( <bold xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">STMN</b> ) designed with an adversarial learning process to balance instance features and prior information from human cognition. The proposed method offers two advantages: 1) better estimation effectiveness is obtained by sparing the transition matrix and 2) better estimation accuracy is obtained with the assistance of human cognition. By exploiting these two advantages, our method parametrically estimates a sparse label transition matrix, effectively converting noisy labels into true labels. The efficiency and superiority of our proposed method are substantiated through comprehensive comparisons with state-of-the-art methods on three synthetic datasets and a real-world dataset. Our code will be available at https://github.com/WheatCao/STMN-Pytorch.","<method>label transition matrix</method>, <method>deep neural networks</method>, <method>human-cognition-assisted method</method>, <method>structured transition matrix network (STMN)</method>, <method>adversarial learning process</method>",<method>deep neural networks</method><method>adversarial learning process</method>
2024,https://openalex.org/W4391107516,Psychology,Multiple Classification of Brain MRI Autism Spectrum Disorder by Age and Gender Using Deep Learning,"Abstract The fact that the rapid and definitive diagnosis of autism cannot be made today and that autism cannot be treated provides an impetus to look into novel technological solutions. To contribute to the resolution of this problem through multiple classifications by considering age and gender factors, in this study, two quadruple and one octal classifications were performed using a deep learning (DL) approach. Gender in one of the four classifications and age groups in the other were considered. In the octal classification, classes were created considering gender and age groups. In addition to the diagnosis of ASD (Autism Spectrum Disorders), another goal of this study is to find out the contribution of gender and age factors to the diagnosis of ASD by making multiple classifications based on age and gender for the first time. Brain structural MRI (sMRI) scans of participators with ASD and TD (Typical Development) were pre-processed in the system originally designed for this purpose. Using the Canny Edge Detection (CED) algorithm, the sMRI image data was cropped in the data pre-processing stage, and the data set was enlarged five times with the data augmentation (DA) techniques. The most optimal convolutional neural network (CNN) models were developed using the grid search optimization (GSO) algorism. The proposed DL prediction system was tested with the five-fold cross-validation technique. Three CNN models were designed to be used in the system. The first of these models is the quadruple classification model created by taking gender into account (model 1), the second is the quadruple classification model created by taking into account age (model 2), and the third is the eightfold classification model created by taking into account both gender and age (model 3). ). The accuracy rates obtained for all three designed models are 80.94, 85.42 and 67.94, respectively. These obtained accuracy rates were compared with pre-trained models by using the transfer learning approach. As a result, it was revealed that age and gender factors were effective in the diagnosis of ASD with the system developed for ASD multiple classifications, and higher accuracy rates were achieved compared to pre-trained models.","<method>deep learning (DL) approach</method>, <method>Canny Edge Detection (CED) algorithm</method>, <method>data augmentation (DA) techniques</method>, <method>convolutional neural network (CNN) models</method>, <method>grid search optimization (GSO) algorithm</method>, <method>five-fold cross-validation technique</method>, <method>transfer learning approach</method>",<method>convolutional neural network (CNN) models</method><method>transfer learning approach</method>
2024,https://openalex.org/W4400461591,Psychology,Counterfactual Explanations and Algorithmic Recourses for Machine Learning: A Review,"Machine learning plays a role in many deployed decision systems, often in ways that are difficult or impossible to understand by human stakeholders. Explaining, in a human-understandable way, the relationship between the input and output of machine learning models is essential to the development of trustworthy machine learning based systems. A burgeoning body of research seeks to define the goals and methods of explainability in machine learning. In this article, we seek to review and categorize research on counterfactual explanations , a specific class of explanation that provides a link between what could have happened had input to a model been changed in a particular way. Modern approaches to counterfactual explainability in machine learning draw connections to the established legal doctrine in many countries, making them appealing to fielded systems in high-impact areas such as finance and healthcare. Thus, we design a rubric with desirable properties of counterfactual explanation algorithms and comprehensively evaluate all currently proposed algorithms against that rubric. Our rubric provides easy comparison and comprehension of the advantages and disadvantages of different approaches and serves as an introduction to major research themes in this field. We also identify gaps and discuss promising research directions in the space of counterfactual explainability.","<method>counterfactual explanations</method>, <method>counterfactual explanation algorithms</method>",<method>counterfactual explanations</method><method>counterfactual explanation algorithms</method>
2024,https://openalex.org/W4390629445,Psychology,Investigating pre-service teachers’ artificial intelligence perception from the perspective of planned behavior theory,"There is a need for teachers who are prepared to teach Artificial Intelligence (AI) across the K-12 learning contexts. Owing to the dearth of teacher education programmes on AI, it is helpful to explore factors to be considered in designing an effective AI programme for future teachers. We posit that understanding how to encourage pre-service teachers to learn AI is thus critical for practitioners and policymakers while designing effective instructional AI teacher education programmes. This exploratory study examined the perceptions of pre-service teachers and their behavioral intention to learn AI, by identifying factors that might affect learning and promoting AI in teacher preparation programmes. This study proposed a research model supported by the theory of planned behavior and expanded with other constructs. The factors that were examined include basic knowledge of AI, subjective norm, AI for social good, perceived self-efficacy, self-transcendent goals, personal relevance, AI anxiety, behavioral intention to learn AI, and actual learning of AI. Using a duly validated questionnaire, we surveyed 796 pre-service teachers in Nigerian Universities. Through structural equation modeling approach analyses, our proposed model explains about 79% of the variance in pre-service teachers' intention to learn AI. Basic knowledge and subjective norm were found to be the most important determinant in pre-service teachers' intention to learn AI. All our hypotheses were supported except for self-efficacy and personal relevance, personal relevance and social good, and behavioral intention and actual learning behavior. The findings provide practitioners, researchers, and policymakers with valuable information to consider in designing effective AI teacher education programmes.",<method>structural equation modeling</method>,No methods remaining
2024,https://openalex.org/W4391531220,Psychology,An Explainable AI Paradigm for Alzheimer’s Diagnosis Using Deep Transfer Learning,"Alzheimer’s disease (AD) is a progressive neurodegenerative disorder that affects millions of individuals worldwide, causing severe cognitive decline and memory impairment. The early and accurate diagnosis of AD is crucial for effective intervention and disease management. In recent years, deep learning techniques have shown promising results in medical image analysis, including AD diagnosis from neuroimaging data. However, the lack of interpretability in deep learning models hinders their adoption in clinical settings, where explainability is essential for gaining trust and acceptance from healthcare professionals. In this study, we propose an explainable AI (XAI)-based approach for the diagnosis of Alzheimer’s disease, leveraging the power of deep transfer learning and ensemble modeling. The proposed framework aims to enhance the interpretability of deep learning models by incorporating XAI techniques, allowing clinicians to understand the decision-making process and providing valuable insights into disease diagnosis. By leveraging popular pre-trained convolutional neural networks (CNNs) such as VGG16, VGG19, DenseNet169, and DenseNet201, we conducted extensive experiments to evaluate their individual performances on a comprehensive dataset. The proposed ensembles, Ensemble-1 (VGG16 and VGG19) and Ensemble-2 (DenseNet169 and DenseNet201), demonstrated superior accuracy, precision, recall, and F1 scores compared to individual models, reaching up to 95%. In order to enhance interpretability and transparency in Alzheimer’s diagnosis, we introduced a novel model achieving an impressive accuracy of 96%. This model incorporates explainable AI techniques, including saliency maps and grad-CAM (gradient-weighted class activation mapping). The integration of these techniques not only contributes to the model’s exceptional accuracy but also provides clinicians and researchers with visual insights into the neural regions influencing the diagnosis. Our findings showcase the potential of combining deep transfer learning with explainable AI in the realm of Alzheimer’s disease diagnosis, paving the way for more interpretable and clinically relevant AI models in healthcare.","<method>deep learning</method>, <method>explainable AI (XAI)</method>, <method>deep transfer learning</method>, <method>ensemble modeling</method>, <method>pre-trained convolutional neural networks (CNNs)</method>, <method>VGG16</method>, <method>VGG19</method>, <method>DenseNet169</method>, <method>DenseNet201</method>, <method>Ensemble-1 (VGG16 and VGG19)</method>, <method>Ensemble-2 (DenseNet169 and DenseNet201)</method>, <method>saliency maps</method>, <method>grad-CAM (gradient-weighted class activation mapping)</method>",<method>deep learning</method><method>explainable AI (XAI)</method><method>deep transfer learning</method><method>ensemble modeling</method><method>pre-trained convolutional neural networks (CNNs)</method><method>VGG16</method><method>VGG19</method><method>DenseNet169</method><method>DenseNet201</method><method>saliency maps</method><method>grad-CAM (gradient-weighted class activation mapping)</method>
2024,https://openalex.org/W4394785902,Psychology,"Evidence-based potential of generative artificial intelligence large language models in orthodontics: a comparative study of ChatGPT, Google Bard, and Microsoft Bing","Summary Background The increasing utilization of large language models (LLMs) in Generative Artificial Intelligence across various medical and dental fields, and specifically orthodontics, raises questions about their accuracy. Objective This study aimed to assess and compare the answers offered by four LLMs: Google’s Bard, OpenAI’s ChatGPT-3.5, and ChatGPT-4, and Microsoft’s Bing, in response to clinically relevant questions within the field of orthodontics. Materials and methods Ten open-type clinical orthodontics-related questions were posed to the LLMs. The responses provided by the LLMs were assessed on a scale ranging from 0 (minimum) to 10 (maximum) points, benchmarked against robust scientific evidence, including consensus statements and systematic reviews, using a predefined rubric. After a 4-week interval from the initial evaluation, the answers were reevaluated to gauge intra-evaluator reliability. Statistical comparisons were conducted on the scores using Friedman’s and Wilcoxon’s tests to identify the model providing the answers with the most comprehensiveness, scientific accuracy, clarity, and relevance. Results Overall, no statistically significant differences between the scores given by the two evaluators, on both scoring occasions, were detected, so an average score for every LLM was computed. The LLM answers scoring the highest, were those of Microsoft Bing Chat (average score = 7.1), followed by ChatGPT 4 (average score = 4.7), Google Bard (average score = 4.6), and finally ChatGPT 3.5 (average score 3.8). While Microsoft Bing Chat statistically outperformed ChatGPT-3.5 (P-value = 0.017) and Google Bard (P-value = 0.029), as well, and Chat GPT-4 outperformed Chat GPT-3.5 (P-value = 0.011), all models occasionally produced answers with a lack of comprehensiveness, scientific accuracy, clarity, and relevance. Limitations The questions asked were indicative and did not cover the entire field of orthodontics. Conclusions Language models (LLMs) show great potential in supporting evidence-based orthodontics. However, their current limitations pose a potential risk of making incorrect healthcare decisions if utilized without careful consideration. Consequently, these tools cannot serve as a substitute for the orthodontist’s essential critical thinking and comprehensive subject knowledge. For effective integration into practice, further research, clinical validation, and enhancements to the models are essential. Clinicians must be mindful of the limitations of LLMs, as their imprudent utilization could have adverse effects on patient care.",<method>large language models (LLMs)</method>,No methods remaining
2024,https://openalex.org/W4402827393,Psychology,Larger and more instructable language models become less reliable,"Abstract The prevailing methods to make large language models more powerful and amenable have been based on continuous scaling up (that is, increasing their size, data volume and computational resources 1 ) and bespoke shaping up (including post-filtering 2,3 , fine tuning or use of human feedback 4,5 ). However, larger and more instructable large language models may have become less reliable. By studying the relationship between difficulty concordance, task avoidance and prompting stability of several language model families, here we show that easy instances for human participants are also easy for the models, but scaled-up, shaped-up models do not secure areas of low difficulty in which either the model does not err or human supervision can spot the errors. We also find that early models often avoid user questions but scaled-up, shaped-up models tend to give an apparently sensible yet wrong answer much more often, including errors on difficult questions that human supervisors frequently overlook. Moreover, we observe that stability to different natural phrasings of the same question is improved by scaling-up and shaping-up interventions, but pockets of variability persist across difficulty levels. These findings highlight the need for a fundamental shift in the design and development of general-purpose artificial intelligence, particularly in high-stakes areas for which a predictable distribution of errors is paramount.","<method>continuous scaling up</method>, <method>post-filtering</method>, <method>fine tuning</method>, <method>use of human feedback</method>",<method>post-filtering</method><method>fine tuning</method><method>use of human feedback</method>
2024,https://openalex.org/W4391126287,Psychology,Evaluating the ChatGPT family of models for biomedical reasoning and classification,"Abstract Objective Large language models (LLMs) have shown impressive ability in biomedical question-answering, but have not been adequately investigated for more specific biomedical applications. This study investigates ChatGPT family of models (GPT-3.5, GPT-4) in biomedical tasks beyond question-answering. Materials and Methods We evaluated model performance with 11 122 samples for two fundamental tasks in the biomedical domain—classification (n = 8676) and reasoning (n = 2446). The first task involves classifying health advice in scientific literature, while the second task is detecting causal relations in biomedical literature. We used 20% of the dataset for prompt development, including zero- and few-shot settings with and without chain-of-thought (CoT). We then evaluated the best prompts from each setting on the remaining dataset, comparing them to models using simple features (BoW with logistic regression) and fine-tuned BioBERT models. Results Fine-tuning BioBERT produced the best classification (F1: 0.800-0.902) and reasoning (F1: 0.851) results. Among LLM approaches, few-shot CoT achieved the best classification (F1: 0.671-0.770) and reasoning (F1: 0.682) results, comparable to the BoW model (F1: 0.602-0.753 and 0.675 for classification and reasoning, respectively). It took 78 h to obtain the best LLM results, compared to 0.078 and 0.008 h for the top-performing BioBERT and BoW models, respectively. Discussion The simple BoW model performed similarly to the most complex LLM prompting. Prompt engineering required significant investment. Conclusion Despite the excitement around viral ChatGPT, fine-tuning for two fundamental biomedical natural language processing tasks remained the best strategy.","<method>ChatGPT family of models (GPT-3.5, GPT-4)</method>, <method>zero-shot prompting</method>, <method>few-shot prompting</method>, <method>chain-of-thought (CoT) prompting</method>, <method>Bag of Words (BoW) with logistic regression</method>, <method>fine-tuned BioBERT models</method>","<method>ChatGPT family of models (GPT-3.5, GPT-4)</method><method>zero-shot prompting</method><method>few-shot prompting</method><method>chain-of-thought (CoT) prompting</method><method>Bag of Words (BoW) with logistic regression</method><method>fine-tuned BioBERT models</method>"
2024,https://openalex.org/W4392285688,Psychology,Machine Learning and Digital Biomarkers Can Detect Early Stages of Neurodegenerative Diseases,"Neurodegenerative diseases (NDs) such as Alzheimer’s Disease (AD) and Parkinson’s Disease (PD) are devastating conditions that can develop without noticeable symptoms, causing irreversible damage to neurons before any signs become clinically evident. NDs are a major cause of disability and mortality worldwide. Currently, there are no cures or treatments to halt their progression. Therefore, the development of early detection methods is urgently needed to delay neuronal loss as soon as possible. Despite advancements in Medtech, the early diagnosis of NDs remains a challenge at the intersection of medical, IT, and regulatory fields. Thus, this review explores “digital biomarkers” (tools designed for remote neurocognitive data collection and AI analysis) as a potential solution. The review summarizes that recent studies combining AI with digital biomarkers suggest the possibility of identifying pre-symptomatic indicators of NDs. For instance, research utilizing convolutional neural networks for eye tracking has achieved significant diagnostic accuracies. ROC-AUC scores reached up to 0.88, indicating high model performance in differentiating between PD patients and healthy controls. Similarly, advancements in facial expression analysis through tools have demonstrated significant potential in detecting emotional changes in ND patients, with some models reaching an accuracy of 0.89 and a precision of 0.85. This review follows a structured approach to article selection, starting with a comprehensive database search and culminating in a rigorous quality assessment and meaning for NDs of the different methods. The process is visualized in 10 tables with 54 parameters describing different approaches and their consequences for understanding various mechanisms in ND changes. However, these methods also face challenges related to data accuracy and privacy concerns. To address these issues, this review proposes strategies that emphasize the need for rigorous validation and rapid integration into clinical practice. Such integration could transform ND diagnostics, making early detection tools more cost-effective and globally accessible. In conclusion, this review underscores the urgent need to incorporate validated digital health tools into mainstream medical practice. This integration could indicate a new era in the early diagnosis of neurodegenerative diseases, potentially altering the trajectory of these conditions for millions worldwide. Thus, by highlighting specific and statistically significant findings, this review demonstrates the current progress in this field and the potential impact of these advancements on the global management of NDs.",<method>convolutional neural networks</method>,<method>convolutional neural networks</method>
2024,https://openalex.org/W4390569131,Psychology,Rapport with a chatbot? The underlying role of anthropomorphism in socio-cognitive perceptions of rapport and e-word of mouth,"This study examines the impact of rapport with chatbots on electronic word of mouth (e-WOM), in the first phase, by considering several antecedents including anthropomorphism. In the second phase, deeper insights are provided into the moderated mediation role of rapport and the moderated moderation effect of value creation and hedonic motivation on e-WOM engagement. With tourism services as the research context, a survey was conducted among 257 visitors from three countries (China, India and New Zealand), selected due to their diverse cultural backgrounds and higher number of inbound visitors to Australia. The partial least squares method was used for data analysis along with multi-group analysis. Findings report the positive role of anthropomorphism in developing rapport with chatbots in digital interactions. Interestingly, rapport had the highest moderated mediation impact in the data from China followed by the data from India. The moderated moderation impact of hedonic motivation was only significant in the data from China, whereas value creation was a significant moderator in the data from both China and New Zealand. The study extends social exchange theory in a human–chatbot or artificial intelligence (AI) interaction context with cultural implications. The findings are useful for organizations relying on customer rapport with AI-based chatbots to ensure long-term customer service through digital interactions.","<method>partial least squares method</method>, <method>multi-group analysis</method>",No methods remaining
2024,https://openalex.org/W4390951664,Psychology,Economics students’ behavioural intention and usage of ChatGPT in higher education: a hybrid structural equation modelling-artificial neural network approach,"The Chat Generative Pre-Trained Transformer, popularly referred to as ChatGPT, is an AI-based technology with the potential to revolutionise conventional teaching and learning in higher education institutions (HEIs). However, it remains unclear which factors influence the behavioural intentions and the actual usage of ChatGPT among economics students in Ghanaian HEIs. In pursuit of this goal, we employed the extended Unified Theory of Acceptance and Use of Technology (UTAUT2) to gain a better understanding of the antecedents influencing the behavioural intentions and actual usage of ChatGPT among economics students. The study surveyed 306 Ghanaian students enrolled in economics at a public university. These students were aware of the existence of ChatGPT applications. We applied a hybrid analytical approach, combining structural equation modelling and artificial neural network (SEM-ANN), to elucidate the causal relationships between variables believed to impact perceived trust, intentions, and actual usage. The results showed that design and interactivity have a significant impact on perceived trust. Similarly, perceived trust, social influence, performance expectancy, hedonic motivation, and habits drive behavioural intentions. Among the various factors influencing behavioural intentions, hedonic motivation emerged as the most dominant. Moreover, behavioural intentions and facilitating conditions significantly drive students' actual use of the ChatGPT. Nevertheless, ethics is not a significant factor in perceived trust, and effort expectancy does not affect behavioral intention. These findings, however, offer theoretical and practical contributions that can serve as guide for a thoughtful and responsible integration of AI-based tools as a future strategy to enhance education accessibility and inclusivity opportunities","<method>structural equation modelling</method>, <method>artificial neural network (SEM-ANN)</method>",No methods remaining
2024,https://openalex.org/W4390987311,Psychology,Reliability of ChatGPT for performing triage task in the emergency department using the Korean Triage and Acuity Scale,"Background Artificial intelligence (AI) technology can enable more efficient decision-making in healthcare settings. There is a growing interest in improving the speed and accuracy of AI systems in providing responses for given tasks in healthcare settings. Objective This study aimed to assess the reliability of ChatGPT in determining emergency department (ED) triage accuracy using the Korean Triage and Acuity Scale (KTAS). Methods Two hundred and two virtual patient cases were built. The gold standard triage classification for each case was established by an experienced ED physician. Three other human raters (ED paramedics) were involved and rated the virtual cases individually. The virtual cases were also rated by two different versions of the chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0). Inter-rater reliability was examined using Fleiss’ kappa and intra-class correlation coefficient (ICC). Results The kappa values for the agreement between the four human raters and ChatGPTs were .523 (version 4.0) and .320 (version 3.5). Of the five levels, the performance was poor when rating patients at levels 1 and 5, as well as case scenarios with additional text descriptions. There were differences in the accuracy of the different versions of GPTs. The ICC between version 3.5 and the gold standard was .520, and that between version 4.0 and the gold standard was .802. Conclusions A substantial level of inter-rater reliability was revealed when GPTs were used as KTAS raters. The current study showed the potential of using GPT in emergency healthcare settings. Considering the shortage of experienced manpower, this AI method may help improve triaging accuracy.","<method>chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0)</method>","<method>chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0)</method>"
2024,https://openalex.org/W4391573023,Psychology,Deep Reinforcement Learning Unleashing the Power of AI in Decision-Making,"Deep Reinforcement Learning (DRL) has emerged as a transformative paradigm in the field of artificial intelligence (AI), offering unprecedented capabilities in decision-making across diverse domains. This article explores the profound impact of DRL on enhancing the decision-making capabilities of AI systems, elucidating its underlying principles, applications, and implications.DRL represents a fusion of deep learning and reinforcement learning, enabling machines to learn complex behaviors and make decisions by interacting with their environment. The utilization of neural networks allows DRL algorithms to handle high-dimensional input spaces, making it well-suited for tasks that involve intricate decision-making processes.One of the key strengths of DRL lies in its ability to address problems with sparse and delayed rewards, common challenges in traditional reinforcement learning. Through a process of trial and error, DRL algorithms can learn optimal decision strategies by navigating through a vast decision space, adapting to dynamic environments, and maximizing cumulative rewards over time.The applications of DRL span various domains, including robotics, finance, healthcare, gaming, and autonomous systems. In robotics, DRL facilitates the development of intelligent agents capable of autonomously navigating complex environments, performing intricate tasks, and adapting to unforeseen circumstances. In finance, DRL is leveraged for portfolio optimization, algorithmic trading, and risk management, demonstrating its potential to revolutionize traditional financial strategies.","<method>Deep Reinforcement Learning (DRL)</method>, <method>deep learning</method>, <method>reinforcement learning</method>",<method>Deep Reinforcement Learning (DRL)</method><method>deep learning</method><method>reinforcement learning</method>
2024,https://openalex.org/W4396712983,Psychology,3WC-GBNRS++: A novel three-way classifier with granular-ball neighborhood rough sets based on uncertainty,"Three-way decision with neighborhood rough sets (3WDNRS) is adept at addressing uncertain problems involving continuous data by configuring the neighborhood radius. However, on one hand, the inputs of 3WDNRS are individual neighborhood granules, which reduce the decision efficiency and generality; on other hand, the thresholds of 3WDNRS require prior knowledge to be approximately set in advance, making it difficult to apply in cases where such knowledge is unavailable. To address these issues, we introduce granular-ball computing (GBC) into 3WDNRS from the perspective of uncertainty. Firstly, we propose an enhanced granular-ball generation method based on DBSCAN called DBGBC. Subsequently, we present an improved granular-ball neighborhood rough sets model (GBNRS++) by combining DBGBC with a quality index. Furthermore, we construct a three-way classifier with granular-ball neighborhood rough sets (3WC-GBNRS++) based on the principle of minimum fuzziness loss. This approach provides an objective and efficient way to determine the thresholds. To further enhance classification accuracy, we design an adaptive granular-ball neighborhood within the subsequent classification process of 3WC-GBNRS++. Finally, experimental results demonstrate that, 3WC-GBNRS++ almost outperformed other comparison methods in terms of effectiveness and robustness, including 4 state-of-the-art granular-balls-based classifiers and 5 classical machine learning classifiers on 12 public benchmark datasets. Moreover, we discuss the limitations of our work and the outlook for future research.","<method>three-way decision with neighborhood rough sets (3WDNRS)</method>, <method>granular-ball computing (GBC)</method>, <method>DBSCAN</method>, <method>granular-ball neighborhood rough sets model (GBNRS++)</method>, <method>three-way classifier with granular-ball neighborhood rough sets (3WC-GBNRS++)</method>, <method>adaptive granular-ball neighborhood</method>",<method>three-way decision with neighborhood rough sets (3WDNRS)</method><method>DBSCAN</method>
2024,https://openalex.org/W4396723505,Psychology,MentaLLaMA: Interpretable Mental Health Analysis on Social Media with Large Language Models,"As an integral part of people's daily lives, social media is becoming a rich source for automatic mental health analysis.As traditional discriminative methods bear poor generalization ability and low interpretability, the recent large language models (LLMs) have been explored for interpretable mental health analysis on social media, which aims to provide detailed explanations along with predictions in zero-shot or few-shot settings.The results show that LLMs still achieve unsatisfactory classification performance in a zero-shot/few-shot manner, which further significantly affects the quality of the generated explanations.Domain-specific finetuning is an effective solution, but faces two critical challenges: 1) lack of high-quality training data.2) no open-source foundation LLMs.To alleviate these problems, we formally model interpretable mental health analysis as a text generation task, and build the first multi-task and multi-source interpretable mental health instruction (IMHI) dataset with 105K data samples to support LLM instruction tuning and evaluation.The raw social media data are collected from 10 existing sources covering 8 mental health analysis tasks.We prompt ChatGPT with expert-designed few-shot prompts to obtain explanations.To ensure the reliability of the explanations, we perform strict automatic and human evaluations on the correctness, consistency, and quality of generated data.Based on the IMHI dataset and LLaMA2 foundation models, we train MentaLLaMA, the first open-source instruction-following LLM series for interpretable mental health analysis on social media.We evaluate Men-taLLaMA and other advanced methods on the IMHI benchmark, the first holistic evaluation benchmark for interpretable mental health analysis.The results show that MentaLLaMA approaches state-of-the-art discriminative methods in correctness and generates human-level explanations.MentaLLaMA models also show strong generalizability to unseen tasks.The project is available at https://github.com/SteveKGYang/MentaLLaMA.","<method>large language models (LLMs)</method>, <method>zero-shot learning</method>, <method>few-shot learning</method>, <method>domain-specific finetuning</method>, <method>instruction tuning</method>, <method>instruction-following large language models</method>",<method>zero-shot learning</method><method>few-shot learning</method><method>domain-specific finetuning</method><method>instruction tuning</method>
2024,https://openalex.org/W4400015499,Psychology,Building entrepreneurial resilience during crisis using generative AI: An empirical study on SMEs,"Recently, Gen AI has garnered significant attention across various sectors of society, particularly capturing the interest of small business due to its capacity to allow them to reassess their business models with minimal investment. To understand how small and medium-sized firms have utilised Gen AI-based tools to cope with the market's high level of turbulence caused by the COVID-19 pandemic, geopolitical crises, and economic slowdown, researchers have conducted an empirical study. Although Gen AI is receiving more attention, there remains a dearth of empirical studies that investigate how it influences the entrepreneurial orientation of firms and their ability to cultivate entrepreneurial resilience amidst market turbulence. Most of the literature offers anecdotal evidence. To address this research gap, the authors have grounded their theoretical model and research hypotheses in the contingent view of dynamic capability. They tested the research hypotheses using cross-sectional data from a pre-tested survey instrument, which yielded 87 useable responses from small and medium enterprises in France. The authors used variance-based structural equation modelling with the commercial WarpPLS 7.0 software to test the theoretical model. The study's findings suggest that Gen AI and EO have a significant influence on building entrepreneurial resilience as higher-order and lower-order dynamic capabilities. However, market turbulence has a negative moderating effect on the path that joins entrepreneurial orientation and entrepreneurial resilience. The results suggest that the assumption that high market turbulence will have positive effects on dynamic capabilities and competitive advantage is not always true, and the linear assumption does not hold, which is consistent with some scholars' assumptions. The study's results offer significant contributions to the contingent view of dynamic capabilities and open new research avenues that require further investigation into the non-linear relationship of market turbulence.",<method>variance-based structural equation modelling</method>,No methods remaining
2024,https://openalex.org/W4397026358,Psychology,Automated Classification of Cognitive Visual Objects Using Multivariate Swarm Sparse Decomposition From Multichannel EEG-MEG Signals,"In visual object decoding, magnetoencephalogram (MEG) and electroencephalogram (EEG) activation patterns demonstrate the utmost discriminative cognitive analysis due to their multivariate oscillatory nature. However, high noise in the recorded EEG-MEG signals and subject-specific variability make it extremely difficult to classify subject's cognitive responses to different visual stimuli. The proposed method is a multivariate extension of the swarm sparse decomposition method (MSSDM) for multivariate pattern analysis of EEG-MEG-based visual activation signals. In comparison, it is an advanced technique for decomposing nonstationary multicomponent signals into a finite number of channel-aligned oscillatory components that significantly enhance visual activation-related sub-bands. The MSSDM method adopts multivariate swarm filtering and sparse spectrum to automatically deliver optimal frequency bands in channel-specific sparse spectrums, resulting in improved filter banks. By combining the advantages of the multivariate SSDM and Riemann's correlation-assisted fusion feature (RCFF), the MSSDM-RCFF algorithm is investigated to improve the visual object recognition ability of EEG-MEG signals. We have also proposed time–frequency representation based on MSSDM to analyze discriminative cognitive patterns of different visual object classes from multichannel EEG-MEG signals. A proposed MSSDM is evaluated on multivariate synthetic signals and multivariate EEG-MEG signals using five classifiers. The proposed fusion feature and linear discriminant analysis classifier-based framework outperformed all existing state-of-the-art methods used for visual object detection and achieved the highest accuracy of 86.42% using tenfold cross-validation on EEG-MEG multichannel signals.","<method>swarm sparse decomposition method (MSSDM)</method>, <method>multivariate swarm filtering</method>, <method>sparse spectrum</method>, <method>Riemann's correlation-assisted fusion feature (RCFF)</method>, <method>MSSDM-RCFF algorithm</method>, <method>time–frequency representation based on MSSDM</method>, <method>linear discriminant analysis classifier</method>",<method>sparse spectrum</method><method>linear discriminant analysis classifier</method>
2024,https://openalex.org/W4391345489,Psychology,CLARUS: An interactive explainable AI platform for manual counterfactuals in graph neural networks,"Lack of trust in artificial intelligence (AI) models in medicine is still the key blockage for the use of AI in clinical decision support systems (CDSS). Although AI models are already performing excellently in systems medicine, their black-box nature entails that patient-specific decisions are incomprehensible for the physician. Explainable AI (XAI) algorithms aim to ""explain"" to a human domain expert, which input features influenced a specific recommendation. However, in the clinical domain, these explanations must lead to some degree of causal understanding by a clinician. We developed the CLARUS platform, aiming to promote human understanding of graph neural network (GNN) predictions. CLARUS enables the visualisation of patient-specific networks, as well as, relevance values for genes and interactions, computed by XAI methods, such as GNNExplainer. This enables domain experts to gain deeper insights into the network and more importantly, the expert can interactively alter the patient-specific network based on the acquired understanding and initiate re-prediction or retraining. This interactivity allows us to ask manual counterfactual questions and analyse the effects on the GNN prediction. We present the first interactive XAI platform prototype, CLARUS, that allows not only the evaluation of specific human counterfactual questions based on user-defined alterations of patient networks and a re-prediction of the clinical outcome but also a retraining of the entire GNN after changing the underlying graph structures. The platform is currently hosted by the GWDG on https://rshiny.gwdg.de/apps/clarus/.","<method>graph neural network (GNN)</method>, <method>Explainable AI (XAI) algorithms</method>, <method>GNNExplainer</method>",<method>graph neural network (GNN)</method><method>GNNExplainer</method>
2024,https://openalex.org/W4400134137,Psychology,Computational intelligence-based classification system for the diagnosis of memory impairment in psychoactive substance users,"Abstract Computational intelligence techniques have emerged as a promising approach for diagnosing various medical conditions, including memory impairment. Increased abuse of psychoactive drugs poses a global public health burden, as repeated exposure to these substances can cause neurodegeneration, premature aging, and negatively affect memory impairment. Many studies in the literature relied on statistical studies, but they remained inaccurate. Some studies relied on physical data because the time factor was not considered, until Artificial Intelligence (AI) techniques came along that proved their worth in this diagnosis. The variable deep neural network method was used to adapt to the intermediate results and re-process the intermediate in case the result is undesirable. Computational intelligence was used in this study to classify a brain image from MRI or CT scans and to show the effectiveness of the dose ratio on health with treatment time, and to diagnose memory impairment in users of psychoactive substances. Understanding the neurotoxic profiles of psychoactive substances and the underlying pathways is hypothesized to be of great importance in improving the risk assessment and treatment of substance use disorders. The results proved the worth of the proposed method in terms of the accuracy of recognition rate as well as the possibility of diagnosis. It can be concluded that the diagnostic efficiency is increased by increasing the number of hidden layers in the neural network and controlling the weights and variables that control the deep learning algorithm. Thus, we conclude that good classification in this field may save human life or early detection of memory impairment.","<method>variable deep neural network method</method>, <method>computational intelligence</method>, <method>deep learning algorithm</method>",No methods remaining
2024,https://openalex.org/W4400981456,Psychology,Multimodal data integration for oncology in the era of deep neural networks: a review,"Cancer research encompasses data across various scales, modalities, and resolutions, from screening and diagnostic imaging to digitized histopathology slides to various types of molecular data and clinical records. The integration of these diverse data types for personalized cancer care and predictive modeling holds the promise of enhancing the accuracy and reliability of cancer screening, diagnosis, and treatment. Traditional analytical methods, which often focus on isolated or unimodal information, fall short of capturing the complex and heterogeneous nature of cancer data. The advent of deep neural networks has spurred the development of sophisticated multimodal data fusion techniques capable of extracting and synthesizing information from disparate sources. Among these, Graph Neural Networks (GNNs) and Transformers have emerged as powerful tools for multimodal learning, demonstrating significant success. This review presents the foundational principles of multimodal learning including oncology data modalities, taxonomy of multimodal learning, and fusion strategies. We delve into the recent advancements in GNNs and Transformers for the fusion of multimodal data in oncology, spotlighting key studies and their pivotal findings. We discuss the unique challenges of multimodal learning, such as data heterogeneity and integration complexities, alongside the opportunities it presents for a more nuanced and comprehensive understanding of cancer. Finally, we present some of the latest comprehensive multimodal pan-cancer data sources. By surveying the landscape of multimodal data integration in oncology, our goal is to underline the transformative potential of multimodal GNNs and Transformers. Through technological advancements and the methodological innovations presented in this review, we aim to chart a course for future research in this promising field. This review may be the first that highlights the current state of multimodal modeling applications in cancer using GNNs and transformers, presents comprehensive multimodal oncology data sources, and sets the stage for multimodal evolution, encouraging further exploration and development in personalized cancer care.","<method>deep neural networks</method>, <method>Graph Neural Networks (GNNs)</method>, <method>Transformers</method>",<method>deep neural networks</method><method>Graph Neural Networks (GNNs)</method><method>Transformers</method>
2024,https://openalex.org/W4391774550,Psychology,Role of machine learning and deep learning techniques in EEG-based BCI emotion recognition system: a review,"Abstract Emotion is a subjective psychophysiological reaction coming from external stimuli which impacts every aspect of our daily lives. Due to the continuing development of non-invasive and portable sensor technologies, such as brain-computer interfaces (BCI), intellectuals from several fields have been interested in emotion recognition techniques. Human emotions can be recognised using a variety of behavioural cues, including gestures and body language, voice, and physiological markers. The first three, however, might be ineffective because people sometimes conceal their genuine emotions either intentionally or unknowingly. More precise and objective emotion recognition can be accomplished using physiological signals. Among other physiological signals, Electroencephalogram (EEG) is more responsive and sensitive to variation in affective states. Various EEG-based emotion recognition methods have recently been introduced. This study reviews EEG-based BCIs for emotion identification and gives an outline of the progress made in this field. A summary of the datasets and techniques utilised to evoke human emotions and various emotion models is also given. We discuss several EEG feature extractions, feature selection/reduction, machine learning, and deep learning algorithms in accordance with standard emotional identification process. We provide an overview of the human brain's EEG rhythms, which are closely related to emotional states. We also go over a number of EEG-based emotion identification research and compare numerous machine learning and deep learning techniques. In conclusion, this study highlights the applications, challenges and potential areas for future research in identification and classification of human emotional states.","<method>feature extraction</method>, <method>feature selection/reduction</method>, <method>machine learning algorithms</method>, <method>deep learning algorithms</method>",<method>feature selection/reduction</method>
2024,https://openalex.org/W4401434014,Psychology,Crafting personalized learning paths with AI for lifelong learning: a systematic literature review,"The rapid evolution of knowledge requires constantly acquiring and updating skills, making lifelong learning crucial. Despite decades of artificial intelligence, recent advances promote new solutions to personalize learning in this context. The purpose of this article is to explore the current state of research on the development of artificial intelligence-mediated solutions for the design of personalized learning paths. To achieve this, a systematic literature review (SRL) of 78 articles published between 2019 and 2024 from the Scopus and Web or Science databases was conducted, answering seven questions grouped into three themes: characteristics of the published research, context of the research, and type of solution analyzed. This study identified that: (a) the greatest production of scientific research on the topic is developed in China, India and the United States, (b) the focus is mainly directed towards the educational context at the higher education level with areas of opportunity for application in the work context, and (c) the development of adaptive learning technologies predominates; however, there is a growing interest in the application of generative language models. This article contributes to the growing interest and literature related to personalized learning under artificial intelligence mediated solutions that will serve as a basis for academic institutions and organizations to design programs under this model.","<method>adaptive learning technologies</method>, <method>generative language models</method>",<method>generative language models</method>
2024,https://openalex.org/W4390777660,Psychology,Unlocking the Potential of XAI for Improved Alzheimer’s Disease Detection and Classification Using a ViT-GRU Model,"Alzheimer's Disease (AD) is a significant cause of dementia worldwide, and its progression from mild to severe affects an individual's ability to perform daily activities independently. The accurate and early diagnosis of AD is crucial for effective clinical intervention. However, interpreting AD from medical images can be challenging, even for experienced radiologists. Therefore, there is a need for an automatic diagnosis of AD, and researchers have investigated the potential of utilizing Artificial Intelligence (AI) techniques, particularly deep learning models, to address this challenge. This study proposes a framework that combines a Vision Transformer (ViT) and a Gated Recurrent Unit (GRU) to detect AD characteristics from Magnetic Resonance Imaging (MRI) images accurately and reliably. The ViT identifies crucial features from the input image, and the GRU establishes clear correlations between these features. The proposed model overcomes the class imbalance issue in the MRI image dataset and achieves superior accuracy and performance compared to existing methods. The model was trained on the Alzheimer's MRI Preprocessed Dataset obtained from Kaggle, achieving notable accuracies of 99.53% for 4-class and 99.69% for binary classification. It also demonstrated a high accuracy of 99.26% for 3-class on the AD Neuroimaging Initiative (ADNI) Baseline Database. These results were validated through a thorough 10-fold cross-validation process. Furthermore, Explainable AI (XAI) techniques were incorporated to make the model interpretable and explainable. This allows clinicians to understand the model's decision-making process and gain insights into the underlying factors driving the AD diagnosis.","<method>Vision Transformer (ViT)</method>, <method>Gated Recurrent Unit (GRU)</method>, <method>Explainable AI (XAI) techniques</method>",<method>Vision Transformer (ViT)</method><method>Gated Recurrent Unit (GRU)</method>
2024,https://openalex.org/W4391325398,Psychology,A fast and robust method for detecting trend turning points in InSAR displacement time series,"Ground deformation monitoring is a crucial task in geohazard management to ensure the safety of lives and infrastructure. Persistent scatterer interferometric synthetic aperture radar (PS-InSAR) is an advanced technique for measuring small displacements on the Earth's surface. Estimated PS-InSAR time series acquired by Sentinel-1 satellites provide a great opportunity for effective monitoring of ground deformation in recent years. However, challenges arise when processing these time series due to their non-uniform sampling, noise from atmosphere and preprocessing issues including phase unwrapping and others. Therefore, estimating the location and direction of trend turning in such time series, as an indicator of ground deformation, is not an easy task. In this work, a sequential turning point detection method (STPD) is proposed and compared with other change point detection methods. Using a large set of simulated time series with various noise types, it is shown that STPD outperforms other methods in terms of overall accuracy and root mean square error for location and direction of trend turnings. As a case study, STPD is applied to detect turning points within PS-InSAR time series for the province of Frosinone in Italy and classified using topography and land cover/use. In addition, an area susceptible to landslides is selected to estimate the starting dates of potential slow-moving landslides. It is also shown that the turning points in the local precipitation time series have a high correlation with the ones in the PS-InSAR time series, indicating that precipitation is a major triggering factor of the displacements in the area. The STPD can rapidly and effectively detect locations and directions of trend turnings and is freely available online in both MATLAB and python.","<method>sequential turning point detection method (STPD)</method>, <method>change point detection methods</method>",<method>change point detection methods</method>
2024,https://openalex.org/W4391810207,Psychology,Machine Learning–Based Prediction of Suicidality in Adolescents With Allergic Rhinitis: Derivation and Validation in 2 Independent Nationwide Cohorts,"Background Given the additional risk of suicide-related behaviors in adolescents with allergic rhinitis (AR), it is important to use the growing field of machine learning (ML) to evaluate this risk. Objective This study aims to evaluate the validity and usefulness of an ML model for predicting suicide risk in patients with AR. Methods We used data from 2 independent survey studies, Korea Youth Risk Behavior Web-based Survey (KYRBS; n=299,468) for the original data set and Korea National Health and Nutrition Examination Survey (KNHANES; n=833) for the external validation data set, to predict suicide risks of AR in adolescents aged 13 to 18 years, with 3.45% (10,341/299,468) and 1.4% (12/833) of the patients attempting suicide in the KYRBS and KNHANES studies, respectively. The outcome of interest was the suicide attempt risks. We selected various ML-based models with hyperparameter tuning in the discovery and performed an area under the receiver operating characteristic curve (AUROC) analysis in the train, test, and external validation data. Results The study data set included 299,468 (KYRBS; original data set) and 833 (KNHANES; external validation data set) patients with AR recruited between 2005 and 2022. The best-performing ML model was the random forest model with a mean AUROC of 84.12% (95% CI 83.98%-84.27%) in the original data set. Applying this result to the external validation data set revealed the best performance among the models, with an AUROC of 89.87% (sensitivity 83.33%, specificity 82.58%, accuracy 82.59%, and balanced accuracy 82.96%). While looking at feature importance, the 5 most important features in predicting suicide attempts in adolescent patients with AR are depression, stress status, academic achievement, age, and alcohol consumption. Conclusions This study emphasizes the potential of ML models in predicting suicide risks in patients with AR, encouraging further application of these models in other conditions to enhance adolescent health and decrease suicide rates.",<method>random forest</method>,<method>random forest</method>
2024,https://openalex.org/W4393222196,Psychology,Finding the Right XAI Method—A Guide for the Evaluation and Ranking of Explainable AI Methods in Climate Science,"Abstract Explainable artificial intelligence (XAI) methods shed light on the predictions of machine learning algorithms. Several different approaches exist and have already been applied in climate science. However, usually missing ground truth explanations complicate their evaluation and comparison, subsequently impeding the choice of the XAI method. Therefore, in this work, we introduce XAI evaluation in the climate context and discuss different desired explanation properties, namely, robustness, faithfulness, randomization, complexity, and localization. To this end, we chose previous work as a case study where the decade of annual-mean temperature maps is predicted. After training both a multilayer perceptron (MLP) and a convolutional neural network (CNN), multiple XAI methods are applied and their skill scores in reference to a random uniform explanation are calculated for each property. Independent of the network, we find that XAI methods such as Integrated Gradients, layerwise relevance propagation, and input times gradients exhibit considerable robustness, faithfulness, and complexity while sacrificing randomization performance. Sensitivity methods, gradient, SmoothGrad, NoiseGrad, and FusionGrad, match the robustness skill but sacrifice faithfulness and complexity for the randomization skill. We find architecture-dependent performance differences regarding robustness, complexity, and localization skills of different XAI methods, highlighting the necessity for research task-specific evaluation. Overall, our work offers an overview of different evaluation properties in the climate science context and shows how to compare and benchmark different explanation methods, assessing their suitability based on strengths and weaknesses, for the specific research problem at hand. By that, we aim to support climate researchers in the selection of a suitable XAI method. Significance Statement Explainable artificial intelligence (XAI) helps to understand the reasoning behind the prediction of a neural network. XAI methods have been applied in climate science to validate networks and provide new insight into physical processes. However, the increasing number of XAI methods can overwhelm practitioners, making it difficult to choose an explanation method. Since XAI methods’ results can vary, uninformed choices might cause misleading conclusions about the network decision. In this work, we introduce XAI evaluation to compare and assess the performance of explanation methods based on five desirable properties. We demonstrate that XAI evaluation reveals the strengths and weaknesses of different XAI methods. Thus, our work provides climate researchers with the tools to compare, analyze, and subsequently choose explanation methods.","<method>multilayer perceptron (MLP)</method>, <method>convolutional neural network (CNN)</method>, <method>Integrated Gradients</method>, <method>layerwise relevance propagation</method>, <method>input times gradients</method>, <method>gradient</method>, <method>SmoothGrad</method>, <method>NoiseGrad</method>, <method>FusionGrad</method>",<method>multilayer perceptron (MLP)</method><method>convolutional neural network (CNN)</method><method>Integrated Gradients</method><method>layerwise relevance propagation</method><method>SmoothGrad</method>
2024,https://openalex.org/W4390660035,Psychology,An Empirical Study on Correlations Between Deep Neural Network Fairness and Neuron Coverage Criteria,"Recently, with the widespread use of deep neural networks (DNNs) in high-stakes decision-making systems (such as fraud detection and prison sentencing), concerns have arisen about the fairness of DNNs in terms of the potential negative impact they may have on individuals and society. Therefore, fairness testing has become an important research topic in DNN testing. At the same time, the neural network coverage criteria (such as criteria based on neuronal activation) is considered as an adequacy test for DNN white-box testing. It is implicitly assumed that improving the coverage can enhance the quality of test suites. Nevertheless, the correlation between DNN fairness (a test property) and coverage criteria (a test method) has not been adequately explored. To address this issue, we conducted a systematic empirical study on seven coverage criteria, six fairness metrics, three fairness testing techniques, and five bias mitigation methods on five DNN models and nine fairness datasets to assess the correlation between coverage criteria and DNN fairness. Our study achieved the following findings: 1) with the increase in the size of the test suite, some of the coverage and fairness metrics changed significantly, as the size of the test suite increased; 2) the statistical correlation between coverage criteria and DNN fairness is limited; and 3) after bias mitigation for improving the fairness of DNN, the change pattern in coverage criteria is different; 4) Models debiased by different bias mitigation methods have a lower correlation between coverage and fairness compared to the original models. Our findings cast doubt on the validity of coverage criteria concerning DNN fairness (i.e., increasing the coverage may even have a negative impact on the fairness of DNNs). Therefore, we warn DNN testers against blindly pursuing higher coverage of coverage criteria at the cost of test properties of DNNs (such as fairness).","<method>deep neural networks (DNNs)</method>, <method>neural network coverage criteria</method>, <method>fairness testing techniques</method>, <method>bias mitigation methods</method>",<method>deep neural networks (DNNs)</method><method>bias mitigation methods</method>
2024,https://openalex.org/W4390742710,Psychology,Machine Learning as a Tool for Hypothesis Generation,"Abstract While hypothesis testing is a highly formalized activity, hypothesis generation remains largely informal. We propose a systematic procedure to generate novel hypotheses about human behavior, which uses the capacity of machine learning algorithms to notice patterns people might not. We illustrate the procedure with a concrete application: judge decisions about whom to jail. We begin with a striking fact: the defendant’s face alone matters greatly for the judge’s jailing decision. In fact, an algorithm given only the pixels in the defendant’s mug shot accounts for up to half of the predictable variation. We develop a procedure that allows human subjects to interact with this black-box algorithm to produce hypotheses about what in the face influences judge decisions. The procedure generates hypotheses that are both interpretable and novel: they are not explained by demographics (e.g., race) or existing psychology research, nor are they already known (even if tacitly) to people or experts. Though these results are specific, our procedure is general. It provides a way to produce novel, interpretable hypotheses from any high-dimensional data set (e.g., cell phones, satellites, online behavior, news headlines, corporate filings, and high-frequency time series). A central tenet of our article is that hypothesis generation is a valuable activity, and we hope this encourages future work in this largely “prescientific” stage of science.",<method>machine learning algorithms</method>,No methods remaining
2024,https://openalex.org/W4391174596,Psychology,Generative Large Language Models for Detection of Speech Recognition Errors in Radiology Reports,"This study evaluated the ability of generative large language models (LLMs) to detect speech recognition errors in radiology reports. A dataset of 3233 CT and MRI reports was assessed by radiologists for speech recognition errors. Errors were categorized as clinically significant or not clinically significant. Performances of five generative LLMs—GPT-3.5-turbo, GPT-4, text-davinci-003, Llama-v2–70B-chat, and Bard—were compared in detecting these errors, using manual error detection as the reference standard. Prompt engineering was used to optimize model performance. GPT-4 demonstrated high accuracy in detecting clinically significant errors (precision, 76.9%; recall, 100%; F1 score, 86.9%) and not clinically significant errors (precision, 93.9%; recall, 94.7%; F1 score, 94.3%). Text-davinci-003 achieved F1 scores of 72% and 46.6% for clinically significant and not clinically significant errors, respectively. GPT-3.5-turbo obtained 59.1% and 32.2% F1 scores, while Llama-v2–70B-chat scored 72.8% and 47.7%. Bard showed the lowest accuracy, with F1 scores of 47.5% and 20.9%. GPT-4 effectively identified challenging errors of nonsense phrases and internally inconsistent statements. Longer reports, resident dictation, and overnight shifts were associated with higher error rates. In conclusion, advanced generative LLMs show potential for automatic detection of speech recognition errors in radiology reports. Keywords: CT, Large Language Model, Machine Learning, MRI, Natural Language Processing, Radiology Reports, Speech, Unsupervised Learning Supplemental material is available for this article. © RSNA, 2024","<method>generative large language models (LLMs)</method>, <method>GPT-3.5-turbo</method>, <method>GPT-4</method>, <method>text-davinci-003</method>, <method>Llama-v2–70B-chat</method>, <method>Bard</method>, <method>prompt engineering</method>",<method>generative large language models (LLMs)</method><method>GPT-3.5-turbo</method><method>GPT-4</method><method>text-davinci-003</method><method>Llama-v2–70B-chat</method>
2024,https://openalex.org/W4391641063,Psychology,Predictors for estimating subcortical EEG responses to continuous speech,"Perception of sounds and speech involves structures in the auditory brainstem that rapidly process ongoing auditory stimuli. The role of these structures in speech processing can be investigated by measuring their electrical activity using scalp-mounted electrodes. However, typical analysis methods involve averaging neural responses to many short repetitive stimuli that bear little relevance to daily listening environments. Recently, subcortical responses to more ecologically relevant continuous speech were detected using linear encoding models. These methods estimate the temporal response function (TRF), which is a regression model that minimises the error between the measured neural signal and a predictor derived from the stimulus. Using predictors that model the highly non-linear peripheral auditory system may improve linear TRF estimation accuracy and peak detection. Here, we compare predictors from both simple and complex peripheral auditory models for estimating brainstem TRFs on electroencephalography (EEG) data from 24 participants listening to continuous speech. We also investigate the data length required for estimating subcortical TRFs, and find that around 12 minutes of data is sufficient for clear wave V peaks (&gt;3 dB SNR) to be seen in nearly all participants. Interestingly, predictors derived from simple filterbank-based models of the peripheral auditory system yield TRF wave V peak SNRs that are not significantly different from those estimated using a complex model of the auditory nerve, provided that the nonlinear effects of adaptation in the auditory system are appropriately modelled. Crucially, computing predictors from these simpler models is more than 50 times faster compared to the complex model. This work paves the way for efficient modelling and detection of subcortical processing of continuous speech, which may lead to improved diagnosis metrics for hearing impairment and assistive hearing technology.","<method>linear encoding models</method>, <method>temporal response function (TRF)</method>, <method>regression model</method>",<method>linear encoding models</method><method>temporal response function (TRF)</method><method>regression model</method>
2024,https://openalex.org/W4399568894,Psychology,Artificial intelligence capability and organizational performance: unraveling the mediating mechanisms of decision-making processes,"Purpose This study investigates the profound impact of artificial intelligence (AI) capabilities on decision-making processes and organizational performance, addressing a crucial gap in the literature by exploring the mediating role of decision-making speed and quality. Design/methodology/approach Drawing upon resource-based theory and prior research, this study constructs a comprehensive model and hypotheses to illuminate the influence of AI capabilities within organizations on decision-making speed, decision quality, and, ultimately, organizational performance. A dataset comprising 230 responses from diverse organizations forms the basis of the analysis, with the study employing a partial least squares structural equation model (PLS-SEM) for robust data examination. Findings The results demonstrate the pivotal role of AI capabilities in shaping organizational decision-making processes and performance. AI capability significantly and positively affects decision-making speed, decision quality, and overall organizational performance. Notably, decision-making speed is a critical factor contributing significantly to enhanced organizational performance. The study further uncovered partial mediation effects, suggesting that decision-making processes partially mediate the relationship between AI capabilities and organizational performance through decision-making speed. Originality/value This study contributes to the existing body of literature by providing empirical evidence of the multifaceted impact of AI capabilities on organizational decision-making and performance. Elucidating the mediating role of decision-making processes advances our understanding of the complex mechanisms through which AI capabilities drive organizational success.",<method>partial least squares structural equation model (PLS-SEM)</method>,No methods remaining
2024,https://openalex.org/W4400770903,Psychology,"A Survey of Imitation Learning: Algorithms, Recent Developments, and Challenges","In recent years, the development of robotics and artificial intelligence (AI) systems has been nothing short of remarkable. As these systems continue to evolve, they are being utilized in increasingly complex and unstructured environments, such as autonomous driving, aerial robotics, and natural language processing. As a consequence, programming their behaviors manually or defining their behavior through the reward functions as done in reinforcement learning (RL) has become exceedingly difficult. This is because such environments require a high degree of flexibility and adaptability, making it challenging to specify an optimal set of rules or reward signals that can account for all the possible situations. In such environments, learning from an expert's behavior through imitation is often more appealing. This is where imitation learning (IL) comes into play -a process where desired behavior is learned by imitating an expert's behavior, which is provided through demonstrations.This article aims to provide an introduction to IL and an overview of its underlying assumptions and approaches. It also offers a detailed description of recent advances and emerging areas of research in the field. Additionally, this article discusses how researchers have addressed common challenges associated with IL and provides potential directions for future research. Overall, the goal of this article is to provide a comprehensive guide to the growing field of IL in robotics and AI.","<method>reinforcement learning (RL)</method>, <method>imitation learning (IL)</method>",<method>reinforcement learning (RL)</method><method>imitation learning (IL)</method>
2024,https://openalex.org/W4390847963,Psychology,Crowdfunding adoption in emerging economies: insights for entrepreneurs and policymakers,"Purpose Crowdfunding has emerged as an alternative financing tool and recently gained attention to foster entrepreneurial dynamism and innovation. The current research has identified the determinants impacting the behavioral intentions of entrepreneurs to use crowdfunding for financing their small and medium-sized enterprises (SMEs). Design/methodology/approach The current article is based on a cross-sectional research design. This research collected the data of 422 owners and managers of SMEs through self-administered questionnaires in the Indian National Capital Region (NCR). The responses were collected from July 17 to October 27, 2022. This article used “partial least squares structural equation modeling” (PLS-SEM) for data analysis. Findings This article offered a robust model with a high explanatory value of 66% of behavioral intention and 62.1% variance in crowdfunding use behavior. The finding also highlighted that performance expectancy, social influence, facilitating conditions, trialability and perceived value significantly impact behavioral intention. However, effort expectancy and perceived risk insignificantly influence behavioral intention. Notably, facilitating conditions, trialability and behavioral intention positively impact use behavior. Practical implications The results of this study will bridge the gap in empirical research on crowdfunding adoption, shedding light on why entrepreneurs hesitate to adopt crowdfunding for financing. Moreover, these results will offer strategic insights for crowdfunding managers and policymakers, aiding them in making informed decisions. Originality/value To the best of the authors' knowledge, this pioneering study built the theoretical framework using three credible technology determinant models. The authors examined crowdfunding-specific contextual factors to improve understanding of the positive effect of technological orientation. This addition assists in strategically arranging entrepreneurs' fundraising conversations more efficiently.",<method>partial least squares structural equation modeling (PLS-SEM)</method>,No methods remaining
2024,https://openalex.org/W4392499245,Psychology,Exploring the role of skin temperature in thermal sensation and thermal comfort: A comprehensive review,"The role of skin temperature as a determinant of human thermal sensation and comfort has gained increasing recognition, prompting a need for a systematic review. This review examines the relationship between skin temperature and thermal sensation, synthesizing insights from 172 studies published since 2000. It uniquely focuses on the indispensable roles of local and mean skin temperatures, a perspective not comprehensively explored in previous literature. The review reveals that the most common measurement points for skin temperature are the face and hands, attributed to their higher thermal sensitivity and the practical ease of measurement. It establishes a clear linear relationship between mean skin temperature and user thermal sensation, though affected by the choice of measurement locations and number of points. A notable finding is the varying impact of local skin temperature on overall thermal sensation in changing environments, with local heating less influential than cooling. The review also uncovers significant demographic variations in thermal sensation, strongly influenced by differing skin temperatures across age groups, genders, and climatic regions. For example, elderly populations exhibit a decreased temperature sensitivity, especially towards warmth. Gender differences are also significant, with females experiencing higher skin temperatures in warmer environments and lower in colder ones. Machine learning (ML)-based methods, especially classification tree-based and support vector machine (SVM) techniques, dominate in predicting thermal sensation and comfort, leveraging skin temperature data. While ML methods are prevalent, statistical regression-based approaches offer valuable empirical insights. Thermo-physiological model-based methods provide reliable results by incorporating detailed skin temperature dynamics. The review identifies a gap in understanding how gender, age, and regional differences influence thermal comfort in diverse environments. The study recommends conducting more nuanced experiments to dissect the impact of these factors and proposes the integration of individual demographic variables into ML models to personalize thermal comfort predictions.","<method>classification tree-based</method>, <method>support vector machine (SVM)</method>, <method>statistical regression-based approaches</method>, <method>thermo-physiological model-based methods</method>",<method>support vector machine (SVM)</method><method>statistical regression-based approaches</method>
2024,https://openalex.org/W4392516399,Psychology,Artificial intelligence in dermatology: advancements and challenges in skin of color,"Abstract Artificial intelligence (AI) uses algorithms and large language models in computers to simulate human‐like problem‐solving and decision‐making. AI programs have recently acquired widespread popularity in the field of dermatology through the application of online tools in the assessment, diagnosis, and treatment of skin conditions. A literature review was conducted using PubMed and Google Scholar analyzing recent literature (from the last 10 years through October 2023) to evaluate current AI programs in use for dermatologic purposes, identifying challenges in this technology when applied to skin of color (SOC), and proposing future steps to enhance the role of AI in dermatologic practice. Challenges surrounding AI and its application to SOC stem from the underrepresentation of SOC in datasets and issues with image quality and standardization. With these existing issues, current AI programs inevitably do worse at identifying lesions in SOC. Additionally, only 30% of the programs identified in this review had data reported on their use in dermatology, specifically in SOC. Significant development of these applications is required for the accurate depiction of darker skin tone images in datasets. More research is warranted in the future to better understand the efficacy of AI in aiding diagnosis and treatment options for SOC patients.","<method>algorithms</method>, <method>large language models</method>",No methods remaining
2024,https://openalex.org/W4392890128,Psychology,"Motivation, work experience, and teacher performance: A comparative study","This research study investigates the effect of intrinsic and extrinsic motivation on employee performance, with a specific focus on the moderating role of employees' work experience. This investigation utilizes a proposed framework, focusing on higher educational institutions in West Bengal, India. It contributes to the human resource management field by comparing teacher performance in private and government academic institutions based on their motivation levels. The study employs a quantitative approach, collecting data from 250 teachers in West Bengal, India, using a structured questionnaire. The dataset underwent analysis employing Partial Least Squares Structural Equation Modeling (PLS-SEM) due to its inherent capacity to accommodate smaller sample sizes while delivering precise and insightful outcomes. The results indicate a strong positive relationship between intrinsic and extrinsic motivation and teacher performance in both types of institutions. Work experience moderates the connection between intrinsic motivation and performance in both sectors but has no significant impact on the relationship between extrinsic motivation and performance in private academic institutions. This study links a gap in the literature by empirically exploring the impact of teacher motivation on their performance and provides valuable insights into the complex interplay among motivation, work experience, and performance. Practically, it emphasizes the importance of employee motivation and accumulated work experience in enhancing performance. This study attempts to underscore the role of work experience as a moderating variable, thereby contributing to the novel discourse in the educational landscape of the post-pandemic era. The findings demand to identification of diverse organizational developmental drivers as work experience does not exhibit a strong mediation effect. However, limitations such as potential response bias should be considered in future research in this area.",<method>Partial Least Squares Structural Equation Modeling (PLS-SEM)</method>,No methods remaining
2024,https://openalex.org/W4399154552,Psychology,Seeking in Ride-on-Demand Service: A Reinforcement Learning Model With Dynamic Price Prediction,"Recent years witness the increasing popularity of ride-on-demand (RoD) services such as Uber and Didi. Compared with traditional taxi, RoD service is more ""data-driven"" and adopts dynamic pricing to manipulate the supply and demand in real time. Dynamic price could be viewed as an accurate and quantitative indicator of the supply and demand, and could provide clues to drivers, passengers, and the service providers, possibly reshaping the ways in which some problems are solved. In this paper, we focus on the seeking route recommendation problem that aims at increasing driver revenue by recommending highly profitable seeking routes to drivers of vacant cars with the help of dynamic prices. We first justify our motivation by showing the importance of route recommendation and answering why it is necessary to consider dynamic prices, based on the analysis of real service data. We then design a dynamic price prediction model to generate the dynamic prices at any given time and location based on multi-source urban data. After that, a reinforcement learning model is adopted to perform seeking route recommendation based on predicted dynamic prices. We conduct extensive experiments in different spatio-temporal combinations and make comparisons with multiple baselines. Results first show that our dynamic price prediction model achieves an accuracy ranging from 83.82% to 90.67% under different settings. It also proves that considering the real-time predicted dynamic prices significantly increases driver revenue by, for example, 12% and 47.5% during weekday evening rush hours, than merely using the average prices or completely ignoring dynamic prices.","<method>dynamic price prediction model</method>, <method>reinforcement learning model</method>",<method>reinforcement learning model</method>
2024,https://openalex.org/W4391715895,Psychology,Deciphering Digital Social Dynamics: A Comparative Study of Logistic Regression and Random Forest in Predicting E-Commerce Customer Behavior,"This study compares Logistic Regression and Random Forest in predicting e-commerce customer churn. Utilizing the E-commerce Customer dataset, it navigates the complexities of customer interactions and behaviors, offering a rich context for analysis. The methodology focuses on meticulous data preprocessing to ensure data integrity, setting the stage for applying and evaluating Logistic Regression and Random Forest. Both models were assessed using accuracy, precision, recall, F1-Score, and AUC-ROC. Logistic Regression showed an accuracy of 90%, precision of 91% for class 0 and 82% for class 1, recall of 98% for class 0 and 50% for class 1, F1-Score of 94% for class 0 and 62% for class 1, and AUC-ROC of 0.88. Random Forest, with its ability to handle complex patterns, demonstrated higher overall performance with an accuracy of 95%, precision of 95% for class 0 and 93% for class 1, recall of 99% for class 0 and 74% for class 1, F1-Score of 97% for class 0 and 82% for class 1, and an AUC-ROC of 0.97. This comparative analysis offers insights into each model's strengths and suitability for predicting customer churn. The findings contribute to a deeper understanding of machine learning applications in e-commerce, guiding stakeholders in enhancing customer retention strategies. This research provides a foundation for further exploration into the digital social dynamics that shape customer behavior in the evolving digital marketplace.","<method>Logistic Regression</method>, <method>Random Forest</method>",<method>Logistic Regression</method><method>Random Forest</method>
2024,https://openalex.org/W4396622079,Psychology,The power of Deep Learning techniques for predicting student performance in Virtual Learning Environments: A systematic literature review,"With the advances in Artificial Intelligence (AI) and the increasing volume of online educational data, Deep Learning techniques have played a critical role in predicting student performance. Recent developments have assisted instructors in determining the strengths and weaknesses of student achievement. This understanding will benefit from adopting the necessary interventions to assist students in improving their performance, helping at-risk of failure students, and preventing dropout rates. The review analyzed 46 studies between 2019 and 2023 that apply one or more Deep Learning (DL) techniques, either single or in combination with Machine Learning (ML) or Ensemble Learning techniques. Moreover, the review utilized datasets from public Massive Open Online Courses (MOOCs), private Learning Management Systems (LMSs), and other platforms. Four categories were used to group the features: demographic, previous academic performance, current academic performance, and learning behavior/activity features. The analysis revealed that the DNNs and CNN-LSTM models were the most common techniques. Moreover, the studies that used DL techniques, such as CNNs, DNNs, and LSTMs, performed well by achieving high prediction accuracy above 90%; other studies achieved accuracy ranging (60 to 90)%. For datasets used within the reviewed studies, even though 44% of the studies used LMSs datasets, Open University Learning Analytics Dataset (OULAD) was the most used dataset from MOOCs. The analysis of grouped features shows that among the various categories examined, learning behavior and activity features stand out as the most significant predictors, suggesting that students engagement with their learning environment through their overall participation offers crucial insights into their success. The educational prediction findings hopefully serve as a strong foundation for administrators and instructors to observe student performance and provide a suitable educational adaptation that can meet their needs to protect them from failure and prevent their dropout.","<method>Deep Learning (DL) techniques</method>, <method>Machine Learning (ML) techniques</method>, <method>Ensemble Learning techniques</method>, <method>DNNs</method>, <method>CNN-LSTM models</method>, <method>CNNs</method>, <method>DNNs</method>, <method>LSTMs</method>",<method>Ensemble Learning techniques</method><method>DNNs</method><method>CNN-LSTM models</method><method>CNNs</method><method>DNNs</method><method>LSTMs</method>
2024,https://openalex.org/W4399442306,Psychology,Integrative analysis of AI-driven optimization in HIV treatment regimens,"The integration of artificial intelligence (AI) into HIV treatment regimens has revolutionized the approach to personalized care and optimization strategies. This study presents an in-depth analysis of the role of AI in transforming HIV treatment, focusing on its ability to tailor therapy to individual patient needs and enhance treatment outcomes. AI-driven optimization in HIV treatment involves the utilization of advanced algorithms and computational techniques to analyze vast amounts of patient data, including genetic information, viral load measurements, and treatment history. By harnessing the power of machine learning and predictive analytics, AI algorithms can identify patterns and trends in patient data that may not be readily apparent to human clinicians. One of the key benefits of AI-driven optimization is its ability to personalize treatment regimens based on individual patient characteristics and disease progression. By considering factors such as drug resistance profiles, comorbidities, and lifestyle factors, AI algorithms can recommend the most effective and well-tolerated treatment options for each patient, leading to improved adherence and clinical outcomes. Furthermore, AI enables continuous monitoring and adjustment of treatment regimens in real time, allowing healthcare providers to respond rapidly to changes in patient status and evolving viral dynamics. This proactive approach to HIV management can help prevent treatment failure and the development of drug resistance, ultimately leading to better long-term outcomes for patients. Despite its transformative potential, AI-driven optimization in HIV treatment is not without challenges. Ethical considerations, data privacy concerns, and the need for robust validation and regulatory oversight are all important factors that must be addressed to ensure the safe and effective implementation of AI algorithms in clinical practice. In conclusion, the integrative analysis presented in this study underscores the significant impact of AI-driven optimization on the personalization and optimization of HIV treatment regimens. By leveraging AI technologies, healthcare providers can tailor treatment approaches to individual patient needs, leading to improved outcomes and quality of life for people living with HIV. Keywords: Integrative Analysis, AI- Driven, Optimization, HIV Treatment, Regimens.","<method>machine learning</method>, <method>predictive analytics</method>",<method>machine learning</method>
2024,https://openalex.org/W4390506438,Psychology,Artificial intelligence for oral squamous cell carcinoma detection based on oral photographs: A comprehensive literature review,"Abstract Introduction Oral squamous cell carcinoma (OSCC) presents a significant global health challenge. The integration of artificial intelligence (AI) and computer vision holds promise for the early detection of OSCC through the analysis of digitized oral photographs. This literature review explores the landscape of AI‐driven OSCC automatic detection, assessing both the performance and limitations of the current state of the art. Materials and Methods An electronic search using several data base was conducted, and a systematic review performed in accordance with PRISMA guidelines (CRD42023441416). Results Several studies have demonstrated remarkable results for this task, consistently achieving sensitivity rates exceeding 85% and accuracy rates surpassing 90%, often encompassing around 1000 images. The review scrutinizes these studies, shedding light on their methodologies, including the use of recent machine learning and pattern recognition approaches coupled with different supervision strategies. However, comparing the results from different papers is challenging due to variations in the datasets used. Discussion Considering these findings, this review underscores the urgent need for more robust and reliable datasets in the field of OSCC detection. Furthermore, it highlights the potential of advanced techniques such as multi‐task learning, attention mechanisms, and ensemble learning as crucial tools in enhancing the accuracy and sensitivity of OSCC detection through oral photographs. Conclusion These insights collectively emphasize the transformative impact of AI‐driven approaches on early OSCC diagnosis, with the potential to significantly improve patient outcomes and healthcare practices.","<method>machine learning</method>, <method>pattern recognition</method>, <method>multi-task learning</method>, <method>attention mechanisms</method>, <method>ensemble learning</method>",<method>machine learning</method><method>multi-task learning</method><method>attention mechanisms</method><method>ensemble learning</method>
2024,https://openalex.org/W4390665001,Psychology,A deep learning model for brain age prediction using minimally preprocessed T1w images as input,"Introduction In the last few years, several models trying to calculate the biological brain age have been proposed based on structural magnetic resonance imaging scans (T1-weighted MRIs, T1w) using multivariate methods and machine learning. We developed and validated a convolutional neural network (CNN)-based biological brain age prediction model that uses one T1w MRI preprocessing step when applying the model to external datasets to simplify implementation and increase accessibility in research settings. Our model only requires rigid image registration to the MNI space, which is an advantage compared to previous methods that require more preprocessing steps, such as feature extraction. Methods We used a multicohort dataset of cognitively healthy individuals (age range = 32.0–95.7 years) comprising 17,296 MRIs for training and evaluation. We compared our model using hold-out (CNN1) and cross-validation (CNN2–4) approaches. To verify generalisability, we used two external datasets with different populations and MRI scan characteristics to evaluate the model. To demonstrate its usability, we included the external dataset’s images in the cross-validation training (CNN3). To ensure that our model used only the brain signal on the image, we also predicted brain age using skull-stripped images (CNN4). Results: The trained models achieved a mean absolute error of 2.99, 2.67, 2.67, and 3.08 years for CNN1–4, respectively. The model’s performance in the external dataset was in the typical range of mean absolute error (MAE) found in the literature for testing sets. Adding the external dataset to the training set (CNN3), overall, MAE is unaffected, but individual cohort MAE improves (5.63–2.25 years). Salience maps of predictions reveal that periventricular, temporal, and insular regions are the most important for age prediction. Discussion We provide indicators for using biological (predicted) brain age as a metric for age correction in neuroimaging studies as an alternative to the traditional chronological age. In conclusion, using different approaches, our CNN-based model showed good performance using one T1w brain MRI preprocessing step. The proposed CNN model is made publicly available for the research community to be easily implemented and used to study ageing and age-related disorders.","<method>multivariate methods</method>, <method>machine learning</method>, <method>convolutional neural network (CNN)</method>, <method>hold-out approach</method>, <method>cross-validation approach</method>",<method>machine learning</method><method>convolutional neural network (CNN)</method><method>hold-out approach</method>
2024,https://openalex.org/W4391035240,Psychology,Detection of epileptic seizure in EEG signals using machine learning and deep learning techniques,"Abstract Around 50 million individuals worldwide suffer from epilepsy, a chronic, non-communicable brain disorder. Several screening methods, including electroencephalography, have been proposed to identify epileptic episodes. EEG data, which are frequently utilised to enhance epilepsy analysis, offer essential information on the electrical processes of the brain. Prior to the emergence of deep learning (DL), feature extraction was accomplished by standard machine learning techniques. As a result, they were only as good as the people who made the features by hand. But with DL, both feature extraction and classification are fully automated. These methods have significantly advanced several fields of medicine, including the diagnosis of epilepsy. In this paper, the works focused on automated epileptic seizure detection using ML and DL techniques are presented as well as their comparative analysis is done. The UCI-Epileptic Seizure Recognition dataset is used for training and validation. Some of the conventional ML and DL algorithms are used with a proposed model which uses long short-term memory (LSTM) to find the best approach. Post that comparative analysis is performed on these algorithms to find the best approach for epileptic seizure detection. As a result, the proposed model LSTM gives a validation accuracy of 97% giving the most appropriate and precise result as compared to other mentioned algorithms used in this study.","<method>machine learning</method>, <method>deep learning</method>, <method>long short-term memory (LSTM)</method>",<method>machine learning</method><method>deep learning</method><method>long short-term memory (LSTM)</method>
2024,https://openalex.org/W4391164242,Psychology,Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models,"Suicidal ideation detection is a vital research area that holds great potential for improving mental health support systems. However, the sensitivity surrounding suicide-related data poses challenges in accessing large-scale, annotated datasets necessary for training effective machine learning models. To address this limitation, we introduce an innovative strategy that leverages the capabilities of generative AI models, such as ChatGPT, Flan-T5, and Llama, to create synthetic data for suicidal ideation detection. Our data generation approach is grounded in social factors extracted from psychology literature and aims to ensure coverage of essential information related to suicidal ideation. In our study, we benchmarked against state-of-the-art NLP classification models, specifically, those centered around the BERT family structures. When trained on the real-world dataset, UMD, these conventional models tend to yield F1-scores ranging from 0.75 to 0.87. Our synthetic data-driven method, informed by social factors, offers consistent F1-scores of 0.82 for both models, suggesting that the richness of topics in synthetic data can bridge the performance gap across different model complexities. Most impressively, when we combined a mere 30% of the UMD dataset with our synthetic data, we witnessed a substantial increase in performance, achieving an F1-score of 0.88 on the UMD test set. Such results underscore the cost-effectiveness and potential of our approach in confronting major challenges in the field, such as data scarcity and the quest for diversity in data representation.","<method>generative AI models</method>, <method>ChatGPT</method>, <method>Flan-T5</method>, <method>Llama</method>, <method>NLP classification models</method>, <method>BERT family structures</method>",<method>generative AI models</method><method>Flan-T5</method><method>Llama</method>
2024,https://openalex.org/W4392138877,Psychology,Prevalence and risk factors analysis of postpartum depression at early stage using hybrid deep learning model,"Postpartum Depression Disorder (PPDD) is a prevalent mental health condition and results in severe depression and suicide attempts in the social community. Prompt actions are crucial in tackling PPDD, which requires a quick recognition and accurate analysis of the probability factors associated with this condition. This concern requires attention. The primary aim of our research is to investigate the feasibility of anticipating an individual's mental state by categorizing individuals with depression from those without depression using a dataset consisting of text along with audio recordings from patients diagnosed with PPDD. This research proposes a hybrid PPDD framework that combines Improved Bi-directional Long Short-Term Memory (IBi-LSTM) with Transfer Learning (TL) based on two Convolutional Neural Network (CNN) architectures, respectively CNN-text and CNN audio. In the proposed model, the CNN section efficiently utilizes TL to obtain crucial knowledge from text and audio characteristics, whereas the improved Bi-LSTM module combines written material and sound data to obtain intricate chronological interpersonal relationships. The proposed model incorporates an attention technique to augment the effectiveness of the Bi-LSTM scheme. An experimental analysis is conducted on the PPDD online textual and speech audio dataset collected from UCI. It includes textual features such as age, women's health tracks, medical histories, demographic information, daily life metrics, psychological evaluations, and 'speech records' of PPDD patients. Data pre-processing is applied to maintain the data integrity and achieve reliable model performance. The proposed model demonstrates a great performance in better precision, recall, accuracy, and F1-score over existing deep learning models, including VGG-16, Base-CNN, and CNN-LSTM. These metrics indicate the model's ability to differentiate among women at risk of PPDD vs. non-PPDD. In addition, the feature importance analysis demonstrates that specific risk factors substantially impact the prediction of PPDD. The findings of this research establish a basis for improved precision and promptness in assessing the risk of PPDD, which may ultimately result in earlier implementation of interventions and the establishment of support networks for women who are susceptible to PPDD.","<method>Improved Bi-directional Long Short-Term Memory (IBi-LSTM)</method>, <method>Transfer Learning (TL)</method>, <method>Convolutional Neural Network (CNN)</method>, <method>Attention technique</method>, <method>VGG-16</method>, <method>Base-CNN</method>, <method>CNN-LSTM</method>",<method>Transfer Learning (TL)</method><method>Convolutional Neural Network (CNN)</method><method>Attention technique</method><method>VGG-16</method><method>CNN-LSTM</method>
2024,https://openalex.org/W4399244247,Psychology,Investigating influencing factors of learning satisfaction in AI ChatGPT for research: University students perspective,"This study investigates the determinants of ChatGPT adoption among university students and its impact on learning satisfaction. Utilizing the Technology Acceptance Model (TAM) and incorporating insights from interaction learning, collaborative learning, and information quality, a structural equation modeling approach was employed. This research collected valuable responses from 262 students at King Faisal University in Saudi Arabia through the use of self-report questionnaires. The data's reliability and validity were assessed using confirmation factor analysis, followed by path analysis to explore the hypotheses in the proposed model. The results indicate the pivotal roles of interaction learning and collaborative learning in fostering ChatGPT adoption. Social interaction played a significant role, as researchers engaging in conversations and knowledge-sharing expressed increased comfort with ChatGPT. Information quality was found to substantially influence researchers' decisions to continue using ChatGPT, emphasizing the need for ongoing improvement in the accuracy and relevance of content provided. Perceived ease of use and perceived usefulness played intermediary roles in linking ChatGPT engagement to learning satisfaction. User-friendly interfaces and perceived utility were identified as crucial factors affecting overall satisfaction levels. Notably, ChatGPT positively impacted learning motivation, indicating its potential to enhance student engagement and interest in learning. The study's findings have implications for educational practitioners seeking to improve the implementation of AI technologies in university students, emphasizing user-friendly design, collaborative learning, and factors influencing satisfaction. The study concludes with insights into the complex interplay between AI-powered tools, learning objectives, and motivation, highlighting the need for continued research to comprehensively understand these dynamics. This study investigates the determinants of ChatGPT adoption among university students and its impact on learning satisfaction. Utilizing the Technology Acceptance Model (TAM) and incorporating insights from interaction learning, collaborative learning, and information quality, a structural equation modeling approach was employed. This research collected valuable responses from 262 students at King Faisal University in Saudi Arabia through the use of self-report questionnaires. The data's reliability and validity were assessed using confirmation factor analysis, followed by path analysis to explore the hypotheses in the proposed model. The results indicate the pivotal roles of interaction learning and collaborative learning in fostering ChatGPT adoption. Social interaction played a significant role, as researchers engaging in conversations and knowledge-sharing expressed increased comfort with ChatGPT. Information quality was found to substantially influence researchers' decisions to continue using ChatGPT, emphasizing the need for ongoing improvement in the accuracy and relevance of content provided. Perceived ease of use and perceived usefulness played intermediary roles in linking ChatGPT engagement to learning satisfaction. User-friendly interfaces and perceived utility were identified as crucial factors affecting overall satisfaction levels. Notably, ChatGPT positively impacted learning motivation, indicating its potential to enhance student engagement and interest in learning. The study's findings have implications for educational practitioners seeking to improve the implementation of AI technologies in university students, emphasizing user-friendly design, collaborative learning, and factors influencing satisfaction. The study concludes with insights into the complex interplay between AI-powered tools, learning objectives, and motivation, highlighting the need for continued research to comprehensively understand these dynamics.","<method>Technology Acceptance Model (TAM)</method>, <method>structural equation modeling</method>, <method>confirmation factor analysis</method>, <method>path analysis</method>",No methods remaining
2024,https://openalex.org/W4399363436,Psychology,Collective Constitutional AI: Aligning a Language Model with Public Input,"There is growing consensus that language model (LM) developers should not be the sole deciders of LM behavior, creating a need for methods that enable the broader public to collectively shape the behavior of LM systems that affect them. To address this need, we present Collective Constitutional AI (CCAI): a multi-stage process for sourcing and integrating public input into LMs—from identifying a target population to sourcing principles to training and evaluating a model. We demonstrate the real-world practicality of this approach by creating what is, to our knowledge, the first LM fine-tuned with collectively sourced public input and evaluating this model against a baseline model trained with established principles from a LM developer. Our quantitative evaluations demonstrate several benefits of our approach: the CCAI-trained model shows lower bias across nine social dimensions compared to the baseline model, while maintaining equivalent performance on language, math, and helpful-harmless evaluations. Qualitative comparisons of the models suggest that the models differ on the basis of their respective constitutions, e.g., when prompted with contentious topics, the CCAI-trained model tends to generate responses that reframe the matter positively instead of a refusal. These results demonstrate a promising, tractable pathway toward publicly informed development of language models.","<method>Collective Constitutional AI (CCAI)</method>, <method>fine-tuning</method>",<method>fine-tuning</method>
2024,https://openalex.org/W3186881383,Psychology,Graph Autoencoders for Embedding Learning in Brain Networks and Major Depressive Disorder Identification,"Brain functional connectivity (FC) networks inferred from functional magnetic resonance imaging (fMRI) have shown altered or aberrant brain functional connectome in various neuropsychiatric disorders. Recent application of deep neural networks to connectome-based classification mostly relies on traditional convolutional neural networks (CNNs) using input FCs on a regular Euclidean grid to learn spatial maps of brain networks neglecting the topological information of the brain networks, leading to potentially sub-optimal performance in brain disorder identification. We propose a novel graph deep learning framework that leverages non-Euclidean information inherent in the graph structure for classifying brain networks in major depressive disorder (MDD). We introduce a novel graph autoencoder (GAE) architecture, built upon graph convolutional networks (GCNs), to embed the topological structure and node content of large fMRI networks into low-dimensional representations. For constructing the brain networks, we employ the Ledoit-Wolf (LDW) shrinkage method to efficiently estimate high-dimensional FC metrics from fMRI data. We explore both supervised and unsupervised techniques for graph embedding learning. The resulting embeddings serve as feature inputs for a deep fully-connected neural network (FCNN) to distinguish MDD from healthy controls (HCs). Evaluating our model on resting-state fMRI MDD dataset, we observe that the GAE-FCNN outperforms several state-of-the-art methods for brain connectome classification, achieving the highest accuracy when using LDW-FC edges as node features. The graph embeddings of fMRI FC networks also reveal significant group differences between MDD and HCs. Our framework demonstrates the feasibility of learning graph embeddings from brain networks, providing valuable discriminative information for diagnosing brain disorders.","<method>deep neural networks</method>, <method>convolutional neural networks (CNNs)</method>, <method>graph deep learning framework</method>, <method>graph autoencoder (GAE)</method>, <method>graph convolutional networks (GCNs)</method>, <method>supervised techniques for graph embedding learning</method>, <method>unsupervised techniques for graph embedding learning</method>, <method>deep fully-connected neural network (FCNN)</method>",<method>deep neural networks</method><method>convolutional neural networks (CNNs)</method><method>graph autoencoder (GAE)</method><method>graph convolutional networks (GCNs)</method><method>supervised techniques for graph embedding learning</method><method>unsupervised techniques for graph embedding learning</method><method>deep fully-connected neural network (FCNN)</method>
2024,https://openalex.org/W4391560128,Psychology,Analyzing Preceding factors affecting behavioral intention on communicational artificial intelligence as an educational tool,"During the pandemic, artificial intelligence was employed and utilized by students around the globe. Students' conduct changed in a variety of ways when schooling returned to regular instruction. This study aimed to analyze the student's behavioral intention and actual academic use of communicational AI (CAI) as an educational tool. This study identified the variables by utilizing an integrated framework based on the Unified Theory of Acceptance and Use of Technology (UTAUT2) and self-determination theory. Through the use of an online survey and Structural Equation Modeling, data from 533 respondents were analyzed. The results showed that perceived relatedness has the most significant effect on the behavioral intention of students in using CAI as an educational tool, followed by perceived autonomy. It showed that students use CAI based on the objective and the possibility of increasing their productivity, rather than any other purpose in the education setting. Among the UTAUT2 domains, only facilitating conditions, habit, and performance expectancy provided a significant direct effect on behavioral intention and an indirect effect on actual academic use. Further implications were presented. Moreover, the methodology and framework of this study could be extended and applied to educational technology-related studies. Lastly, the outcome of this study may be considered in analyzing the behavioral intention of the students as the teaching-learning environment is still continuously expanding and developing.",<method>Structural Equation Modeling</method>,No methods remaining
2024,https://openalex.org/W4391655051,Psychology,Do large language models show decision heuristics similar to humans? A case study using GPT-3.5.,"A Large Language Model (LLM) is an artificial intelligence system trained on vast amounts of natural language data, enabling it to generate human-like responses to written or spoken language input. Generative Pre-Trained Transformer (GPT)-3.5 is an example of an LLM that supports a conversational agent called ChatGPT. In this work, we used a series of novel prompts to determine whether ChatGPT shows heuristics and other context-sensitive responses. We also tested the same prompts on human participants. Across four studies, we found that ChatGPT was influenced by random anchors in making estimates (anchoring, Study 1); it judged the likelihood of two events occurring together to be higher than the likelihood of either event occurring alone, and it was influenced by anecdotal information (representativeness and availability heuristic, Study 2); it found an item to be more efficacious when its features were presented positively rather than negatively-even though both presentations contained statistically equivalent information (framing effect, Study 3); and it valued an owned item more than a newly found item even though the two items were objectively identical (endowment effect, Study 4). In each study, human participants showed similar effects. Heuristics and context-sensitive responses in humans are thought to be driven by cognitive and affective processes such as loss aversion and effort reduction. The fact that an LLM-which lacks these processes-also shows such responses invites consideration of the possibility that language is sufficiently rich to carry these effects and may play a role in generating these effects in humans. (PsycInfo Database Record (c) 2024 APA, all rights reserved).","<method>Large Language Model (LLM)</method>, <method>Generative Pre-Trained Transformer (GPT)-3.5</method>",<method>Generative Pre-Trained Transformer (GPT)-3.5</method>
2024,https://openalex.org/W4392542342,Psychology,Detecting ChatGPT-Generated Code Submissions in a CS1 Course Using Machine Learning Models,"The emergence of publicly accessible large language models (LLMs) such as ChatGPT poses unprecedented risks of new types of plagiarism and cheating where students use LLMs to solve exercises for them. Detecting this behavior will be a necessary component in introductory computer science (CS1) courses, and educators should be well-equipped with detection tools when the need arises. However, ChatGPT generates code non-deterministically, and thus, traditional similarity detectors might not suffice to detect AI-created code. In this work, we explore the affordances of Machine Learning (ML) models for the detection task. We used an openly available dataset of student programs for CS1 assignments and had ChatGPT generate code for the same assignments, and then evaluated the performance of both traditional machine learning models and Abstract Syntax Tree-based (AST-based) deep learning models in detecting ChatGPT code from student code submissions. Our results suggest that both traditional machine learning models and AST-based deep learning models are effective in identifying ChatGPT-generated code with accuracy above 90%. Since the deployment of such models requires ML knowledge and resources that are not always accessible to instructors, we also explore the patterns detected by deep learning models that indicate possible ChatGPT code signatures, which instructors could possibly use to detect LLM-based cheating manually. We also explore whether explicitly asking ChatGPT to impersonate a novice programmer affects the code produced. We further discuss the potential applications of our proposed models for enhancing introductory computer science instruction.","<method>traditional machine learning models</method>, <method>Abstract Syntax Tree-based (AST-based) deep learning models</method>",<method>Abstract Syntax Tree-based (AST-based) deep learning models</method>
2024,https://openalex.org/W4393078946,Psychology,Enhancing End-to-End Multi-Task Dialogue Systems: A Study on Intrinsic Motivation Reinforcement Learning Algorithms for Improved Training and Adaptability,"End-to-end multi-task dialogue systems are usually designed with separate modules for the dialogue pipeline. Among these, the policy module is essential for deciding what to do in response to user input. This policy is trained by reinforcement learning algorithms by taking advantage of an environment in which an agent receives feedback in the form of a reward signal. The current dialogue systems, however, only provide meagre and simplistic rewards. Investigating intrinsic motivation reinforcement learning algorithms is the goal of this study. Through this, the agent can quickly accelerate training and improve its capacity to judge the quality of its actions by teaching it an internal incentive system. In particular, we adapt techniques for random network distillation and curiosity-driven reinforcement learning to measure the frequency of state visits and encourage exploration by using semantic similarity between utterances. Experimental results on MultiWOZ, a heterogeneous dataset, show that intrinsic motivation-based debate systems outperform policies that depend on extrinsic incentives. By adopting random network distillation, for example, which is trained using semantic similarity between user-system dialogues, an astounding average success rate of 73% is achieved. This is a significant improvement over the baseline Proximal Policy optimization (PPO), which has an average success rate of 60%. In addition, performance indicators such as booking rates and completion rates show a 10% rise over the baseline. Furthermore, these intrinsic incentive models help improve the system's policy's resilience in an increasing amount of domains. This implies that they could be useful in scaling up to settings that cover a wider range of domains.","<method>reinforcement learning algorithms</method>, <method>intrinsic motivation reinforcement learning algorithms</method>, <method>random network distillation</method>, <method>curiosity-driven reinforcement learning</method>, <method>Proximal Policy Optimization (PPO)</method>",<method>reinforcement learning algorithms</method><method>intrinsic motivation reinforcement learning algorithms</method><method>random network distillation</method><method>curiosity-driven reinforcement learning</method><method>Proximal Policy Optimization (PPO)</method>
2024,https://openalex.org/W4394633221,Psychology,An efficient Parkinson's disease detection framework: Leveraging time-frequency representation and AlexNet convolutional neural network,"Parkinson's disease (PD) is a progressive neurodegenerative disorder affecting the quality of life of over 10 million individuals worldwide. Early diagnosis is crucial for timely intervention and better patient outcomes. Electroencephalogram (EEG) signals are commonly used for early PD diagnosis due to their potential in monitoring disease progression. But traditional EEG-based methods lack exploration of brain regions that provide essential information about PD, and their performance falls short for real-time applications. To address these limitations, this study proposes a novel approach using a Time-Frequency Representation (TFR) based AlexNet Convolutional Neural Network (CNN) model to explore EEG channel-based analysis and identify critical brain regions efficiently diagnosing PD from EEG data. The Wavelet Scattering Transform (WST) is employed to capture distinct temporal and spectral characteristics, while AlexNet CNN is utilized to detect complex spatial patterns at different scales, accurately identifying intricate EEG patterns associated with PD. The experiment results on two real-time EEG PD datasets: San Diego dataset and the Iowa dataset demonstrate that frontal and central brain regions, including AF4 and AFz electrodes, contribute significantly to providing more representative features compared to other regions for PD detection. The proposed architecture achieves an impressive accuracy of 99.84% for the San Diego dataset and 95.79% for the Iowa dataset, outperforming existing EEG-based PD detection methods. The findings of this research will assist to create an essential technology for efficient PD diagnosis, enhancing patient care and quality of life.","<method>Time-Frequency Representation (TFR) based AlexNet Convolutional Neural Network (CNN)</method>, <method>Wavelet Scattering Transform (WST)</method>, <method>AlexNet CNN</method>",<method>Wavelet Scattering Transform (WST)</method><method>AlexNet CNN</method>
2024,https://openalex.org/W4391023547,Psychology,Multimodal diagnosis model of Alzheimer’s disease based on improved Transformer,"Abstract Purpose Recent technological advancements in data acquisition tools allowed neuroscientists to acquire different modality data to diagnosis Alzheimer’s disease (AD). However, how to fuse these enormous amount different modality data to improve recognizing rate and find significance brain regions is still challenging. Methods The algorithm used multimodal medical images [structural magnetic resonance imaging (sMRI) and positron emission tomography (PET)] as experimental data. Deep feature representations of sMRI and PET images are extracted by 3D convolution neural network (3DCNN). An improved Transformer is then used to progressively learn global correlation information among features. Finally, the information from different modalities is fused for identification. A model-based visualization method is used to explain the decisions of the model and identify brain regions related to AD. Results The model attained a noteworthy classification accuracy of 98.1% for Alzheimer’s disease (AD) using the Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset. Upon examining the visualization results, distinct brain regions associated with AD diagnosis were observed across different image modalities. Notably, the left parahippocampal region emerged consistently as a prominent and significant brain area. Conclusions A large number of comparative experiments have been carried out for the model, and the experimental results verify the reliability of the model. In addition, the model adopts a visualization analysis method based on the characteristics of the model, which improves the interpretability of the model. Some disease-related brain regions were found in the visualization results, which provides reliable information for AD clinical research.","<method>3D convolution neural network (3DCNN)</method>, <method>improved Transformer</method>, <method>model-based visualization method</method>",<method>3D convolution neural network (3DCNN)</method>
2024,https://openalex.org/W4392190113,Psychology,Factors influencing academic performance and dropout rates in higher education,"The aim of this study was to identify and evaluate the most frequently used research methods and factors influencing academic performance, based on a pool of 95 studies, published after 2012. We considered only peer-reviewed papers containing 78 empirical and 17 meta-analytic studies. Our theoretical background lies in the different approaches of the terms 'university dropout' and 'academic performance'. After the systematic analysis we ascertained the most commonly used methods are Educational Data Mining (EDM) algorithms (decision tree, logistic regression and neural networks) and Structural Equation Modelling (SEM). The strength of the predictive power depends on the dataset, however Support Vector Machines, Multilayer Perceptron, Naïve Bayes algorithm were found to be the most precise in prediction. Regarding factors influencing academic performance we derived our results based on 600,000 university students. Considering the data from meta-analyses and systematic reviews, reaching up to 900 studies, we found grade point average (GPA), obtained credits (ECTS) and gender to be the most consistent and decisive predictors of academic performance. Nevertheless, GPA and ECTS (as output variables) are mediated by student factors (intrinsic motivation, self-regulated learning strategies, self-efficacy, prior education) and throughput factors (work, finances, academic engagement). We had contradictory results on age and family background.","<method>Educational Data Mining (EDM) algorithms</method>, <method>decision tree</method>, <method>logistic regression</method>, <method>neural networks</method>, <method>Structural Equation Modelling (SEM)</method>, <method>Support Vector Machines</method>, <method>Multilayer Perceptron</method>, <method>Naïve Bayes algorithm</method>",<method>decision tree</method><method>logistic regression</method><method>neural networks</method><method>Support Vector Machines</method><method>Multilayer Perceptron</method><method>Naïve Bayes algorithm</method>
2024,https://openalex.org/W4392891497,Psychology,Learners’ continuance intention in multimodal language learning education: An innovative multiple linear regression model,"Confronted with the unprecedented COVID-19 pandemic, millions of learners have received, are receiving, or will receive multimodal language learning education. This study aims to explore the relationships between various factors influencing learners' continuance intention by proposing an innovative multiple linear regression model in multimodal language learning education. Participants were randomly recruited (N = 334) in China who had received multimodal language learning education by combining Massive Open Online Courses, Rain Classroom, and WeChat. The research instrument, a comprehensive questionnaire, was sent through the online system named Questionnaire Star developed by technical experts. A multiple linear regression analysis was adopted to test the proposed hypotheses and fit the research model. This study confirms the relationships between the Technology Acceptance Model-inclusive constructs such as perceived ease of use, perceived usefulness, attitudes toward multimodal language learning education, and continuance intention of participating in multimodal language learning education. The Technology Acceptance Model is also associated with other constructs, e.g. Task-technology fit, Individual-technology fit, Openness, and Reputation of multimodal language learning educational institutes, and personal investment in multimodal language learning education. However, personal investment neither directly nor indirectly predicts continuance intention. Educators and designers could make every effort to improve multimodal language learning education to enhance personal investment and foster its association with continuance intention of learners.",<method>multiple linear regression</method>,<method>multiple linear regression</method>
2024,https://openalex.org/W4390618032,Psychology,An interpretable model based on graph learning for diagnosis of Parkinson’s disease with voice-related EEG,"Abstract Parkinson’s disease (PD) exhibits significant clinical heterogeneity, presenting challenges in the identification of reliable electroencephalogram (EEG) biomarkers. Machine learning techniques have been integrated with resting-state EEG for PD diagnosis, but their practicality is constrained by the interpretable features and the stochastic nature of resting-state EEG. The present study proposes a novel and interpretable deep learning model, graph signal processing-graph convolutional networks (GSP-GCNs), using event-related EEG data obtained from a specific task involving vocal pitch regulation for PD diagnosis. By incorporating both local and global information from single-hop and multi-hop networks, our proposed GSP-GCNs models achieved an averaged classification accuracy of 90.2%, exhibiting a significant improvement of 9.5% over other deep learning models. Moreover, the interpretability analysis revealed discriminative distributions of large-scale EEG networks and topographic map of microstate MS5 learned by our models, primarily located in the left ventral premotor cortex, superior temporal gyrus, and Broca’s area that are implicated in PD-related speech disorders, reflecting our GSP-GCN models’ ability to provide interpretable insights identifying distinctive EEG biomarkers from large-scale networks. These findings demonstrate the potential of interpretable deep learning models coupled with voice-related EEG signals for distinguishing PD patients from healthy controls with accuracy and elucidating the underlying neurobiological mechanisms.","<method>machine learning techniques</method>, <method>deep learning models</method>, <method>graph signal processing-graph convolutional networks (GSP-GCNs)</method>",<method>graph signal processing-graph convolutional networks (GSP-GCNs)</method>
2024,https://openalex.org/W4390812034,Psychology,The Utility of AI in Writing a Scientific Review Article on the Impacts of COVID-19 on Musculoskeletal Health,"Abstract Purpose of Review There were two primary purposes to our reviews. First, to provide an update to the scientific community about the impacts of COVID-19 on musculoskeletal health. Second, was to determine the value of using a large language model, ChatGPT 4.0, in the process of writing a scientific review article. To accomplish these objectives, we originally set out to write three review articles on the topic using different methods to produce the initial drafts of the review articles. The first review article was written in the traditional manner by humans, the second was to be written exclusively using ChatGPT (AI-only or AIO), and the third approach was to input the outline and references selected by humans from approach 1 into ChatGPT, using the AI to assist in completing the writing (AI-assisted or AIA). All review articles were extensively fact-checked and edited by all co-authors leading to the final drafts of the manuscripts, which were significantly different from the initial drafts. Recent Findings Unfortunately, during this process, it became clear that approach 2 was not feasible for a very recent topic like COVID-19 as at the time, ChatGPT 4.0 had a cutoff date of September 2021 and all articles published after this date had to be provided to ChatGPT, making approaches 2 and 3 virtually identical. Therefore, only two approaches and two review articles were written (human and AI-assisted). Here we found that the human-only approach took less time to complete than the AI-assisted approach. This was largely due to the number of hours required to fact-check and edit the AI-assisted manuscript. Of note, the AI-assisted approach resulted in inaccurate attributions of references (about 20%) and had a higher similarity index suggesting an increased risk of plagiarism. Summary The main aim of this project was to determine whether the use of AI could improve the process of writing a scientific review article. Based on our experience, with the current state of technology, it would not be advised to solely use AI to write a scientific review article, especially on a recent topic.","<method>large language model, ChatGPT 4.0</method>","<method>large language model, ChatGPT 4.0</method>"
2024,https://openalex.org/W4390881691,Psychology,"Uncertainty Reduction in Flood Susceptibility Mapping Using Random Forest and eXtreme Gradient Boosting Algorithms in Two Tropical Desert Cities, Shibam and Marib, Yemen","Flooding is a natural disaster that coexists with human beings and causes severe loss of life and property worldwide. Although numerous studies for flood susceptibility modelling have been introduced, a notable gap has been the overlooked or reduced consideration of the uncertainty in the accuracy of the produced maps. Challenges such as limited data, uncertainty due to confidence bounds, and the overfitting problem are critical areas for improving accurate models. We focus on the uncertainty in susceptibility mapping, mainly when there is a significant variation in the predictive relevance of the predictor factors. It is also noted that the receiver operating characteristic (ROC) curve may not accurately depict the sensitivity of the resulting susceptibility map to overfitting. Therefore, reducing the overfitting problem was targeted to increase accuracy and improve processing time in flood prediction. This study created a spatial repository to test the models, containing data from historical flooding and twelve topographic and geo-environmental flood conditioning variables. Then, we applied random forest (RF) and extreme gradient boosting (XGB) algorithms to map flood susceptibility, incorporating a variable drop-off in the empirical loop function. The results showed that the drop-off loop function was a crucial method to resolve the model uncertainty associated with the conditioning factors of the susceptibility modelling and methods. The results showed that approximately 8.42% to 9.89% of Marib City and 9.93% to 15.69% of Shibam City areas were highly vulnerable to floods. Furthermore, this study significantly contributes to worldwide endeavors focused on reducing the hazards linked to natural disasters. The approaches used in this study can offer valuable insights and strategies for reducing natural disaster risks, particularly in Yemen.","<method>random forest (RF)</method>, <method>extreme gradient boosting (XGB)</method>",<method>random forest (RF)</method><method>extreme gradient boosting (XGB)</method>
2024,https://openalex.org/W4390959437,Psychology,Machine learning model (RG-DMML) and ensemble algorithm for prediction of students’ retention and graduation in education,"Automated prediction of students' retention and graduation in education using advanced analytical methods such as artificial intelligence (AI), has recently attracted the attention of educators, both in theory and in practice. Whereas invaluable insights and theories for measuring and testing the topic have been proposed, most of the existing methods do not technically highlight the non-trivial factors behind the renowned challenges and attrition. To this effect, by making use of two categories of data collected in a higher education setting about students (i) retention (n = 52262) and (ii) graduation (n = 53639); this study proposes a machine learning model - RG-DMML (retention and graduation data mining and machine learning) and ensemble algorithm for prediction of students' retention and graduation status in education. This was done by training and testing key features that are technically deemed suitable for measuring the constructs (retention and graduation), such as (i) the Average grade of the previous high school, and (ii) the Entry/admission score. The proposed model (RG-DMML) is designed based on the cross industry standard process for data mining (CRISP-DM) methodology, implemented using supervised machine learning technique such as K-Nearest Neighbor (KNN), and validated using the k-fold cross-validation method. The results show that the executed model and algorithm based on the Bagging method and 10-fold cross-validation are efficient and effective for predicting the student's retention and graduation status, with Precision (retention = 0.909, graduation = 0.822), Recall (retention = 1.000, graduation = 0.957), Accuracy (retention = 0.909, graduation = 0.817), F1-Score (retention = 0.952, graduation = 0.885) showing significant high accuracy levels or performance rate, and low Error-rate (retention = 0.090, graduation = 0.182), respectively. In addition, by considering the individual features selected through the Wrapper method in predicting the outputs, the proposed model proved more effective for predicting the students' retention status in comparison to the graduation data. The implications of the models' output and factors that impact the effective prediction or identification of at-risk students, e.g., for timely intervention, counselling, decision-making, and sustainable educational practice are empirically discussed in the study.","<method>machine learning model - RG-DMML (retention and graduation data mining and machine learning)</method>, <method>ensemble algorithm</method>, <method>cross industry standard process for data mining (CRISP-DM) methodology</method>, <method>supervised machine learning technique</method>, <method>K-Nearest Neighbor (KNN)</method>, <method>k-fold cross-validation method</method>, <method>Bagging method</method>, <method>Wrapper method</method>",<method>ensemble algorithm</method><method>supervised machine learning technique</method><method>K-Nearest Neighbor (KNN)</method><method>Wrapper method</method>
2024,https://openalex.org/W4391649643,Psychology,Diagnosis of Alzheimer's disease via optimized lightweight convolution-attention and structural MRI,"Alzheimer's disease (AD) poses a substantial public health challenge, demanding accurate screening and diagnosis. Identifying AD in its early stages, including mild cognitive impairment (MCI) and healthy control (HC), is crucial given the global aging population. Structural magnetic resonance imaging (sMRI) is essential for understanding the brain's structural changes due to atrophy. While current deep learning networks overlook voxel long-term dependencies, vision transformers (ViT) excel at recognizing such dependencies in images, making them valuable in AD diagnosis. Our proposed method integrates convolution-attention mechanisms in transformer-based classifiers for AD brain datasets, enhancing performance without excessive computing resources. Replacing multi-head attention with lightweight multi-head self-attention (LMHSA), employing inverted residual (IRU) blocks, and introducing local feed-forward networks (LFFN) yields exceptional results. Training on AD datasets with a gradient-centralized optimizer and Adam achieves an impressive accuracy rate of 94.31% for multi-class classification, rising to 95.37% for binary classification (AD vs. HC) and 92.15% for HC vs. MCI. These outcomes surpass existing AD diagnosis approaches, showcasing the model's efficacy. Identifying key brain regions aids future clinical solutions for AD and neurodegenerative diseases. However, this study focused exclusively on the AD Neuroimaging Initiative (ADNI) cohort, emphasizing the need for a more robust, generalizable approach incorporating diverse databases beyond ADNI in future research.","<method>vision transformers (ViT)</method>, <method>convolution-attention mechanisms in transformer-based classifiers</method>, <method>lightweight multi-head self-attention (LMHSA)</method>, <method>inverted residual (IRU) blocks</method>, <method>local feed-forward networks (LFFN)</method>, <method>gradient-centralized optimizer</method>, <method>Adam</method>",<method>vision transformers (ViT)</method><method>convolution-attention mechanisms in transformer-based classifiers</method><method>lightweight multi-head self-attention (LMHSA)</method><method>Adam</method>
2024,https://openalex.org/W4392955615,Psychology,Variation in social media sensitivity across people and contexts,"Abstract Social media impacts people’s wellbeing in different ways, but relatively little is known about why this is the case. Here we introduce the construct of “social media sensitivity” to understand how social media and wellbeing associations differ across people and the contexts in which these platforms are used. In a month-long large-scale intensive longitudinal study (total n = 1632; total number of observations = 120,599), we examined for whom and under which circumstances social media was associated with positive and negative changes in social and affective wellbeing. Applying a combination of frequentist and Bayesian multilevel models, we found a small negative average association between social media use AND subsequent wellbeing, but the associations were heterogenous across people. People with psychologically vulnerable dispositions (e.g., those who were depressed, lonely, not satisfied with life) tended to experience heightened negative social media sensitivity in comparison to people who were not psychologically vulnerable. People also experienced heightened negative social media sensitivity when in certain types of places (e.g., in social places, in nature) and while around certain types of people (e.g., around family members, close ties), as compared to using social media in other contexts. Our results suggest that an understanding of the effects of social media on wellbeing should account for the psychological dispositions of social media users, and the physical and social contexts surrounding their use. We discuss theoretical and practical implications of social media sensitivity for scholars, policymakers, and those in the technology industry.","<method>frequentist multilevel models</method>, <method>Bayesian multilevel models</method>",<method>Bayesian multilevel models</method>
2024,https://openalex.org/W4394581105,Psychology,Machine learning-based detection of acute psychosocial stress from body posture and movements,"Abstract Investigating acute stress responses is crucial to understanding the underlying mechanisms of stress. Current stress assessment methods include self-reports that can be biased and biomarkers that are often based on complex laboratory procedures. A promising additional modality for stress assessment might be the observation of body movements, which are affected by negative emotions and threatening situations. In this paper, we investigated the relationship between acute psychosocial stress induction and body posture and movements. We collected motion data from N = 59 individuals over two studies ( Pilot Study : N = 20, Main Study : N = 39) using inertial measurement unit (IMU)-based motion capture suits. In both studies, individuals underwent the Trier Social Stress Test (TSST) and a stress-free control condition (friendly-TSST; f-TSST) in randomized order. Our results show that acute stress induction leads to a reproducible freezing behavior, characterized by less overall motion as well as more and longer periods of no movement. Based on these data, we trained machine learning pipelines to detect acute stress solely from movement information, achieving an accuracy of $${75.0 \pm 17.7}{\%}$$ <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""> <mml:mrow> <mml:mrow> <mml:mn>75.0</mml:mn> <mml:mo>±</mml:mo> <mml:mn>17.7</mml:mn> </mml:mrow> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> ( Pilot Study ) and $${73.4 \pm 7.7}{\%}$$ <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""> <mml:mrow> <mml:mrow> <mml:mn>73.4</mml:mn> <mml:mo>±</mml:mo> <mml:mn>7.7</mml:mn> </mml:mrow> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> ( Main Study ). This, for the first time, suggests that body posture and movements can be used to detect whether individuals are exposed to acute psychosocial stress. While more studies are needed to further validate our approach, we are convinced that motion information can be a valuable extension to the existing biomarkers and can help to obtain a more holistic picture of the human stress response. Our work is the first to systematically explore the use of full-body body posture and movement to gain novel insights into the human stress response and its effects on the body and mind.",<method>machine learning pipelines</method>,No methods remaining
2024,https://openalex.org/W4396832329,Psychology,Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis,"Today's AI systems for medical decision support often succeed on benchmark datasets in research papers but fail in real-world deployment. This work focuses on the decision making of sepsis, an acute life-threatening systematic infection that requires an early diagnosis with high uncertainty from the clinician. Our aim is to explore the design requirements for AI systems that can support clinical experts in making better decisions for the early diagnosis of sepsis. The study begins with a formative study investigating why clinical experts abandon an existing AI-powered Sepsis predictive module in their electrical health record (EHR) system. We argue that a human-centered AI system needs to support human experts in the intermediate stages of a medical decision-making process (e.g., generating hypotheses or gathering data), instead of focusing only on the final decision. Therefore, we build SepsisLab based on a state-of-the-art AI algorithm and extend it to predict the future projection of sepsis development, visualize the prediction uncertainty, and propose actionable suggestions (i.e., which additional laboratory tests can be collected) to reduce such uncertainty. Through heuristic evaluation with six clinicians using our prototype system, we demonstrate that SepsisLab enables a promising human-AI collaboration paradigm for the future of AI-assisted sepsis diagnosis and other high-stakes medical decision making.",<method>state-of-the-art AI algorithm</method>,No methods remaining
2024,https://openalex.org/W4394770576,Psychology,Exploring Factors That Support Pre-service Teachers’ Engagement in Learning Artificial Intelligence,"Abstract Artificial intelligence (AI) is becoming increasingly relevant, and students need to understand the concept. To design an effective AI program for schools, we need to find ways to expose students to AI knowledge, provide AI learning opportunities, and create engaging AI experiences. However, there is a lack of trained teachers who can facilitate students’ AI learning, so we need to focus on developing the capacity of pre-service teachers to teach AI. Since engagement is known to enhance learning, it is necessary to explore how pre-service teachers engage in learning AI. This study aimed to investigate pre-service teachers’ engagement with learning AI after a 4-week AI program at a university. Thirty-five participants took part in the study and reported their perception of engagement with learning AI on a 7-factor scale. The factors assessed in the survey included engagement (cognitive—critical thinking and creativity, behavioral, and social), attitude towards AI, anxiety towards AI, AI readiness, self-transcendent goals, and confidence in learning AI. We used a structural equation modeling approach to test the relationships in our hypothesized model using SmartPLS 4.0. The results of our study supported all our hypotheses, with attitude, anxiety, readiness, self-transcendent goals, and confidence being found to influence engagement. We discuss our findings and consider their implications for practice and policy.",<method>structural equation modeling</method>,No methods remaining
2024,https://openalex.org/W4398130977,Psychology,Imagined Speech-EEG Detection Using Multivariate Swarm Sparse Decomposition-Based Joint Time-Frequency Analysis for Intuitive BCI,"In brain-computer interface (BCI) applications, imagined speech (IMS) decoding based on electroencephalography (EEG) has established a new neuro-paradigm that offers an intuitive communication tool for physically impaired patients.However, existing IMS-EEG-based BCI systems have introduced difficulties in feasible deployment due to nonstationary EEG signals, suboptimal feature extraction, and constrained multi-class scalability.To address these challenges, we have presented a novel approach using the multivariate swarm-sparse decomposition method (MSSDM) for joint time-frequency (JTF) analysis and further developed a feasible end-to-end framework from multichannel IMS-EEG signals for imagined speech detection.MSSDM employs improved multivariate swarm filtering and sparse spectrum techniques to design optimal filter banks for extracting an ensemble of channel-aligned oscillatory components (CAOCs), significantly enhancing IMS activation-related sub-bands.To enhance channelaligned information, multivariate JTF images have been constructed using joint instantaneous frequency and instantaneous amplitude across channels from the obtained CAOCs.Further, JTFbased deep features (JTFDF) were computed using different pretrained neural networks and mapped most discriminant features using two well-known feature correlation techniques: Canonical correlation analysis and Hellinger distance-based correlation.The proposed method has been tested on the 5-class BCI Competition DB and 6-class Coretto DB IMS datasets.The experimental findings on cross-subject reveal that the novel JTFDF feature-based classification model, MSSDM-SqueezeNet-JTFDF, achieved the highest classification performance against all other existing state-of-theart methods in imagined speech recognition.","<method>multivariate swarm-sparse decomposition method (MSSDM)</method>, <method>joint time-frequency (JTF) analysis</method>, <method>multivariate swarm filtering</method>, <method>sparse spectrum techniques</method>, <method>pretrained neural networks</method>, <method>Canonical correlation analysis</method>, <method>Hellinger distance-based correlation</method>, <method>MSSDM-SqueezeNet-JTFDF</method>",<method>sparse spectrum techniques</method><method>pretrained neural networks</method><method>Canonical correlation analysis</method>
2024,https://openalex.org/W4401403528,Psychology,Financial innovation and gender dynamics: a comparative study of male and female FinTech adoption in emerging economies,"Purpose This paper aims to identify the factors influencing the adoption of financial technology (FinTech) services among Indian residents. Moreover, it compares the awareness levels among both male and female users to offer a comprehensive insight into FinTech adoption. Design/methodology/approach The research comprises two cross-sectional surveys utilizing self-administered questionnaires: Study A involves 411 male participants and Study B involves 473 female users in FinTech adoption. This article used a “Statistical Package for Social Science (SPSS) followed by partial least squares-structural equation modeling (PLS-SEM)” for data analysis. Findings The exciting finding reveals that attitude and personal innovativeness have a significant impact, while technology anxiety shows a statistically insignificant impact on awareness in both studies. Surprisingly, the socio-demographic factor significantly impacts awareness (in Study A) and has an insignificant impact on awareness in Study B. Moreover, both studies reveal that awareness significantly impacts perceived usefulness and ease of use. Additionally, the outcomes confirm a positive relation between awareness, perceived usefulness, ease of use and FinTech adoption in both studies. Practical implications The present research will offer valuable insights to all FinTech service providers and stakeholders, aiding them in planning and designing relevant policies. Originality/value As far as the researchers are aware, this study stands as the initial survey into FinTech that specifically examines the impact of gender on technology adoption. The divergence in awareness and adoption rates between males and females and the authors’ insightful findings illuminate the context's uniqueness. Moreover, this article offers a robust model for using FinTech services from the perspective of a developing economy.",<method>partial least squares-structural equation modeling (PLS-SEM)</method>,No methods remaining
2024,https://openalex.org/W4390953182,Psychology,ERTNet: an interpretable transformer-based framework for EEG emotion recognition,"Background Emotion recognition using EEG signals enables clinicians to assess patients’ emotional states with precision and immediacy. However, the complexity of EEG signal data poses challenges for traditional recognition methods. Deep learning techniques effectively capture the nuanced emotional cues within these signals by leveraging extensive data. Nonetheless, most deep learning techniques lack interpretability while maintaining accuracy. Methods We developed an interpretable end-to-end EEG emotion recognition framework rooted in the hybrid CNN and transformer architecture. Specifically, temporal convolution isolates salient information from EEG signals while filtering out potential high-frequency noise. Spatial convolution discerns the topological connections between channels. Subsequently, the transformer module processes the feature maps to integrate high-level spatiotemporal features, enabling the identification of the prevailing emotional state. Results Experiments’ results demonstrated that our model excels in diverse emotion classification, achieving an accuracy of 74.23% ± 2.59% on the dimensional model (DEAP) and 67.17% ± 1.70% on the discrete model (SEED-V). These results surpass the performances of both CNN and LSTM-based counterparts. Through interpretive analysis, we ascertained that the beta and gamma bands in the EEG signals exert the most significant impact on emotion recognition performance. Notably, our model can independently tailor a Gaussian-like convolution kernel, effectively filtering high-frequency noise from the input EEG data. Discussion Given its robust performance and interpretative capabilities, our proposed framework is a promising tool for EEG-driven emotion brain-computer interface.","<method>hybrid CNN and transformer architecture</method>, <method>temporal convolution</method>, <method>spatial convolution</method>, <method>transformer module</method>, <method>CNN</method>, <method>LSTM</method>",<method>hybrid CNN and transformer architecture</method><method>temporal convolution</method><method>spatial convolution</method><method>transformer module</method><method>CNN</method><method>LSTM</method>
2024,https://openalex.org/W4392449443,Psychology,RGBT Tracking via Challenge-Based Appearance Disentanglement and Interaction,"RGB and thermal source data suffer from both shared and specific challenges, and how to explore and exploit them plays a critical role in representing the target appearance in RGBT tracking. In this paper, we propose a novel approach, which performs target appearance representation disentanglement and interaction via both modality-shared and modality-specific challenge attributes, for robust RGBT tracking. In particular, we disentangle the target appearance representations via five challenge-based branches with different structures according to their properties, including three parameter-shared branches to model modality-shared challenges and two parameter-independent branches to model modality-specific challenges. Considering the complementary advantages between modality-specific cues, we propose a guidance interaction module to transfer discriminative features from one modality to another one to enhance the discriminative ability of weak modality. Moreover, we design an aggregation interaction module to combine all challenge-based target representations, which could form more discriminative target representations and fit the challenge-agnostic tracking process. These challenge-based branches are able to model the target appearance under certain challenges so that the target representations can be learned by a few parameters even in the situation of insufficient training data. In addition, to relieve labor costs and avoid label ambiguity, we design a generation strategy to generate training data with different challenge attributes. Comprehensive experiments demonstrate the superiority of the proposed tracker against the state-of-the-art methods on four benchmark datasets.","<method>target appearance representation disentanglement</method>, <method>guidance interaction module</method>, <method>aggregation interaction module</method>, <method>generation strategy to generate training data with different challenge attributes</method>",No methods remaining
2024,https://openalex.org/W4392762829,Psychology,"Nexus between perception, purpose of use, technical challenges and satisfaction for mobile financial services: theory and empirical evidence from Bangladesh","Purpose This study analyzed the relationship between mobile financial services (MFS) usage and customer satisfaction with MFS in Bangladesh, considering perception, purpose of use and technical challenges as the primary factors influencing customer satisfaction with MFS. The aim is to determine the factors most influencing the use of MFS. Design/methodology/approach Data were collected from 400 MFS users through a structured web survey using snowball sampling that is consistent with the nature of MFS users who are difficult to identify or locate. Structural equation modeling (SEM) was used to analyze the data and evaluate the reliability and validity of the measurement model. Findings The results show that customers’ perceptions and satisfaction significantly impact their intention to use MFS. Specifically, customers’ perceptions strongly influence their satisfaction with MFS, and the purpose of use significantly predicts both perception and satisfaction. Technical problems and challenges were found to have no significant impact on satisfaction levels, but other factors were more critical. Furthermore, the integration of innovative technological solutions is crucial for fostering sustainability in MFS, as it enhances reliability and efficiency while minimizing environmental footprints. Research limitations/implications The study was conducted in a single country, relied on self-reported data, and used a cross-sectional design, which limits the ability to draw causal inferences. Future research could explore the factors that influence customer satisfaction with MFS in different countries and regions and incorporate additional variables to provide a more comprehensive understanding of the drivers of customer satisfaction with MFS. Originality/value This study significantly contributes by extending the technology acceptance model (TAM) framework with the innovation resistance theory, offering a nuanced understanding of MFS adoption. The findings challenge conventional wisdom, highlighting the limited impact of technical problems on satisfaction and emphasizing the central role of user perceptions in shaping satisfaction and intention to use.",<method>Structural equation modeling (SEM)</method>,No methods remaining
2024,https://openalex.org/W4393218816,Psychology,A study on smart home use intention of elderly consumers based on technology acceptance models,"Purpose Smart home devices have great potential to improve the quality of life and independence of older people, positively impacting their health, safety, and comfort. However, Chinese research in this field is still in its early stages. Therefore, more comprehensive and in-depth studies are needed to comprehend the various aspects influencing the acceptance and use of smart homes by older users. Patients and methods This study adopted the Technology Acceptance Model (TAM) and included perceived usefulness, perceived ease of use, usage intention, intergenerational technology support, perceived value, and perceived risk as extension variables to delve deeper into the behavioral intentions of older users in smart home services. The study used a convenience sampling method to randomly distribute 236 questionnaires among older adults over the age of 60 in the school’s community and neighboring urban communities who have experience in smart home use and who can complete human-computer interactions either independently or with the help of others, mainly focusing on the four sections: user characteristics, family situation, experience of use, and usage intention. The study used structural equation modeling (SEM) and factor analysis to analyze the completion of questionnaires. Finally, we conducted a validation analysis of the rationality and scientificity of the model and derived the six dimensions of the model of the influencing factors on the use of smart home products by the elderly and the weight sizes of their corresponding 13 influencing factors. Results The results show that perceived usefulness and perceived ease of use have a positive effect on users’ intention to use smart homes. Perceived ease of use has a positive effect on the perceived usefulness of smart homes. In addition, intergenerational technology support, perceived value, and perceived risk impact users’ perceived usefulness and perceived ease of use of the smart home. Conclusion This research aims to describe the factors influencing older users’ willingness to use smart homes. The findings are not only significant for the elderly in China but also of broad value to other regions and countries facing similar demographic challenges. The development of smart homes not only involves the elderly but is also closely related to all segments of society. The government should increase policy support and guide more social forces to participate in the development of the smart home industry. Service providers and designers should fully understand the demand situation and user experience of target users to develop easy-to-use smart home solutions. At the same time, smart homes, as intelligent products for the elderly, need to focus not only on the basic needs of the elderly such as material life and home safety, but also on the spiritual needs of elderly users. Children or caregivers should always pay attention to the psychological state of the elderly and actively guide them to use smart homes to help them realize their self-worth. We look forward to more research focusing on this area in the future and further exploring the specific issues and solutions involved.","<method>Technology Acceptance Model (TAM)</method>, <method>structural equation modeling (SEM)</method>, <method>factor analysis</method>",<method>factor analysis</method>
2024,https://openalex.org/W4394948580,Psychology,Inductive Cognitive Diagnosis for Fast Student Learning in Web-Based Intelligent Education Systems,"Cognitive diagnosis aims to gauge students' mastery levels based on their response logs.Serving as a pivotal module in web-based online intelligent education systems (WOIESs), it plays an upstream and fundamental role in downstream tasks like learning item recommendation and computerized adaptive testing.WOIESs are open learning environment where numerous new students constantly register and complete exercises.In WOIESs, efficient cognitive diagnosis is crucial to fast feedback and accelerating student learning.However, the existing cognitive diagnosis methods always employ intrinsically transductive student-specific embeddings, which become slow and costly due to retraining when dealing with new students who are unseen during training.To this end, this paper proposes an inductive cognitive diagnosis model (ICDM) for fast new students' mastery levels inference in WOIESs.Specifically, in ICDM, we propose a novel student-centered graph (SCG).Rather than inferring mastery levels through updating student-specific embedding, we derive the inductive mastery levels as the aggregated outcomes of students' neighbors in SCG.Namely, SCG enables to shift the task from finding the most suitable student-specific embedding that fits the response logs to finding the most suitable representations for different node types in SCG, and the latter is more efficient since it no longer requires retraining.To obtain this representation, ICDM consists of a construction-aggregation-generationtransformation process to learn the final representation of students, exercises and concepts.Extensive experiments across real-world datasets show that, compared with the existing cognitive diagnosis methods that are always transductive, ICDM is much more faster while maintains the competitive inference performance for new students.","<method>inductive cognitive diagnosis model (ICDM)</method>, <method>student-centered graph (SCG)</method>",No methods remaining
2024,https://openalex.org/W4400196518,Psychology,"Loyalty toward shared e-scooter: Exploring the role of service quality, satisfaction, and environmental consciousness","Shared electric scooter services (SESS) have gained popularity in many cities as an emerging mobility mode. However, SESS is attributed to low utilization rates in some cities. In this context, the significance of users' satisfaction with the provided services, along with their loyalty, becomes particularly pronounced. Therefore, it is essential to evaluate the service quality (SQ) from the users' perspective and understand its effect on satisfaction and loyalty, which are critical factors for the long-term durability and success of service. Thus, this study examines the determinants of user satisfaction and loyalty toward SESS. For this, we conducted an online survey among the SESS users in Chicago. We analyzed the responses using partial least squares structural equation modeling (PLS-SEM) and reflexive thematic analysis (TA). Our results confirm the quality-value-satisfaction-loyalty paradigm and indicate that users' perceptions of SQ, including safety and security, service availability, interface, and perceived affordability, significantly contribute to user loyalty enhancement toward SESS. Perceived value (hedonic value, utilitarian value, and perceived affordability) and satisfaction mediate the impact of SQ on loyalty. Additionally, the results indicate that those who perceive SESS as cost-effective report higher satisfaction levels. Furthermore, users who have pro-environmental attitudes and view SESS as environmentally friendly are more likely to derive hedonic value from the service and exhibit higher loyalty. The TA uncovers key challenges from the user perspective, including pricing, service timing, end-trip facilities (e.g., parking), street pavement condition, vendor operational zoning, and fleet quality, with a specific emphasis on GPS accuracy. These findings provide valuable insights into user behavioral mechanisms, which can be considered as a manifest for service improvement and enhancing efficiency.","<method>partial least squares structural equation modeling (PLS-SEM)</method>, <method>reflexive thematic analysis (TA)</method>",No methods remaining
2024,https://openalex.org/W4400726844,Psychology,Enhancing Brain Tumor Classification by a Comprehensive Study on Transfer Learning Techniques and Model Efficiency Using MRI Datasets,"Brain tumors, a significant health concern, are a leading cause of mortality globally, with an annual projected increase of 5% by the World Health Organization. This work aims to comprehensively analyze the performance of transfer learning methods in identifying the types of brain tumors, with a particular emphasis on the necessity of prompt identification. The study demonstrates how useful it is to use pre-trained models, including models VGG-16, VGG-19, Inception-v3, ResNet-50, DenseNet, and MobileNet—on MRI datasets and used to obtain a precise classification. Using these methods model accuracy and efficiency have been enhanced. The research aims to contribute to improved treatment planning and patient outcomes by implementing optimal methodologies for precise and automated brain tumor analysis, evaluation framework encompasses vital metrics such as confusion matrices, ROC curves, and the achieved Area Under the Curve (AUC) for each approach. The comprehensive methodology outlined in this paper serves as a systematic guide for the implementation and evaluation of brain tumor classification models utilizing deep learning techniques. The integration of visual representations, code snippets, and performance metrics significantly enhances the clarity and understanding of the proposed approach. Among our proposed algorithms, VGG-16 attains the highest accuracy at 97% and consumes only 22% of time as compared to our previous proposed methodology.","<method>transfer learning</method>, <method>VGG-16</method>, <method>VGG-19</method>, <method>Inception-v3</method>, <method>ResNet-50</method>, <method>DenseNet</method>, <method>MobileNet</method>",<method>transfer learning</method><method>VGG-16</method><method>VGG-19</method><method>Inception-v3</method><method>ResNet-50</method><method>DenseNet</method><method>MobileNet</method>
2024,https://openalex.org/W4390771316,Psychology,Building typology classification using convolutional neural networks utilizing multiple ground-level image process for city-scale rapid seismic vulnerability assessment,"Several studies have focused on generating seismic vulnerability maps for earthquake-prone areas, particularly in Indonesia. Building typologies are a key factor in determining vulnerability to earthquakes. However, conducting large-scale field surveys to determine the spatial distribution of building typologies in a city is uneconomical. This paper explores the use of a convolutional neural network (CNN) to automatically detect building typologies from diverse regions in Indonesia, utilizing both conventional and automated building image acquisition processes. In this study, datasets from three distinct image acquisition methods are trained with four unique CNN architectures to identify the best-performing model to classify building typologies. The sample size effect on CNN performance is also investigated. The results showed that randomly sampled Google Street View (GSV) images are the most effective dataset for the CNN model, achieving an f1-score of 84.33%. Among the network architectures tested, MobileNet demonstrated superior performance on the majority of evaluated datasets. As the sample size increases by about 350% in the dataset, there is a positive correlation with up to 2.3% f1-score improvement. Using the best-performing CNN model, two building vulnerability models were employed to assess the spatial distribution of building damage in the urban area of Bandung, considering a hypothetical scenario of an M7 earthquake. Incorporating local construction data, one of the generated maps estimated that approximately 55% of buildings in Bandung would experience moderate to severe structural damage. This study showcases the potential of CNN models in automating regional seismic assessments and providing valuable insights for comprehensive seismic mitigation strategies.","<method>convolutional neural network (CNN)</method>, <method>CNN architectures</method>, <method>MobileNet</method>",<method>convolutional neural network (CNN)</method><method>CNN architectures</method><method>MobileNet</method>
2024,https://openalex.org/W4390817372,Psychology,Brain structure ages—A new biomarker for multi‐disease classification,"Age is an important variable to describe the expected brain's anatomy status across the normal aging trajectory. The deviation from that normative aging trajectory may provide some insights into neurological diseases. In neuroimaging, predicted brain age is widely used to analyze different diseases. However, using only the brain age gap information (i.e., the difference between the chronological age and the estimated age) can be not enough informative for disease classification problems. In this paper, we propose to extend the notion of global brain age by estimating brain structure ages using structural magnetic resonance imaging. To this end, an ensemble of deep learning models is first used to estimate a 3D aging map (i.e., voxel-wise age estimation). Then, a 3D segmentation mask is used to obtain the final brain structure ages. This biomarker can be used in several situations. First, it enables to accurately estimate the brain age for the purpose of anomaly detection at the population level. In this situation, our approach outperforms several state-of-the-art methods. Second, brain structure ages can be used to compute the deviation from the normal aging process of each brain structure. This feature can be used in a multi-disease classification task for an accurate differential diagnosis at the subject level. Finally, the brain structure age deviations of individuals can be visualized, providing some insights about brain abnormality and helping clinicians in real medical contexts.",<method>ensemble of deep learning models</method>,<method>ensemble of deep learning models</method>
2024,https://openalex.org/W4391350390,Psychology,"Machine learning in physical activity, sedentary, and sleep behavior research","Abstract The nature of human movement and non-movement behaviors is complex and multifaceted, making their study complicated and challenging. Thanks to the availability of wearable activity monitors, we can now monitor the full spectrum of physical activity, sedentary, and sleep behaviors better than ever before—whether the subjects are elite athletes, children, adults, or individuals with pre-existing medical conditions. The increasing volume of generated data, combined with the inherent complexities of human movement and non-movement behaviors, necessitates the development of new data analysis methods for the research of physical activity, sedentary, and sleep behaviors. The characteristics of machine learning (ML) methods, including their ability to deal with complicated data, make them suitable for such analysis and thus can be an alternative tool to deal with data of this nature. ML can potentially be an excellent tool for solving many traditional problems related to the research of physical activity, sedentary, and sleep behaviors such as activity recognition, posture detection, profile analysis, and correlates research. However, despite this potential, ML has not yet been widely utilized for analyzing and studying these behaviors. In this review, we aim to introduce experts in physical activity, sedentary behavior, and sleep research—individuals who may possess limited familiarity with ML—to the potential applications of these techniques for analyzing their data. We begin by explaining the underlying principles of the ML modeling pipeline, highlighting the challenges and issues that need to be considered when applying ML. We then present the types of ML: supervised and unsupervised learning, and introduce a few ML algorithms frequently used in supervised and unsupervised learning. Finally, we highlight three research areas where ML methodologies have already been used in physical activity, sedentary behavior, and sleep behavior research, emphasizing their successes and challenges. This paper serves as a resource for ML in physical activity, sedentary, and sleep behavior research, offering guidance and resources to facilitate its utilization.","<method>supervised learning</method>, <method>unsupervised learning</method>",<method>supervised learning</method><method>unsupervised learning</method>
2024,https://openalex.org/W4391509840,Psychology,A dynamic Bayesian optimized active recommender system for curiosity-driven partially Human-in-the-loop automated experiments,"Abstract Optimization of experimental materials synthesis and characterization through active learning methods has been growing over the last decade, with examples ranging from measurements of diffraction on combinatorial alloys at synchrotrons, to searches through chemical space with automated synthesis robots for perovskites. In virtually all cases, the target property of interest for optimization is defined a priori with the ability to shift the trajectory of the optimization based on human-identified findings during the experiment is lacking. Thus, to highlight the best of both human operators and AI-driven experiments, here we present the development of a human–AI collaborated experimental workflow, via a Bayesian optimized active recommender system (BOARS), to shape targets on the fly with human real-time feedback. Here, the human guidance overpowers AI at early iteration when prior knowledge (uncertainty) is minimal (higher), while the AI overpowers the human during later iterations to accelerate the process with the human-assessed goal. We showcase examples of this framework applied to pre-acquired piezoresponse force spectroscopy of a ferroelectric thin film, and in real-time on an atomic force microscope, with human assessment to find symmetric hysteresis loops. It is found that such features appear more affected by subsurface defects than the local domain structure. This work shows the utility of human–AI approaches for curiosity driven exploration of systems across experimental domains.","<method>active learning</method>, <method>Bayesian optimized active recommender system (BOARS)</method>",<method>active learning</method>
2024,https://openalex.org/W4391930362,Psychology,Designing AI for mental health diagnosis: challenges from sub-Saharan African value-laden judgements on mental health disorders,"Recently clinicians have become more reliant on technologies such as artificial intelligence (AI) and machine learning (ML) for effective and accurate diagnosis and prognosis of diseases, especially mental health disorders. These remarks, however, apply primarily to Europe, the USA, China and other technologically developed nations. Africa is yet to leverage the potential applications of AI and ML within the medical space. Sub-Saharan African countries are currently disadvantaged economically and infrastructure-wise. Yet precisely, these circumstances create significant opportunities for the deployment of medical AI, which has already been deployed in some places in the continent. However, while AI and ML have come with enormous promises in Africa, there are still challenges when it comes to successfully applying AI and ML designed elsewhere within the African context, especially in diagnosing mental health disorders. We argue, in this paper, that there ought not to be a homogeneous/generic design of AI and ML used in diagnosing mental health disorders. Our claim is grounded on the premise that mental health disorders cannot be diagnosed solely on 'factual evidence' but on both factual evidence and value-laden judgements of what constitutes mental health disorders in sub-Saharan Africa. For ML to play a successful role in diagnosing mental health disorders in sub-Saharan African medical spaces, with a precise focus on South Africa, we allude that it ought to understand what sub-Saharan Africans consider as mental health disorders, that is, the value-laden judgements of some conditions.","<method>artificial intelligence (AI)</method>, <method>machine learning (ML)</method>",<method>machine learning (ML)</method>
2024,https://openalex.org/W4392130768,Psychology,EEG-based brain-computer interface methods with the aim of rehabilitating advanced stage ALS patients,"Amyotrophic Lateral Sclerosis (ALS) is a neurodegenerative disease that leads to progressive muscle weakness and paralysis, ultimately resulting in the loss of ability to communicate and control the environment. EEG-based Brain-Computer Interface (BCI) methods have shown promise in providing communication and control with the aim of rehabilitating ALS patients. In particular, P300-based BCI has been widely studied and used for ALS rehabilitation. Other EEG-based BCI methods, such as Motor Imagery (MI) based BCI and Hybrid BCI, have also shown promise in ALS rehabilitation. Nonetheless, EEG-based BCI methods hold great potential for improvement. This review article introduces and reviews FFT, WPD, CSP, CSSP, CSP, and GC feature extraction methods. The Common Spatial Pattern (CSP) is an efficient and common technique for extracting data properties used in BCI systems. In addition, Linear Discriminant Analysis (LDA), Support Vector Machine (SVM), Neural Networks (NN), and Deep Learning (DL) classification methods were introduced and reviewed. SVM is the most appropriate classifier due to its insensitivity to the curse of dimensionality. Also, DL is used in the design of BCI systems and is a good choice for BCI systems based on motor imagery with big datasets. Despite the progress made in the field, there are still challenges to overcome, such as improving the accuracy and reliability of EEG signal detection and developing more intuitive and user-friendly interfaces By using BCI, disabled patients can communicate with their caregivers and control their environment using various devices, including wheelchairs, and robotic arms.","<method>FFT</method>, <method>WPD</method>, <method>CSP</method>, <method>CSSP</method>, <method>GC</method>, <method>Linear Discriminant Analysis (LDA)</method>, <method>Support Vector Machine (SVM)</method>, <method>Neural Networks (NN)</method>, <method>Deep Learning (DL)</method>",<method>Linear Discriminant Analysis (LDA)</method><method>Support Vector Machine (SVM)</method><method>Neural Networks (NN)</method><method>Deep Learning (DL)</method>
2024,https://openalex.org/W4392262143,Psychology,Brain Tumor Detection for Efficient Adaptation and Superior Diagnostic Precision by Utilizing MBConv-Finetuned-B0 and Advanced Deep Learning,"In the rapidly evolving landscape of medical imaging, our proposed work presents an innovative and efficient approach to brain tumor detection through advanced deep learning methodologies.Central to our methodology is the strategic utilization of pre-trained weights from the formidable MBConv-Finetuned-B0 model, initially honed on the expansive ImageNet dataset, providing a foundation rich in general visual knowledge.Our subsequent fine-tuning process targets specific layers relevant to brain tumor detection, introducing two distinct convolutional layers, MBConv 6, 55, and MBConv 6, 30, meticulously added to the MBConv-Finetuned-B0 base model.These layers are intricately designed to extract and refine features specific to brain tumors, ensuring a nuanced understanding of pathology and enhancing the model's discrimination and accuracy.The flexibility of our methodology is exemplified by the thoughtful consideration of two fine-tuning options: one that adjusts all layers of the model and another that selectively fine-tunes only the proposed layers.We conduct a detailed comparative analysis, including homogeneity and median feature values, placing our work in direct comparison with established techniques such as Ensemble Transfer Learning and Quantum Variational Classifier (ETL & QVC), Ultra-Light Deep Learning (ULDL) Model, Deep Convolutional Neural Network (DCNN), and Deep Learning and Image Processing (DLIP).The results showcase the model's proficiency, achieving an accuracy of 94%, precision of 84%, recall of 92%, F1 score of 88%, and an AUC-ROC of 96%.Notably, our model demonstrates superior performance in terms of homogeneity (vE Homogeneity: 0.93, vN Homogeneity: 0.91, Enhancement Homogeneity: 0.97) and median feature values (Median vE Feature Value: 0.82, Median vN Feature Value: 0.87, Median Enhancement Feature Value: 0.80), providing a comprehensive understanding of its effectiveness in capturing subtle nuances in brain tumor images.","<method>MBConv-Finetuned-B0 model</method>, <method>fine-tuning</method>, <method>Ensemble Transfer Learning (ETL)</method>, <method>Quantum Variational Classifier (QVC)</method>, <method>Ultra-Light Deep Learning (ULDL) Model</method>, <method>Deep Convolutional Neural Network (DCNN)</method>, <method>Deep Learning and Image Processing (DLIP)</method>",<method>fine-tuning</method><method>Quantum Variational Classifier (QVC)</method><method>Deep Convolutional Neural Network (DCNN)</method>
2024,https://openalex.org/W4392514027,Psychology,Introducing machine‐learning‐based data fusion methods for analyzing multimodal data: An application of measuring trustworthiness of microenterprises,"Abstract Research Summary Multimodal data, comprising interdependent unstructured text, image, and audio data that collectively characterize the same source, with video being a prominent example, offer a wealth of information for strategy researchers. We emphasize the theoretical importance of capturing the interdependencies between different modalities when evaluating multimodal data. To automate the analysis of video data, we introduce advanced deep machine learning and data fusion methods that comprehensively account for all intra‐ and inter‐modality interdependencies. Through an empirical demonstration focused on measuring the trustworthiness of grassroots sellers in live streaming commerce on Tik Tok, we highlight the crucial role of interpersonal interactions in the business success of microenterprises. We provide access to our data and algorithms to facilitate data fusion in strategy research that relies on multimodal data. Managerial Summary Our study highlights the vital role of both verbal and nonverbal communication in attaining strategic objectives. Through the analysis of multimodal data—incorporating text, images, and audio—we demonstrate the essential nature of interpersonal interactions in bolstering trustworthiness, thus facilitating the success of microenterprises. Leveraging advanced machine learning techniques, such as data fusion for multimodal data and explainable artificial intelligence, we notably enhance predictive accuracy and theoretical interpretability in assessing trustworthiness. By bridging strategic research with cutting‐edge computational techniques, we provide practitioners with actionable strategies for enhancing communication effectiveness and fostering trust‐based relationships. Access our data and code for further exploration.","<method>deep machine learning</method>, <method>data fusion</method>, <method>advanced machine learning techniques</method>, <method>explainable artificial intelligence</method>",No methods remaining
2024,https://openalex.org/W4393964796,Psychology,Human-machine dialogues unveiled: an in-depth exploration of individual attitudes and adoption patterns toward AI-powered ChatGPT systems,"Purpose ChatGPT is an advanced artificial intelligence (AI) form that can generate human-like text based on large amounts of data. This paper aims to empirically examine the ChatGPT adoption level among Indian individuals by considering the key factors in determining individuals’ attitudes and intentions toward newly emerged AI tools. Design/methodology/approach This paper used “partial least square structural equation modeling” (PLS-SEM) to investigate the relation among several latent factors by applying a representative sample of 351 individuals. Findings This study found that trialability, performance expectancy and personal innovativeness significantly influence individuals' attitudes, while compatibility and effort expectancy do not significantly impact attitudes. Additionally, trialability, performance expectancy, effort expectancy, personal innovativeness and attitude significantly influence behavioral intentions. However, compatibility has an insignificant impact on behavioral intention. Moreover, the research highlights that attitude and behavioral intention directly correlate with actual use. Specifically, the absence of compatibility makes people hesitate to use technology that does not meet their specific needs. Practical implications These unique findings provide valuable insights for technology service providers and government entities. They can use this information to shape their policies, deliver timely and relevant updates and enhance their strategies to boost the adoption of ChatGPT. Originality/value This paper is one of the pioneering attempts to exhibit the research stream to understand the individual acceptance of ChatGPT in an emerging country. Moreover, it gained significant attention from individuals for delivering a unique experience and promising solutions.",<method>partial least square structural equation modeling (PLS-SEM)</method>,No methods remaining
2024,https://openalex.org/W4394997844,Psychology,Revisiting drug–protein interaction prediction: a novel global–local perspective,"Abstract Motivation Accurate inference of potential drug–protein interactions (DPIs) aids in understanding drug mechanisms and developing novel treatments. Existing deep learning models, however, struggle with accurate node representation in DPI prediction, limiting their performance. Results We propose a new computational framework that integrates global and local features of nodes in the drug–protein bipartite graph for efficient DPI inference. Initially, we employ pre-trained models to acquire fundamental knowledge of drugs and proteins and to determine their initial features. Subsequently, the MinHash and HyperLogLog algorithms are utilized to estimate the similarity and set cardinality between drug and protein subgraphs, serving as their local features. Then, an energy-constrained diffusion mechanism is integrated into the transformer architecture, capturing interdependencies between nodes in the drug–protein bipartite graph and extracting their global features. Finally, we fuse the local and global features of nodes and employ multilayer perceptrons to predict the likelihood of potential DPIs. A comprehensive and precise node representation guarantees efficient prediction of unknown DPIs by the model. Various experiments validate the accuracy and reliability of our model, with molecular docking results revealing its capability to identify potential DPIs not present in existing databases. This approach is expected to offer valuable insights for furthering drug repurposing and personalized medicine research. Availability and implementation Our code and data are accessible at: https://github.com/ZZCrazy00/DPI.","<method>pre-trained models</method>, <method>transformer architecture</method>, <method>multilayer perceptrons</method>",<method>transformer architecture</method><method>multilayer perceptrons</method>
2024,https://openalex.org/W4395675470,Psychology,Transforming Landslide Prediction: A Novel Approach Combining Numerical Methods and Advanced Correlation Analysis in Slope Stability Investigation,"Landslides cause significant economic losses and casualties worldwide. However, robust prediction remains challenging due to the complexity of geological factors contributing to slope stability. Advanced correlation analysis methods can improve prediction capabilities. This study aimed to develop a novel landslide prediction approach that combines numerical modeling and correlation analysis (Spearman rho and Kendall tau) to improve displacement-based failure prediction. Simulations generate multi-location displacement data sets on soil and rock slopes under incremental stability reductions. Targeted monitoring points profile local displacement responses. Statistical analyses, including mean/variance and Spearman/Kendall correlations, quantified displacement-stability relationships. For the homogeneous soil slope, monitoring point 2 of the middle section of the slope showed a mean horizontal displacement of 17.65 mm and a mean vertical displacement of 9.72 mm under stability reduction. Spearman’s rho correlation coefficients ranged from 0.31 to 0.76, while Kendall’s tau values ranged from 0.29 to 0.64, indicating variable displacement–stability relationships. The joint rock slope model had strong positive total displacement correlations (Spearman’s and Kendall’s correlation ranges of +1.0 and −1.0) at most points. Horizontal and vertical displacements reached mean maxima of 44.13 mm and 22.17 mm, respectively, at the unstable point 2 of the center section of the slope. The advanced correlation analysis techniques provided superior identification of parameters affecting slope stability compared to standard methods. The generated predictive model dramatically improves landslide prediction capability, allowing preventive measures to be taken to mitigate future losses through this new approach.","<method>numerical modeling</method>, <method>correlation analysis (Spearman rho)</method>, <method>correlation analysis (Kendall tau)</method>",No methods remaining
2024,https://openalex.org/W4399563755,Psychology,Exploring the frontier: Transformer-based models in EEG signal analysis for brain-computer interfaces,"This review systematically explores the application of transformer-based models in EEG signal processing and brain-computer interface (BCI) development, with a distinct focus on ensuring methodological rigour and adhering to empirical validations within the existing literature. By examining various transformer architectures, such as the Temporal Spatial Transformer Network (TSTN) and EEG Conformer, this review delineates their capabilities in mitigating challenges intrinsic to EEG data, such as noise and artifacts, and their subsequent implications on decoding and classification accuracies across disparate mental tasks. The analytical scope extends to a meticulous examination of attention mechanisms within transformer models, delineating their role in illuminating critical temporal and spatial EEG features and facilitating interpretability in model decision-making processes. The discourse additionally encapsulates emerging works that substantiate the efficacy of transformer models in noise reduction of EEG signals and diversifying applications beyond the conventional motor imagery paradigm. Furthermore, this review elucidates evident gaps and propounds exploratory avenues in the applications of pre-trained transformers in EEG analysis and the potential expansion into real-time and multi-task BCI applications. Collectively, this review distils extant knowledge, navigates through the empirical findings, and puts forward a structured synthesis, thereby serving as a conduit for informed future research endeavours in transformer-enhanced, EEG-based BCI systems.","<method>transformer-based models</method>, <method>Temporal Spatial Transformer Network (TSTN)</method>, <method>EEG Conformer</method>, <method>attention mechanisms within transformer models</method>",<method>transformer-based models</method><method>attention mechanisms within transformer models</method>
2024,https://openalex.org/W4390725372,Psychology,A Novel EEG-Based Parkinson’s Disease Detection Model Using Multiscale Convolutional Prototype Networks,"Objective and accurate detection of Parkinson's disease (PD) is crucial for timely intervention and treatment. Electroencephalography (EEG) has been proven to characterize PD by measuring brain activity. In recent years, deep learning methods have gained great attention in automated PD detection, but their performance is limited by insufficient data samples. In this article, we propose a novel PD automated detection model named the multiscale convolutional prototype network (MCPNet), which integrates and improves upon multiscale convolutional neural networks (CNNs) and prototype learning. On the one hand, it employs multiscale CNNs to extract brain features from different scales, enhancing feature diversity and utilization. On the other hand, a prototype calibration strategy is introduced to mitigate the effect of data noise on prototype generation, improving the generalization performance of model. Multiple within-dataset and cross-dataset experiments on three different datasets demonstrate the effectiveness of our model in PD detection. The leave-one-subject-out (LOSO) results of within-dataset experiments show that MCPNet achieves an accuracy of 92.5%, a sensitivity of 93.1%, a specificity of 91.9%, and an AUC of 92.4% in cross-subject classification between PD patients and healthy controls. In the cross-dataset classification, the performance of MCPNet is somewhat weakened due to dataset variations. However, this weakening is partially compensated by introducing the prototype calibration strategy. With the introduction of the calibration strategy, the accuracy of cross-dataset classification increases to 90.2%, a 4.0% improvement compared to when it is not used. These results indicate that the proposed model may be a promising tool for automated PD diagnosis.","<method>multiscale convolutional neural networks (CNNs)</method>, <method>prototype learning</method>, <method>prototype calibration strategy</method>",<method>multiscale convolutional neural networks (CNNs)</method><method>prototype learning</method>
2024,https://openalex.org/W4390961691,Psychology,"E-government quality from the citizen's perspective: the role of perceived factors, demographic variables and the digital divide","Purpose Governments globally are adopting e-Government services to streamline administrative processes and meet citizens' expectations. This study investigates e-Government service quality from citizens' perspectives in 50 Greek municipalities, using the technology acceptance model (TAM) and cognitive theory. Design/methodology/approach The data from 707 respondents across 50 Greek municipalities are analyzed using structural equation modeling (SEM), ANOVA and moderation analysis. The study assesses the relationships between key factors and citizens' intentions to use e-Government services, examining the impact of demographics and the digital divide. Findings The study reveals that perceived attractiveness (PA), perceived usefulness (PU), perceived ease of use (PEOU) and awareness (AWA) significantly influence citizens' behavioral intentions (BINTs) toward municipal e-Government services. Interestingly, PEOU negatively impacts users' intentions, suggesting dissatisfaction with portal attractiveness and utility. The study explores the influence of demographic variables and the digital divide on citizens' BINTs, highlighting economic activity and income as crucial determinants. Practical implications The study emphasizes the significance of user-friendly design, PU, PEOU and AWA campaigns for the development of effective e-Government platforms. Strategies to address the digital divide and promote citizen engagement are essential for enhancing user experience, service utility and AWA, ultimately fostering a positive attitude toward e-Government. Social implications Addressing demographic differences ensures inclusive e-Government systems, while bridging the digital divide promotes equitable service delivery and citizen engagement. Originality/value This research provides insights into factors influencing citizens' BINTs toward e-Government services. The study's examination of demographic attributes and the digital divide enhances understanding, contributing to the development of citizen-centric e-Government services and supporting inclusive digital transformations.","<method>structural equation modeling (SEM)</method>, <method>ANOVA</method>, <method>moderation analysis</method>",No methods remaining
2024,https://openalex.org/W4391407181,Psychology,DiffMDD: A Diffusion-Based Deep Learning Framework for MDD Diagnosis Using EEG,"Major Depression Disorder (MDD) is a common yet destructive mental disorder that affects millions of people worldwide. Making early and accurate diagnosis of it is very meaningful. Recently, EEG, a non-invasive technique of recording spontaneous electrical activity of brains, has been widely used for MDD diagnosis. However, there are still some challenges in data quality and data size of EEG: (1) A large amount of noise is inevitable during EEG collection, making it difficult to extract discriminative features from raw EEG; (2) It is difficult to recruit a large number of subjects to collect sufficient and diverse data for model training. Both of the challenges cause the overfitting problem, especially for deep learning methods. In this paper, we propose DiffMDD, a diffusion-based deep learning framework for MDD diagnosis using EEG. Specifically, we extract more noise-irrelevant features to improve the model's robustness by designing the Forward Diffusion Noisy Training Module. Then we increase the size and diversity of data to help the model learn more generalized features by designing the Reverse Diffusion Data Augmentation Module. Finally, we re-train the classifier on the augmented dataset for MDD diagnosis. We conducted comprehensive experiments to test the overall performance and each module's effectiveness. The framework was validated on two public MDD diagnosis datasets, achieving the state-of-the-art performance.","<method>diffusion-based deep learning framework</method>, <method>Forward Diffusion Noisy Training Module</method>, <method>Reverse Diffusion Data Augmentation Module</method>",<method>diffusion-based deep learning framework</method>
2024,https://openalex.org/W4391468027,Psychology,Predicting University Student Graduation Using Academic Performance and Machine Learning: A Systematic Literature Review,"Predicting university student graduation is a beneficial tool for both students and institutions. With the help of this predictive capacity, students may make well-informed decisions about their academic and career paths, and institutions can proactively identify students who may not graduate and offer tailored support to ensure their success. The use of machine learning for predicting university student graduation has drawn more attention in recent years. Large datasets of student academic performance data can be used to train machine learning algorithms to identify patterns that are applicable in predicting future outcomes. In accordance with some studies, this approach predicts student graduation with an accuracy rate as high as 90%. Many SLRs have been conducted in this field, but there are still limitations, including not discussing the predictive models and algorithms used, a lack of coverage of the machine learning algorithms applied, small database coverage, keyword selection that does not cover all synonyms relevant to the investigation, and less specific data collection transparency. By delving into the limitations of existing SLRs on this topic, this research not only enhances the understanding of machine learning applications in forecasting student graduation but also fills a crucial gap in the literature. The inclusion of weaknesses in current SLRs provides a foundation for justifying the need for this study, emphasizing the necessity of a more nuanced and comprehensive review to advance the field and guide future research efforts in smart learning environments. This research conducts a thorough systematic review of the existing literature on machine learning-based student graduation prediction models from 70 journal articles from 2018 through 2023 that are pertinent. This review includes the various machine learning algorithms that have been implemented, the various academic performance data that was obtained from students, and the effectiveness of the models that have been developed. It also discusses the difficulties and potential advantages of utilizing machine learning to predict student graduation. The review indicates that the most common approach employed is the prediction of students' academic performance, which relies on data obtained from the Learning Management System and Student Information System. The primary data utilized for prediction purposes consists Student retention and time of academic and behavioral information. Among the various algorithms employed, Support Vector Machine and Random Forest are the most commonly utilized. This study makes a significant contribution to the advancement of learner modules within the smart learning environment.","<method>Support Vector Machine</method>, <method>Random Forest</method>",<method>Support Vector Machine</method><method>Random Forest</method>
2024,https://openalex.org/W4391625720,Psychology,Combining artificial and human intelligence to manage cross-cultural knowledge in humanitarian logistics: a Yin–Yang dialectic systems view of knowledge creation,"Purpose Aiming to resolve cross-cultural paradoxes in combining artificial intelligence (AI) with human intelligence (HI) for international humanitarian logistics, this paper aims to adopt an unorthodox Yin–Yang dialectic approach to address how AI–HI interactions can be interpreted as a sophisticated cross-cultural knowledge creation (KC) system that enables more effective decision-making for providing humanitarian relief across borders. Design/methodology/approach This paper is conceptual and pragmatic in nature, whereas its structure design follows the requirements of a real impact study. Findings Based on experimental information and logical reasoning, the authors first identify three critical cross-cultural challenges in AI–HI collaboration: paradoxes of building a cross-cultural KC system, paradoxes of integrative AI and HI in moral judgement and paradoxes of processing moral-related information with emotions in AI–HI collaboration. Then applying the Yin–Yang dialectic to interpret Klir’s epistemological frame (1993), the authors propose an unconventional stratified system of cross-cultural KC for understanding integrative AI–HI decision-making for humanitarian logistics across cultures. Practical implications This paper aids not only in deeply understanding complex issues stemming from human emotions and cultural cognitions in the context of cross-border humanitarian logistics, but also equips culturally-diverse stakeholders to effectively navigate these challenges and their potential ramifications. It enhances the decision-making process and optimizes the synergy between AI and HI for cross-cultural humanitarian logistics. Originality/value The originality lies in the use of a cognitive methodology of the Yin–Yang dialectic to metaphorize the dynamic genesis of integrative AI-HI KC for international humanitarian logistics. Based on system science and knowledge management, this paper applies game theory, multi-objective optimization and Markov decision process to operationalize the conceptual framework in the context of cross-cultural humanitarian logistics.","<method>game theory</method>, <method>multi-objective optimization</method>, <method>Markov decision process</method>",<method>Markov decision process</method>
2024,https://openalex.org/W4402061574,Psychology,Abstractive Text Summarization Using GAN,"In the field of natural language processing, the task of writing long concepts into short expressions has attracted attention due to its ability to simplify the processing and understanding of information. While traditional transcription techniques are effective to some extent, they often fail to capture the essence and nuances of the original texts. This article explores a new approach to collecting abstract data using artificial neural networks (GANs), a class of deep learning models known for their ability to create patterns of real information. We describe the fundamentals of text collection through a comprehensive review of existing literature and methods and highlight the complexity of GAN-based text. Our goal is to transform complex text into context and meaning by combining the power of GANs with natural language understanding. We detail the design and training of an adaptive GAN model for the text recognition task. We also conduct various experiments and evaluations using established metrics such as ROUGE and BLEU scores to evaluate the effectiveness and efficiency of our approach. The results show that GANs can be used to improve the quality and consistency of generated content, data storage, data analysis paper, etc. It shows its promise in paving the way for advanced applications in fields. Through this research, we aim to contribute to the continued evolution of writing technology, providing insights and innovations that support the field to a new level of well-done.","<method>artificial neural networks (GANs)</method>, <method>GAN-based text</method>, <method>adaptive GAN model</method>",No methods remaining
2024,https://openalex.org/W4390608362,Psychology,"Transformative Potential of AI in Healthcare: Definitions, Applications, and Navigating the Ethical Landscape and Public Perspectives","Artificial intelligence (AI) has emerged as a crucial tool in healthcare with the primary aim of improving patient outcomes and optimizing healthcare delivery. By harnessing machine learning algorithms, natural language processing, and computer vision, AI enables the analysis of complex medical data. The integration of AI into healthcare systems aims to support clinicians, personalize patient care, and enhance population health, all while addressing the challenges posed by rising costs and limited resources. As a subdivision of computer science, AI focuses on the development of advanced algorithms capable of performing complex tasks that were once reliant on human intelligence. The ultimate goal is to achieve human-level performance with improved efficiency and accuracy in problem-solving and task execution, thereby reducing the need for human intervention. Various industries, including engineering, media/entertainment, finance, and education, have already reaped significant benefits by incorporating AI systems into their operations. Notably, the healthcare sector has witnessed rapid growth in the utilization of AI technology. Nevertheless, there remains untapped potential for AI to truly revolutionize the industry. It is important to note that despite concerns about job displacement, AI in healthcare should not be viewed as a threat to human workers. Instead, AI systems are designed to augment and support healthcare professionals, freeing up their time to focus on more complex and critical tasks. By automating routine and repetitive tasks, AI can alleviate the burden on healthcare professionals, allowing them to dedicate more attention to patient care and meaningful interactions. However, legal and ethical challenges must be addressed when embracing AI technology in medicine, alongside comprehensive public education to ensure widespread acceptance.","<method>machine learning algorithms</method>, <method>natural language processing</method>, <method>computer vision</method>",No methods remaining
2024,https://openalex.org/W4390919701,Psychology,Chatbots and Large Language Models in Radiology: A Practical Primer for Clinical and Research Applications,"Although chatbots have existed for decades, the emergence of transformer-based large language models (LLMs) has captivated the world through the most recent wave of artificial intelligence chatbots, including ChatGPT. Transformers are a type of neural network architecture that enables better contextual understanding of language and efficient training on massive amounts of unlabeled data, such as unstructured text from the internet. As LLMs have increased in size, their improved performance and emergent abilities have revolutionized natural language processing. Since language is integral to human thought, applications based on LLMs have transformative potential in many industries. In fact, LLM-based chatbots have demonstrated human-level performance on many professional benchmarks, including in radiology. LLMs offer numerous clinical and research applications in radiology, several of which have been explored in the literature with encouraging results. Multimodal LLMs can simultaneously interpret text and images to generate reports, closely mimicking current diagnostic pathways in radiology. Thus, from requisition to report, LLMs have the opportunity to positively impact nearly every step of the radiology journey. Yet, these impressive models are not without limitations. This article reviews the limitations of LLMs and mitigation strategies, as well as potential uses of LLMs, including multimodal models. Also reviewed are existing LLM-based applications that can enhance efficiency in supervised settings.","<method>transformer-based large language models (LLMs)</method>, <method>Transformers</method>, <method>Multimodal LLMs</method>",<method>transformer-based large language models (LLMs)</method><method>Transformers</method><method>Multimodal LLMs</method>
2024,https://openalex.org/W4399528455,Psychology,Bias and Fairness in Large Language Models: A Survey,"Abstract Rapid advancements of large language models (LLMs) have enabled the processing, understanding, and generation of human-like text, with increasing integration into systems that touch our social sphere. Despite this success, these models can learn, perpetuate, and amplify harmful social biases. In this article, we present a comprehensive survey of bias evaluation and mitigation techniques for LLMs. We first consolidate, formalize, and expand notions of social bias and fairness in natural language processing, defining distinct facets of harm and introducing several desiderata to operationalize fairness for LLMs. We then unify the literature by proposing three intuitive taxonomies, two for bias evaluation, namely, metrics and datasets, and one for mitigation. Our first taxonomy of metrics for bias evaluation disambiguates the relationship between metrics and evaluation datasets, and organizes metrics by the different levels at which they operate in a model: embeddings, probabilities, and generated text. Our second taxonomy of datasets for bias evaluation categorizes datasets by their structure as counterfactual inputs or prompts, and identifies the targeted harms and social groups; we also release a consolidation of publicly available datasets for improved access. Our third taxonomy of techniques for bias mitigation classifies methods by their intervention during pre-processing, in-training, intra-processing, and post-processing, with granular subcategories that elucidate research trends. Finally, we identify open problems and challenges for future work. Synthesizing a wide range of recent research, we aim to provide a clear guide of the existing literature that empowers researchers and practitioners to better understand and prevent the propagation of bias in LLMs.","<method>bias evaluation metrics</method>, <method>bias evaluation datasets</method>, <method>bias mitigation techniques</method>, <method>pre-processing intervention</method>, <method>in-training intervention</method>, <method>intra-processing intervention</method>, <method>post-processing intervention</method>",No methods remaining
2024,https://openalex.org/W4399803256,Psychology,Detecting hallucinations in large language models using semantic entropy,"Abstract Large language model (LLM) systems, such as ChatGPT 1 or Gemini 2 , can show impressive reasoning and question-answering capabilities but often ‘hallucinate’ false outputs and unsubstantiated answers 3,4 . Answering unreliably or without the necessary information prevents adoption in diverse fields, with problems including fabrication of legal precedents 5 or untrue facts in news articles 6 and even posing a risk to human life in medical domains such as radiology 7 . Encouraging truthfulness through supervision or reinforcement has been only partially successful 8 . Researchers need a general method for detecting hallucinations in LLMs that works even with new and unseen questions to which humans might not know the answer. Here we develop new methods grounded in statistics, proposing entropy-based uncertainty estimators for LLMs to detect a subset of hallucinations—confabulations—which are arbitrary and incorrect generations. Our method addresses the fact that one idea can be expressed in many ways by computing uncertainty at the level of meaning rather than specific sequences of words. Our method works across datasets and tasks without a priori knowledge of the task, requires no task-specific data and robustly generalizes to new tasks not seen before. By detecting when a prompt is likely to produce a confabulation, our method helps users understand when they must take extra care with LLMs and opens up new possibilities for using LLMs that are otherwise prevented by their unreliability.",<method>entropy-based uncertainty estimators</method>,<method>entropy-based uncertainty estimators</method>
2024,https://openalex.org/W4390587679,Psychology,"A Systematic Review and Meta-Analysis of Artificial Intelligence Tools in Medicine and Healthcare: Applications, Considerations, Limitations, Motivation and Challenges","Artificial intelligence (AI) has emerged as a transformative force in various sectors, including medicine and healthcare. Large language models like ChatGPT showcase AI’s potential by generating human-like text through prompts. ChatGPT’s adaptability holds promise for reshaping medical practices, improving patient care, and enhancing interactions among healthcare professionals, patients, and data. In pandemic management, ChatGPT rapidly disseminates vital information. It serves as a virtual assistant in surgical consultations, aids dental practices, simplifies medical education, and aids in disease diagnosis. A total of 82 papers were categorised into eight major areas, which are G1: treatment and medicine, G2: buildings and equipment, G3: parts of the human body and areas of the disease, G4: patients, G5: citizens, G6: cellular imaging, radiology, pulse and medical images, G7: doctors and nurses, and G8: tools, devices and administration. Balancing AI’s role with human judgment remains a challenge. A systematic literature review using the PRISMA approach explored AI’s transformative potential in healthcare, highlighting ChatGPT’s versatile applications, limitations, motivation, and challenges. In conclusion, ChatGPT’s diverse medical applications demonstrate its potential for innovation, serving as a valuable resource for students, academics, and researchers in healthcare. Additionally, this study serves as a guide, assisting students, academics, and researchers in the field of medicine and healthcare alike.","<method>Large language models</method>, <method>ChatGPT</method>, <method>systematic literature review using the PRISMA approach</method>",No methods remaining
2024,https://openalex.org/W4392639864,Psychology,Comparing the quality of human and ChatGPT feedback of students’ writing,"Offering students formative feedback on their writing is an effective way to facilitate writing development. Recent advances in AI (i.e., ChatGPT) may function as an automated writing evaluation tool, increasing the amount of feedback students receive and diminishing the burden on teachers to provide frequent feedback to large classes. We examined the ability of generative AI (ChatGPT) to provide formative feedback. We compared the quality of human and AI feedback by scoring the feedback each provided on secondary student essays. We scored the degree to which feedback (a) was criteria-based, (b) provided clear directions for improvement, (c) was accurate, (d) prioritized essential features, and (e) used a supportive tone. 200 pieces of human-generated formative feedback and 200 pieces of AI-generated formative feedback for the same essays. We examined whether ChatGPT and human feedback differed in quality for the whole sample, for compositions that differed in overall quality, and for native English speakers and English learners by comparing descriptive statistics and effect sizes. Human raters were better at providing high-quality feedback to students in all categories other than criteria-based. AI and humans showed differences in feedback quality based on essay quality. Feedback did not vary by language status for humans or AI. Well-trained evaluators provided higher quality feedback than ChatGPT. Considering the ease of generating feedback through ChatGPT and its overall quality, generative AI may still be useful in some contexts, particularly in formative early drafts or instances where a well-trained educator is unavailable.",<method>generative AI (ChatGPT)</method>,<method>generative AI (ChatGPT)</method>
2024,https://openalex.org/W4393252719,Psychology,Application of generative artificial intelligence (GenAI) in language teaching and learning: A scoping literature review,"This scoping literature review examines the application of Generative Artificial Intelligence (GenAI), a disruptive technology, in language teaching and learning. Since its launch in November 2022, GenAI has captured global attention with OpenAI's ChatGPT, powered by the generative pre-trained transformer-3 (GPT-3) large-language model. The emergence of GenAI holds immense implications across various domains, including language education. This review aims to provide an overview of the current state of research and identify research gaps and future directions in this emerging field. The review follows the PRISMA-ScR guidelines and includes eligible publications published between 2017 and July 2023. Four electronic databases were searched and 41 of the 224 initial papers were eventually selected for review. The findings reveal key terms related to GenAI in language education, the most researched language study and education levels, areas of research, attitudes towards GenAI, and the potential benefits and challenges of GenAI application. The review highlights several research gaps, including the need for more empirical studies to assess the effectiveness and impact of GenAI tools, discussion of ethical considerations, targeted interventions for specific language skills, and stakeholder engagement in responsible integration. Educators are encouraged to incorporate GenAI tools into their teaching practices while remaining vigilant about potential risks. Continuous professional development for educators is crucial to ensure informed decision-making and effective integration of GenAI tools. This scoping review contributes to the existing knowledge on the use of GenAI in language education and informs future research and practice in this disruptive and rapidly evolving field.",<method>generative pre-trained transformer-3 (GPT-3)</method>,<method>generative pre-trained transformer-3 (GPT-3)</method>
2024,https://openalex.org/W4390904004,Psychology,The Use of Artificial Intelligence in Writing Scientific Review Articles,"Abstract Purpose of Review With the recent explosion in the use of artificial intelligence (AI) and specifically ChatGPT, we sought to determine whether ChatGPT could be used to assist in writing credible, peer-reviewed, scientific review articles. We also sought to assess, in a scientific study, the advantages and limitations of using ChatGPT for this purpose. To accomplish this, 3 topics of importance in musculoskeletal research were selected: (1) the intersection of Alzheimer’s disease and bone; (2) the neural regulation of fracture healing; and (3) COVID-19 and musculoskeletal health. For each of these topics, 3 approaches to write manuscript drafts were undertaken: (1) human only; (2) ChatGPT only (AI-only); and (3) combination approach of #1 and #2 (AI-assisted). Articles were extensively fact checked and edited to ensure scientific quality, resulting in final manuscripts that were significantly different from the original drafts. Numerous parameters were measured throughout the process to quantitate advantages and disadvantages of approaches. Recent Findings Overall, use of AI decreased the time spent to write the review article, but required more extensive fact checking. With the AI-only approach, up to 70% of the references cited were found to be inaccurate. Interestingly, the AI-assisted approach resulted in the highest similarity indices suggesting a higher likelihood of plagiarism. Finally, although the technology is rapidly changing, at the time of study, ChatGPT 4.0 had a cutoff date of September 2021 rendering identification of recent articles impossible. Therefore, all literature published past the cutoff date was manually provided to ChatGPT, rendering approaches #2 and #3 identical for contemporary citations. As a result, for the COVID-19 and musculoskeletal health topic, approach #2 was abandoned midstream due to the extensive overlap with approach #3. Summary The main objective of this scientific study was to see whether AI could be used in a scientifically appropriate manner to improve the scientific writing process. Indeed, AI reduced the time for writing but had significant inaccuracies. The latter necessitates that AI cannot currently be used alone but could be used with careful oversight by humans to assist in writing scientific review articles.",<method>ChatGPT</method>,No methods remaining
2024,https://openalex.org/W4399450035,Psychology,Power Hungry Processing: Watts Driving the Cost of AI Deployment?,"Recent years have seen a surge in the popularity of commercial AI products based on generative, multi-purpose AI systems promising a unified approach to building machine learning (ML) models into technology. However, this ambition of ""generality"" comes at a steep cost to the environment, given the amount of energy these systems require and the amount of carbon that they emit. In this work, we propose the first systematic comparison of the ongoing inference cost of various categories of ML systems, covering both task-specific (i.e. finetuned models that carry out a single task) and 'general-purpose' models, (i.e. those trained for multiple tasks). We measure deployment cost as the amount of energy and carbon required to perform 1,000 inferences on representative benchmark dataset using these models. We find that multi-purpose, generative architectures are orders of magnitude more expensive than task-specific systems for a variety of tasks, even when controlling for the number of model parameters. We conclude with a discussion around the current trend of deploying multi-purpose generative ML systems, and caution that their utility should be more intentionally weighed against increased costs in terms of energy and emissions. All the data from our study can be accessed via an interactive demo to carry out further exploration and analysis.","<method>finetuned models</method>, <method>multi-purpose generative architectures</method>",No methods remaining
2024,https://openalex.org/W4390833194,Psychology,Towards Conversational Diagnostic AI,"At the heart of medicine lies the physician-patient dialogue, where skillful history-taking paves the way for accurate diagnosis, effective management, and enduring trust. Artificial Intelligence (AI) systems capable of diagnostic dialogue could increase accessibility, consistency, and quality of care. However, approximating clinicians' expertise is an outstanding grand challenge. Here, we introduce AMIE (Articulate Medical Intelligence Explorer), a Large Language Model (LLM) based AI system optimized for diagnostic dialogue. AMIE uses a novel self-play based simulated environment with automated feedback mechanisms for scaling learning across diverse disease conditions, specialties, and contexts. We designed a framework for evaluating clinically-meaningful axes of performance including history-taking, diagnostic accuracy, management reasoning, communication skills, and empathy. We compared AMIE's performance to that of primary care physicians (PCPs) in a randomized, double-blind crossover study of text-based consultations with validated patient actors in the style of an Objective Structured Clinical Examination (OSCE). The study included 149 case scenarios from clinical providers in Canada, the UK, and India, 20 PCPs for comparison with AMIE, and evaluations by specialist physicians and patient actors. AMIE demonstrated greater diagnostic accuracy and superior performance on 28 of 32 axes according to specialist physicians and 24 of 26 axes according to patient actors. Our research has several limitations and should be interpreted with appropriate caution. Clinicians were limited to unfamiliar synchronous text-chat which permits large-scale LLM-patient interactions but is not representative of usual clinical practice. While further research is required before AMIE could be translated to real-world settings, the results represent a milestone towards conversational diagnostic AI.","<method>Large Language Model (LLM)</method>, <method>self-play based simulated environment</method>",No methods remaining
2024,https://openalex.org/W4392791588,Psychology,Can large language models replace humans in systematic reviews? Evaluating <scp>GPT</scp>‐4's efficacy in screening and extracting data from peer‐reviewed and grey literature in multiple languages,"Systematic reviews are vital for guiding practice, research and policy, although they are often slow and labour-intensive. Large language models (LLMs) could speed up and automate systematic reviews, but their performance in such tasks has yet to be comprehensively evaluated against humans, and no study has tested Generative Pre-Trained Transformer (GPT)-4, the biggest LLM so far. This pre-registered study uses a ""human-out-of-the-loop"" approach to evaluate GPT-4's capability in title/abstract screening, full-text review and data extraction across various literature types and languages. Although GPT-4 had accuracy on par with human performance in some tasks, results were skewed by chance agreement and dataset imbalance. Adjusting for these caused performance scores to drop across all stages: for data extraction, performance was moderate, and for screening, it ranged from none in highly balanced literature datasets (~1:1) to moderate in those datasets where the ratio of inclusion to exclusion in studies was imbalanced (~1:3). When screening full-text literature using highly reliable prompts, GPT-4's performance was more robust, reaching ""human-like"" levels. Although our findings indicate that, currently, substantial caution should be exercised if LLMs are being used to conduct systematic reviews, they also offer preliminary evidence that, for certain review tasks delivered under specific conditions, LLMs can rival human performance.","<method>Large language models (LLMs)</method>, <method>Generative Pre-Trained Transformer (GPT)-4</method>",<method>Generative Pre-Trained Transformer (GPT)-4</method>
2024,https://openalex.org/W4391473908,Psychology,Exploring AI-mediated informal digital learning of English (AI-IDLE): a mixed-method investigation of Chinese EFL learners’ AI adoption and experiences,"Recent advancements in natural language processing and large language models have ushered language learning into the age of artificial intelligence (AI). Recognizing the affordances of generative AI tools, this paper aims to examine the degree to which L2 learners accepted and leveraged large language model platforms (e.g. ChatGPT, Bing Chat) for the informal digital learning of English (IDLE) purposes. Employing an explanatory sequential mixed-method design, this study draws on the technology acceptance model (TAM) and collects data via an adapted TAM questionnaire and an interview guide. A total of 867 Chinese EFL (English as a foreign language) learners answered the online survey, while 20 attended the post-survey interviews. Drawing on a validated structural model that elucidates the inter-factor relationships of perceived ease of use, perceived usefulness, intention to use, and actual use, the quantitative analysis provides statistical accounts for EFL learners' adoption of Generative Pre-trained Transformer (GPT) technologies. The qualitative findings, derived from the interview data, reveal three key themes: (1) how perceived usefulness of chatbots for IDLE emerges from hands-on experimentation with these tools; (2) how intention to use increases as learners negotiate chatbot affordances and constraints; and (3) how actual use of chatbots for IDLE involves using these tools as tutors or conversation partners. Connections between quantitative and qualitative findings enhance our understanding of how EFL learners negotiate the affordances and constraints of highly capable AI technologies to participate in creative IDLE practices. By understanding these practices, this study draws attention to the attitudes and practices that constitute AI literacies, ultimately offering implications for future classroom practices and research.",<method>Generative Pre-trained Transformer (GPT)</method>,<method>Generative Pre-trained Transformer (GPT)</method>
2024,https://openalex.org/W4394884079,Psychology,TRANSFORMING FINTECH FRAUD DETECTION WITH ADVANCED ARTIFICIAL INTELLIGENCE ALGORITHMS,"The rapid evolution of financial technology (fintech) platforms has exponentially increased the volume and sophistication of financial transactions, concurrently elevating the risk and complexity of fraudulent activities. This necessitates a paradigm shift in fraud detection methodologies towards more agile, accurate, and predictive solutions. This paper presents a comprehensive study on the transformative potential of advanced Artificial Intelligence (AI) algorithms in enhancing fintech fraud detection mechanisms. By leveraging cutting-edge AI techniques including deep learning, machine learning, and natural language processing, this research aims to develop a robust fraud detection framework capable of identifying, analyzing, and preventing fraudulent transactions in real-time.&#x0D; Our methodology encompasses the deployment of several AI algorithms on extensive datasets comprising genuine and fraudulent financial transactions. Through a comparative analysis, we identify the most effective algorithms in terms of accuracy, efficiency, and scalability. Key findings reveal that deep learning models, particularly those employing neural networks, outperform traditional machine learning models in detecting complex and nuanced fraudulent activities. Furthermore, the integration of natural language processing enables the extraction and analysis of unstructured data, significantly enhancing the detection capabilities.&#x0D; Conclusively, this paper underscores the critical role of advanced AI algorithms in revolutionizing fintech fraud detection. It highlights the superior performance of AI-based models over conventional methods, offering fintech platforms a more dynamic and predictive approach to fraud prevention. This research not only contributes to the academic discourse on financial security but also provides practical insights for fintech companies striving to safeguard their operations against fraud.&#x0D; Keywords: Artificial Intelligence, Fintech, Fraud Detection, Ethical Ai, Regulatory Compliance, Data Privacy, Algorithmic Bias, Predictive Analytics, Blockchain Technology, Quantum Computing, Interdisciplinary Collaboration, Innovation, Transparency, Accountability, Continuous Learning, Ethical Principles, Real-Time Processing, Financial Sector.","<method>deep learning</method>, <method>machine learning</method>, <method>natural language processing</method>, <method>neural networks</method>",<method>deep learning</method><method>machine learning</method><method>neural networks</method>
2024,https://openalex.org/W4391572037,Psychology,Machine Learning Applications in Healthcare: Current Trends and Future Prospects,"The integration of machine learning (ML) in healthcare has witnessed remarkable advancements, transforming the landscape of medical diagnosis, treatment, and overall patient care. This article provides a comprehensive review of the current trends and future prospects of machine learning applications in the healthcare domain.The current landscape is characterized by the utilization of ML algorithms for disease diagnosis and risk prediction, personalized treatment plans, and efficient healthcare resource management. Notable applications include image recognition for radiology and pathology, predictive analytics for disease prognosis, and the development of precision medicine tailored to individual patient profiles.This review explores the evolving role of ML in improving patient outcomes, enhancing clinical decision-making, and optimizing healthcare workflows. It delves into the challenges faced in integrating ML into existing healthcare systems, such as data privacy concerns, interpretability of complex models, and the need for robust validation processes.Additionally, the article discusses future prospects and emerging trends in ML healthcare applications, including the potential for predictive analytics to preemptively identify health issues, the integration of wearable devices and remote monitoring for continuous patient care, and the intersection of ML with genomics for personalized medicine.The overarching goal of this article is to provide healthcare professionals, researchers, and policymakers with insights into the current state of ML applications in healthcare, along with an outlook on the transformative potential that machine learning holds for the future of healthcare delivery and patient outcomes.","<method>machine learning (ML) algorithms</method>, <method>image recognition</method>, <method>predictive analytics</method>",No methods remaining
2024,https://openalex.org/W4392503764,Psychology,Mental-LLM,"Advances in large language models (LLMs) have empowered a variety of applications. However, there is still a significant gap in research when it comes to understanding and enhancing the capabilities of LLMs in the field of mental health. In this work, we present a comprehensive evaluation of multiple LLMs on various mental health prediction tasks via online text data, including Alpaca, Alpaca-LoRA, FLAN-T5, GPT-3.5, and GPT-4. We conduct a broad range of experiments, covering zero-shot prompting, few-shot prompting, and instruction fine-tuning. The results indicate a promising yet limited performance of LLMs with zero-shot and few-shot prompt designs for mental health tasks. More importantly, our experiments show that instruction finetuning can significantly boost the performance of LLMs for all tasks simultaneously. Our best-finetuned models, Mental-Alpaca and Mental-FLAN-T5, outperform the best prompt design of GPT-3.5 (25 and 15 times bigger) by 10.9% on balanced accuracy and the best of GPT-4 (250 and 150 times bigger) by 4.8%. They further perform on par with the state-of-the-art task-specific language model. We also conduct an exploratory case study on LLMs' capability on mental health reasoning tasks, illustrating the promising capability of certain models such as GPT-4. We summarize our findings into a set of action guidelines for potential methods to enhance LLMs' capability for mental health tasks. Meanwhile, we also emphasize the important limitations before achieving deployability in real-world mental health settings, such as known racial and gender bias. We highlight the important ethical risks accompanying this line of research.","<method>zero-shot prompting</method>, <method>few-shot prompting</method>, <method>instruction fine-tuning</method>",<method>zero-shot prompting</method><method>few-shot prompting</method><method>instruction fine-tuning</method>
2024,https://openalex.org/W4392239564,Psychology,Human-AI collaboration patterns in AI-assisted academic writing,"Artificial Intelligence (AI) has increasingly influenced higher education, notably in academic writing where AI-powered assisting tools offer both opportunities and challenges. Recently, the rapid growth of generative AI (GAI) has brought its impacts into sharper focus, yet the dynamics of its utilisation in academic writing remain largely unexplored. This paper focuses on examining the nature of human-AI interactions in academic writing, specifically investigating the strategies doctoral students employ when collaborating with a GAI-powered assisting tool. This study involves 626 recorded activities on how ten doctoral students interact with GAI-powered assisting tool during academic writing. AI-driven learning analytics approach was adopted for three layered analyses: (1) data pre-processing and analysis with quantitative content analysis, (2) sequence analysis with Hidden Markov Model (HMM) and hierarchical sequence clustering, and (3) pattern analysis with process mining. Findings indicate that doctoral students engaging in iterative, highly interactive processes with the GAI-powered assisting tool generally achieve better performance in the writing task. In contrast, those who use GAI merely as a supplementary information source, maintaining a linear writing approach, tend to get lower writing performance. This study points to the need for further investigations into human-AI collaboration in learning in higher education, with implications for tailored educational strategies and solutions.","<method>AI-driven learning analytics</method>, <method>quantitative content analysis</method>, <method>Hidden Markov Model (HMM)</method>, <method>hierarchical sequence clustering</method>, <method>process mining</method>",<method>Hidden Markov Model (HMM)</method>
2024,https://openalex.org/W4392303127,Psychology,Recent advancements and challenges of NLP-based sentiment analysis: A state-of-the-art review,"Sentiment analysis is a method within natural language processing that evaluates and identifies the emotional tone or mood conveyed in textual data. Scrutinizing words and phrases categorizes them into positive, negative, or neutral sentiments. The significance of sentiment analysis lies in its capacity to derive valuable insights from extensive textual data, empowering businesses to grasp customer sentiments, make informed choices, and enhance their offerings. For the further advancement of sentiment analysis, gaining a deep understanding of its algorithms, applications, current performance, and challenges is imperative. Therefore, in this extensive survey, we began exploring the vast array of application domains for sentiment analysis, scrutinizing them within the context of existing research. We then delved into prevalent pre-processing techniques, datasets, and evaluation metrics to enhance comprehension. We also explored Machine Learning, Deep Learning, Large Language Models and Pre-trained models in sentiment analysis, providing insights into their advantages and drawbacks. Subsequently, we precisely reviewed the experimental results and limitations of recent state-of-the-art articles. Finally, we discussed the diverse challenges encountered in sentiment analysis and proposed future research directions to mitigate these concerns. This extensive review provides a complete understanding of sentiment analysis, covering its models, application domains, results analysis, challenges, and research directions.","<method>Machine Learning</method>, <method>Deep Learning</method>, <method>Large Language Models</method>, <method>Pre-trained models</method>",<method>Machine Learning</method><method>Deep Learning</method>
2024,https://openalex.org/W4401171937,Psychology,Exploring students’ perspectives on Generative AI-assisted academic writing,"Abstract The rapid development of generative artificial intelligence (GenAI), including large language models (LLM), has merged to support students in their academic writing process. Keeping pace with the technical and educational landscape requires careful consideration of the opportunities and challenges that GenAI-assisted systems create within education. This serves as a useful and necessary starting point for fully leveraging its potential for learning and teaching. Hence, it is crucial to gather insights from diverse perspectives and use cases from actual users, particularly the unique voices and needs of student-users. Therefore, this study explored and examined students' perceptions and experiences about GenAI-assisted academic writing by conducting in-depth interviews with 20 Chinese students in higher education after completing academic writing tasks using a ChatGPT4-embedded writing system developed by the research team. The study found that students expected AI to serve multiple roles, including multi-tasking writing assistant, virtual tutor, and digital peer to support multifaceted writing processes and performance. Students perceived that GenAI-assisted writing could benefit them in three areas including the writing process, performance, and their affective domain. Meanwhile, they also identified AI-related, student-related, and task-related challenges that were experienced during the GenAI-assisted writing activity. These findings contribute to a more nuanced understanding of GenAI's impact on academic writing that is inclusive of student perspectives, offering implications for educational AI design and instructional design.","<method>generative artificial intelligence (GenAI)</method>, <method>large language models (LLM)</method>, <method>ChatGPT4-embedded writing system</method>",No methods remaining
2024,https://openalex.org/W4390638955,Psychology,Artificial intelligence (AI) learning tools in K-12 education: A scoping review,"Abstract Artificial intelligence (AI) literacy is a global strategic objective in education. However, little is known about how AI should be taught. In this paper, 46 studies in academic conferences and journals are reviewed to investigate pedagogical strategies, learning tools, assessment methods in AI literacy education in K-12 contexts, and students’ learning outcomes. The investigation reveals that the promotion of AI literacy education has seen significant progress in the past two decades. This highlights that intelligent agents, including Google’s Teachable Machine, Learning ML, and Machine Learning for Kids, are age-appropriate tools for AI literacy education in K-12 contexts. Kindergarten students can benefit from learning tools such as PopBots, while software devices, such as Scratch and Python, which help to develop the computational thinking of AI algorithms, can be introduced to both primary and secondary schools. The research shows that project-based, human–computer collaborative learning and play- and game-based approaches, with constructivist methodologies, have been applied frequently in AI literacy education. Cognitive, affective, and behavioral learning outcomes, course satisfaction and soft skills acquisition have been reported. The paper informs educators of appropriate learning tools, pedagogical strategies, assessment methodologies in AI literacy education, and students’ learning outcomes. Research implications and future research directions within the K-12 context are also discussed.","<method>intelligent agents</method>, <method>Teachable Machine</method>, <method>Learning ML</method>, <method>Machine Learning for Kids</method>, <method>project-based learning</method>, <method>human–computer collaborative learning</method>, <method>play- and game-based approaches</method>, <method>constructivist methodologies</method>",<method>Teachable Machine</method>
2024,https://openalex.org/W4391071215,Psychology,Automatic assessment of text-based responses in post-secondary education: A systematic review,"Text-based open-ended questions in academic formative and summative assessments help students become deep learners and prepare them to understand concepts for a subsequent conceptual assessment. However, grading text-based questions, especially in large (>50 enrolled students) courses, is tedious and time-consuming for instructors. Text processing models continue progressing with the rapid development of Artificial Intelligence (AI) tools and Natural Language Processing (NLP) algorithms. Especially after breakthroughs in Large Language Models (LLM), there is immense potential to automate rapid assessment and feedback of text-based responses in education. This systematic review adopts a scientific and reproducible literature search strategy based on the PRISMA process using explicit inclusion and exclusion criteria to study text-based automatic assessment systems in post-secondary education, screening 838 papers and synthesizing 93 studies. To understand how text-based automatic assessment systems have been developed and applied in education in recent years, three research questions are considered: 1) What types of automated assessment systems can be identified using input, output, and processing framework? 2) What are the educational focus and research motivations of studies with automated assessment systems? 3) What are the reported research outcomes in automated assessment systems and the next steps for educational applications? All included studies are summarized and categorized according to a proposed comprehensive framework, including the input and output of the system, research motivation, and research outcomes, aiming to answer the research questions accordingly. Additionally, the typical studies of automated assessment systems, research methods, and application domains in these studies are investigated and summarized. This systematic review provides an overview of recent educational applications of text-based assessment systems for understanding the latest AI/NLP developments assisting in text-based assessments in higher education. Findings will particularly benefit researchers and educators incorporating LLMs such as ChatGPT into their educational activities.","<method>Natural Language Processing (NLP) algorithms</method>, <method>Large Language Models (LLM)</method>",No methods remaining
2024,https://openalex.org/W4392251648,Psychology,A Comprehensive Survey on Source-Free Domain Adaptation,"Over the past decade, domain adaptation has become a widely studied branch of transfer learning which aims to improve performance on target domains by leveraging knowledge from the source domain. Conventional domain adaptation methods often assume access to both source and target domain data simultaneously, which may not be feasible in real-world scenarios due to privacy and confidentiality concerns. As a result, the research of Source-Free Domain Adaptation (SFDA) has drawn growing attention in recent years, which only utilizes the source-trained model and unlabeled target data to adapt to the target domain. Despite the rapid explosion of SFDA work, there has been no timely and comprehensive survey in the field. To fill this gap, we provide a comprehensive survey of recent advances in SFDA and organize them into a unified categorization scheme based on the framework of transfer learning. Instead of presenting each approach independently, we modularize several components of each method to more clearly illustrate their relationships and mechanisms in light of the composite properties of each method. Furthermore, we compare the results of more than 30 representative SFDA methods on three popular classification benchmarks, namely Office-31, Office-home, and VisDA, to explore the effectiveness of various technical routes and the combination effects among them. Additionally, we briefly introduce the applications of SFDA and related fields. Drawing on our analysis of the challenges confronting SFDA, we offer some insights into future research directions and potential settings.","<method>domain adaptation</method>, <method>transfer learning</method>, <method>Source-Free Domain Adaptation (SFDA)</method>",<method>domain adaptation</method><method>transfer learning</method><method>Source-Free Domain Adaptation (SFDA)</method>
2024,https://openalex.org/W4394009485,Psychology,AI-Driven Clinical Decision Support Systems: An Ongoing Pursuit of Potential,"Clinical Decision Support Systems (CDSS) are essential tools in contemporary healthcare, enhancing clinicians' decisions and patient outcomes. The integration of artificial intelligence (AI) is now revolutionizing CDSS even further. This review delves into AI technologies transforming CDSS, their applications in healthcare decision-making, associated challenges, and the potential trajectory toward fully realizing AI-CDSS's potential. The review begins by laying the groundwork with a definition of CDSS and its function within the healthcare field. It then highlights the increasingly significant role that AI is playing in enhancing CDSS effectiveness and efficiency, underlining its evolving prominence in shaping healthcare practices. It examines the integration of AI technologies into CDSS, including machine learning algorithms like neural networks and decision trees, natural language processing, and deep learning. It also addresses the challenges associated with AI integration, such as interpretability and bias. We then shift to AI applications within CDSS, with real-life examples of AI-driven diagnostics, personalized treatment recommendations, risk prediction, early intervention, and AI-assisted clinical documentation. The review emphasizes user-centered design in AI-CDSS integration, addressing usability, trust, workflow, and ethical and legal considerations. It acknowledges prevailing obstacles and suggests strategies for successful AI-CDSS adoption, highlighting the need for workflow alignment and interdisciplinary collaboration. The review concludes by summarizing key findings, underscoring AI's transformative potential in CDSS, and advocating for continued research and innovation. It emphasizes the need for collaborative efforts to realize a future where AI-powered CDSS optimizes healthcare delivery and improves patient outcomes.","<method>neural networks</method>, <method>decision trees</method>, <method>natural language processing</method>, <method>deep learning</method>",<method>neural networks</method><method>decision trees</method><method>deep learning</method>
2024,https://openalex.org/W4390667862,Psychology,Integration of Generative AI Techniques and Applications in Student Behavior and Cognitive Achievement in Arab Higher Education,"The integration of Artificial Intelligence (AI) in higher education has the power to revolutionize the learning experience by fostering engagement, personalization, efficiency, and innovation. AI offers a wide range of exciting possibilities where AI-powered tools enable students to receive tailored feedback and guidance, enabling them to learn at their own pace and excel academically. This research aims to investigate the effects of generative AI techniques and applications on students' cognitive achievement through student behavior. Data was collected through surveys in three Arab countries including Oman, Jordan and Yemen. 768 students from these Arab country's universities were participated in completing surveys randomly. Structure Equation Modeling SEM-PLS was adopted to analysis data. Results reveal that generative AI techniques and applications have positive and significant effects on students' cognitive achievement in Arab higher education institutions. Results also reveal that student behavior enhances the relationship among AI techniques, applications and cognitive achievement. These results highlight the crucial role of AI applications among students in higher education while the integration of this emerging technology is still at the first stage, students' interaction with and utility of these applications show high satisfactory level of their impact on students' behavior and cognitive achievement. This research contributes to literature of generative AI applications giving evidence from Arab region and filling the gap regarding usage of these applications in higher education.","<method>generative AI techniques</method>, <method>Structure Equation Modeling SEM-PLS</method>",<method>generative AI techniques</method>
2024,https://openalex.org/W4398203672,Psychology,Hallucination Rates and Reference Accuracy of ChatGPT and Bard for Systematic Reviews: Comparative Analysis,"Background Large language models (LLMs) have raised both interest and concern in the academic community. They offer the potential for automating literature search and synthesis for systematic reviews but raise concerns regarding their reliability, as the tendency to generate unsupported (hallucinated) content persist. Objective The aim of the study is to assess the performance of LLMs such as ChatGPT and Bard (subsequently rebranded Gemini) to produce references in the context of scientific writing. Methods The performance of ChatGPT and Bard in replicating the results of human-conducted systematic reviews was assessed. Using systematic reviews pertaining to shoulder rotator cuff pathology, these LLMs were tested by providing the same inclusion criteria and comparing the results with original systematic review references, serving as gold standards. The study used 3 key performance metrics: recall, precision, and F1-score, alongside the hallucination rate. Papers were considered “hallucinated” if any 2 of the following information were wrong: title, first author, or year of publication. Results In total, 11 systematic reviews across 4 fields yielded 33 prompts to LLMs (3 LLMs×11 reviews), with 471 references analyzed. Precision rates for GPT-3.5, GPT-4, and Bard were 9.4% (13/139), 13.4% (16/119), and 0% (0/104) respectively (P&lt;.001). Recall rates were 11.9% (13/109) for GPT-3.5 and 13.7% (15/109) for GPT-4, with Bard failing to retrieve any relevant papers (P&lt;.001). Hallucination rates stood at 39.6% (55/139) for GPT-3.5, 28.6% (34/119) for GPT-4, and 91.4% (95/104) for Bard (P&lt;.001). Further analysis of nonhallucinated papers retrieved by GPT models revealed significant differences in identifying various criteria, such as randomized studies, participant criteria, and intervention criteria. The study also noted the geographical and open-access biases in the papers retrieved by the LLMs. Conclusions Given their current performance, it is not recommended for LLMs to be deployed as the primary or exclusive tool for conducting systematic reviews. Any references generated by such models warrant thorough validation by researchers. The high occurrence of hallucinations in LLMs highlights the necessity for refining their training and functionality before confidently using them for rigorous academic purposes.","<method>ChatGPT</method>, <method>Bard (Gemini)</method>, <method>GPT-3.5</method>, <method>GPT-4</method>",<method>GPT-3.5</method><method>GPT-4</method>
2024,https://openalex.org/W4391993876,Psychology,"Digital twin simulation modeling, artificial intelligence-based Internet of Manufacturing Things systems, and virtual machine and cognitive computing algorithms in the Industry 4.0-based Slovak labor market","Research background: On the basis of an analysis of the current situation and expectations in the field of implementation of the elements of the Industry 4.0 concept, the purpose of this paper is to identify the effects on the labor market in large manufacturing enterprises in the Slovak Republic. Purpose of the article: The presented work has a theoretical-empirical nature and consists of a theoretical section and a practical section, which includes statistical indicator analysis and quantitative research. In the theoretical section, the paper discusses the issue of Industry 4.0 in general, with a focus on its impact on the labor market, thus laying the groundwork for future research on the subject. Methods: The output of this work is an analysis of selected indicators of the manufacturing industry sector in the Slovak Republic, based on the most recent employment data analysis in the first stage and quantitative research survey in the second stage, with the respondents being manufacturing industry companies operating in the Slovak Republic, and whose primary objective is to determine the current status of the implementation of the elements and technologies of Industry 4.0 in production companies in the Slovak Republic, as well as the factors influencing this situation, such as digital twin simulation modeling, artificial intelligence-based Internet of Manufacturing Things systems, and virtual machine and cognitive computing algorithms. Findings &amp; value added: The research findings indicate that the degree of digitization adopted by businesses in the Slovak Republic is comparatively less robust and more sluggish to adapt. This is primarily attributable to the underdeveloped educational system, population reluctance, self-actualization, and inadequate state support. Recommendations for the Slovak market aim to increase the digital proficiency of businesses and of the general populace through various means, such as reforming legislation, enhancing state support for entrepreneurs, and modifying the education system, constituting the added value of the work.","<method>digital twin simulation modeling</method>, <method>artificial intelligence-based Internet of Manufacturing Things systems</method>, <method>virtual machine algorithms</method>, <method>cognitive computing algorithms</method>",No methods remaining
2024,https://openalex.org/W4392109462,Psychology,Exploring User Adoption of ChatGPT: A Technology Acceptance Model Perspective,"In the rapidly evolving landscape of technology, the emergence of Chat Generative Pre-trained Transformer (ChatGPT) marks a pivotal milestone in the realm of Artificial Intelligence (AI). However, little research has reported the predictors of people's intentions to use ChatGPT. This pioneering study empirically examines user adoption through the lens of the Technology Acceptance Model (TAM) using a convenience sampling method. The study surveyed 784 ChatGPT users in China, of whom 58.93% were males. The results have revealed several key findings: (1) perceived usefulness, perceived ease of use, behavioral intention, and use behavior were positively correlated with each other; (2) behavioral intention acted as a mediating factor in the relationship between perceived usefulness and use behavior, as well as the relationship between perceived ease of use and use behavior; (3) perceived usefulness and behavioral intention played a chain-mediated role between perceived ease of use and use behavior; (4) the relationship between behavioral intention and use behavior exhibited greater strength among females compared to males; (5) the association between behavioral intention and use behavior was found to be stronger among urban users in comparison to their rural counterparts; (6) the connections between perceived ease of use and perceived usefulness, perceived ease of use and behavioral intention, and behavioral intention and use behavior were observed to be stronger among individuals with higher educational backgrounds relative to those with lower educational backgrounds. These findings provide crucial nuanced insights to advance the practical application of ChatGPT, emphasizing the need for enhanced usability and ease of use. However, this study exclusively captured usage behaviors within the Chinese user base. Future investigations could encompass diverse demographics across multiple countries, enabling cross-cultural comparisons.",<method>Technology Acceptance Model (TAM)</method>,No methods remaining
2024,https://openalex.org/W4393086054,Psychology,Empowering student self‐regulated learning and science education through <scp>ChatGPT</scp>: A pioneering pilot study,"In recent years, AI technologies have been developed to promote students' self‐regulated learning (SRL) and proactive learning in digital learning environments. This paper discusses a comparative study between generative AI‐based (SRLbot) and rule‐based AI chatbots (Nemobot) in a 3‐week science learning experience with 74 Secondary 4 students in Hong Kong. The experimental group used SRLbot to maintain a regular study habit and facilitate their SRL, while the control group utilized rule‐based AI chatbots. Results showed that SRLbot effectively enhanced students' science knowledge, behavioural engagement and motivation. Quantile regression analysis indicated that the number of interactions significantly predicted variations in SRL. Students appreciated the personalized recommendations and flexibility of SRLbot, which adjusted responses based on their specific learning and SRL scenarios. The ChatGPT‐enhanced instructional design reduced learning anxiety and promoted learning performance, motivation and sustained learning habits. Students' feedback on learning challenges, psychological support and self‐regulation behaviours provided insights into their progress and experience with this technology. SRLbot's adaptability and personalized approach distinguished it from rule‐based chatbots. The findings offer valuable evidence for AI developers and educators to consider generative AI settings and chatbot design, facilitating greater success in online science learning. Practitioner notes What is already known about this topic AI technologies have been used to support student self‐regulated learning (SRL) across subjects. SRL has been identified as an important aspect of student learning that can be developed through technological support. Generative AI technologies like ChatGPT have shown potential for enhancing student learning by providing personalized guidance and feedback. What this paper adds This paper reports on a case study that specifically examines the effectiveness of ChatGPT in promoting SRL among secondary students. The study provides evidence that ChatGPT can enhance students' science knowledge, motivation and SRL compared to a rule‐based AI chatbot. The study offers insights into how ChatGPT can be used as a tool to facilitate SRL and promote sustained learning habits. Implications for practice and/or policy The findings of this study suggest that educators should consider the potential of ChatGPT and other generative AI technologies to support student learning and SRL. Educators and students should be aware of the limitations of AI technologies and ensure that they are used appropriately to generate desired responses. It is also important to equip teachers and students with AI competencies to enable them to use AI for learning and teaching.","<method>generative AI-based chatbot (SRLbot)</method>, <method>rule-based AI chatbot (Nemobot)</method>, <method>ChatGPT-enhanced instructional design</method>",No methods remaining
2024,https://openalex.org/W4392119583,Psychology,Object detection and tracking in Precision Farming: a systematic review,"Object Detection and Tracking have gained importance in recent years because of the great advances in image and video analysis techniques and the accurate results these technologies are producing. Moreover, they have successfully been applied to multiple fields, including the agricultural domain since they offer real-time monitoring of the status of the crops and animals while counting how many are present within a field/barn. This review aims to review the current literature on Object Detection and Tracking within the field of Precision Farming. For that, over 300 research articles were explored, from which 150 articles from the last five years were systematically reviewed and analysed regarding the algorithms they implemented, the domain they belong to, the difficulties they faced, and which limitations should be tackled in the future. Lastly, it examines potential issues that this approach might have, for instance, the lack of open-source datasets with labelled data. The findings of this study indicate that Object Detection and Tracking are critical techniques to enhance Precision Farming and pave the way for robotization for the agricultural sector since they provide accurate results and insights on crop and animal management, and optimize resource allocation. Future work should focus on the optimal acquisition of the datasets prior to Object Detection and Tracking, along with the consideration of the biophysical environment of the farming scenarios.","<method>Object Detection</method>, <method>Tracking</method>",<method>Object Detection</method>
2024,https://openalex.org/W4392202731,Psychology,Applying large language models and chain-of-thought for automatic scoring,"This study investigates the application of large language models (LLMs), specifically GPT-3.5 and GPT-4, with Chain-of-Though (CoT) in the automatic scoring of student-written responses to science assessments. We focused on overcoming the challenges of accessibility, technical complexity, and lack of explainability that have previously limited the use of artificial intelligence-based automatic scoring tools among researchers and educators. With a testing dataset comprising six assessment tasks (three binomial and three trinomial) with 1650 student responses, we employed six prompt engineering strategies to automatically score student responses. The six strategies combined zero-shot or few-shot learning with CoT, either alone or alongside item stem and scoring rubrics, developed based on a novel approach, WRVRT (prompt writing, reviewing, validating, revising, and testing). Results indicated that few-shot (acc = 0.67) outperformed zero-shot learning (acc = 0.60), with 12.6% increase. CoT, when used without item stem and scoring rubrics, did not significantly affect scoring accuracy (acc = 0.60). However, CoT prompting paired with contextual item stems and rubrics proved to be a significant contributor to scoring accuracy (13.44% increase for zero-shot; 3.7% increase for few-shot). We found a more balanced accuracy across different proficiency categories when CoT was used with a scoring rubric, highlighting the importance of domain-specific reasoning in enhancing the effectiveness of LLMs in scoring tasks. We also found that GPT-4 demonstrated superior performance over GPT -3.5 in various scoring tasks when combined with the single-call greedy sampling or ensemble voting nucleus sampling strategy, showing 8.64% difference. Particularly, the single-call greedy sampling strategy with GPT-4 outperformed other approaches. This study also demonstrates the potential of LLMs in facilitating explainable and interpretable automatic scoring, emphasizing that CoT enhances accuracy and transparency, particularly when used with item stem and scoring rubrics.","<method>large language models (LLMs)</method>, <method>GPT-3.5</method>, <method>GPT-4</method>, <method>Chain-of-Thought (CoT)</method>, <method>zero-shot learning</method>, <method>few-shot learning</method>, <method>prompt engineering strategies</method>, <method>WRVRT (prompt writing, reviewing, validating, revising, and testing)</method>, <method>single-call greedy sampling strategy</method>, <method>ensemble voting nucleus sampling strategy</method>",<method>GPT-3.5</method><method>GPT-4</method><method>Chain-of-Thought (CoT)</method><method>zero-shot learning</method><method>few-shot learning</method>
2024,https://openalex.org/W4390584313,Psychology,A Conceptual Model for Inclusive Technology: Advancing Disability Inclusion through Artificial Intelligence,"Artificial intelligence (AI) has ushered in transformative changes, championing inclusion and accessibility for individuals with disabilities. This article delves into the remarkable AI-driven solutions that have revolutionized their lives across various domains. From assistive technologies such as voice recognition and AI-powered smart glasses catering to diverse needs, to healthcare benefiting from early disease detection algorithms and wearable devices that monitor vital signs and alert caregivers in emergencies, AI has steered in significant enhancements. Moreover, AI-driven prosthetics and exoskeletons have substantially improved mobility for those with limb impairments. The realm of education has not been left untouched, with AI tools creating inclusive learning environments that adapt to individual learning styles, paving the way for academic success among students with disabilities. However, the boundless potential of AI also presents ethical concerns and challenges. Issues like safeguarding data privacy, mitigating algorithmic bias, and bridging the digital divide must be thoughtfully addressed to fully harness AI’s potential in empowering individuals with disabilities. To complement these achievements, a robust conceptual model for AI disability inclusion serves as the theoretical framework, guiding the development of tailored AI solutions. By striking a harmonious balance between innovation and ethics, AI has the power to significantly enhance the overall quality of life for individuals with disabilities across a spectrum of vital areas.","<method>voice recognition</method>, <method>early disease detection algorithms</method>",No methods remaining
2024,https://openalex.org/W4391103530,Psychology,Transformative Breast Cancer Diagnosis using CNNs with Optimized ReduceLROnPlateau and Early Stopping Enhancements,"Abstract Breast cancer stands as a paramount public health concern worldwide, underscoring an imperative necessity within the research sphere for precision-driven and efficacious methodologies facilitating accurate detection. The existing diagnostic approaches in breast cancer often suffer from limitations in accuracy and efficiency, leading to delayed detection and subsequent challenges in personalized treatment planning. The primary focus of this research is to overcome these shortcomings by harnessing the power of advanced deep learning techniques, thereby revolutionizing the precision and reliability of breast cancer classification. This research addresses the critical need for improved breast cancer diagnostics by introducing a novel Convolutional Neural Network (CNN) model integrated with an Early Stopping callback and ReduceLROnPlateau callback. By enhancing the precision and reliability of breast cancer classification, the study aims to overcome the limitations of existing diagnostic methods, ultimately leading to better patient outcomes and reduced mortality rates. The comprehensive methodology includes diverse datasets, meticulous image preprocessing, robust model training, and validation strategies, emphasizing the model's adaptability and reliability in varied clinical contexts. The findings showcase the CNN model's exceptional performance, achieving a 95.2% accuracy rate in distinguishing cancerous and non-cancerous breast tissue in the integrated dataset, thereby demonstrating its potential for enhancing clinical decision-making and fostering the development of AI-driven diagnostic solutions.","<method>Convolutional Neural Network (CNN)</method>, <method>Early Stopping callback</method>, <method>ReduceLROnPlateau callback</method>",<method>Convolutional Neural Network (CNN)</method><method>Early Stopping callback</method>
2024,https://openalex.org/W4393160204,Psychology,Detecting and Preventing Hallucinations in Large Vision Language Models,"Instruction tuned Large Vision Language Models (LVLMs) have significantly advanced in generalizing across a diverse set of multi-modal tasks, especially for Visual Question Answering (VQA). However, generating detailed responses that are visually grounded is still a challenging task for these models. We find that even the current state-of-the-art LVLMs (InstructBLIP) still contain a staggering 30 percent of the hallucinatory text in the form of non-existent objects, unfaithful descriptions, and inaccurate relationships. To address this, we introduce M-HalDetect, a Multimodal Hallucination Detection Dataset that can be used to train and benchmark models for hallucination detection and prevention. M-HalDetect consists of 16k fine-grained annotations on VQA examples, making it the first comprehensive multi-modal hallucination detection dataset for detailed image descriptions. Unlike previous work that only consider object hallucination, we additionally annotate both entity descriptions and relationships that are unfaithful. To demonstrate the potential of this dataset for hallucination prevention, we optimize InstructBLIP through our novel Fine-grained Direct Preference Optimization (FDPO). We also train fine-grained multi-modal reward models from InstructBLIP and evaluate their effectiveness with best-of-n rejection sampling (RS). We perform human evaluation on both FDPO and rejection sampling, and find that they reduce hallucination rates in InstructBLIP by 41% and 55% respectively. We also find that our reward model generalizes to other multi-modal models, reducing hallucinations in LLaVA and mPLUG-OWL by 15% and 57% respectively, and has strong correlation with human evaluated accuracy scores. The dataset is available at https://github.com/hendryx-scale/mhal-detect.","<method>Instruction tuned Large Vision Language Models (LVLMs)</method>, <method>Fine-grained Direct Preference Optimization (FDPO)</method>, <method>fine-grained multi-modal reward models</method>, <method>best-of-n rejection sampling (RS)</method>",<method>Instruction tuned Large Vision Language Models (LVLMs)</method>
2024,https://openalex.org/W4392462461,Psychology,Sentiment Analysis in the Age of Generative AI,"Abstract In the rapidly advancing age of Generative AI, Large Language Models (LLMs) such as ChatGPT stand at the forefront of disrupting marketing practice and research. This paper presents a comprehensive exploration of LLMs’ proficiency in sentiment analysis, a core task in marketing research for understanding consumer emotions, opinions, and perceptions. We benchmark the performance of three state-of-the-art LLMs, i.e., GPT-3.5, GPT-4, and Llama 2, against established, high-performing transfer learning models. Despite their zero-shot nature, our research reveals that LLMs can not only compete with but in some cases also surpass traditional transfer learning methods in terms of sentiment classification accuracy. We investigate the influence of textual data characteristics and analytical procedures on classification accuracy, shedding light on how data origin, text complexity, and prompting techniques impact LLM performance. We find that linguistic features such as the presence of lengthy, content-laden words improve classification performance, while other features such as single-sentence reviews and less structured social media text documents reduce performance. Further, we explore the explainability of sentiment classifications generated by LLMs. The findings indicate that LLMs, especially Llama 2, offer remarkable classification explanations, highlighting their advanced human-like reasoning capabilities. Collectively, this paper enriches the current understanding of sentiment analysis, providing valuable insights and guidance for the selection of suitable methods by marketing researchers and practitioners in the age of Generative AI.","<method>Large Language Models (LLMs)</method>, <method>GPT-3.5</method>, <method>GPT-4</method>, <method>Llama 2</method>, <method>transfer learning models</method>",<method>GPT-3.5</method><method>GPT-4</method><method>Llama 2</method><method>transfer learning models</method>
2024,https://openalex.org/W4392866984,Psychology,Language-based game theory in the age of artificial intelligence,"Understanding human behaviour in decision problems and strategic interactions has wide-ranging applications in economics, psychology, and artificial intelligence. Game theory offers a robust foundation for this understanding, based on the idea that individuals aim to maximize a utility function. However, the exact factors influencing strategy choices remain elusive. While traditional models try to explain human behaviour as a function of the outcomes of available actions, recent experimental research reveals that linguistic content significantly impacts decision-making, thus prompting a paradigm shift from outcome-based to language-based utility functions. This shift is more urgent than ever, given the advancement of generative AI, which has the potential to support humans in making critical decisions through language-based interactions. We propose sentiment analysis as a fundamental tool for this shift and take an initial step by analyzing 61 experimental instructions from the dictator game, an economic game capturing the balance between self-interest and the interest of others, which is at the core of many social interactions. Our meta-analysis shows that sentiment analysis can explain human behaviour beyond economic outcomes. We discuss future research directions. We hope this work sets the stage for a novel game theoretical approach that emphasizes the importance of language in human decisions.",<method>sentiment analysis</method>,No methods remaining
2024,https://openalex.org/W4393154152,Psychology,NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models,"Trained with an unprecedented scale of data, large language models (LLMs) like ChatGPT and GPT-4 exhibit the emergence of significant reasoning abilities from model scaling. Such a trend underscored the potential of training LLMs with unlimited language data, advancing the development of a universal embodied agent. In this work, we introduce the NavGPT, a purely LLM-based instruction-following navigation agent, to reveal the reasoning capability of GPT models in complex embodied scenes by performing zero-shot sequential action prediction for vision-and-language navigation (VLN). At each step, NavGPT takes the textual descriptions of visual observations, navigation history, and future explorable directions as inputs to reason the agent's current status, and makes the decision to approach the target. Through comprehensive experiments, we demonstrate NavGPT can explicitly perform high-level planning for navigation, including decomposing instruction into sub-goals, integrating commonsense knowledge relevant to navigation task resolution, identifying landmarks from observed scenes, tracking navigation progress, and adapting to exceptions with plan adjustment. Furthermore, we show that LLMs is capable of generating high-quality navigational instructions from observations and actions along a path, as well as drawing accurate top-down metric trajectory given the agent's navigation history. Despite the performance of using NavGPT to zero-shot R2R tasks still falling short of trained models, we suggest adapting multi-modality inputs for LLMs to use as visual navigation agents and applying the explicit reasoning of LLMs to benefit learning-based models. Code is available at: https://github.com/GengzeZhou/NavGPT.","<method>large language models (LLMs)</method>, <method>ChatGPT</method>, <method>GPT-4</method>, <method>NavGPT</method>, <method>zero-shot sequential action prediction</method>",<method>GPT-4</method><method>zero-shot sequential action prediction</method>
2024,https://openalex.org/W4394681533,Psychology,REVIEWING THE IMPACT OF HEALTH INFORMATION TECHNOLOGY ON HEALTHCARE MANAGEMENT EFFICIENCY,"This research paper explores the intricate relationship between Health Information Technology (HIT) and healthcare management efficiency, investigating current trends, emerging technologies, and their potential implications. The study encompasses a thorough literature review, highlighting the impact of HIT on operational and clinical aspects of healthcare delivery. Key findings reveal the transformative role of technology in streamlining administrative processes, improving communication, and enhancing overall patient care. Ethical considerations, patient privacy, and regulation compliance are crucial factors in successfully implementing HIT. Looking towards the future, the paper anticipates the integration of emerging technologies such as Artificial Intelligence, Blockchain, and the Internet of Things, signalling a paradigm shift in healthcare management. While acknowledging the potential benefits, the research also underscores the importance of ethical frameworks, transparency, and user-centred design in adopting these technologies. The study concludes with reflections on the limitations of the research, suggesting avenues for future exploration. Recommendations emphasize the need for ongoing research, longitudinal studies, and a global perspective to ensure healthcare organizations effectively leverage technology while maintaining ethical standards. The findings of this research carry implications for healthcare practitioners, policymakers, and technology innovators, encouraging a strategic and ethical approach to the ever-evolving landscape of health information technology.&#x0D; Keywords: Health Information Technology, Healthcare Management Efficiency, Emerging Technologies, Ethical Considerations, Patient Privacy.",<method>Artificial Intelligence</method>,No methods remaining
2024,https://openalex.org/W4402780379,Psychology,Investigating Spatial Effects through Machine Learning and Leveraging Explainable AI for Child Malnutrition in Pakistan,"While socioeconomic gradients in regional health inequalities are firmly established, the synergistic interactions between socioeconomic deprivation and climate vulnerability within convenient proximity and neighbourhood locations with health disparities remain poorly explored and thus require deep understanding within a regional context. Furthermore, disregarding the importance of spatial spillover effects and nonlinear effects of covariates on childhood stunting are inevitable in dealing with an enduring issue of regional health inequalities. The present study aims to investigate the spatial inequalities in childhood stunting at the district level in Pakistan and validate the importance of spatial lag in predicting childhood stunting. Furthermore, it examines the presence of any nonlinear relationships among the selected independent features with childhood stunting. The study utilized data related to socioeconomic features from MICS 2017–2018 and climatic data from Integrated Contextual Analysis. A multi-model approach was employed to address the research questions, which included Ordinary Least Squares Regression (OLS), various Spatial Models, Machine Learning Algorithms and Explainable Artificial Intelligence methods. Firstly, OLS was used to analyse and test the linear relationships among selected variables. Secondly, Spatial Durbin Error Model (SDEM) was used to detect and capture the impact of spatial spillover on childhood stunting. Third, XGBoost and Random Forest machine learning algorithms were employed to examine and validate the importance of the spatial lag component. Finally, EXAI methods such as SHapley were utilized to identify potential nonlinear relationships. The study found a clear pattern of spatial clustering and geographical disparities in childhood stunting, with multidimensional poverty, high climate vulnerability and early marriage worsening childhood stunting. In contrast, low climate vulnerability, high exposure to mass media and high women’s literacy were found to reduce childhood stunting. The use of machine learning algorithms, specifically XGBoost and Random Forest, highlighted the significant role played by the average value in the neighbourhood in predicting childhood stunting in nearby districts, confirming that the spatial spillover effect is not bounded by geographical boundaries. Furthermore, EXAI methods such as partial dependency plot reveal the existence of a nonlinear relationship between multidimensional poverty and childhood stunting. The study’s findings provide valuable insights into the spatial distribution of childhood stunting in Pakistan, emphasizing the importance of considering spatial effects in predicting childhood stunting. Individual and household-level factors such as exposure to mass media and women’s literacy have shown positive implications for childhood stunting. It further provides a justification for the usage of EXAI methods to draw better insights and propose customised intervention policies accordingly.","<method>Ordinary Least Squares Regression (OLS)</method>, <method>Spatial Durbin Error Model (SDEM)</method>, <method>XGBoost</method>, <method>Random Forest</method>, <method>Explainable Artificial Intelligence (EXAI) methods</method>, <method>SHapley</method>, <method>partial dependency plot</method>",<method>XGBoost</method><method>Random Forest</method><method>partial dependency plot</method>
2024,https://openalex.org/W4392764062,Psychology,"When artificial intelligence substitutes humans in higher education: the cost of loneliness, student success, and retention","Artificial intelligence (AI) may be the new-new-norm in a post-pandemic learning environment. There is a growing number of university students using AI like ChatGPT and Bard to support their academic experience. Much of the AI in higher education research to date has focused on academic integrity and matters of authorship; yet, there may be unintended consequences beyond these concerns for students. That is, there may be people who reduce their formal social interactions while using these tools. This study evaluates 387 university students and their relationship to – and with – artificial intelligence large-language model-based tools. Using structural equation modelling, the study finds evidence that while AI chatbots designed for information provision may be associated with student performance, when social support, psychological wellbeing, loneliness, and sense of belonging are considered it has a net negative effect on achievement. This study tests an AI-specific form of social support, and the cost it may pose to student success, wellbeing, and retention. Indeed, while AI chatbot usage may be associated with poorer social outcomes, human-substitution activity that may be occurring when a student chooses to seek support from an AI rather than a human (e.g. a librarian, professor, or student advisor) may pose interesting learning and teaching policy implications. We explore the implications of this from the lens of student success and belonging.",<method>structural equation modelling</method>,No methods remaining
2024,https://openalex.org/W4390659289,Psychology,Cognition-Driven Structural Prior for Instance-Dependent Label Transition Matrix Estimation,"The label transition matrix has emerged as a widely accepted method for mitigating label noise in machine learning. In recent years, numerous studies have centered on leveraging deep neural networks to estimate the label transition matrix for individual instances within the context of instance-dependent noise. However, these methods suffer from low search efficiency due to the large space of feasible solutions. Behind this drawback, we have explored that the real murderer lies in the invalid class transitions, that is, the actual transition probability between certain classes is zero but is estimated to have a certain value. To mask the <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">invalid class transitions</i> , we introduced a human-cognition-assisted method with structural information from human cognition. Specifically, we introduce a structured transition matrix network ( <bold xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">STMN</b> ) designed with an adversarial learning process to balance instance features and prior information from human cognition. The proposed method offers two advantages: 1) better estimation effectiveness is obtained by sparing the transition matrix and 2) better estimation accuracy is obtained with the assistance of human cognition. By exploiting these two advantages, our method parametrically estimates a sparse label transition matrix, effectively converting noisy labels into true labels. The efficiency and superiority of our proposed method are substantiated through comprehensive comparisons with state-of-the-art methods on three synthetic datasets and a real-world dataset. Our code will be available at https://github.com/WheatCao/STMN-Pytorch.","<method>label transition matrix</method>, <method>deep neural networks</method>, <method>structured transition matrix network (STMN)</method>, <method>adversarial learning process</method>",<method>deep neural networks</method><method>adversarial learning process</method>
2024,https://openalex.org/W4391044499,Psychology,Artificial intelligence (AI)—it’s the end of the tox as we know it (and I feel fine)*,"The rapid progress of AI impacts diverse scientific disciplines, including toxicology, and has the potential to transform chemical safety evaluation. Toxicology has evolved from an empirical science focused on observing apical outcomes of chemical exposure, to a data-rich field ripe for AI integration. The volume, variety and velocity of toxicological data from legacy studies, literature, high-throughput assays, sensor technologies and omics approaches create opportunities but also complexities that AI can help address. In particular, machine learning is well suited to handle and integrate large, heterogeneous datasets that are both structured and unstructured-a key challenge in modern toxicology. AI methods like deep neural networks, large language models, and natural language processing have successfully predicted toxicity endpoints, analyzed high-throughput data, extracted facts from literature, and generated synthetic data. Beyond automating data capture, analysis, and prediction, AI techniques show promise for accelerating quantitative risk assessment by providing probabilistic outputs to capture uncertainties. AI also enables explanation methods to unravel mechanisms and increase trust in modeled predictions. However, issues like model interpretability, data biases, and transparency currently limit regulatory endorsement of AI. Multidisciplinary collaboration is needed to ensure development of interpretable, robust, and human-centered AI systems. Rather than just automating human tasks at scale, transformative AI can catalyze innovation in how evidence is gathered, data are generated, hypotheses are formed and tested, and tasks are performed to usher new paradigms in chemical safety assessment. Used judiciously, AI has immense potential to advance toxicology into a more predictive, mechanism-based, and evidence-integrated scientific discipline to better safeguard human and environmental wellbeing across diverse populations.","<method>machine learning</method>, <method>deep neural networks</method>, <method>large language models</method>, <method>natural language processing</method>",<method>machine learning</method><method>deep neural networks</method>
2024,https://openalex.org/W4391107516,Psychology,Multiple Classification of Brain MRI Autism Spectrum Disorder by Age and Gender Using Deep Learning,"Abstract The fact that the rapid and definitive diagnosis of autism cannot be made today and that autism cannot be treated provides an impetus to look into novel technological solutions. To contribute to the resolution of this problem through multiple classifications by considering age and gender factors, in this study, two quadruple and one octal classifications were performed using a deep learning (DL) approach. Gender in one of the four classifications and age groups in the other were considered. In the octal classification, classes were created considering gender and age groups. In addition to the diagnosis of ASD (Autism Spectrum Disorders), another goal of this study is to find out the contribution of gender and age factors to the diagnosis of ASD by making multiple classifications based on age and gender for the first time. Brain structural MRI (sMRI) scans of participators with ASD and TD (Typical Development) were pre-processed in the system originally designed for this purpose. Using the Canny Edge Detection (CED) algorithm, the sMRI image data was cropped in the data pre-processing stage, and the data set was enlarged five times with the data augmentation (DA) techniques. The most optimal convolutional neural network (CNN) models were developed using the grid search optimization (GSO) algorism. The proposed DL prediction system was tested with the five-fold cross-validation technique. Three CNN models were designed to be used in the system. The first of these models is the quadruple classification model created by taking gender into account (model 1), the second is the quadruple classification model created by taking into account age (model 2), and the third is the eightfold classification model created by taking into account both gender and age (model 3). ). The accuracy rates obtained for all three designed models are 80.94, 85.42 and 67.94, respectively. These obtained accuracy rates were compared with pre-trained models by using the transfer learning approach. As a result, it was revealed that age and gender factors were effective in the diagnosis of ASD with the system developed for ASD multiple classifications, and higher accuracy rates were achieved compared to pre-trained models.","<method>deep learning (DL) approach</method>, <method>Canny Edge Detection (CED) algorithm</method>, <method>data augmentation (DA) techniques</method>, <method>convolutional neural network (CNN) models</method>, <method>grid search optimization (GSO) algorithm</method>, <method>five-fold cross-validation technique</method>, <method>transfer learning approach</method>",<method>convolutional neural network (CNN) models</method><method>transfer learning approach</method>
2024,https://openalex.org/W4400461591,Psychology,Counterfactual Explanations and Algorithmic Recourses for Machine Learning: A Review,"Machine learning plays a role in many deployed decision systems, often in ways that are difficult or impossible to understand by human stakeholders. Explaining, in a human-understandable way, the relationship between the input and output of machine learning models is essential to the development of trustworthy machine learning based systems. A burgeoning body of research seeks to define the goals and methods of explainability in machine learning. In this article, we seek to review and categorize research on counterfactual explanations , a specific class of explanation that provides a link between what could have happened had input to a model been changed in a particular way. Modern approaches to counterfactual explainability in machine learning draw connections to the established legal doctrine in many countries, making them appealing to fielded systems in high-impact areas such as finance and healthcare. Thus, we design a rubric with desirable properties of counterfactual explanation algorithms and comprehensively evaluate all currently proposed algorithms against that rubric. Our rubric provides easy comparison and comprehension of the advantages and disadvantages of different approaches and serves as an introduction to major research themes in this field. We also identify gaps and discuss promising research directions in the space of counterfactual explainability.","<method>counterfactual explanations</method>, <method>counterfactual explanation algorithms</method>",<method>counterfactual explanations</method><method>counterfactual explanation algorithms</method>
2024,https://openalex.org/W4401533174,Psychology,The Crowdless Future? Generative AI and Creative Problem-Solving,"The rapid advances in generative artificial intelligence (AI) open up attractive opportunities for creative problem-solving through human-guided AI partnerships. To explore this potential, we initiated a crowdsourcing challenge focused on sustainable, circular economy business ideas generated by the human crowd (HC) and collaborative human-AI efforts using two alternative forms of solution search. The challenge attracted 125 global solvers from various industries, and we used strategic prompt engineering to generate the human-AI solutions. We recruited 300 external human evaluators to judge a randomized selection of 13 out of 234 solutions, totaling 3,900 evaluator-solution pairs. Our results indicate that while human crowd solutions exhibited higher novelty—both on average and for highly novel outcomes—human-AI solutions demonstrated superior strategic viability, financial and environmental value, and overall quality. Notably, human-AI solutions cocreated through differentiated search, where human-guided prompts instructed the large language model to sequentially generate outputs distinct from previous iterations, outperformed solutions generated through independent search. By incorporating “AI in the loop” into human-centered creative problem-solving, our study demonstrates a scalable, cost-effective approach to augment the early innovation phases and lays the groundwork for investigating how integrating human-AI solution search processes can drive more impactful innovations. Funding: This work was supported by Harvard Business School (Division of Research and Faculty Development) and the Laboratory for Innovation Science at Harvard (LISH) at the Digital Data and Design (D 3 ) Institute at Harvard. Supplemental Material: The online appendix is available at https://doi.org/10.1287/orsc.2023.18430 .","<method>strategic prompt engineering</method>, <method>large language model</method>",<method>large language model</method>
2024,https://openalex.org/W4391145008,Psychology,Assessing ChatGPT’s Mastery of Bloom’s Taxonomy Using Psychosomatic Medicine Exam Questions: Mixed-Methods Study,"Background Large language models such as GPT-4 (Generative Pre-trained Transformer 4) are being increasingly used in medicine and medical education. However, these models are prone to “hallucinations” (ie, outputs that seem convincing while being factually incorrect). It is currently unknown how these errors by large language models relate to the different cognitive levels defined in Bloom’s taxonomy. Objective This study aims to explore how GPT-4 performs in terms of Bloom’s taxonomy using psychosomatic medicine exam questions. Methods We used a large data set of psychosomatic medicine multiple-choice questions (N=307) with real-world results derived from medical school exams. GPT-4 answered the multiple-choice questions using 2 distinct prompt versions: detailed and short. The answers were analyzed using a quantitative approach and a qualitative approach. Focusing on incorrectly answered questions, we categorized reasoning errors according to the hierarchical framework of Bloom’s taxonomy. Results GPT-4’s performance in answering exam questions yielded a high success rate: 93% (284/307) for the detailed prompt and 91% (278/307) for the short prompt. Questions answered correctly by GPT-4 had a statistically significant higher difficulty than questions answered incorrectly (P=.002 for the detailed prompt and P&lt;.001 for the short prompt). Independent of the prompt, GPT-4’s lowest exam performance was 78.9% (15/19), thereby always surpassing the “pass” threshold. Our qualitative analysis of incorrect answers, based on Bloom’s taxonomy, showed that errors were primarily in the “remember” (29/68) and “understand” (23/68) cognitive levels; specific issues arose in recalling details, understanding conceptual relationships, and adhering to standardized guidelines. Conclusions GPT-4 demonstrated a remarkable success rate when confronted with psychosomatic medicine multiple-choice exam questions, aligning with previous findings. When evaluated through Bloom’s taxonomy, our data revealed that GPT-4 occasionally ignored specific facts (remember), provided illogical reasoning (understand), or failed to apply concepts to a new situation (apply). These errors, which were confidently presented, could be attributed to inherent model biases and the tendency to generate outputs that maximize likelihood.","<method>large language models</method>, <method>GPT-4 (Generative Pre-trained Transformer 4)</method>",<method>GPT-4 (Generative Pre-trained Transformer 4)</method>
2024,https://openalex.org/W4391531220,Psychology,An Explainable AI Paradigm for Alzheimer’s Diagnosis Using Deep Transfer Learning,"Alzheimer’s disease (AD) is a progressive neurodegenerative disorder that affects millions of individuals worldwide, causing severe cognitive decline and memory impairment. The early and accurate diagnosis of AD is crucial for effective intervention and disease management. In recent years, deep learning techniques have shown promising results in medical image analysis, including AD diagnosis from neuroimaging data. However, the lack of interpretability in deep learning models hinders their adoption in clinical settings, where explainability is essential for gaining trust and acceptance from healthcare professionals. In this study, we propose an explainable AI (XAI)-based approach for the diagnosis of Alzheimer’s disease, leveraging the power of deep transfer learning and ensemble modeling. The proposed framework aims to enhance the interpretability of deep learning models by incorporating XAI techniques, allowing clinicians to understand the decision-making process and providing valuable insights into disease diagnosis. By leveraging popular pre-trained convolutional neural networks (CNNs) such as VGG16, VGG19, DenseNet169, and DenseNet201, we conducted extensive experiments to evaluate their individual performances on a comprehensive dataset. The proposed ensembles, Ensemble-1 (VGG16 and VGG19) and Ensemble-2 (DenseNet169 and DenseNet201), demonstrated superior accuracy, precision, recall, and F1 scores compared to individual models, reaching up to 95%. In order to enhance interpretability and transparency in Alzheimer’s diagnosis, we introduced a novel model achieving an impressive accuracy of 96%. This model incorporates explainable AI techniques, including saliency maps and grad-CAM (gradient-weighted class activation mapping). The integration of these techniques not only contributes to the model’s exceptional accuracy but also provides clinicians and researchers with visual insights into the neural regions influencing the diagnosis. Our findings showcase the potential of combining deep transfer learning with explainable AI in the realm of Alzheimer’s disease diagnosis, paving the way for more interpretable and clinically relevant AI models in healthcare.","<method>deep learning</method>, <method>explainable AI (XAI)</method>, <method>deep transfer learning</method>, <method>ensemble modeling</method>, <method>pre-trained convolutional neural networks (CNNs)</method>, <method>VGG16</method>, <method>VGG19</method>, <method>DenseNet169</method>, <method>DenseNet201</method>, <method>Ensemble-1 (VGG16 and VGG19)</method>, <method>Ensemble-2 (DenseNet169 and DenseNet201)</method>, <method>saliency maps</method>, <method>grad-CAM (gradient-weighted class activation mapping)</method>",<method>deep learning</method><method>explainable AI (XAI)</method><method>deep transfer learning</method><method>ensemble modeling</method><method>pre-trained convolutional neural networks (CNNs)</method><method>VGG16</method><method>VGG19</method><method>DenseNet169</method><method>DenseNet201</method><method>saliency maps</method><method>grad-CAM (gradient-weighted class activation mapping)</method>
2024,https://openalex.org/W4391678457,Psychology,AI in personalized learning,"Artificial Intelligence (AI) has revolutionized various sectors, and its impact on education, specifically in personalized learning, is increasingly significant. Personalized learning aims to cater to individual students' unique needs, learning styles, and abilities, enabling them to achieve better educational outcomes. AI technologies offer the potential to transform traditional educational models by providing adaptive and tailored approaches that enhance student engagement, learning efficiency, and overall educational experiences. This abstract provides an overview of the role of AI in personalized learning and highlights its key benefits and challenges. The abstract also explores various AI-powered tools and techniques used in personalized learning environments, such as intelligent tutoring systems, recommendation engines, and adaptive assessments. These tools leverage machine learning algorithms, natural language processing, and data analytics to gather and analyze vast amounts of educational data, providing valuable insights for personalized instruction. AI in personalized learning facilitates adaptive content delivery, enabling students to learn at their own pace and according to their individual strengths and weaknesses. Intelligent tutoring systems, for instance, offer customized feedback, explanations, and recommendations based on real-time student interactions, fostering deeper comprehension and engagement. Moreover, AI-powered recommendation engines provide personalized learning resources and materials that align with students' interests, preferences, and skill levels, creating a more tailored and immersive learning experience. While AI in personalized learning presents numerous benefits, it also poses certain challenges. Privacy concerns, ethical considerations, and potential biases in AI algorithms must be carefully addressed to ensure the responsible and equitable use of these technologies. Furthermore, effective implementation requires adequate infrastructure, access to quality data, and teacher training to leverage AI tools optimally.","<method>intelligent tutoring systems</method>, <method>recommendation engines</method>, <method>adaptive assessments</method>, <method>machine learning algorithms</method>, <method>natural language processing</method>, <method>data analytics</method>",No methods remaining
2024,https://openalex.org/W4393009377,Psychology,Generative Artificial Intelligence in Higher Education: Exploring Ways of Harnessing Pedagogical Practices with the Assistance of ChatGPT,"There is a growing interest in using generative artificial intelligence (AI) for educational purposes within the higher education environments, while AI applications (such as ChatGPT) can transform traditional teaching and learning methods. ChatGPT is an advanced AI tool that generates new content and human-like responses. The purpose of this paper is to use ChatGPT as a research assistant in order to explore ways AI can be harnessed to enhance pedagogical practices in higher education. This is a qualitative study, in which the output-responses generated by ChatGPT provided a starting point for the investigation. AI can be harnessed to enhance pedagogical practices in higher education in various ways including personalized learning, automated assessment and feedback generation, virtual assistants and chatbots, content creation, resource recommendation, time management, language translation and support, research assistance, simulations and virtual labs. Other educational affordances that can strengthen the teaching and learning experience regard collaboration and communication, accessibility and inclusivity, as well as AI literacy. When implementing AI tools such as ChatGPT in higher education, ethical considerations (e.g., data privacy, transparency, accessibility, cultural sensitivity), potential misuses and concerns need to also be addressed. Although ChatGPT can aid the generation of content-ideas for further exploration, it is a complementary-supportive tool, and its output necessitates human evaluation and review. The integration of ChatGPT and other AI tools in the higher educational process/practices has implications for educators, students, design of curricula, and university policy makers. Received: 17 January 2024 | Revised: 27 February 2024 | Accepted: 19 March 2024 Conflicts of Interest The author declares that she has no conflicts of interest to this work. Data Availability Statement Data sharing is not applicable to this article as no new data were created or analyzed in this study.","<method>generative artificial intelligence (AI)</method>, <method>ChatGPT</method>",No methods remaining
2024,https://openalex.org/W4393091384,Psychology,REVIEWING THE TRANSFORMATIONAL IMPACT OF EDGE COMPUTING ON REAL-TIME DATA PROCESSING AND ANALYTICS,"Edge computing has emerged as a pivotal paradigm shift in the realm of data processing and analytics, revolutionizing the way organizations handle real-time data. This review presents a comprehensive review of the transformational impact of edge computing on real-time data processing and analytics. Firstly, the review delves into the fundamental concepts of edge computing, elucidating its architectural framework and highlighting its distinct advantages over traditional cloud-centric approaches. By distributing computational resources closer to data sources, edge computing mitigates latency issues and enhances responsiveness, thereby enabling real-time data processing at the edge. Furthermore, this review explores how edge computing facilitates the seamless integration of analytics capabilities into edge devices, empowering organizations to derive actionable insights at the source of data generation. Leveraging advanced analytics algorithms, such as machine learning and artificial intelligence, edge computing enables autonomous decision-making and predictive analytics in real time, fostering innovation across diverse industry verticals. Moreover, the review examines the transformative implications of edge computing on various sectors, including healthcare, manufacturing, transportation, and smart cities. By enabling localized data processing and analytics, edge computing enhances operational efficiency, ensures data privacy and security, and unlocks new opportunities for business optimization and value creation. This review underscores the profound impact of edge computing on real-time data processing and analytics, revolutionizing the way organizations harness data to drive informed decision-making and gain competitive advantage in today's dynamic business landscape. As edge computing continues to evolve, its transformative potential is poised to redefine the future of data-driven innovation and digital transformation.&#x0D; Keywords: Edge, Computing, Analytics, Data, Impact, Review.","<method>machine learning</method>, <method>artificial intelligence</method>",<method>machine learning</method>
2024,https://openalex.org/W4394859632,Psychology,Artificial intelligence in healthcare delivery: Prospects and pitfalls,"This review provides a comprehensive examination of the integration of Artificial Intelligence (AI) into healthcare, focusing on its transformative implications and challenges. Utilising a systematic search strategy across electronic databases such as PubMed, Scopus, Embase, and Sciencedirect, relevant peer-reviewed articles published in English between January 2010 till date were identified. Findings reveal AI's significant impact on healthcare delivery, including its role in enhancing diagnostic precision, enabling treatment personalisation, facilitating predictive analytics, automating tasks, and driving robotics. AI algorithms demonstrate high accuracy in analysing medical images for disease diagnosis and enable the creation of tailored treatment plans based on patient data analysis. Predictive analytics identify high-risk patients for proactive interventions, while AI-powered tools streamline workflows, improving efficiency and patient experience. Additionally, AI-driven robotics automate tasks and enhance care delivery, particularly in rehabilitation and surgery. However, challenges such as data quality, interpretability, bias, and regulatory frameworks must be addressed for responsible AI implementation. Recommendations emphasise the need for robust ethical and legal frameworks, human-AI collaboration, safety validation, education, and comprehensive regulation to ensure the ethical and effective integration of AI in healthcare. This review provides valuable insights into AI's transformative potential in healthcare while advocating for responsible implementation to ensure patient safety and efficacy.","<method>AI algorithms</method>, <method>Predictive analytics</method>, <method>AI-powered tools</method>, <method>AI-driven robotics</method>",No methods remaining
2024,https://openalex.org/W4391399751,Psychology,"Human-in-the-Loop Reinforcement Learning: A Survey and Position on Requirements, Challenges, and Opportunities","Artificial intelligence (AI) and especially reinforcement learning (RL) have the potential to enable agents to learn and perform tasks autonomously with superhuman performance. However, we consider RL as fundamentally a Human-in-the-Loop (HITL) paradigm, even when an agent eventually performs its task autonomously. In cases where the reward function is challenging or impossible to define, HITL approaches are considered particularly advantageous. The application of Reinforcement Learning from Human Feedback (RLHF) in systems such as ChatGPT demonstrates the effectiveness of optimizing for user experience and integrating their feedback into the training loop. In HITL RL, human input is integrated during the agent’s learning process, allowing iterative updates and fine-tuning based on human feedback, thus enhancing the agent’s performance. Since the human is an essential part of this process, we argue that human-centric approaches are the key to successful RL, a fact that has not been adequately considered in the existing literature. This paper aims to inform readers about current explainability methods in HITL RL. It also shows how the application of explainable AI (xAI) and specific improvements to existing explainability approaches can enable a better human-agent interaction in HITL RL for all types of users, whether for lay people, domain experts, or machine learning specialists. Accounting for the workflow in HITL RL and based on software and machine learning methodologies, this article identifies four phases for human involvement for creating HITL RL systems: (1) Agent Development, (2) Agent Learning, (3) Agent Evaluation, and (4) Agent Deployment. We highlight human involvement, explanation requirements, new challenges, and goals for each phase. We furthermore identify low-risk, high-return opportunities for explainability research in HITL RL and present long-term research goals to advance the field. Finally, we propose a vision of human-robot collaboration that allows both parties to reach their full potential and cooperate effectively.","<method>reinforcement learning (RL)</method>, <method>Reinforcement Learning from Human Feedback (RLHF)</method>, <method>explainable AI (xAI)</method>",<method>reinforcement learning (RL)</method><method>Reinforcement Learning from Human Feedback (RLHF)</method><method>explainable AI (xAI)</method>
2024,https://openalex.org/W4394785902,Psychology,"Evidence-based potential of generative artificial intelligence large language models in orthodontics: a comparative study of ChatGPT, Google Bard, and Microsoft Bing","Summary Background The increasing utilization of large language models (LLMs) in Generative Artificial Intelligence across various medical and dental fields, and specifically orthodontics, raises questions about their accuracy. Objective This study aimed to assess and compare the answers offered by four LLMs: Google’s Bard, OpenAI’s ChatGPT-3.5, and ChatGPT-4, and Microsoft’s Bing, in response to clinically relevant questions within the field of orthodontics. Materials and methods Ten open-type clinical orthodontics-related questions were posed to the LLMs. The responses provided by the LLMs were assessed on a scale ranging from 0 (minimum) to 10 (maximum) points, benchmarked against robust scientific evidence, including consensus statements and systematic reviews, using a predefined rubric. After a 4-week interval from the initial evaluation, the answers were reevaluated to gauge intra-evaluator reliability. Statistical comparisons were conducted on the scores using Friedman’s and Wilcoxon’s tests to identify the model providing the answers with the most comprehensiveness, scientific accuracy, clarity, and relevance. Results Overall, no statistically significant differences between the scores given by the two evaluators, on both scoring occasions, were detected, so an average score for every LLM was computed. The LLM answers scoring the highest, were those of Microsoft Bing Chat (average score = 7.1), followed by ChatGPT 4 (average score = 4.7), Google Bard (average score = 4.6), and finally ChatGPT 3.5 (average score 3.8). While Microsoft Bing Chat statistically outperformed ChatGPT-3.5 (P-value = 0.017) and Google Bard (P-value = 0.029), as well, and Chat GPT-4 outperformed Chat GPT-3.5 (P-value = 0.011), all models occasionally produced answers with a lack of comprehensiveness, scientific accuracy, clarity, and relevance. Limitations The questions asked were indicative and did not cover the entire field of orthodontics. Conclusions Language models (LLMs) show great potential in supporting evidence-based orthodontics. However, their current limitations pose a potential risk of making incorrect healthcare decisions if utilized without careful consideration. Consequently, these tools cannot serve as a substitute for the orthodontist’s essential critical thinking and comprehensive subject knowledge. For effective integration into practice, further research, clinical validation, and enhancements to the models are essential. Clinicians must be mindful of the limitations of LLMs, as their imprudent utilization could have adverse effects on patient care.",<method>large language models (LLMs)</method>,No methods remaining
2024,https://openalex.org/W4401844424,Psychology,AlphaFold predictions of fold-switched conformations are driven by structure memorization,"Abstract Recent work suggests that AlphaFold (AF)–a deep learning-based model that can accurately infer protein structure from sequence–may discern important features of folded protein energy landscapes, defined by the diversity and frequency of different conformations in the folded state. Here, we test the limits of its predictive power on fold-switching proteins, which assume two structures with regions of distinct secondary and/or tertiary structure. We find that (1) AF is a weak predictor of fold switching and (2) some of its successes result from memorization of training-set structures rather than learned protein energetics. Combining &gt;280,000 models from several implementations of AF2 and AF3, a 35% success rate was achieved for fold switchers likely in AF’s training sets. AF2’s confidence metrics selected against models consistent with experimentally determined fold-switching structures and failed to discriminate between low and high energy conformations. Further, AF captured only one out of seven experimentally confirmed fold switchers outside of its training sets despite extensive sampling of an additional ~280,000 models. Several observations indicate that AF2 has memorized structural information during training, and AF3 misassigns coevolutionary restraints. These limitations constrain the scope of successful predictions, highlighting the need for physically based methods that readily predict multiple protein conformations.","<method>AlphaFold (AF)</method>, <method>AF2</method>, <method>AF3</method>",<method>AlphaFold (AF)</method><method>AF2</method>
2024,https://openalex.org/W4402827393,Psychology,Larger and more instructable language models become less reliable,"Abstract The prevailing methods to make large language models more powerful and amenable have been based on continuous scaling up (that is, increasing their size, data volume and computational resources 1 ) and bespoke shaping up (including post-filtering 2,3 , fine tuning or use of human feedback 4,5 ). However, larger and more instructable large language models may have become less reliable. By studying the relationship between difficulty concordance, task avoidance and prompting stability of several language model families, here we show that easy instances for human participants are also easy for the models, but scaled-up, shaped-up models do not secure areas of low difficulty in which either the model does not err or human supervision can spot the errors. We also find that early models often avoid user questions but scaled-up, shaped-up models tend to give an apparently sensible yet wrong answer much more often, including errors on difficult questions that human supervisors frequently overlook. Moreover, we observe that stability to different natural phrasings of the same question is improved by scaling-up and shaping-up interventions, but pockets of variability persist across difficulty levels. These findings highlight the need for a fundamental shift in the design and development of general-purpose artificial intelligence, particularly in high-stakes areas for which a predictable distribution of errors is paramount.","<method>continuous scaling up</method>, <method>post-filtering</method>, <method>fine tuning</method>, <method>use of human feedback</method>",<method>post-filtering</method><method>fine tuning</method><method>use of human feedback</method>
2024,https://openalex.org/W4390975281,Psychology,Semantic and Instance Segmentation in Coastal Urban Spatial Perception: A Multi-Task Learning Framework with an Attention Mechanism,"With the continuous acceleration of urbanization, urban planning and design require more in-depth research and development. Street view images can express rich urban features and guide residents’ emotions toward a city, thereby providing the most intuitive reflection of their perception of the city’s spatial quality. However, current researchers mainly conduct research on urban spatial quality through subjective experiential judgment, which includes problems such as a high cost and a low judgment accuracy. In response to these problems, this study proposes a multi-task learning urban spatial attribute perception model that integrates an attention mechanism. Via this model, the existing attributes of urban street scenes are analyzed. Then, the model is improved by introducing semantic segmentation and instance segmentation to identify and match the qualities of the urban space. The experimental results show that the multi-task learning urban spatial attribute perception model with an integrated attention mechanism has prediction accuracies of 79.54%, 78.62%, 79.68%, 77.42%, 78.45%, and 76.98% for the urban spatial attributes of beauty, boredom, depression, liveliness, safety, and richness, respectively. The accuracy of the multi-task learning urban spatial scene feature image segmentation model with an integrated attention mechanism is 95.4, 94.8, 96.2, 92.1, and 96.7 for roads, walls, sky, vehicles, and buildings, respectively. The multi-task learning urban spatial scene feature image segmentation model with an integrated attention mechanism has a higher recognition accuracy for urban spatial buildings than other models. These research results indicate the model’s effectiveness in matching urban spatial quality with public perception.","<method>multi-task learning</method>, <method>attention mechanism</method>, <method>semantic segmentation</method>, <method>instance segmentation</method>",<method>multi-task learning</method><method>attention mechanism</method><method>semantic segmentation</method><method>instance segmentation</method>
2024,https://openalex.org/W4391126287,Psychology,Evaluating the ChatGPT family of models for biomedical reasoning and classification,"Abstract Objective Large language models (LLMs) have shown impressive ability in biomedical question-answering, but have not been adequately investigated for more specific biomedical applications. This study investigates ChatGPT family of models (GPT-3.5, GPT-4) in biomedical tasks beyond question-answering. Materials and Methods We evaluated model performance with 11 122 samples for two fundamental tasks in the biomedical domain—classification (n = 8676) and reasoning (n = 2446). The first task involves classifying health advice in scientific literature, while the second task is detecting causal relations in biomedical literature. We used 20% of the dataset for prompt development, including zero- and few-shot settings with and without chain-of-thought (CoT). We then evaluated the best prompts from each setting on the remaining dataset, comparing them to models using simple features (BoW with logistic regression) and fine-tuned BioBERT models. Results Fine-tuning BioBERT produced the best classification (F1: 0.800-0.902) and reasoning (F1: 0.851) results. Among LLM approaches, few-shot CoT achieved the best classification (F1: 0.671-0.770) and reasoning (F1: 0.682) results, comparable to the BoW model (F1: 0.602-0.753 and 0.675 for classification and reasoning, respectively). It took 78 h to obtain the best LLM results, compared to 0.078 and 0.008 h for the top-performing BioBERT and BoW models, respectively. Discussion The simple BoW model performed similarly to the most complex LLM prompting. Prompt engineering required significant investment. Conclusion Despite the excitement around viral ChatGPT, fine-tuning for two fundamental biomedical natural language processing tasks remained the best strategy.","<method>ChatGPT family of models (GPT-3.5, GPT-4)</method>, <method>zero-shot prompting</method>, <method>few-shot prompting</method>, <method>chain-of-thought (CoT) prompting</method>, <method>Bag of Words (BoW) with logistic regression</method>, <method>fine-tuned BioBERT</method>","<method>ChatGPT family of models (GPT-3.5, GPT-4)</method><method>zero-shot prompting</method><method>few-shot prompting</method><method>chain-of-thought (CoT) prompting</method><method>Bag of Words (BoW) with logistic regression</method><method>fine-tuned BioBERT</method>"
2024,https://openalex.org/W4391482140,Psychology,The implementation of the cognitive theory of multimedia learning in the design and evaluation of an AI educational video assistant utilizing large language models,"The integration of Artificial Intelligence (AI) holds immense potential for revolutionizing education; especially, in contexts where multimodal learning experiences are designed. This paper investigated the potential benefits of Generative Artificial Intelligence (AI) in education, concentrating on the design and evaluation of an AI Educational Video Assistant tailored for multimodal learning experiences. The tool, utilizing the principles of the Cognitive Theory of Multimedia Learning (CTML), comprises three modules: Transcription, Engagement, and Reinforcement, each focusing on distinct aspects of the learning process. Integration of Automatic Speech Recognition (ASR) using OpenAI's Whisper and Google's Large Language Model (LLM) Bard. Our twofold objective includes both the development of this AI assistant tool and the assessment of its effect on improving the learning experiences. For the evaluation, a mixed methods approach was adopted, combining human evaluation by nine educational experts with automatic metrics. Participants provided their perceptions on the tool's effectiveness in terms of engagement, content organization, clarity, and usability. Additionally, automatic metrics including Content Distinctiveness and Readability scores were computed. The results from the human evaluation suggest positive impacts across all assessed domains. The automatic metrics further proved the tool's ability in content generation and readability. Collectively, these preliminary results highlight the tool's potential to revolutionize educational design and provide personalized and engaging learning experiences.","<method>Generative Artificial Intelligence (AI)</method>, <method>Automatic Speech Recognition (ASR)</method>, <method>Large Language Model (LLM)</method>",No methods remaining
2024,https://openalex.org/W4391574742,Psychology,Optimum tuned mass damper inerter under near-fault pulse-like ground motions of buildings including soil-structure interaction,"This study investigates the effectiveness of the tuned mass damper inerter (TMDI) in mitigating building response, considering the soil structure interaction (SSI). Three types of models are examined: single degree of freedom (SDOF), low-rise multi-degree of freedom (MDOF), and high-rise MDOF. Additionally, the natural period of the SDOF model is varied to explore the TMDI's efficacy across different ranges. Frequency and time domain analysis are conducted under pulse-like ground motions. The H2 and genetic algorithm (GA) are used to optimize the parameters of the TMDI. In this optimization method the transfer function for displacement response is minimized. In time domain analysis we used Newmark's integration method to solve the equation of motion for all the cases considered. It is found that the optimized TMDI proves highly effective in mitigating the displacement response of the buildings, accounting for SSI. Notably, its efficiency is more pronounced when pulse period aligns closely with the buildings' natural period. In addition, a notable pattern emerges, wherein the TMDI excels in mitigating response for buildings experiencing large motion, thereby enhancing safety under severe conditions. These findings offer valuable insights into the application and optimization of the TMDI to enhance seismic performance in various buildings, while considering complex interaction with the soil.",<method>genetic algorithm (GA)</method>,<method>genetic algorithm (GA)</method>
2024,https://openalex.org/W4392285688,Psychology,Machine Learning and Digital Biomarkers Can Detect Early Stages of Neurodegenerative Diseases,"Neurodegenerative diseases (NDs) such as Alzheimer’s Disease (AD) and Parkinson’s Disease (PD) are devastating conditions that can develop without noticeable symptoms, causing irreversible damage to neurons before any signs become clinically evident. NDs are a major cause of disability and mortality worldwide. Currently, there are no cures or treatments to halt their progression. Therefore, the development of early detection methods is urgently needed to delay neuronal loss as soon as possible. Despite advancements in Medtech, the early diagnosis of NDs remains a challenge at the intersection of medical, IT, and regulatory fields. Thus, this review explores “digital biomarkers” (tools designed for remote neurocognitive data collection and AI analysis) as a potential solution. The review summarizes that recent studies combining AI with digital biomarkers suggest the possibility of identifying pre-symptomatic indicators of NDs. For instance, research utilizing convolutional neural networks for eye tracking has achieved significant diagnostic accuracies. ROC-AUC scores reached up to 0.88, indicating high model performance in differentiating between PD patients and healthy controls. Similarly, advancements in facial expression analysis through tools have demonstrated significant potential in detecting emotional changes in ND patients, with some models reaching an accuracy of 0.89 and a precision of 0.85. This review follows a structured approach to article selection, starting with a comprehensive database search and culminating in a rigorous quality assessment and meaning for NDs of the different methods. The process is visualized in 10 tables with 54 parameters describing different approaches and their consequences for understanding various mechanisms in ND changes. However, these methods also face challenges related to data accuracy and privacy concerns. To address these issues, this review proposes strategies that emphasize the need for rigorous validation and rapid integration into clinical practice. Such integration could transform ND diagnostics, making early detection tools more cost-effective and globally accessible. In conclusion, this review underscores the urgent need to incorporate validated digital health tools into mainstream medical practice. This integration could indicate a new era in the early diagnosis of neurodegenerative diseases, potentially altering the trajectory of these conditions for millions worldwide. Thus, by highlighting specific and statistically significant findings, this review demonstrates the current progress in this field and the potential impact of these advancements on the global management of NDs.",<method>convolutional neural networks</method>,<method>convolutional neural networks</method>
2024,https://openalex.org/W4392404912,Psychology,The Impact of Artificial Intelligence on Students' Learning Experience,"The integration of artificial intelligence (AI) in education has the potential to revolutionize the learning experience for students. This abstract provides an overview of the impact of AI on students' learning experience, highlighting its benefits and potential challenges.AI technologies such as machine learning, natural language processing, and data analytics have been increasingly adopted in educational settings. These technologies enable personalized and adaptive learning experiences, providing students with tailored content and feedback based on their individual needs and learning styles. AI-powered educational platforms can analyze vast amounts of data to identify patterns and offer personalized recommendations, thereby enhancing students' engagement and motivation.One of the significant benefits of AI in education is its ability to provide immediate and constructive feedback to students. Automated grading systems powered by AI algorithms can assess and provide feedback on assignments, quizzes, and exams promptly, allowing students to understand their strengths and weaknesses in real-time. This timely feedback facilitates self-reflection and enables students to make necessary improvements, leading to enhanced learning outcomes.Furthermore, AI can support collaborative learning environments. Intelligent tutoring systems and virtual learning assistants can facilitate group discussions, provide guidance, and foster collaboration among students. These AI-powered tools can promote active participation, critical thinking, and problem-solving skills, creating a dynamic learning environment that mirrors real-world scenarios.However, the integration of AI in education also poses challenges that need to be addressed. Privacy and ethical concerns arise when dealing with student data, as AI relies on collecting and analyzing personal information to provide personalized experiences. Safeguarding student data privacy and ensuring ethical use of AI technologies are essential considerations for educators and policymakers.Additionally, there is a potential risk of over-reliance on AI technologies, leading to a passive learning experience for students. Balancing the use of AI with human instruction and guidance is crucial to maintain meaningful interactions and promote deeper understanding.","<method>machine learning</method>, <method>natural language processing</method>, <method>AI algorithms</method>",<method>machine learning</method>
2024,https://openalex.org/W4399857583,Psychology,Integrating artificial intelligence to assess emotions in learning environments: a systematic literature review,"Introduction Artificial Intelligence (AI) is transforming multiple sectors within our society, including education. In this context, emotions play a fundamental role in the teaching-learning process given that they influence academic performance, motivation, information retention, and student well-being. Thus, the integration of AI in emotional assessment within educational environments offers several advantages that can transform how we understand and address the socio-emotional development of students. However, there remains a lack of comprehensive approach that systematizes advancements, challenges, and opportunities in this field. Aim This systematic literature review aims to explore how artificial intelligence (AI) is used to evaluate emotions within educational settings. We provide a comprehensive overview of the current state of research, focusing on advancements, challenges, and opportunities in the domain of AI-driven emotional assessment within educational settings. Method The review involved a search across the following academic databases: Pubmed, Web of Science, PsycINFO and Scopus. Forty-one articles were selected that meet the established inclusion criteria. These articles were analyzed to extract key insights related to the integration of AI and emotional assessment within educational environments. Results The findings reveal a variety of AI-driven approaches that were developed to capture and analyze students’ emotional states during learning activities. The findings are summarized in four fundamental topics: (1) emotion recognition in education, (2) technology integration and learning outcomes, (3) special education and assistive technology, (4) affective computing. Among the key AI techniques employed are machine learning and facial recognition, which are used to assess emotions. These approaches demonstrate promising potential in enhancing pedagogical strategies and creating adaptive learning environments that cater to individual emotional needs. The review identified emerging factors that, while important, require further investigation to understand their relationships and implications fully. These elements could significantly enhance the use of AI in assessing emotions within educational settings. Specifically, we are referring to: (1) federated learning, (2) convolutional neural network (CNN), (3) recurrent neural network (RNN), (4) facial expression databases, and (5) ethics in the development of intelligent systems. Conclusion This systematic literature review showcases the significance of AI in revolutionizing educational practices through emotion assessment. While advancements are evident, challenges related to accuracy, privacy, and cross-cultural validity were also identified. The synthesis of existing research highlights the need for further research into refining AI models for emotion recognition and emphasizes the importance of ethical considerations in implementing AI technologies within educational contexts.","<method>machine learning</method>, <method>facial recognition</method>, <method>federated learning</method>, <method>convolutional neural network (CNN)</method>, <method>recurrent neural network (RNN)</method>",<method>machine learning</method><method>federated learning</method><method>convolutional neural network (CNN)</method><method>recurrent neural network (RNN)</method>
2024,https://openalex.org/W4390490725,Psychology,Evaluating LLM-generated Worked Examples in an Introductory Programming Course,"Worked examples, which illustrate the process for solving a problem step-by-step, are a well-established pedagogical technique that has been widely studied in computing classrooms. However, creating high-quality worked examples is very time-intensive for educators, and thus learners tend not to have access to a broad range of such examples. The recent emergence of powerful large language models (LLMs), which appear capable of generating high-quality human-like content, may offer a solution. Separate strands of recent work have shown that LLMs can accurately generate code suitable for a novice audience, and that they can generate high-quality explanations of code. Therefore, LLMs may be well suited to creating a broad range of worked examples, overcoming the bottleneck of manual effort that is currently required. In this work, we present a novel tool, 'WorkedGen', which uses an LLM to generate interactive worked examples. We evaluate this tool with both an expert assessment of the content, and a user study involving students in a first-year Python programming course (n = ~400). We find that prompt chaining and one-shot learning are useful strategies for optimising the output of an LLM when producing worked examples. Our expert analysis suggests that LLMs generate clear explanations, and our classroom deployment revealed that students find the LLM-generated worked examples useful for their learning. We propose several avenues for future work, including investigating WorkedGen's value in a range of programming languages, and with more complex questions suitable for more advanced courses.","<method>large language models (LLMs)</method>, <method>prompt chaining</method>, <method>one-shot learning</method>",<method>prompt chaining</method><method>one-shot learning</method>
2024,https://openalex.org/W4393250851,Psychology,Evaluating the subjective perceptions of streetscapes using street-view images,"Developing a model to evaluate urban streetscapes based on subjective perceptions is important for quantitative understanding. However, previous studies have only considered limited types of subjective perceptions, neglecting the relationships between them. Further, accurately measuring subjective perception with low computational costs for large-scale urban regions at high spatial resolutions has been difficult. We present a deep-learning-based multilabel classification model that can measure 22 subjective perceptions scores from street-view images. This model uses the results of a web questionnaire survey encompassing 22 subjective perceptions, with 8.8 million responses. Our model demonstrates high accuracy (0.80–0.91) in measuring subjective perception scores from street-view images and achieves low computational cost by training on 22 subjective perception relationships. The 22 subjective perceptions were analyzed using PCA and k-means analysis. By categorizing the 22 subjective perceptions into a two-dimensional space visualized and grouped into distinct groups—positive, negative, calm, and lively—we unearthed vital insights into the intricate nuances of human perception. In addition, the study used semantic segmentation to extract landscape elements from street-view images and applied ℓ1-regularized sparse modeling to identify the landscape elements structurally correlating with each subjective perception class. The analysis revealed that only seven out of nineteen landscape elements significantly correlated with subjective impressions, and these effects varied by class. Notably, sky coverage positively influences positive subjective perceptions, such as attractiveness and calmness, but negatively affects lively impressions. The proposed model can be used to map the overall image of a city and identify landscape design issues in community development design.","<method>deep-learning-based multilabel classification model</method>, <method>PCA</method>, <method>k-means analysis</method>, <method>semantic segmentation</method>, <method>ℓ1-regularized sparse modeling</method>",<method>PCA</method><method>k-means analysis</method><method>semantic segmentation</method><method>ℓ1-regularized sparse modeling</method>
2024,https://openalex.org/W4392812555,Psychology,Artificial intelligence and human translation: A contrastive study based on legal texts,"Artificial intelligence has advanced significantly in recent years, affecting multiple aspects of life. In particular, this has had an impact on the machine translation of texts, reducing or removing human interaction. Artificial intelligence (AI)-based translation software models have thus become widely available, and these now include Google Translate, Bing, Microsoft Translator, DeepL, Reverso, Systran Translate, and Amazon Translate. Several computer-aided translation (CAT) tools such as Memoq, Trados, Smartcat, Lokalise, Smartling, Crowdin, TextUnited, and Memsource are also available. More recently, artificial intelligence has been applied in the development of applications such as ChatGPT, ChatSonic, GPT-3 Playground, Chat GPT 4 and YouChat, which simulate conversational responses to researchers' inquiries, mimicking human interactions more directly. This study thus aimed to examine any remaining contrasts between human and AI translation in the legal field to investigate the potential hypothesis that there is now no difference between human and AI translation. The paper thus also examined concerns about whether the need for human translators will decline in the face of AI development, as well as beginning to assess whether it will ever be possible for those in the legal field to depend only on machine translation. To achieve this, a collection of legal texts from various contracts was chosen, and these pieces were both allocated to legal translators and subjected to AI translation systems. Using a contrastive methodology, the study thus examined the differences between AI and human translation, examining the strengths and weaknesses of both approaches and discussing the situations in which each approach might be most effective.","<method>Artificial intelligence (AI)-based translation software models</method>, <method>ChatGPT</method>, <method>ChatSonic</method>, <method>GPT-3 Playground</method>, <method>Chat GPT 4</method>, <method>YouChat</method>",No methods remaining
2024,https://openalex.org/W4396908686,Psychology,Firefighter Skill Advancement through IoT-Enabled Virtual Reality and CNN-Based Training,"To maintain the safety and efficacy of firefighters in various circumstances, modern firefighting necessitates constantly improving skills and training techniques. Utilizing the Internet of Things (IoT), virtual reality (VR), and convolutional neural networks (CNN), this paper details a novel method for training firefighters. The proposed system collects real-time data on ambient variables, equipment state, and firefighter biometrics via integrating IoT sensors into firefighting equipment and training settings. Using this information, it can develop lifelike VR training simulations of difficult and potentially dangerous scenarios. To make the training settings more realistic and malleable, CNN-based algorithms are used to assess the data. The capacity to simulate a wide variety of firefighting situations, customize training difficulty depending on individual and team performance, and provide instant feedback and performance metrics to trainees are all major benefits of this method. The method also allows teachers to check in and evaluate their learners remotely, improving instruction quality. An IoT-enabled VR and CNN-based training technique has shown promising preliminary results in pilot trials, suggesting it might greatly enhance firefighter competence, situational awareness, and decision-making ability. Because of this, it has the potential to completely alter the way firefighters are informed and prepared for the ever-changing dangers users may encounter on the job.",<method>convolutional neural networks (CNN)</method>,<method>convolutional neural networks (CNN)</method>
2024,https://openalex.org/W4404134492,Psychology,Bias in medical AI: Implications for clinical decision-making,"Biases in medical artificial intelligence (AI) arise and compound throughout the AI lifecycle. These biases can have significant clinical consequences, especially in applications that involve clinical decision-making. Left unaddressed, biased medical AI can lead to substandard clinical decisions and the perpetuation and exacerbation of longstanding healthcare disparities. We discuss potential biases that can arise at different stages in the AI development pipeline and how they can affect AI algorithms and clinical decision-making. Bias can occur in data features and labels, model development and evaluation, deployment, and publication. Insufficient sample sizes for certain patient groups can result in suboptimal performance, algorithm underestimation, and clinically unmeaningful predictions. Missing patient findings can also produce biased model behavior, including capturable but nonrandomly missing data, such as diagnosis codes, and data that is not usually or not easily captured, such as social determinants of health. Expertly annotated labels used to train supervised learning models may reflect implicit cognitive biases or substandard care practices. Overreliance on performance metrics during model development may obscure bias and diminish a model's clinical utility. When applied to data outside the training cohort, model performance can deteriorate from previous validation and can do so differentially across subgroups. How end users interact with deployed solutions can introduce bias. Finally, where models are developed and published, and by whom, impacts the trajectories and priorities of future medical AI development. Solutions to mitigate bias must be implemented with care, which include the collection of large and diverse data sets, statistical debiasing methods, thorough model evaluation, emphasis on model interpretability, and standardized bias reporting and transparency requirements. Prior to real-world implementation in clinical settings, rigorous validation through clinical trials is critical to demonstrate unbiased application. Addressing biases across model development stages is crucial for ensuring all patients benefit equitably from the future of medical AI.","<method>supervised learning</method>, <method>statistical debiasing methods</method>",<method>supervised learning</method><method>statistical debiasing methods</method>
2024,https://openalex.org/W4391753792,Psychology,Flood Detection with SAR: A Review of Techniques and Datasets,"Floods are among the most severe and impacting natural disasters. Their occurrence rate and intensity have been significantly increasing worldwide in the last years due to climate change and urbanization, bringing unprecedented effects on human lives and activities. Hence, providing a prompt response to flooding events is of crucial relevance for humanitarian, social and economic reasons. Satellite remote sensing using synthetic aperture radar (SAR) offers a great deal of support in facing flood events and mitigating their effects on a global scale. As opposed to multi-spectral sensors, SAR offers important advantages, as it enables Earth’s surface imaging regardless of weather and sunlight illumination conditions. In the last decade, the increasing availability of SAR data, even at no cost, thanks to the efforts of international and national space agencies, has been deeply stimulating research activities in every Earth observation field, including flood mapping and monitoring, where advanced processing paradigms, e.g., fuzzy logic, machine learning, data fusion, have been applied, demonstrating their superiority with respect to traditional classification strategies. However, a fair assessment of the performance and reliability of flood mapping techniques is of key importance for an efficient disasters response and, hence, should be addressed carefully and on a quantitative basis trough synthetic quality metrics and high-quality reference data. To this end, the recent development of open SAR datasets specifically covering flood events with related ground-truth reference data can support thorough and objective validation as well as reproducibility of results. Notwithstanding, SAR-based flood monitoring still suffers from severe limitations, especially in vegetated and urban areas, where complex scattering mechanisms can impair an accurate extraction of water regions. All such aspects, including classification methodologies, SAR datasets, validation strategies, challenges and future perspectives for SAR-based flood mapping are described and discussed.","<method>fuzzy logic</method>, <method>machine learning</method>, <method>data fusion</method>",<method>machine learning</method>
2024,https://openalex.org/W4390753190,Psychology,Investigating the impact of motion in the scanner on brain age predictions,"Abstract Brain Age Gap (BAG) is defined as the difference between the brain’s predicted age and the chronological age of an individual. Magnetic resonance imaging (MRI)-based BAG can quantify acceleration of brain aging, and is used to infer brain health as aging and disease interact. Motion in the scanner is a common occurrence that can affect the acquired MRI data and act as a major confound in the derived models. As such, age-related changes in head motion may impact the observed age-related differences. However, the relationship between head motion and BAG as estimated by structural MRI has not been systematically examined. The aim of this study is to assess the impact of motion on voxel-based morphometry (VBM) based BAG. Data were obtained from two sources: i) T1-weighted (T1w) MRIs from the Cambridge Centre for Ageing and Neuroscience (CamCAN) were used to train the brain age prediction model, and ii) T1w MRIs from the Movement-related artifacts (MR-ART) dataset were used to assess the impact of motion on BAG. MR-ART includes one motion-free and two motion-affected (one low and one high) 3D T1w MRIs. We also visually rated the motion levels of the MR-ART MRIs from 0 to 5, with 0 meaning no motion and 5 high motion levels. All images were pre-processed through a standard VBM pipeline. GM density across cortical and subcortical regions were then used to train the brain age prediction model and assess the relationship between BAG and MRI motion. Principal component analysis was used to perform dimension reduction and extract the VBM-based features. BAG was estimated by regressing out the portion of delta age explained by chronological age. Linear mixed-effects models were used to investigate the relationship between BAG and motion session as well as motion severity, including participant IDs as random effects. We repeated the same analysis using cortical thickness based on FreeSurfer 7.4.1 and to compare the results for volumetric versus surface-based measures of brain morphometry. In contrast with the session with no induced motion, predicted delta age was significantly higher for high motion sessions 2.35 years (t = 5.17, p &amp;lt; 0.0001), with marginal effect for low motion sessions 0.95 years (t = 2.11, p = 0.035) for VBM analysis as well as 3.46 years (t = 11.45, p &amp;lt; 0.0001) for high motion and 2.28 years (t = 7.54, p &amp;lt; 0.0001) for low motion based on cortical thickness. In addition, delta age was significantly associated with motion severity as evaluated by visual rating 0.45 years per rating level (t = 4.59, p &amp;lt; 0.0001) for VBM analysis and 0.83 years per motion level (t = 12.89, p &amp;lt; 0.0001) for cortical thickness analysis. Motion in the scanner can significantly impact brain age estimates, and needs to be accounted for as a confound, particularly when studying populations that are known to have higher levels of motion in the scanner. These results have significant implications for brain age studies in aging and neurodegeneration. Based on these findings, we recommend assessment and inclusion of visual motion ratings in such studies. In cases that the visual rating proves prohibitive, we recommend the inclusion of normalized Euler number from FreeSurfer as defined in the manuscript as a covariate in the models.","<method>brain age prediction model</method>, <method>principal component analysis</method>, <method>regression</method>, <method>linear mixed-effects models</method>",<method>principal component analysis</method><method>regression</method>
2024,https://openalex.org/W4390987311,Psychology,Reliability of ChatGPT for performing triage task in the emergency department using the Korean Triage and Acuity Scale,"Background Artificial intelligence (AI) technology can enable more efficient decision-making in healthcare settings. There is a growing interest in improving the speed and accuracy of AI systems in providing responses for given tasks in healthcare settings. Objective This study aimed to assess the reliability of ChatGPT in determining emergency department (ED) triage accuracy using the Korean Triage and Acuity Scale (KTAS). Methods Two hundred and two virtual patient cases were built. The gold standard triage classification for each case was established by an experienced ED physician. Three other human raters (ED paramedics) were involved and rated the virtual cases individually. The virtual cases were also rated by two different versions of the chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0). Inter-rater reliability was examined using Fleiss’ kappa and intra-class correlation coefficient (ICC). Results The kappa values for the agreement between the four human raters and ChatGPTs were .523 (version 4.0) and .320 (version 3.5). Of the five levels, the performance was poor when rating patients at levels 1 and 5, as well as case scenarios with additional text descriptions. There were differences in the accuracy of the different versions of GPTs. The ICC between version 3.5 and the gold standard was .520, and that between version 4.0 and the gold standard was .802. Conclusions A substantial level of inter-rater reliability was revealed when GPTs were used as KTAS raters. The current study showed the potential of using GPT in emergency healthcare settings. Considering the shortage of experienced manpower, this AI method may help improve triaging accuracy.","<method>chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0)</method>","<method>chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0)</method>"
2024,https://openalex.org/W4391061837,Psychology,Approaches and game elements used to tailor digital gamification for learning: A systematic literature review,"The systematic review examined research on tailored digital gamification for learning based on 43 peer-reviewed articles published between 2013 and 2022. The study aimed to investigate tailored approaches and game elements, contributing to the use of tailored digital gamification in educational settings. The tailored approaches were categorized as personalization, adaptation, and recommendation, with user modeling as their basis. Five clusters of game elements were employed when using these tailored approaches in digital gamified classes. The findings imply that most of the articles in this review were still in the stage of class preparation and focused on what information can be used to tailor. More empirical studies need to be conducted to examine the motivating effects of tailored digital gamifying classes, using the approaches of personalization, adaptation, and recommendation. Additionally, twenty-three game elements were found in this review study, among which reward was the most often used. Then these game elements were grouped into five clusters based on their functions, that is, performance, personal, social, ecological, and fictional cluster. A variety of game element clusters reflect multiple aspects of gamification. The use of them in each tailored approach might contribute to a better understanding and selection of game elements when tailoring digital gamification. These findings provide a holistic picture of common approaches and related game elements in tailored digital gamifying classes. Teachers and curriculum designers can benefit from this study by considering appropriate approaches and game elements.","<method>personalization</method>, <method>adaptation</method>, <method>recommendation</method>, <method>user modeling</method>",No methods remaining
2024,https://openalex.org/W4391573023,Psychology,Deep Reinforcement Learning Unleashing the Power of AI in Decision-Making,"Deep Reinforcement Learning (DRL) has emerged as a transformative paradigm in the field of artificial intelligence (AI), offering unprecedented capabilities in decision-making across diverse domains. This article explores the profound impact of DRL on enhancing the decision-making capabilities of AI systems, elucidating its underlying principles, applications, and implications.DRL represents a fusion of deep learning and reinforcement learning, enabling machines to learn complex behaviors and make decisions by interacting with their environment. The utilization of neural networks allows DRL algorithms to handle high-dimensional input spaces, making it well-suited for tasks that involve intricate decision-making processes.One of the key strengths of DRL lies in its ability to address problems with sparse and delayed rewards, common challenges in traditional reinforcement learning. Through a process of trial and error, DRL algorithms can learn optimal decision strategies by navigating through a vast decision space, adapting to dynamic environments, and maximizing cumulative rewards over time.The applications of DRL span various domains, including robotics, finance, healthcare, gaming, and autonomous systems. In robotics, DRL facilitates the development of intelligent agents capable of autonomously navigating complex environments, performing intricate tasks, and adapting to unforeseen circumstances. In finance, DRL is leveraged for portfolio optimization, algorithmic trading, and risk management, demonstrating its potential to revolutionize traditional financial strategies.","<method>Deep Reinforcement Learning (DRL)</method>, <method>deep learning</method>, <method>reinforcement learning</method>",<method>Deep Reinforcement Learning (DRL)</method><method>deep learning</method><method>reinforcement learning</method>
2024,https://openalex.org/W4396712983,Psychology,3WC-GBNRS++: A novel three-way classifier with granular-ball neighborhood rough sets based on uncertainty,"Three-way decision with neighborhood rough sets (3WDNRS) is adept at addressing uncertain problems involving continuous data by configuring the neighborhood radius. However, on one hand, the inputs of 3WDNRS are individual neighborhood granules, which reduce the decision efficiency and generality; on other hand, the thresholds of 3WDNRS require prior knowledge to be approximately set in advance, making it difficult to apply in cases where such knowledge is unavailable. To address these issues, we introduce granular-ball computing (GBC) into 3WDNRS from the perspective of uncertainty. Firstly, we propose an enhanced granular-ball generation method based on DBSCAN called DBGBC. Subsequently, we present an improved granular-ball neighborhood rough sets model (GBNRS++) by combining DBGBC with a quality index. Furthermore, we construct a three-way classifier with granular-ball neighborhood rough sets (3WC-GBNRS++) based on the principle of minimum fuzziness loss. This approach provides an objective and efficient way to determine the thresholds. To further enhance classification accuracy, we design an adaptive granular-ball neighborhood within the subsequent classification process of 3WC-GBNRS++. Finally, experimental results demonstrate that, 3WC-GBNRS++ almost outperformed other comparison methods in terms of effectiveness and robustness, including 4 state-of-the-art granular-balls-based classifiers and 5 classical machine learning classifiers on 12 public benchmark datasets. Moreover, we discuss the limitations of our work and the outlook for future research.","<method>three-way decision with neighborhood rough sets (3WDNRS)</method>, <method>granular-ball computing (GBC)</method>, <method>DBSCAN</method>, <method>granular-ball neighborhood rough sets model (GBNRS++)</method>, <method>three-way classifier with granular-ball neighborhood rough sets (3WC-GBNRS++)</method>, <method>adaptive granular-ball neighborhood</method>",<method>three-way decision with neighborhood rough sets (3WDNRS)</method><method>DBSCAN</method>
2024,https://openalex.org/W4396723505,Psychology,MentaLLaMA: Interpretable Mental Health Analysis on Social Media with Large Language Models,"As an integral part of people's daily lives, social media is becoming a rich source for automatic mental health analysis.As traditional discriminative methods bear poor generalization ability and low interpretability, the recent large language models (LLMs) have been explored for interpretable mental health analysis on social media, which aims to provide detailed explanations along with predictions in zero-shot or few-shot settings.The results show that LLMs still achieve unsatisfactory classification performance in a zero-shot/few-shot manner, which further significantly affects the quality of the generated explanations.Domain-specific finetuning is an effective solution, but faces two critical challenges: 1) lack of high-quality training data.2) no open-source foundation LLMs.To alleviate these problems, we formally model interpretable mental health analysis as a text generation task, and build the first multi-task and multi-source interpretable mental health instruction (IMHI) dataset with 105K data samples to support LLM instruction tuning and evaluation.The raw social media data are collected from 10 existing sources covering 8 mental health analysis tasks.We prompt ChatGPT with expert-designed few-shot prompts to obtain explanations.To ensure the reliability of the explanations, we perform strict automatic and human evaluations on the correctness, consistency, and quality of generated data.Based on the IMHI dataset and LLaMA2 foundation models, we train MentaLLaMA, the first open-source instruction-following LLM series for interpretable mental health analysis on social media.We evaluate Men-taLLaMA and other advanced methods on the IMHI benchmark, the first holistic evaluation benchmark for interpretable mental health analysis.The results show that MentaLLaMA approaches state-of-the-art discriminative methods in correctness and generates human-level explanations.MentaLLaMA models also show strong generalizability to unseen tasks.The project is available at https://github.com/SteveKGYang/MentaLLaMA.","<method>large language models (LLMs)</method>, <method>zero-shot learning</method>, <method>few-shot learning</method>, <method>domain-specific finetuning</method>, <method>instruction tuning</method>, <method>instruction-following large language models</method>",<method>zero-shot learning</method><method>few-shot learning</method><method>domain-specific finetuning</method><method>instruction tuning</method>
2024,https://openalex.org/W4390577959,Psychology,MixFormer: End-to-End Tracking With Iterative Mixed Attention,"Visual object tracking often employs a multi-stage pipeline of feature extraction, target information integration, and bounding box estimation. To simplify this pipeline and unify the process of feature extraction and target information integration, in this paper, we present a compact tracking framework, termed as MixFormer, built upon transformers. Our core design is to utilize the flexibility of attention operations, and we propose a Mixed Attention Module (MAM) for simultaneous feature extraction and target information integration. This synchronous modeling scheme allows us to extract target-specific discriminative features and perform extensive communication between target and search area. Based on MAM, we build our MixFormer trackers simply by stacking multiple MAMs and placing a localization head on top. Specifically, we instantiate two types of MixFormer trackers, a hierarchical tracker MixCvT, and a non-hierarchical simple tracker MixViT. For these two trackers, we investigate a series of pre-training methods and uncover the different behaviors between supervised pre-training and self-supervised pre-training in our MixFormer trackers. We also extend the masked autoencoder pre-training to our MixFormer trackers and design the new competitive TrackMAE pre-training technique. Finally, to handle multiple target templates during online tracking, we devise an asymmetric attention scheme in MAM to reduce computational cost, and propose an effective score prediction module to select high-quality templates. Our MixFormer trackers set a new state-of-the-art performance on seven tracking benchmarks, including LaSOT, TrackingNet, VOT2020, GOT-10 k, OTB100, TOTB and UAV123. In particular, our MixViT-L achieves AUC scores of 73.3% on LaSOT, 86.1% on TrackingNet and 82.8% on TOTB.","<method>transformers</method>, <method>Mixed Attention Module (MAM)</method>, <method>MixFormer trackers</method>, <method>hierarchical tracker MixCvT</method>, <method>non-hierarchical simple tracker MixViT</method>, <method>supervised pre-training</method>, <method>self-supervised pre-training</method>, <method>masked autoencoder pre-training</method>, <method>TrackMAE pre-training technique</method>, <method>asymmetric attention scheme</method>, <method>score prediction module</method>",<method>transformers</method><method>MixFormer trackers</method><method>supervised pre-training</method><method>self-supervised pre-training</method><method>masked autoencoder pre-training</method>
2024,https://openalex.org/W4391429431,Psychology,The impact of chatbots based on large language models on second language vocabulary acquisition,"In recent years, the integration of artificial intelligence (AI) and machine learning (ML) into education, particularly for Personalized Language Learning (PLL), has garnered significant attention. This approach tailors interventions to address the unique challenges faced by individual learners. Large Language Models (LLMs), including Chatbots, have demonstrated a substantial potential in automating and enhancing educational tasks, effectively capturing the complexity and diversity of human language. In this study, 52 foreign language students were randomly divided into two groups: one with the assistance of a Chatbot based on LLMs and one without. Both groups learned the same series of target words over eight weeks. Post-treatment assessments, including systematic observation and quantitative tests assessing both receptive and productive vocabulary knowledge, were conducted immediately after the study and again two weeks later. The findings demonstrate that employing an AI Chatbot based on LLMs significantly aids students in acquiring both receptive and productive vocabulary knowledge during their second language learning journey. Notably, Chatbots contribute to the long-term retention of productive vocabulary and facilitate incidental vocabulary learning. This study offers valuable insights into the practical benefits of LLM-based tools in language learning, with a specific emphasis on vocabulary development. Chatbots utilizing LLMs emerge as effective language learning aids. It emphasizes the importance of educators understanding the potential of these technologies in L2 vocabulary instruction and encourages the adoption of strategic teaching methods incorporating such tools.","<method>Large Language Models (LLMs)</method>, <method>Chatbots based on LLMs</method>",No methods remaining
2024,https://openalex.org/W4392173880,Psychology,Supporting Teachers’ Professional Development With Generative AI: The Effects on Higher Order Thinking and Self-Efficacy,"Generative AI has emerged as a noteworthy milestone and a consequential advancement in the annals of major disciplines within the domains of human science and technology. This study aims to explore the effects of generative AI-assisted pre-service teaching skills training on pre-service teachers' self-efficacy and higher order thinking. The participants of this study were 215 pre-service mathematics, science, and computer teachers from a university in China. Firstly, a pretest-posttest quasi-experimental design was implemented for an experimental group (teaching skills training by generative AI) and a control group (teaching skills training by traditional methods) by investigating the teacher self-efficacy and higher order thinking of the two groups before and after the experiment. Secondly, a semi-structured interview comprising open-ended questions was administered to 25 pre-service teachers within the experimental group to present their views on generative AI-assisted teaching. The results showed that the scores of pre-service teachers in the experimental group, who used generative AI for teachers' professional development, were considerably higher than those of the control group, both in teacher self-efficacy (F = 8.589, p = 0.0084< 0.05) and higher order thinking (F = 7.217, p = 0.008 < 0.05). It revealed that generative AI can be effective in supporting teachers' professional development. This study produced a practical teachers' professional development method for pre-service teachers with generative AI.",<method>generative AI</method>,No methods remaining
2024,https://openalex.org/W4392816828,Psychology,Role of Artificial Intelligence in Higher Education- An Empirical Investigation,"The importance of artificial intelligence (AI) is growing in all economic sectors and thus also in higher education. In recent years, there have been significant developments in this concept of ""Artificial Intelligence in Education (AIED)"". The purpose of this study was to find out how the concept of artificial intelligence can be applied to teaching and learning in higher education and the implications of the use of artificial intelligence in higher education. The impact of the development of technologies on learning is often studied on the methods and scope of learning and teaching. Artificial intelligence enables higher education services to become easily accessible with extraordinary speed, not only in the classroom but also outside the classroom. This report seeks to explore how AI will become an integral part of universities and seeks to examine its immediate and future impact on various aspects of higher education. The challenges of implementing AI in these institutes were also explored. As artificial intelligence (AI) research in education increases, many researchers in the field believe that the role of teachers, schools and leaders in education will change. In this regard, the aim of this study is to investigate which are the possible scenarios for the arrival of artificial intelligence in education and what impact it can have on the future of schools. In this research, it confirmed that artificial intelligence has been widely adopted and used in various forms in education, especially educational institutions. Artificial intelligence was initially implemented in the form of computers and computer-related technologies, moving to web-based and web-based intelligent educational systems, and finally with the use of embedded computing systems and other technologies such as humanoid robots and web-based chatbots teachers &amp; tasks and assignments independently or with tutors. With these platforms, teachers could perform various administrative tasks such as grading and Work more effectively and efficiently and achieve higher quality in your learning activities. On the other hand, because the systems use machine learning and adaptability, the curriculum and content are adapted which improved uptake and retention, which improved the student experience and the overall quality of education.",<method>machine learning</method>,<method>machine learning</method>
2024,https://openalex.org/W4397026358,Psychology,Automated Classification of Cognitive Visual Objects Using Multivariate Swarm Sparse Decomposition From Multichannel EEG-MEG Signals,"In visual object decoding, magnetoencephalogram (MEG) and electroencephalogram (EEG) activation patterns demonstrate the utmost discriminative cognitive analysis due to their multivariate oscillatory nature. However, high noise in the recorded EEG-MEG signals and subject-specific variability make it extremely difficult to classify subject's cognitive responses to different visual stimuli. The proposed method is a multivariate extension of the swarm sparse decomposition method (MSSDM) for multivariate pattern analysis of EEG-MEG-based visual activation signals. In comparison, it is an advanced technique for decomposing nonstationary multicomponent signals into a finite number of channel-aligned oscillatory components that significantly enhance visual activation-related sub-bands. The MSSDM method adopts multivariate swarm filtering and sparse spectrum to automatically deliver optimal frequency bands in channel-specific sparse spectrums, resulting in improved filter banks. By combining the advantages of the multivariate SSDM and Riemann's correlation-assisted fusion feature (RCFF), the MSSDM-RCFF algorithm is investigated to improve the visual object recognition ability of EEG-MEG signals. We have also proposed time–frequency representation based on MSSDM to analyze discriminative cognitive patterns of different visual object classes from multichannel EEG-MEG signals. A proposed MSSDM is evaluated on multivariate synthetic signals and multivariate EEG-MEG signals using five classifiers. The proposed fusion feature and linear discriminant analysis classifier-based framework outperformed all existing state-of-the-art methods used for visual object detection and achieved the highest accuracy of 86.42% using tenfold cross-validation on EEG-MEG multichannel signals.","<method>swarm sparse decomposition method (MSSDM)</method>, <method>multivariate swarm filtering</method>, <method>sparse spectrum</method>, <method>Riemann's correlation-assisted fusion feature (RCFF)</method>, <method>MSSDM-RCFF algorithm</method>, <method>time–frequency representation based on MSSDM</method>, <method>linear discriminant analysis classifier</method>",<method>sparse spectrum</method><method>linear discriminant analysis classifier</method>
2024,https://openalex.org/W4399704837,Psychology,Advanced surveillance and detection systems using deep learning to combat human trafficking,"Human trafficking remains one of the most heinous crimes, often hidden in plain sight, making it a complex challenge for law enforcement worldwide. The integration of deep learning into advanced surveillance and detection systems presents a promising frontier in the fight against this global issue. This review article explores the transformative impact of deep learning algorithms on surveillance technologies designed to detect patterns and anomalies indicative of human trafficking activities. We delve into various case studies where artificial intelligence (AI)-powered surveillance has not only facilitated the identification and rescue of victims but also significantly hindered the operational capabilities of trafficking networks. By analyzing the deployment of these systems in different contexts, this article assesses their effectiveness, the ethical implications of surveillance, the balance between privacy and security, and the future potential for scaling these technologies. Additionally, we explore the collaborative dynamics between AI technology developers and law enforcement agencies, emphasizing the need for a synergistic approach to maximize the impact of these technologies. This review aims to provide a comprehensive understanding of how cutting-edge deep learning applications are becoming crucial tools in the strategic arsenal against human trafficking, offering a beacon of hope for victims and a significant challenge to traffickers.","<method>deep learning algorithms</method>, <method>artificial intelligence (AI)-powered surveillance</method>",No methods remaining
2024,https://openalex.org/W4403619648,Psychology,Enhancing black-box models: Advances in explainable artificial intelligence for ethical decision-making,"Transparency, trust, and accountability are among the issues raised by artificial intelligence's (AI) growing reliance on black-box models, especially in high-stakes industries like healthcare, finance, and criminal justice. These models, which are frequently distinguished by their intricacy and opacity, are capable of producing extremely accurate forecasts, but users and decision-makers are still unable to fully understand how they operate. In response to this challenge, the field of Explainable AI (XAI) has emerged with the goal of demystifying these models by offering insights into their decision-making processes. Our ability to interpret model behavior has greatly improved with recent developments in XAI techniques, such as SHAP (Shapley Additive Explanations), LIME (Local Interpretable Model-agnostic Explanations), and counterfactual explanations. These instruments make it easier to recognize bias, promote trust, and guarantee adherence to moral principles and laws like the GDPR and the AI Act. Modern XAI techniques are reviewed in this research along with how they are used in moral decision-making. It looks at how explainability can improve fairness, reduce the risks of AI bias and discrimination, and assist well-informed decision-making in a variety of industries. It also examines the trade-offs between performance and interpretability of models, as well as the growing trends toward user-centric explainability techniques. In order to ensure responsible AI development and deployment, XAI's role in fostering accountability and transparency will become increasingly important as AI becomes more integrated into critical systems.","<method>SHAP (Shapley Additive Explanations)</method>, <method>LIME (Local Interpretable Model-agnostic Explanations)</method>, <method>counterfactual explanations</method>",<method>SHAP (Shapley Additive Explanations)</method><method>LIME (Local Interpretable Model-agnostic Explanations)</method><method>counterfactual explanations</method>
2024,https://openalex.org/W4390562274,Psychology,Active inference as a theory of sentient behavior,"This review paper offers an overview of the history and future of active inference—a unifying perspective on action and perception. Active inference is based upon the idea that sentient behavior depends upon our brains' implicit use of internal models to predict, infer, and direct action. Our focus is upon the conceptual roots and development of this theory of (basic) sentience and does not follow a rigid chronological narrative. We trace the evolution from Helmholtzian ideas on unconscious inference, through to a contemporary understanding of action and perception. In doing so, we touch upon related perspectives, the neural underpinnings of active inference, and the opportunities for future development. Key steps in this development include the formulation of predictive coding models and related theories of neuronal message passing, the use of sequential models for planning and policy optimization, and the importance of hierarchical (temporally) deep internal (i.e., generative or world) models. Active inference has been used to account for aspects of anatomy and neurophysiology, to offer theories of psychopathology in terms of aberrant precision control, and to unify extant psychological theories. We anticipate further development in all these areas and note the exciting early work applying active inference beyond neuroscience. This suggests a future not just in biology, but in robotics, machine learning, and artificial intelligence.","<method>active inference</method>, <method>predictive coding models</method>, <method>sequential models for planning and policy optimization</method>, <method>hierarchical (temporally) deep internal (generative or world) models</method>",<method>active inference</method><method>predictive coding models</method><method>sequential models for planning and policy optimization</method>
2024,https://openalex.org/W4391345489,Psychology,CLARUS: An interactive explainable AI platform for manual counterfactuals in graph neural networks,"Lack of trust in artificial intelligence (AI) models in medicine is still the key blockage for the use of AI in clinical decision support systems (CDSS). Although AI models are already performing excellently in systems medicine, their black-box nature entails that patient-specific decisions are incomprehensible for the physician. Explainable AI (XAI) algorithms aim to ""explain"" to a human domain expert, which input features influenced a specific recommendation. However, in the clinical domain, these explanations must lead to some degree of causal understanding by a clinician. We developed the CLARUS platform, aiming to promote human understanding of graph neural network (GNN) predictions. CLARUS enables the visualisation of patient-specific networks, as well as, relevance values for genes and interactions, computed by XAI methods, such as GNNExplainer. This enables domain experts to gain deeper insights into the network and more importantly, the expert can interactively alter the patient-specific network based on the acquired understanding and initiate re-prediction or retraining. This interactivity allows us to ask manual counterfactual questions and analyse the effects on the GNN prediction. We present the first interactive XAI platform prototype, CLARUS, that allows not only the evaluation of specific human counterfactual questions based on user-defined alterations of patient networks and a re-prediction of the clinical outcome but also a retraining of the entire GNN after changing the underlying graph structures. The platform is currently hosted by the GWDG on https://rshiny.gwdg.de/apps/clarus/.","<method>graph neural network (GNN)</method>, <method>Explainable AI (XAI) algorithms</method>, <method>GNNExplainer</method>",<method>graph neural network (GNN)</method><method>GNNExplainer</method>
2024,https://openalex.org/W4393157467,Psychology,Visual Adversarial Examples Jailbreak Aligned Large Language Models,"Warning: this paper contains data, prompts, and model outputs that are offensive in nature. Recently, there has been a surge of interest in integrating vision into Large Language Models (LLMs), exemplified by Visual Language Models (VLMs) such as Flamingo and GPT-4. This paper sheds light on the security and safety implications of this trend. First, we underscore that the continuous and high-dimensional nature of the visual input makes it a weak link against adversarial attacks, representing an expanded attack surface of vision-integrated LLMs. Second, we highlight that the versatility of LLMs also presents visual attackers with a wider array of achievable adversarial objectives, extending the implications of security failures beyond mere misclassification. As an illustration, we present a case study in which we exploit visual adversarial examples to circumvent the safety guardrail of aligned LLMs with integrated vision. Intriguingly, we discover that a single visual adversarial example can universally jailbreak an aligned LLM, compelling it to heed a wide range of harmful instructions (that it otherwise would not) and generate harmful content that transcends the narrow scope of a `few-shot' derogatory corpus initially employed to optimize the adversarial example. Our study underscores the escalating adversarial risks associated with the pursuit of multimodality. Our findings also connect the long-studied adversarial vulnerabilities of neural networks to the nascent field of AI alignment. The presented attack suggests a fundamental adversarial challenge for AI alignment, especially in light of the emerging trend toward multimodality in frontier foundation models.","<method>Visual Language Models (VLMs)</method>, <method>Flamingo</method>, <method>GPT-4</method>, <method>visual adversarial examples</method>",<method>Visual Language Models (VLMs)</method><method>Flamingo</method><method>GPT-4</method>
2024,https://openalex.org/W4400134137,Psychology,Computational intelligence-based classification system for the diagnosis of memory impairment in psychoactive substance users,"Abstract Computational intelligence techniques have emerged as a promising approach for diagnosing various medical conditions, including memory impairment. Increased abuse of psychoactive drugs poses a global public health burden, as repeated exposure to these substances can cause neurodegeneration, premature aging, and negatively affect memory impairment. Many studies in the literature relied on statistical studies, but they remained inaccurate. Some studies relied on physical data because the time factor was not considered, until Artificial Intelligence (AI) techniques came along that proved their worth in this diagnosis. The variable deep neural network method was used to adapt to the intermediate results and re-process the intermediate in case the result is undesirable. Computational intelligence was used in this study to classify a brain image from MRI or CT scans and to show the effectiveness of the dose ratio on health with treatment time, and to diagnose memory impairment in users of psychoactive substances. Understanding the neurotoxic profiles of psychoactive substances and the underlying pathways is hypothesized to be of great importance in improving the risk assessment and treatment of substance use disorders. The results proved the worth of the proposed method in terms of the accuracy of recognition rate as well as the possibility of diagnosis. It can be concluded that the diagnostic efficiency is increased by increasing the number of hidden layers in the neural network and controlling the weights and variables that control the deep learning algorithm. Thus, we conclude that good classification in this field may save human life or early detection of memory impairment.","<method>Artificial Intelligence (AI) techniques</method>, <method>variable deep neural network method</method>, <method>computational intelligence</method>, <method>deep learning algorithm</method>",No methods remaining
2024,https://openalex.org/W4400981456,Psychology,Multimodal data integration for oncology in the era of deep neural networks: a review,"Cancer research encompasses data across various scales, modalities, and resolutions, from screening and diagnostic imaging to digitized histopathology slides to various types of molecular data and clinical records. The integration of these diverse data types for personalized cancer care and predictive modeling holds the promise of enhancing the accuracy and reliability of cancer screening, diagnosis, and treatment. Traditional analytical methods, which often focus on isolated or unimodal information, fall short of capturing the complex and heterogeneous nature of cancer data. The advent of deep neural networks has spurred the development of sophisticated multimodal data fusion techniques capable of extracting and synthesizing information from disparate sources. Among these, Graph Neural Networks (GNNs) and Transformers have emerged as powerful tools for multimodal learning, demonstrating significant success. This review presents the foundational principles of multimodal learning including oncology data modalities, taxonomy of multimodal learning, and fusion strategies. We delve into the recent advancements in GNNs and Transformers for the fusion of multimodal data in oncology, spotlighting key studies and their pivotal findings. We discuss the unique challenges of multimodal learning, such as data heterogeneity and integration complexities, alongside the opportunities it presents for a more nuanced and comprehensive understanding of cancer. Finally, we present some of the latest comprehensive multimodal pan-cancer data sources. By surveying the landscape of multimodal data integration in oncology, our goal is to underline the transformative potential of multimodal GNNs and Transformers. Through technological advancements and the methodological innovations presented in this review, we aim to chart a course for future research in this promising field. This review may be the first that highlights the current state of multimodal modeling applications in cancer using GNNs and transformers, presents comprehensive multimodal oncology data sources, and sets the stage for multimodal evolution, encouraging further exploration and development in personalized cancer care.","<method>deep neural networks</method>, <method>Graph Neural Networks (GNNs)</method>, <method>Transformers</method>",<method>deep neural networks</method><method>Graph Neural Networks (GNNs)</method><method>Transformers</method>
2024,https://openalex.org/W4391774550,Psychology,Role of machine learning and deep learning techniques in EEG-based BCI emotion recognition system: a review,"Abstract Emotion is a subjective psychophysiological reaction coming from external stimuli which impacts every aspect of our daily lives. Due to the continuing development of non-invasive and portable sensor technologies, such as brain-computer interfaces (BCI), intellectuals from several fields have been interested in emotion recognition techniques. Human emotions can be recognised using a variety of behavioural cues, including gestures and body language, voice, and physiological markers. The first three, however, might be ineffective because people sometimes conceal their genuine emotions either intentionally or unknowingly. More precise and objective emotion recognition can be accomplished using physiological signals. Among other physiological signals, Electroencephalogram (EEG) is more responsive and sensitive to variation in affective states. Various EEG-based emotion recognition methods have recently been introduced. This study reviews EEG-based BCIs for emotion identification and gives an outline of the progress made in this field. A summary of the datasets and techniques utilised to evoke human emotions and various emotion models is also given. We discuss several EEG feature extractions, feature selection/reduction, machine learning, and deep learning algorithms in accordance with standard emotional identification process. We provide an overview of the human brain's EEG rhythms, which are closely related to emotional states. We also go over a number of EEG-based emotion identification research and compare numerous machine learning and deep learning techniques. In conclusion, this study highlights the applications, challenges and potential areas for future research in identification and classification of human emotional states.","<method>feature extraction</method>, <method>feature selection/reduction</method>, <method>machine learning algorithms</method>, <method>deep learning algorithms</method>",<method>feature selection/reduction</method>
2024,https://openalex.org/W4391811765,Psychology,Usefulness and Accuracy of Artificial Intelligence Chatbot Responses to Patient Questions for Neurosurgical Procedures,"BACKGROUND AND OBJECTIVES: The Internet has become a primary source of health information, leading patients to seek answers online before consulting health care providers. This study aims to evaluate the implementation of Chat Generative Pre-Trained Transformer (ChatGPT) in neurosurgery by assessing the accuracy and helpfulness of artificial intelligence (AI)–generated responses to common postsurgical questions. METHODS: A list of 60 commonly asked questions regarding neurosurgical procedures was developed. ChatGPT-3.0, ChatGPT-3.5, and ChatGPT-4.0 responses to these questions were recorded and graded by numerous practitioners for accuracy and helpfulness. The understandability and actionability of the answers were assessed using the Patient Education Materials Assessment Tool. Readability analysis was conducted using established scales. RESULTS: A total of 1080 responses were evaluated, equally divided among ChatGPT-3.0, 3.5, and 4.0, each contributing 360 responses. The mean helpfulness score across the 3 subsections was 3.511 ± 0.647 while the accuracy score was 4.165 ± 0.567. The Patient Education Materials Assessment Tool analysis revealed that the AI-generated responses had higher actionability scores than understandability. This indicates that the answers provided practical guidance and recommendations that patients could apply effectively. On the other hand, the mean Flesch Reading Ease score was 33.5, suggesting that the readability level of the responses was relatively complex. The Raygor Readability Estimate scores ranged within the graduate level, with an average score of the 15th grade. CONCLUSION: The artificial intelligence chatbot's responses, although factually accurate, were not rated highly beneficial, with only marginal differences in perceived helpfulness and accuracy between ChatGPT-3.0 and ChatGPT-3.5 versions. Despite this, the responses from ChatGPT-4.0 showed a notable improvement in understandability, indicating enhanced readability over earlier versions.","<method>Chat Generative Pre-Trained Transformer (ChatGPT-3.0)</method>, <method>Chat Generative Pre-Trained Transformer (ChatGPT-3.5)</method>, <method>Chat Generative Pre-Trained Transformer (ChatGPT-4.0)</method>",No methods remaining
2024,https://openalex.org/W4393971547,Psychology,A self-attention-based CNN-Bi-LSTM model for accurate state-of-charge estimation of lithium-ion batteries,"In the quest for clean and efficient energy solutions, lithium-ion batteries have emerged at the forefront of technological innovation. Accurate state-of-charge (SOC) estimation across a broad temperature range is essential for extending battery longevity, and enduring effective management of overcharge and over-discharge conditions. However, prevailing challenges persist in achieving precise SOC estimates and generalizing across a wide temperature range, particularly at lower temperatures. Our comparative analysis reveals that, while a single-layer bidirectional LSTM model with a self-attention mechanism achieves remarkable SOC estimation accuracy at room temperature, the intricacies of SOC estimation at lower temperatures necessitate the incorporation of more hidden layers and more complex network architecture to capture intricate features influencing battery dynamics. Hence, we propose a deep learning model, based on convolutional neural networks integrating bidirectional long short-term memory and self-attention mechanism (CNN-Bi-LSTM-AM), specifically designed to tackle the challenges of achieving accurate SOC estimations across a wide temperature range. The proposed model demonstrates proficiency in capturing both spatial and temporal dependencies critical for lithium-ion battery SOC estimation. Furthermore, the integration of a self-attention mechanism enhances the model's adeptness to discern pertinent features and patterns within the dataset, thereby improving its overall performance and robustness, even in sub-room temperature environments.","<method>single-layer bidirectional LSTM model with a self-attention mechanism</method>, <method>deep learning model based on convolutional neural networks integrating bidirectional long short-term memory and self-attention mechanism (CNN-Bi-LSTM-AM)</method>",<method>single-layer bidirectional LSTM model with a self-attention mechanism</method><method>deep learning model based on convolutional neural networks integrating bidirectional long short-term memory and self-attention mechanism (CNN-Bi-LSTM-AM)</method>
2024,https://openalex.org/W4399054302,Psychology,Artificial Intelligence in Point-of-Care Biosensing: Challenges and Opportunities,"The integration of artificial intelligence (AI) into point-of-care (POC) biosensing has the potential to revolutionize diagnostic methodologies by offering rapid, accurate, and accessible health assessment directly at the patient level. This review paper explores the transformative impact of AI technologies on POC biosensing, emphasizing recent computational advancements, ongoing challenges, and future prospects in the field. We provide an overview of core biosensing technologies and their use at the POC, highlighting ongoing issues and challenges that may be solved with AI. We follow with an overview of AI methodologies that can be applied to biosensing, including machine learning algorithms, neural networks, and data processing frameworks that facilitate real-time analytical decision-making. We explore the applications of AI at each stage of the biosensor development process, highlighting the diverse opportunities beyond simple data analysis procedures. We include a thorough analysis of outstanding challenges in the field of AI-assisted biosensing, focusing on the technical and ethical challenges regarding the widespread adoption of these technologies, such as data security, algorithmic bias, and regulatory compliance. Through this review, we aim to emphasize the role of AI in advancing POC biosensing and inform researchers, clinicians, and policymakers about the potential of these technologies in reshaping global healthcare landscapes.","<method>machine learning algorithms</method>, <method>neural networks</method>",<method>neural networks</method>
2024,https://openalex.org/W4399426804,Psychology,Evaluating the persuasive influence of political microtargeting with large language models,"Recent advancements in large language models (LLMs) have raised the prospect of scalable, automated, and fine-grained political microtargeting on a scale previously unseen; however, the persuasive influence of microtargeting with LLMs remains unclear. Here, we build a custom web application capable of integrating self-reported demographic and political data into GPT-4 prompts in real-time, facilitating the live creation of unique messages tailored to persuade individual users on four political issues. We then deploy this application in a preregistered randomized control experiment ( n = 8,587) to investigate the extent to which access to individual-level data increases the persuasive influence of GPT-4. Our approach yields two key findings. First, messages generated by GPT-4 were broadly persuasive, in some cases increasing support for an issue stance by up to 12 percentage points. Second, in aggregate, the persuasive impact of microtargeted messages was not statistically different from that of non-microtargeted messages (4.83 vs. 6.20 percentage points, respectively, P = 0.226). These trends hold even when manipulating the type and number of attributes used to tailor the message. These findings suggest—contrary to widespread speculation—that the influence of current LLMs may reside not in their ability to tailor messages to individuals but rather in the persuasiveness of their generic, nontargeted messages. We release our experimental dataset, GPTarget2024 , as an empirical baseline for future research.",<method>GPT-4</method>,<method>GPT-4</method>
2024,https://openalex.org/W4396832329,Psychology,Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis,"Today's AI systems for medical decision support often succeed on benchmark datasets in research papers but fail in real-world deployment. This work focuses on the decision making of sepsis, an acute life-threatening systematic infection that requires an early diagnosis with high uncertainty from the clinician. Our aim is to explore the design requirements for AI systems that can support clinical experts in making better decisions for the early diagnosis of sepsis. The study begins with a formative study investigating why clinical experts abandon an existing AI-powered Sepsis predictive module in their electrical health record (EHR) system. We argue that a human-centered AI system needs to support human experts in the intermediate stages of a medical decision-making process (e.g., generating hypotheses or gathering data), instead of focusing only on the final decision. Therefore, we build SepsisLab based on a state-of-the-art AI algorithm and extend it to predict the future projection of sepsis development, visualize the prediction uncertainty, and propose actionable suggestions (i.e., which additional laboratory tests can be collected) to reduce such uncertainty. Through heuristic evaluation with six clinicians using our prototype system, we demonstrate that SepsisLab enables a promising human-AI collaboration paradigm for the future of AI-assisted sepsis diagnosis and other high-stakes medical decision making.",<method>state-of-the-art AI algorithm</method>,No methods remaining
2024,https://openalex.org/W4393904218,Psychology,Multilevel analysis of COVID-19 vaccination intention: the moderating role of economic and cultural country characteristics,"Abstract Background Predictors of COVID-19 (coronavirus) vaccination have been extensively researched; however, the contextual factors contributing to understanding vaccination intention remain largely unexplored. The present study aimed to investigate the moderating role of economic development (Gross domestic product - GDP per capita), economic inequality (Gini index), the perceived corruption index and Hofstede’s measurements of cultural values—index of individualism/collectivism and power distance index—in the relationship between determinants of satisfaction with the healthcare system, trust in political institutions, conspiracy beliefs and COVID-19 vaccination intention. Methods A multilevel modelling approach was employed on a sample of approximately 51 000 individuals nested within 26 countries. Data were drawn from the European Social Survey Round 10. The model examined the effect of individual- and country-level predictors and their interaction on vaccination intention. Results Satisfaction with the healthcare system had a stronger positive effect on intention to get vaccinated in countries with lower perceived corruption and more individualistic countries. Trust in political institutions had a stronger positive effect on vaccination intention in countries with higher economic development and lower perceived corruption, while a negative effect of conspiracy beliefs on vaccination intention was stronger in countries with lower economic development, higher perceived corruption and a more collectivistic cultural orientation. Conclusion Our findings highlight the importance of considering individual and contextual factors when addressing vaccination intention.",<method>multilevel modelling</method>,No methods remaining
2024,https://openalex.org/W4390506881,Medicine,Discovering biomarkers associated and predicting cardiovascular disease with high accuracy using a novel nexus of machine learning techniques for precision medicine,"Abstract Personalized interventions are deemed vital given the intricate characteristics, advancement, inherent genetic composition, and diversity of cardiovascular diseases (CVDs). The appropriate utilization of artificial intelligence (AI) and machine learning (ML) methodologies can yield novel understandings of CVDs, enabling improved personalized treatments through predictive analysis and deep phenotyping. In this study, we proposed and employed a novel approach combining traditional statistics and a nexus of cutting-edge AI/ML techniques to identify significant biomarkers for our predictive engine by analyzing the complete transcriptome of CVD patients. After robust gene expression data pre-processing, we utilized three statistical tests (Pearson correlation, Chi-square test, and ANOVA) to assess the differences in transcriptomic expression and clinical characteristics between healthy individuals and CVD patients. Next, the recursive feature elimination classifier assigned rankings to transcriptomic features based on their relation to the case–control variable. The top ten percent of commonly observed significant biomarkers were evaluated using four unique ML classifiers (Random Forest, Support Vector Machine, Xtreme Gradient Boosting Decision Trees, and k-Nearest Neighbors). After optimizing hyperparameters, the ensembled models, which were implemented using a soft voting classifier, accurately differentiated between patients and healthy individuals. We have uncovered 18 transcriptomic biomarkers that are highly significant in the CVD population that were used to predict disease with up to 96% accuracy. Additionally, we cross-validated our results with clinical records collected from patients in our cohort. The identified biomarkers served as potential indicators for early detection of CVDs. With its successful implementation, our newly developed predictive engine provides a valuable framework for identifying patients with CVDs based on their biomarker profiles.","<method>recursive feature elimination classifier</method>, <method>Random Forest</method>, <method>Support Vector Machine</method>, <method>Xtreme Gradient Boosting Decision Trees</method>, <method>k-Nearest Neighbors</method>, <method>soft voting classifier</method>",<method>Random Forest</method><method>Support Vector Machine</method><method>Xtreme Gradient Boosting Decision Trees</method><method>k-Nearest Neighbors</method><method>soft voting classifier</method>
2024,https://openalex.org/W4391292768,Medicine,Improving large language models for clinical named entity recognition via prompt engineering,"Abstract Importance The study highlights the potential of large language models, specifically GPT-3.5 and GPT-4, in processing complex clinical data and extracting meaningful information with minimal training data. By developing and refining prompt-based strategies, we can significantly enhance the models’ performance, making them viable tools for clinical NER tasks and possibly reducing the reliance on extensive annotated datasets. Objectives This study quantifies the capabilities of GPT-3.5 and GPT-4 for clinical named entity recognition (NER) tasks and proposes task-specific prompts to improve their performance. Materials and Methods We evaluated these models on 2 clinical NER tasks: (1) to extract medical problems, treatments, and tests from clinical notes in the MTSamples corpus, following the 2010 i2b2 concept extraction shared task, and (2) to identify nervous system disorder-related adverse events from safety reports in the vaccine adverse event reporting system (VAERS). To improve the GPT models' performance, we developed a clinical task-specific prompt framework that includes (1) baseline prompts with task description and format specification, (2) annotation guideline-based prompts, (3) error analysis-based instructions, and (4) annotated samples for few-shot learning. We assessed each prompt's effectiveness and compared the models to BioClinicalBERT. Results Using baseline prompts, GPT-3.5 and GPT-4 achieved relaxed F1 scores of 0.634, 0.804 for MTSamples and 0.301, 0.593 for VAERS. Additional prompt components consistently improved model performance. When all 4 components were used, GPT-3.5 and GPT-4 achieved relaxed F1 socres of 0.794, 0.861 for MTSamples and 0.676, 0.736 for VAERS, demonstrating the effectiveness of our prompt framework. Although these results trail BioClinicalBERT (F1 of 0.901 for the MTSamples dataset and 0.802 for the VAERS), it is very promising considering few training samples are needed. Discussion The study’s findings suggest a promising direction in leveraging LLMs for clinical NER tasks. However, while the performance of GPT models improved with task-specific prompts, there's a need for further development and refinement. LLMs like GPT-4 show potential in achieving close performance to state-of-the-art models like BioClinicalBERT, but they still require careful prompt engineering and understanding of task-specific knowledge. The study also underscores the importance of evaluation schemas that accurately reflect the capabilities and performance of LLMs in clinical settings. Conclusion While direct application of GPT models to clinical NER tasks falls short of optimal performance, our task-specific prompt framework, incorporating medical knowledge and training samples, significantly enhances GPT models' feasibility for potential clinical applications.","<method>large language models (GPT-3.5)</method>, <method>large language models (GPT-4)</method>, <method>prompt-based strategies</method>, <method>task-specific prompt framework</method>, <method>few-shot learning</method>, <method>BioClinicalBERT</method>",<method>large language models (GPT-3.5)</method><method>large language models (GPT-4)</method><method>prompt-based strategies</method><method>few-shot learning</method><method>BioClinicalBERT</method>
2024,https://openalex.org/W4392754729,Medicine,"Revolutionizing agriculture with artificial intelligence: plant disease detection methods, applications, and their limitations","Accurate and rapid plant disease detection is critical for enhancing long-term agricultural yield. Disease infection poses the most significant challenge in crop production, potentially leading to economic losses. Viruses, fungi, bacteria, and other infectious organisms can affect numerous plant parts, including roots, stems, and leaves. Traditional techniques for plant disease detection are time-consuming, require expertise, and are resource-intensive. Therefore, automated leaf disease diagnosis using artificial intelligence (AI) with Internet of Things (IoT) sensors methodologies are considered for the analysis and detection. This research examines four crop diseases: tomato, chilli, potato, and cucumber. It also highlights the most prevalent diseases and infections in these four types of vegetables, along with their symptoms. This review provides detailed predetermined steps to predict plant diseases using AI. Predetermined steps include image acquisition, preprocessing, segmentation, feature selection, and classification. Machine learning (ML) and deep understanding (DL) detection models are discussed. A comprehensive examination of various existing ML and DL-based studies to detect the disease of the following four crops is discussed, including the datasets used to evaluate these studies. We also provided the list of plant disease detection datasets. Finally, different ML and DL application problems are identified and discussed, along with future research prospects, by combining AI with IoT platforms like smart drones for field-based disease detection and monitoring. This work will help other practitioners in surveying different plant disease detection strategies and the limits of present systems.","<method>artificial intelligence (AI)</method>, <method>machine learning (ML)</method>, <method>deep learning (DL)</method>",<method>machine learning (ML)</method><method>deep learning (DL)</method>
2024,https://openalex.org/W4392791588,Medicine,Can large language models replace humans in systematic reviews? Evaluating <scp>GPT</scp>‐4's efficacy in screening and extracting data from peer‐reviewed and grey literature in multiple languages,"Systematic reviews are vital for guiding practice, research and policy, although they are often slow and labour-intensive. Large language models (LLMs) could speed up and automate systematic reviews, but their performance in such tasks has yet to be comprehensively evaluated against humans, and no study has tested Generative Pre-Trained Transformer (GPT)-4, the biggest LLM so far. This pre-registered study uses a ""human-out-of-the-loop"" approach to evaluate GPT-4's capability in title/abstract screening, full-text review and data extraction across various literature types and languages. Although GPT-4 had accuracy on par with human performance in some tasks, results were skewed by chance agreement and dataset imbalance. Adjusting for these caused performance scores to drop across all stages: for data extraction, performance was moderate, and for screening, it ranged from none in highly balanced literature datasets (~1:1) to moderate in those datasets where the ratio of inclusion to exclusion in studies was imbalanced (~1:3). When screening full-text literature using highly reliable prompts, GPT-4's performance was more robust, reaching ""human-like"" levels. Although our findings indicate that, currently, substantial caution should be exercised if LLMs are being used to conduct systematic reviews, they also offer preliminary evidence that, for certain review tasks delivered under specific conditions, LLMs can rival human performance.","<method>Large language models (LLMs)</method>, <method>Generative Pre-Trained Transformer (GPT)-4</method>",<method>Generative Pre-Trained Transformer (GPT)-4</method>
2024,https://openalex.org/W4395050972,Medicine,Optimization of hepatological clinical guidelines interpretation by large language models: a retrieval augmented generation-based framework,"Abstract Large language models (LLMs) can potentially transform healthcare, particularly in providing the right information to the right provider at the right time in the hospital workflow. This study investigates the integration of LLMs into healthcare, specifically focusing on improving clinical decision support systems (CDSSs) through accurate interpretation of medical guidelines for chronic Hepatitis C Virus infection management. Utilizing OpenAI’s GPT-4 Turbo model, we developed a customized LLM framework that incorporates retrieval augmented generation (RAG) and prompt engineering. Our framework involved guideline conversion into the best-structured format that can be efficiently processed by LLMs to provide the most accurate output. An ablation study was conducted to evaluate the impact of different formatting and learning strategies on the LLM’s answer generation accuracy. The baseline GPT-4 Turbo model’s performance was compared against five experimental setups with increasing levels of complexity: inclusion of in-context guidelines, guideline reformatting, and implementation of few-shot learning. Our primary outcome was the qualitative assessment of accuracy based on expert review, while secondary outcomes included the quantitative measurement of similarity of LLM-generated responses to expert-provided answers using text-similarity scores. The results showed a significant improvement in accuracy from 43 to 99% ( p &lt; 0.001), when guidelines were provided as context in a coherent corpus of text and non-text sources were converted into text. In addition, few-shot learning did not seem to improve overall accuracy. The study highlights that structured guideline reformatting and advanced prompt engineering (data quality vs. data quantity) can enhance the efficacy of LLM integrations to CDSSs for guideline delivery.","<method>Large language models (LLMs)</method>, <method>OpenAI’s GPT-4 Turbo model</method>, <method>retrieval augmented generation (RAG)</method>, <method>prompt engineering</method>, <method>few-shot learning</method>",<method>OpenAI’s GPT-4 Turbo model</method><method>retrieval augmented generation (RAG)</method><method>few-shot learning</method>
2024,https://openalex.org/W4393247259,Medicine,Employing deep learning and transfer learning for accurate brain tumor detection,"Abstract Artificial intelligence-powered deep learning methods are being used to diagnose brain tumors with high accuracy, owing to their ability to process large amounts of data. Magnetic resonance imaging stands as the gold standard for brain tumor diagnosis using machine vision, surpassing computed tomography, ultrasound, and X-ray imaging in its effectiveness. Despite this, brain tumor diagnosis remains a challenging endeavour due to the intricate structure of the brain. This study delves into the potential of deep transfer learning architectures to elevate the accuracy of brain tumor diagnosis. Transfer learning is a machine learning technique that allows us to repurpose pre-trained models on new tasks. This can be particularly useful for medical imaging tasks, where labelled data is often scarce. Four distinct transfer learning architectures were assessed in this study: ResNet152, VGG19, DenseNet169, and MobileNetv3. The models were trained and validated on a dataset from benchmark database: Kaggle. Five-fold cross validation was adopted for training and testing. To enhance the balance of the dataset and improve the performance of the models, image enhancement techniques were applied to the data for the four categories: pituitary, normal, meningioma, and glioma. MobileNetv3 achieved the highest accuracy of 99.75%, significantly outperforming other existing methods. This demonstrates the potential of deep transfer learning architectures to revolutionize the field of brain tumor diagnosis.","<method>deep learning</method>, <method>machine vision</method>, <method>deep transfer learning</method>, <method>transfer learning</method>, <method>ResNet152</method>, <method>VGG19</method>, <method>DenseNet169</method>, <method>MobileNetv3</method>, <method>five-fold cross validation</method>",<method>deep learning</method><method>deep transfer learning</method><method>transfer learning</method><method>ResNet152</method><method>VGG19</method><method>DenseNet169</method><method>MobileNetv3</method>
2024,https://openalex.org/W4391103530,Medicine,Transformative Breast Cancer Diagnosis using CNNs with Optimized ReduceLROnPlateau and Early Stopping Enhancements,"Abstract Breast cancer stands as a paramount public health concern worldwide, underscoring an imperative necessity within the research sphere for precision-driven and efficacious methodologies facilitating accurate detection. The existing diagnostic approaches in breast cancer often suffer from limitations in accuracy and efficiency, leading to delayed detection and subsequent challenges in personalized treatment planning. The primary focus of this research is to overcome these shortcomings by harnessing the power of advanced deep learning techniques, thereby revolutionizing the precision and reliability of breast cancer classification. This research addresses the critical need for improved breast cancer diagnostics by introducing a novel Convolutional Neural Network (CNN) model integrated with an Early Stopping callback and ReduceLROnPlateau callback. By enhancing the precision and reliability of breast cancer classification, the study aims to overcome the limitations of existing diagnostic methods, ultimately leading to better patient outcomes and reduced mortality rates. The comprehensive methodology includes diverse datasets, meticulous image preprocessing, robust model training, and validation strategies, emphasizing the model's adaptability and reliability in varied clinical contexts. The findings showcase the CNN model's exceptional performance, achieving a 95.2% accuracy rate in distinguishing cancerous and non-cancerous breast tissue in the integrated dataset, thereby demonstrating its potential for enhancing clinical decision-making and fostering the development of AI-driven diagnostic solutions.","<method>Convolutional Neural Network (CNN)</method>, <method>Early Stopping callback</method>, <method>ReduceLROnPlateau callback</method>",<method>Convolutional Neural Network (CNN)</method><method>Early Stopping callback</method>
2024,https://openalex.org/W4391528827,Medicine,Deep learning-aided decision support for diagnosis of skin disease across skin tones,"Abstract Although advances in deep learning systems for image-based medical diagnosis demonstrate their potential to augment clinical decision-making, the effectiveness of physician–machine partnerships remains an open question, in part because physicians and algorithms are both susceptible to systematic errors, especially for diagnosis of underrepresented populations. Here we present results from a large-scale digital experiment involving board-certified dermatologists ( n = 389) and primary-care physicians ( n = 459) from 39 countries to evaluate the accuracy of diagnoses submitted by physicians in a store-and-forward teledermatology simulation. In this experiment, physicians were presented with 364 images spanning 46 skin diseases and asked to submit up to four differential diagnoses. Specialists and generalists achieved diagnostic accuracies of 38% and 19%, respectively, but both specialists and generalists were four percentage points less accurate for the diagnosis of images of dark skin as compared to light skin. Fair deep learning system decision support improved the diagnostic accuracy of both specialists and generalists by more than 33%, but exacerbated the gap in the diagnostic accuracy of generalists across skin tones. These results demonstrate that well-designed physician–machine partnerships can enhance the diagnostic accuracy of physicians, illustrating that success in improving overall diagnostic accuracy does not necessarily address bias.",<method>deep learning system decision support</method>,No methods remaining
2024,https://openalex.org/W4402780379,Medicine,Investigating Spatial Effects through Machine Learning and Leveraging Explainable AI for Child Malnutrition in Pakistan,"While socioeconomic gradients in regional health inequalities are firmly established, the synergistic interactions between socioeconomic deprivation and climate vulnerability within convenient proximity and neighbourhood locations with health disparities remain poorly explored and thus require deep understanding within a regional context. Furthermore, disregarding the importance of spatial spillover effects and nonlinear effects of covariates on childhood stunting are inevitable in dealing with an enduring issue of regional health inequalities. The present study aims to investigate the spatial inequalities in childhood stunting at the district level in Pakistan and validate the importance of spatial lag in predicting childhood stunting. Furthermore, it examines the presence of any nonlinear relationships among the selected independent features with childhood stunting. The study utilized data related to socioeconomic features from MICS 2017–2018 and climatic data from Integrated Contextual Analysis. A multi-model approach was employed to address the research questions, which included Ordinary Least Squares Regression (OLS), various Spatial Models, Machine Learning Algorithms and Explainable Artificial Intelligence methods. Firstly, OLS was used to analyse and test the linear relationships among selected variables. Secondly, Spatial Durbin Error Model (SDEM) was used to detect and capture the impact of spatial spillover on childhood stunting. Third, XGBoost and Random Forest machine learning algorithms were employed to examine and validate the importance of the spatial lag component. Finally, EXAI methods such as SHapley were utilized to identify potential nonlinear relationships. The study found a clear pattern of spatial clustering and geographical disparities in childhood stunting, with multidimensional poverty, high climate vulnerability and early marriage worsening childhood stunting. In contrast, low climate vulnerability, high exposure to mass media and high women’s literacy were found to reduce childhood stunting. The use of machine learning algorithms, specifically XGBoost and Random Forest, highlighted the significant role played by the average value in the neighbourhood in predicting childhood stunting in nearby districts, confirming that the spatial spillover effect is not bounded by geographical boundaries. Furthermore, EXAI methods such as partial dependency plot reveal the existence of a nonlinear relationship between multidimensional poverty and childhood stunting. The study’s findings provide valuable insights into the spatial distribution of childhood stunting in Pakistan, emphasizing the importance of considering spatial effects in predicting childhood stunting. Individual and household-level factors such as exposure to mass media and women’s literacy have shown positive implications for childhood stunting. It further provides a justification for the usage of EXAI methods to draw better insights and propose customised intervention policies accordingly.","<method>Ordinary Least Squares Regression (OLS)</method>, <method>Spatial Durbin Error Model (SDEM)</method>, <method>XGBoost</method>, <method>Random Forest</method>, <method>Explainable Artificial Intelligence (EXAI) methods</method>, <method>SHapley</method>, <method>partial dependency plot</method>",<method>XGBoost</method><method>Random Forest</method><method>partial dependency plot</method>
2024,https://openalex.org/W4393119757,Medicine,Unmasking bias in artificial intelligence: a systematic review of bias detection and mitigation strategies in electronic health record-based models,"Abstract Objectives Leveraging artificial intelligence (AI) in conjunction with electronic health records (EHRs) holds transformative potential to improve healthcare. However, addressing bias in AI, which risks worsening healthcare disparities, cannot be overlooked. This study reviews methods to handle various biases in AI models developed using EHR data. Materials and Methods We conducted a systematic review following the Preferred Reporting Items for Systematic Reviews and Meta-analyses guidelines, analyzing articles from PubMed, Web of Science, and IEEE published between January 01, 2010 and December 17, 2023. The review identified key biases, outlined strategies for detecting and mitigating bias throughout the AI model development, and analyzed metrics for bias assessment. Results Of the 450 articles retrieved, 20 met our criteria, revealing 6 major bias types: algorithmic, confounding, implicit, measurement, selection, and temporal. The AI models were primarily developed for predictive tasks, yet none have been deployed in real-world healthcare settings. Five studies concentrated on the detection of implicit and algorithmic biases employing fairness metrics like statistical parity, equal opportunity, and predictive equity. Fifteen studies proposed strategies for mitigating biases, especially targeting implicit and selection biases. These strategies, evaluated through both performance and fairness metrics, predominantly involved data collection and preprocessing techniques like resampling and reweighting. Discussion This review highlights evolving strategies to mitigate bias in EHR-based AI models, emphasizing the urgent need for both standardized and detailed reporting of the methodologies and systematic real-world testing and evaluation. Such measures are essential for gauging models’ practical impact and fostering ethical AI that ensures fairness and equity in healthcare.","<method>resampling</method>, <method>reweighting</method>",<method>resampling</method><method>reweighting</method>
2024,https://openalex.org/W4391235397,Medicine,Real-Time Plant Disease Dataset Development and Detection of Plant Disease Using Deep Learning,"Agriculture plays a significant role in meeting food needs and providing food security for the increasingly growing global population, which has increased by 0.88% since 2022. Plant diseases can reduce food production and affect food security. Worldwide crop loss due to plant disease is estimated to be around 14.1%. The lack of proper identification of plant disease at the early stages of infection can result in inappropriate disease control measures. Therefore, the automatic identification and diagnosis of plant diseases are highly recommended. Lack of availability of large amounts of data that are not processed to a large extent is one of the main challenges in plant disease diagnosis. In the current manuscript, we developed datasets for food grains specifically for rice, wheat, and maize to address the identified challenges. The developed datasets consider the common diseases (two bacterial diseases and two fungal diseases of rice, four fungal diseases of maize, and four fungal diseases of wheat) that affect crop yields and cause damage to the whole plant. The datasets developed were applied to eight fine-tuned deep learning models with the same training hyperparameters. The experimental results based on eight fine-tuned deep learning models show that, while recognizing maize leaf diseases, the models Xception and MobileNet performed best with a testing accuracy of 0.9580 and 0.9464 respectively. Similarly, while recognizing the wheat leaf diseases, the models MobileNetV2 and MobileNet performed best with a testing accuracy of 0.9632 and 0.9628 respectively. The Xception and Inception V3 models performed best, with a testing accuracy of 0.9728 and 0.9620, respectively, for recognizing rice leaf diseases. The research also proposes a new convolutional neural network (CNN) model trained from scratch on all three food grain datasets developed. The proposed model performs well and shows a testing accuracy of 0.9704, 0.9706, and 0.9808 respectively on the maize, rice, and wheat datasets.","<method>fine-tuned deep learning models</method>, <method>Xception</method>, <method>MobileNet</method>, <method>MobileNetV2</method>, <method>Inception V3</method>, <method>convolutional neural network (CNN) model trained from scratch</method>",<method>fine-tuned deep learning models</method><method>Xception</method><method>MobileNet</method><method>MobileNetV2</method><method>Inception V3</method><method>convolutional neural network (CNN) model trained from scratch</method>
2024,https://openalex.org/W4396494945,Medicine,Vision–language foundation model for echocardiogram interpretation,"Abstract The development of robust artificial intelligence models for echocardiography has been limited by the availability of annotated clinical data. Here, to address this challenge and improve the performance of cardiac imaging models, we developed EchoCLIP, a vision–language foundation model for echocardiography, that learns the relationship between cardiac ultrasound images and the interpretations of expert cardiologists across a wide range of patients and indications for imaging. After training on 1,032,975 cardiac ultrasound videos and corresponding expert text, EchoCLIP performs well on a diverse range of benchmarks for cardiac image interpretation, despite not having been explicitly trained for individual interpretation tasks. EchoCLIP can assess cardiac function (mean absolute error of 7.1% when predicting left ventricular ejection fraction in an external validation dataset) and identify implanted intracardiac devices (area under the curve (AUC) of 0.84, 0.92 and 0.97 for pacemakers, percutaneous mitral valve repair and artificial aortic valves, respectively). We also developed a long-context variant (EchoCLIP-R) using a custom tokenizer based on common echocardiography concepts. EchoCLIP-R accurately identified unique patients across multiple videos (AUC of 0.86), identified clinical transitions such as heart transplants (AUC of 0.79) and cardiac surgery (AUC 0.77) and enabled robust image-to-text search (mean cross-modal retrieval rank in the top 1% of candidate text reports). These capabilities represent a substantial step toward understanding and applying foundation models in cardiovascular imaging for preliminary interpretation of echocardiographic findings.","<method>vision–language foundation model</method>, <method>EchoCLIP</method>, <method>long-context variant (EchoCLIP-R)</method>, <method>custom tokenizer</method>",<method>vision–language foundation model</method>
2024,https://openalex.org/W4391320803,Medicine,Oral squamous cell carcinoma detection using EfficientNet on histopathological images,"Introduction Oral Squamous Cell Carcinoma (OSCC) poses a significant challenge in oncology due to the absence of precise diagnostic tools, leading to delays in identifying the condition. Current diagnostic methods for OSCC have limitations in accuracy and efficiency, highlighting the need for more reliable approaches. This study aims to explore the discriminative potential of histopathological images of oral epithelium and OSCC. By utilizing a database containing 1224 images from 230 patients, captured at varying magnifications and publicly available, a customized deep learning model based on EfficientNetB3 was developed. The model’s objective was to differentiate between normal epithelium and OSCC tissues by employing advanced techniques such as data augmentation, regularization, and optimization. Methods The research utilized a histopathological imaging database for Oral Cancer analysis, incorporating 1224 images from 230 patients. These images, taken at various magnifications, formed the basis for training a specialized deep learning model built upon the EfficientNetB3 architecture. The model underwent training to distinguish between normal epithelium and OSCC tissues, employing sophisticated methodologies including data augmentation, regularization techniques, and optimization strategies. Results The customized deep learning model achieved significant success, showcasing a remarkable 99% accuracy when tested on the dataset. This high accuracy underscores the model’s efficacy in effectively discerning between normal epithelium and OSCC tissues. Furthermore, the model exhibited impressive precision, recall, and F1-score metrics, reinforcing its potential as a robust diagnostic tool for OSCC. Discussion This research demonstrates the promising potential of employing deep learning models to address the diagnostic challenges associated with OSCC. The model’s ability to achieve a 99% accuracy rate on the test dataset signifies a considerable leap forward in earlier and more accurate detection of OSCC. Leveraging advanced techniques in machine learning, such as data augmentation and optimization, has shown promising results in improving patient outcomes through timely and precise identification of OSCC.","<method>deep learning model based on EfficientNetB3</method>, <method>data augmentation</method>, <method>regularization</method>, <method>optimization</method>",<method>deep learning model based on EfficientNetB3</method>
2024,https://openalex.org/W4400993192,Medicine,Damage identification of steel bridge based on data augmentation and adaptive optimization neural network,"With the advancement of deep learning, data-driven structural damage identification (SDI) has shown considerable development. However, collecting vibration signals related to structural damage poses certain challenges, which can undermine the accuracy of the identification results produced by data-driven SDI methods in scenarios where data is scarce. This paper introduces an innovative approach to bridge SDI in a few-shot context by integrating an adaptive simulated annealing particle swarm optimization-convolutional neural network (ASAPSO-CNN) as the foundational framework, augmented by data enhancement techniques. Firstly, three specific types of noise are introduced to augment the source signals used for training. Subsequently, the source signals and augmented signals are recombined to construct a four-dimensional matrix as the input to the CNN, while defining the damage feature vector as the output. Secondly, a CNN is constructed to establish the mapping relationship between the input and output. Then, an adaptive fitness function is proposed that simultaneously considers the accuracy of SDI, model complexity, and training efficiency. The ASAPSO is employed to adaptively optimize the hyperparameters of the CNN. The proposed method is validated on an experimental model of a three-span continuous beam. It is compared with four other data-driven methods, demonstrating good effectiveness and robustness of SDI under cases of scarce data. Finally, the effectiveness of this SDI method is validated in a real-world case of a steel truss bridge.","<method>adaptive simulated annealing particle swarm optimization-convolutional neural network (ASAPSO-CNN)</method>, <method>data enhancement techniques</method>, <method>convolutional neural network (CNN)</method>, <method>adaptive simulated annealing particle swarm optimization (ASAPSO)</method>",<method>convolutional neural network (CNN)</method>
2024,https://openalex.org/W4390588437,Medicine,Enhancing heart disease prediction using a self-attention-based transformer model,"Abstract Cardiovascular diseases (CVDs) continue to be the leading cause of more than 17 million mortalities worldwide. The early detection of heart failure with high accuracy is crucial for clinical trials and therapy. Patients will be categorized into various types of heart disease based on characteristics like blood pressure, cholesterol levels, heart rate, and other characteristics. With the use of an automatic system, we can provide early diagnoses for those who are prone to heart failure by analyzing their characteristics. In this work, we deploy a novel self-attention-based transformer model, that combines self-attention mechanisms and transformer networks to predict CVD risk. The self-attention layers capture contextual information and generate representations that effectively model complex patterns in the data. Self-attention mechanisms provide interpretability by giving each component of the input sequence a certain amount of attention weight. This includes adjusting the input and output layers, incorporating more layers, and modifying the attention processes to collect relevant information. This also makes it possible for physicians to comprehend which features of the data contributed to the model's predictions. The proposed model is tested on the Cleveland dataset, a benchmark dataset of the University of California Irvine (UCI) machine learning (ML) repository. Comparing the proposed model to several baseline approaches, we achieved the highest accuracy of 96.51%. Furthermore, the outcomes of our experiments demonstrate that the prediction rate of our model is higher than that of other cutting-edge approaches used for heart disease prediction.","<method>self-attention-based transformer model</method>, <method>self-attention mechanisms</method>, <method>transformer networks</method>",<method>self-attention-based transformer model</method><method>self-attention mechanisms</method><method>transformer networks</method>
2024,https://openalex.org/W4400937555,Medicine,The diagnostic and triage accuracy of the GPT-3 artificial intelligence model: an observational study,"BackgroundArtificial intelligence (AI) applications in health care have been effective in many areas of medicine, but they are often trained for a single task using labelled data, making deployment and generalisability challenging. How well a general-purpose AI language model performs diagnosis and triage relative to physicians and laypeople is not well understood.MethodsWe compared the predictive accuracy of Generative Pre-trained Transformer 3 (GPT-3)'s diagnostic and triage ability for 48 validated synthetic case vignettes (<50 words; sixth-grade reading level or below) of both common (eg, viral illness) and severe (eg, heart attack) conditions to a nationally representative sample of 5000 lay people from the USA who could use the internet to find the correct options and 21 practising physicians at Harvard Medical School. There were 12 vignettes for each of four triage categories: emergent, within one day, within 1 week, and self-care. The correct diagnosis and triage category (ie, ground truth) for each vignette was determined by two general internists at Harvard Medical School. For each vignette, human respondents and GPT-3 were prompted to list diagnoses in order of likelihood, and the vignette was marked as correct if the ground-truth diagnosis was in the top three of the listed diagnoses. For triage accuracy, we examined whether the human respondents' and GPT-3's selected triage was exactly correct according to the four triage categories, or matched a dichotomised triage variable (emergent or within 1 day vs within 1 week or self-care). We estimated GPT-3's diagnostic and triage confidence on a given vignette using a modified bootstrap resampling procedure, and examined how well calibrated GPT-3's confidence was by computing calibration curves and Brier scores. We also performed subgroup analysis by case acuity, and an error analysis for triage advice to characterise how its advice might affect patients using this tool to decide if they should seek medical care immediately.FindingsAmong all cases, GPT-3 replied with the correct diagnosis in its top three for 88% (42/48, 95% CI 75–94) of cases, compared with 54% (2700/5000, 53–55) for lay individuals (p<0.0001) and 96% (637/666, 94–97) for physicians (p=0·012). GPT-3 triaged 70% correct (34/48, 57–82) versus 74% (3706/5000, 73–75; p=0.60) for lay individuals and 91% (608/666, 89–93%; p<0.0001) for physicians. As measured by the Brier score, GPT-3 confidence in its top prediction was reasonably well calibrated for diagnosis (Brier score=0·18) and triage (Brier score=0·22). We observed an inverse relationship between case acuity and GPT-3 accuracy (p<0·0001) with a fitted trend line of –8·33% decrease in accuracy for every level of increase in case acuity. For triage error analysis, GPT-3 deprioritised truly emergent cases in seven instances.InterpretationA general-purpose AI language model without any content-specific training could perform diagnosis at levels close to, but below, physicians and better than lay individuals. We found that GPT-3's performance was inferior to physicians for triage, sometimes by a large margin, and its performance was closer to that of lay individuals. Although the diagnostic performance of GPT-3 was comparable to physicians, it was significantly better than a typical person using a search engine.FundingThe National Heart, Lung, and Blood Institute.","<method>Generative Pre-trained Transformer 3 (GPT-3)</method>, <method>modified bootstrap resampling procedure</method>",<method>Generative Pre-trained Transformer 3 (GPT-3)</method>
2024,https://openalex.org/W4391097427,Medicine,"Quantifying the direct and indirect effects of terrain, climate and human activity on the spatial pattern of kNDVI-based vegetation growth: A case study from the Minjiang River Basin, Southeast China","In the context of global change, it is vital to comprehensively understand the spatial pattern and driving mechanism of vegetation growth to maintain the stability of watershed ecosystems. Previous research has focused mainly on identifying the main drivers of vegetation growth, while the direct and indirect effects of climate, terrain, and human activity on vegetation growth have rarely been explored. This study used the Minjiang River Basin (MRB), an important ecological barrier and the largest watershed in southeastern China, as an example. The kernel normalized difference vegetation index (kNDVI) was calculated on the Google Earth Engine (GEE) platform to examine the spatial pattern and evolution characteristics of vegetation growth. The optimal parameter-based geographical detector (OPGD) and partial least squares structural equation modeling (PLS-SEM) were used to analyze how terrain, climate, and human activity influenced the spatial pattern of the kNDVI. (1) From 2001 to 2020, vegetation growth in the MRB was predominantly rated as excellent or good, and 88.93% of the area showed an increasing trend of vegetation growth. (2) The OPGD revealed that the primary drivers influencing the spatial distribution of the kNDVI in the MRB included population density, nighttime light, elevation and temperature, which explained >40% of the variation in the kNDVI. The interaction of all paired drivers enhanced the explanatory power of the kNDVI, among which the strongest interaction was between population density and elevation, and the second interaction was between population density and temperature. (3) PLS-SEM revealed that human activity had a direct negative effect on the kNDVI, while terrain and climate had direct and indirect positive effects on the kNDVI. Overall, the total effects of terrain, climate and human activity on the kNDVI were 0.594, 0.233 and − 0.495, respectively, indicating that the positive effect of terrain outweighed the negative effect of human activity on vegetation growth in the MRB. These findings not only provide scientific evidence for ecological conservation and management in the MRB but also offer a useful reference for other regions exploring the complex causes of spatial patterns of vegetation growth.","<method>optimal parameter-based geographical detector (OPGD)</method>, <method>partial least squares structural equation modeling (PLS-SEM)</method>",No methods remaining
2024,https://openalex.org/W4392285688,Medicine,Machine Learning and Digital Biomarkers Can Detect Early Stages of Neurodegenerative Diseases,"Neurodegenerative diseases (NDs) such as Alzheimer’s Disease (AD) and Parkinson’s Disease (PD) are devastating conditions that can develop without noticeable symptoms, causing irreversible damage to neurons before any signs become clinically evident. NDs are a major cause of disability and mortality worldwide. Currently, there are no cures or treatments to halt their progression. Therefore, the development of early detection methods is urgently needed to delay neuronal loss as soon as possible. Despite advancements in Medtech, the early diagnosis of NDs remains a challenge at the intersection of medical, IT, and regulatory fields. Thus, this review explores “digital biomarkers” (tools designed for remote neurocognitive data collection and AI analysis) as a potential solution. The review summarizes that recent studies combining AI with digital biomarkers suggest the possibility of identifying pre-symptomatic indicators of NDs. For instance, research utilizing convolutional neural networks for eye tracking has achieved significant diagnostic accuracies. ROC-AUC scores reached up to 0.88, indicating high model performance in differentiating between PD patients and healthy controls. Similarly, advancements in facial expression analysis through tools have demonstrated significant potential in detecting emotional changes in ND patients, with some models reaching an accuracy of 0.89 and a precision of 0.85. This review follows a structured approach to article selection, starting with a comprehensive database search and culminating in a rigorous quality assessment and meaning for NDs of the different methods. The process is visualized in 10 tables with 54 parameters describing different approaches and their consequences for understanding various mechanisms in ND changes. However, these methods also face challenges related to data accuracy and privacy concerns. To address these issues, this review proposes strategies that emphasize the need for rigorous validation and rapid integration into clinical practice. Such integration could transform ND diagnostics, making early detection tools more cost-effective and globally accessible. In conclusion, this review underscores the urgent need to incorporate validated digital health tools into mainstream medical practice. This integration could indicate a new era in the early diagnosis of neurodegenerative diseases, potentially altering the trajectory of these conditions for millions worldwide. Thus, by highlighting specific and statistically significant findings, this review demonstrates the current progress in this field and the potential impact of these advancements on the global management of NDs.",<method>convolutional neural networks</method>,<method>convolutional neural networks</method>
2024,https://openalex.org/W4393167823,Medicine,Risk analysis and assessment of water resource carrying capacity based on weighted gray model with improved entropy weighting method in the central plains region of China,"The issue of global water shortage is a serious concern. The scientific evaluation of water resource carrying capacity (WRCC) serves as the foundation for implementing measures to protect water resources. In addition, most of the studies are based on the analysis and research of regional WRCC from the aspects of water quantity and water quality. There are few studies on the four aspects of water resources endowment conditions, society, economy and ecological environment, which is difficult to scientifically and accurately reflect the analysis and evaluation of regional WRCC by the four systems. Therefore, it is necessary to conduct a deeper discussion and Analysis on this topic. This study presents a WRCC index system and corresponding ranking criteria based on 20 influencing factors from four aspects: water resources endowment (WRE), economy, society, and ecological environment. In addition, by combining the improved entropy weighting method (EWM) with gray correlation analysis, the weighted gray technique for order preference by similarity to an ideal solution (TOPSIS) model is proposed for analyzing and assessing WRCC risk. Finally, the WRCC of the study area from 2012 to 2021 is comprehensively evaluated in the central plains region of China (CPROC) as an example. The results show that the comprehensive evaluation obtained a multi-year average value of 0.2935, and the water resources shortage in the CPROC is generally in grade III status. The comprehensive average value of Beijing is 0.345, and the comprehensive average value of Henan is 0.397. The overall degree of water resources shortage is in the state of grade V shortage, Shaanxi is in the state of grade IV shortage, and the degree of water resources in Tianjin and Shanxi is relatively good. This study provides corresponding scientific basis and methodological guidance for the sustainable utilization of water resources and healthy socio-economic performance in the CPROC.","<method>improved entropy weighting method (EWM)</method>, <method>gray correlation analysis</method>, <method>weighted gray technique for order preference by similarity to an ideal solution (TOPSIS) model</method>",No methods remaining
2024,https://openalex.org/W4402757343,Medicine,"Global prevalence, trend and projection of myopia in children and adolescents from 1990 to 2050: a comprehensive systematic review and meta-analysis","Background Myopia is a pervasive global public health concern, particularly among the younger population. However, the escalating prevalence of myopia remains uncertain. Hence, our research aims to ascertain the global and regional prevalence of myopia, along with its occurrence within specific demographic groups. Methods An exhaustive literature search was performed on several databases covering the period from their inception to 27 June 2023. The global prevalence of myopia was determined by employing pooled estimates with a 95% CI, and further analysis was conducted to assess variations in prevalence estimates across different subgroups. Additionally, a time series model was utilised to forecast and fit accurately the future prevalence of myopia for the next three decades. Results This study encompasses a comprehensive analysis of 276 studies, involving a total of 5 410 945 participants from 50 countries across all six continents. The findings revealed a gradual increase in pooled prevalence of myopia, ranging from 24.32% (95% CI 15.23% to 33.40%) to 35.81% (95% CI 31.70% to 39.91%), observed from 1990 to 2023, and projections indicate that this prevalence is expected to reach 36.59% in 2040 and 39.80% in 2050. Notably, individuals residing in East Asia (35.22%) or in urban areas (28.55%), female gender (33.57%), adolescents (47.00%), and high school students (45.71%) exhibit a higher proportion of myopia prevalence. Conclusion The global prevalence of childhood myopia is substantial, affecting approximately one-third of children and adolescents, with notable variations in prevalence across different demographic groups. It is anticipated that the global incidence of myopia will exceed 740 million cases by 2050.",<method>time series model</method>,No methods remaining
2024,https://openalex.org/W4390607226,Medicine,RanMerFormer: Randomized vision transformer with token merging for brain tumor classification,"Brains are the control center of the nervous system in human bodies, and brain tumor is one of the most deadly diseases. Currently, magnetic resonance imaging (MRI) is the most effective way to brain tumors early detection in clinical diagnoses due to its superior imaging quality for soft tissues. Manual analysis of brain MRI is error-prone which depends on empirical experience and the fatigue state of the radiologists to a large extent. Computer-aided diagnosis (CAD) systems are becoming more and more impactful because they can provide accurate prediction results based on medical images with advanced techniques from computer vision. Therefore, a novel CAD method for brain tumor classification named RanMerFormer is presented in this paper. A pre-trained vision transformer is used as the backbone model. Then, a merging mechanism is proposed to remove the redundant tokens in the vision transformer, which improves computing efficiency substantially. Finally, a randomized vector functional-link serves as the head in the proposed RanMerFormer, which can be trained swiftly. All the simulation results are obtained from two public benchmark datasets, which reveal that the proposed RanMerFormer can achieve state-of-the-art performance for brain tumor classification. The trained RanMerFormer can be applied in real-world scenarios to assist in brain tumor diagnosis.","<method>vision transformer</method>, <method>randomized vector functional-link</method>",<method>vision transformer</method><method>randomized vector functional-link</method>
2024,https://openalex.org/W4391023920,Medicine,A hybrid deep CNN model for brain tumor image multi-classification,"Abstract The current approach to diagnosing and classifying brain tumors relies on the histological evaluation of biopsy samples, which is invasive, time-consuming, and susceptible to manual errors. These limitations underscore the pressing need for a fully automated, deep-learning-based multi-classification system for brain malignancies. This article aims to leverage a deep convolutional neural network (CNN) to enhance early detection and presents three distinct CNN models designed for different types of classification tasks. The first CNN model achieves an impressive detection accuracy of 99.53% for brain tumors. The second CNN model, with an accuracy of 93.81%, proficiently categorizes brain tumors into five distinct types: normal, glioma, meningioma, pituitary, and metastatic. Furthermore, the third CNN model demonstrates an accuracy of 98.56% in accurately classifying brain tumors into their different grades. To ensure optimal performance, a grid search optimization approach is employed to automatically fine-tune all the relevant hyperparameters of the CNN models. The utilization of large, publicly accessible clinical datasets results in robust and reliable classification outcomes. This article conducts a comprehensive comparison of the proposed models against classical models, such as AlexNet, DenseNet121, ResNet-101, VGG-19, and GoogleNet, reaffirming the superiority of the deep CNN-based approach in advancing the field of brain tumor classification and early detection.","<method>deep convolutional neural network (CNN)</method>, <method>grid search optimization</method>, <method>AlexNet</method>, <method>DenseNet121</method>, <method>ResNet-101</method>, <method>VGG-19</method>, <method>GoogleNet</method>",<method>deep convolutional neural network (CNN)</method><method>AlexNet</method><method>DenseNet121</method><method>ResNet-101</method><method>VGG-19</method><method>GoogleNet</method>
2024,https://openalex.org/W4390706643,Medicine,Present and Future Innovations in AI and Cardiac MRI,"Cardiac MRI is used to diagnose and treat patients with a multitude of cardiovascular diseases. Despite the growth of clinical cardiac MRI, complicated image prescriptions and long acquisition protocols limit the specialty and restrain its impact on the practice of medicine. Artificial intelligence (AI)-the ability to mimic human intelligence in learning and performing tasks-will impact nearly all aspects of MRI. Deep learning (DL) primarily uses an artificial neural network to learn a specific task from example data sets. Self-driving scanners are increasingly available, where AI automatically controls cardiac image prescriptions. These scanners offer faster image collection with higher spatial and temporal resolution, eliminating the need for cardiac triggering or breath holding. In the future, fully automated inline image analysis will most likely provide all contour drawings and initial measurements to the reader. Advanced analysis using radiomic or DL features may provide new insights and information not typically extracted in the current analysis workflow. AI may further help integrate these features with clinical, genetic, wearable-device, and ""omics"" data to improve patient outcomes. This article presents an overview of AI and its application in cardiac MRI, including in image acquisition, reconstruction, and processing, and opportunities for more personalized cardiovascular care through extraction of novel imaging markers.","<method>Artificial intelligence (AI)</method>, <method>Deep learning (DL)</method>, <method>artificial neural network</method>, <method>radiomic features</method>, <method>DL features</method>",<method>Deep learning (DL)</method><method>artificial neural network</method>
2024,https://openalex.org/W4391508432,Medicine,Artificial intelligence-driven virtual rehabilitation for people living in the community: A scoping review,"Abstract Virtual Rehabilitation (VRehab) is a promising approach to improving the physical and mental functioning of patients living in the community. The use of VRehab technology results in the generation of multi-modal datasets collected through various devices. This presents opportunities for the development of Artificial Intelligence (AI) techniques in VRehab, namely the measurement, detection, and prediction of various patients’ health outcomes. The objective of this scoping review was to explore the applications and effectiveness of incorporating AI into home-based VRehab programs. PubMed/MEDLINE, Embase, IEEE Xplore, Web of Science databases, and Google Scholar were searched from inception until June 2023 for studies that applied AI for the delivery of VRehab programs to the homes of adult patients. After screening 2172 unique titles and abstracts and 51 full-text studies, 13 studies were included in the review. A variety of AI algorithms were applied to analyze data collected from various sensors and make inferences about patients’ health outcomes, most involving evaluating patients’ exercise quality and providing feedback to patients. The AI algorithms used in the studies were mostly fuzzy rule-based methods, template matching, and deep neural networks. Despite the growing body of literature on the use of AI in VRehab, very few studies have examined its use in patients’ homes. Current research suggests that integrating AI with home-based VRehab can lead to improved rehabilitation outcomes for patients. However, further research is required to fully assess the effectiveness of various forms of AI-driven home-based VRehab, taking into account its unique challenges and using standardized metrics.","<method>fuzzy rule-based methods</method>, <method>template matching</method>, <method>deep neural networks</method>",<method>fuzzy rule-based methods</method><method>deep neural networks</method>
2024,https://openalex.org/W4395037579,Medicine,Assessing ChatGPT 4.0’s test performance and clinical diagnostic accuracy on USMLE STEP 2 CK and clinical case reports,"Abstract While there is data assessing the test performance of artificial intelligence (AI) chatbots, including the Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0), there is scarce data on its diagnostic accuracy of clinical cases. We assessed the large language model (LLM), ChatGPT 4.0, on its ability to answer questions from the United States Medical Licensing Exam (USMLE) Step 2, as well as its ability to generate a differential diagnosis based on corresponding clinical vignettes from published case reports. A total of 109 Step 2 Clinical Knowledge (CK) practice questions were inputted into both ChatGPT 3.5 and ChatGPT 4.0, asking ChatGPT to pick the correct answer. Compared to its previous version, ChatGPT 3.5, we found improved accuracy of ChatGPT 4.0 when answering these questions, from 47.7 to 87.2% ( p = 0.035) respectively. Utilizing the topics tested on Step 2 CK questions, we additionally found 63 corresponding published case report vignettes and asked ChatGPT 4.0 to come up with its top three differential diagnosis. ChatGPT 4.0 accurately created a shortlist of differential diagnoses in 74.6% of the 63 case reports (74.6%). We analyzed ChatGPT 4.0’s confidence in its diagnosis by asking it to rank its top three differentials from most to least likely. Out of the 47 correct diagnoses, 33 were the first (70.2%) on the differential diagnosis list, 11 were second (23.4%), and three were third (6.4%). Our study shows the continued iterative improvement in ChatGPT’s ability to answer standardized USMLE questions accurately and provides insights into ChatGPT’s clinical diagnostic accuracy.","<method>Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0)</method>, <method>ChatGPT 3.5</method>, <method>large language model (LLM)</method>",<method>Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0)</method><method>large language model (LLM)</method>
2024,https://openalex.org/W4402521185,Medicine,Advanced Ensemble Machine Learning Techniques for Optimizing Diabetes Mellitus Prognostication: A Detailed Examination of Hospital Data,"Diabetes is a chronic disease that affects millions of people worldwide. Early diagnosis and effective management are crucial for reducing its complications. Diabetes is the fourth-highest cause of mortality due to its association with various comorbidities, including heart disease, nerve damage, blood vessel damage, and blindness. The potential of machine learning algorithms in predicting Diabetes and related conditions is significant, and mining diabetes data is an efficient method for extracting new insights.The primary objective of this study is to develop an enhanced ensemble model to predict Diabetes with improved accuracy by leveraging various machine learning algorithms.This study tested several popular machine learning algorithms commonly used in diabetes prediction, including Naive Bayes (NB), Generalized Linear Model (GLM), Logistic Regression (LR), Fast Large Margin (FLM), Deep Learning (DL), Decision Tree (DT), Random Forest (RF), Gradient Boosted Trees (GBT), and Support Vector Machine (SVM). The performance of these algorithms was compared, and two different ensemble techniques—stacking and voting—were used to build a more accurate predictive model.The top three algorithms based on accuracy were Deep Learning, Naive Bayes, and Gradient Boosted Trees. The machine learning algorithms revealed that individuals with Diabetes are significantly affected by the number of chronic conditions they have, as well as their gender and age. The ensemble models, particularly the stacking method, provided higher accuracy than individual algorithms. The stacking ensemble model achieved a slightly better accuracy of 99.94% compared to 99.34% for the voting method.Building an ensemble model significantly increased the accuracy of predicting Diabetes and related conditions. The stacking ensemble model, in particular, demonstrated superior performance, highlighting the importance of combining multiple machine learning approaches to enhance predictive accuracy","<method>Naive Bayes (NB)</method>, <method>Generalized Linear Model (GLM)</method>, <method>Logistic Regression (LR)</method>, <method>Fast Large Margin (FLM)</method>, <method>Deep Learning (DL)</method>, <method>Decision Tree (DT)</method>, <method>Random Forest (RF)</method>, <method>Gradient Boosted Trees (GBT)</method>, <method>Support Vector Machine (SVM)</method>, <method>stacking ensemble</method>, <method>voting ensemble</method>",<method>Naive Bayes (NB)</method><method>Logistic Regression (LR)</method><method>Deep Learning (DL)</method><method>Decision Tree (DT)</method><method>Random Forest (RF)</method><method>Gradient Boosted Trees (GBT)</method><method>Support Vector Machine (SVM)</method><method>stacking ensemble</method><method>voting ensemble</method>
2024,https://openalex.org/W4390987311,Medicine,Reliability of ChatGPT for performing triage task in the emergency department using the Korean Triage and Acuity Scale,"Background Artificial intelligence (AI) technology can enable more efficient decision-making in healthcare settings. There is a growing interest in improving the speed and accuracy of AI systems in providing responses for given tasks in healthcare settings. Objective This study aimed to assess the reliability of ChatGPT in determining emergency department (ED) triage accuracy using the Korean Triage and Acuity Scale (KTAS). Methods Two hundred and two virtual patient cases were built. The gold standard triage classification for each case was established by an experienced ED physician. Three other human raters (ED paramedics) were involved and rated the virtual cases individually. The virtual cases were also rated by two different versions of the chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0). Inter-rater reliability was examined using Fleiss’ kappa and intra-class correlation coefficient (ICC). Results The kappa values for the agreement between the four human raters and ChatGPTs were .523 (version 4.0) and .320 (version 3.5). Of the five levels, the performance was poor when rating patients at levels 1 and 5, as well as case scenarios with additional text descriptions. There were differences in the accuracy of the different versions of GPTs. The ICC between version 3.5 and the gold standard was .520, and that between version 4.0 and the gold standard was .802. Conclusions A substantial level of inter-rater reliability was revealed when GPTs were used as KTAS raters. The current study showed the potential of using GPT in emergency healthcare settings. Considering the shortage of experienced manpower, this AI method may help improve triaging accuracy.","<method>chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0)</method>","<method>chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0)</method>"
2024,https://openalex.org/W4391145465,Medicine,Assessing generalisability of deep learning-based polyp detection and segmentation methods through a computer vision challenge,"Abstract Polyps are well-known cancer precursors identified by colonoscopy. However, variability in their size, appearance, and location makes the detection of polyps challenging. Moreover, colonoscopy surveillance and removal of polyps are highly operator-dependent procedures and occur in a highly complex organ topology. There exists a high missed detection rate and incomplete removal of colonic polyps. To assist in clinical procedures and reduce missed rates, automated methods for detecting and segmenting polyps using machine learning have been achieved in past years. However, the major drawback in most of these methods is their ability to generalise to out-of-sample unseen datasets from different centres, populations, modalities, and acquisition systems. To test this hypothesis rigorously, we, together with expert gastroenterologists, curated a multi-centre and multi-population dataset acquired from six different colonoscopy systems and challenged the computational expert teams to develop robust automated detection and segmentation methods in a crowd-sourcing Endoscopic computer vision challenge. This work put forward rigorous generalisability tests and assesses the usability of devised deep learning methods in dynamic and actual clinical colonoscopy procedures. We analyse the results of four top performing teams for the detection task and five top performing teams for the segmentation task. Our analyses demonstrate that the top-ranking teams concentrated mainly on accuracy over the real-time performance required for clinical applicability. We further dissect the devised methods and provide an experiment-based hypothesis that reveals the need for improved generalisability to tackle diversity present in multi-centre datasets and routine clinical procedures.","<method>machine learning</method>, <method>deep learning</method>",<method>machine learning</method><method>deep learning</method>
2024,https://openalex.org/W4391878291,Medicine,Effective lung nodule detection using deep CNN with dual attention mechanisms,"Abstract Novel methods are required to enhance lung cancer detection, which has overtaken other cancer-related causes of death as the major cause of cancer-related mortality. Radiologists have long-standing methods for locating lung nodules in patients with lung cancer, such as computed tomography (CT) scans. Radiologists must manually review a significant amount of CT scan pictures, which makes the process time-consuming and prone to human error. Computer-aided diagnosis (CAD) systems have been created to help radiologists with their evaluations in order to overcome these difficulties. These systems make use of cutting-edge deep learning architectures. These CAD systems are designed to improve lung nodule diagnosis efficiency and accuracy. In this study, a bespoke convolutional neural network (CNN) with a dual attention mechanism was created, which was especially crafted to concentrate on the most important elements in images of lung nodules. The CNN model extracts informative features from the images, while the attention module incorporates both channel attention and spatial attention mechanisms to selectively highlight significant features. After the attention module, global average pooling is applied to summarize the spatial information. To evaluate the performance of the proposed model, extensive experiments were conducted using benchmark dataset of lung nodules. The results of these experiments demonstrated that our model surpasses recent models and achieves state-of-the-art accuracy in lung nodule detection and classification tasks.","<method>convolutional neural network (CNN)</method>, <method>dual attention mechanism</method>, <method>channel attention</method>, <method>spatial attention</method>, <method>global average pooling</method>",<method>convolutional neural network (CNN)</method><method>dual attention mechanism</method><method>channel attention</method><method>spatial attention</method><method>global average pooling</method>
2024,https://openalex.org/W4392004069,Medicine,A precise model for skin cancer diagnosis using hybrid U-Net and improved MobileNet-V3 with hyperparameters optimization,"Abstract Skin cancer is a frequently occurring and possibly deadly disease that necessitates prompt and precise diagnosis in order to ensure efficacious treatment. This paper introduces an innovative approach for accurately identifying skin cancer by utilizing Convolution Neural Network architecture and optimizing hyperparameters. The proposed approach aims to increase the precision and efficacy of skin cancer recognition and consequently enhance patients' experiences. This investigation aims to tackle various significant challenges in skin cancer recognition, encompassing feature extraction, model architecture design, and optimizing hyperparameters. The proposed model utilizes advanced deep-learning methodologies to extract complex features and patterns from skin cancer images. We enhance the learning procedure of deep learning by integrating Standard U-Net and Improved MobileNet-V3 with optimization techniques, allowing the model to differentiate malignant and benign skin cancers. Also substituted the crossed-entropy loss function of the Mobilenet-v3 mathematical framework with a bias loss function to enhance the accuracy. The model's squeeze and excitation component was replaced with the practical channel attention component to achieve parameter reduction. Integrating cross-layer connections among Mobile modules has been proposed to leverage synthetic features effectively. The dilated convolutions were incorporated into the model to enhance the receptive field. The optimization of hyperparameters is of utmost importance in improving the efficiency of deep learning models. To fine-tune the model's hyperparameter, we employ sophisticated optimization methods such as the Bayesian optimization method using pre-trained CNN architecture MobileNet-V3. The proposed model is compared with existing models, i.e., MobileNet, VGG-16, MobileNet-V2, Resnet-152v2 and VGG-19 on the “HAM-10000 Melanoma Skin Cancer dataset"". The empirical findings illustrate that the proposed optimized hybrid MobileNet-V3 model outperforms existing skin cancer detection and segmentation techniques based on high precision of 97.84%, sensitivity of 96.35%, accuracy of 98.86% and specificity of 97.32%. The enhanced performance of this research resulted in timelier and more precise diagnoses, potentially contributing to life-saving outcomes and mitigating healthcare expenditures.","<method>Convolution Neural Network</method>, <method>deep-learning methodologies</method>, <method>Standard U-Net</method>, <method>Improved MobileNet-V3</method>, <method>bias loss function</method>, <method>practical channel attention component</method>, <method>cross-layer connections among Mobile modules</method>, <method>dilated convolutions</method>, <method>Bayesian optimization method</method>, <method>pre-trained CNN architecture MobileNet-V3</method>",<method>Standard U-Net</method><method>Improved MobileNet-V3</method><method>dilated convolutions</method><method>Bayesian optimization method</method><method>pre-trained CNN architecture MobileNet-V3</method>
2024,https://openalex.org/W4391718168,Medicine,A comparative study of explainable ensemble learning and logistic regression for predicting in-hospital mortality in the emergency department,"Abstract This study addresses the challenges associated with emergency department (ED) overcrowding and emphasizes the need for efficient risk stratification tools to identify high-risk patients for early intervention. While several scoring systems, often based on logistic regression (LR) models, have been proposed to indicate patient illness severity, this study aims to compare the predictive performance of ensemble learning (EL) models with LR for in-hospital mortality in the ED. A cross-sectional single-center study was conducted at the ED of Imam Reza Hospital in northeast Iran from March 2016 to March 2017. The study included adult patients with one to three levels of emergency severity index. EL models using Bagging, AdaBoost, random forests (RF), Stacking and extreme gradient boosting (XGB) algorithms, along with an LR model, were constructed. The training and validation visits from the ED were randomly divided into 80% and 20%, respectively. After training the proposed models using tenfold cross-validation, their predictive performance was evaluated. Model performance was compared using the Brier score (BS), The area under the receiver operating characteristics curve (AUROC), The area and precision–recall curve (AUCPR), Hosmer–Lemeshow (H–L) goodness-of-fit test, precision, sensitivity, accuracy, F1-score, and Matthews correlation coefficient (MCC). The study included 2025 unique patients admitted to the hospital’s ED, with a total percentage of hospital deaths at approximately 19%. In the training group and the validation group, 274 of 1476 (18.6%) and 152 of 728 (20.8%) patients died during hospitalization, respectively. According to the evaluation of the presented framework, EL models, particularly Bagging, predicted in-hospital mortality with the highest AUROC (0.839, CI (0.802–0.875)) and AUCPR = 0.64 comparable in terms of discrimination power with LR (AUROC (0.826, CI (0.787–0.864)) and AUCPR = 0.61). XGB achieved the highest precision (0.83), sensitivity (0.831), accuracy (0.842), F1-score (0.833), and the highest MCC (0.48). Additionally, the most accurate models in the unbalanced dataset belonged to RF with the lowest BS (0.128). Although all studied models overestimate mortality risk and have insufficient calibration ( P &gt; 0.05), stacking demonstrated relatively good agreement between predicted and actual mortality. EL models are not superior to LR in predicting in-hospital mortality in the ED. Both EL and LR models can be considered as screening tools to identify patients at risk of mortality.","<method>logistic regression (LR)</method>, <method>ensemble learning (EL)</method>, <method>Bagging</method>, <method>AdaBoost</method>, <method>random forests (RF)</method>, <method>Stacking</method>, <method>extreme gradient boosting (XGB)</method>",<method>logistic regression (LR)</method><method>ensemble learning (EL)</method><method>Bagging</method><method>AdaBoost</method><method>random forests (RF)</method><method>Stacking</method><method>extreme gradient boosting (XGB)</method>
2024,https://openalex.org/W4400981456,Medicine,Multimodal data integration for oncology in the era of deep neural networks: a review,"Cancer research encompasses data across various scales, modalities, and resolutions, from screening and diagnostic imaging to digitized histopathology slides to various types of molecular data and clinical records. The integration of these diverse data types for personalized cancer care and predictive modeling holds the promise of enhancing the accuracy and reliability of cancer screening, diagnosis, and treatment. Traditional analytical methods, which often focus on isolated or unimodal information, fall short of capturing the complex and heterogeneous nature of cancer data. The advent of deep neural networks has spurred the development of sophisticated multimodal data fusion techniques capable of extracting and synthesizing information from disparate sources. Among these, Graph Neural Networks (GNNs) and Transformers have emerged as powerful tools for multimodal learning, demonstrating significant success. This review presents the foundational principles of multimodal learning including oncology data modalities, taxonomy of multimodal learning, and fusion strategies. We delve into the recent advancements in GNNs and Transformers for the fusion of multimodal data in oncology, spotlighting key studies and their pivotal findings. We discuss the unique challenges of multimodal learning, such as data heterogeneity and integration complexities, alongside the opportunities it presents for a more nuanced and comprehensive understanding of cancer. Finally, we present some of the latest comprehensive multimodal pan-cancer data sources. By surveying the landscape of multimodal data integration in oncology, our goal is to underline the transformative potential of multimodal GNNs and Transformers. Through technological advancements and the methodological innovations presented in this review, we aim to chart a course for future research in this promising field. This review may be the first that highlights the current state of multimodal modeling applications in cancer using GNNs and transformers, presents comprehensive multimodal oncology data sources, and sets the stage for multimodal evolution, encouraging further exploration and development in personalized cancer care.","<method>deep neural networks</method>, <method>Graph Neural Networks (GNNs)</method>, <method>Transformers</method>",<method>deep neural networks</method><method>Graph Neural Networks (GNNs)</method><method>Transformers</method>
2024,https://openalex.org/W4390708138,Medicine,Accuracy of GPT-4 in histopathological image detection and classification of colorectal adenomas,"Aims To evaluate the accuracy of Chat Generative Pre-trained Transformer (ChatGPT) powered by GPT-4 in histopathological image detection and classification of colorectal adenomas using the diagnostic consensus provided by pathologists as a reference standard. Methods A study was conducted with 100 colorectal polyp photomicrographs, comprising an equal number of adenomas and non-adenomas, classified by two pathologists. These images were analysed by classic GPT-4 for 1 time in October 2023 and custom GPT-4 for 20 times in December 2023. GPT-4’s responses were compared against the reference standard through statistical measures to evaluate its proficiency in histopathological diagnosis, with the pathologists further assessing the model’s descriptive accuracy. Results GPT-4 demonstrated a median sensitivity of 74% and specificity of 36% for adenoma detection. The median accuracy of polyp classification varied, ranging from 16% for non-specific changes to 36% for tubular adenomas. Its diagnostic consistency, indicated by low kappa values ranging from 0.06 to 0.11, suggested only poor to slight agreement. All of the microscopic descriptions corresponded with their diagnoses. GPT-4 also commented about the limitations in its diagnoses (eg, slide diagnosis best done by pathologists, the inadequacy of single-image diagnostic conclusions, the need for clinical data and a higher magnification view). Conclusions GPT-4 showed high sensitivity but low specificity in detecting adenomas and varied accuracy for polyp classification. However, its diagnostic consistency was low. This artificial intelligence tool acknowledged its diagnostic limitations, emphasising the need for a pathologist’s expertise and additional clinical context.","<method>Chat Generative Pre-trained Transformer (ChatGPT) powered by GPT-4</method>, <method>classic GPT-4</method>, <method>custom GPT-4</method>",<method>Chat Generative Pre-trained Transformer (ChatGPT) powered by GPT-4</method>
2024,https://openalex.org/W4390870882,Medicine,A domain adaptation approach to damage classification with an application to bridge monitoring,"Data-driven machine-learning algorithms generally suffer from a lack of labelled health-state data, mainly those referring to damage conditions. To address such an issue, population-based structural health monitoring seeks to enrich the original dataset by transferring knowledge from a population of monitored structures. Within this context, this paper presents a transfer learning approach, based on domain adaptation, to leverage information from completely-labelled bridge structure data to accurately predict new instances of an unknown target domain. Since intrinsic structural differences may cause distribution shifts, domain adaptation attempts to minimise the distance between the domains and to learn a mapping within a shared feature space. Specifically, the methodology involves the long-term acquisition of natural frequencies from several structural scenarios. Such damage-sensitive features are then aligned via domain adaptation so that a machine-learning algorithm can effectively utilise the labelled source domain data and generalise well to the unlabelled target-domain data. The described procedure is applied to two case studies, including the Z24 and the S101 benchmark bridges and their finite element models, respectively. The results demonstrate the successful exchange of health-state labels to identify the damage class within a population of bridges equipped with SHM systems, showing potential to reduce computational efforts and to deal with scarce or poor data sets in application to bridge network monitoring.","<method>transfer learning</method>, <method>domain adaptation</method>, <method>machine-learning algorithm</method>",<method>transfer learning</method><method>domain adaptation</method>
2024,https://openalex.org/W4392200867,Medicine,Revolutionizing core muscle analysis in female sexual dysfunction based on machine learning,"Abstract The purpose of this study is to investigate the role of core muscles in female sexual dysfunction (FSD) and develop comprehensive rehabilitation programs to address this issue. We aim to answer the following research questions: what are the roles of core muscles in FSD, and how can machine and deep learning models accurately predict changes in core muscles during FSD? FSD is a common condition that affects women of all ages, characterized by symptoms such as decreased libido, difficulty achieving orgasm, and pain during intercourse. We conducted a comprehensive analysis of changes in core muscles during FSD using machine and deep learning. We evaluated the performance of multiple models, including multi-layer perceptron (MLP), long short-term memory (LSTM), convolutional neural network (CNN), recurrent neural network (RNN), ElasticNetCV, random forest regressor, SVR, and Bagging regressor. The models were evaluated based on mean squared error (MSE), mean absolute error (MAE), and R-squared (R 2 ) score. Our results show that CNN and random forest regressor are the most accurate models for predicting changes in core muscles during FSD. CNN achieved the lowest MSE (0.002) and the highest R 2 score (0.988), while random forest regressor also performed well with an MSE of 0.0021 and an R 2 score of 0.9905. Our study demonstrates that machine and deep learning models can accurately predict changes in core muscles during FSD. The neglected core muscles play a significant role in FSD, highlighting the need for comprehensive rehabilitation programs that address these muscles. By developing these programs, we can improve the quality of life for women with FSD and help them achieve optimal sexual health.","<method>multi-layer perceptron (MLP)</method>, <method>long short-term memory (LSTM)</method>, <method>convolutional neural network (CNN)</method>, <method>recurrent neural network (RNN)</method>, <method>ElasticNetCV</method>, <method>random forest regressor</method>, <method>SVR</method>, <method>Bagging regressor</method>",<method>multi-layer perceptron (MLP)</method><method>long short-term memory (LSTM)</method><method>convolutional neural network (CNN)</method><method>recurrent neural network (RNN)</method><method>ElasticNetCV</method><method>random forest regressor</method><method>SVR</method><method>Bagging regressor</method>
2024,https://openalex.org/W4392356867,Medicine,The SAFE procedure: a practical stopping heuristic for active learning-based screening in systematic reviews and meta-analyses,"Abstract Active learning has become an increasingly popular method for screening large amounts of data in systematic reviews and meta-analyses. The active learning process continually improves its predictions on the remaining unlabeled records, with the goal of identifying all relevant records as early as possible. However, determining the optimal point at which to stop the active learning process is a challenge. The cost of additional labeling of records by the reviewer must be balanced against the cost of erroneous exclusions. This paper introduces the SAFE procedure, a practical and conservative set of stopping heuristics that offers a clear guideline for determining when to end the active learning process in screening software like ASReview. The eclectic mix of stopping heuristics helps to minimize the risk of missing relevant papers in the screening process. The proposed stopping heuristic balances the costs of continued screening with the risk of missing relevant records, providing a practical solution for reviewers to make informed decisions on when to stop screening. Although active learning can significantly enhance the quality and efficiency of screening, this method may be more applicable to certain types of datasets and problems. Ultimately, the decision to stop the active learning process depends on careful consideration of the trade-off between the costs of additional record labeling against the potential errors of the current model for the specific dataset and context.",<method>active learning</method>,<method>active learning</method>
2024,https://openalex.org/W4403545332,Medicine,Evaluating AI and Machine Learning Models in Breast Cancer Detection: A Review of Convolutional Neural Networks (CNN) and Global Research Trends,"Numerous studies have highlighted the significance of artificial intelligence (AI) in breast cancer diagnosis. However, systematic reviews of AI applications in this field often lack cohesion, with each study adopting a unique approach. The aim of this study is to provide a detailed examination of AI's role in breast cancer diagnosis through citation analysis, helping to categorize the key areas that attract academic attention. It also includes a thematic analysis to identify the specific research topics within each category. A total of 30,200 studies related to breast cancer and AI, published between 2015 and 2024, were sourced from databases such as IEEE, Scopus, PubMed, Springer, and Google Scholar. After applying inclusion and exclusion criteria, 32 relevant studies were identified. Most of these studies utilized classification models for breast cancer prediction, with high accuracy being the most commonly reported performance metric. Convolutional Neural Networks (CNN) emerged as the preferred model in many studies. The findings indicate that both the quantity and quality of AI-based algorithms in breast cancer diagnosis are increases in the given years. AI is increasingly seen as a complement to healthcare sector and clinical expertise, with the target of enhancing the accessibility and affordability of quality healthcare worldwide.","<method>classification models</method>, <method>Convolutional Neural Networks (CNN)</method>",<method>Convolutional Neural Networks (CNN)</method>
2024,https://openalex.org/W4390777660,Medicine,Unlocking the Potential of XAI for Improved Alzheimer’s Disease Detection and Classification Using a ViT-GRU Model,"Alzheimer's Disease (AD) is a significant cause of dementia worldwide, and its progression from mild to severe affects an individual's ability to perform daily activities independently. The accurate and early diagnosis of AD is crucial for effective clinical intervention. However, interpreting AD from medical images can be challenging, even for experienced radiologists. Therefore, there is a need for an automatic diagnosis of AD, and researchers have investigated the potential of utilizing Artificial Intelligence (AI) techniques, particularly deep learning models, to address this challenge. This study proposes a framework that combines a Vision Transformer (ViT) and a Gated Recurrent Unit (GRU) to detect AD characteristics from Magnetic Resonance Imaging (MRI) images accurately and reliably. The ViT identifies crucial features from the input image, and the GRU establishes clear correlations between these features. The proposed model overcomes the class imbalance issue in the MRI image dataset and achieves superior accuracy and performance compared to existing methods. The model was trained on the Alzheimer's MRI Preprocessed Dataset obtained from Kaggle, achieving notable accuracies of 99.53% for 4-class and 99.69% for binary classification. It also demonstrated a high accuracy of 99.26% for 3-class on the AD Neuroimaging Initiative (ADNI) Baseline Database. These results were validated through a thorough 10-fold cross-validation process. Furthermore, Explainable AI (XAI) techniques were incorporated to make the model interpretable and explainable. This allows clinicians to understand the model's decision-making process and gain insights into the underlying factors driving the AD diagnosis.","<method>Vision Transformer (ViT)</method>, <method>Gated Recurrent Unit (GRU)</method>, <method>Explainable AI (XAI) techniques</method>",<method>Vision Transformer (ViT)</method><method>Gated Recurrent Unit (GRU)</method>
2024,https://openalex.org/W4391166899,Medicine,"Prediction of atmospheric PM2.5 level by machine learning techniques in Isfahan, Iran","Abstract With increasing levels of air pollution, air quality prediction has attracted more attention. Mathematical models are being developed by researchers to achieve precise predictions. Monitoring and prediction of atmospheric PM 2.5 levels, as a predominant pollutant, is essential in emission mitigation programs. In this study, meteorological datasets from 9 years in Isfahan city, a large metropolis of Iran, were applied to predict the PM 2.5 levels, using four machine learning algorithms including Artificial Neural |Networks (ANNs), K-Nearest-Neighbors (KNN), Support Vector |Machines (SVMs) and ensembles of classification trees Random Forest (RF). The data from 7 air quality monitoring stations located in Isfahan City were taken into consideration. The Confusion Matrix and Cross-Entropy Loss were used to analyze the performance of classification models. Several parameters, including sensitivity, specificity, accuracy, F1 score, precision, and the area under the curve (AUC), are computed to assess model performance. Finally, by introducing the predicted data for 2020 into ArcGIS software and using the IDW (Inverse Distance Weighting) method, interpolation was conducted for the area of Isfahan city and the pollution map was illustrated for each month of the year. The results showed that, based on the accuracy percentage, the ANN model has a better performance (90.1%) in predicting PM 2.5 grades compared to the other models for the applied meteorological dataset, followed by RF (86.1%), SVM (84.6%) and KNN (82.2%) models, respectively. Therefore, ANN modelling provides a feasible procedure for the managerial planning of air pollution control.","<method>Artificial Neural Networks (ANNs)</method>, <method>K-Nearest-Neighbors (KNN)</method>, <method>Support Vector Machines (SVMs)</method>, <method>Random Forest (RF)</method>",<method>Artificial Neural Networks (ANNs)</method><method>K-Nearest-Neighbors (KNN)</method><method>Support Vector Machines (SVMs)</method><method>Random Forest (RF)</method>
2024,https://openalex.org/W4391751277,Medicine,Digital health technologies and machine learning augment patient reported outcomes to remotely characterise rheumatoid arthritis,"Digital measures of health status captured during daily life could greatly augment current in-clinic assessments for rheumatoid arthritis (RA), to enable better assessment of disease progression and impact. This work presents results from weaRAble-PRO, a 14-day observational study, which aimed to investigate how digital health technologies (DHT), such as smartphones and wearables, could augment patient reported outcomes (PRO) to determine RA status and severity in a study of 30 moderate-to-severe RA patients, compared to 30 matched healthy controls (HC). Sensor-based measures of health status, mobility, dexterity, fatigue, and other RA specific symptoms were extracted from daily iPhone guided tests (GT), as well as actigraphy and heart rate sensor data, which was passively recorded from patients' Apple smartwatch continuously over the study duration. We subsequently developed a machine learning (ML) framework to distinguish RA status and to estimate RA severity. It was found that daily wearable sensor-outcomes robustly distinguished RA from HC participants (F1, 0.807). Furthermore, by day 7 of the study (half-way), a sufficient volume of data had been collected to reliably capture the characteristics of RA participants. In addition, we observed that the detection of RA severity levels could be improved by augmenting standard patient reported outcomes with sensor-based features (F1, 0.833) in comparison to using PRO assessments alone (F1, 0.759), and that the combination of modalities could reliability measure continuous RA severity, as determined by the clinician-assessed RAPID-3 score at baseline (r",<method>machine learning (ML) framework</method>,No methods remaining
2024,https://openalex.org/W4391810207,Medicine,Machine Learning–Based Prediction of Suicidality in Adolescents With Allergic Rhinitis: Derivation and Validation in 2 Independent Nationwide Cohorts,"Background Given the additional risk of suicide-related behaviors in adolescents with allergic rhinitis (AR), it is important to use the growing field of machine learning (ML) to evaluate this risk. Objective This study aims to evaluate the validity and usefulness of an ML model for predicting suicide risk in patients with AR. Methods We used data from 2 independent survey studies, Korea Youth Risk Behavior Web-based Survey (KYRBS; n=299,468) for the original data set and Korea National Health and Nutrition Examination Survey (KNHANES; n=833) for the external validation data set, to predict suicide risks of AR in adolescents aged 13 to 18 years, with 3.45% (10,341/299,468) and 1.4% (12/833) of the patients attempting suicide in the KYRBS and KNHANES studies, respectively. The outcome of interest was the suicide attempt risks. We selected various ML-based models with hyperparameter tuning in the discovery and performed an area under the receiver operating characteristic curve (AUROC) analysis in the train, test, and external validation data. Results The study data set included 299,468 (KYRBS; original data set) and 833 (KNHANES; external validation data set) patients with AR recruited between 2005 and 2022. The best-performing ML model was the random forest model with a mean AUROC of 84.12% (95% CI 83.98%-84.27%) in the original data set. Applying this result to the external validation data set revealed the best performance among the models, with an AUROC of 89.87% (sensitivity 83.33%, specificity 82.58%, accuracy 82.59%, and balanced accuracy 82.96%). While looking at feature importance, the 5 most important features in predicting suicide attempts in adolescent patients with AR are depression, stress status, academic achievement, age, and alcohol consumption. Conclusions This study emphasizes the potential of ML models in predicting suicide risks in patients with AR, encouraging further application of these models in other conditions to enhance adolescent health and decrease suicide rates.",<method>random forest</method>,<method>random forest</method>
2024,https://openalex.org/W4392450360,Medicine,Geographically weighted machine learning for modeling spatial heterogeneity in traffic crash frequency and determinants in US,"Spatial analyses of traffic crashes have drawn much interest due to the nature of the spatial dependence and spatial heterogeneity in the crash data. This study makes the best of Geographically Weighted Random Forest (GW-RF) model to explore the local associations between crash frequency and various influencing factors in the US, including road network attributes, socio-economic characteristics, and land use factors collected from multiple data sources. Special emphasis is put on modeling the spatial heterogeneity in the effects of a factor on crash frequency in different geographical areas in a data-driven way. The GW-RF model outperforms global models (e.g. Random Forest) and conventional geographically weighted regression, demonstrating superior predictive accuracy and elucidating spatial variations. The GW-RF model reveals spatial distinctions in the effects of certain factors on crash frequency. For example, the importance of intersection density varies significantly across regions, with high significance in the southern and northeastern areas. Low-grade road density emerges as influential in specific cities. The findings highlight the significance of different factors in influencing crash frequency across zones. Road network factors, particularly intersection density, exhibit high importance universally, while socioeconomic variables demonstrate moderate effects. Interestingly, land use variables show relatively lower importance. The outcomes could help to allocate resources and implement tailored interventions to reduce the likelihood of crashes.","<method>Geographically Weighted Random Forest (GW-RF)</method>, <method>Random Forest</method>, <method>geographically weighted regression</method>",<method>Geographically Weighted Random Forest (GW-RF)</method><method>Random Forest</method>
2024,https://openalex.org/W4393405326,Medicine,"Developing Deep LSTMs With Later Temporal Attention for Predicting COVID-19 Severity, Clinical Outcome, and Antibody Level by Screening Serological Indicators Over Time","Objective: The clinical course of COVID-19, as well as the immunological reaction, is notable for its extreme variability. Identifying the main associated factors might help understand the disease progression and physiological status of COVID-19 patients. The dynamic changes of the antibody against Spike protein are crucial for understanding the immune response. This work explores a temporal attention (TA) mechanism of deep learning to predict COVID-19 disease severity, clinical outcomes, and Spike antibody levels by screening serological indicators over time. Methods: We use feature selection techniques to filter feature subsets that are highly correlated with the target. The specific deep Long Short-Term Memory (LSTM) models are employed to capture the dynamic changes of disease severity, clinical outcome, and Spike antibody level. We also propose deep LSTMs with a TA mechanism to emphasize the later blood test records because later records often attract more attention from doctors. Results: Risk factors highly correlated with COVID-19 are revealed. LSTM achieves the highest classification accuracy for disease severity prediction. Temporal Attention Long Short-Term Memory (TA-LSTM) achieves the best performance for clinical outcome prediction. For Spike antibody level prediction, LSTM achieves the best permanence. Conclusion: The experimental results demonstrate the effectiveness of the proposed models. The proposed models can provide a computer-aided medical diagnostics system by simply using time series of serological indicators.","<method>feature selection techniques</method>, <method>deep Long Short-Term Memory (LSTM) models</method>, <method>deep LSTMs with a temporal attention (TA) mechanism</method>, <method>Temporal Attention Long Short-Term Memory (TA-LSTM)</method>",<method>deep Long Short-Term Memory (LSTM) models</method><method>deep LSTMs with a temporal attention (TA) mechanism</method><method>Temporal Attention Long Short-Term Memory (TA-LSTM)</method>
2024,https://openalex.org/W4401537518,Medicine,A New Brain Network Construction Paradigm for Brain Disorder via Diffusion-Based Graph Contrastive Learning,"Brain network analysis plays an increasingly important role in studying brain function and the exploring of disease mechanisms. However, existing brain network construction tools have some limitations, including dependency on empirical users, weak consistency in repeated experiments and time-consuming processes. In this work, a diffusion-based brain network pipeline, DGCL is designed for end-to-end construction of brain networks. Initially, the brain region-aware module (BRAM) precisely determines the spatial locations of brain regions by the diffusion process, avoiding subjective parameter selection. Subsequently, DGCL employs graph contrastive learning to optimize brain connections by eliminating individual differences in redundant connections unrelated to diseases, thereby enhancing the consistency of brain networks within the same group. Finally, the node-graph contrastive loss and classification loss jointly constrain the learning process of the model to obtain the reconstructed brain network, which is then used to analyze important brain connections. Validation on two datasets, ADNI and ABIDE, demonstrates that DGCL surpasses traditional methods and other deep learning models in predicting disease development stages. Significantly, the proposed model improves the efficiency and generalization of brain network construction. In summary, the proposed DGCL can be served as a universal brain network construction scheme, which can effectively identify important brain connections through generative paradigms and has the potential to provide disease interpretability support for neuroscience research.","<method>diffusion process</method>, <method>graph contrastive learning</method>, <method>node-graph contrastive loss</method>, <method>classification loss</method>",<method>diffusion process</method><method>graph contrastive learning</method>
2024,https://openalex.org/W4390819402,Medicine,Development and Validation of a Machine Learning Model to Predict Weekly Risk of Hypoglycemia in Patients with Type 1 Diabetes Based on Continuous Glucose Monitoring,"Aim: The aim of this study was to develop and validate a prediction model based on CGM data to identify a week-to-week risk profile of excessive hypoglycemia. Methods: We analyzed, trained, and internally tested two prediction models using CGM data from 205 type 1 diabetes patients with long-term CGM monitoring. A binary classification approach (XGBoost) combined with feature engineering deployed on the CGM signals was utilized to predict excessive hypoglycemia risk defined by two targets (TBR > 4% and the upper TBR 90th percentile limit) of time below range (TBR) the following week. The models were validated in two independent cohorts with a total of 253 additional patients. Results: A total of 61,470 weeks of CGM data were included in the analysis. The XGBoost models had a ROC-AUC of 0.83-0.87 (95% confidence interval [CI]; 0.83-0.88) in the test dataset. The external validation showed ROC-AUCs of 0.81-0.90. The most discriminative features included the low blood glucose index (LBGI), the glycemic risk assessment diabetes equation (GRADE), hypoglycemia, the TBR, waveform length, the CV and mean glucose during the previous week. This highlights that the pattern of hypoglycemia combined with glucose variability during the past week contains information on the risk of future hypoglycemia. Conclusion: Prediction models based on real-world CGM data can be used to predict the risk of hypoglycemia in the forthcoming week. The models showed good performance in both the internal and external validation cohorts.",<method>XGBoost</method>,<method>XGBoost</method>
2024,https://openalex.org/W4391243967,Medicine,Reviews and syntheses: Remotely sensed optical time series for monitoring vegetation productivity,"Abstract. Vegetation productivity is a critical indicator of global ecosystem health and is impacted by human activities and climate change. A wide range of optical sensing platforms, from ground-based to airborne and satellite, provide spatially continuous information on terrestrial vegetation status and functioning. As optical Earth observation (EO) data are usually routinely acquired, vegetation can be monitored repeatedly over time, reflecting seasonal vegetation patterns and trends in vegetation productivity metrics. Such metrics include gross primary productivity, net primary productivity, biomass, or yield. To summarize current knowledge, in this paper we systematically reviewed time series (TS) literature for assessing state-of-the-art vegetation productivity monitoring approaches for different ecosystems based on optical remote sensing (RS) data. As the integration of solar-induced fluorescence (SIF) data in vegetation productivity processing chains has emerged as a promising source, we also include this relatively recent sensor modality. We define three methodological categories to derive productivity metrics from remotely sensed TS of vegetation indices or quantitative traits: (i) trend analysis and anomaly detection, (ii) land surface phenology, and (iii) integration and assimilation of TS-derived metrics into statistical and process-based dynamic vegetation models (DVMs). Although the majority of used TS data streams originate from data acquired from satellite platforms, TS data from aircraft and unoccupied aerial vehicles have found their way into productivity monitoring studies. To facilitate processing, we provide a list of common toolboxes for inferring productivity metrics and information from TS data. We further discuss validation strategies of the RS data derived productivity metrics: (1) using in situ measured data, such as yield; (2) sensor networks of distinct sensors, including spectroradiometers, flux towers, or phenological cameras; and (3) inter-comparison of different productivity metrics. Finally, we address current challenges and propose a conceptual framework for productivity metrics derivation, including fully integrated DVMs and radiative transfer models here labelled as “Digital Twin”. This novel framework meets the requirements of multiple ecosystems and enables both an improved understanding of vegetation temporal dynamics in response to climate and environmental drivers and enhances the accuracy of vegetation productivity monitoring.","<method>trend analysis and anomaly detection</method>, <method>land surface phenology</method>, <method>integration and assimilation of time series-derived metrics into statistical and process-based dynamic vegetation models (DVMs)</method>, <method>fully integrated dynamic vegetation models (DVMs) and radiative transfer models (“Digital Twin” framework)</method>",No methods remaining
2024,https://openalex.org/W4391437034,Medicine,A methodical exploration of imaging modalities from dataset to detection through machine learning paradigms in prominent lung disease diagnosis: a review,"Abstract Background Lung diseases, both infectious and non-infectious, are the most prevalent cause of mortality overall in the world. Medical research has identified pneumonia, lung cancer, and Corona Virus Disease 2019 (COVID-19) as prominent lung diseases prioritized over others. Imaging modalities, including X-rays, computer tomography (CT) scans, magnetic resonance imaging (MRIs), positron emission tomography (PET) scans, and others, are primarily employed in medical assessments because they provide computed data that can be utilized as input datasets for computer-assisted diagnostic systems. Imaging datasets are used to develop and evaluate machine learning (ML) methods to analyze and predict prominent lung diseases. Objective This review analyzes ML paradigms, imaging modalities' utilization, and recent developments for prominent lung diseases. Furthermore, the research also explores various datasets available publically that are being used for prominent lung diseases. Methods The well-known databases of academic studies that have been subjected to peer review, namely ScienceDirect, arXiv, IEEE Xplore, MDPI, and many more, were used for the search of relevant articles. Applied keywords and combinations used to search procedures with primary considerations for review, such as pneumonia, lung cancer, COVID-19, various imaging modalities, ML, convolutional neural networks (CNNs), transfer learning, and ensemble learning. Results This research finding indicates that X-ray datasets are preferred for detecting pneumonia, while CT scan datasets are predominantly favored for detecting lung cancer. Furthermore, in COVID-19 detection, X-ray datasets are prioritized over CT scan datasets. The analysis reveals that X-rays and CT scans have surpassed all other imaging techniques. It has been observed that using CNNs yields a high degree of accuracy and practicability in identifying prominent lung diseases. Transfer learning and ensemble learning are complementary techniques to CNNs to facilitate analysis. Furthermore, accuracy is the most favored metric for assessment.","<method>machine learning (ML)</method>, <method>convolutional neural networks (CNNs)</method>, <method>transfer learning</method>, <method>ensemble learning</method>",<method>machine learning (ML)</method><method>convolutional neural networks (CNNs)</method><method>transfer learning</method><method>ensemble learning</method>
2024,https://openalex.org/W4392056032,Medicine,A novel fusion framework of deep bottleneck residual convolutional neural network for breast cancer classification from mammogram images,"With over 2.1 million new cases of breast cancer diagnosed annually, the incidence and mortality rate of this disease pose severe global health issues for women. Identifying the disease’s influence is the only practical way to lessen it immediately. Numerous research works have developed automated methods using different medical imaging to identify BC. Still, the precision of each strategy differs based on the available resources, the issue’s nature, and the dataset being used. We proposed a novel deep bottleneck convolutional neural network with a quantum optimization algorithm for breast cancer classification and diagnosis from mammogram images. Two novel deep architectures named three-residual blocks bottleneck and four-residual blocks bottle have been proposed with parallel and single paths. Bayesian Optimization (BO) has been employed to initialize hyperparameter values and train the architectures on the selected dataset. Deep features are extracted from the global average pool layer of both models. After that, a kernel-based canonical correlation analysis and entropy technique is proposed for the extracted deep features fusion. The fused feature set is further refined using an optimization technique named quantum generalized normal distribution optimization. The selected features are finally classified using several neural network classifiers, such as bi-layered and wide-neural networks. The experimental process was conducted on a publicly available mammogram imaging dataset named INbreast, and a maximum accuracy of 96.5% was obtained. Moreover, for the proposed method, the sensitivity rate is 96.45, the precision rate is 96.5, the F1 score value is 96.64, the MCC value is 92.97%, and the Kappa value is 92.97%, respectively. The proposed architectures are further utilized for the diagnosis process of infected regions. In addition, a detailed comparison has been conducted with a few recent techniques showing the proposed framework’s higher accuracy and precision rate.","<method>deep bottleneck convolutional neural network</method>, <method>quantum optimization algorithm</method>, <method>three-residual blocks bottleneck architecture</method>, <method>four-residual blocks bottleneck architecture</method>, <method>Bayesian Optimization (BO)</method>, <method>kernel-based canonical correlation analysis</method>, <method>entropy technique</method>, <method>quantum generalized normal distribution optimization</method>, <method>bi-layered neural network classifier</method>, <method>wide-neural network classifier</method>",<method>deep bottleneck convolutional neural network</method><method>three-residual blocks bottleneck architecture</method><method>Bayesian Optimization (BO)</method><method>kernel-based canonical correlation analysis</method><method>bi-layered neural network classifier</method><method>wide-neural network classifier</method>
2024,https://openalex.org/W4392139441,Medicine,Artificial intelligence for radiographic imaging detection of caries lesions: a systematic review,"Abstract Background The aim of this systematic review is to evaluate the diagnostic performance of Artificial Intelligence (AI) models designed for the detection of caries lesion (CL). Materials and methods An electronic literature search was conducted on PubMed, Web of Science, SCOPUS, LILACS and Embase databases for retrospective, prospective and cross-sectional studies published until January 2023, using the following keywords: artificial intelligence (AI), machine learning (ML), deep learning (DL), artificial neural networks (ANN), convolutional neural networks (CNN), deep convolutional neural networks (DCNN), radiology, detection, diagnosis and dental caries (DC). The quality assessment was performed using the guidelines of QUADAS-2. Results Twenty articles that met the selection criteria were evaluated. Five studies were performed on periapical radiographs, nine on bitewings, and six on orthopantomography. The number of imaging examinations included ranged from 15 to 2900. Four studies investigated ANN models, fifteen CNN models, and two DCNN models. Twelve were retrospective studies, six cross-sectional and two prospective. The following diagnostic performance was achieved in detecting CL: sensitivity from 0.44 to 0.86, specificity from 0.85 to 0.98, precision from 0.50 to 0.94, PPV (Positive Predictive Value) 0.86, NPV (Negative Predictive Value) 0.95, accuracy from 0.73 to 0.98, area under the curve (AUC) from 0.84 to 0.98, intersection over union of 0.3–0.4 and 0.78, Dice coefficient 0.66 and 0.88, F1-score from 0.64 to 0.92. According to the QUADAS-2 evaluation, most studies exhibited a low risk of bias. Conclusion AI-based models have demonstrated good diagnostic performance, potentially being an important aid in CL detection. Some limitations of these studies are related to the size and heterogeneity of the datasets. Future studies need to rely on comparable, large, and clinically meaningful datasets. Protocol PROSPERO identifier: CRD42023470708","<method>Artificial Neural Networks (ANN)</method>, <method>Convolutional Neural Networks (CNN)</method>, <method>Deep Convolutional Neural Networks (DCNN)</method>",<method>Artificial Neural Networks (ANN)</method><method>Convolutional Neural Networks (CNN)</method><method>Deep Convolutional Neural Networks (DCNN)</method>
2024,https://openalex.org/W4400227316,Medicine,FPSO/LNG hawser system lifetime assessment by Gaidai multivariate risk assessment method,"Abstract Floating Production Storage and Offloading (FPSO) unit being an offshore vessel, storing and producing crude oil, prior to crude oil being transported by accompanying shuttle tanker. Critical mooring/hawser strains during offloading operation have to be accurately predicted, in order to maintain operational safety and reliability. During certain types of offloading, excessive hawser tensions may occur, causing operational risks. Current study examines FPSO vessel’s dynamic reactions to hydrodynamic wave-induced loads, given realistic in situ environmental conditions, utilizing the AQWA software package. Current study advocates novel multi-dimensional spatiotemporal risks assessment approach, that is particularly well suited for large dataset analysis, based on numerical simulations (or measurements). Advocated multivariate reliability methodology may be useful for a variety of marine and offshore systems that must endure severe environmental stressors during their intended operational lifespan. Methodology, presented in this study provides advanced capability to efficiently, yet accurately evaluate dynamic system failure, hazard and damage risks, given representative dynamic record of multidimensional system’s inter-correlated critical components. Gaidai risk assessment method being novel dynamic multidimensional system’s lifetime assessment methodology. In order to validate and benchmark Gaidai risk assessment method, in this study it was applied to FPSO and potentially LNG (i.e., Liquid Natural Gas) vessels dynamics. Major advantage of the advocated approach is that there are no existing alternative risk assessment methods, able to tackle unlimited number of system’s dimensions. Accurate multi-dimensional risk assessment had been carried out, based on numerically simulated data, partially verified by available laboratory experiments. Confidence intervals had been given for predicted dynamic high-dimensional system risk levels.",<method>Gaidai risk assessment method</method>,No methods remaining
2024,https://openalex.org/W4391174596,Medicine,Generative Large Language Models for Detection of Speech Recognition Errors in Radiology Reports,"This study evaluated the ability of generative large language models (LLMs) to detect speech recognition errors in radiology reports. A dataset of 3233 CT and MRI reports was assessed by radiologists for speech recognition errors. Errors were categorized as clinically significant or not clinically significant. Performances of five generative LLMs—GPT-3.5-turbo, GPT-4, text-davinci-003, Llama-v2–70B-chat, and Bard—were compared in detecting these errors, using manual error detection as the reference standard. Prompt engineering was used to optimize model performance. GPT-4 demonstrated high accuracy in detecting clinically significant errors (precision, 76.9%; recall, 100%; F1 score, 86.9%) and not clinically significant errors (precision, 93.9%; recall, 94.7%; F1 score, 94.3%). Text-davinci-003 achieved F1 scores of 72% and 46.6% for clinically significant and not clinically significant errors, respectively. GPT-3.5-turbo obtained 59.1% and 32.2% F1 scores, while Llama-v2–70B-chat scored 72.8% and 47.7%. Bard showed the lowest accuracy, with F1 scores of 47.5% and 20.9%. GPT-4 effectively identified challenging errors of nonsense phrases and internally inconsistent statements. Longer reports, resident dictation, and overnight shifts were associated with higher error rates. In conclusion, advanced generative LLMs show potential for automatic detection of speech recognition errors in radiology reports. Keywords: CT, Large Language Model, Machine Learning, MRI, Natural Language Processing, Radiology Reports, Speech, Unsupervised Learning Supplemental material is available for this article. © RSNA, 2024","<method>generative large language models (LLMs)</method>, <method>GPT-3.5-turbo</method>, <method>GPT-4</method>, <method>text-davinci-003</method>, <method>Llama-v2–70B-chat</method>, <method>Bard</method>, <method>prompt engineering</method>, <method>unsupervised learning</method>",<method>generative large language models (LLMs)</method><method>GPT-3.5-turbo</method><method>GPT-4</method><method>text-davinci-003</method><method>Llama-v2–70B-chat</method><method>unsupervised learning</method>
2024,https://openalex.org/W4391480252,Medicine,Performance of convolutional neural networks for the classification of brain tumors using magnetic resonance imaging,"Brain tumors are a diverse group of neoplasms that are challenging to detect and classify due to their varying characteristics. Deep learning techniques have proven to be effective in tumor classification. However, there is a lack of studies that compare these techniques using a common methodology. This work aims to analyze the performance of convolutional neural networks in the classification of brain tumors. We propose a network consisting of a few convolutional layers, batch normalization, and max-pooling. Then, we explore recent deep architectures, such as VGG, ResNet, EfficientNet, or ConvNeXt. The study relies on two magnetic resonance imaging datasets with over 3000 images of three types of tumors –gliomas, meningiomas, and pituitary tumors–, as well as images without tumors. We determine the optimal hyperparameters of the networks using the training and validation sets. The training and test sets are used to assess the performance of the models from different perspectives, including training from scratch, data augmentation, transfer learning, and fine-tuning. The experiments are performed using the TensorFlow and Keras libraries in Python. We compare the accuracy of the models and analyze their complexity based on the capacity of the networks, their training times, and image throughput. Several networks achieve high accuracy rates on both datasets, with the best model achieving 98.7% accuracy, which is on par with state-of-the-art methods. The average precision for each type of tumor is 94.3% for gliomas, 93.8% for meningiomas, 97.9% for pituitary tumors, and 95.3% for images without tumors. VGG is the largest model with over 171 million parameters, whereas MobileNet and EfficientNetB0 are the smallest ones with 3.2 and 5.9 million parameters, respectively. These two neural networks are also the fastest to train with 23.7 and 25.4 seconds per epoch, respectively. On the other hand, ConvNext is the slowest model with 58.2 seconds per epoch. Our custom model obtained the highest image throughput with 234.37 images per second, followed by MobileNet with 226 images per second. ConvNext obtained the smallest throughput with 97.35 images per second. ResNet, MobileNet, and EfficientNet are the most accurate networks, with MobileNet and EfficientNet demonstrating superior performance in terms of complexity. Most models achieve the best accuracy using transfer learning followed by a fine-tuning step. However, data augmentation does not contribute to increasing the accuracy of the models in general.","<method>convolutional neural networks</method>, <method>batch normalization</method>, <method>max-pooling</method>, <method>VGG</method>, <method>ResNet</method>, <method>EfficientNet</method>, <method>ConvNeXt</method>, <method>training from scratch</method>, <method>data augmentation</method>, <method>transfer learning</method>, <method>fine-tuning</method>",<method>convolutional neural networks</method><method>batch normalization</method><method>max-pooling</method><method>VGG</method><method>ResNet</method><method>EfficientNet</method><method>ConvNeXt</method><method>transfer learning</method><method>fine-tuning</method>
2024,https://openalex.org/W4391641063,Medicine,Predictors for estimating subcortical EEG responses to continuous speech,"Perception of sounds and speech involves structures in the auditory brainstem that rapidly process ongoing auditory stimuli. The role of these structures in speech processing can be investigated by measuring their electrical activity using scalp-mounted electrodes. However, typical analysis methods involve averaging neural responses to many short repetitive stimuli that bear little relevance to daily listening environments. Recently, subcortical responses to more ecologically relevant continuous speech were detected using linear encoding models. These methods estimate the temporal response function (TRF), which is a regression model that minimises the error between the measured neural signal and a predictor derived from the stimulus. Using predictors that model the highly non-linear peripheral auditory system may improve linear TRF estimation accuracy and peak detection. Here, we compare predictors from both simple and complex peripheral auditory models for estimating brainstem TRFs on electroencephalography (EEG) data from 24 participants listening to continuous speech. We also investigate the data length required for estimating subcortical TRFs, and find that around 12 minutes of data is sufficient for clear wave V peaks (&gt;3 dB SNR) to be seen in nearly all participants. Interestingly, predictors derived from simple filterbank-based models of the peripheral auditory system yield TRF wave V peak SNRs that are not significantly different from those estimated using a complex model of the auditory nerve, provided that the nonlinear effects of adaptation in the auditory system are appropriately modelled. Crucially, computing predictors from these simpler models is more than 50 times faster compared to the complex model. This work paves the way for efficient modelling and detection of subcortical processing of continuous speech, which may lead to improved diagnosis metrics for hearing impairment and assistive hearing technology.","<method>linear encoding models</method>, <method>temporal response function (TRF)</method>, <method>regression model</method>",<method>linear encoding models</method><method>temporal response function (TRF)</method><method>regression model</method>
2024,https://openalex.org/W4393044095,Medicine,"Comparative performance analysis of Boruta, SHAP, and Borutashap for disease diagnosis: A study with multiple machine learning algorithms","Interpretable machine learning models are instrumental in disease diagnosis and clinical decision-making, shedding light on relevant features. Notably, Boruta, SHAP (SHapley Additive exPlanations), and BorutaShap were employed for feature selection, each contributing to the identification of crucial features. These selected features were then utilized to train six machine learning algorithms, including LR, SVM, ETC, AdaBoost, RF, and LR, using diverse medical datasets obtained from public sources after rigorous preprocessing. The performance of each feature selection technique was evaluated across multiple ML models, assessing accuracy, precision, recall, and F1-score metrics. Among these, SHAP showcased superior performance, achieving average accuracies of 80.17%, 85.13%, 90.00%, and 99.55% across diabetes, cardiovascular, statlog, and thyroid disease datasets, respectively. Notably, the LGBM emerged as the most effective algorithm, boasting an average accuracy of 91.00% for most disease states. Moreover, SHAP enhanced the interpretability of the models, providing valuable insights into the underlying mechanisms driving disease diagnosis. This comprehensive study contributes significant insights into feature selection techniques and machine learning algorithms for disease diagnosis, benefiting researchers and practitioners in the medical field. Further exploration of feature selection methods and algorithms holds promise for advancing disease diagnosis methodologies, paving the way for more accurate and interpretable diagnostic models.","<method>Boruta</method>, <method>SHAP (SHapley Additive exPlanations)</method>, <method>BorutaShap</method>, <method>LR</method>, <method>SVM</method>, <method>ETC</method>, <method>AdaBoost</method>, <method>RF</method>, <method>LGBM</method>",<method>Boruta</method><method>SHAP (SHapley Additive exPlanations)</method><method>LR</method><method>SVM</method><method>AdaBoost</method><method>RF</method><method>LGBM</method>
2024,https://openalex.org/W4394975332,Medicine,Distilling large language models for matching patients to clinical trials,"Abstract Objective The objective of this study is to systematically examine the efficacy of both proprietary (GPT-3.5, GPT-4) and open-source large language models (LLMs) (LLAMA 7B, 13B, 70B) in the context of matching patients to clinical trials in healthcare. Materials and methods The study employs a multifaceted evaluation framework, incorporating extensive automated and human-centric assessments along with a detailed error analysis for each model, and assesses LLMs’ capabilities in analyzing patient eligibility against clinical trial’s inclusion and exclusion criteria. To improve the adaptability of open-source LLMs, a specialized synthetic dataset was created using GPT-4, facilitating effective fine-tuning under constrained data conditions. Results The findings indicate that open-source LLMs, when fine-tuned on this limited and synthetic dataset, achieve performance parity with their proprietary counterparts, such as GPT-3.5. Discussion This study highlights the recent success of LLMs in the high-stakes domain of healthcare, specifically in patient-trial matching. The research demonstrates the potential of open-source models to match the performance of proprietary models when fine-tuned appropriately, addressing challenges like cost, privacy, and reproducibility concerns associated with closed-source proprietary LLMs. Conclusion The study underscores the opportunity for open-source LLMs in patient-trial matching. To encourage further research and applications in this field, the annotated evaluation dataset and the fine-tuned LLM, Trial-LLAMA, are released for public use.","<method>GPT-3.5</method>, <method>GPT-4</method>, <method>LLAMA 7B</method>, <method>LLAMA 13B</method>, <method>LLAMA 70B</method>, <method>fine-tuning</method>",<method>GPT-3.5</method><method>GPT-4</method><method>LLAMA 7B</method><method>LLAMA 13B</method><method>LLAMA 70B</method><method>fine-tuning</method>
2024,https://openalex.org/W4390547705,Medicine,Impact of random oversampling and random undersampling on the performance of prediction models developed using observational health data,"Abstract Background There is currently no consensus on the impact of class imbalance methods on the performance of clinical prediction models. We aimed to empirically investigate the impact of random oversampling and random undersampling, two commonly used class imbalance methods, on the internal and external validation performance of prediction models developed using observational health data. Methods We developed and externally validated prediction models for various outcomes of interest within a target population of people with pharmaceutically treated depression across four large observational health databases. We used three different classifiers (lasso logistic regression, random forest, XGBoost) and varied the target imbalance ratio. We evaluated the impact on model performance in terms of discrimination and calibration. Discrimination was assessed using the area under the receiver operating characteristic curve (AUROC) and calibration was assessed using calibration plots. Results We developed and externally validated a total of 1,566 prediction models. On internal and external validation, random oversampling and random undersampling generally did not result in higher AUROCs. Moreover, we found overestimated risks, although this miscalibration could largely be corrected by recalibrating the models towards the imbalance ratios in the original dataset. Conclusions Overall, we found that random oversampling or random undersampling generally does not improve the internal and external validation performance of prediction models developed in large observational health databases. Based on our findings, we do not recommend applying random oversampling or random undersampling when developing prediction models in large observational health databases.","<method>random oversampling</method>, <method>random undersampling</method>, <method>lasso logistic regression</method>, <method>random forest</method>, <method>XGBoost</method>",<method>random undersampling</method><method>lasso logistic regression</method><method>random forest</method><method>XGBoost</method>
2024,https://openalex.org/W4390579686,Medicine,Auto-detection of the coronavirus disease by using deep convolutional neural networks and X-ray photographs,"Abstract The most widely used method for detecting Coronavirus Disease 2019 (COVID-19) is real-time polymerase chain reaction. However, this method has several drawbacks, including high cost, lengthy turnaround time for results, and the potential for false-negative results due to limited sensitivity. To address these issues, additional technologies such as computed tomography (CT) or X-rays have been employed for diagnosing the disease. Chest X-rays are more commonly used than CT scans due to the widespread availability of X-ray machines, lower ionizing radiation, and lower cost of equipment. COVID-19 presents certain radiological biomarkers that can be observed through chest X-rays, making it necessary for radiologists to manually search for these biomarkers. However, this process is time-consuming and prone to errors. Therefore, there is a critical need to develop an automated system for evaluating chest X-rays. Deep learning techniques can be employed to expedite this process. In this study, a deep learning-based method called Custom Convolutional Neural Network (Custom-CNN) is proposed for identifying COVID-19 infection in chest X-rays. The Custom-CNN model consists of eight weighted layers and utilizes strategies like dropout and batch normalization to enhance performance and reduce overfitting. The proposed approach achieved a classification accuracy of 98.19% and aims to accurately classify COVID-19, normal, and pneumonia samples.","<method>Deep learning</method>, <method>Custom Convolutional Neural Network (Custom-CNN)</method>, <method>dropout</method>, <method>batch normalization</method>",<method>Deep learning</method><method>dropout</method><method>batch normalization</method>
2024,https://openalex.org/W4390913521,Medicine,A Review of Intraocular Lens Power Calculation Formulas Based on Artificial Intelligence,"Purpose: The proper selection of an intraocular lens power calculation formula is an essential aspect of cataract surgery. This study evaluated the accuracy of artificial intelligence-based formulas. Design: Systematic review. Methods: This review comprises articles evaluating the exactness of artificial intelligence-based formulas published from 2017 to July 2023. The papers were identified by a literature search of various databases (Pubmed/MEDLINE, Google Scholar, Crossref, Cochrane Library, Web of Science, and SciELO) using the terms “IOL formulas”, “FullMonte”, “Ladas”, “Hill-RBF”, “PEARL-DGS”, “Kane”, “Karmona”, “Hoffer QST”, and “Nallasamy”. In total, 25 peer-reviewed articles in English with the maximum sample and the largest number of compared formulas were examined. Results: The scores of the mean absolute error and percentage of patients within ±0.5 D and ±1.0 D were used to estimate the exactness of the formulas. In most studies the Kane formula obtained the smallest mean absolute error and the highest percentage of patients within ±0.5 D and ±1.0 D. Second place was typically achieved by the PEARL DGS formula. The limitations of the studies were also discussed. Conclusions: Kane seems to be the most accurate artificial intelligence-based formula. PEARL DGS also gives very good results. Hoffer QST, Karmona, and Nallasamy are the newest, and need further evaluation.","<method>FullMonte</method>, <method>Ladas</method>, <method>Hill-RBF</method>, <method>PEARL-DGS</method>, <method>Kane</method>, <method>Karmona</method>, <method>Hoffer QST</method>, <method>Nallasamy</method>",No methods remaining
2024,https://openalex.org/W4391202196,Medicine,Screening of miRNAs as prognostic biomarkers and their associated hub targets across Hepatocellular carcinoma using survival-based bioinformatics approach,"The hepatocellular carcinoma (HCC) incident rate is gradually increasing yearly despite all the research and efforts taken by scientific communities and governing bodies. Approximately 90% of all liver cancer cases belong to HCC. Usually, HCC patients approach the treatment in the late stages of this malignancy which becomes the primary cause of high mortality rate. The knowledge about molecular pathogenesis of HCC is limited and needs more attention from researchers to identify the driver genes and miRNAs, which causes to translate this information into clinical practice. Therefore, the key regulators identification of miRNA-mRNA regulatory network is essential to identify HCC-associated genes. We extracted microRNA (miRNA) and messenger RNA (mRNA) expression datasets of normal and tumor HCC patient samples from UCSC Xena followed by identifying differentially expressed genes (DEGs) and differentially expressed miRNAs (DEMs). Univariate and multivariate cox-proportional hazard models were utilized to identify DEMs having significant association with overall survival (OS). Kaplan-Meier (KM) plotter was used to validate the presence of prognostic DEMs. A risk-score model was used to evaluate the effectiveness of KM-plotter validated DEMs combination on risk of samples. Target DEGs of prognostic miRNAs were identified via sources such as miRTargetLink and miRWalk followed by their validation in an external microarray cohort and enrichment analysis. 562 DEGs and 388 DEMs were identified followed by seven prognostic miRNAs (i.e., miR-19a, miR-19b, miR-30d-5p, miR-424-5p, miR-3677-5p, miR-3913-5p, miR-7705) post univariate, multivariate, risk-score model evaluation and KM-plotter analyses. ANLN, MRO, CPEB3 were their targets and were also validated in GSE84005 dataset. The findings of this study decipher that most significant miRNAs and their identified target genes have association with apoptosis, inflammation, cell cycle regulation and cancer-related pathways, which appear to contribute to HCC pathogenesis and therefore, the discovery of new targets.","<method>univariate cox-proportional hazard model</method>, <method>multivariate cox-proportional hazard model</method>, <method>Kaplan-Meier (KM) plotter</method>, <method>risk-score model</method>",No methods remaining
2024,https://openalex.org/W4391480223,Medicine,GAN-based generation of realistic 3D volumetric data: A systematic review and taxonomy,"With the massive proliferation of data-driven algorithms, such as deep learning-based approaches, the availability of high-quality data is of great interest. Volumetric data is very important in medicine, as it ranges from disease diagnoses to therapy monitoring. When the dataset is sufficient, models can be trained to help doctors with these tasks. Unfortunately, there are scenarios where large amounts of data is unavailable. For example, rare diseases and privacy issues can lead to restricted data availability. In non-medical fields, the high cost of obtaining enough high-quality data can also be a concern. A solution to these problems can be the generation of realistic synthetic data using Generative Adversarial Networks (GANs). The existence of these mechanisms is a good asset, especially in healthcare, as the data must be of good quality, realistic, and without privacy issues. Therefore, most of the publications on volumetric GANs are within the medical domain. In this review, we provide a summary of works that generate realistic volumetric synthetic data using GANs. We therefore outline GAN-based methods in these areas with common architectures, loss functions and evaluation metrics, including their advantages and disadvantages. We present a novel taxonomy, evaluations, challenges, and research opportunities to provide a holistic overview of the current state of volumetric GANs.","<method>deep learning-based approaches</method>, <method>Generative Adversarial Networks (GANs)</method>, <method>GAN-based methods</method>",<method>Generative Adversarial Networks (GANs)</method><method>GAN-based methods</method>
2024,https://openalex.org/W4392302759,Medicine,Molecular structural modeling and physical characteristics of anti-breast cancer drugs via some novel topological descriptors and regression models,"Research is continuously being pursued to treat cancer patients and prevent the disease by developing new medicines. However, experimental drug design and development is a costly, time-consuming, and challenging process. Alternatively, computational and mathematical techniques play an important role in optimally achieving this goal. Among these mathematical techniques, topological indices (TIs) have many applications in the drugs used for the treatment of breast cancer. TIs can be utilized to forecast the effectiveness of drugs by providing molecular structure information and related properties of the drugs. In addition, these can assist in the design and discovery of new drugs by providing insights into the structure-property/structure-activity relationships. In this article, a Quantitative Structure Property Relationship (QSPR) analysis is carried out using some novel degree-based molecular descriptors and regression models to predict various properties (such as boiling point, melting point, enthalpy, flashpoint, molar refraction, molar volume, and polarizability) of 14 drugs used for the breast cancer treatment. The molecular structures of these drugs are topologically modeled through vertex and edge partitioning techniques of graph theory, and then linear regression models are developed to correlate the computed values with the experimental properties of the drugs to investigate the performance of TIs in predicting these properties. The results confirmed the potential of the considered topological indices as a tool for drug discovery and design in the field of breast cancer treatment.","<method>Quantitative Structure Property Relationship (QSPR) analysis</method>, <method>regression models</method>, <method>linear regression models</method>",<method>regression models</method><method>linear regression models</method>
2024,https://openalex.org/W4392499245,Medicine,Exploring the role of skin temperature in thermal sensation and thermal comfort: A comprehensive review,"The role of skin temperature as a determinant of human thermal sensation and comfort has gained increasing recognition, prompting a need for a systematic review. This review examines the relationship between skin temperature and thermal sensation, synthesizing insights from 172 studies published since 2000. It uniquely focuses on the indispensable roles of local and mean skin temperatures, a perspective not comprehensively explored in previous literature. The review reveals that the most common measurement points for skin temperature are the face and hands, attributed to their higher thermal sensitivity and the practical ease of measurement. It establishes a clear linear relationship between mean skin temperature and user thermal sensation, though affected by the choice of measurement locations and number of points. A notable finding is the varying impact of local skin temperature on overall thermal sensation in changing environments, with local heating less influential than cooling. The review also uncovers significant demographic variations in thermal sensation, strongly influenced by differing skin temperatures across age groups, genders, and climatic regions. For example, elderly populations exhibit a decreased temperature sensitivity, especially towards warmth. Gender differences are also significant, with females experiencing higher skin temperatures in warmer environments and lower in colder ones. Machine learning (ML)-based methods, especially classification tree-based and support vector machine (SVM) techniques, dominate in predicting thermal sensation and comfort, leveraging skin temperature data. While ML methods are prevalent, statistical regression-based approaches offer valuable empirical insights. Thermo-physiological model-based methods provide reliable results by incorporating detailed skin temperature dynamics. The review identifies a gap in understanding how gender, age, and regional differences influence thermal comfort in diverse environments. The study recommends conducting more nuanced experiments to dissect the impact of these factors and proposes the integration of individual demographic variables into ML models to personalize thermal comfort predictions.","<method>classification tree-based</method>, <method>support vector machine (SVM)</method>, <method>statistical regression-based approaches</method>, <method>thermo-physiological model-based methods</method>",<method>support vector machine (SVM)</method><method>statistical regression-based approaches</method>
2024,https://openalex.org/W4392516399,Medicine,Artificial intelligence in dermatology: advancements and challenges in skin of color,"Abstract Artificial intelligence (AI) uses algorithms and large language models in computers to simulate human‐like problem‐solving and decision‐making. AI programs have recently acquired widespread popularity in the field of dermatology through the application of online tools in the assessment, diagnosis, and treatment of skin conditions. A literature review was conducted using PubMed and Google Scholar analyzing recent literature (from the last 10 years through October 2023) to evaluate current AI programs in use for dermatologic purposes, identifying challenges in this technology when applied to skin of color (SOC), and proposing future steps to enhance the role of AI in dermatologic practice. Challenges surrounding AI and its application to SOC stem from the underrepresentation of SOC in datasets and issues with image quality and standardization. With these existing issues, current AI programs inevitably do worse at identifying lesions in SOC. Additionally, only 30% of the programs identified in this review had data reported on their use in dermatology, specifically in SOC. Significant development of these applications is required for the accurate depiction of darker skin tone images in datasets. More research is warranted in the future to better understand the efficacy of AI in aiding diagnosis and treatment options for SOC patients.","<method>algorithms</method>, <method>large language models</method>",No methods remaining
2024,https://openalex.org/W4394011823,Medicine,"Artificial intelligence in lung cancer screening: Detection, classification, prediction, and prognosis","Abstract Background The exceptional capabilities of artificial intelligence (AI) in extracting image information and processing complex models have led to its recognition across various medical fields. With the continuous evolution of AI technologies based on deep learning, particularly the advent of convolutional neural networks (CNNs), AI presents an expanded horizon of applications in lung cancer screening, including lung segmentation, nodule detection, false‐positive reduction, nodule classification, and prognosis. Methodology This review initially analyzes the current status of AI technologies. It then explores the applications of AI in lung cancer screening, including lung segmentation, nodule detection, and classification, and assesses the potential of AI in enhancing the sensitivity of nodule detection and reducing false‐positive rates. Finally, it addresses the challenges and future directions of AI in lung cancer screening. Results AI holds substantial prospects in lung cancer screening. It demonstrates significant potential in improving nodule detection sensitivity, reducing false‐positive rates, and classifying nodules, while also showing value in predicting nodule growth and pathological/genetic typing. Conclusions AI offers a promising supportive approach to lung cancer screening, presenting considerable potential in enhancing nodule detection sensitivity, reducing false‐positive rates, and classifying nodules. However, the universality and interpretability of AI results need further enhancement. Future research should focus on the large‐scale validation of new deep learning‐based algorithms and multi‐center studies to improve the efficacy of AI in lung cancer screening.","<method>artificial intelligence (AI)</method>, <method>deep learning</method>, <method>convolutional neural networks (CNNs)</method>, <method>deep learning-based algorithms</method>",<method>deep learning</method><method>convolutional neural networks (CNNs)</method>
2024,https://openalex.org/W4398141531,Medicine,Enhancing EfficientNetv2 with global and efficient channel attention mechanisms for accurate MRI-Based brain tumor classification,"Abstract The early and accurate diagnosis of brain tumors is critical for effective treatment planning, with Magnetic Resonance Imaging (MRI) serving as a key tool in the non-invasive examination of such conditions. Despite the advancements in Computer-Aided Diagnosis (CADx) systems powered by deep learning, the challenge of accurately classifying brain tumors from MRI scans persists due to the high variability of tumor appearances and the subtlety of early-stage manifestations. This work introduces a novel adaptation of the EfficientNetv2 architecture, enhanced with Global Attention Mechanism (GAM) and Efficient Channel Attention (ECA), aimed at overcoming these hurdles. This enhancement not only amplifies the model’s ability to focus on salient features within complex MRI images but also significantly improves the classification accuracy of brain tumors. Our approach distinguishes itself by meticulously integrating attention mechanisms that systematically enhance feature extraction, thereby achieving superior performance in detecting a broad spectrum of brain tumors. Demonstrated through extensive experiments on a large public dataset, our model achieves an exceptional high-test accuracy of 99.76%, setting a new benchmark in MRI-based brain tumor classification. Moreover, the incorporation of Grad-CAM visualization techniques sheds light on the model’s decision-making process, offering transparent and interpretable insights that are invaluable for clinical assessment. By addressing the limitations inherent in previous models, this study not only advances the field of medical imaging analysis but also highlights the pivotal role of attention mechanisms in enhancing the interpretability and accuracy of deep learning models for brain tumor diagnosis. This research sets the stage for advanced CADx systems, enhancing patient care and treatment outcomes.","<method>EfficientNetv2 architecture</method>, <method>Global Attention Mechanism (GAM)</method>, <method>Efficient Channel Attention (ECA)</method>, <method>Grad-CAM visualization techniques</method>",<method>EfficientNetv2 architecture</method><method>Global Attention Mechanism (GAM)</method><method>Efficient Channel Attention (ECA)</method>
2024,https://openalex.org/W4399128365,Medicine,Automated model discovery for human cardiac tissue: Discovering the best model and parameters,"For more than half a century, scientists have developed mathematical models to understand the behavior of the human heart. Today, we have dozens of heart tissue models to choose from, but selecting the best model is limited to expert professionals, prone to user bias, and vulnerable to human error. Here we take the human out of the loop and automate the process of model discovery. Towards this goal, we establish a novel incompressible orthotropic constitutive neural network to simultaneously discover both, model and parameters, that best explain human cardiac tissue. Notably, our network features 32 individual terms, 8 isotropic and 24 anisotropic, and fully autonomously selects the best model, out of more than 4 billion possible combinations of terms. We demonstrate that we can successfully train the network with triaxial shear and biaxial extension tests and systematically sparsify the parameter vector with L1-regularization. Strikingly, we robustly discover a four-term model that features a quadratic term in the second invariant I2, and exponential quadratic terms in the fourth and eighth invariants I4f, I4n, and I8fs. Importantly, our discovered model is interpretable by design and has parameters with well-defined physical units. We show that it outperforms popular existing myocardium models and generalizes well, from homogeneous laboratory tests to heterogeneous whole heart simulations. This is made possible by a new universal material subroutine that directly takes the discovered network weights as input. Automating the process of model discovery has the potential to democratize cardiac modeling, broaden participation in scientific discovery, and accelerate the development of innovative treatments for cardiovascular disease. Our source code, data, and examples are available at https://github.com/LivingMatterLab/CANN.","<method>incompressible orthotropic constitutive neural network</method>, <method>L1-regularization</method>",<method>L1-regularization</method>
2024,https://openalex.org/W4391068733,Medicine,Improving diabetes disease patients classification using stacking ensemble method with PIMA and local healthcare data,"Diabetes mellitus, a chronic metabolic disorder, continues to be a major public health issue around the world. It is estimated that one in every two diabetics is undiagnosed. Early diagnosis and management of diabetes can also prevent or delay the onset of complications. With the help of a variety of machine learning and deep learning models, stacking algorithms, and other techniques, our study's goal is to detect diseases early. In this study, we propose two stacking-based models for diabetes disease classification using a combination of the PIMA Indian diabetes dataset, simulated data, and additional data collected from a local healthcare facility. We use both the classical and deep neural network stacking ensemble methods to combine the predictions of multiple classification models and improve classification accuracy and robustness. In the evaluation protocol, we used both the train-test and cross-validation (CV) techniques to validate our proposed model. The highest accuracy is obtained by stacking ensemble with three NN architectures, resulting in an accuracy of 95.50 %, precision of 94 %, recall of 97 %, and f1-score of 96 % using 5-fold CV on simulation study. The stacked accuracy obtained from ML algorithms for the Pima Indian Diabetes dataset is 75.03 % using the train-test split protocol, while the accuracy obtained from the CV protocol is 77.10 % on the stacked model. The range of performance scores that outperformed the CV protocol 2.23 %–12 %. Our proposed method achieves a high accuracy range from 92 % to 95 %, precision, recall, and F1-score ranges from 88 % to 96 % using classical and deep neural network (NN)-based stacking method on the primary dataset. The proposed dataset and ensemble method could be useful in the early detection and treatment of diabetes, as well as in the advancement of machine learning and data analysis techniques in the healthcare industry.","<method>machine learning models</method>, <method>deep learning models</method>, <method>stacking algorithms</method>, <method>stacking-based models</method>, <method>classical stacking ensemble methods</method>, <method>deep neural network stacking ensemble methods</method>, <method>train-test technique</method>, <method>cross-validation (CV) technique</method>",<method>stacking algorithms</method><method>stacking-based models</method><method>classical stacking ensemble methods</method><method>deep neural network stacking ensemble methods</method>
2024,https://openalex.org/W4391598337,Medicine,Federated Learning for Decentralized Artificial Intelligence in Melanoma Diagnostics,"Importance The development of artificial intelligence (AI)–based melanoma classifiers typically calls for large, centralized datasets, requiring hospitals to give away their patient data, which raises serious privacy concerns. To address this concern, decentralized federated learning has been proposed, where classifier development is distributed across hospitals. Objective To investigate whether a more privacy-preserving federated learning approach can achieve comparable diagnostic performance to a classical centralized (ie, single-model) and ensemble learning approach for AI-based melanoma diagnostics. Design, Setting, and Participants This multicentric, single-arm diagnostic study developed a federated model for melanoma-nevus classification using histopathological whole-slide images prospectively acquired at 6 German university hospitals between April 2021 and February 2023 and benchmarked it using both a holdout and an external test dataset. Data analysis was performed from February to April 2023. Exposures All whole-slide images were retrospectively analyzed by an AI-based classifier without influencing routine clinical care. Main Outcomes and Measures The area under the receiver operating characteristic curve (AUROC) served as the primary end point for evaluating the diagnostic performance. Secondary end points included balanced accuracy, sensitivity, and specificity. Results The study included 1025 whole-slide images of clinically melanoma-suspicious skin lesions from 923 patients, consisting of 388 histopathologically confirmed invasive melanomas and 637 nevi. The median (range) age at diagnosis was 58 (18-95) years for the training set, 57 (18-93) years for the holdout test dataset, and 61 (18-95) years for the external test dataset; the median (range) Breslow thickness was 0.70 (0.10-34.00) mm, 0.70 (0.20-14.40) mm, and 0.80 (0.30-20.00) mm, respectively. The federated approach (0.8579; 95% CI, 0.7693-0.9299) performed significantly worse than the classical centralized approach (0.9024; 95% CI, 0.8379-0.9565) in terms of AUROC on a holdout test dataset (pairwise Wilcoxon signed-rank, P &amp;amp;lt; .001) but performed significantly better (0.9126; 95% CI, 0.8810-0.9412) than the classical centralized approach (0.9045; 95% CI, 0.8701-0.9331) on an external test dataset (pairwise Wilcoxon signed-rank, P &amp;amp;lt; .001). Notably, the federated approach performed significantly worse than the ensemble approach on both the holdout (0.8867; 95% CI, 0.8103-0.9481) and external test dataset (0.9227; 95% CI, 0.8941-0.9479). Conclusions and Relevance The findings of this diagnostic study suggest that federated learning is a viable approach for the binary classification of invasive melanomas and nevi on a clinically representative distributed dataset. Federated learning can improve privacy protection in AI-based melanoma diagnostics while simultaneously promoting collaboration across institutions and countries. Moreover, it may have the potential to be extended to other image classification tasks in digital cancer histopathology and beyond.","<method>federated learning</method>, <method>classical centralized (single-model) approach</method>, <method>ensemble learning approach</method>",<method>federated learning</method><method>ensemble learning approach</method>
2024,https://openalex.org/W4391692539,Medicine,Exploration of Interpretability Techniques for Deep COVID-19 Classification Using Chest X-ray Images,"The outbreak of COVID-19 has shocked the entire world with its fairly rapid spread, and has challenged different sectors. One of the most effective ways to limit its spread is the early and accurate diagnosing of infected patients. Medical imaging, such as X-ray and computed tomography (CT), combined with the potential of artificial intelligence (AI), plays an essential role in supporting medical personnel in the diagnosis process. Thus, in this article, five different deep learning models (ResNet18, ResNet34, InceptionV3, InceptionResNetV2, and DenseNet161) and their ensemble, using majority voting, have been used to classify COVID-19, pneumoniæ and healthy subjects using chest X-ray images. Multilabel classification was performed to predict multiple pathologies for each patient, if present. Firstly, the interpretability of each of the networks was thoroughly studied using local interpretability methods—occlusion, saliency, input X gradient, guided backpropagation, integrated gradients, and DeepLIFT—and using a global technique—neuron activation profiles. The mean micro F1 score of the models for COVID-19 classifications ranged from 0.66 to 0.875, and was 0.89 for the ensemble of the network models. The qualitative results showed that the ResNets were the most interpretable models. This research demonstrates the importance of using interpretability methods to compare different models before making a decision regarding the best performing model.","<method>ResNet18</method>, <method>ResNet34</method>, <method>InceptionV3</method>, <method>InceptionResNetV2</method>, <method>DenseNet161</method>, <method>ensemble using majority voting</method>, <method>occlusion</method>, <method>saliency</method>, <method>input X gradient</method>, <method>guided backpropagation</method>, <method>integrated gradients</method>, <method>DeepLIFT</method>, <method>neuron activation profiles</method>",<method>ResNet18</method><method>ResNet34</method><method>InceptionV3</method><method>InceptionResNetV2</method><method>DenseNet161</method><method>ensemble using majority voting</method><method>saliency</method><method>input X gradient</method><method>guided backpropagation</method><method>integrated gradients</method><method>DeepLIFT</method>
2024,https://openalex.org/W4393131920,Medicine,Diabetic foot ulcers segmentation challenge report: Benchmark and analysis,"Monitoring the healing progress of diabetic foot ulcers is a challenging process. Accurate segmentation of foot ulcers can help podiatrists to quantitatively measure the size of wound regions to assist prediction of healing status. The main challenge in this field is the lack of publicly available manual delineation, which can be time consuming and laborious. Recently, methods based on deep learning have shown excellent results in automatic segmentation of medical images, however, they require large-scale datasets for training, and there is limited consensus on which methods perform the best. The 2022 Diabetic Foot Ulcers segmentation challenge was held in conjunction with the 2022 International Conference on Medical Image Computing and Computer Assisted Intervention, which sought to address these issues and stimulate progress in this research domain. A training set of 2000 images exhibiting diabetic foot ulcers was released with corresponding segmentation ground truth masks. Of the 72 (approved) requests from 47 countries, 26 teams used this data to develop fully automated systems to predict the true segmentation masks on a test set of 2000 images, with the corresponding ground truth segmentation masks kept private. Predictions from participating teams were scored and ranked according to their average Dice similarity coefficient of the ground truth masks and prediction masks. The winning team achieved a Dice of 0.7287 for diabetic foot ulcer segmentation. This challenge has now entered a live leaderboard stage where it serves as a challenging benchmark for diabetic foot ulcer segmentation.",<method>deep learning</method>,<method>deep learning</method>
2024,https://openalex.org/W4394620240,Medicine,Human-AI interaction in skin cancer diagnosis: a systematic review and meta-analysis,"Abstract The development of diagnostic tools for skin cancer based on artificial intelligence (AI) is increasing rapidly and will likely soon be widely implemented in clinical use. Even though the performance of these algorithms is promising in theory, there is limited evidence on the impact of AI assistance on human diagnostic decisions. Therefore, the aim of this systematic review and meta-analysis was to study the effect of AI assistance on the accuracy of skin cancer diagnosis. We searched PubMed, Embase, IEE Xplore, Scopus and conference proceedings for articles from 1/1/2017 to 11/8/2022. We included studies comparing the performance of clinicians diagnosing at least one skin cancer with and without deep learning-based AI assistance. Summary estimates of sensitivity and specificity of diagnostic accuracy with versus without AI assistance were computed using a bivariate random effects model. We identified 2983 studies, of which ten were eligible for meta-analysis. For clinicians without AI assistance, pooled sensitivity was 74.8% (95% CI 68.6–80.1) and specificity was 81.5% (95% CI 73.9–87.3). For AI-assisted clinicians, the overall sensitivity was 81.1% (95% CI 74.4–86.5) and specificity was 86.1% (95% CI 79.2–90.9). AI benefitted medical professionals of all experience levels in subgroup analyses, with the largest improvement among non-dermatologists. No publication bias was detected, and sensitivity analysis revealed that the findings were robust. AI in the hands of clinicians has the potential to improve diagnostic accuracy in skin cancer diagnosis. Given that most studies were conducted in experimental settings, we encourage future studies to further investigate these potential benefits in real-life settings.","<method>deep learning-based AI assistance</method>, <method>bivariate random effects model</method>",No methods remaining
2024,https://openalex.org/W4396679651,Medicine,Predictive Modelling of Critical Vital Signs in ICU Patients by Machine Learning: An Early Warning System for Improved Patient Outcomes,"Accurate monitoring of vital signs in an ICU is integral to understanding overall physical well-being for patients. Our research endeavor employed machine learning techniques to construct a predictive classification model utilizing continuous ICU vital sign measurements. The primary aim was to develop an early warning system capable of forecasting whether vital indicators would reach critical values within one hour; our ultimate aim was to enable healthcare professionals, including nurses and doctors, to intervene proactively, preventing emergency situations which could result in organ dysfunction or mortality. Our comprehensive dataset comprises vital sign measurements, lab test results, procedures, and medications from over 50,000 patients collected via rigorous preprocessing procedures like data cleansing, bias correction, feature extraction and selection to produce an insightful dataset with distinguishing attributes. After selecting an algorithmic set that included Decision Trees (DT), Support Vector Machines (SVM), Recurrent Neural Networks (RNN), and Long Short-Term Memory (LSTM), to predict critical vital signs in ICU patients one hour in advance - such as Heart Rate, SpO2, Mean Artery Pressure (MAP), Respiratory Rate (RR), and Systolic Blood Pressure (SBP). Our models included Heart Rate prediction as well as respiratory Rate/RR predictions/SBP estimation models. The results of the study demonstrated the efficacy and accuracy of machine learning methods designed to anticipate imminent changes to vital signs. Utilizing such predictive models, healthcare providers can increase their capacity to address potential complications before they occur, ultimately leading to improved patient outcomes in challenging settings.","<method>Decision Trees (DT)</method>, <method>Support Vector Machines (SVM)</method>, <method>Recurrent Neural Networks (RNN)</method>, <method>Long Short-Term Memory (LSTM)</method>",<method>Decision Trees (DT)</method><method>Support Vector Machines (SVM)</method><method>Recurrent Neural Networks (RNN)</method><method>Long Short-Term Memory (LSTM)</method>
2024,https://openalex.org/W4396834505,Medicine,Enhancing cervical cancer detection and robust classification through a fusion of deep learning models,"Abstract Cervical cancer, the second most prevalent cancer affecting women, arises from abnormal cell growth in the cervix, a crucial anatomical structure within the uterus. The significance of early detection cannot be overstated, prompting the use of various screening methods such as Pap smears, colposcopy, and Human Papillomavirus (HPV) testing to identify potential risks and initiate timely intervention. These screening procedures encompass visual inspections, Pap smears, colposcopies, biopsies, and HPV-DNA testing, each demanding the specialized knowledge and skills of experienced physicians and pathologists due to the inherently subjective nature of cancer diagnosis. In response to the imperative for efficient and intelligent screening, this article introduces a groundbreaking methodology that leverages pre-trained deep neural network models, including Alexnet, Resnet-101, Resnet-152, and InceptionV3, for feature extraction. The fine-tuning of these models is accompanied by the integration of diverse machine learning algorithms, with ResNet152 showcasing exceptional performance, achieving an impressive accuracy rate of 98.08%. It is noteworthy that the SIPaKMeD dataset, publicly accessible and utilized in this study, contributes to the transparency and reproducibility of our findings. The proposed hybrid methodology combines aspects of DL and ML for cervical cancer classification. Most intricate and complicated features from images can be extracted through DL. Further various ML algorithms can be implemented on extracted features. This innovative approach not only holds promise for significantly improving cervical cancer detection but also underscores the transformative potential of intelligent automation within the realm of medical diagnostics, paving the way for more accurate and timely interventions.","<method>Alexnet</method>, <method>Resnet-101</method>, <method>Resnet-152</method>, <method>InceptionV3</method>, <method>deep neural network models</method>, <method>fine-tuning</method>, <method>machine learning algorithms</method>, <method>hybrid methodology combining DL and ML</method>",<method>Alexnet</method><method>Resnet-101</method><method>Resnet-152</method><method>InceptionV3</method><method>deep neural network models</method><method>fine-tuning</method>
2024,https://openalex.org/W4399258783,Medicine,A review of uncertainty quantification in medical image analysis: Probabilistic and non-probabilistic methods,"The comprehensive integration of machine learning healthcare models within clinical practice remains suboptimal, notwithstanding the proliferation of high-performing solutions reported in the literature. A predominant factor hindering widespread adoption pertains to an insufficiency of evidence affirming the reliability of the aforementioned models. Recently, uncertainty quantification methods have been proposed as a potential solution to quantify the reliability of machine learning models and thus increase the interpretability and acceptability of the results. In this review, we offer a comprehensive overview of the prevailing methods proposed to quantify the uncertainty inherent in machine learning models developed for various medical image tasks. Contrary to earlier reviews that exclusively focused on probabilistic methods, this review also explores non-probabilistic approaches, thereby furnishing a more holistic survey of research pertaining to uncertainty quantification for machine learning models. Analysis of medical images with the summary and discussion on medical applications and the corresponding uncertainty evaluation protocols are presented, which focus on the specific challenges of uncertainty in medical image analysis. We also highlight some potential future research work at the end. Generally, this review aims to allow researchers from both clinical and technical backgrounds to gain a quick and yet in-depth understanding of the research in uncertainty quantification for medical image analysis machine learning models.","<method>uncertainty quantification methods</method>, <method>probabilistic methods</method>, <method>non-probabilistic approaches</method>",<method>probabilistic methods</method><method>non-probabilistic approaches</method>
2024,https://openalex.org/W4399442306,Medicine,Integrative analysis of AI-driven optimization in HIV treatment regimens,"The integration of artificial intelligence (AI) into HIV treatment regimens has revolutionized the approach to personalized care and optimization strategies. This study presents an in-depth analysis of the role of AI in transforming HIV treatment, focusing on its ability to tailor therapy to individual patient needs and enhance treatment outcomes. AI-driven optimization in HIV treatment involves the utilization of advanced algorithms and computational techniques to analyze vast amounts of patient data, including genetic information, viral load measurements, and treatment history. By harnessing the power of machine learning and predictive analytics, AI algorithms can identify patterns and trends in patient data that may not be readily apparent to human clinicians. One of the key benefits of AI-driven optimization is its ability to personalize treatment regimens based on individual patient characteristics and disease progression. By considering factors such as drug resistance profiles, comorbidities, and lifestyle factors, AI algorithms can recommend the most effective and well-tolerated treatment options for each patient, leading to improved adherence and clinical outcomes. Furthermore, AI enables continuous monitoring and adjustment of treatment regimens in real time, allowing healthcare providers to respond rapidly to changes in patient status and evolving viral dynamics. This proactive approach to HIV management can help prevent treatment failure and the development of drug resistance, ultimately leading to better long-term outcomes for patients. Despite its transformative potential, AI-driven optimization in HIV treatment is not without challenges. Ethical considerations, data privacy concerns, and the need for robust validation and regulatory oversight are all important factors that must be addressed to ensure the safe and effective implementation of AI algorithms in clinical practice. In conclusion, the integrative analysis presented in this study underscores the significant impact of AI-driven optimization on the personalization and optimization of HIV treatment regimens. By leveraging AI technologies, healthcare providers can tailor treatment approaches to individual patient needs, leading to improved outcomes and quality of life for people living with HIV. Keywords: Integrative Analysis, AI- Driven, Optimization, HIV Treatment, Regimens.","<method>machine learning</method>, <method>predictive analytics</method>",<method>machine learning</method>
2024,https://openalex.org/W4390506438,Medicine,Artificial intelligence for oral squamous cell carcinoma detection based on oral photographs: A comprehensive literature review,"Abstract Introduction Oral squamous cell carcinoma (OSCC) presents a significant global health challenge. The integration of artificial intelligence (AI) and computer vision holds promise for the early detection of OSCC through the analysis of digitized oral photographs. This literature review explores the landscape of AI‐driven OSCC automatic detection, assessing both the performance and limitations of the current state of the art. Materials and Methods An electronic search using several data base was conducted, and a systematic review performed in accordance with PRISMA guidelines (CRD42023441416). Results Several studies have demonstrated remarkable results for this task, consistently achieving sensitivity rates exceeding 85% and accuracy rates surpassing 90%, often encompassing around 1000 images. The review scrutinizes these studies, shedding light on their methodologies, including the use of recent machine learning and pattern recognition approaches coupled with different supervision strategies. However, comparing the results from different papers is challenging due to variations in the datasets used. Discussion Considering these findings, this review underscores the urgent need for more robust and reliable datasets in the field of OSCC detection. Furthermore, it highlights the potential of advanced techniques such as multi‐task learning, attention mechanisms, and ensemble learning as crucial tools in enhancing the accuracy and sensitivity of OSCC detection through oral photographs. Conclusion These insights collectively emphasize the transformative impact of AI‐driven approaches on early OSCC diagnosis, with the potential to significantly improve patient outcomes and healthcare practices.","<method>machine learning</method>, <method>pattern recognition</method>, <method>multi-task learning</method>, <method>attention mechanisms</method>, <method>ensemble learning</method>",<method>machine learning</method><method>multi-task learning</method><method>attention mechanisms</method><method>ensemble learning</method>
2024,https://openalex.org/W4391096835,Medicine,Diagnostic Performance Comparison between Generative AI and Physicians: A Systematic Review and Meta-Analysis,"Abstract Background The rapid advancement of generative artificial intelligence (AI) has led to the wide dissemination of models with exceptional understanding and generation of human language. Their integration into healthcare has shown potential for improving medical diagnostics, yet a comprehensive diagnostic performance evaluation of generative AI models and the comparison of their diagnostic performance with that of physicians has not been extensively explored. Methods In this systematic review and meta-analysis, a comprehensive search of Medline, Scopus, Web of Science, Cochrane Central, and MedRxiv was conducted for studies published from June 2018 through December 2023, focusing on those that validate generative AI models for diagnostic tasks. The risk of bias was assessed using the Prediction Model Study Risk of Bias Assessment Tool. Meta-regression was performed to summarize the performance of the models and to compare the accuracy of the models with that of physicians. Results The search resulted in 54 studies being included in the meta-analysis. Nine generative AI models were evaluated across 17 medical specialties. The quality assessment indicated a high risk of bias in the majority of studies, primarily due to small sample sizes. The overall accuracy for generative AI models across 54 studies was 56.9% (95% confidence interval [CI]: 51.0–62.7%). The meta-analysis demonstrated that, on average, physicians exceeded the accuracy of the models (difference in accuracy: 14.4% [95% CI: 4.9–23.8%], p-value =0.004). However, both Prometheus (Bing) and GPT-4 showed slightly better performance compared to non-experts (-2.3% [95% CI: -27.0–22.4%], p-value = 0.848 and -0.32% [95% CI: -14.4–13.7%], p-value = 0.962), but slightly underperformed when compared to experts (10.9% [95% CI: -13.1–35.0%], p-value = 0.356 and 12.9% [95% CI: 0.15–25.7%], p-value = 0.048). The sub-analysis revealed significantly improved accuracy in the fields of Gynecology, Pediatrics, Orthopedic surgery, Plastic surgery, and Otolaryngology, while showing reduced accuracy for Neurology, Psychiatry, Rheumatology, and Endocrinology compared to that of General Medicine. No significant heterogeneity was observed based on the risk of bias. Conclusions Generative AI exhibits promising diagnostic capabilities, with accuracy varying significantly by model and medical specialty. Although they have not reached the reliability of expert physicians, the findings suggest that generative AI models have the potential to enhance healthcare delivery and medical education, provided they are integrated with caution and their limitations are well-understood. Key Points Question: What is the diagnostic accuracy of generative AI models and how does this accuracy compare to that of physicians? Findings: This meta-analysis found that generative AI models have a pooled accuracy of 56.9% (95% confidence interval: 51.0–62.7%). The accuracy of expert physicians exceeds that of AI in all specialties, however, some generative AI models are comparable to non-expert physicians. Meaning: The diagnostic performance of generative AI models suggests that they do not match the level of experienced physicians but that they may have potential applications in healthcare delivery and medical education.",<method>generative AI models</method>,<method>generative AI models</method>
2024,https://openalex.org/W4391113105,Medicine,A systematic review of artificial intelligence techniques for oral cancer detection,"Oral cancer is a form of cancer that develops in the tissue of an oral cavity. Detection at an early stage is necessary to prevent the mortality rate in cancer patients. Artificial intelligence (AI) techniques play a significant role in assisting with diagnosing oral cancer. The AI techniques provide better detection accuracy and help automate oral cancer detection. The study shows that AI has a wide range of algorithms and provides outcomes in the most precise manner possible. We provide an overview of different input types and apply an appropriate algorithm to detect oral cancer. We aim to provide an overview of various AI techniques that can be used to automate oral cancer detection and to analyze these techniques to improve the efficiency and accuracy of oral cancer screening. We provide a summary of various methods available for oral cancer detection. We cover different input image formats, their processing, and the need for segmentation and feature extraction. We further include a list of other conventional strategies. We focus on various AI techniques for detecting oral cancer, including deep learning, machine learning, fuzzy computing, data mining, and genetic algorithms, and evaluates their benefits and drawbacks. The larger part of the articles focused on deep learning (37%) methods, followed by machine learning (32%), genetic algorithms (12%), data mining techniques (10%), and fuzzy computing (9%) for oral cancer detection.","<method>deep learning</method>, <method>machine learning</method>, <method>fuzzy computing</method>, <method>data mining</method>, <method>genetic algorithms</method>",<method>deep learning</method><method>machine learning</method><method>genetic algorithms</method>
2024,https://openalex.org/W4391164242,Medicine,Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models,"Suicidal ideation detection is a vital research area that holds great potential for improving mental health support systems. However, the sensitivity surrounding suicide-related data poses challenges in accessing large-scale, annotated datasets necessary for training effective machine learning models. To address this limitation, we introduce an innovative strategy that leverages the capabilities of generative AI models, such as ChatGPT, Flan-T5, and Llama, to create synthetic data for suicidal ideation detection. Our data generation approach is grounded in social factors extracted from psychology literature and aims to ensure coverage of essential information related to suicidal ideation. In our study, we benchmarked against state-of-the-art NLP classification models, specifically, those centered around the BERT family structures. When trained on the real-world dataset, UMD, these conventional models tend to yield F1-scores ranging from 0.75 to 0.87. Our synthetic data-driven method, informed by social factors, offers consistent F1-scores of 0.82 for both models, suggesting that the richness of topics in synthetic data can bridge the performance gap across different model complexities. Most impressively, when we combined a mere 30% of the UMD dataset with our synthetic data, we witnessed a substantial increase in performance, achieving an F1-score of 0.88 on the UMD test set. Such results underscore the cost-effectiveness and potential of our approach in confronting major challenges in the field, such as data scarcity and the quest for diversity in data representation.","<method>generative AI models</method>, <method>ChatGPT</method>, <method>Flan-T5</method>, <method>Llama</method>, <method>NLP classification models</method>, <method>BERT family structures</method>",<method>generative AI models</method><method>Flan-T5</method><method>Llama</method>
2024,https://openalex.org/W4391613588,Medicine,Artificial intelligence framework for heart disease classification from audio signals,"Abstract As cardiovascular disorders are prevalent, there is a growing demand for reliable and precise diagnostic methods within this domain. Audio signal-based heart disease detection is a promising area of research that leverages sound signals generated by the heart to identify and diagnose cardiovascular disorders. Machine learning (ML) and deep learning (DL) techniques are pivotal in classifying and identifying heart disease from audio signals. This study investigates ML and DL techniques to detect heart disease by analyzing noisy sound signals. This study employed two subsets of datasets from the PASCAL CHALLENGE having real heart audios. The research process and visually depict signals using spectrograms and Mel-Frequency Cepstral Coefficients (MFCCs). We employ data augmentation to improve the model’s performance by introducing synthetic noise to the heart sound signals. In addition, a feature ensembler is developed to integrate various audio feature extraction techniques. Several machine learning and deep learning classifiers are utilized for heart disease detection. Among the numerous models studied and previous study findings, the multilayer perceptron model performed best, with an accuracy rate of 95.65%. This study demonstrates the potential of this methodology in accurately detecting heart disease from sound signals. These findings present promising opportunities for enhancing medical diagnosis and patient care.","<method>machine learning (ML)</method>, <method>deep learning (DL)</method>, <method>multilayer perceptron model</method>",<method>machine learning (ML)</method><method>deep learning (DL)</method><method>multilayer perceptron model</method>
2024,https://openalex.org/W4391820319,Medicine,Investigation on explainable machine learning models to predict chronic kidney diseases,"Chronic kidney disease (CKD) is a major worldwide health problem, affecting a large proportion of the world's population and leading to higher morbidity and death rates. The early stages of CKD sometimes present without visible symptoms, causing patients to be unaware. Early detection and treatments are critical in reducing complications and improving the overall quality of life for people afflicted. In this work, we investigate the use of an explainable artificial intelligence (XAI)-based strategy, leveraging clinical characteristics, to predict CKD. This study collected clinical data from 491 patients, comprising 56 with CKD and 435 without CKD, encompassing clinical, laboratory, and demographic variables. To develop the predictive model, five machine learning (ML) methods, namely logistic regression (LR), random forest (RF), decision tree (DT), Naïve Bayes (NB), and extreme gradient boosting (XGBoost), were employed. The optimal model was selected based on accuracy and area under the curve (AUC). Additionally, the SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable Model-agnostic Explanations) algorithms were utilized to demonstrate the influence of the features on the optimal model. Among the five models developed, the XGBoost model achieved the best performance with an AUC of 0.9689 and an accuracy of 93.29%. The analysis of feature importance revealed that creatinine, glycosylated hemoglobin type A1C (HgbA1C), and age were the three most influential features in the XGBoost model. The SHAP force analysis further illustrated the model's visualization of individualized CKD predictions. For further insights into individual predictions, we also utilized the LIME algorithm. This study presents an interpretable ML-based approach for the early prediction of CKD. The SHAP and LIME methods enhance the interpretability of ML models and help clinicians better understand the rationale behind the predicted outcomes more effectively.","<method>logistic regression (LR)</method>, <method>random forest (RF)</method>, <method>decision tree (DT)</method>, <method>Naïve Bayes (NB)</method>, <method>extreme gradient boosting (XGBoost)</method>, <method>SHAP (SHapley Additive exPlanations)</method>, <method>LIME (Local Interpretable Model-agnostic Explanations)</method>",<method>logistic regression (LR)</method><method>random forest (RF)</method><method>decision tree (DT)</method><method>Naïve Bayes (NB)</method><method>extreme gradient boosting (XGBoost)</method><method>SHAP (SHapley Additive exPlanations)</method><method>LIME (Local Interpretable Model-agnostic Explanations)</method>
2024,https://openalex.org/W4392058879,Medicine,Prostate cancer grading framework based on deep transfer learning and Aquila optimizer,"Abstract Prostate cancer is the one of the most dominant cancer among males. It represents one of the leading cancer death causes worldwide. Due to the current evolution of artificial intelligence in medical imaging, deep learning has been successfully applied in diseases diagnosis. However, most of the recent studies in prostate cancer classification suffers from either low accuracy or lack of data. Therefore, the present work introduces a hybrid framework for early and accurate classification and segmentation of prostate cancer using deep learning. The proposed framework consists of two stages, namely classification stage and segmentation stage. In the classification stage, 8 pretrained convolutional neural networks were fine-tuned using Aquila optimizer and used to classify patients of prostate cancer from normal ones. If the patient is diagnosed with prostate cancer, segmenting the cancerous spot from the overall image using U-Net can help in accurate diagnosis, and here comes the importance of the segmentation stage. The proposed framework is trained on 3 different datasets in order to generalize the framework. The best reported classification accuracies of the proposed framework are 88.91% using MobileNet for the “ISUP Grade-wise Prostate Cancer” dataset and 100% using MobileNet and ResNet152 for the “Transverse Plane Prostate Dataset” dataset with precisions 89.22% and 100%, respectively. U-Net model gives an average segmentation accuracy and AUC of 98.46% and 0.9778, respectively, using the “PANDA: Resized Train Data (512 × 512)” dataset. The results give an indicator of the acceptable performance of the proposed framework.","<method>pretrained convolutional neural networks</method>, <method>Aquila optimizer</method>, <method>MobileNet</method>, <method>ResNet152</method>, <method>U-Net</method>",<method>pretrained convolutional neural networks</method><method>MobileNet</method><method>ResNet152</method><method>U-Net</method>
2024,https://openalex.org/W4392714393,Medicine,Fostering a Safety Culture in Manufacturing Industry through Safety Behavior: A Structural Equation Modelling Approach,"Creating a robust safety management system is crucial for fostering a culture of safety in the workplace, particularly in industries like manufacturing where improvements are still needed. This study aimed to assess the impact of safety behavior on safety culture within the manufacturing sector. Employing a quantitative approach, questionnaires were distributed to 342 employees in manufacturing firms during data collection. The collected data underwent analysis using Structural Equation Modeling through IBM-SPSS-AMOS 24.0 to test the proposed model. The study findings revealed that components of safety behavior, specifically safety compliance and safety leadership, have a significant influence on safety culture. This implies that prioritizing safety behavior and culture is vital for occupational safety and health, aligning with guidelines set by responsible entities to ensure a secure work environment. The insights gained from this research can be instrumental in highlighting the importance of safety culture, the pivotal role of leadership, the complex nature of safety culture, and the potential for measuring and enhancing it. By understanding these implications, organizations can foster a safety-centric culture that not only protects employees but also enhances overall performance. Additionally, this research contributed to the existing literature by examining an integrated higher-order construct model using the SEM technique, predicting the model by 53 percent. The insights garnered from this study are applicable to various types of firms, emphasizing the integral role of safety culture in any organization.",<method>Structural Equation Modeling</method>,No methods remaining
2024,https://openalex.org/W4393222088,Medicine,Methodological insights into ChatGPT’s screening performance in systematic reviews,"Abstract Background The screening process for systematic reviews and meta-analyses in medical research is a labor-intensive and time-consuming task. While machine learning and deep learning have been applied to facilitate this process, these methods often require training data and user annotation. This study aims to assess the efficacy of ChatGPT, a large language model based on the Generative Pretrained Transformers (GPT) architecture, in automating the screening process for systematic reviews in radiology without the need for training data. Methods A prospective simulation study was conducted between May 2nd and 24th, 2023, comparing ChatGPT’s performance in screening abstracts against that of general physicians (GPs). A total of 1198 abstracts across three subfields of radiology were evaluated. Metrics such as sensitivity, specificity, positive and negative predictive values (PPV and NPV), workload saving, and others were employed. Statistical analyses included the Kappa coefficient for inter-rater agreement, ROC curve plotting, AUC calculation, and bootstrapping for p-values and confidence intervals. Results ChatGPT completed the screening process within an hour, while GPs took an average of 7–10 days. The AI model achieved a sensitivity of 95% and an NPV of 99%, slightly outperforming the GPs’ sensitive consensus (i.e., including records if at least one person includes them). It also exhibited remarkably low false negative counts and high workload savings, ranging from 40 to 83%. However, ChatGPT had lower specificity and PPV compared to human raters. The average Kappa agreement between ChatGPT and other raters was 0.27. Conclusions ChatGPT shows promise in automating the article screening phase of systematic reviews, achieving high sensitivity and workload savings. While not entirely replacing human expertise, it could serve as an efficient first-line screening tool, particularly in reducing the burden on human resources. Further studies are needed to fine-tune its capabilities and validate its utility across different medical subfields.","<method>machine learning</method>, <method>deep learning</method>, <method>ChatGPT</method>, <method>Generative Pretrained Transformers (GPT) architecture</method>",<method>machine learning</method><method>deep learning</method><method>Generative Pretrained Transformers (GPT) architecture</method>
2024,https://openalex.org/W4393991916,Medicine,Advancing Ligand Docking through Deep Learning: Challenges and Prospects in Virtual Screening,"ConspectusMolecular docking, also termed ligand docking (LD), is a pivotal element of structure-based virtual screening (SBVS) used to predict the binding conformations and affinities of protein–ligand complexes. Traditional LD methodologies rely on a search and scoring framework, utilizing heuristic algorithms to explore binding conformations and scoring functions to evaluate binding strengths. However, to meet the efficiency demands of SBVS, these algorithms and functions are often simplified, prioritizing speed over accuracy.The emergence of deep learning (DL) has exerted a profound impact on diverse fields, ranging from natural language processing to computer vision and drug discovery. DeepMind's AlphaFold2 has impressively exhibited its ability to accurately predict protein structures solely from amino acid sequences, highlighting the remarkable potential of DL in conformation prediction. This groundbreaking advancement circumvents the traditional search-scoring frameworks in LD, enhancing both accuracy and processing speed and thereby catalyzing a broader adoption of DL algorithms in binding pose prediction. Nevertheless, a consensus on certain aspects remains elusive.In this Account, we delineate the current status of employing DL to augment LD within the VS paradigm, highlighting our contributions to this domain. Furthermore, we discuss the challenges and future prospects, drawing insights from our scholarly investigations. Initially, we present an overview of VS and LD, followed by an introduction to DL paradigms, which deviate significantly from traditional search-scoring frameworks. Subsequently, we delve into the challenges associated with the development of DL-based LD (DLLD), encompassing evaluation metrics, application scenarios, and physical plausibility of the predicted conformations. In the evaluation of LD algorithms, it is essential to recognize the multifaceted nature of the metrics. While the accuracy of binding pose prediction, often measured by the success rate, is a pivotal aspect, the scoring/screening power and computational speed of these algorithms are equally important given the pivotal role of LD tools in VS. Regarding application scenarios, early methods focused on blind docking, where the binding site is unknown. However, recent studies suggest a shift toward identifying binding sites rather than solely predicting binding poses within these models. In contrast, LD with a known pocket in VS has been shown to be more practical. Physical plausibility poses another significant challenge. Although DLLD models often achieve higher success rates compared to traditional methods, they may generate poses with implausible local structures, such as incorrect bond angles or lengths, which are disadvantageous for postprocessing tasks like visualization. Finally, we discuss the future perspectives for DLLD, emphasizing the need to improve generalization ability, strike a balance between speed and accuracy, account for protein conformation flexibility, and enhance physical plausibility. Additionally, we delve into the comparison between generative and regression algorithms in this context, exploring their respective strengths and potential.","<method>deep learning (DL)</method>, <method>DeepMind's AlphaFold2</method>, <method>DL-based ligand docking (DLLD)</method>, <method>generative algorithms</method>, <method>regression algorithms</method>",<method>deep learning (DL)</method><method>DeepMind's AlphaFold2</method><method>regression algorithms</method>
2024,https://openalex.org/W4398169659,Medicine,The Sociodemographic Biases in Machine Learning Algorithms: A Biomedical Informatics Perspective,"Artificial intelligence models represented in machine learning algorithms are promising tools for risk assessment used to guide clinical and other health care decisions. Machine learning algorithms, however, may house biases that propagate stereotypes, inequities, and discrimination that contribute to socioeconomic health care disparities. The biases include those related to some sociodemographic characteristics such as race, ethnicity, gender, age, insurance, and socioeconomic status from the use of erroneous electronic health record data. Additionally, there is concern that training data and algorithmic biases in large language models pose potential drawbacks. These biases affect the lives and livelihoods of a significant percentage of the population in the United States and globally. The social and economic consequences of the associated backlash cannot be underestimated. Here, we outline some of the sociodemographic, training data, and algorithmic biases that undermine sound health care risk assessment and medical decision-making that should be addressed in the health care system. We present a perspective and overview of these biases by gender, race, ethnicity, age, historically marginalized communities, algorithmic bias, biased evaluations, implicit bias, selection/sampling bias, socioeconomic status biases, biased data distributions, cultural biases and insurance status bias, conformation bias, information bias and anchoring biases and make recommendations to improve large language model training data, including de-biasing techniques such as counterfactual role-reversed sentences during knowledge distillation, fine-tuning, prefix attachment at training time, the use of toxicity classifiers, retrieval augmented generation and algorithmic modification to mitigate the biases moving forward.","<method>knowledge distillation</method>, <method>fine-tuning</method>, <method>prefix attachment at training time</method>, <method>toxicity classifiers</method>, <method>retrieval augmented generation</method>, <method>algorithmic modification</method>",<method>knowledge distillation</method><method>fine-tuning</method><method>retrieval augmented generation</method>
2024,https://openalex.org/W4399244247,Medicine,Investigating influencing factors of learning satisfaction in AI ChatGPT for research: University students perspective,"This study investigates the determinants of ChatGPT adoption among university students and its impact on learning satisfaction. Utilizing the Technology Acceptance Model (TAM) and incorporating insights from interaction learning, collaborative learning, and information quality, a structural equation modeling approach was employed. This research collected valuable responses from 262 students at King Faisal University in Saudi Arabia through the use of self-report questionnaires. The data's reliability and validity were assessed using confirmation factor analysis, followed by path analysis to explore the hypotheses in the proposed model. The results indicate the pivotal roles of interaction learning and collaborative learning in fostering ChatGPT adoption. Social interaction played a significant role, as researchers engaging in conversations and knowledge-sharing expressed increased comfort with ChatGPT. Information quality was found to substantially influence researchers' decisions to continue using ChatGPT, emphasizing the need for ongoing improvement in the accuracy and relevance of content provided. Perceived ease of use and perceived usefulness played intermediary roles in linking ChatGPT engagement to learning satisfaction. User-friendly interfaces and perceived utility were identified as crucial factors affecting overall satisfaction levels. Notably, ChatGPT positively impacted learning motivation, indicating its potential to enhance student engagement and interest in learning. The study's findings have implications for educational practitioners seeking to improve the implementation of AI technologies in university students, emphasizing user-friendly design, collaborative learning, and factors influencing satisfaction. The study concludes with insights into the complex interplay between AI-powered tools, learning objectives, and motivation, highlighting the need for continued research to comprehensively understand these dynamics. This study investigates the determinants of ChatGPT adoption among university students and its impact on learning satisfaction. Utilizing the Technology Acceptance Model (TAM) and incorporating insights from interaction learning, collaborative learning, and information quality, a structural equation modeling approach was employed. This research collected valuable responses from 262 students at King Faisal University in Saudi Arabia through the use of self-report questionnaires. The data's reliability and validity were assessed using confirmation factor analysis, followed by path analysis to explore the hypotheses in the proposed model. The results indicate the pivotal roles of interaction learning and collaborative learning in fostering ChatGPT adoption. Social interaction played a significant role, as researchers engaging in conversations and knowledge-sharing expressed increased comfort with ChatGPT. Information quality was found to substantially influence researchers' decisions to continue using ChatGPT, emphasizing the need for ongoing improvement in the accuracy and relevance of content provided. Perceived ease of use and perceived usefulness played intermediary roles in linking ChatGPT engagement to learning satisfaction. User-friendly interfaces and perceived utility were identified as crucial factors affecting overall satisfaction levels. Notably, ChatGPT positively impacted learning motivation, indicating its potential to enhance student engagement and interest in learning. The study's findings have implications for educational practitioners seeking to improve the implementation of AI technologies in university students, emphasizing user-friendly design, collaborative learning, and factors influencing satisfaction. The study concludes with insights into the complex interplay between AI-powered tools, learning objectives, and motivation, highlighting the need for continued research to comprehensively understand these dynamics.","<method>Technology Acceptance Model (TAM)</method>, <method>structural equation modeling</method>, <method>confirmation factor analysis</method>, <method>path analysis</method>",No methods remaining
2024,https://openalex.org/W4399715357,Medicine,AI-POWERED FRAUD DETECTION IN BANKING: SAFEGUARDING FINANCIAL TRANSACTIONS,"The banking industry's metamorphosis through digitalization has unquestionably revolutionized accessibility and convenience for customers worldwide. However, this paradigm shift has ushered in a new era of challenges, most notably in the realm of cybersecurity. Conventional rule-based fraud detection strategies have struggled to keep pace with the rapid evolution of cyber threats, prompting a surge of interest in more adaptive approaches like unsupervised learning. Furthermore, the COVID-19 pandemic has exacerbated the issue of bank fraud due to the widespread transition to online platforms and the proliferation of charitable funds, which present ripe opportunities for exploitation by cybercriminals. In response to these pressing concerns, this study delves into the realm of machine learning algorithms for the analysis and identification of fraudulent banking transactions. Notably, it contributes scientific novelty by developing models specifically tailored to this purpose and implementing innovative preprocessing techniques to enhance detection accuracy. Utilizing a diverse array of algorithms, including Random Forest, K-Nearest Neighbor (KNN), Naïve Bayes, Decision Trees, and Logistic Regression, the study showcases promising results. In particular, logistic regression and decision tree models exhibit impressive accuracy and Area Under the Curve (AUC) values of approximately 0.98, 0.97 and 0.95, 0.94, respectively. Given the pervasive nature of banking fraud in our digital society, the utilization of artificial intelligence algorithms for fraud detection stands as a critical and timely endeavor, promising enhanced security and trust in the financial ecosystem.","<method>unsupervised learning</method>, <method>Random Forest</method>, <method>K-Nearest Neighbor (KNN)</method>, <method>Naïve Bayes</method>, <method>Decision Trees</method>, <method>Logistic Regression</method>",<method>unsupervised learning</method><method>Random Forest</method><method>K-Nearest Neighbor (KNN)</method><method>Naïve Bayes</method><method>Decision Trees</method><method>Logistic Regression</method>
2024,https://openalex.org/W4391042406,Medicine,"A comparative analysis of machine learning techniques for aboveground biomass estimation: A case study of the Western Ghats, India","Accurate assessment of aboveground biomass (AGB) in tropical forests, particularly within a biodiversity hotspot, is vital for sustainable resource management and the preservation of ecosystems. However, estimating AGB in tropical forests is complex due to the diverse and intricate nature of vegetation, necessitating the integration of data from multiple sources. To tackle this challenge, our study utilized seven machine learning algorithms to analyze various combination of multisource datasets. We developed seven models/scenarios that incorporated Sentinel-1, Sentinel-2 as well as environmental factors such as topography, soil and climate to identify key variables for accurate estimation of AGB. For optimal performance, hyperparameters of the algorithms were fine-tuned through 10-fold cross-validation and their accuracy were assessed using the testing dataset. We found that the integrated model of satellite datasets, topography, climate, and soil variables exhibited the highest accuracy, where ensemble stacking, that combined multiple MLAs, proved to be reliable and best suited for predicting AGB (mean absolute error-3.97 Mg 0.1 ha−1, root mean square error-5.67 Mg 0.1 ha−1, and coefficient of determination - 0.82). Notably, the top predictor variables included Sentinel-2 bands (near infrared and green), soil properties (pH and soil organic carbon), and topography (elevation). The study emphasizes the significance of incorporating environmental variables (specifically topography and soil properties) along with Sentinel datasets to improve the accuracy of AGB estimation. This approach has the potential for broader applications, specifically in regions where vegetation productivity is governed by diverse environmental conditions.","<method>machine learning algorithms</method>, <method>ensemble stacking</method>",<method>ensemble stacking</method>
2024,https://openalex.org/W4391166814,Medicine,Identifying top ten predictors of type 2 diabetes through machine learning analysis of UK Biobank data,"Abstract The study aimed to identify the most predictive factors for the development of type 2 diabetes. Using an XGboost classification model, we projected type 2 diabetes incidence over a 10-year horizon. We deliberately minimized the selection of baseline factors to fully exploit the rich dataset from the UK Biobank. The predictive value of features was assessed using shap values, with model performance evaluated via Receiver Operating Characteristic Area Under the Curve, sensitivity, and specificity. Data from the UK Biobank, encompassing a vast population with comprehensive demographic and health data, was employed. The study enrolled 450,000 participants aged 40–69, excluding those with pre-existing diabetes. Among 448,277 participants, 12,148 developed type 2 diabetes within a decade. HbA1c emerged as the foremost predictor, followed by BMI, waist circumference, blood glucose, family history of diabetes, gamma-glutamyl transferase, waist-hip ratio, HDL cholesterol, age, and urate. Our XGboost model achieved a Receiver Operating Characteristic Area Under the Curve of 0.9 for 10-year type 2 diabetes prediction, with a reduced 10-feature model achieving 0.88. Easily measurable biological factors surpassed traditional risk factors like diet, physical activity, and socioeconomic status in predicting type 2 diabetes. Furthermore, high prediction accuracy could be maintained using just the top 10 biological factors, with additional ones offering marginal improvements. These findings underscore the significance of biological markers in type 2 diabetes prediction.","<method>XGboost classification model</method>, <method>shap values</method>",<method>XGboost classification model</method><method>shap values</method>
2024,https://openalex.org/W4391305160,Medicine,Protocol for metadata and image collection at diabetic foot ulcer clinics: enabling research in wound analytics and deep learning,"Abstract Background The escalating impact of diabetes and its complications, including diabetic foot ulcers (DFUs), presents global challenges in quality of life, economics, and resources, affecting around half a billion people. DFU healing is hindered by hyperglycemia-related issues and diverse diabetes-related physiological changes, necessitating ongoing personalized care. Artificial intelligence and clinical research strive to address these challenges by facilitating early detection and efficient treatments despite resource constraints. This study establishes a standardized framework for DFU data collection, introducing a dedicated case report form, a comprehensive dataset named Zivot with patient population clinical feature breakdowns and a baseline for DFU detection using this dataset and a UNet architecture. Results Following this protocol, we created the Zivot dataset consisting of 269 patients with active DFUs, and about 3700 RGB images and corresponding thermal and depth maps for the DFUs. The effectiveness of collecting a consistent and clean dataset was demonstrated using a bounding box prediction deep learning network that was constructed with EfficientNet as the feature extractor and UNet architecture. The network was trained on the Zivot dataset, and the evaluation metrics showed promising values of 0.79 and 0.86 for F1-score and mAP segmentation metrics. Conclusions This work and the Zivot database offer a foundation for further exploration of holistic and multimodal approaches to DFU research.","<method>UNet architecture</method>, <method>bounding box prediction deep learning network</method>, <method>EfficientNet</method>",<method>UNet architecture</method><method>EfficientNet</method>
2024,https://openalex.org/W4392693790,Medicine,BINDTI: A bi-directional Intention network for drug-target interaction identification based on attention mechanisms,"The identification of drug-target interactions (DTIs) is an essential step in drug discovery. In vitro experimental methods are expensive, laborious, and time-consuming. Deep learning has witnessed promising progress in DTI prediction. However, how to precisely represent drug and protein features is a major challenge for DTI prediction. Here, we developed an end-to-end DTI identification framework called BINDTI based on bi-directional Intention network. First, drug features are encoded with graph convolutional networks based on its 2D molecular graph obtained by its SMILES string. Next, protein features are encoded based on its amino acid sequence through a mixed model called ACmix, which integrates self-attention mechanism and convolution. Third, drug and target features are fused through bi-directional Intention network, which combines Intention and multi-head attention. Finally, unknown drug-target (DT) pairs are classified through multilayer perceptron based on the fused DT features. The results demonstrate that BINDTI greatly outperformed four baseline methods (i.e., CPI-GNN, TransfomerCPI, MolTrans, and IIFDTI) on the BindingDB, BioSNAP, DrugBank, and Human datasets. More importantly, it was more appropriate to predict new DTIs than the four baseline methods on imbalanced datasets. Ablation experimental results elucidated that both bi-directional Intention and ACmix could greatly advance DTI prediction. The fused feature visualization and case studies manifested that the predicted results by BINDTI were basically consistent with the true ones. We anticipate that the proposed BINDTI framework can find new low-cost drug candidates, improve drugs' virtual screening, and further facilitate drug repositioning as well as drug discovery. BINDTI is publicly available at <uri xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">https://github.com/plhhnu/BINDTI</uri> .","<method>graph convolutional networks</method>, <method>self-attention mechanism</method>, <method>convolution</method>, <method>ACmix</method>, <method>bi-directional Intention network</method>, <method>Intention</method>, <method>multi-head attention</method>, <method>multilayer perceptron</method>",<method>graph convolutional networks</method><method>self-attention mechanism</method><method>convolution</method><method>multi-head attention</method><method>multilayer perceptron</method>
2024,https://openalex.org/W4400006942,Medicine,Prediction of Alzheimer's disease progression within 6 years using speech: A novel approach leveraging language models,"Abstract INTRODUCTION Identification of individuals with mild cognitive impairment (MCI) who are at risk of developing Alzheimer's disease (AD) is crucial for early intervention and selection of clinical trials. METHODS We applied natural language processing techniques along with machine learning methods to develop a method for automated prediction of progression to AD within 6 years using speech. The study design was evaluated on the neuropsychological test interviews of n = 166 participants from the Framingham Heart Study, comprising 90 progressive MCI and 76 stable MCI cases. RESULTS Our best models, which used features generated from speech data, as well as age, sex, and education level, achieved an accuracy of 78.5% and a sensitivity of 81.1% to predict MCI‐to‐AD progression within 6 years. DISCUSSION The proposed method offers a fully automated procedure, providing an opportunity to develop an inexpensive, broadly accessible, and easy‐to‐administer screening tool for MCI‐to‐AD progression prediction, facilitating development of remote assessment. Highlights Voice recordings from neuropsychological exams coupled with basic demographics can lead to strong predictive models of progression to dementia from mild cognitive impairment. The study leveraged AI methods for speech recognition and processed the resulting text using language models. The developed AI‐powered pipeline can lead to fully automated assessment that could enable remote and cost‐effective screening and prognosis for Alzehimer's disease.","<method>natural language processing</method>, <method>machine learning</method>, <method>speech recognition</method>, <method>language models</method>",<method>machine learning</method>
2024,https://openalex.org/W4390884647,Medicine,Detecting COVID-19 in chest CT images based on several pre-trained models,"Abstract This paper explores the use of chest CT scans for early detection of COVID-19 and improved patient outcomes. The proposed method employs advanced techniques, including binary cross-entropy, transfer learning, and deep convolutional neural networks, to achieve accurate results. The COVIDx dataset, which contains 104,009 chest CT images from 1,489 patients, is used for a comprehensive analysis of the virus. A sample of 13,413 images from this dataset is categorised into two groups: 7,395 CT scans of individuals with confirmed COVID-19 and 6,018 images of normal cases. The study presents pre-trained transfer learning models such as ResNet (50), VGG (19), VGG (16), and Inception V3 to enhance the DCNN for classifying the input CT images. The binary cross-entropy metric is used to compare COVID-19 cases with normal cases based on predicted probabilities for each class. Stochastic Gradient Descent and Adam optimizers are employed to address overfitting issues. The study shows that the proposed pre-trained transfer learning models achieve accuracies of 99.07%, 98.70%, 98.55%, and 96.23%, respectively, in the validation set using the Adam optimizer. Therefore, the proposed work demonstrates the effectiveness of pre-trained transfer learning models in enhancing the accuracy of DCNNs for image classification. Furthermore, this paper provides valuable insights for the development of more accurate and efficient diagnostic tools for COVID-19.","<method>binary cross-entropy</method>, <method>transfer learning</method>, <method>deep convolutional neural networks</method>, <method>pre-trained transfer learning models</method>, <method>ResNet (50)</method>, <method>VGG (19)</method>, <method>VGG (16)</method>, <method>Inception V3</method>, <method>Stochastic Gradient Descent optimizer</method>, <method>Adam optimizer</method>",<method>transfer learning</method><method>deep convolutional neural networks</method><method>pre-trained transfer learning models</method><method>ResNet (50)</method><method>VGG (19)</method><method>VGG (16)</method><method>Inception V3</method><method>Stochastic Gradient Descent optimizer</method><method>Adam optimizer</method>
2024,https://openalex.org/W4391892547,Medicine,A Novel Early Detection and Prevention of Coronary Heart Disease Framework Using Hybrid Deep Learning Model and Neural Fuzzy Inference System,"Diabetes is the ""mother of all diseases"" as it affects multiple organs of body of an individual in some way. Its timely detection and management are critically important. Otherwise, the long run, it can cause several complications in a diabetic. Heart disease is one of the major complications of diabetes.This work proposed an Optimal Scrutiny Boosted Graph Convolutional LSTM (O-SBGC-LSTM), SBGC-LSTM enhanced by Eurygaster Optimization Algorithm (EOA) to tune hyperparameters for early prevention and detection of diabetes disease. This work proposed an Optimal Scrutiny Boosted Graph Convolutional LSTM (O-SBGC-LSTM), SBGC-LSTM enhanced by Eurygaster Optimization Algorithm (EOA) to tune hyperparameters for early prevention and detection of diabetes disease. This method not only captures discriminative features in spatial configuration and temporal dynamics but also explore the co-occurrence relationship between spatial and temporal domains. This method also presents a temporal hierarchical architecture to increase temporal receptive fields of top SBGC-LSTM layer, which boosts the ability to learn high-level semantic representation and significantly reduces computation cost. The performance of O-SBGC-LSTM was found overall to be satisfactory, reaching >98% accuracy in most studies. In comparison with classic machine learning approaches, proposed hybrid DL was found to achieve better performance in almost all studies that reported such comparison outcomes. Furthermore, prevention is better than cure. Additionally, employed fuzzy based inference techniques to enhance the prevention procedure using suggestion table.","<method>Optimal Scrutiny Boosted Graph Convolutional LSTM (O-SBGC-LSTM)</method>, <method>Scrutiny Boosted Graph Convolutional LSTM (SBGC-LSTM)</method>, <method>Eurygaster Optimization Algorithm (EOA)</method>, <method>fuzzy based inference techniques</method>",<method>fuzzy based inference techniques</method>
2024,https://openalex.org/W4392195911,Medicine,<scp>CerviFormer</scp>: A pap smear‐based cervical cancer classification method using cross‐attention and latent transformer,"Abstract Cervical cancer is one of the primary causes of death in women. It should be diagnosed early and treated according to the best medical advice, similar to other diseases, to ensure that its effects are as minimal as possible. Pap smear images are one of the most constructive ways for identifying this type of cancer. This study proposes a cross‐attention‐based Transfomer approach for the reliable classification of cervical cancer in pap smear images. In this study, we propose the CerviFormer‐a model that depends on the Transformers and thereby requires minimal architectural assumptions about the size of the input data. The model uses a cross‐attention technique to repeatedly consolidate the input data into a compact latent Transformer module, which enables it to manage very large‐scale inputs. We evaluated our model on two publicly available pap smear datasets. For 3‐state classification on the Sipakmed data, the model achieved an accuracy of 96.67%. For 2‐state classification on the Herlev data, the model achieved an accuracy of 94.57%. Experimental results on two publicly accessible datasets demonstrate that the proposed method achieves competitive results when compared to contemporary approaches. The proposed method brings forth a comprehensive classification model to detect cervical cancer in pap smear images. This may aid medical professionals in providing better cervical cancer treatment, consequently, enhancing the overall effectiveness of the entire testing process.","<method>cross-attention-based Transformer</method>, <method>Transformers</method>",<method>cross-attention-based Transformer</method><method>Transformers</method>
2024,https://openalex.org/W4392915169,Medicine,Unified deep learning models for enhanced lung cancer prediction with ResNet-50–101 and EfficientNet-B3 using DICOM images,"Abstract Significant advancements in machine learning algorithms have the potential to aid in the early detection and prevention of cancer, a devastating disease. However, traditional research methods face obstacles, and the amount of cancer-related information is rapidly expanding. The authors have developed a helpful support system using three distinct deep-learning models, ResNet-50, EfficientNet-B3, and ResNet-101, along with transfer learning, to predict lung cancer, thereby contributing to health and reducing the mortality rate associated with this condition. This offer aims to address the issue effectively. Using a dataset of 1,000 DICOM lung cancer images from the LIDC-IDRI repository, each image is classified into four different categories. Although deep learning is still making progress in its ability to analyze and understand cancer data, this research marks a significant step forward in the fight against cancer, promoting better health outcomes and potentially lowering the mortality rate. The Fusion Model, like all other models, achieved 100% precision in classifying Squamous Cells. The Fusion Model and ResNet-50 achieved a precision of 90%, closely followed by EfficientNet-B3 and ResNet-101 with slightly lower precision. To prevent overfitting and improve data collection and planning, the authors implemented a data extension strategy. The relationship between acquiring knowledge and reaching specific scores was also connected to advancing and addressing the issue of imprecise accuracy, ultimately contributing to advancements in health and a reduction in the mortality rate associated with lung cancer.","<method>ResNet-50</method>, <method>EfficientNet-B3</method>, <method>ResNet-101</method>, <method>transfer learning</method>, <method>Fusion Model</method>",<method>ResNet-50</method><method>EfficientNet-B3</method><method>ResNet-101</method><method>transfer learning</method>
2024,https://openalex.org/W4390490875,Medicine,More Robots are Coming: Large Multimodal Models (ChatGPT) can Solve Visually Diverse Images of Parsons Problems,"Large language models are reshaping computing education. Based on recent research, these models explain code better than students, answer multiple choice questions at or above the class average, and generate code that can pass automated tests in introductory courses. In response to these capabilities, instructors have quickly adjusted their courses and assessment methods to align with shifting learning goals and the increased risk of academic integrity issues. While some scholars have advocated for the integration of visual problems as a safeguard against the capabilities of language models, new multimodal models now have vision and language capabilities that may allow them to analyze and solve visual problems. In this paper, we compare the large multimodal model (LMMs) GPT-4V with Bard, an LLM that uses Google Lens for text recognition. We find that LMMs, which have learned both pixel features (from images) and text features (from prompts) in the same embedding space, performed substantially better than Bard which uses a piecemeal approach. With a specific focus on Parsons problems presented across diverse visual representations, our results show that GPT-4V solved 96.7% these visual problems, struggling minimally with a single Parsons problem. Conversely, Bard performed poorly by only solving 69.2% of problems, struggling with common issues like hallucinations and refusals. These findings suggest that merely transitioning to visual programming problems might not be a panacea to issues of academic integrity in the generative AI era.","<method>large language models (LLMs)</method>, <method>large multimodal models (LMMs)</method>",<method>large multimodal models (LMMs)</method>
2024,https://openalex.org/W4390737642,Medicine,Artificial intelligence for diabetic retinopathy detection: A systematic review,"The incidence of diabetic retinopathy (DR) has increased at a rapid pace in recent years all over the world. Diabetic eye illness is identified as one of the most common reasons for vision loss among people. To properly manage DR, there has been immense research and exploration of state-of-the-art methods using artificial intelligence (AI) enabled models. Specifically, AI-empowered models combine multiple machine learning (ML) and deep learning (DL) based algorithms to improve the performance of the developed system architectures that are commercially utilized for the detection of DR disease. However, these models still exhibit several limitations, such as computational complexity, low accuracy in DR stage detection due to class imbalance, more time consumption, and high maintenance cost. To overcome these limits, a more advanced model is required to accurately predict the DR stage in the initial stages. For example, the identification of DR disease in the initial stage helps the ophthalmologist to make an accurate and safe diagnosis, and thereby, eyesight-related issues may be treated more effectively. This study conducted a systematic literature review (SLR) to provide a detailed discussion of the background of diabetic retinopathy, its major causes, challenges faced by ophthalmologists in DR detection, and possible solutions for identifying DR in the initial stage. Also, the SLR provides an in-depth analysis of the existing state-of-the-art techniques and system models used in DR diagnosis based on AI, ML, and recently developed DL-based approaches. Furthermore, this present survey would be helpful for the research community to receive information on the recent approaches used for DR identification along with their significant challenges and limitations.","<method>artificial intelligence (AI) enabled models</method>, <method>machine learning (ML) based algorithms</method>, <method>deep learning (DL) based algorithms</method>",No methods remaining
2024,https://openalex.org/W4390812034,Medicine,The Utility of AI in Writing a Scientific Review Article on the Impacts of COVID-19 on Musculoskeletal Health,"Abstract Purpose of Review There were two primary purposes to our reviews. First, to provide an update to the scientific community about the impacts of COVID-19 on musculoskeletal health. Second, was to determine the value of using a large language model, ChatGPT 4.0, in the process of writing a scientific review article. To accomplish these objectives, we originally set out to write three review articles on the topic using different methods to produce the initial drafts of the review articles. The first review article was written in the traditional manner by humans, the second was to be written exclusively using ChatGPT (AI-only or AIO), and the third approach was to input the outline and references selected by humans from approach 1 into ChatGPT, using the AI to assist in completing the writing (AI-assisted or AIA). All review articles were extensively fact-checked and edited by all co-authors leading to the final drafts of the manuscripts, which were significantly different from the initial drafts. Recent Findings Unfortunately, during this process, it became clear that approach 2 was not feasible for a very recent topic like COVID-19 as at the time, ChatGPT 4.0 had a cutoff date of September 2021 and all articles published after this date had to be provided to ChatGPT, making approaches 2 and 3 virtually identical. Therefore, only two approaches and two review articles were written (human and AI-assisted). Here we found that the human-only approach took less time to complete than the AI-assisted approach. This was largely due to the number of hours required to fact-check and edit the AI-assisted manuscript. Of note, the AI-assisted approach resulted in inaccurate attributions of references (about 20%) and had a higher similarity index suggesting an increased risk of plagiarism. Summary The main aim of this project was to determine whether the use of AI could improve the process of writing a scientific review article. Based on our experience, with the current state of technology, it would not be advised to solely use AI to write a scientific review article, especially on a recent topic.","<method>large language model, ChatGPT 4.0</method>","<method>large language model, ChatGPT 4.0</method>"
2024,https://openalex.org/W4390959437,Medicine,Machine learning model (RG-DMML) and ensemble algorithm for prediction of students’ retention and graduation in education,"Automated prediction of students' retention and graduation in education using advanced analytical methods such as artificial intelligence (AI), has recently attracted the attention of educators, both in theory and in practice. Whereas invaluable insights and theories for measuring and testing the topic have been proposed, most of the existing methods do not technically highlight the non-trivial factors behind the renowned challenges and attrition. To this effect, by making use of two categories of data collected in a higher education setting about students (i) retention (n = 52262) and (ii) graduation (n = 53639); this study proposes a machine learning model - RG-DMML (retention and graduation data mining and machine learning) and ensemble algorithm for prediction of students' retention and graduation status in education. This was done by training and testing key features that are technically deemed suitable for measuring the constructs (retention and graduation), such as (i) the Average grade of the previous high school, and (ii) the Entry/admission score. The proposed model (RG-DMML) is designed based on the cross industry standard process for data mining (CRISP-DM) methodology, implemented using supervised machine learning technique such as K-Nearest Neighbor (KNN), and validated using the k-fold cross-validation method. The results show that the executed model and algorithm based on the Bagging method and 10-fold cross-validation are efficient and effective for predicting the student's retention and graduation status, with Precision (retention = 0.909, graduation = 0.822), Recall (retention = 1.000, graduation = 0.957), Accuracy (retention = 0.909, graduation = 0.817), F1-Score (retention = 0.952, graduation = 0.885) showing significant high accuracy levels or performance rate, and low Error-rate (retention = 0.090, graduation = 0.182), respectively. In addition, by considering the individual features selected through the Wrapper method in predicting the outputs, the proposed model proved more effective for predicting the students' retention status in comparison to the graduation data. The implications of the models' output and factors that impact the effective prediction or identification of at-risk students, e.g., for timely intervention, counselling, decision-making, and sustainable educational practice are empirically discussed in the study.","<method>machine learning model - RG-DMML (retention and graduation data mining and machine learning)</method>, <method>ensemble algorithm</method>, <method>cross industry standard process for data mining (CRISP-DM) methodology</method>, <method>supervised machine learning technique</method>, <method>K-Nearest Neighbor (KNN)</method>, <method>k-fold cross-validation method</method>, <method>Bagging method</method>, <method>Wrapper method</method>",<method>ensemble algorithm</method><method>supervised machine learning technique</method><method>K-Nearest Neighbor (KNN)</method><method>Wrapper method</method>
2024,https://openalex.org/W4391542772,Medicine,Deep learning algorithm-based multimodal MRI radiomics and pathomics data improve prediction of bone metastases in primary prostate cancer,"Abstract Purpose Bone metastasis is a significant contributor to morbidity and mortality in advanced prostate cancer, and early diagnosis is challenging due to its insidious onset. The use of machine learning to obtain prognostic information from pathological images has been highlighted. However, there is a limited understanding of the potential of early prediction of bone metastasis through the feature combination method from various sources. This study presents a method of integrating multimodal data to enhance the feasibility of early diagnosis of bone metastasis in prostate cancer. Methods and materials Overall, 211 patients diagnosed with prostate cancer (PCa) at Gansu Provincial Hospital between January 2017 and February 2023 were included in this study. The patients were randomized (8:2) into a training group ( n = 169) and a validation group ( n = 42). The region of interest (ROI) were segmented from the three magnetic resonance imaging (MRI) sequences (T2WI, DWI, and ADC), and pathological features were extracted from tissue sections (hematoxylin and eosin [H&amp;E] staining, 10 × 20). A deep learning (DL) model using ResNet 50 was employed to extract deep transfer learning (DTL) features. The least absolute shrinkage and selection operator (LASSO) regression method was utilized for feature selection, feature construction, and reducing feature dimensions. Different machine learning classifiers were used to build predictive models. The performance of the models was evaluated using receiver operating characteristic curves. The net clinical benefit was assessed using decision curve analysis (DCA). The goodness of fit was evaluated using calibration curves. A joint model nomogram was eventually developed by combining clinically independent risk factors. Results The best prediction models based on DTL and pathomics features showed area under the curve (AUC) values of 0.89 (95% confidence interval [CI], 0.799–0.989) and 0.85 (95% CI, 0.714–0.989), respectively. The AUC for the best prediction model based on radiomics features and combining radiomics features, DTL features, and pathomics features were 0.86 (95% CI, 0.735–0.979) and 0.93 (95% CI, 0.854–1.000), respectively. Based on DCA and calibration curves, the model demonstrated good net clinical benefit and fit. Conclusion Multimodal radiomics and pathomics serve as valuable predictors of the risk of bone metastases in patients with primary PCa.","<method>deep learning (DL) model using ResNet 50</method>, <method>deep transfer learning (DTL) features</method>, <method>least absolute shrinkage and selection operator (LASSO) regression method</method>, <method>machine learning classifiers</method>",<method>deep learning (DL) model using ResNet 50</method><method>deep transfer learning (DTL) features</method><method>least absolute shrinkage and selection operator (LASSO) regression method</method>
2024,https://openalex.org/W4391814741,Medicine,Explainable hybrid vision transformers and convolutional network for multimodal glioma segmentation in brain MRI,"Abstract Accurate localization of gliomas, the most common malignant primary brain cancer, and its different sub-region from multimodal magnetic resonance imaging (MRI) volumes are highly important for interventional procedures. Recently, deep learning models have been applied widely to assist automatic lesion segmentation tasks for neurosurgical interventions. However, these models are often complex and represented as “black box” models which limit their applicability in clinical practice. This article introduces new hybrid vision Transformers and convolutional neural networks for accurate and robust glioma segmentation in Brain MRI scans. Our proposed method, TransXAI, provides surgeon-understandable heatmaps to make the neural networks transparent. TransXAI employs a post-hoc explanation technique that provides visual interpretation after the brain tumor localization is made without any network architecture modifications or accuracy tradeoffs. Our experimental findings showed that TransXAI achieves competitive performance in extracting both local and global contexts in addition to generating explainable saliency maps to help understand the prediction of the deep network. Further, visualization maps are obtained to realize the flow of information in the internal layers of the encoder-decoder network and understand the contribution of MRI modalities in the final prediction. The explainability process could provide medical professionals with additional information about the tumor segmentation results and therefore aid in understanding how the deep learning model is capable of processing MRI data successfully. Thus, it enables the physicians’ trust in such deep learning systems towards applying them clinically. To facilitate TransXAI model development and results reproducibility, we will share the source code and the pre-trained models after acceptance at https://github.com/razeineldin/TransXAI .","<method>vision Transformers</method>, <method>convolutional neural networks</method>, <method>post-hoc explanation technique</method>, <method>encoder-decoder network</method>",<method>vision Transformers</method><method>convolutional neural networks</method><method>post-hoc explanation technique</method><method>encoder-decoder network</method>
2024,https://openalex.org/W4392231575,Medicine,Cardiologist-level interpretable knowledge-fused deep neural network for automatic arrhythmia diagnosis,"Abstract Background Long-term monitoring of Electrocardiogram (ECG) recordings is crucial to diagnose arrhythmias. Clinicians can find it challenging to diagnose arrhythmias, and this is a particular issue in more remote and underdeveloped areas. The development of digital ECG and AI methods could assist clinicians who need to diagnose arrhythmias outside of the hospital setting. Methods We constructed a large-scale Chinese ECG benchmark dataset using data from 272,753 patients collected from January 2017 to December 2021. The dataset contains ECG recordings from all common arrhythmias present in the Chinese population. Several experienced cardiologists from Shanghai First People’s Hospital labeled the dataset. We then developed a deep learning-based multi-label interpretable diagnostic model from the ECG recordings. We utilized Accuracy, F1 score and AUC-ROC to compare the performance of our model with that of the cardiologists, as well as with six comparison models, using testing and hidden data sets. Results The results show that our approach achieves an F1 score of 83.51%, an average AUC ROC score of 0.977, and 93.74% mean accuracy for 6 common arrhythmias. Results from the hidden dataset demonstrate the performance of our approach exceeds that of cardiologists. Our approach also highlights the diagnostic process. Conclusions Our diagnosis system has superior diagnostic performance over that of clinicians. It also has the potential to help clinicians rapidly identify abnormal regions on ECG recordings, thus improving efficiency and accuracy of clinical ECG diagnosis in China. This approach could therefore potentially improve the productivity of out-of-hospital ECG diagnosis and provides a promising prospect for telemedicine.",<method>deep learning-based multi-label interpretable diagnostic model</method>,No methods remaining
2024,https://openalex.org/W4392391366,Medicine,Prediction of Effectiveness and Toxicities of Immune Checkpoint Inhibitors Using Real-World Patient Data,"PURPOSE Although immune checkpoint inhibitors (ICIs) have improved outcomes in certain patients with cancer, they can also cause life-threatening immunotoxicities. Predicting immunotoxicity risks alongside response could provide a personalized risk-benefit profile, inform therapeutic decision making, and improve clinical trial cohort selection. We aimed to build a machine learning (ML) framework using routine electronic health record (EHR) data to predict hepatitis, colitis, pneumonitis, and 1-year overall survival. METHODS Real-world EHR data of more than 2,200 patients treated with ICI through December 31, 2018, were used to develop predictive models. Using a prediction time point of ICI initiation, a 1-year prediction time window was applied to create binary labels for the four outcomes for each patient. Feature engineering involved aggregating laboratory measurements over appropriate time windows (60-365 days). Patients were randomly partitioned into training (80%) and test (20%) sets. Random forest classifiers were developed using a rigorous model development framework. RESULTS The patient cohort had a median age of 63 years and was 61.8% male. Patients predominantly had melanoma (37.8%), lung cancer (27.3%), or genitourinary cancer (16.4%). They were treated with PD-1 (60.4%), PD-L1 (9.0%), and CTLA-4 (19.7%) ICIs. Our models demonstrate reasonably strong performance, with AUCs of 0.739, 0.729, 0.755, and 0.752 for the pneumonitis, hepatitis, colitis, and 1-year overall survival models, respectively. Each model relies on an outcome-specific feature set, though some features are shared among models. CONCLUSION To our knowledge, this is the first ML solution that assesses individual ICI risk-benefit profiles based predominantly on routine structured EHR data. As such, use of our ML solution will not require additional data collection or documentation in the clinic.","<method>machine learning (ML) framework</method>, <method>random forest classifiers</method>",<method>random forest classifiers</method>
2024,https://openalex.org/W4392694180,Medicine,NSGA-II-DL: Metaheuristic Optimal Feature Selection With Deep Learning Framework for HER2 Classification in Breast Cancer,"Immunohistochemistry (IHC) slides are graded for breast cancer based on visual markers and morphological characteristics of stained membrane regions. The usage of whole slide images (WSIs) from histology in digital pathology algorithms for computer-assisted evaluations has increased recently. Human epidermal growth factor receptor 2 (HER2)-stained microscopic images are challenging, time-consuming, and error-prone to evaluate manually. This is due to different staining, overlapped regions, and huge, non-homogeneous slides. Additionally, the classification of HER2 images by the selection of fundamental features must be used to capture the difficult elements of the images, such as the irregular cell structure and the coloring of the tissue of the cells. To solve the above problems, a transfer learning model-based, trainable metaheuristic method for choosing the best features is suggested in this paper. Moreover, the suggested model is efficient in reducing model complexity and computational costs as well as avoiding overfitting. The four main components of the proposed cascaded design are: (a) converting WSIs to tiled images and enhancing contrast with fast local Laplacian filtering (FlLpF); (b) extracting features with a ResNet50 CNN technique based on transfer learning; (c) selecting the most informative features with the help of a non-dominated sorting genetic algorithm (NSGA-II) optimizer; and (d) using a support vector machine (SVM) to classify HER2 scores. Results from the HER2SC and HER2GAN datasets show that the suggested model is superior to other methods already in use, with 94.4% accuracy, 93.71% precision, 98.07% specificity, 93.83% sensitivity, and a 93.71% F1-score for the HER2SC dataset being achieved.","<method>transfer learning</method>, <method>ResNet50 CNN</method>, <method>non-dominated sorting genetic algorithm (NSGA-II)</method>, <method>support vector machine (SVM)</method>",<method>transfer learning</method><method>ResNet50 CNN</method><method>non-dominated sorting genetic algorithm (NSGA-II)</method><method>support vector machine (SVM)</method>
2024,https://openalex.org/W4392926377,Medicine,Generalizability of machine learning in predicting antimicrobial resistance in E. coli: a multi-country case study in Africa,"Abstract Background Antimicrobial resistance (AMR) remains a significant global health threat particularly impacting low- and middle-income countries (LMICs). These regions often grapple with limited healthcare resources and access to advanced diagnostic tools. Consequently, there is a pressing need for innovative approaches that can enhance AMR surveillance and management. Machine learning (ML) though underutilized in these settings, presents a promising avenue. This study leverages ML models trained on whole-genome sequencing data from England, where such data is more readily available, to predict AMR in E . coli , targeting key antibiotics such as ciprofloxacin, ampicillin, and cefotaxime. A crucial part of our work involved the validation of these models using an independent dataset from Africa, specifically from Uganda, Nigeria, and Tanzania, to ascertain their applicability and effectiveness in LMICs. Results Model performance varied across antibiotics. The Support Vector Machine excelled in predicting ciprofloxacin resistance (87% accuracy, F1 Score: 0.57), Light Gradient Boosting Machine for cefotaxime (92% accuracy, F1 Score: 0.42), and Gradient Boosting for ampicillin (58% accuracy, F1 Score: 0.66). In validation with data from Africa, Logistic Regression showed high accuracy for ampicillin (94%, F1 Score: 0.97), while Random Forest and Light Gradient Boosting Machine were effective for ciprofloxacin (50% accuracy, F1 Score: 0.56) and cefotaxime (45% accuracy, F1 Score:0.54), respectively. Key mutations associated with AMR were identified for these antibiotics. Conclusion As the threat of AMR continues to rise, the successful application of these models, particularly on genomic datasets from LMICs, signals a promising avenue for improving AMR prediction to support large AMR surveillance programs. This work thus not only expands our current understanding of the genetic underpinnings of AMR but also provides a robust methodological framework that can guide future research and applications in the fight against AMR.","<method>Support Vector Machine</method>, <method>Light Gradient Boosting Machine</method>, <method>Gradient Boosting</method>, <method>Logistic Regression</method>, <method>Random Forest</method>",<method>Support Vector Machine</method><method>Light Gradient Boosting Machine</method><method>Gradient Boosting</method><method>Logistic Regression</method><method>Random Forest</method>
2024,https://openalex.org/W4393260925,Medicine,Accurate and interpretable drug-drug interaction prediction enabled by knowledge subgraph learning,"Abstract Background Discovering potential drug-drug interactions (DDIs) is a long-standing challenge in clinical treatments and drug developments. Recently, deep learning techniques have been developed for DDI prediction. However, they generally require a huge number of samples, while known DDIs are rare. Methods In this work, we present KnowDDI, a graph neural network-based method that addresses the above challenge. KnowDDI enhances drug representations by adaptively leveraging rich neighborhood information from large biomedical knowledge graphs. Then, it learns a knowledge subgraph for each drug-pair to interpret the predicted DDI, where each of the edges is associated with a connection strength indicating the importance of a known DDI or resembling strength between a drug-pair whose connection is unknown. Thus, the lack of DDIs is implicitly compensated by the enriched drug representations and propagated drug similarities. Results Here we show the evaluation results of KnowDDI on two benchmark DDI datasets. Results show that KnowDDI obtains the state-of-the-art prediction performance with better interpretability. We also find that KnowDDI suffers less than existing works given a sparser knowledge graph. This indicates that the propagated drug similarities play a more important role in compensating for the lack of DDIs when the drug representations are less enriched. Conclusions KnowDDI nicely combines the efficiency of deep learning techniques and the rich prior knowledge in biomedical knowledge graphs. As an original open-source tool, KnowDDI can help detect possible interactions in a broad range of relevant interaction prediction tasks, such as protein-protein interactions, drug-target interactions and disease-gene interactions, eventually promoting the development of biomedicine and healthcare.","<method>deep learning techniques</method>, <method>graph neural network-based method</method>",<method>graph neural network-based method</method>
2024,https://openalex.org/W4393276564,Medicine,Artificial intelligence–based assessment of built environment from Google Street View and coronary artery disease prevalence,"Abstract Background and Aims Built environment plays an important role in the development of cardiovascular disease. Tools to evaluate the built environment using machine vision and informatic approaches have been limited. This study aimed to investigate the association between machine vision–based built environment and prevalence of cardiometabolic disease in US cities. Methods This cross-sectional study used features extracted from Google Street View (GSV) images to measure the built environment and link them with prevalence of coronary heart disease (CHD). Convolutional neural networks, linear mixed-effects models, and activation maps were utilized to predict health outcomes and identify feature associations with CHD at the census tract level. The study obtained 0.53 million GSV images covering 789 census tracts in seven US cities (Cleveland, OH; Fremont, CA; Kansas City, MO; Detroit, MI; Bellevue, WA; Brownsville, TX; and Denver, CO). Results Built environment features extracted from GSV using deep learning predicted 63% of the census tract variation in CHD prevalence. The addition of GSV features improved a model that only included census tract-level age, sex, race, income, and education or composite indices of social determinant of health. Activation maps from the features revealed a set of neighbourhood features represented by buildings and roads associated with CHD prevalence. Conclusions In this cross-sectional study, the prevalence of CHD was associated with built environment factors derived from GSV through deep learning analysis, independent of census tract demographics. Machine vision–enabled assessment of the built environment could potentially offer a more precise approach to identify at-risk neighbourhoods, thereby providing an efficient avenue to address and reduce cardiovascular health disparities in urban environments.","<method>convolutional neural networks</method>, <method>linear mixed-effects models</method>, <method>activation maps</method>",<method>convolutional neural networks</method><method>activation maps</method>
2024,https://openalex.org/W4394581105,Medicine,Machine learning-based detection of acute psychosocial stress from body posture and movements,"Abstract Investigating acute stress responses is crucial to understanding the underlying mechanisms of stress. Current stress assessment methods include self-reports that can be biased and biomarkers that are often based on complex laboratory procedures. A promising additional modality for stress assessment might be the observation of body movements, which are affected by negative emotions and threatening situations. In this paper, we investigated the relationship between acute psychosocial stress induction and body posture and movements. We collected motion data from N = 59 individuals over two studies ( Pilot Study : N = 20, Main Study : N = 39) using inertial measurement unit (IMU)-based motion capture suits. In both studies, individuals underwent the Trier Social Stress Test (TSST) and a stress-free control condition (friendly-TSST; f-TSST) in randomized order. Our results show that acute stress induction leads to a reproducible freezing behavior, characterized by less overall motion as well as more and longer periods of no movement. Based on these data, we trained machine learning pipelines to detect acute stress solely from movement information, achieving an accuracy of $${75.0 \pm 17.7}{\%}$$ <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""> <mml:mrow> <mml:mrow> <mml:mn>75.0</mml:mn> <mml:mo>±</mml:mo> <mml:mn>17.7</mml:mn> </mml:mrow> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> ( Pilot Study ) and $${73.4 \pm 7.7}{\%}$$ <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""> <mml:mrow> <mml:mrow> <mml:mn>73.4</mml:mn> <mml:mo>±</mml:mo> <mml:mn>7.7</mml:mn> </mml:mrow> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> ( Main Study ). This, for the first time, suggests that body posture and movements can be used to detect whether individuals are exposed to acute psychosocial stress. While more studies are needed to further validate our approach, we are convinced that motion information can be a valuable extension to the existing biomarkers and can help to obtain a more holistic picture of the human stress response. Our work is the first to systematically explore the use of full-body body posture and movement to gain novel insights into the human stress response and its effects on the body and mind.",<method>machine learning pipelines</method>,No methods remaining
2024,https://openalex.org/W4394693547,Medicine,Urban morphology clustering analysis to identify heat-prone neighbourhoods in cities,"Exposure to heat is a major health concern to urban populations. Cities aim to reduce outdoor thermal stress by adapting the built environment, but the spatial heterogeneity within cities makes it difficult to establish universal mitigation strategies. We present a methodology that identifies the hottest neighbourhoods in a city and links them to underlying patterns in urban form and function, to derive heat mitigation measures for individual neighbourhoods according to their characteristics, mitigation potential, and average surface temperature. The method applies k-means clustering and is applicable to any city using available datasets on surface cover and building morphology, as well as globally available satellite measurements of surface temperatures. Here, we present a heat-mitigation analysis for the city of Zurich. The clustering differentiates seven neighbourhood types, including two types of residential areas, modern neighbourhoods with high-rise buildings, historical districts, and industrial zones. The hottest temperatures are in neighbourhoods with extensive impervious ground cover such as railway tracks and airport parking. Surface temperatures strongly correlate with impervious surface cover and vegetation cover for all neighbourhoods, with building cover only for non-industrial built neighbourhoods, and with sky-view factor for all neighbourhoods except those with large vegetation cover. Historical, modern, and industrial neighbourhoods are particular heat-prone, and increasing vegetation for evaporative cooling is a suggested mitigation strategy for all. Modern and industrial areas could benefit from shading through increase of tree cover, while historical centres may adapt vertical greening as suitable heat mitigation strategy.",<method>k-means clustering</method>,<method>k-means clustering</method>
2024,https://openalex.org/W4394767609,Medicine,Cardiac Arrhythmia Classification Using Advanced Deep Learning Techniques on Digitized ECG Datasets,"ECG classification or heartbeat classification is an extremely valuable tool in cardiology. Deep learning-based techniques for the analysis of ECG signals assist human experts in the timely diagnosis of cardiac diseases and help save precious lives. This research aims at digitizing a dataset of images of ECG records into time series signals and then applying deep learning (DL) techniques on the digitized dataset. State-of-the-art DL techniques are proposed for the classification of the ECG signals into different cardiac classes. Multiple DL models, including a convolutional neural network (CNN), a long short-term memory (LSTM) network, and a self-supervised learning (SSL)-based model using autoencoders are explored and compared in this study. The models are trained on the dataset generated from ECG plots of patients from various healthcare institutes in Pakistan. First, the ECG images are digitized, segmenting the lead II heartbeats, and then the digitized signals are passed to the proposed deep learning models for classification. Among the different DL models used in this study, the proposed CNN model achieves the highest accuracy of ∼92%. The proposed model is highly accurate and provides fast inference for real-time and direct monitoring of ECG signals that are captured from the electrodes (sensors) placed on different parts of the body. Using the digitized form of ECG signals instead of images for the classification of cardiac arrhythmia allows cardiologists to utilize DL models directly on ECG signals from an ECG machine for the real-time and accurate monitoring of ECGs.","<method>deep learning (DL) techniques</method>, <method>convolutional neural network (CNN)</method>, <method>long short-term memory (LSTM) network</method>, <method>self-supervised learning (SSL)-based model using autoencoders</method>",<method>convolutional neural network (CNN)</method><method>long short-term memory (LSTM) network</method><method>self-supervised learning (SSL)-based model using autoencoders</method>
2024,https://openalex.org/W4396832329,Medicine,Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis,"Today's AI systems for medical decision support often succeed on benchmark datasets in research papers but fail in real-world deployment. This work focuses on the decision making of sepsis, an acute life-threatening systematic infection that requires an early diagnosis with high uncertainty from the clinician. Our aim is to explore the design requirements for AI systems that can support clinical experts in making better decisions for the early diagnosis of sepsis. The study begins with a formative study investigating why clinical experts abandon an existing AI-powered Sepsis predictive module in their electrical health record (EHR) system. We argue that a human-centered AI system needs to support human experts in the intermediate stages of a medical decision-making process (e.g., generating hypotheses or gathering data), instead of focusing only on the final decision. Therefore, we build SepsisLab based on a state-of-the-art AI algorithm and extend it to predict the future projection of sepsis development, visualize the prediction uncertainty, and propose actionable suggestions (i.e., which additional laboratory tests can be collected) to reduce such uncertainty. Through heuristic evaluation with six clinicians using our prototype system, we demonstrate that SepsisLab enables a promising human-AI collaboration paradigm for the future of AI-assisted sepsis diagnosis and other high-stakes medical decision making.",<method>state-of-the-art AI algorithm</method>,No methods remaining
2024,https://openalex.org/W4400429759,Medicine,Deep learning for lungs cancer detection: a review,"Abstract Although lung cancer has been recognized to be the deadliest type of cancer, a good prognosis and efficient treatment depend on early detection. Medical practitioners’ burden is reduced by deep learning techniques, especially Deep Convolutional Neural Networks (DCNN), which are essential in automating the diagnosis and classification of diseases. In this study, we use a variety of medical imaging modalities, including X-rays, WSI, CT scans, and MRI, to thoroughly investigate the use of deep learning techniques in the field of lung cancer diagnosis and classification. This study conducts a comprehensive Systematic Literature Review (SLR) using deep learning techniques for lung cancer research, providing a comprehensive overview of the methodology, cutting-edge developments, quality assessments, and customized deep learning approaches. It presents data from reputable journals and concentrates on the years 2015–2024. Deep learning techniques solve the difficulty of manually identifying and selecting abstract features from lung cancer images. This study includes a wide range of deep learning methods for classifying lung cancer but focuses especially on the most popular method, the Convolutional Neural Network (CNN). CNN can achieve maximum accuracy because of its multi-layer structure, automatic learning of weights, and capacity to communicate local weights. Various algorithms are shown with performance measures like precision, accuracy, specificity, sensitivity, and AUC; CNN consistently shows the greatest accuracy. The findings highlight the important contributions of DCNN in improving lung cancer detection and classification, making them an invaluable resource for researchers looking to gain a greater knowledge of deep learning’s function in medical applications.","<method>Deep Convolutional Neural Networks (DCNN)</method>, <method>deep learning techniques</method>, <method>Convolutional Neural Network (CNN)</method>",<method>Deep Convolutional Neural Networks (DCNN)</method><method>Convolutional Neural Network (CNN)</method>
2024,https://openalex.org/W4405128863,Medicine,Machine Learning in Public Health Forecasting and Monitoring the Zika Virus,"The Zika virus is a severe public health threat all across the world, owing to its spreading mechanism through Aedes mosquitoes and its ability to result in extreme neurological diseases, which include the congenital Zika syndrome and the Guillain-Barré syndrome, amongst others. Conventional monitoring techniques often fail because many asymptomatic cases render early diagnosis challenging. Machine learning (ML) techniques can be seen as a constructive development in addressing this challenge, which entails predicting and tracking the spread of diseases such as Zika through extensive and complex datasets. Data analytic ML systems also enhance early warning systems and situational uplift by using data from social media, climate history, and genetics. This helps reasonably to predict the mosquito population biologically and the environmental factors that favor the spread of the virus for a more practical approach from the public health sector. Over and above, some issues are still pending, especially regarding the quality of data, understanding the models and how to apply such models within the current health systems. These factors must be solved to implement ML successfully in surveillance practice. This review provides an overview of the issue, stating the potential of machine learning applications in the development of public health, whose actions focus on Zika and other diseases transmitted by vectors.","<method>Machine learning (ML) techniques</method>, <method>Data analytic ML systems</method>",No methods remaining
2024,https://openalex.org/W4390483004,Medicine,Population-Specific Glucose Prediction in Diabetes Care With Transformer-Based Deep Learning on the Edge,"Leveraging continuous glucose monitoring (CGM) systems, real-time blood glucose (BG) forecasting is essential for proactive interventions, playing a crucial role in enhancing the management of type 1 diabetes (T1D) and type 2 diabetes (T2D). However, developing a model generalized to a population and subsequently embedding it within a microchip of a wearable device presents significant technical challenges. Furthermore, the domain of BG prediction in T2D remains under-explored in the literature. In light of this, we propose a population-specific BG prediction model, leveraging the capabilities of the temporal fusion Transformer (TFT) to adjust predictions based on personal demographic data. Then the trained model is embedded within a system-on-chip, integral to our low-power and low-cost customized wearable device. This device seamlessly communicates with CGM systems through Bluetooth and provides timely BG predictions using edge computing. When evaluated on two publicly available clinical datasets with a total of 124 participants with T1D or T2D, the embedded TFT model consistently demonstrated superior performance, achieving the lowest prediction errors when compared with a range of machine learning baseline methods. Executing the TFT model on our wearable device requires minimal memory and power consumption, enabling continuous decision support for more than 51 days on a single Li-Poly battery charge. These findings demonstrate the significant potential of the proposed TFT model and wearable device in enhancing the quality of life for people with diabetes and effectively addressing real-world challenges.","<method>temporal fusion Transformer (TFT)</method>, <method>machine learning baseline methods</method>",<method>temporal fusion Transformer (TFT)</method>
2024,https://openalex.org/W4390506124,Medicine,Machine learning models for predicting preeclampsia: a systematic review,"Abstract Background This systematic review provides an overview of machine learning (ML) approaches for predicting preeclampsia. Method This review adhered to the Preferred Reporting Items for Systematic Reviews and Meta-Analyzes (PRISMA) guidelines. We searched the Cochrane Central Register, PubMed, EMBASE, ProQuest, Scopus, and Google Scholar up to February 2023. Search terms were limited to “preeclampsia” AND “artificial intelligence” OR “machine learning” OR “deep learning.” All studies that used ML-based analysis for predicting preeclampsia in pregnant women were considered. Non-English articles and those that are unrelated to the topic were excluded. The PROBAST was used to assess the risk of bias and applicability of each included study. Results The search strategy yielded 128 citations; after duplicates were removed and title and abstract screening was completed, 18 full-text articles were evaluated for eligibility. Four studies were included in this review. Two studies were at low risk of bias, and two had low to moderate risk. All of the study designs included were retrospective cohort studies. Nine distinct models were chosen as ML models from the four studies. Maternal characteristics, medical history, medication intake, obstetrical history, and laboratory and ultrasound findings obtained during prenatal care visits were candidate predictors to train the ML model. Elastic net, stochastic gradient boosting, extreme gradient boosting, and Random forest were among the best models to predict preeclampsia. All four studies used metrics such as the area under the curve, true positive rate, negative positive rate, accuracy, precision, recall, and F1 score. The AUC of ML models varied from 0.860 to 0.973 in four studies. Conclusion The results of studies yielded high prediction performance of ML models for preeclampsia risk from routine early pregnancy information.","<method>Elastic net</method>, <method>stochastic gradient boosting</method>, <method>extreme gradient boosting</method>, <method>Random forest</method>",<method>Elastic net</method><method>stochastic gradient boosting</method><method>extreme gradient boosting</method><method>Random forest</method>
2024,https://openalex.org/W4390563519,Medicine,Association between dietary antioxidant intakes and chronic respiratory diseases in adults,"BackgroundChronic respiratory diseases (CRDs) pose a significant global health burden. Antioxidant-rich diets have been associated with improved lung health, but the specific relationship with CRDs remains unclear.MethodsThis study examined the relationship between dietary antioxidant intakes and CRDs using data from the 2001–2018 National Health and Nutrition Examination Survey (NHANES). Information on dietary antioxidant intakes, including vitamins A, C, and E, zinc, selenium, and carotenoid, were collected from the 2 24-h recall interviews to calculate composite dietary antioxidant index (CDAI). CRDs were determined based on self-reported physician diagnoses. To examine the relationship between CDAI and CRDs, multivariate logistic regression was used. To study potential non-linear correlations within these associations, restricted cubic spline (RCS) regression was performed.ResultsThe study involved 40 557 individuals. The median CDAI was −0.09 (−2.05, 2.25). We discovered those who were in the fourth quartile of CDAI scores had a 19% lower prevalence than those in the first quartile (OR = 0.81 [0.72–0.91], Ptrend < 0.01) after adjusting for all relevant covariates. The fourth quartile of CDAI was linked with a lower prevalence of emphysema (OR = 0.57 [0.40–0.81], Ptrend < 0.01) and chronic bronchitis (OR = 0.74 [0.62–0.88], Ptrend < 0.01). RCS regression showed that CDAI was non-linearly related to the prevalence of CRDs, with inflection points of 3.20 (P for non-linearity <0.01). The stratified analysis did not identify variables that significantly affected the results.ConclusionHigher dietary antioxidant intakes were related with a lower prevalence of CRDs (particularly emphysema and chronic bronchitis) in general adults.","<method>multivariate logistic regression</method>, <method>restricted cubic spline (RCS) regression</method>",<method>multivariate logistic regression</method>
2024,https://openalex.org/W4390618348,Medicine,Artificial intelligence auxiliary diagnosis and treatment system for breast cancer in developing countries,"BACKGROUND: In many developing countries, a significant number of breast cancer patients are unable to receive timely treatment due to a large population base, high patient numbers, and limited medical resources. OBJECTIVE: This paper proposes a breast cancer assisted diagnosis system based on electronic medical records. The goal of this system is to address the limitations of existing systems, which primarily rely on structured electronic records and may miss crucial information stored in unstructured records. METHODS: The proposed approach is a breast cancer assisted diagnosis system based on electronic medical records. The system utilizes breast cancer enhanced convolutional neural networks with semantic initialization filters (BC-INIT-CNN). It extracts highly relevant tumor markers from unstructured medical records to aid in breast cancer staging diagnosis and effectively utilizes the important information present in unstructured records. RESULTS: The model’s performance is assessed using various evaluation metrics. Such as accuracy, ROC curves, and Precision-Recall curves. Comparative analysis demonstrates that the BC-INIT-CNN model outperforms several existing methods in terms of accuracy and computational efficiency. CONCLUSIONS: The proposed breast cancer assisted diagnosis system based on BC-INIT-CNN showcases the potential to address the challenges faced by developing countries in providing timely treatment to breast cancer patients. By leveraging unstructured medical records and extracting relevant tumor markers, the system enables accurate staging diagnosis and enhances the utilization of valuable information.",<method>breast cancer enhanced convolutional neural networks with semantic initialization filters (BC-INIT-CNN)</method>,No methods remaining
2024,https://openalex.org/W4392915224,Medicine,"An Extensive Investigation into the Use of Machine Learning Tools and Deep Neural Networks for the Recognition of Skin Cancer: Challenges, Future Directions, and a Comprehensive Review","Skin cancer poses a serious risk to one’s health and can only be effectively treated with early detection. Early identification is critical since skin cancer has a higher fatality rate, and it expands gradually to different areas of the body. The rapid growth of automated diagnosis frameworks has led to the combination of diverse machine learning, deep learning, and computer vision algorithms for detecting clinical samples and atypical skin lesion specimens. Automated methods for recognizing skin cancer that use deep learning techniques are discussed in this article: convolutional neural networks, and, in general, artificial neural networks. The recognition of symmetries is a key point in dealing with the skin cancer image datasets; hence, in developing the appropriate architecture of neural networks, as it can improve the performance and release capacities of the network. The current study emphasizes the need for an automated method to identify skin lesions to reduce the amount of time and effort required for the diagnostic process, as well as the novel aspect of using algorithms based on deep learning for skin lesion detection. The analysis concludes with underlying research directions for the future, which will assist in better addressing the difficulties encountered in human skin cancer recognition. By highlighting the drawbacks and advantages of prior techniques, the authors hope to establish a standard for future analysis in the domain of human skin lesion diagnostics.","<method>convolutional neural networks</method>, <method>artificial neural networks</method>",<method>convolutional neural networks</method><method>artificial neural networks</method>
2024,https://openalex.org/W4395076002,Medicine,DenRAM: neuromorphic dendritic architecture with RRAM for efficient temporal processing with delays,"An increasing number of studies are highlighting the importance of spatial dendritic branching in pyramidal neurons in the neocortex for supporting non-linear computation through localized synaptic integration. In particular, dendritic branches play a key role in temporal signal processing and feature detection. This is accomplished thanks to coincidence detection (CD) mechanisms enabled by the presence of synaptic delays that align temporally disparate inputs for effective integration. Computational studies on spiking neural networks further highlight the significance of delays for achieving spatio-temporal pattern recognition with pure feed-forward neural networks, without the need of resorting to recurrent architectures. In this work, we present ""DenRAM"", the first realization of a feed-forward spiking neural network with dendritic compartments, implemented using analog electronic circuits integrated into a 130 nm technology node and coupled with Resistive Random Access Memory (RRAM) technology. DenRAM's dendritic circuits use RRAM devices to implement both delays and synaptic weights in the network. By configuring the RRAM devices to reproduce bio-realistic timescales, and by exploiting their heterogeneity we experimentally demonstrate DenRAM's ability to replicate synaptic delay profiles, and to efficiently implement CD for spatio-temporal pattern recognition. To validate the architecture, we conduct comprehensive system-level simulations on two representative temporal benchmarks, demonstrating DenRAM's resilience to analog hardware noise, and its superior accuracy compared to recurrent architectures with an equivalent number of parameters. DenRAM not only brings rich temporal processing capabilities to neuromorphic architectures, but also reduces the memory footprint of edge devices, warrants high accuracy on temporal benchmarks, and represents a significant step-forward in low-power real-time signal processing technologies.",<method>feed-forward spiking neural network</method>,<method>feed-forward spiking neural network</method>
2024,https://openalex.org/W4395084642,Medicine,CerviLearnNet: Advancing cervical cancer diagnosis with reinforcement learning-enhanced convolutional networks,"Women tend to face many problems throughout their lives; cervical cancer is one of the most dangerous diseases that they can face, and it has many negative consequences. Regular screening and treatment of precancerous lesions play a vital role in the fight against cervical cancer. It is becoming increasingly common in medical practice to predict the early stages of serious illnesses, such as heart attacks, kidney failure, and cancer, using machine learning-based techniques. To overcome these obstacles, we propose the use of auxiliary modules and a special residual block, to record contextual interactions between object classes and to support the object reference strategy. Unlike the latest state-of-the-art classification method, we create a new architecture called the Reinforcement Learning Cancer Network, ""RL-CancerNet"", which diagnoses cervical cancer with incredible accuracy. We trained and tested our method on two well-known publicly available datasets, SipaKMeD and Herlev, to assess it and enable comparisons with earlier methods. Cervical cancer images were labeled in this dataset; therefore, they had to be marked manually. Our study shows that, compared to previous approaches for the assignment of classifying cervical cancer as an early cellular change, the proposed approach generates a more reliable and stable image derived from images of datasets of vastly different sizes, indicating that it will be effective for other datasets.","<method>machine learning-based techniques</method>, <method>Reinforcement Learning Cancer Network (RL-CancerNet)</method>",No methods remaining
2024,https://openalex.org/W4396622164,Medicine,Colon and lung cancer classification from multi-modal images using resilient and efficient neural network architectures,"Automatic classification of colon and lung cancer images is crucial for early detection and accurate diagnostics. However, there is room for improvement to enhance accuracy, ensuring better diagnostic precision. This study introduces two novel dense architectures (D1 and D2) and emphasizes their effectiveness in classifying colon and lung cancer from diverse images. It also highlights their resilience, efficiency, and superior performance across multiple datasets. These architectures were tested on various types of datasets, including NCT-CRC-HE-100K (set of 100,000 non-overlapping image patches from hematoxylin and eosin (H&E) stained histological images of human colorectal cancer (CRC) and normal tissue), CRC-VAL-HE-7K (set of 7180 image patches from N=50 patients with colorectal adenocarcinoma, no overlap with patients in NCT-CRC-HE-100K), LC25000 (Lung and Colon Cancer Histopathological Image), and IQ-OTHNCCD (Iraq-Oncology Teaching Hospital/National Center for Cancer Diseases), showcasing their effectiveness in classifying colon and lung cancers from histopathological and Computed Tomography (CT) scan images. This underscores the multi-modal image classification capability of the proposed models. Moreover, the study addresses imbalanced datasets, particularly in CRC-VAL-HE-7K and IQ-OTHNCCD, with a specific focus on model resilience and robustness. To assess overall performance, the study conducted experiments in different scenarios. The D1 model achieved an impressive 99.80% accuracy on the NCT-CRC-HE-100K dataset, with a Jaccard Index (J) of 0.8371, a Matthew's Correlation Coefficient (MCC) of 0.9073, a Cohen's Kappa (Kp) of 0.9057, and a Critical Success Index (CSI) of 0.8213. When subjected to 10-fold cross-validation on LC25000, the D1 model averaged (avg) 99.96% accuracy (avg J, MCC, Kp, and CSI of 0.9993, 0.9987, 0.9853, and 0.9990), surpassing recent reported performances. Furthermore, the ensemble of D1 and D2 reached 93% accuracy (J, MCC, Kp, and CSI of 0.7556, 0.8839, 0.8796, and 0.7140) on the IQ-OTHNCCD dataset, exceeding recent benchmarks and aligning with other reported results. Efficiency evaluations were conducted in various scenarios. For instance, training on only 10% of LC25000 resulted in high accuracy rates of 99.19% (J, MCC, Kp, and CSI of 0.9840, 0.9898, 0.9898, and 0.9837) (D1) and 99.30% (J, MCC, Kp, and CSI of 0.9863, 0.9913, 0.9913, and 0.9861) (D2). In NCT-CRC-HE-100K, D2 achieved an impressive 99.53% accuracy (J, MCC, Kp, and CSI of 0.9906, 0.9946, 0.9946, and 0.9906) with training on only 30% of the dataset and testing on the remaining 70%. When tested on CRC-VAL-HE-7K, D1 and D2 achieved 95% accuracy (J, MCC, Kp, and CSI of 0.8845, 0.9455, 0.9452, and 0.8745) and 96% accuracy (J, MCC, Kp, and CSI of 0.8926, 0.9504, 0.9503, and 0.8798), respectively, outperforming previously reported results and aligning closely with others. Lastly, training D2 on just 10% of NCT-CRC-HE-100K and testing on CRC-VAL-HE-7K resulted in significant outperformance of InceptionV3, Xception, and DenseNet201 benchmarks, achieving an accuracy rate of 82.98% (J, MCC, Kp, and CSI of 0.7227, 0.8095, 0.8081, and 0.6671). Finally, using explainable AI algorithms such as Grad-CAM, Grad-CAM++, Score-CAM, and Faster Score-CAM, along with their emphasized versions, we visualized the features from the last layer of DenseNet201 for histopathological as well as CT-scan image samples. The proposed dense models, with their multi-modality, robustness, and efficiency in cancer image classification, hold the promise of significant advancements in medical diagnostics. They have the potential to revolutionize early cancer detection and improve healthcare accessibility worldwide.","<method>dense architectures (D1 and D2)</method>, <method>ensemble of D1 and D2</method>, <method>InceptionV3</method>, <method>Xception</method>, <method>DenseNet201</method>, <method>Grad-CAM</method>, <method>Grad-CAM++</method>, <method>Score-CAM</method>, <method>Faster Score-CAM</method>",<method>InceptionV3</method><method>Xception</method><method>DenseNet201</method><method>Grad-CAM</method><method>Grad-CAM++</method><method>Score-CAM</method><method>Faster Score-CAM</method>
2024,https://openalex.org/W4399322162,Medicine,Integration of deep learning and habitat radiomics for predicting the response to immunotherapy in NSCLC patients,"Abstract Background The non-invasive biomarkers for predicting immunotherapy response are urgently needed to prevent both premature cessation of treatment and ineffective extension. This study aimed to construct a non-invasive model for predicting immunotherapy response, based on the integration of deep learning and habitat radiomics in patients with advanced non-small cell lung cancer (NSCLC). Methods Independent patient cohorts from three medical centers were enrolled for training ( n = 164) and test ( n = 82). Habitat imaging radiomics features were derived from sub-regions clustered from individual’s tumor by K-means method. The deep learning features were extracted based on 3D ResNet algorithm. Pearson correlation coefficient, T test and least absolute shrinkage and selection operator regression were used to select features. Support vector machine was applied to implement deep learning and habitat radiomics, respectively. Then, a combination model was developed integrating both sources of data. Results The combination model obtained a strong well-performance, achieving area under receiver operating characteristics curve of 0.865 (95% CI 0.772–0.931). The model significantly discerned high and low-risk patients, and exhibited a significant benefit in the clinical use. Conclusion The integration of deep-leaning and habitat radiomics contributed to predicting response to immunotherapy in patients with NSCLC. The developed integration model may be used as potential tool for individual immunotherapy management.","<method>K-means</method>, <method>3D ResNet algorithm</method>, <method>least absolute shrinkage and selection operator regression</method>, <method>Support vector machine</method>",<method>K-means</method><method>3D ResNet algorithm</method><method>least absolute shrinkage and selection operator regression</method><method>Support vector machine</method>
2024,https://openalex.org/W4399986067,Medicine,Comparing machine learning algorithms to predict vegetation fire detections in Pakistan,"Abstract Vegetation fires have major impacts on the ecosystem and present a significant threat to human life. Vegetation fires consists of forest fires, cropland fires, and other vegetation fires in this study. Currently, there is a limited amount of research on the long-term prediction of vegetation fires in Pakistan. The exact effect of every factor on the frequency of vegetation fires remains unclear when using standard analysis. This research utilized the high proficiency of machine learning algorithms to combine data from several sources, including the MODIS Global Fire Atlas dataset, topographic, climatic conditions, and different vegetation types acquired between 2001 and 2022. We tested many algorithms and ultimately chose four models for formal data processing. Their selection was based on their performance metrics, such as accuracy, computational efficiency, and preliminary test results. The model’s logistic regression, a random forest, a support vector machine, and an eXtreme Gradient Boosting were used to identify and select the nine key factors of forest and cropland fires and, in the case of other vegetation, seven key factors that cause a fire in Pakistan. The findings indicated that the vegetation fire prediction models achieved prediction accuracies ranging from 78.7 to 87.5% for forest fires, 70.4 to 84.0% for cropland fires, and 66.6 to 83.1% for other vegetation. Additionally, the area under the curve (AUC) values ranged from 83.6 to 93.4% in forest fires, 72.6 to 90.6% in cropland fires, and 74.2 to 90.7% in other vegetation. The random forest model had the highest accuracy rate of 87.5% in forest fires, 84.0% in cropland fires, and 83.1% in other vegetation and also the highest AUC value of 93.4% in forest fires, 90.6% in cropland fires, and 90.7% in other vegetation, proving to be the most optimal performance model. The models provided predictive insights into specific conditions and regional susceptibilities to fire occurrences, adding significant value beyond the initial MODIS detection data. The maps generated to analyze Pakistan’s vegetation fire risk showed the geographical distribution of areas with high, moderate, and low vegetation fire risks, highlighting predictive risk assessments rather than historical fire detections.","<method>logistic regression</method>, <method>random forest</method>, <method>support vector machine</method>, <method>eXtreme Gradient Boosting</method>",<method>logistic regression</method><method>random forest</method><method>support vector machine</method><method>eXtreme Gradient Boosting</method>
2024,https://openalex.org/W4400335482,Medicine,Enhancing ECG-based heart age: impact of acquisition parameters and generalization strategies for varying signal morphologies and corruptions,"Electrocardiogram (ECG) is a non-invasive approach to capture the overall electrical activity produced by the contraction and relaxation of the cardiac muscles. It has been established in the literature that the difference between ECG-derived age and chronological age represents a general measure of cardiovascular health. Elevated ECG-derived age strongly correlates with cardiovascular conditions (e.g., atherosclerotic cardiovascular disease). However, the neural networks for ECG age estimation are yet to be thoroughly evaluated from the perspective of ECG acquisition parameters. Additionally, deep learning systems for ECG analysis encounter challenges in generalizing across diverse ECG morphologies in various ethnic groups and are susceptible to errors with signals that exhibit random or systematic distortions To address these challenges, we perform a comprehensive empirical study to determine the threshold for the sampling rate and duration of ECG signals while considering their impact on the computational cost of the neural networks. To tackle the concern of ECG waveform variability in different populations, we evaluate the feasibility of utilizing pre-trained and fine-tuned networks to estimate ECG age in different ethnic groups. Additionally, we empirically demonstrate that finetuning is an environmentally sustainable way to train neural networks, and it significantly decreases the ECG instances required (by more than <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML"" id=""IM1""><mml:mn>100</mml:mn><mml:mo>×</mml:mo></mml:math> ) for attaining performance similar to the networks trained from random weight initialization on a complete dataset. Finally, we systematically evaluate augmentation schemes for ECG signals in the context of age estimation and introduce a random cropping scheme that provides best-in-class performance while using shorter-duration ECG signals. The results also show that random cropping enables the networks to perform well with systematic and random ECG signal corruptions.","<method>neural networks</method>, <method>pre-trained networks</method>, <method>fine-tuned networks</method>, <method>finetuning</method>, <method>augmentation schemes</method>, <method>random cropping scheme</method>",<method>neural networks</method><method>fine-tuned networks</method><method>finetuning</method>
2024,https://openalex.org/W4400896445,Medicine,Recent deep learning-based brain tumor segmentation models using multi-modality magnetic resonance imaging: a prospective survey,"Radiologists encounter significant challenges when segmenting and determining brain tumors in patients because this information assists in treatment planning. The utilization of artificial intelligence (AI), especially deep learning (DL), has emerged as a useful tool in healthcare, aiding radiologists in their diagnostic processes. This empowers radiologists to understand the biology of tumors better and provide personalized care to patients with brain tumors. The segmentation of brain tumors using multi-modal magnetic resonance imaging (MRI) images has received considerable attention. In this survey, we first discuss multi-modal and available magnetic resonance imaging modalities and their properties. Subsequently, we discuss the most recent DL-based models for brain tumor segmentation using multi-modal MRI. We divide this section into three parts based on the architecture: the first is for models that use the backbone of convolutional neural networks (CNN), the second is for vision transformer-based models, and the third is for hybrid models that use both convolutional neural networks and transformer in the architecture. In addition, in-depth statistical analysis is performed of the recent publication, frequently used datasets, and evaluation metrics for segmentation tasks. Finally, open research challenges are identified and suggested promising future directions for brain tumor segmentation to improve diagnostic accuracy and treatment outcomes for patients with brain tumors. This aligns with public health goals to use health technologies for better healthcare delivery and population health management.","<method>deep learning (DL)</method>, <method>convolutional neural networks (CNN)</method>, <method>vision transformer-based models</method>, <method>hybrid models that use both convolutional neural networks and transformer</method>",<method>deep learning (DL)</method><method>convolutional neural networks (CNN)</method><method>vision transformer-based models</method><method>hybrid models that use both convolutional neural networks and transformer</method>
2024,https://openalex.org/W4401363688,Medicine,Artificial intelligence applications in the diagnosis and treatment of bacterial infections,"The diagnosis and treatment of bacterial infections in the medical and public health field in the 21st century remain significantly challenging. Artificial Intelligence (AI) has emerged as a powerful new tool in diagnosing and treating bacterial infections. AI is rapidly revolutionizing epidemiological studies of infectious diseases, providing effective early warning, prevention, and control of outbreaks. Machine learning models provide a highly flexible way to simulate and predict the complex mechanisms of pathogen-host interactions, which is crucial for a comprehensive understanding of the nature of diseases. Machine learning-based pathogen identification technology and antimicrobial drug susceptibility testing break through the limitations of traditional methods, significantly shorten the time from sample collection to the determination of result, and greatly improve the speed and accuracy of laboratory testing. In addition, AI technology application in treating bacterial infections, particularly in the research and development of drugs and vaccines, and the application of innovative therapies such as bacteriophage, provides new strategies for improving therapy and curbing bacterial resistance. Although AI has a broad application prospect in diagnosing and treating bacterial infections, significant challenges remain in data quality and quantity, model interpretability, clinical integration, and patient privacy protection. To overcome these challenges and, realize widespread application in clinical practice, interdisciplinary cooperation, technology innovation, and policy support are essential components of the joint efforts required. In summary, with continuous advancements and in-depth application of AI technology, AI will enable doctors to more effectivelyaddress the challenge of bacterial infection, promoting the development of medical practice toward precision, efficiency, and personalization; optimizing the best nursing and treatment plans for patients; and providing strong support for public health safety.","<method>Artificial Intelligence (AI)</method>, <method>Machine learning models</method>, <method>Machine learning-based pathogen identification technology</method>, <method>Machine learning-based antimicrobial drug susceptibility testing</method>",No methods remaining
2024,https://openalex.org/W4403343918,Medicine,A comprehensive investigation of multimodal deep learning fusion strategies for breast cancer classification,"In breast cancer research, diverse data types and formats, such as radiological images, clinical records, histological data, and expression analysis, are employed. Given the intricate nature of natural phenomena, relying on the features of a single modality is seldom sufficient for comprehensive analysis. Therefore, it is possible to guarantee medical relevance and achieve improved clinical outcomes by combining several modalities. The presen study carefully maps and reviews 47 primary articles from six well-known digital libraries that were published between 2018 and 2023 for breast cancer classification based on multimodal deep learning fusion (MDLF) techniques. This systematic literature review encompasses various aspects, including the medical modalities combined, the datasets utilized in these studies, the techniques, models, and architectures used in MDLF and it also discusses the advantages and limitations of each approach. The analysis of selected papers has revealed a compelling trend: the emergence of new modalities and combinations that were previously unexplored in the context of breast cancer classification. This exploration has not only expanded the scope of predictive models but also introduced fresh perspectives for addressing diverse targets, ranging from screening to diagnosis and prognosis. The practical advantages of MDLF are evident in its ability to enhance the predictive capabilities of machine learning models, resulting in improved accuracy across diverse applications. The prevalence of deep learning models underscores their success in autonomously discerning complex patterns, offering a substantial departure from traditional machine learning approaches. Furthermore, the paper explores the challenges and future directions in this field, including the need for larger datasets, the use of ensemble learning methods, and the interpretation of multimodal models.","<method>multimodal deep learning fusion (MDLF)</method>, <method>machine learning models</method>, <method>deep learning models</method>, <method>ensemble learning methods</method>",<method>ensemble learning methods</method>
2024,https://openalex.org/W4390662926,Medicine,Artificial intelligence performance in detecting lymphoma from medical imaging: a systematic review and meta-analysis,"Abstract Background Accurate diagnosis and early treatment are essential in the fight against lymphatic cancer. The application of artificial intelligence (AI) in the field of medical imaging shows great potential, but the diagnostic accuracy of lymphoma is unclear. This study was done to systematically review and meta-analyse researches concerning the diagnostic performance of AI in detecting lymphoma using medical imaging for the first time. Methods Searches were conducted in Medline, Embase, IEEE and Cochrane up to December 2023. Data extraction and assessment of the included study quality were independently conducted by two investigators. Studies that reported the diagnostic performance of an AI model/s for the early detection of lymphoma using medical imaging were included in the systemic review. We extracted the binary diagnostic accuracy data to obtain the outcomes of interest: sensitivity (SE), specificity (SP), and Area Under the Curve (AUC). The study was registered with the PROSPERO, CRD42022383386. Results Thirty studies were included in the systematic review, sixteen of which were meta-analyzed with a pooled sensitivity of 87% (95%CI 83–91%), specificity of 94% (92–96%), and AUC of 97% (95–98%). Satisfactory diagnostic performance was observed in subgroup analyses based on algorithms types (machine learning versus deep learning, and whether transfer learning was applied), sample size (≤ 200 or &gt; 200), clinicians versus AI models and geographical distribution of institutions (Asia versus non-Asia). Conclusions Even if possible overestimation and further studies with a better standards for application of AI algorithms in lymphoma detection are needed, we suggest the AI may be useful in lymphoma diagnosis.","<method>machine learning</method>, <method>deep learning</method>, <method>transfer learning</method>",<method>machine learning</method><method>deep learning</method><method>transfer learning</method>
2024,https://openalex.org/W4390906064,Medicine,A critical moment in machine learning in medicine: on reproducible and interpretable learning,"Over the past two decades, advances in computational power and data availability combined with increased accessibility to pre-trained models have led to an exponential rise in machine learning (ML) publications. While ML may have the potential to transform healthcare, this sharp increase in ML research output without focus on methodological rigor and standard reporting guidelines has fueled a reproducibility crisis. In addition, the rapidly growing complexity of these models compromises their interpretability, which currently impedes their successful and widespread clinical adoption. In medicine, where failure of such models may have severe implications for patients' health, the high requirements for accuracy, robustness, and interpretability confront ML researchers with a unique set of challenges. In this review, we discuss the semantics of reproducibility and interpretability, as well as related issues and challenges, and outline possible solutions to counteracting the ""black box"". To foster reproducibility, standard reporting guidelines need to be further developed and data or code sharing encouraged. Editors and reviewers may equally play a critical role by establishing high methodological standards and thus preventing the dissemination of low-quality ML publications. To foster interpretable learning, the use of simpler models more suitable for medical data can inform the clinician how results are generated based on input data. Model-agnostic explanation tools, sensitivity analysis, and hidden layer representations constitute further promising approaches to increase interpretability. Balancing model performance and interpretability are important to ensure clinical applicability. We have now reached a critical moment for ML in medicine, where addressing these issues and implementing appropriate solutions will be vital for the future evolution of the field.","<method>simpler models</method>, <method>model-agnostic explanation tools</method>, <method>sensitivity analysis</method>, <method>hidden layer representations</method>",<method>model-agnostic explanation tools</method>
2024,https://openalex.org/W4391127198,Medicine,Risk predictions of surgical wound complications based on a machine learning algorithm: A systematic review,"Abstract Surgical wounds may arise due to harm inflicted upon soft tissue during surgical intervention, and many complications and injuries may accompany them. These complications can lead to prolonged hospitalization and poorer clinical outcomes. Also, Machine learning (ML) is a Section of artificial intelligence (AI) that has emerged in medical care and is increasingly used for diagnosis, complications, prognosis and recurrence prediction. This study aims to investigate surgical wound risk predictions and management using a ML algorithm by R programming language analysis. The systematic review, following PRISMA guidelines, spanned electronic databases using search terms like ‘machine learning’, ‘surgical’ and ‘wound’. Inclusion criteria covered experimental studies from 1990 to the present on ML's application in surgical wound evaluation. Exclusion criteria included studies lacking full text, focusing on ML in all surgeries, neglecting wound assessment and duplications. Two authors rigorously assessed titles, abstracts and full texts, excluding reviews and guidelines. Ultimately, relevant articles were then analysed. The present study identified nine articles employing ML for surgical wound management. The analysis encompassed various surgical procedures, including Cardiothoracic, Caesarean total abdominal colectomy, Burn plastic surgery, facial plastic surgery, laparotomy, minimal invasive surgery, hernia repair and unspecified surgeries. ML was skillful in evaluating surgical site infections (SSI) in seven studies, while two extended its use to burn‐grade diagnosis and wound classification. Support Vector Machine (SVM) and Convolutional Neural Network (CNN) were the most utilized algorithms. ANN achieved a 96% accuracy in facial plastic surgery wound management. CNN demonstrated commendable accuracies in various surgeries, and SVM exhibited high accuracy in multiple surgeries and burn plastic surgery. In sum, these findings underscore ML's potential for significant improvements in postoperative management and the development of enhanced care techniques, particularly in surgical wound management.","<method>Support Vector Machine (SVM)</method>, <method>Convolutional Neural Network (CNN)</method>, <method>Artificial Neural Network (ANN)</method>",<method>Support Vector Machine (SVM)</method><method>Convolutional Neural Network (CNN)</method><method>Artificial Neural Network (ANN)</method>
2024,https://openalex.org/W4391187635,Medicine,Prediction models for postoperative delirium in elderly patients with machine-learning algorithms and SHapley Additive exPlanations,"Abstract Postoperative delirium (POD) is a common and severe complication in elderly patients with hip fractures. Identifying high-risk patients with POD can help improve the outcome of patients with hip fractures. We conducted a retrospective study on elderly patients (≥65 years of age) who underwent orthopedic surgery with hip fracture between January 2014 and August 2019. Conventional logistic regression and five machine-learning algorithms were used to construct prediction models of POD. A nomogram for POD prediction was built with the logistic regression method. The area under the receiver operating characteristic curve (AUC-ROC), accuracy, sensitivity, and precision were calculated to evaluate different models. Feature importance of individuals was interpreted using Shapley Additive Explanations (SHAP). About 797 patients were enrolled in the study, with the incidence of POD at 9.28% (74/797). The age, renal insufficiency, chronic obstructive pulmonary disease (COPD), use of antipsychotics, lactate dehydrogenase (LDH), and C-reactive protein are used to build a nomogram for POD with an AUC of 0.71. The AUCs of five machine-learning models are 0.81 (Random Forest), 0.80 (GBM), 0.68 (AdaBoost), 0.77 (XGBoost), and 0.70 (SVM). The sensitivities of the six models range from 68.8% (logistic regression and SVM) to 91.9% (Random Forest). The precisions of the six machine-learning models range from 18.3% (logistic regression) to 67.8% (SVM). Six prediction models of POD in patients with hip fractures were constructed using logistic regression and five machine-learning algorithms. The application of machine-learning algorithms could provide convenient POD risk stratification to benefit elderly hip fracture patients.","<method>logistic regression</method>, <method>Random Forest</method>, <method>GBM</method>, <method>AdaBoost</method>, <method>XGBoost</method>, <method>SVM</method>",<method>logistic regression</method><method>Random Forest</method><method>GBM</method><method>AdaBoost</method><method>XGBoost</method><method>SVM</method>
2024,https://openalex.org/W4391277876,Medicine,Predicting mechanical properties of self-healing concrete with Trichoderma Reesei Fungus using machine learning,"Trichoderma Reesei is a mesophilic and filamentous fungus. It is an anamorph of the fungus Hypocrea jecorina, in addition, T. reesei can secrete large amounts of cellulolytic enzymes and form dextrose PDA (potato dextrose agar) and potato injection. After the preparation of fungi, it is added to the cracked samples. The experimental samples were 150 mm3 cubic compression and 70 mm x 30 mm x 15 mm cracks on the surface of each cube. Different fungi water extracts were used with 0, 50.5, 6.37, and 8.42 liters of water per ml. The results show that the addition of 8.42 (ml) of the mushroom extract with one liter of water has the maximum compressive strength with more than 18.99 MPa for 28 days, 16.7 for 14 days, and 14.5 for 7 days. In this study, linear regression, lasso regression, and rigid regression have been used to predict compressive strength, also the cooperation between mushroom juice per milliliter and compressive strength has been predicted. To find the accuracy, Correlation Coefficient (R2), Mean Absolute Errors (MAE), and Root Mean Square Error have been used. The results of machine learning show that the results of linear regression and rigid regression R2 were more than 0.98. In addition, the relationship compressive strength prediction results showed that R2 for fungi broth with one liter of water was 5.05 mL was more than 0.98. Finally, this study shows that the fungus Trichoderma reesei is an effective agent for curing concrete and improving the compressive strength of concrete.","<method>linear regression</method>, <method>lasso regression</method>, <method>rigid regression</method>",<method>linear regression</method><method>lasso regression</method>
2024,https://openalex.org/W4391670546,Medicine,Random forest regression for prediction of Covid-19 daily cases and deaths in Turkey,"During pandemic periods, there is an intense flow of patients to hospitals. Depending on the disease, many patients may require hospitalization. In some cases, these patients must be taken to intensive care units and emergency interventions must be performed. However, finding a sufficient number of hospital beds or intensive care units during pandemic periods poses a big problem. In these periods, fast and effective planning is more important than ever. Another problem experienced during pandemic periods is the burial of the dead in case the number of deaths increases. This is also a situation that requires due planning. We can learn some lessons from Covid 19 pandemic and be prepared for the future ones. In this paper, statistical properties of the daily cases and daily deaths in Turkey, which is one of the most affected countries by the pandemic in the World, are studied. It is found that the characteristics are nonstationary. Then, random forest regression is applied to predict Covid-19 daily cases and deaths. In addition, seven other machine learning models, namely bagging, AdaBoost, gradient boosting, XGBoost, decision tree, LSTM and ARIMA regressors are built for comparison. The performance of the models are measured using accuracy, coefficient of variation, root-mean-square score and relative error metrics. When random forest regressors are employed, test data related to daily cases are predicted with an accuracy of 92.30% and with an r2 score of 0.9893. Besides, daily deaths are predicted with an accuracy of 91.39% and with an r2 score of 0.9834. The closest rival in predictions is the bagging regressor. Nevertheless, the results provided by this algoritm changed in different runs and this fact is shown in the study, as well. Comparisons are based on test data. Comparisons with the earlier works are also provided.","<method>random forest regression</method>, <method>bagging</method>, <method>AdaBoost</method>, <method>gradient boosting</method>, <method>XGBoost</method>, <method>decision tree</method>, <method>LSTM</method>, <method>ARIMA regressors</method>",<method>random forest regression</method><method>bagging</method><method>AdaBoost</method><method>gradient boosting</method><method>XGBoost</method><method>decision tree</method><method>LSTM</method>
2024,https://openalex.org/W4391677331,Medicine,An artificial intelligence based abdominal aortic aneurysm prognosis classifier to predict patient outcomes,"Abstract Abdominal aortic aneurysms (AAA) have been rigorously investigated to understand when their clinically-estimated risk of rupture—an event that is the 13th leading cause of death in the US—exceeds the risk associated with repair. Yet the current clinical guideline remains a one-size-fits-all “maximum diameter criterion” whereby AAA exceeding a threshold diameter is thought to make the risk of rupture high enough to warrant intervention. However, between 7 and 23.4% of smaller-sized AAA have been reported to rupture with diameters below the threshold. In this study, we train and assess machine learning models using clinical, biomechanical, and morphological indices from 381 patients to develop an aneurysm prognosis classifier to predict one of three outcomes for a given AAA patient: their AAA will remain stable, their AAA will require repair based as currently indicated from the maximum diameter criterion, or their AAA will rupture. This study represents the largest cohort of AAA patients that utilizes the first available medical image and clinical data to classify patient outcomes. The APC model therefore represents a potential clinical tool to striate specific patient outcomes using machine learning models and patient-specific image-based (biomechanical and morphological) and clinical data as input. Such a tool could greatly assist clinicians in their management decisions for patients with AAA.",<method>machine learning models</method>,No methods remaining
2024,https://openalex.org/W4391991419,Medicine,Economic evaluation for medical artificial intelligence: accuracy vs. cost-effectiveness in a diabetic retinopathy screening case,"Abstract Artificial intelligence (AI) models have shown great accuracy in health screening. However, for real-world implementation, high accuracy may not guarantee cost-effectiveness. Improving AI’s sensitivity finds more high-risk patients but may raise medical costs while increasing specificity reduces unnecessary referrals but may weaken detection capability. To evaluate the trade-off between AI model performance and the long-running cost-effectiveness, we conducted a cost-effectiveness analysis in a nationwide diabetic retinopathy (DR) screening program in China, comprising 251,535 participants with diabetes over 30 years. We tested a validated AI model in 1100 different diagnostic performances (presented as sensitivity/specificity pairs) and modeled annual screening scenarios. The status quo was defined as the scenario with the most accurate AI performance. The incremental cost-effectiveness ratio (ICER) was calculated for other scenarios against the status quo as cost-effectiveness metrics. Compared to the status quo (sensitivity/specificity: 93.3%/87.7%), six scenarios were cost-saving and seven were cost-effective. To achieve cost-saving or cost-effective, the AI model should reach a minimum sensitivity of 88.2% and specificity of 80.4%. The most cost-effective AI model exhibited higher sensitivity (96.3%) and lower specificity (80.4%) than the status quo. In settings with higher DR prevalence and willingness-to-pay levels, the AI needed higher sensitivity for optimal cost-effectiveness. Urban regions and younger patient groups also required higher sensitivity in AI-based screening. In real-world DR screening, the most accurate AI model may not be the most cost-effective. Cost-effectiveness should be independently evaluated, which is most likely to be affected by the AI’s sensitivity.",<method>Artificial intelligence (AI) models</method>,No methods remaining
2024,https://openalex.org/W4392386754,Medicine,A Comparative Analysis of Machine Learning Algorithms for Breast Cancer Detection and Identification of Key Predictive Features,"Cancer, a disease with numerous subtypes, poses a deadly threat to human life, with the potential for successful clinical treatment heavily reliant on early detection and appropriate treatment planning.The classification of cancer patients into either low or high-risk subgroups is critical.Consequently, various research teams spanning the biomedical and bioinformatics fields have explored the use of Machine Learning (ML) technology in this crucial domain.The impressive capability of ML algorithms to discern significant features in complex datasets underscores their value.In the current study, we propose a framework to detect breast cancer (through benign and malignant categorization) utilizing advanced ML techniques with high accuracy.This framework deploys the Wisconsin Breast Cancer (Diagnostic) dataset.Five supervised ML techniques, namely Decision Tree, Random Forest (RF), Support Vector Machine (SVM), Extreme Gradient Boosting (XGBoost), and Artificial Neural Network (ANN), are trained for classification purposes.Out of 569 samples, 70% are allocated for training while the other 30% for testing.A comprehensive evaluation of ML techniques is performed using an array of metrics: precision, recall, specificity, F1 score, classification accuracy, ROC Curve, training time, and feature utilization.Additionally, feature importance is computed for each classifier.The results reveal that the SVM has the maximum accuracy as 97.66%, with an F1-score of 0.98 for benign and 0.97 for malignant classifications.Conversely, the decision tree registers the minimum performance (94.55%) with an F1-score of 0.95 for benign and 0.91 for malignant classes.Accuracy scores for RF, XGBoost, and ANN stand at 95.32%, 95.91%, and 97.07%, with corresponding F1-scores of 0.96, 0.97, and 0.98 for benign and 0.94, 0.95, and 0.96 for malignant respectively.Interestingly, RF and XGBoost exhibited near-equivalent similarly with respect of accuracy measurements.In the context of the area over the ROC curve, SVM outperformed the other ML classifiers and also reported the shortest training time.Conversely, the ANN reported the longest training time.","<method>Decision Tree</method>, <method>Random Forest (RF)</method>, <method>Support Vector Machine (SVM)</method>, <method>Extreme Gradient Boosting (XGBoost)</method>, <method>Artificial Neural Network (ANN)</method>",<method>Decision Tree</method><method>Random Forest (RF)</method><method>Support Vector Machine (SVM)</method><method>Extreme Gradient Boosting (XGBoost)</method><method>Artificial Neural Network (ANN)</method>
2024,https://openalex.org/W4392471890,Medicine,An interpretable machine learning system for colorectal cancer diagnosis from pathology slides,"Abstract Considering the profound transformation affecting pathology practice, we aimed to develop a scalable artificial intelligence (AI) system to diagnose colorectal cancer from whole-slide images (WSI). For this, we propose a deep learning (DL) system that learns from weak labels, a sampling strategy that reduces the number of training samples by a factor of six without compromising performance, an approach to leverage a small subset of fully annotated samples, and a prototype with explainable predictions, active learning features and parallelisation. Noting some problems in the literature, this study is conducted with one of the largest WSI colorectal samples dataset with approximately 10,500 WSIs. Of these samples, 900 are testing samples. Furthermore, the robustness of the proposed method is assessed with two additional external datasets (TCGA and PAIP) and a dataset of samples collected directly from the proposed prototype. Our proposed method predicts, for the patch-based tiles, a class based on the severity of the dysplasia and uses that information to classify the whole slide. It is trained with an interpretable mixed-supervision scheme to leverage the domain knowledge introduced by pathologists through spatial annotations. The mixed-supervision scheme allowed for an intelligent sampling strategy effectively evaluated in several different scenarios without compromising the performance. On the internal dataset, the method shows an accuracy of 93.44% and a sensitivity between positive (low-grade and high-grade dysplasia) and non-neoplastic samples of 0.996. On the external test samples varied with TCGA being the most challenging dataset with an overall accuracy of 84.91% and a sensitivity of 0.996.","<method>deep learning (DL) system that learns from weak labels</method>, <method>sampling strategy that reduces the number of training samples</method>, <method>approach to leverage a small subset of fully annotated samples</method>, <method>prototype with explainable predictions</method>, <method>active learning features</method>, <method>interpretable mixed-supervision scheme</method>",<method>deep learning (DL) system that learns from weak labels</method>
2024,https://openalex.org/W4392520481,Medicine,Predicting sepsis in-hospital mortality with machine learning: a multi-center study using clinical and inflammatory biomarkers,"Abstract Background This study aimed to develop and validate an interpretable machine-learning model that utilizes clinical features and inflammatory biomarkers to predict the risk of in-hospital mortality in critically ill patients suffering from sepsis. Methods We enrolled all patients diagnosed with sepsis in the Medical Information Mart for Intensive Care IV (MIMIC-IV, v.2.0), eICU Collaborative Research Care (eICU-CRD 2.0), and the Amsterdam University Medical Centers databases (AmsterdamUMCdb 1.0.2). LASSO regression was employed for feature selection. Seven machine-learning methods were applied to develop prognostic models. The optimal model was chosen based on its accuracy, F1 score and area under curve (AUC) in the validation cohort. Moreover, we utilized the SHapley Additive exPlanations (SHAP) method to elucidate the effects of the features attributed to the model and analyze how individual features affect the model’s output. Finally, Spearman correlation analysis examined the associations among continuous predictor variables. Restricted cubic splines (RCS) explored potential non-linear relationships between continuous risk factors and in-hospital mortality. Results 3535 patients with sepsis were eligible for participation in this study. The median age of the participants was 66 years (IQR, 55–77 years), and 56% were male. After selection, 12 of the 45 clinical parameters collected on the first day after ICU admission remained associated with prognosis and were used to develop machine-learning models. Among seven constructed models, the eXtreme Gradient Boosting (XGBoost) model achieved the best performance, with an AUC of 0.94 and an F1 score of 0.937 in the validation cohort. Feature importance analysis revealed that Age, AST, invasive ventilation treatment, and serum urea nitrogen (BUN) were the top four features of the XGBoost model with the most significant impact. Inflammatory biomarkers may have prognostic value. Furthermore, SHAP force analysis illustrated how the constructed model visualized the prediction of the model. Conclusions This study demonstrated the potential of machine-learning approaches for early prediction of outcomes in patients with sepsis. The SHAP method could improve the interoperability of machine-learning models and help clinicians better understand the reasoning behind the outcome.","<method>LASSO regression</method>, <method>eXtreme Gradient Boosting (XGBoost)</method>, <method>SHapley Additive exPlanations (SHAP)</method>",<method>LASSO regression</method><method>eXtreme Gradient Boosting (XGBoost)</method><method>SHapley Additive exPlanations (SHAP)</method>
2024,https://openalex.org/W4392973999,Medicine,"Advancements in Pancreatic Cancer Detection: Integrating Biomarkers, Imaging Technologies, and Machine Learning for Early Diagnosis","Artificial intelligence (AI) has come to play a pivotal role in revolutionizing medical practices, particularly in the field of pancreatic cancer detection and management. As a leading cause of cancer-related deaths, pancreatic cancer warrants innovative approaches due to its typically advanced stage at diagnosis and dismal survival rates. Present detection methods, constrained by limitations in accuracy and efficiency, underscore the necessity for novel solutions. AI-driven methodologies present promising avenues for enhancing early detection and prognosis forecasting. Through the analysis of imaging data, biomarker profiles, and clinical information, AI algorithms excel in discerning subtle abnormalities indicative of pancreatic cancer with remarkable precision. Moreover, machine learning (ML) algorithms facilitate the amalgamation of diverse data sources to optimize patient care. However, despite its huge potential, the implementation of AI in pancreatic cancer detection faces various challenges. Issues such as the scarcity of comprehensive datasets, biases in algorithm development, and concerns regarding data privacy and security necessitate thorough scrutiny. While AI offers immense promise in transforming pancreatic cancer detection and management, ongoing research and collaborative efforts are indispensable in overcoming technical hurdles and ethical dilemmas. This review delves into the evolution of AI, its application in pancreatic cancer detection, and the challenges and ethical considerations inherent in its integration.","<method>AI algorithms</method>, <method>machine learning (ML) algorithms</method>",No methods remaining
2024,https://openalex.org/W4393137838,Medicine,Structural health monitoring on offshore jacket platforms using a novel ensemble deep learning model,"Monitoring health condition of offshore jacket platforms is crucial to prevent unexpected structural damages, where a prevailing challenge involves translating available feature information into structural damage patterns. Although the artificial neural network (ANN) models are popular in addressing this challenge, they often fail to capture the temporal correlations between the feature information and the damage patterns, which reduce their capability for discovering the laws governing the structural damage detection. To bridge this research gap, this study proposes a novel ensemble deep learning model to enhance the temporal feature extraction to improve the damage pattern identification. In this approach, a one-dimensional Convolutional Neural Network (CNN) extracts the spatiotemporal features from the structural vibration measurements. Simultaneously, a SENet attention mechanism is introduced to select the most informatic features. Subsequently, a bidirectional long short-term memory network (BiLSTM) is employed to learn the mapping between the extracted features and the structural damage patterns. Furthermore, the particle swarm optimization (PSO) algorithm is used to optimize the BiLSTM hyperparameters to enhance its stability and reliability. Both simulations and experiments are carried out to collect the vibration responses of the offshore jacket structure in different damage scenarios. The analysis results demonstrate that the proposed method produces remarkable improvement with respect to the accuracy and robustness in identifying the structural damages when compared with the ANNs. The overall detection accuracy of the proposed CNN-BiLSTM-Attention ensemble model is beyond 95%, which provides strong applicability to practical structural health monitoring of offshore platforms.","<method>artificial neural network (ANN)</method>, <method>ensemble deep learning model</method>, <method>one-dimensional Convolutional Neural Network (CNN)</method>, <method>SENet attention mechanism</method>, <method>bidirectional long short-term memory network (BiLSTM)</method>, <method>particle swarm optimization (PSO) algorithm</method>",<method>artificial neural network (ANN)</method><method>ensemble deep learning model</method><method>one-dimensional Convolutional Neural Network (CNN)</method><method>SENet attention mechanism</method><method>bidirectional long short-term memory network (BiLSTM)</method><method>particle swarm optimization (PSO) algorithm</method>
2024,https://openalex.org/W4393218816,Medicine,A study on smart home use intention of elderly consumers based on technology acceptance models,"Purpose Smart home devices have great potential to improve the quality of life and independence of older people, positively impacting their health, safety, and comfort. However, Chinese research in this field is still in its early stages. Therefore, more comprehensive and in-depth studies are needed to comprehend the various aspects influencing the acceptance and use of smart homes by older users. Patients and methods This study adopted the Technology Acceptance Model (TAM) and included perceived usefulness, perceived ease of use, usage intention, intergenerational technology support, perceived value, and perceived risk as extension variables to delve deeper into the behavioral intentions of older users in smart home services. The study used a convenience sampling method to randomly distribute 236 questionnaires among older adults over the age of 60 in the school’s community and neighboring urban communities who have experience in smart home use and who can complete human-computer interactions either independently or with the help of others, mainly focusing on the four sections: user characteristics, family situation, experience of use, and usage intention. The study used structural equation modeling (SEM) and factor analysis to analyze the completion of questionnaires. Finally, we conducted a validation analysis of the rationality and scientificity of the model and derived the six dimensions of the model of the influencing factors on the use of smart home products by the elderly and the weight sizes of their corresponding 13 influencing factors. Results The results show that perceived usefulness and perceived ease of use have a positive effect on users’ intention to use smart homes. Perceived ease of use has a positive effect on the perceived usefulness of smart homes. In addition, intergenerational technology support, perceived value, and perceived risk impact users’ perceived usefulness and perceived ease of use of the smart home. Conclusion This research aims to describe the factors influencing older users’ willingness to use smart homes. The findings are not only significant for the elderly in China but also of broad value to other regions and countries facing similar demographic challenges. The development of smart homes not only involves the elderly but is also closely related to all segments of society. The government should increase policy support and guide more social forces to participate in the development of the smart home industry. Service providers and designers should fully understand the demand situation and user experience of target users to develop easy-to-use smart home solutions. At the same time, smart homes, as intelligent products for the elderly, need to focus not only on the basic needs of the elderly such as material life and home safety, but also on the spiritual needs of elderly users. Children or caregivers should always pay attention to the psychological state of the elderly and actively guide them to use smart homes to help them realize their self-worth. We look forward to more research focusing on this area in the future and further exploring the specific issues and solutions involved.","<method>Technology Acceptance Model (TAM)</method>, <method>structural equation modeling (SEM)</method>, <method>factor analysis</method>",<method>factor analysis</method>
2024,https://openalex.org/W4393281695,Medicine,An ensemble classification approach for cervical cancer prediction using behavioral risk factors,"Cervical cancer is a significant public health concern among females worldwide. Despite being preventable, it remains a leading cause of mortality. Early detection is crucial for successful treatment and improved survival rates. This study proposes an ensemble Machine Learning (ML) classifier for efficient and accurate identification of cervical cancer using medical data. The proposed methodology involves preparing two datasets using effective preprocessing techniques, extracting essential features using the scikit-learn package, and developing an ensemble classifier based on Random Forest, Support Vector Machine, Gaussian Naïve Bayes, and Decision Tree classifier traits. Comparison with other state-of-the-art algorithms using several ML techniques, including support vector machine, decision tree, random forest, Naïve Bayes, logistic regression, CatBoost, and AdaBoost, demonstrates that the proposed ensemble classifier outperforms them significantly, achieving accuracies of 98.06% and 95.45% for Dataset 1 and Dataset 2, respectively. The proposed ensemble classifier outperforms current state-of-the-art algorithms by 1.50% and 6.67% for Dataset 1 and Dataset 2, respectively, highlighting its superior performance compared to existing methods. The study also utilizes a five-fold cross-validation technique to analyze the benefits and drawbacks of the proposed methodology for predicting cervical cancer using medical data. The Receiver Operating Characteristic (ROC) curves with corresponding Area Under the Curve (AUC) values are 0.95 for Dataset 1 and 0.97 for Dataset 2, indicating the overall performance of the classifiers in distinguishing between the classes. Additionally, we employed SHapley Additive exPlanations (SHAP) as an Explainable Artificial Intelligence (XAI) technique to visualize the classifier's performance, providing insights into the important features contributing to cervical cancer identification. The results demonstrate that the proposed ensemble classifier can efficiently and accurately identify cervical cancer and potentially improve cervical cancer diagnosis and treatment.","<method>ensemble Machine Learning (ML) classifier</method>, <method>Random Forest</method>, <method>Support Vector Machine</method>, <method>Gaussian Naïve Bayes</method>, <method>Decision Tree classifier</method>, <method>support vector machine</method>, <method>decision tree</method>, <method>random forest</method>, <method>Naïve Bayes</method>, <method>logistic regression</method>, <method>CatBoost</method>, <method>AdaBoost</method>, <method>five-fold cross-validation</method>, <method>SHapley Additive exPlanations (SHAP)</method>",<method>ensemble Machine Learning (ML) classifier</method><method>Random Forest</method><method>Support Vector Machine</method><method>Gaussian Naïve Bayes</method><method>Decision Tree classifier</method><method>support vector machine</method><method>decision tree</method><method>random forest</method><method>Naïve Bayes</method><method>logistic regression</method><method>CatBoost</method><method>AdaBoost</method><method>SHapley Additive exPlanations (SHAP)</method>
2024,https://openalex.org/W4393853620,Medicine,"The economics of deep and machine learning-based algorithms for COVID-19 prediction, detection, and diagnosis shaping the organizational management of hospitals","Research background: Deep and machine learning-based algorithms can assist in COVID-19 image-based medical diagnosis and symptom tracing, optimize intensive care unit admission, and use clinical data to determine patient prioritization and mortality risk, being pivotal in qualitative care provision, reducing medical errors, and increasing patient survival rates, thus diminishing the massive healthcare system burden in relation to severe COVID-19 inpatient stay duration, while increasing operational costs throughout the organizational management of hospitals. Data-driven financial and scenario-based contingency planning, predictive modelling tools, and risk pooling mechanisms should be deployed for additional medical equipment and unforeseen healthcare demand expenses. Purpose of the article: We show that deep and machine learning-based and clinical decision making systems can optimize patient survival likelihood and treatment outcomes with regard to susceptible, infected, and recovered individuals, performing accurate analyses by data modeling based on vital and clinical signs, surveillance data, and infection-related biomarkers, and furthering hospital facility optimization in terms of intensive care unit bed allocation. Methods: The review software systems employed for article screening and quality evaluation were: AMSTAR, AXIS, DistillerSR, Eppi-Reviewer, MMAT, PICO Portal, Rayyan, ROBIS, and SRDR. Findings &amp; value added: Deep and machine learning-based clinical decision support tools can forecast COVID-19 spread, confirmed cases, and infection and mortality rates for data-driven appropriate treatment and resource allocations in effective therapeutic and diagnosis protocol development, by determining suitable measures and regulations and by using symptoms and comorbidities, vital signs, clinical and laboratory data and medical records across intensive care units, impacting the healthcare financing infrastructure. As a result of heightened use of personal protective equipment, hospital pharmacy and medication, outpatient treatment, and medical supplies, revenue loss and financial vulnerability occur, also due to expenses related to hiring additional staff and to critical resource expenditures. Hospital costs for COVID-19 medical care, screening, treatment capacity expansion, and personal protective equipment can lead to further financial losses while affecting COVID-19 frontline hospital workers and patients.","<method>deep learning-based algorithms</method>, <method>machine learning-based algorithms</method>, <method>deep and machine learning-based clinical decision support tools</method>",No methods remaining
2024,https://openalex.org/W4393864192,Medicine,Comprehensive evaluation and performance analysis of machine learning in heart disease prediction,"Heart disease is a leading cause of mortality on a global scale. Accurately predicting cardiovascular disease poses a significant challenge within clinical data analysis. The present study introduces a prediction model that utilizes various combinations of information and employs multiple established classification approaches. The proposed technique combines the genetic algorithm (GA) and the recursive feature elimination method (RFEM) to select relevant features, thus enhancing the model's robustness. Techniques like the under sampling clustering oversampling method (USCOM) address the issue of data imbalance, thereby improving the model's predictive capabilities. The classification challenge employs a multilayer deep convolutional neural network (MLDCNN), trained using the adaptive elephant herd optimization method (AEHOM). The proposed machine learning-based heart disease prediction method (ML-HDPM) demonstrates outstanding performance across various crucial evaluation parameters, as indicated by its comprehensive assessment. During the training process, the ML-HDPM model exhibits a high level of performance, achieving an accuracy rate of 95.5% and a precision rate of 94.8%. The system's sensitivity (recall) performs with a high accuracy rate of 96.2%, while the F-score highlights its well-balanced performance, measuring 91.5%. It is worth noting that the specificity of ML-HDPM is recorded at a remarkable 89.7%. The findings underscore the potential of ML-HDPM to transform the prediction of heart disease and aid healthcare practitioners in providing precise diagnoses, exerting a substantial influence on patient care outcomes.","<method>genetic algorithm (GA)</method>, <method>recursive feature elimination method (RFEM)</method>, <method>under sampling clustering oversampling method (USCOM)</method>, <method>multilayer deep convolutional neural network (MLDCNN)</method>, <method>adaptive elephant herd optimization method (AEHOM)</method>",<method>genetic algorithm (GA)</method><method>multilayer deep convolutional neural network (MLDCNN)</method>
2024,https://openalex.org/W4396557972,Medicine,Enhancing breast cancer segmentation and classification: An Ensemble Deep Convolutional Neural Network and U-net approach on ultrasound images,"Breast cancer is a condition where the irregular growth of breast cells occurs uncontrollably, leading to the formation of tumors. It poses a significant threat to women's lives globally, emphasizing the need for enhanced methods of detecting and categorizing the disease. In this work, we propose an Ensemble Deep Convolutional Neural Network (EDCNN) model that exhibits superior accuracy compared to several transfer learning models and the Vision Transformer model. Our EDCNN model integrates the strengths of the MobileNet and Xception models to improve its performance in breast cancer detection and classification. We employ various preprocessing techniques, including image resizing, data normalization, and data augmentation, to prepare the data for analysis. By following these measures, the formatting is optimized, and the model's capacity to make generalizations is improved. We trained and evaluated our proposed EDCNN model using ultrasound images, a widely available modality for breast cancer imaging. The outcomes of our experiments illustrate that the EDCNN model attains an exceptional accuracy of 87.82% on Dataset 1 and 85.69% on Dataset 2, surpassing the performance of several well-known transfer learning models and the Vision Transformer model. Furthermore, an AUC value of 0.91 on Dataset 1 highlights the robustness and effectiveness of our proposed model. Moreover, we highlight the incorporation of the Grad-CAM Explainable Artificial Intelligence (XAI) technique to improve the interpretability and transparency of our proposed model. Additionally, we performed image segmentation using the U-Net segmentation technique on the input ultrasound images. This segmentation process allowed for the identification and isolation of specific regions of interest, facilitating a more comprehensive analysis of breast cancer characteristics. In conclusion, the study presents a creative approach to detecting and categorizing breast cancer, demonstrating the superior performance of the EDCNN model compared to well-established transfer learning models. Through advanced deep learning techniques and image segmentation, this study contributes to improving diagnosis and treatment outcomes in breast cancer.","<method>Ensemble Deep Convolutional Neural Network (EDCNN)</method>, <method>MobileNet</method>, <method>Xception</method>, <method>transfer learning models</method>, <method>Vision Transformer model</method>, <method>Grad-CAM Explainable Artificial Intelligence (XAI) technique</method>, <method>U-Net segmentation technique</method>",<method>MobileNet</method><method>Xception</method><method>transfer learning models</method><method>Vision Transformer model</method><method>Grad-CAM Explainable Artificial Intelligence (XAI) technique</method><method>U-Net segmentation technique</method>
2024,https://openalex.org/W4396894907,Medicine,Employing machine learning for enhanced abdominal fat prediction in cavitation post-treatment,"This study investigates the application of cavitation in non-invasive abdominal fat reduction and body contouring, a topic of considerable interest in the medical and aesthetic fields. We explore the potential of cavitation to alter abdominal fat composition and delve into the optimization of fat prediction models using advanced hyperparameter optimization techniques, Hyperopt and Optuna. Our objective is to enhance the predictive accuracy of abdominal fat dynamics post-cavitation treatment. Employing a robust dataset with abdominal fat measurements and cavitation treatment parameters, we evaluate the efficacy of our approach through regression analysis. The performance of Hyperopt and Optuna regression models is assessed using metrics such as mean squared error, mean absolute error, and R-squared score. Our results reveal that both models exhibit strong predictive capabilities, with R-squared scores reaching 94.12% and 94.11% for post-treatment visceral fat, and 71.15% and 70.48% for post-treatment subcutaneous fat predictions, respectively. Additionally, we investigate feature selection techniques to pinpoint critical predictors within the fat prediction models. Techniques including F-value selection, mutual information, recursive feature elimination with logistic regression and random forests, variance thresholding, and feature importance evaluation are utilized. The analysis identifies key features such as BMI, waist circumference, and pretreatment fat levels as significant predictors of post-treatment fat outcomes. Our findings underscore the effectiveness of hyperparameter optimization in refining fat prediction models and offer valuable insights for the advancement of non-invasive fat reduction methods. This research holds important implications for both the scientific community and clinical practitioners, paving the way for improved treatment strategies in the realm of body contouring.","<method>Hyperopt regression models</method>, <method>Optuna regression models</method>, <method>F-value selection</method>, <method>mutual information</method>, <method>recursive feature elimination with logistic regression</method>, <method>recursive feature elimination with random forests</method>, <method>variance thresholding</method>, <method>feature importance evaluation</method>",<method>mutual information</method><method>recursive feature elimination with logistic regression</method><method>recursive feature elimination with random forests</method><method>variance thresholding</method>
2024,https://openalex.org/W4397044870,Medicine,Advancements in Predictive Microbiology: Integrating New Technologies for Efficient Food Safety Models,"Predictive microbiology is a rapidly evolving field that has gained significant interest over the years due to its diverse application in food safety. Predictive models are widely used in food microbiology to estimate the growth of microorganisms in food products. These models represent the dynamic interactions between intrinsic and extrinsic food factors as mathematical equations and then apply these data to predict shelf life, spoilage, and microbial risk assessment. Due to their ability to predict the microbial risk, these tools are also integrated into hazard analysis critical control point (HACCP) protocols. However, like most new technologies, several limitations have been linked to their use. Predictive models have been found incapable of modeling the intricate microbial interactions in food colonized by different bacteria populations under dynamic environmental conditions. To address this issue, researchers are integrating several new technologies into predictive models to improve efficiency and accuracy. Increasingly, newer technologies such as whole genome sequencing (WGS), metagenomics, artificial intelligence, and machine learning are being rapidly adopted into newer-generation models. This has facilitated the development of devices based on robotics, the Internet of Things, and time-temperature indicators that are being incorporated into food processing both domestically and industrially globally. This study reviewed current research on predictive models, limitations, challenges, and newer technologies being integrated into developing more efficient models. Machine learning algorithms commonly employed in predictive modeling are discussed with emphasis on their application in research and industry and their advantages over traditional models.","<method>artificial intelligence</method>, <method>machine learning</method>, <method>machine learning algorithms</method>",<method>machine learning</method>
2024,https://openalex.org/W4399708678,Medicine,Detection of Parkinson disease using multiclass machine learning approach,"Parkinson's Disease (PD) is a prevalent neurological condition characterized by motor and cognitive impairments, typically manifesting around the age of 50 and presenting symptoms such as gait difficulties and speech impairments. Although a cure remains elusive, symptom management through medication is possible. Timely detection is pivotal for effective disease management. In this study, we leverage Machine Learning (ML) and Deep Learning (DL) techniques, specifically K-Nearest Neighbor (KNN) and Feed-forward Neural Network (FNN) models, to differentiate between individuals with PD and healthy individuals based on voice signal characteristics. Our dataset, sourced from the University of California at Irvine (UCI), comprises 195 voice recordings collected from 31 patients. To optimize model performance, we employ various strategies including Synthetic Minority Over-sampling Technique (SMOTE) for addressing class imbalance, Feature Selection to identify the most relevant features, and hyperparameter tuning using RandomizedSearchCV. Our experimentation reveals that the FNN and KSVM models, trained on an 80-20 split of the dataset for training and testing respectively, yield the most promising results. The FNN model achieves an impressive overall accuracy of 99.11%, with 98.78% recall, 99.96% precision, and a 99.23% f1-score. Similarly, the KSVM model demonstrates strong performance with an overall accuracy of 95.89%, recall of 96.88%, precision of 98.71%, and an f1-score of 97.62%. Overall, our study showcases the efficacy of ML and DL techniques in accurately identifying PD from voice signals, underscoring the potential for these approaches to contribute significantly to early diagnosis and intervention strategies for Parkinson's Disease.","<method>K-Nearest Neighbor (KNN)</method>, <method>Feed-forward Neural Network (FNN)</method>, <method>Synthetic Minority Over-sampling Technique (SMOTE)</method>, <method>Feature Selection</method>, <method>RandomizedSearchCV</method>, <method>KSVM</method>",<method>K-Nearest Neighbor (KNN)</method><method>Feed-forward Neural Network (FNN)</method><method>Feature Selection</method><method>RandomizedSearchCV</method><method>KSVM</method>
2024,https://openalex.org/W4400528496,Medicine,Deep learning empowered breast cancer diagnosis: Advancements in detection and classification,"Recent advancements in AI, driven by big data technologies, have reshaped various industries, with a strong focus on data-driven approaches. This has resulted in remarkable progress in fields like computer vision, e-commerce, cybersecurity, and healthcare, primarily fueled by the integration of machine learning and deep learning models. Notably, the intersection of oncology and computer science has given rise to Computer-Aided Diagnosis (CAD) systems, offering vital tools to aid medical professionals in tumor detection, classification, recurrence tracking, and prognosis prediction. Breast cancer, a significant global health concern, is particularly prevalent in Asia due to diverse factors like lifestyle, genetics, environmental exposures, and healthcare accessibility. Early detection through mammography screening is critical, but the accuracy of mammograms can vary due to factors like breast composition and tumor characteristics, leading to potential misdiagnoses. To address this, an innovative CAD system leveraging deep learning and computer vision techniques was introduced. This system enhances breast cancer diagnosis by independently identifying and categorizing breast lesions, segmenting mass lesions, and classifying them based on pathology. Thorough validation using the Curated Breast Imaging Subset of Digital Database for Screening Mammography (CBIS-DDSM) demonstrated the CAD system’s exceptional performance, with a 99% success rate in detecting and classifying breast masses. While the accuracy of detection is 98.5%, when segmenting breast masses into separate groups for examination, the method’s performance was approximately 95.39%. Upon completing all the analysis, the system’s classification phase yielded an overall accuracy of 99.16% for classification. The potential for this integrated framework to outperform current deep learning techniques is proposed, despite potential challenges related to the high number of trainable parameters. Ultimately, this recommended framework offers valuable support to researchers and physicians in breast cancer diagnosis by harnessing cutting-edge AI and image processing technologies, extending recent advances in deep learning to the medical domain.","<method>deep learning</method>, <method>computer vision techniques</method>",<method>deep learning</method>
2024,https://openalex.org/W4390611263,Medicine,Machine Learning in the Parkinson’s disease smartwatch (PADS) dataset,"Abstract The utilisation of smart devices, such as smartwatches and smartphones, in the field of movement disorders research has gained significant attention. However, the absence of a comprehensive dataset with movement data and clinical annotations, encompassing a wide range of movement disorders including Parkinson’s disease (PD) and its differential diagnoses (DD), presents a significant gap. The availability of such a dataset is crucial for the development of reliable machine learning (ML) models on smart devices, enabling the detection of diseases and monitoring of treatment efficacy in a home-based setting. We conducted a three-year cross-sectional study at a large tertiary care hospital. A multi-modal smartphone app integrated electronic questionnaires and smartwatch measures during an interactive assessment designed by neurologists to provoke subtle changes in movement pathologies. We captured over 5000 clinical assessment steps from 504 participants, including PD, DD, and healthy controls (HC). After age-matching, an integrative ML approach combining classical signal processing and advanced deep learning techniques was implemented and cross-validated. The models achieved an average balanced accuracy of 91.16% in the classification PD vs. HC, while PD vs. DD scored 72.42%. The numbers suggest promising performance while distinguishing similar disorders remains challenging. The extensive annotations, including details on demographics, medical history, symptoms, and movement steps, provide a comprehensive database to ML techniques and encourage further investigations into phenotypical biomarkers related to movement disorders.","<method>classical signal processing</method>, <method>advanced deep learning techniques</method>",No methods remaining
2024,https://openalex.org/W4390707476,Medicine,CT-Based Intratumoral and Peritumoral Radiomics Nomograms for the Preoperative Prediction of Spread Through Air Spaces in Clinical Stage IA Non-small Cell Lung Cancer,"The study aims to investigate the value of intratumoral and peritumoral radiomics and clinical-radiological features for predicting spread through air spaces (STAS) in patients with clinical stage IA non-small cell lung cancer (NSCLC). A total of 336 NSCLC patients from our hospital were randomly divided into the training cohort (n = 236) and the internal validation cohort (n = 100) at a ratio of 7:3, and 69 patients from the other two external hospitals were collected as the external validation cohort. Univariate and multivariate analyses were used to select clinical-radiological features and construct a clinical model. The GTV, PTV5, PTV10, PTV15, PTV20, GPTV5, GPTV10, GPTV15, and GPTV20 models were constructed based on intratumoral and peritumoral (5 mm, 10 mm, 15 mm, 20 mm) radiomics features. Additionally, the radscore of the optimal radiomics model and clinical-radiological predictors were used to construct a combined model and plot a nomogram. Lastly, the ROC curve and AUC value were used to evaluate the diagnostic performance of the model. Tumor density type (OR = 6.738) and distal ribbon sign (OR = 5.141) were independent risk factors for the occurrence of STAS. The GPTV10 model outperformed the other radiomics models, and its AUC values were 0.887, 0.876, and 0.868 in the three cohorts. The AUC values of the combined model constructed based on GPTV10 radscore and clinical-radiological predictors were 0.901, 0.875, and 0.878. DeLong test results revealed that the combined model was superior to the clinical model in the three cohorts. The nomogram based on GPTV10 radscore and clinical-radiological features exhibited high predictive efficiency for STAS status in NSCLC.",<method>radiomics</method>,No methods remaining
2024,https://openalex.org/W4390734415,Medicine,Cobdock: an accurate and practical machine learning-based consensus blind docking method,"Abstract Probing the surface of proteins to predict the binding site and binding affinity for a given small molecule is a critical but challenging task in drug discovery. Blind docking addresses this issue by performing docking on binding regions randomly sampled from the entire protein surface. However, compared with local docking, blind docking is less accurate and reliable because the docking space is too largetly sampled. Cavity detection-guided blind docking methods improved the accuracy by using cavity detection (also known as binding site detection) tools to guide the docking procedure. However, it is worth noting that the performance of these methods heavily relies on the quality of the cavity detection tool. This constraint, namely the dependence on a single cavity detection tool, significantly impacts the overall performance of cavity detection-guided methods. To overcome this limitation, we proposed Co nsensus B lind Dock (CoBDock), a novel blind, parallel docking method that uses machine learning algorithms to integrate docking and cavity detection results to improve not only binding site identification but also pose prediction accuracy. Our experiments on several datasets, including PDBBind 2020, ADS, MTi, DUD-E, and CASF-2016, showed that CoBDock has better binding site and binding mode performance than other state-of-the-art cavity detector tools and blind docking methods.",<method>machine learning algorithms</method>,No methods remaining
2024,https://openalex.org/W4390817372,Medicine,Brain structure ages—A new biomarker for multi‐disease classification,"Age is an important variable to describe the expected brain's anatomy status across the normal aging trajectory. The deviation from that normative aging trajectory may provide some insights into neurological diseases. In neuroimaging, predicted brain age is widely used to analyze different diseases. However, using only the brain age gap information (i.e., the difference between the chronological age and the estimated age) can be not enough informative for disease classification problems. In this paper, we propose to extend the notion of global brain age by estimating brain structure ages using structural magnetic resonance imaging. To this end, an ensemble of deep learning models is first used to estimate a 3D aging map (i.e., voxel-wise age estimation). Then, a 3D segmentation mask is used to obtain the final brain structure ages. This biomarker can be used in several situations. First, it enables to accurately estimate the brain age for the purpose of anomaly detection at the population level. In this situation, our approach outperforms several state-of-the-art methods. Second, brain structure ages can be used to compute the deviation from the normal aging process of each brain structure. This feature can be used in a multi-disease classification task for an accurate differential diagnosis at the subject level. Finally, the brain structure age deviations of individuals can be visualized, providing some insights about brain abnormality and helping clinicians in real medical contexts.",<method>ensemble of deep learning models</method>,<method>ensemble of deep learning models</method>
2024,https://openalex.org/W4391097175,Medicine,Toward Improving Breast Cancer Classification Using an Adaptive Voting Ensemble Learning Algorithm,"Over the past decade, breast cancer has been the most common type of cancer in women. Different methods were proposed for breast cancer detection. These methods mainly classify and categorize malignant and Benign tumors. Machine learning is a practical approach for breast cancer classification. Data mining and classification are effective methods to predict and categorize breast cancer. The optimum classification for detecting Breast Cancer (BC) is ensemble-based. The ensemble approach involves using multiple ways to find the best possible solution. This study used the Wisconsin Breast Cancer Diagnostic (WBCD) dataset. We created a voting ensemble classifier that combines four different machine learning models: Extra Trees Classifier (ETC), Light Gradient Boosting Machine (LightGBM), Ridge Classifier (RC), and Linear Discriminant Analysis (LDA). The proposed ELRL-E approach achieved an accuracy of 97.6%, a precision of 96.4%, a recall of 100%, and an F1 score of 98.1%. Various output evaluations are used to evaluate the performance and efficiency of the proposed model and other classifiers. Overall, the recommended strategy performed better. Results are directly compared with the individual classifier and different recognized state-of-the-art classifiers. The primary objective of this study is to identify the most influential ensemble machine learning classifier for breast cancer detection and diagnosis in terms of accuracy and AUC score.","<method>Machine learning</method>, <method>Data mining</method>, <method>classification</method>, <method>ensemble-based classification</method>, <method>voting ensemble classifier</method>, <method>Extra Trees Classifier (ETC)</method>, <method>Light Gradient Boosting Machine (LightGBM)</method>, <method>Ridge Classifier (RC)</method>, <method>Linear Discriminant Analysis (LDA)</method>",<method>Machine learning</method><method>ensemble-based classification</method><method>voting ensemble classifier</method><method>Extra Trees Classifier (ETC)</method><method>Light Gradient Boosting Machine (LightGBM)</method><method>Ridge Classifier (RC)</method><method>Linear Discriminant Analysis (LDA)</method>
2024,https://openalex.org/W4391324248,Medicine,"The Prediction of Clinical Mastitis in Dairy Cows Based on Milk Yield, Rumination Time, and Milk Electrical Conductivity Using Machine Learning Algorithms","In commercial dairy farms, mastitis is associated with increased antimicrobial use and associated resistance, which may affect milk production. This study aimed to develop sensor-based prediction models for naturally occurring clinical bovine mastitis using nine machine learning algorithms with data from 447 mastitic and 2146 healthy cows obtained from five commercial farms in Northeast China. The variables were related to daily activity, rumination time, and daily milk yield of cows, as well as milk electrical conductivity. Both Z-standardized and non-standardized datasets pertaining to four specific stages of lactation were used to train and test prediction models. For all four subgroups, the Z-standardized dataset yielded better results than those of the non-standardized one, with the multilayer artificial neural net algorithm showing the best performance. Variables of importance had a similar rank in this algorithm, indicating the consistency of these variables as predictors for bovine mastitis in commercial farms with similar automatic systems. Moreover, the peak milk yield (PMY) of mastitic cows was significantly higher than that of healthy cows (p &lt; 0.005), indicating that high-yielding cattle are more prone to mastitis. Our results show that machine learning algorithms are effective tools for predicting mastitis in dairy cows for immediate intervention and management in commercial farms.","<method>machine learning algorithms</method>, <method>multilayer artificial neural net algorithm</method>",<method>multilayer artificial neural net algorithm</method>
2024,https://openalex.org/W4391350390,Medicine,"Machine learning in physical activity, sedentary, and sleep behavior research","Abstract The nature of human movement and non-movement behaviors is complex and multifaceted, making their study complicated and challenging. Thanks to the availability of wearable activity monitors, we can now monitor the full spectrum of physical activity, sedentary, and sleep behaviors better than ever before—whether the subjects are elite athletes, children, adults, or individuals with pre-existing medical conditions. The increasing volume of generated data, combined with the inherent complexities of human movement and non-movement behaviors, necessitates the development of new data analysis methods for the research of physical activity, sedentary, and sleep behaviors. The characteristics of machine learning (ML) methods, including their ability to deal with complicated data, make them suitable for such analysis and thus can be an alternative tool to deal with data of this nature. ML can potentially be an excellent tool for solving many traditional problems related to the research of physical activity, sedentary, and sleep behaviors such as activity recognition, posture detection, profile analysis, and correlates research. However, despite this potential, ML has not yet been widely utilized for analyzing and studying these behaviors. In this review, we aim to introduce experts in physical activity, sedentary behavior, and sleep research—individuals who may possess limited familiarity with ML—to the potential applications of these techniques for analyzing their data. We begin by explaining the underlying principles of the ML modeling pipeline, highlighting the challenges and issues that need to be considered when applying ML. We then present the types of ML: supervised and unsupervised learning, and introduce a few ML algorithms frequently used in supervised and unsupervised learning. Finally, we highlight three research areas where ML methodologies have already been used in physical activity, sedentary behavior, and sleep behavior research, emphasizing their successes and challenges. This paper serves as a resource for ML in physical activity, sedentary, and sleep behavior research, offering guidance and resources to facilitate its utilization.","<method>machine learning (ML)</method>, <method>supervised learning</method>, <method>unsupervised learning</method>",<method>machine learning (ML)</method><method>supervised learning</method><method>unsupervised learning</method>
2024,https://openalex.org/W4391593760,Medicine,Enhanced Jaya Optimization Algorithm with Deep Learning Assisted Oral Cancer Diagnosis on IoT Healthcare Systems,"Recently, healthcare systems integrate the power of deep learning (DL) models with the connectivity and data processing capabilities of the Internet of Things (IoT) to enhance the early recognition and diagnosis of disease. Oral cancer diagnosis comprises the detection of cancerous or pre-cancerous abrasions in the oral cavity. Timely identification is essential for successful treatment and enhanced prognosis. Here is an overview of the key aspects of oral cancer diagnosis. One potential benefit of utilizing DL for oral cancer detection is that it analyses huge counts of data fast and accurately, and it could not need clear programming of the rules for recognizing abnormalities. This can create the procedure of detecting oral cancer more effective and efficient. Thus, the study presents an Enhanced Jaya Optimization Algorithm with Deep Learning Based Oral Cancer Classification (EJOADL-OCC) method. The presented EJOADL-OCC method aims to classify and detect the existence of oral cancer accurately and effectively. To accomplish this, the presented EJOADL-OCC method initially exploits median filtering for the noise elimination. Next, the feature vector generation process is performed by the residual network (ResNetv2) model with EJOA as a hyperparameter optimizer. For accurate classification of oral cancer, a continuously restricted Boltzmann machine with a deep belief network (CRBM-DBN) model. The simulated validation of the EJOADL-OCC algorithm is tested by the series of simulations and the outcome demonstrates its supremacy over present DL approaches.","<method>Deep Learning (DL)</method>, <method>Enhanced Jaya Optimization Algorithm (EJOA)</method>, <method>Residual Network (ResNetv2)</method>, <method>Continuously Restricted Boltzmann Machine with Deep Belief Network (CRBM-DBN)</method>",<method>Deep Learning (DL)</method><method>Residual Network (ResNetv2)</method>
2024,https://openalex.org/W4391730908,Medicine,Shedding light on ai in radiology: A systematic review and taxonomy of eye gaze-driven interpretability in deep learning,"X-ray imaging plays a crucial role in diagnostic medicine. Yet, a significant portion of the global population lacks access to this essential technology due to a shortage of trained radiologists. Eye-tracking data and deep learning models can enhance X-ray analysis by mapping expert focus areas, guiding automated anomaly detection, optimizing workflow efficiency, and bolstering training methods for novice radiologists. However, the literature shows contradictory results regarding the usefulness of eye-tracking data in deep-learning architectures for abnormality detection. We argue that these discrepancies between studies in the literature are due to (a) the way eye-tracking data is (or is not) processed, (b) the types of deep learning architectures chosen, and (c) the type of application that these architectures will have. We conducted a systematic literature review using PRISMA to address these contradicting results. We analyzed 60 studies that incorporated eye-tracking data in a deep-learning approach for different application goals in radiology. We performed a comparative analysis to understand if eye gaze data contains feature maps that can be useful under a deep learning approach and whether they can promote more interpretable predictions. To the best of our knowledge, this is the first survey in the area that performs a thorough investigation of eye gaze data processing techniques and their impacts in different deep learning architectures for applications such as error detection, classification, object detection, expertise level analysis, fatigue estimation and human attention prediction in medical imaging data. Our analysis resulted in two main contributions: (1) taxonomy that first divides the literature by task, enabling us to analyze the value eye movement can bring for each case and build guidelines regarding architectures and gaze processing techniques adequate for each application, and (2) an overall analysis of how eye gaze data can promote explainability in radiology.","<method>deep learning models</method>, <method>deep learning architectures</method>",No methods remaining
2024,https://openalex.org/W4390506881,Medicine,Discovering biomarkers associated and predicting cardiovascular disease with high accuracy using a novel nexus of machine learning techniques for precision medicine,"Abstract Personalized interventions are deemed vital given the intricate characteristics, advancement, inherent genetic composition, and diversity of cardiovascular diseases (CVDs). The appropriate utilization of artificial intelligence (AI) and machine learning (ML) methodologies can yield novel understandings of CVDs, enabling improved personalized treatments through predictive analysis and deep phenotyping. In this study, we proposed and employed a novel approach combining traditional statistics and a nexus of cutting-edge AI/ML techniques to identify significant biomarkers for our predictive engine by analyzing the complete transcriptome of CVD patients. After robust gene expression data pre-processing, we utilized three statistical tests (Pearson correlation, Chi-square test, and ANOVA) to assess the differences in transcriptomic expression and clinical characteristics between healthy individuals and CVD patients. Next, the recursive feature elimination classifier assigned rankings to transcriptomic features based on their relation to the case–control variable. The top ten percent of commonly observed significant biomarkers were evaluated using four unique ML classifiers (Random Forest, Support Vector Machine, Xtreme Gradient Boosting Decision Trees, and k-Nearest Neighbors). After optimizing hyperparameters, the ensembled models, which were implemented using a soft voting classifier, accurately differentiated between patients and healthy individuals. We have uncovered 18 transcriptomic biomarkers that are highly significant in the CVD population that were used to predict disease with up to 96% accuracy. Additionally, we cross-validated our results with clinical records collected from patients in our cohort. The identified biomarkers served as potential indicators for early detection of CVDs. With its successful implementation, our newly developed predictive engine provides a valuable framework for identifying patients with CVDs based on their biomarker profiles.","<method>recursive feature elimination classifier</method>, <method>Random Forest</method>, <method>Support Vector Machine</method>, <method>Xtreme Gradient Boosting Decision Trees</method>, <method>k-Nearest Neighbors</method>, <method>soft voting classifier</method>",<method>Random Forest</method><method>Support Vector Machine</method><method>Xtreme Gradient Boosting Decision Trees</method><method>k-Nearest Neighbors</method><method>soft voting classifier</method>
2024,https://openalex.org/W4392851477,Medicine,"Generative AI in healthcare: an implementation science informed translational path on application, integration and governance","Abstract Background Artificial intelligence (AI), particularly generative AI, has emerged as a transformative tool in healthcare, with the potential to revolutionize clinical decision-making and improve health outcomes. Generative AI, capable of generating new data such as text and images, holds promise in enhancing patient care, revolutionizing disease diagnosis and expanding treatment options. However, the utility and impact of generative AI in healthcare remain poorly understood, with concerns around ethical and medico-legal implications, integration into healthcare service delivery and workforce utilisation. Also, there is not a clear pathway to implement and integrate generative AI in healthcare delivery. Methods This article aims to provide a comprehensive overview of the use of generative AI in healthcare, focusing on the utility of the technology in healthcare and its translational application highlighting the need for careful planning, execution and management of expectations in adopting generative AI in clinical medicine. Key considerations include factors such as data privacy, security and the irreplaceable role of clinicians’ expertise. Frameworks like the technology acceptance model (TAM) and the Non-Adoption, Abandonment, Scale-up, Spread and Sustainability (NASSS) model are considered to promote responsible integration. These frameworks allow anticipating and proactively addressing barriers to adoption, facilitating stakeholder participation and responsibly transitioning care systems to harness generative AI’s potential. Results Generative AI has the potential to transform healthcare through automated systems, enhanced clinical decision-making and democratization of expertise with diagnostic support tools providing timely, personalized suggestions. Generative AI applications across billing, diagnosis, treatment and research can also make healthcare delivery more efficient, equitable and effective. However, integration of generative AI necessitates meticulous change management and risk mitigation strategies. Technological capabilities alone cannot shift complex care ecosystems overnight; rather, structured adoption programs grounded in implementation science are imperative. Conclusions It is strongly argued in this article that generative AI can usher in tremendous healthcare progress, if introduced responsibly. Strategic adoption based on implementation science, incremental deployment and balanced messaging around opportunities versus limitations helps promote safe, ethical generative AI integration. Extensive real-world piloting and iteration aligned to clinical priorities should drive development. With conscientious governance centred on human wellbeing over technological novelty, generative AI can enhance accessibility, affordability and quality of care. As these models continue advancing rapidly, ongoing reassessment and transparent communication around their strengths and weaknesses remain vital to restoring trust, realizing positive potential and, most importantly, improving patient outcomes.","<method>generative AI</method>, <method>technology acceptance model (TAM)</method>, <method>Non-Adoption, Abandonment, Scale-up, Spread and Sustainability (NASSS) model</method>, <method>implementation science</method>",No methods remaining
2024,https://openalex.org/W4390919701,Medicine,Chatbots and Large Language Models in Radiology: A Practical Primer for Clinical and Research Applications,"Although chatbots have existed for decades, the emergence of transformer-based large language models (LLMs) has captivated the world through the most recent wave of artificial intelligence chatbots, including ChatGPT. Transformers are a type of neural network architecture that enables better contextual understanding of language and efficient training on massive amounts of unlabeled data, such as unstructured text from the internet. As LLMs have increased in size, their improved performance and emergent abilities have revolutionized natural language processing. Since language is integral to human thought, applications based on LLMs have transformative potential in many industries. In fact, LLM-based chatbots have demonstrated human-level performance on many professional benchmarks, including in radiology. LLMs offer numerous clinical and research applications in radiology, several of which have been explored in the literature with encouraging results. Multimodal LLMs can simultaneously interpret text and images to generate reports, closely mimicking current diagnostic pathways in radiology. Thus, from requisition to report, LLMs have the opportunity to positively impact nearly every step of the radiology journey. Yet, these impressive models are not without limitations. This article reviews the limitations of LLMs and mitigation strategies, as well as potential uses of LLMs, including multimodal models. Also reviewed are existing LLM-based applications that can enhance efficiency in supervised settings.","<method>transformer-based large language models (LLMs)</method>, <method>Transformers</method>, <method>Multimodal LLMs</method>",<method>transformer-based large language models (LLMs)</method><method>Transformers</method><method>Multimodal LLMs</method>
2024,https://openalex.org/W4391292768,Medicine,Improving large language models for clinical named entity recognition via prompt engineering,"Abstract Importance The study highlights the potential of large language models, specifically GPT-3.5 and GPT-4, in processing complex clinical data and extracting meaningful information with minimal training data. By developing and refining prompt-based strategies, we can significantly enhance the models’ performance, making them viable tools for clinical NER tasks and possibly reducing the reliance on extensive annotated datasets. Objectives This study quantifies the capabilities of GPT-3.5 and GPT-4 for clinical named entity recognition (NER) tasks and proposes task-specific prompts to improve their performance. Materials and Methods We evaluated these models on 2 clinical NER tasks: (1) to extract medical problems, treatments, and tests from clinical notes in the MTSamples corpus, following the 2010 i2b2 concept extraction shared task, and (2) to identify nervous system disorder-related adverse events from safety reports in the vaccine adverse event reporting system (VAERS). To improve the GPT models' performance, we developed a clinical task-specific prompt framework that includes (1) baseline prompts with task description and format specification, (2) annotation guideline-based prompts, (3) error analysis-based instructions, and (4) annotated samples for few-shot learning. We assessed each prompt's effectiveness and compared the models to BioClinicalBERT. Results Using baseline prompts, GPT-3.5 and GPT-4 achieved relaxed F1 scores of 0.634, 0.804 for MTSamples and 0.301, 0.593 for VAERS. Additional prompt components consistently improved model performance. When all 4 components were used, GPT-3.5 and GPT-4 achieved relaxed F1 socres of 0.794, 0.861 for MTSamples and 0.676, 0.736 for VAERS, demonstrating the effectiveness of our prompt framework. Although these results trail BioClinicalBERT (F1 of 0.901 for the MTSamples dataset and 0.802 for the VAERS), it is very promising considering few training samples are needed. Discussion The study’s findings suggest a promising direction in leveraging LLMs for clinical NER tasks. However, while the performance of GPT models improved with task-specific prompts, there's a need for further development and refinement. LLMs like GPT-4 show potential in achieving close performance to state-of-the-art models like BioClinicalBERT, but they still require careful prompt engineering and understanding of task-specific knowledge. The study also underscores the importance of evaluation schemas that accurately reflect the capabilities and performance of LLMs in clinical settings. Conclusion While direct application of GPT models to clinical NER tasks falls short of optimal performance, our task-specific prompt framework, incorporating medical knowledge and training samples, significantly enhances GPT models' feasibility for potential clinical applications.","<method>GPT-3.5</method>, <method>GPT-4</method>, <method>prompt-based strategies</method>, <method>task-specific prompts</method>, <method>few-shot learning</method>, <method>BioClinicalBERT</method>",<method>GPT-3.5</method><method>GPT-4</method><method>prompt-based strategies</method><method>few-shot learning</method><method>BioClinicalBERT</method>
2024,https://openalex.org/W4390587679,Medicine,"A Systematic Review and Meta-Analysis of Artificial Intelligence Tools in Medicine and Healthcare: Applications, Considerations, Limitations, Motivation and Challenges","Artificial intelligence (AI) has emerged as a transformative force in various sectors, including medicine and healthcare. Large language models like ChatGPT showcase AI’s potential by generating human-like text through prompts. ChatGPT’s adaptability holds promise for reshaping medical practices, improving patient care, and enhancing interactions among healthcare professionals, patients, and data. In pandemic management, ChatGPT rapidly disseminates vital information. It serves as a virtual assistant in surgical consultations, aids dental practices, simplifies medical education, and aids in disease diagnosis. A total of 82 papers were categorised into eight major areas, which are G1: treatment and medicine, G2: buildings and equipment, G3: parts of the human body and areas of the disease, G4: patients, G5: citizens, G6: cellular imaging, radiology, pulse and medical images, G7: doctors and nurses, and G8: tools, devices and administration. Balancing AI’s role with human judgment remains a challenge. A systematic literature review using the PRISMA approach explored AI’s transformative potential in healthcare, highlighting ChatGPT’s versatile applications, limitations, motivation, and challenges. In conclusion, ChatGPT’s diverse medical applications demonstrate its potential for innovation, serving as a valuable resource for students, academics, and researchers in healthcare. Additionally, this study serves as a guide, assisting students, academics, and researchers in the field of medicine and healthcare alike.","<method>Large language models</method>, <method>ChatGPT</method>, <method>systematic literature review using the PRISMA approach</method>",No methods remaining
2024,https://openalex.org/W4392193191,Medicine,Challenges and barriers of using large language models (LLM) such as ChatGPT for diagnostic medicine with a focus on digital pathology – a recent scoping review,"Abstract Background The integration of large language models (LLMs) like ChatGPT in diagnostic medicine, with a focus on digital pathology, has garnered significant attention. However, understanding the challenges and barriers associated with the use of LLMs in this context is crucial for their successful implementation. Methods A scoping review was conducted to explore the challenges and barriers of using LLMs, in diagnostic medicine with a focus on digital pathology. A comprehensive search was conducted using electronic databases, including PubMed and Google Scholar, for relevant articles published within the past four years. The selected articles were critically analyzed to identify and summarize the challenges and barriers reported in the literature. Results The scoping review identified several challenges and barriers associated with the use of LLMs in diagnostic medicine. These included limitations in contextual understanding and interpretability, biases in training data, ethical considerations, impact on healthcare professionals, and regulatory concerns. Contextual understanding and interpretability challenges arise due to the lack of true understanding of medical concepts and lack of these models being explicitly trained on medical records selected by trained professionals, and the black-box nature of LLMs. Biases in training data pose a risk of perpetuating disparities and inaccuracies in diagnoses. Ethical considerations include patient privacy, data security, and responsible AI use. The integration of LLMs may impact healthcare professionals’ autonomy and decision-making abilities. Regulatory concerns surround the need for guidelines and frameworks to ensure safe and ethical implementation. Conclusion The scoping review highlights the challenges and barriers of using LLMs in diagnostic medicine with a focus on digital pathology. Understanding these challenges is essential for addressing the limitations and developing strategies to overcome barriers. It is critical for health professionals to be involved in the selection of data and fine tuning of the models. Further research, validation, and collaboration between AI developers, healthcare professionals, and regulatory bodies are necessary to ensure the responsible and effective integration of LLMs in diagnostic medicine.",<method>large language models (LLMs)</method>,No methods remaining
2024,https://openalex.org/W4390940921,Medicine,Solving olympiad geometry without human demonstrations,"Abstract Proving mathematical theorems at the olympiad level represents a notable milestone in human-level automated reasoning 1–4 , owing to their reputed difficulty among the world’s best talents in pre-university mathematics. Current machine-learning approaches, however, are not applicable to most mathematical domains owing to the high cost of translating human proofs into machine-verifiable format. The problem is even worse for geometry because of its unique translation challenges 1,5 , resulting in severe scarcity of training data. We propose AlphaGeometry, a theorem prover for Euclidean plane geometry that sidesteps the need for human demonstrations by synthesizing millions of theorems and proofs across different levels of complexity. AlphaGeometry is a neuro-symbolic system that uses a neural language model, trained from scratch on our large-scale synthetic data, to guide a symbolic deduction engine through infinite branching points in challenging problems. On a test set of 30 latest olympiad-level problems, AlphaGeometry solves 25, outperforming the previous best method that only solves ten problems and approaching the performance of an average International Mathematical Olympiad (IMO) gold medallist. Notably, AlphaGeometry produces human-readable proofs, solves all geometry problems in the IMO 2000 and 2015 under human expert evaluation and discovers a generalized version of a translated IMO theorem in 2004.","<method>neural language model</method>, <method>neuro-symbolic system</method>",<method>neural language model</method><method>neuro-symbolic system</method>
2024,https://openalex.org/W4390904004,Medicine,The Use of Artificial Intelligence in Writing Scientific Review Articles,"Abstract Purpose of Review With the recent explosion in the use of artificial intelligence (AI) and specifically ChatGPT, we sought to determine whether ChatGPT could be used to assist in writing credible, peer-reviewed, scientific review articles. We also sought to assess, in a scientific study, the advantages and limitations of using ChatGPT for this purpose. To accomplish this, 3 topics of importance in musculoskeletal research were selected: (1) the intersection of Alzheimer’s disease and bone; (2) the neural regulation of fracture healing; and (3) COVID-19 and musculoskeletal health. For each of these topics, 3 approaches to write manuscript drafts were undertaken: (1) human only; (2) ChatGPT only (AI-only); and (3) combination approach of #1 and #2 (AI-assisted). Articles were extensively fact checked and edited to ensure scientific quality, resulting in final manuscripts that were significantly different from the original drafts. Numerous parameters were measured throughout the process to quantitate advantages and disadvantages of approaches. Recent Findings Overall, use of AI decreased the time spent to write the review article, but required more extensive fact checking. With the AI-only approach, up to 70% of the references cited were found to be inaccurate. Interestingly, the AI-assisted approach resulted in the highest similarity indices suggesting a higher likelihood of plagiarism. Finally, although the technology is rapidly changing, at the time of study, ChatGPT 4.0 had a cutoff date of September 2021 rendering identification of recent articles impossible. Therefore, all literature published past the cutoff date was manually provided to ChatGPT, rendering approaches #2 and #3 identical for contemporary citations. As a result, for the COVID-19 and musculoskeletal health topic, approach #2 was abandoned midstream due to the extensive overlap with approach #3. Summary The main objective of this scientific study was to see whether AI could be used in a scientifically appropriate manner to improve the scientific writing process. Indeed, AI reduced the time for writing but had significant inaccuracies. The latter necessitates that AI cannot currently be used alone but could be used with careful oversight by humans to assist in writing scientific review articles.",<method>ChatGPT</method>,No methods remaining
2024,https://openalex.org/W4390833194,Medicine,Towards Conversational Diagnostic AI,"At the heart of medicine lies the physician-patient dialogue, where skillful history-taking paves the way for accurate diagnosis, effective management, and enduring trust. Artificial Intelligence (AI) systems capable of diagnostic dialogue could increase accessibility, consistency, and quality of care. However, approximating clinicians' expertise is an outstanding grand challenge. Here, we introduce AMIE (Articulate Medical Intelligence Explorer), a Large Language Model (LLM) based AI system optimized for diagnostic dialogue. AMIE uses a novel self-play based simulated environment with automated feedback mechanisms for scaling learning across diverse disease conditions, specialties, and contexts. We designed a framework for evaluating clinically-meaningful axes of performance including history-taking, diagnostic accuracy, management reasoning, communication skills, and empathy. We compared AMIE's performance to that of primary care physicians (PCPs) in a randomized, double-blind crossover study of text-based consultations with validated patient actors in the style of an Objective Structured Clinical Examination (OSCE). The study included 149 case scenarios from clinical providers in Canada, the UK, and India, 20 PCPs for comparison with AMIE, and evaluations by specialist physicians and patient actors. AMIE demonstrated greater diagnostic accuracy and superior performance on 28 of 32 axes according to specialist physicians and 24 of 26 axes according to patient actors. Our research has several limitations and should be interpreted with appropriate caution. Clinicians were limited to unfamiliar synchronous text-chat which permits large-scale LLM-patient interactions but is not representative of usual clinical practice. While further research is required before AMIE could be translated to real-world settings, the results represent a milestone towards conversational diagnostic AI.","<method>Large Language Model (LLM)</method>, <method>self-play based simulated environment</method>, <method>automated feedback mechanisms</method>",No methods remaining
2024,https://openalex.org/W4391577343,Medicine,The Image Biomarker Standardization Initiative: Standardized Convolutional Filters for Reproducible Radiomics and Enhanced Clinical Insights,"Filters are commonly used to enhance specific structures and patterns in images, such as vessels or peritumoral regions, to enable clinical insights beyond the visible image using radiomics. However, their lack of standardization restricts reproducibility and clinical translation of radiomics decision support tools. In this special report, teams of researchers who developed radiomics software participated in a three-phase study (September 2020 to December 2022) to establish a standardized set of filters. The first two phases focused on finding reference filtered images and reference feature values for commonly used convolutional filters: mean, Laplacian of Gaussian, Laws and Gabor kernels, separable and nonseparable wavelets (including decomposed forms), and Riesz transformations. In the first phase, 15 teams used digital phantoms to establish 33 reference filtered images of 36 filter configurations. In phase 2, 11 teams used a chest CT image to derive reference values for 323 of 396 features computed from filtered images using 22 filter and image processing configurations. Reference filtered images and feature values for Riesz transformations were not established. Reproducibility of standardized convolutional filters was validated on a public data set of multimodal imaging (CT, fluorodeoxyglucose PET, and T1-weighted MRI) in 51 patients with soft-tissue sarcoma. At validation, reproducibility of 486 features computed from filtered images using nine configurations × three imaging modalities was assessed using the lower bounds of 95% CIs of intraclass correlation coefficients. Out of 486 features, 458 were found to be reproducible across nine teams with lower bounds of 95% CIs of intraclass correlation coefficients greater than 0.75. In conclusion, eight filter types were standardized with reference filtered images and reference feature values for verifying and calibrating radiomics software packages. A web-based tool is available for compliance checking. © RSNA, 2024 Supplemental material is available for this article. See also the editorial by Huisman and D'Antonoli in this issue.","<method>mean convolutional filter</method>, <method>Laplacian of Gaussian filter</method>, <method>Laws filter</method>, <method>Gabor kernels</method>, <method>separable wavelets</method>, <method>nonseparable wavelets</method>, <method>Riesz transformations</method>",<method>nonseparable wavelets</method>
2024,https://openalex.org/W4392643126,Medicine,Generative Artificial Intelligence to Transform Inpatient Discharge Summaries to Patient-Friendly Language and Format,"Importance By law, patients have immediate access to discharge notes in their medical records. Technical language and abbreviations make notes difficult to read and understand for a typical patient. Large language models (LLMs [eg, GPT-4]) have the potential to transform these notes into patient-friendly language and format. Objective To determine whether an LLM can transform discharge summaries into a format that is more readable and understandable. Design, Setting, and Participants This cross-sectional study evaluated a sample of the discharge summaries of adult patients discharged from the General Internal Medicine service at NYU (New York University) Langone Health from June 1 to 30, 2023. Patients discharged as deceased were excluded. All discharge summaries were processed by the LLM between July 26 and August 5, 2023. Interventions A secure Health Insurance Portability and Accountability Act–compliant platform, Microsoft Azure OpenAI, was used to transform these discharge summaries into a patient-friendly format between July 26 and August 5, 2023. Main Outcomes and Measures Outcomes included readability as measured by Flesch-Kincaid Grade Level and understandability using Patient Education Materials Assessment Tool (PEMAT) scores. Readability and understandability of the original discharge summaries were compared with the transformed, patient-friendly discharge summaries created through the LLM. As balancing metrics, accuracy and completeness of the patient-friendly version were measured. Results Discharge summaries of 50 patients (31 female [62.0%] and 19 male [38.0%]) were included. The median patient age was 65.5 (IQR, 59.0-77.5) years. Mean (SD) Flesch-Kincaid Grade Level was significantly lower in the patient-friendly discharge summaries (6.2 [0.5] vs 11.0 [1.5]; P &amp;amp;lt; .001). PEMAT understandability scores were significantly higher for patient-friendly discharge summaries (81% vs 13%; P &amp;amp;lt; .001). Two physicians reviewed each patient-friendly discharge summary for accuracy on a 6-point scale, with 54 of 100 reviews (54.0%) giving the best possible rating of 6. Summaries were rated entirely complete in 56 reviews (56.0%). Eighteen reviews noted safety concerns, mostly involving omissions, but also several inaccurate statements (termed hallucinations). Conclusions and Relevance The findings of this cross-sectional study of 50 discharge summaries suggest that LLMs can be used to translate discharge summaries into patient-friendly language and formats that are significantly more readable and understandable than discharge summaries as they appear in electronic health records. However, implementation will require improvements in accuracy, completeness, and safety. Given the safety concerns, initial implementation will require physician review.",<method>Large language models (LLMs)</method>,No methods remaining
2024,https://openalex.org/W4391968719,Medicine,Artificial intelligence and IoT driven technologies for environmental pollution monitoring and management,"Detecting hazardous substances in the environment is crucial for protecting human wellbeing and ecosystems. As technology continues to advance, artificial intelligence (AI) has emerged as a promising tool for creating sensors that can effectively detect and analyze these hazardous substances. The increasing advancements in information technology have led to a growing interest in utilizing this technology for environmental pollution detection. AI-driven sensor systems, AI and Internet of Things (IoT) can be efficiently used for environmental monitoring, such as those for detecting air pollutants, water contaminants, and soil toxins. With the increasing concerns about the detrimental impact of legacy and emerging hazardous substances on ecosystems and human health, it is necessary to develop advanced monitoring systems that can efficiently detect, analyze, and respond to potential risks. Therefore, this review aims to explore recent advancements in using AI, sensors and IOTs for environmental pollution monitoring, taking into account the complexities of predicting and tracking pollution changes due to the dynamic nature of the environment. Integrating machine learning (ML) methods has the potential to revolutionize environmental science, but it also poses challenges. Important considerations include balancing model performance and interpretability, understanding ML model requirements, selecting appropriate models, and addressing concerns related to data sharing. Through examining these issues, this study seeks to highlight the latest trends in leveraging AI and IOT for environmental pollution monitoring.","<method>artificial intelligence (AI)</method>, <method>machine learning (ML) methods</method>",No methods remaining
2024,https://openalex.org/W4392754729,Medicine,"Revolutionizing agriculture with artificial intelligence: plant disease detection methods, applications, and their limitations","Accurate and rapid plant disease detection is critical for enhancing long-term agricultural yield. Disease infection poses the most significant challenge in crop production, potentially leading to economic losses. Viruses, fungi, bacteria, and other infectious organisms can affect numerous plant parts, including roots, stems, and leaves. Traditional techniques for plant disease detection are time-consuming, require expertise, and are resource-intensive. Therefore, automated leaf disease diagnosis using artificial intelligence (AI) with Internet of Things (IoT) sensors methodologies are considered for the analysis and detection. This research examines four crop diseases: tomato, chilli, potato, and cucumber. It also highlights the most prevalent diseases and infections in these four types of vegetables, along with their symptoms. This review provides detailed predetermined steps to predict plant diseases using AI. Predetermined steps include image acquisition, preprocessing, segmentation, feature selection, and classification. Machine learning (ML) and deep understanding (DL) detection models are discussed. A comprehensive examination of various existing ML and DL-based studies to detect the disease of the following four crops is discussed, including the datasets used to evaluate these studies. We also provided the list of plant disease detection datasets. Finally, different ML and DL application problems are identified and discussed, along with future research prospects, by combining AI with IoT platforms like smart drones for field-based disease detection and monitoring. This work will help other practitioners in surveying different plant disease detection strategies and the limits of present systems.","<method>image acquisition</method>, <method>preprocessing</method>, <method>segmentation</method>, <method>feature selection</method>, <method>classification</method>, <method>machine learning (ML)</method>, <method>deep learning (DL)</method>",<method>feature selection</method><method>machine learning (ML)</method><method>deep learning (DL)</method>
2024,https://openalex.org/W4392386497,Medicine,Clinical applications of artificial intelligence in robotic surgery,"Abstract Artificial intelligence (AI) is revolutionizing nearly every aspect of modern life. In the medical field, robotic surgery is the sector with some of the most innovative and impactful advancements. In this narrative review, we outline recent contributions of AI to the field of robotic surgery with a particular focus on intraoperative enhancement. AI modeling is allowing surgeons to have advanced intraoperative metrics such as force and tactile measurements, enhanced detection of positive surgical margins, and even allowing for the complete automation of certain steps in surgical procedures. AI is also Query revolutionizing the field of surgical education. AI modeling applied to intraoperative surgical video feeds and instrument kinematics data is allowing for the generation of automated skills assessments. AI also shows promise for the generation and delivery of highly specialized intraoperative surgical feedback for training surgeons. Although the adoption and integration of AI show promise in robotic surgery, it raises important, complex ethical questions. Frameworks for thinking through ethical dilemmas raised by AI are outlined in this review. AI enhancements in robotic surgery is some of the most groundbreaking research happening today, and the studies outlined in this review represent some of the most exciting innovations in recent years.",<method>AI modeling</method>,No methods remaining
2024,https://openalex.org/W4392791588,Medicine,Can large language models replace humans in systematic reviews? Evaluating <scp>GPT</scp>‐4's efficacy in screening and extracting data from peer‐reviewed and grey literature in multiple languages,"Systematic reviews are vital for guiding practice, research and policy, although they are often slow and labour-intensive. Large language models (LLMs) could speed up and automate systematic reviews, but their performance in such tasks has yet to be comprehensively evaluated against humans, and no study has tested Generative Pre-Trained Transformer (GPT)-4, the biggest LLM so far. This pre-registered study uses a ""human-out-of-the-loop"" approach to evaluate GPT-4's capability in title/abstract screening, full-text review and data extraction across various literature types and languages. Although GPT-4 had accuracy on par with human performance in some tasks, results were skewed by chance agreement and dataset imbalance. Adjusting for these caused performance scores to drop across all stages: for data extraction, performance was moderate, and for screening, it ranged from none in highly balanced literature datasets (~1:1) to moderate in those datasets where the ratio of inclusion to exclusion in studies was imbalanced (~1:3). When screening full-text literature using highly reliable prompts, GPT-4's performance was more robust, reaching ""human-like"" levels. Although our findings indicate that, currently, substantial caution should be exercised if LLMs are being used to conduct systematic reviews, they also offer preliminary evidence that, for certain review tasks delivered under specific conditions, LLMs can rival human performance.","<method>Large language models (LLMs)</method>, <method>Generative Pre-Trained Transformer (GPT)-4</method>",<method>Generative Pre-Trained Transformer (GPT)-4</method>
2024,https://openalex.org/W4390496023,Medicine,Improved Support Vector Machine based on CNN-SVD for vision-threatening diabetic retinopathy detection and classification,"The integration of artificial intelligence (AI) in diagnosing diabetic retinopathy, a major contributor to global vision impairment, is becoming increasingly pronounced. Notably, the detection of vision-threatening diabetic retinopathy (VTDR) has been significantly fortified through automated techniques. Traditionally, the reliance on manual analysis of retinal images, albeit slow and error-prone, constituted the conventional approach. Addressing this, our study introduces a novel methodology that amplifies the robustness and precision of the detection process. This is complemented by the groundbreaking Hierarchical Block Attention (HBA) and HBA-U-Net architecture, which notably propel attention mechanisms in image segmentation. This innovative model refines image processing without imposing excessive computational demands by honing in on individual pixel intricacies, spatial relationships, and channel-specific attention. Building upon this innovation, our proposed method employs a multi-stage strategy encompassing data pre-processing, feature extraction via a hybrid CNN-SVD model, and classification employing an amalgamation of Improved Support Vector Machine-Radial Basis Function (ISVM-RBF), DT, and KNN techniques. Rigorously tested on the IDRiD dataset classified into five severity tiers, the hybrid model yields remarkable performance, achieving a 99.18% accuracy, 98.15% sensitivity, and 100% specificity in VTDR detection, thus surpassing existing methods. These results underscore a more potent avenue for diagnosing and addressing this crucial ocular condition while underscoring AI's transformative potential in medical care, particularly in ophthalmology.","<method>Hierarchical Block Attention (HBA)</method>, <method>HBA-U-Net architecture</method>, <method>hybrid CNN-SVD model</method>, <method>Improved Support Vector Machine-Radial Basis Function (ISVM-RBF)</method>, <method>DT</method>, <method>KNN</method>",<method>hybrid CNN-SVD model</method><method>DT</method><method>KNN</method>
2024,https://openalex.org/W4391572037,Medicine,Machine Learning Applications in Healthcare: Current Trends and Future Prospects,"The integration of machine learning (ML) in healthcare has witnessed remarkable advancements, transforming the landscape of medical diagnosis, treatment, and overall patient care. This article provides a comprehensive review of the current trends and future prospects of machine learning applications in the healthcare domain.The current landscape is characterized by the utilization of ML algorithms for disease diagnosis and risk prediction, personalized treatment plans, and efficient healthcare resource management. Notable applications include image recognition for radiology and pathology, predictive analytics for disease prognosis, and the development of precision medicine tailored to individual patient profiles.This review explores the evolving role of ML in improving patient outcomes, enhancing clinical decision-making, and optimizing healthcare workflows. It delves into the challenges faced in integrating ML into existing healthcare systems, such as data privacy concerns, interpretability of complex models, and the need for robust validation processes.Additionally, the article discusses future prospects and emerging trends in ML healthcare applications, including the potential for predictive analytics to preemptively identify health issues, the integration of wearable devices and remote monitoring for continuous patient care, and the intersection of ML with genomics for personalized medicine.The overarching goal of this article is to provide healthcare professionals, researchers, and policymakers with insights into the current state of ML applications in healthcare, along with an outlook on the transformative potential that machine learning holds for the future of healthcare delivery and patient outcomes.","<method>machine learning (ML) algorithms</method>, <method>image recognition</method>, <method>predictive analytics</method>",No methods remaining
2024,https://openalex.org/W4399885365,Medicine,Convolutional neural network classification of cancer cytopathology images: taking breast cancer as an example,"Breast cancer is a relatively common cancer among gynecological cancers. Its diagnosis often relies on the pathology of cells in the lesion. The pathological diagnosis of breast cancer not only requires professionals and time, but also sometimes involves subjective judgment. To address the challenges of dependence on pathologists expertise and the time-consuming nature of achieving accurate breast pathological image classification, this paper introduces an approach utilizing convolutional neural networks (CNNs) for the rapid categorization of pathological images, aiming to enhance the efficiency of breast pathological image detection. And the approach enables the rapid and automatic classification of pathological images into benign and malignant groups. The methodology involves utilizing a convolutional neural network (CNN) model leveraging the Inceptionv3 architecture and transfer learning algorithm for extracting features from pathological images. Utilizing a neural network with fully connected layers and employing the SoftMax function for image classification. Additionally, the concept of image partitioning is introduced to handle high-resolution images. To achieve the ultimate classification outcome, the classification probabilities of each image block are aggregated using three algorithms: summation, product, and maximum. Experimental validation was conducted on the BreaKHis public dataset, resulting in accuracy rates surpassing 0.92 across all four magnification coefficients (40X, 100X, 200X, and 400X). It demonstrates that the proposed method effectively enhances the accuracy in classifying pathological images of breast cancer.","<method>convolutional neural networks (CNNs)</method>, <method>Inceptionv3 architecture</method>, <method>transfer learning algorithm</method>, <method>neural network with fully connected layers</method>, <method>SoftMax function for image classification</method>, <method>image partitioning</method>, <method>aggregation algorithms: summation, product, and maximum</method>",<method>convolutional neural networks (CNNs)</method><method>Inceptionv3 architecture</method><method>transfer learning algorithm</method><method>neural network with fully connected layers</method>
2024,https://openalex.org/W4395050972,Medicine,Optimization of hepatological clinical guidelines interpretation by large language models: a retrieval augmented generation-based framework,"Abstract Large language models (LLMs) can potentially transform healthcare, particularly in providing the right information to the right provider at the right time in the hospital workflow. This study investigates the integration of LLMs into healthcare, specifically focusing on improving clinical decision support systems (CDSSs) through accurate interpretation of medical guidelines for chronic Hepatitis C Virus infection management. Utilizing OpenAI’s GPT-4 Turbo model, we developed a customized LLM framework that incorporates retrieval augmented generation (RAG) and prompt engineering. Our framework involved guideline conversion into the best-structured format that can be efficiently processed by LLMs to provide the most accurate output. An ablation study was conducted to evaluate the impact of different formatting and learning strategies on the LLM’s answer generation accuracy. The baseline GPT-4 Turbo model’s performance was compared against five experimental setups with increasing levels of complexity: inclusion of in-context guidelines, guideline reformatting, and implementation of few-shot learning. Our primary outcome was the qualitative assessment of accuracy based on expert review, while secondary outcomes included the quantitative measurement of similarity of LLM-generated responses to expert-provided answers using text-similarity scores. The results showed a significant improvement in accuracy from 43 to 99% ( p &lt; 0.001), when guidelines were provided as context in a coherent corpus of text and non-text sources were converted into text. In addition, few-shot learning did not seem to improve overall accuracy. The study highlights that structured guideline reformatting and advanced prompt engineering (data quality vs. data quantity) can enhance the efficacy of LLM integrations to CDSSs for guideline delivery.","<method>Large language models (LLMs)</method>, <method>OpenAI’s GPT-4 Turbo model</method>, <method>retrieval augmented generation (RAG)</method>, <method>prompt engineering</method>, <method>few-shot learning</method>",<method>OpenAI’s GPT-4 Turbo model</method><method>retrieval augmented generation (RAG)</method><method>few-shot learning</method>
2024,https://openalex.org/W4393247259,Medicine,Employing deep learning and transfer learning for accurate brain tumor detection,"Abstract Artificial intelligence-powered deep learning methods are being used to diagnose brain tumors with high accuracy, owing to their ability to process large amounts of data. Magnetic resonance imaging stands as the gold standard for brain tumor diagnosis using machine vision, surpassing computed tomography, ultrasound, and X-ray imaging in its effectiveness. Despite this, brain tumor diagnosis remains a challenging endeavour due to the intricate structure of the brain. This study delves into the potential of deep transfer learning architectures to elevate the accuracy of brain tumor diagnosis. Transfer learning is a machine learning technique that allows us to repurpose pre-trained models on new tasks. This can be particularly useful for medical imaging tasks, where labelled data is often scarce. Four distinct transfer learning architectures were assessed in this study: ResNet152, VGG19, DenseNet169, and MobileNetv3. The models were trained and validated on a dataset from benchmark database: Kaggle. Five-fold cross validation was adopted for training and testing. To enhance the balance of the dataset and improve the performance of the models, image enhancement techniques were applied to the data for the four categories: pituitary, normal, meningioma, and glioma. MobileNetv3 achieved the highest accuracy of 99.75%, significantly outperforming other existing methods. This demonstrates the potential of deep transfer learning architectures to revolutionize the field of brain tumor diagnosis.","<method>deep learning</method>, <method>machine vision</method>, <method>deep transfer learning architectures</method>, <method>transfer learning</method>, <method>ResNet152</method>, <method>VGG19</method>, <method>DenseNet169</method>, <method>MobileNetv3</method>, <method>five-fold cross validation</method>",<method>deep learning</method><method>deep transfer learning architectures</method><method>transfer learning</method><method>ResNet152</method><method>VGG19</method><method>DenseNet169</method><method>MobileNetv3</method>
2024,https://openalex.org/W4390880481,Medicine,Liquid-metal-based three-dimensional microelectrode arrays integrated with implantable ultrathin retinal prosthesis for vision restoration,"Abstract Electronic retinal prostheses for stimulating retinal neurons are promising for vision restoration. However, the rigid electrodes of conventional retinal implants can inflict damage on the soft retina tissue. They also have limited selectivity due to their poor proximity to target cells in the degenerative retina. Here we present a soft artificial retina (thickness, 10 μm) where flexible ultrathin photosensitive transistors are integrated with three-dimensional stimulation electrodes of eutectic gallium–indium alloy. Platinum nanoclusters locally coated only on the tip of these three-dimensional liquid-metal electrodes show advantages in reducing the impedance of the stimulation electrodes. These microelectrodes can enhance the proximity to the target retinal ganglion cells and provide effective charge injections (72.84 mC cm −2 ) to elicit neural responses in the retina. Their low Young’s modulus (234 kPa), owing to their liquid form, can minimize damage to the retina. Furthermore, we used an unsupervised machine learning approach to effectively identify the evoked spikes to grade neural activities within the retinal ganglion cells. Results from in vivo experiments on a retinal degeneration mouse model reveal that the spatiotemporal distribution of neural responses on their retina can be mapped under selective localized illumination areas of light, suggesting the restoration of their vision.",<method>unsupervised machine learning</method>,<method>unsupervised machine learning</method>
2024,https://openalex.org/W4390584313,Medicine,A Conceptual Model for Inclusive Technology: Advancing Disability Inclusion through Artificial Intelligence,"Artificial intelligence (AI) has ushered in transformative changes, championing inclusion and accessibility for individuals with disabilities. This article delves into the remarkable AI-driven solutions that have revolutionized their lives across various domains. From assistive technologies such as voice recognition and AI-powered smart glasses catering to diverse needs, to healthcare benefiting from early disease detection algorithms and wearable devices that monitor vital signs and alert caregivers in emergencies, AI has steered in significant enhancements. Moreover, AI-driven prosthetics and exoskeletons have substantially improved mobility for those with limb impairments. The realm of education has not been left untouched, with AI tools creating inclusive learning environments that adapt to individual learning styles, paving the way for academic success among students with disabilities. However, the boundless potential of AI also presents ethical concerns and challenges. Issues like safeguarding data privacy, mitigating algorithmic bias, and bridging the digital divide must be thoughtfully addressed to fully harness AI’s potential in empowering individuals with disabilities. To complement these achievements, a robust conceptual model for AI disability inclusion serves as the theoretical framework, guiding the development of tailored AI solutions. By striking a harmonious balance between innovation and ethics, AI has the power to significantly enhance the overall quality of life for individuals with disabilities across a spectrum of vital areas.","<method>voice recognition</method>, <method>early disease detection algorithms</method>",No methods remaining
2024,https://openalex.org/W4391103530,Medicine,Transformative Breast Cancer Diagnosis using CNNs with Optimized ReduceLROnPlateau and Early Stopping Enhancements,"Abstract Breast cancer stands as a paramount public health concern worldwide, underscoring an imperative necessity within the research sphere for precision-driven and efficacious methodologies facilitating accurate detection. The existing diagnostic approaches in breast cancer often suffer from limitations in accuracy and efficiency, leading to delayed detection and subsequent challenges in personalized treatment planning. The primary focus of this research is to overcome these shortcomings by harnessing the power of advanced deep learning techniques, thereby revolutionizing the precision and reliability of breast cancer classification. This research addresses the critical need for improved breast cancer diagnostics by introducing a novel Convolutional Neural Network (CNN) model integrated with an Early Stopping callback and ReduceLROnPlateau callback. By enhancing the precision and reliability of breast cancer classification, the study aims to overcome the limitations of existing diagnostic methods, ultimately leading to better patient outcomes and reduced mortality rates. The comprehensive methodology includes diverse datasets, meticulous image preprocessing, robust model training, and validation strategies, emphasizing the model's adaptability and reliability in varied clinical contexts. The findings showcase the CNN model's exceptional performance, achieving a 95.2% accuracy rate in distinguishing cancerous and non-cancerous breast tissue in the integrated dataset, thereby demonstrating its potential for enhancing clinical decision-making and fostering the development of AI-driven diagnostic solutions.","<method>Convolutional Neural Network (CNN)</method>, <method>Early Stopping callback</method>, <method>ReduceLROnPlateau callback</method>",<method>Convolutional Neural Network (CNN)</method><method>Early Stopping callback</method>
2024,https://openalex.org/W4391528827,Medicine,Deep learning-aided decision support for diagnosis of skin disease across skin tones,"Abstract Although advances in deep learning systems for image-based medical diagnosis demonstrate their potential to augment clinical decision-making, the effectiveness of physician–machine partnerships remains an open question, in part because physicians and algorithms are both susceptible to systematic errors, especially for diagnosis of underrepresented populations. Here we present results from a large-scale digital experiment involving board-certified dermatologists ( n = 389) and primary-care physicians ( n = 459) from 39 countries to evaluate the accuracy of diagnoses submitted by physicians in a store-and-forward teledermatology simulation. In this experiment, physicians were presented with 364 images spanning 46 skin diseases and asked to submit up to four differential diagnoses. Specialists and generalists achieved diagnostic accuracies of 38% and 19%, respectively, but both specialists and generalists were four percentage points less accurate for the diagnosis of images of dark skin as compared to light skin. Fair deep learning system decision support improved the diagnostic accuracy of both specialists and generalists by more than 33%, but exacerbated the gap in the diagnostic accuracy of generalists across skin tones. These results demonstrate that well-designed physician–machine partnerships can enhance the diagnostic accuracy of physicians, illustrating that success in improving overall diagnostic accuracy does not necessarily address bias.",<method>deep learning system decision support</method>,No methods remaining
2024,https://openalex.org/W4391094954,Medicine,Artificial Intelligence in Surgery: The Future is Now,"Background Clinical Artificial intelligence (AI) has reached a critical inflection point. Advances in algorithmic science and increased understanding of operational considerations in AI deployment are opening the door to widespread clinical pathway transformation. For surgery in particular, the application of machine learning algorithms in fields such as computer vision and operative robotics are poised to radically change how we screen, diagnose, risk-stratify, treat and follow-up patients, in both pre- and post-operative stages, and within operating theatres. Summary In this paper, we summarise the current landscape of existing and emerging integrations within complex surgical care pathways. We investigate effective methods for practical use of AI throughout the patient pathway, from early screening and accurate diagnosis to intraoperative robotics, post-operative monitoring and follow-up. Horizon scanning of AI technologies in surgery is used to identify novel innovations that can enhance surgical practice today, with potential for paradigm shifts across core domains of surgical practice in the future. Any AI-driven future must be built on responsible and ethical usage, reinforced by effective oversight of data governance, and of risks to patient safety in deployment. Implementation is additionally bound to considerations of usability and pathway feasibility, and the need for robust healthcare technology assessment and evidence generation. While these factors are traditionally seen as barriers to translating AI into practice, we discuss how holistic implementation practices can create a solid foundation for scaling AI across pathways. Key Messages The next decade will see rapid translation of experimental development into real-world impact. AI will require evolution of work practices, but will also enhance patient safety, enhance surgical quality outcomes, and provide significant value for surgeons and health systems. Surgical practice has always sat on a bedrock of technological innovation. For those that follow this tradition, the future of AI in surgery starts now.",<method>machine learning algorithms</method>,No methods remaining
2024,https://openalex.org/W4391177783,Medicine,"Making food systems more resilient to food safety risks by including artificial intelligence, big data, and internet of things into food safety early warning and emerging risk identification tools","Abstract To enhance the resilience of food systems to food safety risks, it is vitally important for national authorities and international organizations to be able to identify emerging food safety risks and to provide early warning signals in a timely manner. This review provides an overview of existing and experimental applications of artificial intelligence (AI), big data, and internet of things as part of early warning and emerging risk identification tools and methods in the food safety domain. There is an ongoing rapid development of systems fed by numerous, real‐time, and diverse data with the aim of early warning and identification of emerging food safety risks. The suitability of big data and AI to support such systems is illustrated by two cases in which climate change drives the emergence of risks, namely, harmful algal blooms affecting seafood and fungal growth and mycotoxin formation in crops. Automation and machine learning are crucial for the development of future real‐time food safety risk early warning systems. Although these developments increase the feasibility and effectiveness of prospective early warning and emerging risk identification tools, their implementation may prove challenging, particularly for low‐ and middle‐income countries due to low connectivity and data availability. It is advocated to overcome these challenges by improving the capability and capacity of national authorities, as well as by enhancing their collaboration with the private sector and international organizations.","<method>artificial intelligence (AI)</method>, <method>machine learning</method>",<method>machine learning</method>
2024,https://openalex.org/W4402780379,Medicine,Investigating Spatial Effects through Machine Learning and Leveraging Explainable AI for Child Malnutrition in Pakistan,"While socioeconomic gradients in regional health inequalities are firmly established, the synergistic interactions between socioeconomic deprivation and climate vulnerability within convenient proximity and neighbourhood locations with health disparities remain poorly explored and thus require deep understanding within a regional context. Furthermore, disregarding the importance of spatial spillover effects and nonlinear effects of covariates on childhood stunting are inevitable in dealing with an enduring issue of regional health inequalities. The present study aims to investigate the spatial inequalities in childhood stunting at the district level in Pakistan and validate the importance of spatial lag in predicting childhood stunting. Furthermore, it examines the presence of any nonlinear relationships among the selected independent features with childhood stunting. The study utilized data related to socioeconomic features from MICS 2017–2018 and climatic data from Integrated Contextual Analysis. A multi-model approach was employed to address the research questions, which included Ordinary Least Squares Regression (OLS), various Spatial Models, Machine Learning Algorithms and Explainable Artificial Intelligence methods. Firstly, OLS was used to analyse and test the linear relationships among selected variables. Secondly, Spatial Durbin Error Model (SDEM) was used to detect and capture the impact of spatial spillover on childhood stunting. Third, XGBoost and Random Forest machine learning algorithms were employed to examine and validate the importance of the spatial lag component. Finally, EXAI methods such as SHapley were utilized to identify potential nonlinear relationships. The study found a clear pattern of spatial clustering and geographical disparities in childhood stunting, with multidimensional poverty, high climate vulnerability and early marriage worsening childhood stunting. In contrast, low climate vulnerability, high exposure to mass media and high women’s literacy were found to reduce childhood stunting. The use of machine learning algorithms, specifically XGBoost and Random Forest, highlighted the significant role played by the average value in the neighbourhood in predicting childhood stunting in nearby districts, confirming that the spatial spillover effect is not bounded by geographical boundaries. Furthermore, EXAI methods such as partial dependency plot reveal the existence of a nonlinear relationship between multidimensional poverty and childhood stunting. The study’s findings provide valuable insights into the spatial distribution of childhood stunting in Pakistan, emphasizing the importance of considering spatial effects in predicting childhood stunting. Individual and household-level factors such as exposure to mass media and women’s literacy have shown positive implications for childhood stunting. It further provides a justification for the usage of EXAI methods to draw better insights and propose customised intervention policies accordingly.","<method>Ordinary Least Squares Regression (OLS)</method>, <method>Spatial Durbin Error Model (SDEM)</method>, <method>XGBoost</method>, <method>Random Forest</method>, <method>Explainable Artificial Intelligence (EXAI) methods</method>, <method>SHapley</method>, <method>partial dependency plot</method>",<method>XGBoost</method><method>Random Forest</method><method>partial dependency plot</method>
2024,https://openalex.org/W4394572337,Medicine,Methods of determining optimal cut-point of diagnostic biomarkers with application of clinical data in ROC analysis: an update review,"Abstract Introduction An important application of ROC analysis is the determination of the optimal cut-point for biomarkers in diagnostic studies. This comprehensive review provides a framework of cut-point election for biomarkers in diagnostic medicine. Methods Several methods were proposed for the selection of optional cut-points. The validity and precision of the proposed methods were discussed and the clinical application of the methods was illustrated with a practical example of clinical diagnostic data of C-reactive protein (CRP), erythrocyte sedimentation rate (ESR) and malondialdehyde (MDA) for prediction of inflammatory bowel disease (IBD) patients using the NCSS software. Results Our results in the clinical data suggested that for CRP and MDA, the calculated cut-points of the Youden index, Euclidean index, Product and Union index methods were consistent in predicting IBD patients, while for ESR, only the Euclidean and Product methods yielded similar estimates. However, the diagnostic odds ratio (DOR) method provided more extreme values for the optimal cut-point for all biomarkers analyzed. Conclusion Overall, the four methods including the Youden index, Euclidean index, Product, and IU can produce quite similar optimal cut-points for binormal pairs with the same variance. The cut-point determined with the Youden index may not agree with the other three methods in the case of skewed distributions while DOR does not produce valid informative cut-points. Therefore, more extensive Monte Carlo simulation studies are needed to investigate the conditions of test result distributions that may lead to inconsistent findings in clinical diagnostics.","<method>Youden index</method>, <method>Euclidean index</method>, <method>Product</method>, <method>Union index (IU)</method>, <method>Diagnostic odds ratio (DOR)</method>",No methods remaining
2024,https://openalex.org/W4391376295,Medicine,"Detection of a facemask in real-time using deep learning methods:
  Prevention of Covid 19","A health crisis is raging all over the world with the rapid transmission of the novel-coronavirus disease (Covid-19). Out of the guidelines issued by the World Health Organisation (WHO) to protect us against Covid-19, wearing a facemask is the most effective. Many countries have necessitated the wearing of face masks, but monitoring a large number of people to ensure that they are wearing masks in a crowded place is a challenging task in itself. The novel-coronavirus disease (Covid-19) has already affected our day-to-day life as well as world trade movements. By the end of April 2021, the world has recorded 144,358,956 confirmed cases of novel-coronavirus disease (Covid-19) including 3,066,113 deaths according to the world health organization (WHO). These increasing numbers motivate automated techniques for the detection of a facemask in real-time scenarios for the prevention of Covid-19. We propose a technique using deep learning that works for single and multiple people in a frame recorded via webcam in still or in motion. We have also experimented with our approach in night light. The accuracy of our model is good compared to the other approaches in the literature; ranging from 74% for multiple people in a nightlight to 99% for a single person in daylight.",<method>deep learning</method>,<method>deep learning</method>
2024,https://openalex.org/W4393119757,Medicine,Unmasking bias in artificial intelligence: a systematic review of bias detection and mitigation strategies in electronic health record-based models,"Abstract Objectives Leveraging artificial intelligence (AI) in conjunction with electronic health records (EHRs) holds transformative potential to improve healthcare. However, addressing bias in AI, which risks worsening healthcare disparities, cannot be overlooked. This study reviews methods to handle various biases in AI models developed using EHR data. Materials and Methods We conducted a systematic review following the Preferred Reporting Items for Systematic Reviews and Meta-analyses guidelines, analyzing articles from PubMed, Web of Science, and IEEE published between January 01, 2010 and December 17, 2023. The review identified key biases, outlined strategies for detecting and mitigating bias throughout the AI model development, and analyzed metrics for bias assessment. Results Of the 450 articles retrieved, 20 met our criteria, revealing 6 major bias types: algorithmic, confounding, implicit, measurement, selection, and temporal. The AI models were primarily developed for predictive tasks, yet none have been deployed in real-world healthcare settings. Five studies concentrated on the detection of implicit and algorithmic biases employing fairness metrics like statistical parity, equal opportunity, and predictive equity. Fifteen studies proposed strategies for mitigating biases, especially targeting implicit and selection biases. These strategies, evaluated through both performance and fairness metrics, predominantly involved data collection and preprocessing techniques like resampling and reweighting. Discussion This review highlights evolving strategies to mitigate bias in EHR-based AI models, emphasizing the urgent need for both standardized and detailed reporting of the methodologies and systematic real-world testing and evaluation. Such measures are essential for gauging models’ practical impact and fostering ethical AI that ensures fairness and equity in healthcare.","<method>resampling</method>, <method>reweighting</method>",<method>resampling</method><method>reweighting</method>
2024,https://openalex.org/W4393941607,Medicine,Large language models as assistance for glaucoma surgical cases: a ChatGPT vs. Google Gemini comparison,"Abstract Purpose The aim of this study was to define the capability of ChatGPT-4 and Google Gemini in analyzing detailed glaucoma case descriptions and suggesting an accurate surgical plan. Methods Retrospective analysis of 60 medical records of surgical glaucoma was divided into “ordinary” ( n = 40) and “challenging” ( n = 20) scenarios. Case descriptions were entered into ChatGPT and Bard’s interfaces with the question “What kind of surgery would you perform?” and repeated three times to analyze the answers’ consistency. After collecting the answers, we assessed the level of agreement with the unified opinion of three glaucoma surgeons. Moreover, we graded the quality of the responses with scores from 1 (poor quality) to 5 (excellent quality), according to the Global Quality Score (GQS) and compared the results. Results ChatGPT surgical choice was consistent with those of glaucoma specialists in 35/60 cases (58%), compared to 19/60 (32%) of Gemini ( p = 0.0001). Gemini was not able to complete the task in 16 cases (27%). Trabeculectomy was the most frequent choice for both chatbots (53% and 50% for ChatGPT and Gemini, respectively). In “challenging” cases, ChatGPT agreed with specialists in 9/20 choices (45%), outperforming Google Gemini performances (4/20, 20%). Overall, GQS scores were 3.5 ± 1.2 and 2.1 ± 1.5 for ChatGPT and Gemini ( p = 0.002). This difference was even more marked if focusing only on “challenging” cases (1.5 ± 1.4 vs. 3.0 ± 1.5, p = 0.001). Conclusion ChatGPT-4 showed a good analysis performance for glaucoma surgical cases, either ordinary or challenging. On the other side, Google Gemini showed strong limitations in this setting, presenting high rates of unprecise or missed answers.","<method>ChatGPT-4</method>, <method>Google Gemini</method>",<method>Google Gemini</method>
2024,https://openalex.org/W4391235397,Medicine,Real-Time Plant Disease Dataset Development and Detection of Plant Disease Using Deep Learning,"Agriculture plays a significant role in meeting food needs and providing food security for the increasingly growing global population, which has increased by 0.88% since 2022. Plant diseases can reduce food production and affect food security. Worldwide crop loss due to plant disease is estimated to be around 14.1%. The lack of proper identification of plant disease at the early stages of infection can result in inappropriate disease control measures. Therefore, the automatic identification and diagnosis of plant diseases are highly recommended. Lack of availability of large amounts of data that are not processed to a large extent is one of the main challenges in plant disease diagnosis. In the current manuscript, we developed datasets for food grains specifically for rice, wheat, and maize to address the identified challenges. The developed datasets consider the common diseases (two bacterial diseases and two fungal diseases of rice, four fungal diseases of maize, and four fungal diseases of wheat) that affect crop yields and cause damage to the whole plant. The datasets developed were applied to eight fine-tuned deep learning models with the same training hyperparameters. The experimental results based on eight fine-tuned deep learning models show that, while recognizing maize leaf diseases, the models Xception and MobileNet performed best with a testing accuracy of 0.9580 and 0.9464 respectively. Similarly, while recognizing the wheat leaf diseases, the models MobileNetV2 and MobileNet performed best with a testing accuracy of 0.9632 and 0.9628 respectively. The Xception and Inception V3 models performed best, with a testing accuracy of 0.9728 and 0.9620, respectively, for recognizing rice leaf diseases. The research also proposes a new convolutional neural network (CNN) model trained from scratch on all three food grain datasets developed. The proposed model performs well and shows a testing accuracy of 0.9704, 0.9706, and 0.9808 respectively on the maize, rice, and wheat datasets.","<method>fine-tuned deep learning models</method>, <method>Xception</method>, <method>MobileNet</method>, <method>MobileNetV2</method>, <method>Inception V3</method>, <method>convolutional neural network (CNN) model trained from scratch</method>",<method>fine-tuned deep learning models</method><method>Xception</method><method>MobileNet</method><method>MobileNetV2</method><method>Inception V3</method><method>convolutional neural network (CNN) model trained from scratch</method>
2024,https://openalex.org/W4396494945,Medicine,Vision–language foundation model for echocardiogram interpretation,"Abstract The development of robust artificial intelligence models for echocardiography has been limited by the availability of annotated clinical data. Here, to address this challenge and improve the performance of cardiac imaging models, we developed EchoCLIP, a vision–language foundation model for echocardiography, that learns the relationship between cardiac ultrasound images and the interpretations of expert cardiologists across a wide range of patients and indications for imaging. After training on 1,032,975 cardiac ultrasound videos and corresponding expert text, EchoCLIP performs well on a diverse range of benchmarks for cardiac image interpretation, despite not having been explicitly trained for individual interpretation tasks. EchoCLIP can assess cardiac function (mean absolute error of 7.1% when predicting left ventricular ejection fraction in an external validation dataset) and identify implanted intracardiac devices (area under the curve (AUC) of 0.84, 0.92 and 0.97 for pacemakers, percutaneous mitral valve repair and artificial aortic valves, respectively). We also developed a long-context variant (EchoCLIP-R) using a custom tokenizer based on common echocardiography concepts. EchoCLIP-R accurately identified unique patients across multiple videos (AUC of 0.86), identified clinical transitions such as heart transplants (AUC of 0.79) and cardiac surgery (AUC 0.77) and enabled robust image-to-text search (mean cross-modal retrieval rank in the top 1% of candidate text reports). These capabilities represent a substantial step toward understanding and applying foundation models in cardiovascular imaging for preliminary interpretation of echocardiographic findings.","<method>vision–language foundation model</method>, <method>EchoCLIP</method>, <method>long-context variant (EchoCLIP-R)</method>, <method>custom tokenizer</method>",<method>vision–language foundation model</method>
2024,https://openalex.org/W4391320803,Medicine,Oral squamous cell carcinoma detection using EfficientNet on histopathological images,"Introduction Oral Squamous Cell Carcinoma (OSCC) poses a significant challenge in oncology due to the absence of precise diagnostic tools, leading to delays in identifying the condition. Current diagnostic methods for OSCC have limitations in accuracy and efficiency, highlighting the need for more reliable approaches. This study aims to explore the discriminative potential of histopathological images of oral epithelium and OSCC. By utilizing a database containing 1224 images from 230 patients, captured at varying magnifications and publicly available, a customized deep learning model based on EfficientNetB3 was developed. The model’s objective was to differentiate between normal epithelium and OSCC tissues by employing advanced techniques such as data augmentation, regularization, and optimization. Methods The research utilized a histopathological imaging database for Oral Cancer analysis, incorporating 1224 images from 230 patients. These images, taken at various magnifications, formed the basis for training a specialized deep learning model built upon the EfficientNetB3 architecture. The model underwent training to distinguish between normal epithelium and OSCC tissues, employing sophisticated methodologies including data augmentation, regularization techniques, and optimization strategies. Results The customized deep learning model achieved significant success, showcasing a remarkable 99% accuracy when tested on the dataset. This high accuracy underscores the model’s efficacy in effectively discerning between normal epithelium and OSCC tissues. Furthermore, the model exhibited impressive precision, recall, and F1-score metrics, reinforcing its potential as a robust diagnostic tool for OSCC. Discussion This research demonstrates the promising potential of employing deep learning models to address the diagnostic challenges associated with OSCC. The model’s ability to achieve a 99% accuracy rate on the test dataset signifies a considerable leap forward in earlier and more accurate detection of OSCC. Leveraging advanced techniques in machine learning, such as data augmentation and optimization, has shown promising results in improving patient outcomes through timely and precise identification of OSCC.","<method>deep learning model based on EfficientNetB3</method>, <method>data augmentation</method>, <method>regularization</method>, <method>optimization</method>",<method>deep learning model based on EfficientNetB3</method>
2024,https://openalex.org/W4392450439,Medicine,Dr. Google to Dr. ChatGPT: assessing the content and quality of artificial intelligence-generated medical information on appendicitis,"Abstract Introduction Generative artificial intelligence (AI) chatbots have recently been posited as potential sources of online medical information for patients making medical decisions. Existing online patient-oriented medical information has repeatedly been shown to be of variable quality and difficult readability. Therefore, we sought to evaluate the content and quality of AI-generated medical information on acute appendicitis. Methods A modified DISCERN assessment tool, comprising 16 distinct criteria each scored on a 5-point Likert scale (score range 16–80), was used to assess AI-generated content. Readability was determined using the Flesch Reading Ease (FRE) and Flesch-Kincaid Grade Level (FKGL) scores. Four popular chatbots, ChatGPT-3.5 and ChatGPT-4, Bard, and Claude-2, were prompted to generate medical information about appendicitis. Three investigators independently scored the generated texts blinded to the identity of the AI platforms. Results ChatGPT-3.5, ChatGPT-4, Bard, and Claude-2 had overall mean (SD) quality scores of 60.7 (1.2), 62.0 (1.0), 62.3 (1.2), and 51.3 (2.3), respectively, on a scale of 16–80. Inter-rater reliability was 0.81, 0.75, 0.81, and 0.72, respectively, indicating substantial agreement. Claude-2 demonstrated a significantly lower mean quality score compared to ChatGPT-4 ( p = 0.001), ChatGPT-3.5 ( p = 0.005), and Bard ( p = 0.001). Bard was the only AI platform that listed verifiable sources, while Claude-2 provided fabricated sources. All chatbots except for Claude-2 advised readers to consult a physician if experiencing symptoms. Regarding readability, FKGL and FRE scores of ChatGPT-3.5, ChatGPT-4, Bard, and Claude-2 were 14.6 and 23.8, 11.9 and 33.9, 8.6 and 52.8, 11.0 and 36.6, respectively, indicating difficulty readability at a college reading skill level. Conclusion AI-generated medical information on appendicitis scored favorably upon quality assessment, but most either fabricated sources or did not provide any altogether. Additionally, overall readability far exceeded recommended levels for the public. Generative AI platforms demonstrate measured potential for patient education and engagement about appendicitis.",<method>Generative artificial intelligence (AI) chatbots</method>,No methods remaining
2024,https://openalex.org/W4400993192,Medicine,Damage identification of steel bridge based on data augmentation and adaptive optimization neural network,"With the advancement of deep learning, data-driven structural damage identification (SDI) has shown considerable development. However, collecting vibration signals related to structural damage poses certain challenges, which can undermine the accuracy of the identification results produced by data-driven SDI methods in scenarios where data is scarce. This paper introduces an innovative approach to bridge SDI in a few-shot context by integrating an adaptive simulated annealing particle swarm optimization-convolutional neural network (ASAPSO-CNN) as the foundational framework, augmented by data enhancement techniques. Firstly, three specific types of noise are introduced to augment the source signals used for training. Subsequently, the source signals and augmented signals are recombined to construct a four-dimensional matrix as the input to the CNN, while defining the damage feature vector as the output. Secondly, a CNN is constructed to establish the mapping relationship between the input and output. Then, an adaptive fitness function is proposed that simultaneously considers the accuracy of SDI, model complexity, and training efficiency. The ASAPSO is employed to adaptively optimize the hyperparameters of the CNN. The proposed method is validated on an experimental model of a three-span continuous beam. It is compared with four other data-driven methods, demonstrating good effectiveness and robustness of SDI under cases of scarce data. Finally, the effectiveness of this SDI method is validated in a real-world case of a steel truss bridge.","<method>adaptive simulated annealing particle swarm optimization-convolutional neural network (ASAPSO-CNN)</method>, <method>data enhancement techniques</method>, <method>convolutional neural network (CNN)</method>, <method>adaptive fitness function</method>, <method>adaptive simulated annealing particle swarm optimization (ASAPSO)</method>",<method>convolutional neural network (CNN)</method>
2024,https://openalex.org/W4390588437,Medicine,Enhancing heart disease prediction using a self-attention-based transformer model,"Abstract Cardiovascular diseases (CVDs) continue to be the leading cause of more than 17 million mortalities worldwide. The early detection of heart failure with high accuracy is crucial for clinical trials and therapy. Patients will be categorized into various types of heart disease based on characteristics like blood pressure, cholesterol levels, heart rate, and other characteristics. With the use of an automatic system, we can provide early diagnoses for those who are prone to heart failure by analyzing their characteristics. In this work, we deploy a novel self-attention-based transformer model, that combines self-attention mechanisms and transformer networks to predict CVD risk. The self-attention layers capture contextual information and generate representations that effectively model complex patterns in the data. Self-attention mechanisms provide interpretability by giving each component of the input sequence a certain amount of attention weight. This includes adjusting the input and output layers, incorporating more layers, and modifying the attention processes to collect relevant information. This also makes it possible for physicians to comprehend which features of the data contributed to the model's predictions. The proposed model is tested on the Cleveland dataset, a benchmark dataset of the University of California Irvine (UCI) machine learning (ML) repository. Comparing the proposed model to several baseline approaches, we achieved the highest accuracy of 96.51%. Furthermore, the outcomes of our experiments demonstrate that the prediction rate of our model is higher than that of other cutting-edge approaches used for heart disease prediction.","<method>self-attention-based transformer model</method>, <method>self-attention mechanisms</method>, <method>transformer networks</method>",<method>self-attention-based transformer model</method><method>self-attention mechanisms</method><method>transformer networks</method>
2024,https://openalex.org/W4393353042,Medicine,SNC_Net: Skin Cancer Detection by Integrating Handcrafted and Deep Learning-Based Features Using Dermoscopy Images,"The medical sciences are facing a major problem with the auto-detection of disease due to the fast growth in population density. Intelligent systems assist medical professionals in early disease detection and also help to provide consistent treatment that reduces the mortality rate. Skin cancer is considered to be the deadliest and most severe kind of cancer. Medical professionals utilize dermoscopy images to make a manual diagnosis of skin cancer. This method is labor-intensive and time-consuming and demands a considerable level of expertise. Automated detection methods are necessary for the early detection of skin cancer. The occurrence of hair and air bubbles in dermoscopic images affects the diagnosis of skin cancer. This research aims to classify eight different types of skin cancer, namely actinic keratosis (AKs), dermatofibroma (DFa), melanoma (MELa), basal cell carcinoma (BCCa), squamous cell carcinoma (SCCa), melanocytic nevus (MNi), vascular lesion (VASn), and benign keratosis (BKs). In this study, we propose SNC_Net, which integrates features derived from dermoscopic images through deep learning (DL) models and handcrafted (HC) feature extraction methods with the aim of improving the performance of the classifier. A convolutional neural network (CNN) is employed for classification. Dermoscopy images from the publicly accessible ISIC 2019 dataset for skin cancer detection is utilized to train and validate the model. The performance of the proposed model is compared with four baseline models, namely EfficientNetB0 (B1), MobileNetV2 (B2), DenseNet-121 (B3), and ResNet-101 (B4), and six state-of-the-art (SOTA) classifiers. With an accuracy of 97.81%, a precision of 98.31%, a recall of 97.89%, and an F1 score of 98.10%, the proposed model outperformed the SOTA classifiers as well as the four baseline models. Moreover, an Ablation study is also performed on the proposed method to validate its performance. The proposed method therefore assists dermatologists and other medical professionals in early skin cancer detection.","<method>deep learning (DL) models</method>, <method>handcrafted (HC) feature extraction methods</method>, <method>convolutional neural network (CNN)</method>, <method>EfficientNetB0</method>, <method>MobileNetV2</method>, <method>DenseNet-121</method>, <method>ResNet-101</method>",<method>deep learning (DL) models</method><method>convolutional neural network (CNN)</method><method>EfficientNetB0</method><method>MobileNetV2</method><method>DenseNet-121</method><method>ResNet-101</method>
2024,https://openalex.org/W4400937555,Medicine,The diagnostic and triage accuracy of the GPT-3 artificial intelligence model: an observational study,"BackgroundArtificial intelligence (AI) applications in health care have been effective in many areas of medicine, but they are often trained for a single task using labelled data, making deployment and generalisability challenging. How well a general-purpose AI language model performs diagnosis and triage relative to physicians and laypeople is not well understood.MethodsWe compared the predictive accuracy of Generative Pre-trained Transformer 3 (GPT-3)'s diagnostic and triage ability for 48 validated synthetic case vignettes (<50 words; sixth-grade reading level or below) of both common (eg, viral illness) and severe (eg, heart attack) conditions to a nationally representative sample of 5000 lay people from the USA who could use the internet to find the correct options and 21 practising physicians at Harvard Medical School. There were 12 vignettes for each of four triage categories: emergent, within one day, within 1 week, and self-care. The correct diagnosis and triage category (ie, ground truth) for each vignette was determined by two general internists at Harvard Medical School. For each vignette, human respondents and GPT-3 were prompted to list diagnoses in order of likelihood, and the vignette was marked as correct if the ground-truth diagnosis was in the top three of the listed diagnoses. For triage accuracy, we examined whether the human respondents' and GPT-3's selected triage was exactly correct according to the four triage categories, or matched a dichotomised triage variable (emergent or within 1 day vs within 1 week or self-care). We estimated GPT-3's diagnostic and triage confidence on a given vignette using a modified bootstrap resampling procedure, and examined how well calibrated GPT-3's confidence was by computing calibration curves and Brier scores. We also performed subgroup analysis by case acuity, and an error analysis for triage advice to characterise how its advice might affect patients using this tool to decide if they should seek medical care immediately.FindingsAmong all cases, GPT-3 replied with the correct diagnosis in its top three for 88% (42/48, 95% CI 75–94) of cases, compared with 54% (2700/5000, 53–55) for lay individuals (p<0.0001) and 96% (637/666, 94–97) for physicians (p=0·012). GPT-3 triaged 70% correct (34/48, 57–82) versus 74% (3706/5000, 73–75; p=0.60) for lay individuals and 91% (608/666, 89–93%; p<0.0001) for physicians. As measured by the Brier score, GPT-3 confidence in its top prediction was reasonably well calibrated for diagnosis (Brier score=0·18) and triage (Brier score=0·22). We observed an inverse relationship between case acuity and GPT-3 accuracy (p<0·0001) with a fitted trend line of –8·33% decrease in accuracy for every level of increase in case acuity. For triage error analysis, GPT-3 deprioritised truly emergent cases in seven instances.InterpretationA general-purpose AI language model without any content-specific training could perform diagnosis at levels close to, but below, physicians and better than lay individuals. We found that GPT-3's performance was inferior to physicians for triage, sometimes by a large margin, and its performance was closer to that of lay individuals. Although the diagnostic performance of GPT-3 was comparable to physicians, it was significantly better than a typical person using a search engine.FundingThe National Heart, Lung, and Blood Institute.","<method>Generative Pre-trained Transformer 3 (GPT-3)</method>, <method>modified bootstrap resampling procedure</method>",<method>Generative Pre-trained Transformer 3 (GPT-3)</method>
2024,https://openalex.org/W4392285688,Medicine,Machine Learning and Digital Biomarkers Can Detect Early Stages of Neurodegenerative Diseases,"Neurodegenerative diseases (NDs) such as Alzheimer’s Disease (AD) and Parkinson’s Disease (PD) are devastating conditions that can develop without noticeable symptoms, causing irreversible damage to neurons before any signs become clinically evident. NDs are a major cause of disability and mortality worldwide. Currently, there are no cures or treatments to halt their progression. Therefore, the development of early detection methods is urgently needed to delay neuronal loss as soon as possible. Despite advancements in Medtech, the early diagnosis of NDs remains a challenge at the intersection of medical, IT, and regulatory fields. Thus, this review explores “digital biomarkers” (tools designed for remote neurocognitive data collection and AI analysis) as a potential solution. The review summarizes that recent studies combining AI with digital biomarkers suggest the possibility of identifying pre-symptomatic indicators of NDs. For instance, research utilizing convolutional neural networks for eye tracking has achieved significant diagnostic accuracies. ROC-AUC scores reached up to 0.88, indicating high model performance in differentiating between PD patients and healthy controls. Similarly, advancements in facial expression analysis through tools have demonstrated significant potential in detecting emotional changes in ND patients, with some models reaching an accuracy of 0.89 and a precision of 0.85. This review follows a structured approach to article selection, starting with a comprehensive database search and culminating in a rigorous quality assessment and meaning for NDs of the different methods. The process is visualized in 10 tables with 54 parameters describing different approaches and their consequences for understanding various mechanisms in ND changes. However, these methods also face challenges related to data accuracy and privacy concerns. To address these issues, this review proposes strategies that emphasize the need for rigorous validation and rapid integration into clinical practice. Such integration could transform ND diagnostics, making early detection tools more cost-effective and globally accessible. In conclusion, this review underscores the urgent need to incorporate validated digital health tools into mainstream medical practice. This integration could indicate a new era in the early diagnosis of neurodegenerative diseases, potentially altering the trajectory of these conditions for millions worldwide. Thus, by highlighting specific and statistically significant findings, this review demonstrates the current progress in this field and the potential impact of these advancements on the global management of NDs.",<method>convolutional neural networks</method>,<method>convolutional neural networks</method>
2024,https://openalex.org/W4390607226,Medicine,RanMerFormer: Randomized vision transformer with token merging for brain tumor classification,"Brains are the control center of the nervous system in human bodies, and brain tumor is one of the most deadly diseases. Currently, magnetic resonance imaging (MRI) is the most effective way to brain tumors early detection in clinical diagnoses due to its superior imaging quality for soft tissues. Manual analysis of brain MRI is error-prone which depends on empirical experience and the fatigue state of the radiologists to a large extent. Computer-aided diagnosis (CAD) systems are becoming more and more impactful because they can provide accurate prediction results based on medical images with advanced techniques from computer vision. Therefore, a novel CAD method for brain tumor classification named RanMerFormer is presented in this paper. A pre-trained vision transformer is used as the backbone model. Then, a merging mechanism is proposed to remove the redundant tokens in the vision transformer, which improves computing efficiency substantially. Finally, a randomized vector functional-link serves as the head in the proposed RanMerFormer, which can be trained swiftly. All the simulation results are obtained from two public benchmark datasets, which reveal that the proposed RanMerFormer can achieve state-of-the-art performance for brain tumor classification. The trained RanMerFormer can be applied in real-world scenarios to assist in brain tumor diagnosis.","<method>pre-trained vision transformer</method>, <method>merging mechanism to remove redundant tokens in the vision transformer</method>, <method>randomized vector functional-link</method>",<method>pre-trained vision transformer</method><method>randomized vector functional-link</method>
2024,https://openalex.org/W4391023920,Medicine,A hybrid deep CNN model for brain tumor image multi-classification,"Abstract The current approach to diagnosing and classifying brain tumors relies on the histological evaluation of biopsy samples, which is invasive, time-consuming, and susceptible to manual errors. These limitations underscore the pressing need for a fully automated, deep-learning-based multi-classification system for brain malignancies. This article aims to leverage a deep convolutional neural network (CNN) to enhance early detection and presents three distinct CNN models designed for different types of classification tasks. The first CNN model achieves an impressive detection accuracy of 99.53% for brain tumors. The second CNN model, with an accuracy of 93.81%, proficiently categorizes brain tumors into five distinct types: normal, glioma, meningioma, pituitary, and metastatic. Furthermore, the third CNN model demonstrates an accuracy of 98.56% in accurately classifying brain tumors into their different grades. To ensure optimal performance, a grid search optimization approach is employed to automatically fine-tune all the relevant hyperparameters of the CNN models. The utilization of large, publicly accessible clinical datasets results in robust and reliable classification outcomes. This article conducts a comprehensive comparison of the proposed models against classical models, such as AlexNet, DenseNet121, ResNet-101, VGG-19, and GoogleNet, reaffirming the superiority of the deep CNN-based approach in advancing the field of brain tumor classification and early detection.","<method>deep convolutional neural network (CNN)</method>, <method>grid search optimization</method>, <method>AlexNet</method>, <method>DenseNet121</method>, <method>ResNet-101</method>, <method>VGG-19</method>, <method>GoogleNet</method>",<method>deep convolutional neural network (CNN)</method><method>AlexNet</method><method>DenseNet121</method><method>ResNet-101</method><method>VGG-19</method><method>GoogleNet</method>
2024,https://openalex.org/W4391341367,Medicine,Automated Tool Support for Glaucoma Identification With Explainability Using Fundus Images,"Glaucoma is a progressive eye condition that causes irreversible vision loss due to damage to the optic nerve. Recent developments in deep learning and the accessibility of computing resources have provided tool support for automated glaucoma diagnosis. Despite deep learning's advances in disease diagnosis using medical images, generic convolutional neural networks are still not widely used in medical practices due to the limited trustworthiness of these models. Although deep learning-based glaucoma classification has gained popularity in recent years, only a few of them have addressed the explainability and interpretability of the models, which increases confidence in using such applications. This study presents state-of-the-art deep learning techniques to segment and classify fundus images to predict glaucoma conditions and applies visualization techniques to explain the results to ease understandability. Our predictions are based on U-Net with attention mechanisms with ResNet50 for the segmentation process and a modified Inception V3 architecture for the classification. Attention U-Net with modified ResNet50 backbone obtained 99.58% and 98.05% accuracies for optic disc segmentation and optic cup segmentation, respectively for the RIM-ONE dataset. Additionally, we generate heatmaps that highlight the regions that impacted the glaucoma diagnosis using both Gradient-weighted Class Activation Mapping (Grad-CAM) and Grad-CAM++. Our model that classifies the segmented images achieves accuracy, sensitivity, and specificity values of 98.97%, 99.42%, and 95.59%, respectively, with the RIM-ONE dataset. This model can be used as a support tool for automated glaucoma identification using fundus images.","<method>U-Net with attention mechanisms</method>, <method>ResNet50</method>, <method>modified Inception V3 architecture</method>, <method>Attention U-Net with modified ResNet50 backbone</method>, <method>Gradient-weighted Class Activation Mapping (Grad-CAM)</method>, <method>Grad-CAM++</method>",<method>U-Net with attention mechanisms</method><method>ResNet50</method><method>modified Inception V3 architecture</method><method>Attention U-Net with modified ResNet50 backbone</method><method>Gradient-weighted Class Activation Mapping (Grad-CAM)</method><method>Grad-CAM++</method>
2024,https://openalex.org/W4391610180,Medicine,"Generative artificial intelligence in drug discovery: basic framework, recent advances, challenges, and opportunities","There are two main ways to discover or design small drug molecules. The first involves fine-tuning existing molecules or commercially successful drugs through quantitative structure-activity relationships and virtual screening. The second approach involves generating new molecules through de novo drug design or inverse quantitative structure-activity relationship. Both methods aim to get a drug molecule with the best pharmacokinetic and pharmacodynamic profiles. However, bringing a new drug to market is an expensive and time-consuming endeavor, with the average cost being estimated at around $2.5 billion. One of the biggest challenges is screening the vast number of potential drug candidates to find one that is both safe and effective. The development of artificial intelligence in recent years has been phenomenal, ushering in a revolution in many fields. The field of pharmaceutical sciences has also significantly benefited from multiple applications of artificial intelligence, especially drug discovery projects. Artificial intelligence models are finding use in molecular property prediction, molecule generation, virtual screening, synthesis planning, repurposing, among others. Lately, generative artificial intelligence has gained popularity across domains for its ability to generate entirely new data, such as images, sentences, audios, videos, novel chemical molecules, etc. Generative artificial intelligence has also delivered promising results in drug discovery and development. This review article delves into the fundamentals and framework of various generative artificial intelligence models in the context of drug discovery via de novo drug design approach. Various basic and advanced models have been discussed, along with their recent applications. The review also explores recent examples and advances in the generative artificial intelligence approach, as well as the challenges and ongoing efforts to fully harness the potential of generative artificial intelligence in generating novel drug molecules in a faster and more affordable manner. Some clinical-level assets generated form generative artificial intelligence have also been discussed in this review to show the ever-increasing application of artificial intelligence in drug discovery through commercial partnerships.","<method>quantitative structure-activity relationships</method>, <method>virtual screening</method>, <method>de novo drug design</method>, <method>inverse quantitative structure-activity relationship</method>, <method>artificial intelligence models</method>, <method>molecular property prediction</method>, <method>molecule generation</method>, <method>virtual screening</method>, <method>synthesis planning</method>, <method>repurposing</method>, <method>generative artificial intelligence</method>, <method>generative artificial intelligence models</method>",<method>inverse quantitative structure-activity relationship</method><method>generative artificial intelligence models</method>
2024,https://openalex.org/W4392703844,Medicine,Collaborative Enhancement of Consistency and Accuracy in US Diagnosis of Thyroid Nodules Using Large Language Models,"Background Large language models (LLMs) hold substantial promise for medical imaging interpretation. However, there is a lack of studies on their feasibility in handling reasoning questions associated with medical diagnosis. Purpose To investigate the viability of leveraging three publicly available LLMs to enhance consistency and diagnostic accuracy in medical imaging based on standardized reporting, with pathology as the reference standard. Materials and Methods US images of thyroid nodules with pathologic results were retrospectively collected from a tertiary referral hospital between July 2022 and December 2022 and used to evaluate malignancy diagnoses generated by three LLMs-OpenAI's ChatGPT 3.5, ChatGPT 4.0, and Google's Bard. Inter- and intra-LLM agreement of diagnosis were evaluated. Then, diagnostic performance, including accuracy, sensitivity, specificity, and area under the receiver operating characteristic curve (AUC), was evaluated and compared for the LLMs and three interactive approaches: human reader combined with LLMs, image-to-text model combined with LLMs, and an end-to-end convolutional neural network model. Results A total of 1161 US images of thyroid nodules (498 benign, 663 malignant) from 725 patients (mean age, 42.2 years ± 14.1 [SD]; 516 women) were evaluated. ChatGPT 4.0 and Bard displayed substantial to almost perfect intra-LLM agreement (κ range, 0.65-0.86 [95% CI: 0.64, 0.86]), while ChatGPT 3.5 showed fair to substantial agreement (κ range, 0.36-0.68 [95% CI: 0.36, 0.68]). ChatGPT 4.0 had an accuracy of 78%-86% (95% CI: 76%, 88%) and sensitivity of 86%-95% (95% CI: 83%, 96%), compared with 74%-86% (95% CI: 71%, 88%) and 74%-91% (95% CI: 71%, 93%), respectively, for Bard. Moreover, with ChatGPT 4.0, the image-to-text-LLM strategy exhibited an AUC (0.83 [95% CI: 0.80, 0.85]) and accuracy (84% [95% CI: 82%, 86%]) comparable to those of the human-LLM interaction strategy with two senior readers and one junior reader and exceeding those of the human-LLM interaction strategy with one junior reader. Conclusion LLMs, particularly integrated with image-to-text approaches, show potential in enhancing diagnostic medical imaging. ChatGPT 4.0 was optimal for consistency and diagnostic accuracy when compared with Bard and ChatGPT 3.5. © RSNA, 2024","<method>OpenAI's ChatGPT 3.5</method>, <method>ChatGPT 4.0</method>, <method>Google's Bard</method>, <method>image-to-text model combined with LLMs</method>, <method>end-to-end convolutional neural network model</method>",<method>image-to-text model combined with LLMs</method><method>end-to-end convolutional neural network model</method>
2024,https://openalex.org/W4393021028,Medicine,Foresight—a generative pretrained transformer for modelling of patient timelines using electronic health records: a retrospective modelling study,"BackgroundAn electronic health record (EHR) holds detailed longitudinal information about a patient's health status and general clinical history, a large portion of which is stored as unstructured, free text. Existing approaches to model a patient's trajectory focus mostly on structured data and a subset of single-domain outcomes. This study aims to evaluate the effectiveness of Foresight, a generative transformer in temporal modelling of patient data, integrating both free text and structured formats, to predict a diverse array of future medical outcomes, such as disorders, substances (eg, to do with medicines, allergies, or poisonings), procedures, and findings (eg, relating to observations, judgements, or assessments).MethodsForesight is a novel transformer-based pipeline that uses named entity recognition and linking tools to convert EHR document text into structured, coded concepts, followed by providing probabilistic forecasts for future medical events, such as disorders, substances, procedures, and findings. The Foresight pipeline has four main components: (1) CogStack (data retrieval and preprocessing); (2) the Medical Concept Annotation Toolkit (structuring of the free-text information from EHRs); (3) Foresight Core (deep-learning model for biomedical concept modelling); and (4) the Foresight web application. We processed the entire free-text portion from three different hospital datasets (King's College Hospital [KCH], South London and Maudsley [SLaM], and the US Medical Information Mart for Intensive Care III [MIMIC-III]), resulting in information from 811 336 patients and covering both physical and mental health institutions. We measured the performance of models using custom metrics derived from precision and recall.FindingsForesight achieved a precision@10 (ie, of 10 forecasted candidates, at least one is correct) of 0·68 (SD 0·0027) for the KCH dataset, 0·76 (0·0032) for the SLaM dataset, and 0·88 (0·0018) for the MIMIC-III dataset, for forecasting the next new disorder in a patient timeline. Foresight also achieved a precision@10 value of 0·80 (0·0013) for the KCH dataset, 0·81 (0·0026) for the SLaM dataset, and 0·91 (0·0011) for the MIMIC-III dataset, for forecasting the next new biomedical concept. In addition, Foresight was validated on 34 synthetic patient timelines by five clinicians and achieved a relevancy of 33 (97% [95% CI 91–100]) of 34 for the top forecasted candidate disorder. As a generative model, Foresight can forecast follow-on biomedical concepts for as many steps as required.InterpretationForesight is a general-purpose model for biomedical concept modelling that can be used for real-world risk forecasting, virtual trials, and clinical research to study the progression of disorders, to simulate interventions and counterfactuals, and for educational purposes.FundingNational Health Service Artificial Intelligence Laboratory, National Institute for Health and Care Research Biomedical Research Centre, and Health Data Research UK.","<method>generative transformer</method>, <method>transformer-based pipeline</method>, <method>named entity recognition</method>, <method>deep-learning model</method>",<method>generative transformer</method><method>named entity recognition</method>
2024,https://openalex.org/W4398183427,Medicine,Evaluating the accuracy of a state-of-the-art large language model for prediction of admissions from the emergency room,"Abstract Background Artificial intelligence (AI) and large language models (LLMs) can play a critical role in emergency room operations by augmenting decision-making about patient admission. However, there are no studies for LLMs using real-world data and scenarios, in comparison to and being informed by traditional supervised machine learning (ML) models. We evaluated the performance of GPT-4 for predicting patient admissions from emergency department (ED) visits. We compared performance to traditional ML models both naively and when informed by few-shot examples and/or numerical probabilities. Methods We conducted a retrospective study using electronic health records across 7 NYC hospitals. We trained Bio-Clinical-BERT and XGBoost (XGB) models on unstructured and structured data, respectively, and created an ensemble model reflecting ML performance. We then assessed GPT-4 capabilities in many scenarios: through Zero-shot, Few-shot with and without retrieval-augmented generation (RAG), and with and without ML numerical probabilities. Results The Ensemble ML model achieved an area under the receiver operating characteristic curve (AUC) of 0.88, an area under the precision-recall curve (AUPRC) of 0.72 and an accuracy of 82.9%. The naïve GPT-4's performance (0.79 AUC, 0.48 AUPRC, and 77.5% accuracy) showed substantial improvement when given limited, relevant data to learn from (ie, RAG) and underlying ML probabilities (0.87 AUC, 0.71 AUPRC, and 83.1% accuracy). Interestingly, RAG alone boosted performance to near peak levels (0.82 AUC, 0.56 AUPRC, and 81.3% accuracy). Conclusions The naïve LLM had limited performance but showed significant improvement in predicting ED admissions when supplemented with real-world examples to learn from, particularly through RAG, and/or numerical probabilities from traditional ML models. Its peak performance, although slightly lower than the pure ML model, is noteworthy given its potential for providing reasoning behind predictions. Further refinement of LLMs with real-world data is necessary for successful integration as decision-support tools in care settings.","<method>GPT-4</method>, <method>Bio-Clinical-BERT</method>, <method>XGBoost (XGB)</method>, <method>Ensemble model</method>, <method>Zero-shot</method>, <method>Few-shot</method>, <method>Retrieval-augmented generation (RAG)</method>",<method>GPT-4</method><method>XGBoost (XGB)</method><method>Ensemble model</method><method>Zero-shot</method><method>Few-shot</method><method>Retrieval-augmented generation (RAG)</method>
2024,https://openalex.org/W4390706643,Medicine,Present and Future Innovations in AI and Cardiac MRI,"Cardiac MRI is used to diagnose and treat patients with a multitude of cardiovascular diseases. Despite the growth of clinical cardiac MRI, complicated image prescriptions and long acquisition protocols limit the specialty and restrain its impact on the practice of medicine. Artificial intelligence (AI)-the ability to mimic human intelligence in learning and performing tasks-will impact nearly all aspects of MRI. Deep learning (DL) primarily uses an artificial neural network to learn a specific task from example data sets. Self-driving scanners are increasingly available, where AI automatically controls cardiac image prescriptions. These scanners offer faster image collection with higher spatial and temporal resolution, eliminating the need for cardiac triggering or breath holding. In the future, fully automated inline image analysis will most likely provide all contour drawings and initial measurements to the reader. Advanced analysis using radiomic or DL features may provide new insights and information not typically extracted in the current analysis workflow. AI may further help integrate these features with clinical, genetic, wearable-device, and ""omics"" data to improve patient outcomes. This article presents an overview of AI and its application in cardiac MRI, including in image acquisition, reconstruction, and processing, and opportunities for more personalized cardiovascular care through extraction of novel imaging markers.","<method>Artificial intelligence (AI)</method>, <method>Deep learning (DL)</method>, <method>artificial neural network</method>, <method>radiomic features</method>, <method>DL features</method>",<method>Deep learning (DL)</method><method>artificial neural network</method>
2024,https://openalex.org/W4391317367,Medicine,Automated localization of mandibular landmarks in the construction of mandibular median sagittal plane,"Abstract Objective To use deep learning to segment the mandible and identify three-dimensional (3D) anatomical landmarks from cone-beam computed tomography (CBCT) images, the planes constructed from the mandibular midline landmarks were compared and analyzed to find the best mandibular midsagittal plane (MMSP). Methods A total of 400 participants were randomly divided into a training group ( n = 360) and a validation group ( n = 40). Normal individuals were used as the test group ( n = 50). The PointRend deep learning mechanism segmented the mandible from CBCT images and accurately identified 27 anatomic landmarks via PoseNet. 3D coordinates of 5 central landmarks and 2 pairs of side landmarks were obtained for the test group. Every 35 combinations of 3 midline landmarks were screened using the template mapping technique. The asymmetry index (AI) was calculated for each of the 35 mirror planes. The template mapping technique plane was used as the reference plane; the top four planes with the smallest AIs were compared through distance, volume difference, and similarity index to find the plane with the fewest errors. Results The mandible was segmented automatically in 10 ± 1.5 s with a 0.98 Dice similarity coefficient. The mean landmark localization error for the 27 landmarks was 1.04 ± 0.28 mm. MMSP should use the plane made by B (supramentale), Gn (gnathion), and F (mandibular foramen). The average AI grade was 1.6 (min–max: 0.59–3.61). There was no significant difference in distance or volume ( P &gt; 0.05); however, the similarity index was significantly different ( P &lt; 0.01). Conclusion Deep learning can automatically segment the mandible, identify anatomic landmarks, and address medicinal demands in people without mandibular deformities. The most accurate MMSP was the B-Gn-F plane.","<method>PointRend deep learning mechanism</method>, <method>PoseNet</method>",<method>PointRend deep learning mechanism</method><method>PoseNet</method>
2024,https://openalex.org/W4391508432,Medicine,Artificial intelligence-driven virtual rehabilitation for people living in the community: A scoping review,"Abstract Virtual Rehabilitation (VRehab) is a promising approach to improving the physical and mental functioning of patients living in the community. The use of VRehab technology results in the generation of multi-modal datasets collected through various devices. This presents opportunities for the development of Artificial Intelligence (AI) techniques in VRehab, namely the measurement, detection, and prediction of various patients’ health outcomes. The objective of this scoping review was to explore the applications and effectiveness of incorporating AI into home-based VRehab programs. PubMed/MEDLINE, Embase, IEEE Xplore, Web of Science databases, and Google Scholar were searched from inception until June 2023 for studies that applied AI for the delivery of VRehab programs to the homes of adult patients. After screening 2172 unique titles and abstracts and 51 full-text studies, 13 studies were included in the review. A variety of AI algorithms were applied to analyze data collected from various sensors and make inferences about patients’ health outcomes, most involving evaluating patients’ exercise quality and providing feedback to patients. The AI algorithms used in the studies were mostly fuzzy rule-based methods, template matching, and deep neural networks. Despite the growing body of literature on the use of AI in VRehab, very few studies have examined its use in patients’ homes. Current research suggests that integrating AI with home-based VRehab can lead to improved rehabilitation outcomes for patients. However, further research is required to fully assess the effectiveness of various forms of AI-driven home-based VRehab, taking into account its unique challenges and using standardized metrics.","<method>fuzzy rule-based methods</method>, <method>template matching</method>, <method>deep neural networks</method>",<method>fuzzy rule-based methods</method><method>deep neural networks</method>
2024,https://openalex.org/W4392215277,Medicine,Automated forest inventory: Analysis of high-density airborne LiDAR point clouds with 3D deep learning,"Detailed forest inventories are critical for sustainable and flexible management of forest resources, to conserve various ecosystem services. Modern airborne laser scanners deliver high-density point clouds with great potential for fine-scale forest inventory and analysis, but automatically partitioning those point clouds into meaningful entities like individual trees or tree components remains a challenge. The present study aims to fill this gap and introduces a deep learning framework, termed ForAINet, that is able to perform such a segmentation across diverse forest types and geographic regions. From the segmented data, we then derive relevant biophysical parameters of individual trees as well as stands. The system has been tested on FOR-Instance, a dataset of point clouds that have been acquired in five different countries using surveying drones. The segmentation back-end achieves over 85% F-score for individual trees, respectively over 73% mean IoU across five semantic categories: ground, low vegetation, stems, live branches and dead branches. Building on the segmentation results our pipeline then densely calculates biophysical features of each individual tree (height, crown diameter, crown volume, DBH, and location) and properties per stand (digital terrain model and stand density). Especially crown-related features are in most cases retrieved with high accuracy, whereas the estimates for DBH and location are less reliable, due to the airborne scanning setup.",<method>deep learning framework</method>,No methods remaining
2024,https://openalex.org/W4392406184,Medicine,A Lesion-Based Diabetic Retinopathy Detection Through Hybrid Deep Learning Model,"Diabetic retinopathy (DR) can be defined as visual impairment caused by prolonged diabetes affecting the blood vessels in the retina. Globally, it stands as the primary contributor to blindness, impacting approximately 191 million individuals. While prior research has addressed DR classification using retinal fundus images, existing methods often focus on isolated lesion detection, lacking a comprehensive framework for the simultaneous identification of all lesions. Previous studies concentrated on early-stage features like exudates, aneurysms, hemorrhages, and blood vessels, sidelining severe-stage lesions such as cotton wool spots, venous beading, very severe intraretinal microvascular abnormalities (IRMA), diffuse intraretinal hemorrhages, capillary degeneration, highly activated microglia, and retinal pigment epithelium (RPE) damage. In this study, a deep learning approach is proposed to classify DR fundus images by severity levels, utilizing GoogleNet and ResNet models based on adaptive particle swarm optimizer (APSO), for enhanced feature extraction. The extracted features from the hybrid model are further used with different machine learning models like random forest, support vector machine, decision tree, and linear regression models. Experimental results showcased the proposed hybrid framework outperforming advanced approaches with a remarkable 94% accuracy on the benchmark dataset. This method demonstrates potential enhancements in precision, recall, accuracy, and F1 score for different DR severity levels.","<method>deep learning</method>, <method>GoogleNet</method>, <method>ResNet</method>, <method>adaptive particle swarm optimizer (APSO)</method>, <method>random forest</method>, <method>support vector machine</method>, <method>decision tree</method>, <method>linear regression</method>",<method>deep learning</method><method>GoogleNet</method><method>ResNet</method><method>adaptive particle swarm optimizer (APSO)</method><method>random forest</method><method>support vector machine</method><method>decision tree</method><method>linear regression</method>
2024,https://openalex.org/W4393905353,Medicine,Theranostics and artificial intelligence: new frontiers in personalized medicine,"The field of theranostics is rapidly advancing, driven by the goals of enhancing patient care. Recent breakthroughs in artificial intelligence (AI) and its innovative theranostic applications have marked a critical step forward in nuclear medicine, leading to a significant paradigm shift in precision oncology. For instance, AI-assisted tumor characterization, including automated image interpretation, tumor segmentation, feature identification, and prediction of high-risk lesions, improves diagnostic processes, offering a precise and detailed evaluation. With a comprehensive assessment tailored to an individual's unique clinical profile, AI algorithms promise to enhance patient risk classification, thereby benefiting the alignment of patient needs with the most appropriate treatment plans. By uncovering potential factors unseeable to the human eye, such as intrinsic variations in tumor radiosensitivity or molecular profile, AI software has the potential to revolutionize the prediction of response heterogeneity. For accurate and efficient dosimetry calculations, AI technology offers significant advantages by providing customized phantoms and streamlining complex mathematical algorithms, making personalized dosimetry feasible and accessible in busy clinical settings. AI tools have the potential to be leveraged to predict and mitigate treatment-related adverse events, allowing early interventions. Additionally, generative AI can be utilized to find new targets for developing novel radiopharmaceuticals and facilitate drug discovery. However, while there is immense potential and notable interest in the role of AI in theranostics, these technologies do not lack limitations and challenges. There remains still much to be explored and understood. In this study, we investigate the current applications of AI in theranostics and seek to broaden the horizons for future research and innovation.","<method>AI-assisted tumor characterization</method>, <method>automated image interpretation</method>, <method>tumor segmentation</method>, <method>feature identification</method>, <method>prediction of high-risk lesions</method>, <method>AI algorithms for patient risk classification</method>, <method>AI software for prediction of response heterogeneity</method>, <method>AI technology for dosimetry calculations with customized phantoms</method>, <method>AI tools to predict and mitigate treatment-related adverse events</method>, <method>generative AI for finding new targets and drug discovery</method>",No methods remaining
2024,https://openalex.org/W4395037579,Medicine,Assessing ChatGPT 4.0’s test performance and clinical diagnostic accuracy on USMLE STEP 2 CK and clinical case reports,"Abstract While there is data assessing the test performance of artificial intelligence (AI) chatbots, including the Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0), there is scarce data on its diagnostic accuracy of clinical cases. We assessed the large language model (LLM), ChatGPT 4.0, on its ability to answer questions from the United States Medical Licensing Exam (USMLE) Step 2, as well as its ability to generate a differential diagnosis based on corresponding clinical vignettes from published case reports. A total of 109 Step 2 Clinical Knowledge (CK) practice questions were inputted into both ChatGPT 3.5 and ChatGPT 4.0, asking ChatGPT to pick the correct answer. Compared to its previous version, ChatGPT 3.5, we found improved accuracy of ChatGPT 4.0 when answering these questions, from 47.7 to 87.2% ( p = 0.035) respectively. Utilizing the topics tested on Step 2 CK questions, we additionally found 63 corresponding published case report vignettes and asked ChatGPT 4.0 to come up with its top three differential diagnosis. ChatGPT 4.0 accurately created a shortlist of differential diagnoses in 74.6% of the 63 case reports (74.6%). We analyzed ChatGPT 4.0’s confidence in its diagnosis by asking it to rank its top three differentials from most to least likely. Out of the 47 correct diagnoses, 33 were the first (70.2%) on the differential diagnosis list, 11 were second (23.4%), and three were third (6.4%). Our study shows the continued iterative improvement in ChatGPT’s ability to answer standardized USMLE questions accurately and provides insights into ChatGPT’s clinical diagnostic accuracy.","<method>Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0)</method>, <method>ChatGPT 3.5</method>, <method>large language model (LLM)</method>",<method>Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0)</method><method>large language model (LLM)</method>
2024,https://openalex.org/W4402521185,Medicine,Advanced Ensemble Machine Learning Techniques for Optimizing Diabetes Mellitus Prognostication: A Detailed Examination of Hospital Data,"Diabetes is a chronic disease that affects millions of people worldwide. Early diagnosis and effective management are crucial for reducing its complications. Diabetes is the fourth-highest cause of mortality due to its association with various comorbidities, including heart disease, nerve damage, blood vessel damage, and blindness. The potential of machine learning algorithms in predicting Diabetes and related conditions is significant, and mining diabetes data is an efficient method for extracting new insights.The primary objective of this study is to develop an enhanced ensemble model to predict Diabetes with improved accuracy by leveraging various machine learning algorithms.This study tested several popular machine learning algorithms commonly used in diabetes prediction, including Naive Bayes (NB), Generalized Linear Model (GLM), Logistic Regression (LR), Fast Large Margin (FLM), Deep Learning (DL), Decision Tree (DT), Random Forest (RF), Gradient Boosted Trees (GBT), and Support Vector Machine (SVM). The performance of these algorithms was compared, and two different ensemble techniques—stacking and voting—were used to build a more accurate predictive model.The top three algorithms based on accuracy were Deep Learning, Naive Bayes, and Gradient Boosted Trees. The machine learning algorithms revealed that individuals with Diabetes are significantly affected by the number of chronic conditions they have, as well as their gender and age. The ensemble models, particularly the stacking method, provided higher accuracy than individual algorithms. The stacking ensemble model achieved a slightly better accuracy of 99.94% compared to 99.34% for the voting method.Building an ensemble model significantly increased the accuracy of predicting Diabetes and related conditions. The stacking ensemble model, in particular, demonstrated superior performance, highlighting the importance of combining multiple machine learning approaches to enhance predictive accuracy","<method>Naive Bayes (NB)</method>, <method>Generalized Linear Model (GLM)</method>, <method>Logistic Regression (LR)</method>, <method>Fast Large Margin (FLM)</method>, <method>Deep Learning (DL)</method>, <method>Decision Tree (DT)</method>, <method>Random Forest (RF)</method>, <method>Gradient Boosted Trees (GBT)</method>, <method>Support Vector Machine (SVM)</method>, <method>stacking ensemble</method>, <method>voting ensemble</method>",<method>Naive Bayes (NB)</method><method>Logistic Regression (LR)</method><method>Deep Learning (DL)</method><method>Decision Tree (DT)</method><method>Random Forest (RF)</method><method>Gradient Boosted Trees (GBT)</method><method>Support Vector Machine (SVM)</method><method>stacking ensemble</method><method>voting ensemble</method>
2024,https://openalex.org/W4404134492,Medicine,Bias in medical AI: Implications for clinical decision-making,"Biases in medical artificial intelligence (AI) arise and compound throughout the AI lifecycle. These biases can have significant clinical consequences, especially in applications that involve clinical decision-making. Left unaddressed, biased medical AI can lead to substandard clinical decisions and the perpetuation and exacerbation of longstanding healthcare disparities. We discuss potential biases that can arise at different stages in the AI development pipeline and how they can affect AI algorithms and clinical decision-making. Bias can occur in data features and labels, model development and evaluation, deployment, and publication. Insufficient sample sizes for certain patient groups can result in suboptimal performance, algorithm underestimation, and clinically unmeaningful predictions. Missing patient findings can also produce biased model behavior, including capturable but nonrandomly missing data, such as diagnosis codes, and data that is not usually or not easily captured, such as social determinants of health. Expertly annotated labels used to train supervised learning models may reflect implicit cognitive biases or substandard care practices. Overreliance on performance metrics during model development may obscure bias and diminish a model's clinical utility. When applied to data outside the training cohort, model performance can deteriorate from previous validation and can do so differentially across subgroups. How end users interact with deployed solutions can introduce bias. Finally, where models are developed and published, and by whom, impacts the trajectories and priorities of future medical AI development. Solutions to mitigate bias must be implemented with care, which include the collection of large and diverse data sets, statistical debiasing methods, thorough model evaluation, emphasis on model interpretability, and standardized bias reporting and transparency requirements. Prior to real-world implementation in clinical settings, rigorous validation through clinical trials is critical to demonstrate unbiased application. Addressing biases across model development stages is crucial for ensuring all patients benefit equitably from the future of medical AI.","<method>supervised learning</method>, <method>statistical debiasing methods</method>",<method>supervised learning</method><method>statistical debiasing methods</method>
2024,https://openalex.org/W4391135342,Medicine,Performance of Generative Pretrained Transformer on the National Medical Licensing Examination in Japan,"The remarkable performance of ChatGPT, launched in November 2022, has significantly impacted the field of natural language processing, inspiring the application of large language models as supportive tools in clinical practice and research worldwide. Although GPT-3.5 recently scored high on the United States Medical Licensing Examination, its performance on medical licensing examinations of other nations, especially non-English speaking nations, has not been sufficiently evaluated. This study assessed GPT’s performance on the National Medical Licensing Examination (NMLE) in Japan and compared it with the actual minimal passing rate for this exam. In particular, the performances of both the GPT-3.5 and GPT-4 models were considered for the comparative analysis. We initially used the GPT models and several prompts for 290 questions without image data from the 116 th NMLE (held in February 2022 in Japan) to maximize the performance for delivering correct answers and explanations of the questions. Thereafter, we tested the performance of the best GPT model (GPT-4) with optimized prompts on a dataset of 262 questions without images from the latest 117 th NMLE (held in February 2023). The best model with the optimized prompts scored 82.7% for the essential questions and 77.2% for the basic and clinical questions, both of which sufficed the minimum passing scoring rates of 80.0% and 74.6%, respectively. After an exploratory analysis of 56 incorrect answers from the model, we identified the three major factors contributing to the generation of the incorrect answers—insufficient medical knowledge, information on Japan-specific medical system and guidelines, and mathematical errors. In conclusion, GPT-4 with our optimized prompts achieved a minimum passing scoring rate in the latest 117 th NMLE in Japan. Beyond its original design of answering examination questions for humans, these artificial intelligence (AI) models can serve as one of the best “sidekicks” for solving problems and addressing the unmet needs in the medical and healthcare fields.","<method>GPT-3.5</method>, <method>GPT-4</method>",<method>GPT-3.5</method><method>GPT-4</method>
2024,https://openalex.org/W4391707561,Medicine,Efficient Communication in Wireless Sensor Networks Using Optimized Energy Efficient Engroove Leach Clustering Protocol,"The Wireless Sensor Network (WSN) is a network that is constructed in regions that are inaccessible to human beings. The widespread deployment of wireless micro sensors will make it possible to conduct accurate environmental monitoring for a use in both civil and military environments. They make use of these data to monitor and keep track of the physical data of the surrounding environment in order to ensure the sustainability of the area. The data have to be picked up by the sensor, and then sent to the sink node where they may be processed. The nodes of the WSNs are powered by batteries, therefore they eventually run out of power. This energy restriction has an effect on the network life span and environmental sustainability. The objective of this study is to further improve the Engroove Leach (EL) protocol's energy efficiency so that the network can operate for a very long time while consuming the least amount of energy. The lifespan of WSNs is being extended often using clustering and routing strategies. The Meta Inspired Hawks Fragment Optimization (MIHFO) system, which is based on passive clustering, is used in this study to do clustering. The cluster head is chosen based on the nodes' residual energy, distance to neighbors, distance to base station, node degree, and node centrality. Based on distance, residual energy, and node degree, an algorithm known as Heuristic Wing Antfly Optimization (HWAFO) selects the optimum path between the cluster head and Base Station (BS). They examine the number of nodes that are active, their energy consumption, and the number of data packets that the BS receives. The overall experimentation is carried out under the MATLAB environment. From the analysis, it has been discovered that the suggested approach yields noticeably superior outcomes in terms of throughput, packet delivery and drop ratio, and average energy consumption.","<method>Meta Inspired Hawks Fragment Optimization (MIHFO)</method>, <method>Heuristic Wing Antfly Optimization (HWAFO)</method>",No methods remaining
2024,https://openalex.org/W4395049366,Medicine,A novel SpaSA based hyper-parameter optimized FCEDN with adaptive CNN classification for skin cancer detection,"Abstract Skin cancer is the most prevalent kind of cancer in people. It is estimated that more than 1 million people get skin cancer every year in the world. The effectiveness of the disease’s therapy is significantly impacted by early identification of this illness. Preprocessing is the initial detecting stage in enhancing the quality of skin images by removing undesired background noise and objects. This study aims is to compile preprocessing techniques for skin cancer imaging that are currently accessible. Researchers looking into automated skin cancer diagnosis might use this article as an excellent place to start. The fully convolutional encoder–decoder network and Sparrow search algorithm (FCEDN-SpaSA) are proposed in this study for the segmentation of dermoscopic images. The individual wolf method and the ensemble ghosting technique are integrated to generate a neighbour-based search strategy in SpaSA for stressing the correct balance between navigation and exploitation. The classification procedure is accomplished by using an adaptive CNN technique to discriminate between normal skin and malignant skin lesions suggestive of disease. Our method provides classification accuracies comparable to commonly used incremental learning techniques while using less energy, storage space, memory access, and training time (only network updates with new training samples, no network sharing). In a simulation, the segmentation performance of the proposed technique on the ISBI 2017, ISIC 2018, and PH2 datasets reached accuracies of 95.28%, 95.89%, 92.70%, and 98.78%, respectively, on the same dataset and assessed the classification performance. It is accurate 91.67% of the time. The efficiency of the suggested strategy is demonstrated through comparisons with cutting-edge methodologies.","<method>fully convolutional encoder–decoder network</method>, <method>Sparrow search algorithm (SpaSA)</method>, <method>individual wolf method</method>, <method>ensemble ghosting technique</method>, <method>adaptive CNN technique</method>, <method>incremental learning techniques</method>",<method>fully convolutional encoder–decoder network</method><method>Sparrow search algorithm (SpaSA)</method><method>adaptive CNN technique</method><method>incremental learning techniques</method>
2024,https://openalex.org/W4390753190,Medicine,Investigating the impact of motion in the scanner on brain age predictions,"Abstract Brain Age Gap (BAG) is defined as the difference between the brain’s predicted age and the chronological age of an individual. Magnetic resonance imaging (MRI)-based BAG can quantify acceleration of brain aging, and is used to infer brain health as aging and disease interact. Motion in the scanner is a common occurrence that can affect the acquired MRI data and act as a major confound in the derived models. As such, age-related changes in head motion may impact the observed age-related differences. However, the relationship between head motion and BAG as estimated by structural MRI has not been systematically examined. The aim of this study is to assess the impact of motion on voxel-based morphometry (VBM) based BAG. Data were obtained from two sources: i) T1-weighted (T1w) MRIs from the Cambridge Centre for Ageing and Neuroscience (CamCAN) were used to train the brain age prediction model, and ii) T1w MRIs from the Movement-related artifacts (MR-ART) dataset were used to assess the impact of motion on BAG. MR-ART includes one motion-free and two motion-affected (one low and one high) 3D T1w MRIs. We also visually rated the motion levels of the MR-ART MRIs from 0 to 5, with 0 meaning no motion and 5 high motion levels. All images were pre-processed through a standard VBM pipeline. GM density across cortical and subcortical regions were then used to train the brain age prediction model and assess the relationship between BAG and MRI motion. Principal component analysis was used to perform dimension reduction and extract the VBM-based features. BAG was estimated by regressing out the portion of delta age explained by chronological age. Linear mixed-effects models were used to investigate the relationship between BAG and motion session as well as motion severity, including participant IDs as random effects. We repeated the same analysis using cortical thickness based on FreeSurfer 7.4.1 and to compare the results for volumetric versus surface-based measures of brain morphometry. In contrast with the session with no induced motion, predicted delta age was significantly higher for high motion sessions 2.35 years (t = 5.17, p &amp;lt; 0.0001), with marginal effect for low motion sessions 0.95 years (t = 2.11, p = 0.035) for VBM analysis as well as 3.46 years (t = 11.45, p &amp;lt; 0.0001) for high motion and 2.28 years (t = 7.54, p &amp;lt; 0.0001) for low motion based on cortical thickness. In addition, delta age was significantly associated with motion severity as evaluated by visual rating 0.45 years per rating level (t = 4.59, p &amp;lt; 0.0001) for VBM analysis and 0.83 years per motion level (t = 12.89, p &amp;lt; 0.0001) for cortical thickness analysis. Motion in the scanner can significantly impact brain age estimates, and needs to be accounted for as a confound, particularly when studying populations that are known to have higher levels of motion in the scanner. These results have significant implications for brain age studies in aging and neurodegeneration. Based on these findings, we recommend assessment and inclusion of visual motion ratings in such studies. In cases that the visual rating proves prohibitive, we recommend the inclusion of normalized Euler number from FreeSurfer as defined in the manuscript as a covariate in the models.","<method>brain age prediction model</method>, <method>principal component analysis</method>, <method>regression</method>, <method>linear mixed-effects models</method>",<method>principal component analysis</method><method>regression</method>
2024,https://openalex.org/W4390987311,Medicine,Reliability of ChatGPT for performing triage task in the emergency department using the Korean Triage and Acuity Scale,"Background Artificial intelligence (AI) technology can enable more efficient decision-making in healthcare settings. There is a growing interest in improving the speed and accuracy of AI systems in providing responses for given tasks in healthcare settings. Objective This study aimed to assess the reliability of ChatGPT in determining emergency department (ED) triage accuracy using the Korean Triage and Acuity Scale (KTAS). Methods Two hundred and two virtual patient cases were built. The gold standard triage classification for each case was established by an experienced ED physician. Three other human raters (ED paramedics) were involved and rated the virtual cases individually. The virtual cases were also rated by two different versions of the chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0). Inter-rater reliability was examined using Fleiss’ kappa and intra-class correlation coefficient (ICC). Results The kappa values for the agreement between the four human raters and ChatGPTs were .523 (version 4.0) and .320 (version 3.5). Of the five levels, the performance was poor when rating patients at levels 1 and 5, as well as case scenarios with additional text descriptions. There were differences in the accuracy of the different versions of GPTs. The ICC between version 3.5 and the gold standard was .520, and that between version 4.0 and the gold standard was .802. Conclusions A substantial level of inter-rater reliability was revealed when GPTs were used as KTAS raters. The current study showed the potential of using GPT in emergency healthcare settings. Considering the shortage of experienced manpower, this AI method may help improve triaging accuracy.","<method>chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0)</method>","<method>chat generative pre-trained transformer (ChatGPT, 3.5 and 4.0)</method>"
2024,https://openalex.org/W4391145465,Medicine,Assessing generalisability of deep learning-based polyp detection and segmentation methods through a computer vision challenge,"Abstract Polyps are well-known cancer precursors identified by colonoscopy. However, variability in their size, appearance, and location makes the detection of polyps challenging. Moreover, colonoscopy surveillance and removal of polyps are highly operator-dependent procedures and occur in a highly complex organ topology. There exists a high missed detection rate and incomplete removal of colonic polyps. To assist in clinical procedures and reduce missed rates, automated methods for detecting and segmenting polyps using machine learning have been achieved in past years. However, the major drawback in most of these methods is their ability to generalise to out-of-sample unseen datasets from different centres, populations, modalities, and acquisition systems. To test this hypothesis rigorously, we, together with expert gastroenterologists, curated a multi-centre and multi-population dataset acquired from six different colonoscopy systems and challenged the computational expert teams to develop robust automated detection and segmentation methods in a crowd-sourcing Endoscopic computer vision challenge. This work put forward rigorous generalisability tests and assesses the usability of devised deep learning methods in dynamic and actual clinical colonoscopy procedures. We analyse the results of four top performing teams for the detection task and five top performing teams for the segmentation task. Our analyses demonstrate that the top-ranking teams concentrated mainly on accuracy over the real-time performance required for clinical applicability. We further dissect the devised methods and provide an experiment-based hypothesis that reveals the need for improved generalisability to tackle diversity present in multi-centre datasets and routine clinical procedures.","<method>machine learning</method>, <method>deep learning</method>",<method>machine learning</method><method>deep learning</method>
2024,https://openalex.org/W4393201840,Medicine,"Clinical gait analysis using video-based pose estimation: Multiple perspectives, clinical populations, and measuring change","Gait dysfunction is common in many clinical populations and often has a profound and deleterious impact on independence and quality of life. Gait analysis is a foundational component of rehabilitation because it is critical to identify and understand the specific deficits that should be targeted prior to the initiation of treatment. Unfortunately, current state-of-the-art approaches to gait analysis (e.g., marker-based motion capture systems, instrumented gait mats) are largely inaccessible due to prohibitive costs of time, money, and effort required to perform the assessments. Here, we demonstrate the ability to perform quantitative gait analyses in multiple clinical populations using only simple videos recorded using low-cost devices (tablets). We report four primary advances: 1) a novel, versatile workflow that leverages an open-source human pose estimation algorithm (OpenPose) to perform gait analyses using videos recorded from multiple different perspectives (e.g., frontal, sagittal), 2) validation of this workflow in three different populations of participants (adults without gait impairment, persons post-stroke, and persons with Parkinson’s disease) via comparison to ground-truth three-dimensional motion capture, 3) demonstration of the ability to capture clinically relevant, condition-specific gait parameters, and 4) tracking of within-participant changes in gait, as is required to measure progress in rehabilitation and recovery. Importantly, our workflow has been made freely available and does not require prior gait analysis expertise. The ability to perform quantitative gait analyses in nearly any setting using only low-cost devices and computer vision offers significant potential for dramatic improvement in the accessibility of clinical gait analysis across different patient populations.",<method>human pose estimation algorithm (OpenPose)</method>,<method>human pose estimation algorithm (OpenPose)</method>
2024,https://openalex.org/W4396570916,Medicine,ELRL-MD: a deep learning approach for myocarditis diagnosis using cardiac magnetic resonance images with ensemble and reinforcement learning integration,"Abstract Objective. Myocarditis poses a significant health risk, often precipitated by viral infections like coronavirus disease, and can lead to fatal cardiac complications. As a less invasive alternative to the standard diagnostic practice of endomyocardial biopsy, which is highly invasive and thus limited to severe cases, cardiac magnetic resonance (CMR) imaging offers a promising solution for detecting myocardial abnormalities. Approach. This study introduces a deep model called ELRL-MD that combines ensemble learning and reinforcement learning (RL) for effective myocarditis diagnosis from CMR images. The model begins with pre-training via the artificial bee colony (ABC) algorithm to enhance the starting point for learning. An array of convolutional neural networks (CNNs) then works in concert to extract and integrate features from CMR images for accurate diagnosis. Leveraging the Z-Alizadeh Sani myocarditis CMR dataset, the model employs RL to navigate the dataset’s imbalance by conceptualizing diagnosis as a decision-making process. Main results. ELRL-DM demonstrates remarkable efficacy, surpassing other deep learning, conventional machine learning, and transfer learning models, achieving an F-measure of 88.2% and a geometric mean of 90.6%. Extensive experimentation helped pinpoint the optimal reward function settings and the perfect count of CNNs. Significance. The study addresses the primary technical challenge of inherent data imbalance in CMR imaging datasets and the risk of models converging on local optima due to suboptimal initial weight settings. Further analysis, leaving out ABC and RL components, confirmed their contributions to the model’s overall performance, underscoring the effectiveness of addressing these critical technical challenges.","<method>ensemble learning</method>, <method>reinforcement learning (RL)</method>, <method>artificial bee colony (ABC) algorithm</method>, <method>convolutional neural networks (CNNs)</method>, <method>deep learning</method>, <method>conventional machine learning</method>, <method>transfer learning</method>",<method>ensemble learning</method><method>reinforcement learning (RL)</method><method>artificial bee colony (ABC) algorithm</method><method>convolutional neural networks (CNNs)</method><method>deep learning</method><method>transfer learning</method>
2024,https://openalex.org/W4396831262,Medicine,GPT-4 Turbo with Vision fails to outperform text-only GPT-4 Turbo in the Japan Diagnostic Radiology Board Examination,"Abstract Purpose To assess the performance of GPT-4 Turbo with Vision (GPT-4TV), OpenAI’s latest multimodal large language model, by comparing its ability to process both text and image inputs with that of the text-only GPT-4 Turbo (GPT-4 T) in the context of the Japan Diagnostic Radiology Board Examination (JDRBE). Materials and methods The dataset comprised questions from JDRBE 2021 and 2023. A total of six board-certified diagnostic radiologists discussed the questions and provided ground-truth answers by consulting relevant literature as necessary. The following questions were excluded: those lacking associated images, those with no unanimous agreement on answers, and those including images rejected by the OpenAI application programming interface. The inputs for GPT-4TV included both text and images, whereas those for GPT-4 T were entirely text. Both models were deployed on the dataset, and their performance was compared using McNemar’s exact test. The radiological credibility of the responses was assessed by two diagnostic radiologists through the assignment of legitimacy scores on a five-point Likert scale. These scores were subsequently used to compare model performance using Wilcoxon's signed-rank test. Results The dataset comprised 139 questions. GPT-4TV correctly answered 62 questions (45%), whereas GPT-4 T correctly answered 57 questions (41%). A statistical analysis found no significant performance difference between the two models (P = 0.44). The GPT-4TV responses received significantly lower legitimacy scores from both radiologists than the GPT-4 T responses. Conclusion No significant enhancement in accuracy was observed when using GPT-4TV with image input compared with that of using text-only GPT-4 T for JDRBE questions.","<method>GPT-4 Turbo with Vision (GPT-4TV)</method>, <method>GPT-4 Turbo (GPT-4 T)</method>",<method>GPT-4 Turbo (GPT-4 T)</method>
2024,https://openalex.org/W4390531926,Medicine,The role of artificial intelligence in generating original scientific research,"Artificial intelligence (AI) is a revolutionary technology that is finding wide application across numerous sectors. Large language models (LLMs) are an emerging subset technology of AI and have been developed to communicate using human languages. At their core, LLMs are trained with vast amounts of information extracted from the internet, including text and images. Their ability to create human-like, expert text in almost any subject means they are increasingly being used as an aid to presentation, particularly in scientific writing. However, we wondered whether LLMs could go further, generating original scientific research and preparing the results for publication. We tasked GPT-4, an LLM, to write an original pharmaceutics manuscript, on a topic that is itself novel. It was able to conceive a research hypothesis, define an experimental protocol, produce photo-realistic images of printlets, generate believable analytical data from a range of instruments and write a convincing publication-ready manuscript with evidence of critical interpretation. The model achieved all this is less than 1h. Moreover, the generated data were multi-modal in nature, including thermal analyses, vibrational spectroscopy and dissolution testing, demonstrating multi-disciplinary expertise in the LLM. One area in which the model failed, however, was in referencing to the literature. Since the generated experimental results appeared believable though, we suggest that LLMs could certainly play a role in scientific research but with human input, interpretation and data validation. We discuss the potential benefits and current bottlenecks for realising this ambition here.","<method>Large language models (LLMs)</method>, <method>GPT-4</method>",<method>GPT-4</method>
2024,https://openalex.org/W4391061191,Medicine,LBO-MPAM: Ladybug Beetle Optimization-based multilayer perceptron attention module for segmenting the skin lesion and automatic localization,"In recent years, skin cancer has been the most dangerous disease noticed among people worldwide. Skin cancer should be identified earlier to reduce the rate of mortality. Employing dermoscopic images can identify and categorise skin cancer effectively. But, the visual evaluation is a complex procedure to be done in the dermoscopic image. However, Deep learning (DL) is an efficient method for skin cancer detection; however, segmenting the skin lesion and automatic localisation in an earlier stage is complicated. In this paper, a novel Ladybug Beetle Optimization-Double Attention Based Multilevel 1-D CNN (LBO-DAM 1-D CNN) technique is proposed to detect and classify skin cancer. To improve skin lesion type discriminability, the two types of attention modules are introduced. The Ultra-Lightweight Subspace Attention Module (ULSAM) is utilised for classifying the feature maps into different stages to validate the frequency from different image samples. However, the multilayer perceptron attention module (MLPAM) is determined to provide information regarding skin cancer classification and diminish the noise and unwanted data. To minimise data loss, it is then combined with hierarchical complementarity during classification. Second, a modified MLPAM is used to extract significant feature spaces for network learning, select the most important information, and reduce feature space redundancy. The Ladybug Beetle Optimization (LBO) algorithm provides the optimal classification solution by minimising the loss rate of DAM 1-D CNN architecture. The experimentation is conducted on three different datasets such as ISIC2020, HAM10000, and the melanoma detection dataset. The experimental results revealed that the proposed method is compared with different existing methods such as IMFO-KELM, Mask RCNN, M-SVM, DCNN-9, and TL-CNN with different datasets. These methods attained 94.56, 92.65, 90.56, 88.65, and 95.5 for the ISIC2020 dataset but the proposed method enhanced the classification performance by attaining 97.02. Also, the validation is based on metrics, namely, accuracy, precision, sensitivity, and F1-score of 97.03%, 97.05%, 97.58%, and 97.27% for a total of 500 epochs.","<method>Deep learning (DL)</method>, <method>Ladybug Beetle Optimization-Double Attention Based Multilevel 1-D CNN (LBO-DAM 1-D CNN)</method>, <method>Ultra-Lightweight Subspace Attention Module (ULSAM)</method>, <method>multilayer perceptron attention module (MLPAM)</method>, <method>Ladybug Beetle Optimization (LBO) algorithm</method>, <method>IMFO-KELM</method>, <method>Mask RCNN</method>, <method>M-SVM</method>, <method>DCNN-9</method>, <method>TL-CNN</method>",<method>Deep learning (DL)</method><method>Mask RCNN</method><method>M-SVM</method>
2024,https://openalex.org/W4391878291,Medicine,Effective lung nodule detection using deep CNN with dual attention mechanisms,"Abstract Novel methods are required to enhance lung cancer detection, which has overtaken other cancer-related causes of death as the major cause of cancer-related mortality. Radiologists have long-standing methods for locating lung nodules in patients with lung cancer, such as computed tomography (CT) scans. Radiologists must manually review a significant amount of CT scan pictures, which makes the process time-consuming and prone to human error. Computer-aided diagnosis (CAD) systems have been created to help radiologists with their evaluations in order to overcome these difficulties. These systems make use of cutting-edge deep learning architectures. These CAD systems are designed to improve lung nodule diagnosis efficiency and accuracy. In this study, a bespoke convolutional neural network (CNN) with a dual attention mechanism was created, which was especially crafted to concentrate on the most important elements in images of lung nodules. The CNN model extracts informative features from the images, while the attention module incorporates both channel attention and spatial attention mechanisms to selectively highlight significant features. After the attention module, global average pooling is applied to summarize the spatial information. To evaluate the performance of the proposed model, extensive experiments were conducted using benchmark dataset of lung nodules. The results of these experiments demonstrated that our model surpasses recent models and achieves state-of-the-art accuracy in lung nodule detection and classification tasks.","<method>convolutional neural network (CNN)</method>, <method>dual attention mechanism</method>, <method>channel attention</method>, <method>spatial attention</method>, <method>global average pooling</method>",<method>convolutional neural network (CNN)</method><method>dual attention mechanism</method><method>channel attention</method><method>spatial attention</method><method>global average pooling</method>
2024,https://openalex.org/W4392004069,Medicine,A precise model for skin cancer diagnosis using hybrid U-Net and improved MobileNet-V3 with hyperparameters optimization,"Abstract Skin cancer is a frequently occurring and possibly deadly disease that necessitates prompt and precise diagnosis in order to ensure efficacious treatment. This paper introduces an innovative approach for accurately identifying skin cancer by utilizing Convolution Neural Network architecture and optimizing hyperparameters. The proposed approach aims to increase the precision and efficacy of skin cancer recognition and consequently enhance patients' experiences. This investigation aims to tackle various significant challenges in skin cancer recognition, encompassing feature extraction, model architecture design, and optimizing hyperparameters. The proposed model utilizes advanced deep-learning methodologies to extract complex features and patterns from skin cancer images. We enhance the learning procedure of deep learning by integrating Standard U-Net and Improved MobileNet-V3 with optimization techniques, allowing the model to differentiate malignant and benign skin cancers. Also substituted the crossed-entropy loss function of the Mobilenet-v3 mathematical framework with a bias loss function to enhance the accuracy. The model's squeeze and excitation component was replaced with the practical channel attention component to achieve parameter reduction. Integrating cross-layer connections among Mobile modules has been proposed to leverage synthetic features effectively. The dilated convolutions were incorporated into the model to enhance the receptive field. The optimization of hyperparameters is of utmost importance in improving the efficiency of deep learning models. To fine-tune the model's hyperparameter, we employ sophisticated optimization methods such as the Bayesian optimization method using pre-trained CNN architecture MobileNet-V3. The proposed model is compared with existing models, i.e., MobileNet, VGG-16, MobileNet-V2, Resnet-152v2 and VGG-19 on the “HAM-10000 Melanoma Skin Cancer dataset"". The empirical findings illustrate that the proposed optimized hybrid MobileNet-V3 model outperforms existing skin cancer detection and segmentation techniques based on high precision of 97.84%, sensitivity of 96.35%, accuracy of 98.86% and specificity of 97.32%. The enhanced performance of this research resulted in timelier and more precise diagnoses, potentially contributing to life-saving outcomes and mitigating healthcare expenditures.","<method>Convolution Neural Network</method>, <method>deep-learning methodologies</method>, <method>Standard U-Net</method>, <method>Improved MobileNet-V3</method>, <method>bias loss function</method>, <method>practical channel attention component</method>, <method>cross-layer connections among Mobile modules</method>, <method>dilated convolutions</method>, <method>Bayesian optimization method</method>, <method>pre-trained CNN architecture MobileNet-V3</method>",<method>Standard U-Net</method><method>Improved MobileNet-V3</method><method>dilated convolutions</method><method>Bayesian optimization method</method><method>pre-trained CNN architecture MobileNet-V3</method>
2024,https://openalex.org/W4400644938,Medicine,Leveraging artificial intelligence in vaccine development: A narrative review,"Vaccine development stands as a cornerstone of public health efforts, pivotal in curbing infectious diseases and reducing global morbidity and mortality. However, traditional vaccine development methods are often time-consuming, costly, and inefficient. The advent of artificial intelligence (AI) has ushered in a new era in vaccine design, offering unprecedented opportunities to expedite the process. This narrative review explores the role of AI in vaccine development, focusing on antigen selection, epitope prediction, adjuvant identification, and optimization strategies. AI algorithms, including machine learning and deep learning, leverage genomic data, protein structures, and immune system interactions to predict antigenic epitopes, assess immunogenicity, and prioritize antigens for experimentation. Furthermore, AI-driven approaches facilitate the rational design of immunogens and the identification of novel adjuvant candidates with optimal safety and efficacy profiles. Challenges such as data heterogeneity, model interpretability, and regulatory considerations must be addressed to realize the full potential of AI in vaccine development. Integrating emerging technologies, such as single-cell omics and synthetic biology, promises to enhance vaccine design precision and scalability. This review underscores the transformative impact of AI on vaccine development and highlights the need for interdisciplinary collaborations and regulatory harmonization to accelerate the delivery of safe and effective vaccines against infectious diseases.","<method>machine learning</method>, <method>deep learning</method>",<method>machine learning</method><method>deep learning</method>
2024,https://openalex.org/W4391361574,Medicine,Efficient pneumonia detection using Vision Transformers on chest X-rays,"Abstract Pneumonia is a widespread and acute respiratory infection that impacts people of all ages. Early detection and treatment of pneumonia are essential for avoiding complications and enhancing clinical results. We can reduce mortality, improve healthcare efficiency, and contribute to the global battle against a disease that has plagued humanity for centuries by devising and deploying effective detection methods. Detecting pneumonia is not only a medical necessity but also a humanitarian imperative and a technological frontier. Chest X-rays are a frequently used imaging modality for diagnosing pneumonia. This paper examines in detail a cutting-edge method for detecting pneumonia implemented on the Vision Transformer (ViT) architecture on a public dataset of chest X-rays available on Kaggle. To acquire global context and spatial relationships from chest X-ray images, the proposed framework deploys the ViT model, which integrates self-attention mechanisms and transformer architecture. According to our experimentation with the proposed Vision Transformer-based framework, it achieves a higher accuracy of 97.61%, sensitivity of 95%, and specificity of 98% in detecting pneumonia from chest X-rays. The ViT model is preferable for capturing global context, comprehending spatial relationships, and processing images that have different resolutions. The framework establishes its efficacy as a robust pneumonia detection solution by surpassing convolutional neural network (CNN) based architectures.","<method>Vision Transformer (ViT)</method>, <method>self-attention mechanisms</method>, <method>transformer architecture</method>, <method>convolutional neural network (CNN) based architectures</method>",<method>Vision Transformer (ViT)</method><method>self-attention mechanisms</method><method>transformer architecture</method><method>convolutional neural network (CNN) based architectures</method>
2024,https://openalex.org/W4391671371,Medicine,Collaborative threat intelligence: Enhancing IoT security through blockchain and machine learning integration,"Ensuring robust security in the Internet of Things (IoT) landscape is of paramount importance. This research article presents a novel approach to enhance IoT security by leveraging collaborative threat intelligence and integrating blockchain technology with machine learning (ML) models. The iOS application acts as a central control centre, facilitating the reporting and sharing of detected threats. The shared threat data is securely stored on a blockchain network, enabling ML models to access and learn from a diverse range of threat scenarios. The research focuses on implementing Random Forest, Decision Tree classifier, Ensemble, LSTM, and CNN models on the IoT23 dataset within the context of a Collaborative Threat Intelligence Framework for IoT Security. Through an iterative process, the models' accuracy is improved by reducing false negatives through the collaborative threat intelligence system. The article investigates the implementation details, privacy considerations, and the seamless integration of ML-based techniques for continuous model improvement. Experimental evaluations on the IoT23 dataset demonstrate the effectiveness of the proposed system in enhancing IoT security and mitigating potential threats. The research contributes to the advancement of collaborative threat intelligence and blockchain technology in the context of IoT security, paving the way for more secure and reliable IoT deployments.","<method>Random Forest</method>, <method>Decision Tree classifier</method>, <method>Ensemble</method>, <method>LSTM</method>, <method>CNN</method>",<method>Random Forest</method><method>Decision Tree classifier</method><method>Ensemble</method><method>LSTM</method><method>CNN</method>
2024,https://openalex.org/W4399537055,Medicine,Assessing the efficacy of 3D Dual-CycleGAN model for multi-contrast MRI synthesis,"Abstract Background This research presents a novel methodology for synthesizing 3D multi-contrast MRI images utilizing the 3D Dual-CycleGAN architecture. The performance of the model is evaluated on different MRI sequences, including T1-weighted (T1W), T1-weighted contrast-enhanced (T1c), T2-weighted (T2W), and FLAIR sequences. Results Our approach demonstrates proficient learning capabilities in transforming T1W images into target modalities. The proposed framework encompasses a combination of different loss functions including voxel-wise, gradient difference, perceptual, and structural similarity losses. These loss components, along with adversarial and dual cycle-consistency losses, contribute significantly to realistic and accurate syntheses. Evaluation metrics including MAE, PMAE, RMSE, PCC, PSNR, and SSIM are employed to assess the fidelity of synthesized images compared to their ground truth counterparts. Empirical results indicate the effectiveness of the 3D Dual-CycleGAN model in generating T1c images from T1W inputs with minimal average discrepancies (MAE of 2.8 ± 2.61) and strong similarity (SSIM of 0.82 ± 0.28). Furthermore, the synthesis of T2W and FLAIR images yields promising outcomes, demonstrating acceptable average discrepancies (MAE of 3.87 ± 3.32 for T2W and 3.82 ± 3.32 for FLAIR) and reasonable similarities (SSIM of 0.82 ± 0.28 for T2W and 0.80 ± 0.29 for FLAIR) relative to the original images. Conclusions These findings underscore the efficacy of the 3D Dual-CycleGAN model in generating high-fidelity images, with significant implications for diverse applications in the field of medical imaging.",<method>3D Dual-CycleGAN</method>,No methods remaining
2024,https://openalex.org/W4400981456,Medicine,Multimodal data integration for oncology in the era of deep neural networks: a review,"Cancer research encompasses data across various scales, modalities, and resolutions, from screening and diagnostic imaging to digitized histopathology slides to various types of molecular data and clinical records. The integration of these diverse data types for personalized cancer care and predictive modeling holds the promise of enhancing the accuracy and reliability of cancer screening, diagnosis, and treatment. Traditional analytical methods, which often focus on isolated or unimodal information, fall short of capturing the complex and heterogeneous nature of cancer data. The advent of deep neural networks has spurred the development of sophisticated multimodal data fusion techniques capable of extracting and synthesizing information from disparate sources. Among these, Graph Neural Networks (GNNs) and Transformers have emerged as powerful tools for multimodal learning, demonstrating significant success. This review presents the foundational principles of multimodal learning including oncology data modalities, taxonomy of multimodal learning, and fusion strategies. We delve into the recent advancements in GNNs and Transformers for the fusion of multimodal data in oncology, spotlighting key studies and their pivotal findings. We discuss the unique challenges of multimodal learning, such as data heterogeneity and integration complexities, alongside the opportunities it presents for a more nuanced and comprehensive understanding of cancer. Finally, we present some of the latest comprehensive multimodal pan-cancer data sources. By surveying the landscape of multimodal data integration in oncology, our goal is to underline the transformative potential of multimodal GNNs and Transformers. Through technological advancements and the methodological innovations presented in this review, we aim to chart a course for future research in this promising field. This review may be the first that highlights the current state of multimodal modeling applications in cancer using GNNs and transformers, presents comprehensive multimodal oncology data sources, and sets the stage for multimodal evolution, encouraging further exploration and development in personalized cancer care.","<method>deep neural networks</method>, <method>Graph Neural Networks (GNNs)</method>, <method>Transformers</method>",<method>deep neural networks</method><method>Graph Neural Networks (GNNs)</method><method>Transformers</method>
2024,https://openalex.org/W4390870882,Medicine,A domain adaptation approach to damage classification with an application to bridge monitoring,"Data-driven machine-learning algorithms generally suffer from a lack of labelled health-state data, mainly those referring to damage conditions. To address such an issue, population-based structural health monitoring seeks to enrich the original dataset by transferring knowledge from a population of monitored structures. Within this context, this paper presents a transfer learning approach, based on domain adaptation, to leverage information from completely-labelled bridge structure data to accurately predict new instances of an unknown target domain. Since intrinsic structural differences may cause distribution shifts, domain adaptation attempts to minimise the distance between the domains and to learn a mapping within a shared feature space. Specifically, the methodology involves the long-term acquisition of natural frequencies from several structural scenarios. Such damage-sensitive features are then aligned via domain adaptation so that a machine-learning algorithm can effectively utilise the labelled source domain data and generalise well to the unlabelled target-domain data. The described procedure is applied to two case studies, including the Z24 and the S101 benchmark bridges and their finite element models, respectively. The results demonstrate the successful exchange of health-state labels to identify the damage class within a population of bridges equipped with SHM systems, showing potential to reduce computational efforts and to deal with scarce or poor data sets in application to bridge network monitoring.","<method>transfer learning</method>, <method>domain adaptation</method>, <method>machine-learning algorithm</method>",<method>transfer learning</method><method>domain adaptation</method>
2024,https://openalex.org/W4391317914,Medicine,Exploring data mining and machine learning in gynecologic oncology,"Abstract Gynecologic (GYN) malignancies are gaining new and much-needed attention, perpetually fueling literature. Intra-/inter-tumor heterogeneity and “frightened” global distribution by race, ethnicity, and human development index, are pivotal clues to such ubiquitous interest. To advance “precision medicine” and downplay the heavy burden, data mining (DM) is timely in clinical GYN oncology. No consolidated work has been conducted to examine the depth and breadth of DM applicability as an adjunct to GYN oncology, emphasizing machine learning (ML)-based schemes. This systematic literature review (SLR) synthesizes evidence to fill knowledge gaps, flaws, and limitations. We report this SLR in compliance with Kitchenham and Charters’ guidelines. Defined research questions and PICO crafted a search string across five libraries: PubMed, IEEE Xplore, ScienceDirect, SpringerLink, and Google Scholar—over the past decade. Of the 3499 potential records, 181 primary studies were eligible for in-depth analysis. A spike (60.53%) corollary to cervical neoplasms is denoted onward 2019, predominantly featuring empirical solution proposals drawn from cohorts. Medical records led (23.77%, 53 art.). DM-ML in use is primarily built on neural networks (127 art.), appoint classification (73.19%, 172 art.) and diagnoses (42%, 111 art.), all devoted to assessment. Summarized evidence is sufficient to guide and support the clinical utility of DM schemes in GYN oncology. Gaps persist, inculpating the interoperability of single-institute scrutiny. Cross-cohort generalizability is needed to establish evidence while avoiding outcome reporting bias to locally, site-specific trained models. This SLR is exempt from ethics approval as it entails published articles.","<method>data mining (DM)</method>, <method>machine learning (ML)-based schemes</method>, <method>neural networks</method>",<method>neural networks</method>
2024,https://openalex.org/W4391811765,Medicine,Usefulness and Accuracy of Artificial Intelligence Chatbot Responses to Patient Questions for Neurosurgical Procedures,"BACKGROUND AND OBJECTIVES: The Internet has become a primary source of health information, leading patients to seek answers online before consulting health care providers. This study aims to evaluate the implementation of Chat Generative Pre-Trained Transformer (ChatGPT) in neurosurgery by assessing the accuracy and helpfulness of artificial intelligence (AI)–generated responses to common postsurgical questions. METHODS: A list of 60 commonly asked questions regarding neurosurgical procedures was developed. ChatGPT-3.0, ChatGPT-3.5, and ChatGPT-4.0 responses to these questions were recorded and graded by numerous practitioners for accuracy and helpfulness. The understandability and actionability of the answers were assessed using the Patient Education Materials Assessment Tool. Readability analysis was conducted using established scales. RESULTS: A total of 1080 responses were evaluated, equally divided among ChatGPT-3.0, 3.5, and 4.0, each contributing 360 responses. The mean helpfulness score across the 3 subsections was 3.511 ± 0.647 while the accuracy score was 4.165 ± 0.567. The Patient Education Materials Assessment Tool analysis revealed that the AI-generated responses had higher actionability scores than understandability. This indicates that the answers provided practical guidance and recommendations that patients could apply effectively. On the other hand, the mean Flesch Reading Ease score was 33.5, suggesting that the readability level of the responses was relatively complex. The Raygor Readability Estimate scores ranged within the graduate level, with an average score of the 15th grade. CONCLUSION: The artificial intelligence chatbot's responses, although factually accurate, were not rated highly beneficial, with only marginal differences in perceived helpfulness and accuracy between ChatGPT-3.0 and ChatGPT-3.5 versions. Despite this, the responses from ChatGPT-4.0 showed a notable improvement in understandability, indicating enhanced readability over earlier versions.","<method>Chat Generative Pre-Trained Transformer (ChatGPT-3.0)</method>, <method>Chat Generative Pre-Trained Transformer (ChatGPT-3.5)</method>, <method>Chat Generative Pre-Trained Transformer (ChatGPT-4.0)</method>",No methods remaining
2024,https://openalex.org/W4392200867,Medicine,Revolutionizing core muscle analysis in female sexual dysfunction based on machine learning,"Abstract The purpose of this study is to investigate the role of core muscles in female sexual dysfunction (FSD) and develop comprehensive rehabilitation programs to address this issue. We aim to answer the following research questions: what are the roles of core muscles in FSD, and how can machine and deep learning models accurately predict changes in core muscles during FSD? FSD is a common condition that affects women of all ages, characterized by symptoms such as decreased libido, difficulty achieving orgasm, and pain during intercourse. We conducted a comprehensive analysis of changes in core muscles during FSD using machine and deep learning. We evaluated the performance of multiple models, including multi-layer perceptron (MLP), long short-term memory (LSTM), convolutional neural network (CNN), recurrent neural network (RNN), ElasticNetCV, random forest regressor, SVR, and Bagging regressor. The models were evaluated based on mean squared error (MSE), mean absolute error (MAE), and R-squared (R 2 ) score. Our results show that CNN and random forest regressor are the most accurate models for predicting changes in core muscles during FSD. CNN achieved the lowest MSE (0.002) and the highest R 2 score (0.988), while random forest regressor also performed well with an MSE of 0.0021 and an R 2 score of 0.9905. Our study demonstrates that machine and deep learning models can accurately predict changes in core muscles during FSD. The neglected core muscles play a significant role in FSD, highlighting the need for comprehensive rehabilitation programs that address these muscles. By developing these programs, we can improve the quality of life for women with FSD and help them achieve optimal sexual health.","<method>multi-layer perceptron (MLP)</method>, <method>long short-term memory (LSTM)</method>, <method>convolutional neural network (CNN)</method>, <method>recurrent neural network (RNN)</method>, <method>ElasticNetCV</method>, <method>random forest regressor</method>, <method>SVR</method>, <method>Bagging regressor</method>",<method>multi-layer perceptron (MLP)</method><method>long short-term memory (LSTM)</method><method>convolutional neural network (CNN)</method><method>recurrent neural network (RNN)</method><method>ElasticNetCV</method><method>random forest regressor</method><method>SVR</method><method>Bagging regressor</method>
2024,https://openalex.org/W4392356867,Medicine,The SAFE procedure: a practical stopping heuristic for active learning-based screening in systematic reviews and meta-analyses,"Abstract Active learning has become an increasingly popular method for screening large amounts of data in systematic reviews and meta-analyses. The active learning process continually improves its predictions on the remaining unlabeled records, with the goal of identifying all relevant records as early as possible. However, determining the optimal point at which to stop the active learning process is a challenge. The cost of additional labeling of records by the reviewer must be balanced against the cost of erroneous exclusions. This paper introduces the SAFE procedure, a practical and conservative set of stopping heuristics that offers a clear guideline for determining when to end the active learning process in screening software like ASReview. The eclectic mix of stopping heuristics helps to minimize the risk of missing relevant papers in the screening process. The proposed stopping heuristic balances the costs of continued screening with the risk of missing relevant records, providing a practical solution for reviewers to make informed decisions on when to stop screening. Although active learning can significantly enhance the quality and efficiency of screening, this method may be more applicable to certain types of datasets and problems. Ultimately, the decision to stop the active learning process depends on careful consideration of the trade-off between the costs of additional record labeling against the potential errors of the current model for the specific dataset and context.",<method>active learning</method>,<method>active learning</method>
2024,https://openalex.org/W4392391621,Medicine,Autonomous Artificial Intelligence vs Artificial Intelligence–Assisted Human Optical Diagnosis of Colorectal Polyps: A Randomized Controlled Trial,"Background & AimsArtificial intelligence (AI)–based optical diagnosis systems (CADx) have been developed to allow pathology prediction of colorectal polyps during colonoscopies. However, CADx systems have not yet been validated for autonomous performance. Therefore, we conducted a trial comparing autonomous AI to AI-assisted human (AI-H) optical diagnosis.MethodsWe performed a randomized noninferiority trial of patients undergoing elective colonoscopies at 1 academic institution. Patients were randomized into (1) autonomous AI-based CADx optical diagnosis of diminutive polyps without human input or (2) diagnosis by endoscopists who performed optical diagnosis of diminutive polyps after seeing the real-time CADx diagnosis. The primary outcome was accuracy in optical diagnosis in both arms using pathology as the gold standard. Secondary outcomes included agreement with pathology for surveillance intervals.ResultsA total of 467 patients were randomized (238 patients/158 polyps in the autonomous AI group and 229 patients/179 polyps in the AI-H group). Accuracy for optical diagnosis was 77.2% (95% confidence interval [CI], 69.7–84.7) in the autonomous AI group and 72.1% (95% CI, 65.5–78.6) in the AI-H group (P = .86). For high-confidence diagnoses, accuracy for optical diagnosis was 77.2% (95% CI, 69.7–84.7) in the autonomous AI group and 75.5% (95% CI, 67.9–82.0) in the AI-H group. Autonomous AI had statistically significantly higher agreement with pathology-based surveillance intervals compared to AI-H (91.5% [95% CI, 86.9–96.1] vs 82.1% [95% CI, 76.5–87.7]; P = .016).ConclusionsAutonomous AI-based optical diagnosis exhibits noninferior accuracy to endoscopist-based diagnosis. Both autonomous AI and AI-H exhibited relatively low accuracy for optical diagnosis; however, autonomous AI achieved higher agreement with pathology-based surveillance intervals. (ClinicalTrials.gov, Number NCT05236790) Artificial intelligence (AI)–based optical diagnosis systems (CADx) have been developed to allow pathology prediction of colorectal polyps during colonoscopies. However, CADx systems have not yet been validated for autonomous performance. Therefore, we conducted a trial comparing autonomous AI to AI-assisted human (AI-H) optical diagnosis. We performed a randomized noninferiority trial of patients undergoing elective colonoscopies at 1 academic institution. Patients were randomized into (1) autonomous AI-based CADx optical diagnosis of diminutive polyps without human input or (2) diagnosis by endoscopists who performed optical diagnosis of diminutive polyps after seeing the real-time CADx diagnosis. The primary outcome was accuracy in optical diagnosis in both arms using pathology as the gold standard. Secondary outcomes included agreement with pathology for surveillance intervals. A total of 467 patients were randomized (238 patients/158 polyps in the autonomous AI group and 229 patients/179 polyps in the AI-H group). Accuracy for optical diagnosis was 77.2% (95% confidence interval [CI], 69.7–84.7) in the autonomous AI group and 72.1% (95% CI, 65.5–78.6) in the AI-H group (P = .86). For high-confidence diagnoses, accuracy for optical diagnosis was 77.2% (95% CI, 69.7–84.7) in the autonomous AI group and 75.5% (95% CI, 67.9–82.0) in the AI-H group. Autonomous AI had statistically significantly higher agreement with pathology-based surveillance intervals compared to AI-H (91.5% [95% CI, 86.9–96.1] vs 82.1% [95% CI, 76.5–87.7]; P = .016). Autonomous AI-based optical diagnosis exhibits noninferior accuracy to endoscopist-based diagnosis. Both autonomous AI and AI-H exhibited relatively low accuracy for optical diagnosis; however, autonomous AI achieved higher agreement with pathology-based surveillance intervals. (ClinicalTrials.gov, Number NCT05236790)","<method>autonomous AI-based CADx optical diagnosis</method>, <method>AI-assisted human (AI-H) optical diagnosis</method>",No methods remaining
2024,https://openalex.org/W4392565345,Medicine,Empowering personalized pharmacogenomics with generative AI solutions,"Abstract Objective This study evaluates an AI assistant developed using OpenAI’s GPT-4 for interpreting pharmacogenomic (PGx) testing results, aiming to improve decision-making and knowledge sharing in clinical genetics and to enhance patient care with equitable access. Materials and Methods The AI assistant employs retrieval-augmented generation (RAG), which combines retrieval and generative techniques, by harnessing a knowledge base (KB) that comprises data from the Clinical Pharmacogenetics Implementation Consortium (CPIC). It uses context-aware GPT-4 to generate tailored responses to user queries from this KB, further refined through prompt engineering and guardrails. Results Evaluated against a specialized PGx question catalog, the AI assistant showed high efficacy in addressing user queries. Compared with OpenAI’s ChatGPT 3.5, it demonstrated better performance, especially in provider-specific queries requiring specialized data and citations. Key areas for improvement include enhancing accuracy, relevancy, and representative language in responses. Discussion The integration of context-aware GPT-4 with RAG significantly enhanced the AI assistant’s utility. RAG’s ability to incorporate domain-specific CPIC data, including recent literature, proved beneficial. Challenges persist, such as the need for specialized genetic/PGx models to improve accuracy and relevancy and addressing ethical, regulatory, and safety concerns. Conclusion This study underscores generative AI’s potential for transforming healthcare provider support and patient accessibility to complex pharmacogenomic information. While careful implementation of large language models like GPT-4 is necessary, it is clear that they can substantially improve understanding of pharmacogenomic data. With further development, these tools could augment healthcare expertise, provider productivity, and the delivery of equitable, patient-centered healthcare services.","<method>retrieval-augmented generation (RAG)</method>, <method>context-aware GPT-4</method>, <method>prompt engineering</method>",<method>retrieval-augmented generation (RAG)</method>
2024,https://openalex.org/W4392783658,Medicine,AI applications in musculoskeletal imaging: a narrative review,"This narrative review focuses on clinical applications of artificial intelligence (AI) in musculoskeletal imaging. A range of musculoskeletal disorders are discussed using a clinical-based approach, including trauma, bone age estimation, osteoarthritis, bone and soft-tissue tumors, and orthopedic implant-related pathology. Several AI algorithms have been applied to fracture detection and classification, which are potentially helpful tools for radiologists and clinicians. In bone age assessment, AI methods have been applied to assist radiologists by automatizing workflow, thus reducing workload and inter-observer variability. AI may potentially aid radiologists in identifying and grading abnormal findings of osteoarthritis as well as predicting the onset or progression of this disease. Either alone or combined with radiomics, AI algorithms may potentially improve diagnosis and outcome prediction of bone and soft-tissue tumors. Finally, information regarding appropriate positioning of orthopedic implants and related complications may be obtained using AI algorithms. In conclusion, rather than replacing radiologists, the use of AI should instead help them to optimize workflow, augment diagnostic performance, and keep up with ever-increasing workload.Relevance statement This narrative review provides an overview of AI applications in musculoskeletal imaging. As the number of AI technologies continues to increase, it will be crucial for radiologists to play a role in their selection and application as well as to fully understand their potential value in clinical practice. Key points • AI may potentially assist musculoskeletal radiologists in several interpretative tasks.• AI applications to trauma, age estimation, osteoarthritis, tumors, and orthopedic implants are discussed.• AI should help radiologists to optimize workflow and augment diagnostic performance.","<method>AI algorithms</method>, <method>AI methods</method>, <method>radiomics</method>",No methods remaining
2024,https://openalex.org/W4392820641,Medicine,Analysis of human errors in human-autonomy collaboration in autonomous ships operations through shore control experimental data,"Human-autonomy collaboration plays a pivotal role in the development of Maritime autonomous surface ships (MASS), as Shore control center (SCC) operators may engage in the control loop by directly operating the MASS, or, in the supervisory loop, monitoring the MASS and taking over control when needed. Thus, efficient human performance during takeover control and operation is crucial for the safety of MASS operations. However, since the MASS is still in the early phase of development, the mechanism of human errors is unknown, and the data on human-autonomy collaborative operation is scarce. Human reliability analysis (HRA) aims to assess human errors qualitatively and quantitatively, and is widely used in various complex systems to help safety analysis. This study is dedicated to incorporating advanced HRA methods elements to identify and quantify human errors during taking over control and operation of a MASS in collision avoidance scenarios. It presents virtual experimental results, combined with theoretical human error identification and assessment methods. At first, we apply the Human-System Interaction in Autonomy (H-SIA) method to identify potential human errors; secondly, we identify relevant Performance Shaping Factors (PSFs) including Experience, Boredom, Task complexity, Available time and Pre-warning, and performance measures of the human errors, and implement them in the virtual experiment based on a full-scale autonomous ferry research vessel called milliAmpere2. Finally, we build a Bayesian Network (BN) to present causal and probabilistic relationships between PSFs and human errors through experimental data. The results show that available time has the highest impact on takeover performance of operators, followed by task complexity and pre-warning. Boredom does not present a significant sole impact unless combined with available time. Experience does not show a significant impact on human performance. In addition to the relevance of the human errors analysis to the safe development and operational design of MASS, the developed method benefits other human-autonomy collaborative systems. The developed BN model shows adaptability to assess human error probabilities, and the practical significance of integrating experimental data into the existing HRA methodologies for complex systems.",<method>Bayesian Network (BN)</method>,<method>Bayesian Network (BN)</method>
2024,https://openalex.org/W4396722287,Medicine,Performance of an Open-Source Large Language Model in Extracting Information from Free-Text Radiology Reports,"Purpose To assess the performance of a local open-source large language model (LLM) in various information extraction tasks from real-life emergency brain MRI reports. Materials and Methods All consecutive emergency brain MRI reports written in 2022 from a French quaternary center were retrospectively reviewed. Two radiologists identified MRI scans that were performed in the emergency department for headaches. Four radiologists scored the reports' conclusions as either normal or abnormal. Abnormalities were labeled as either headache-causing or incidental. Vicuna (LMSYS Org), an open-source LLM, performed the same tasks. Vicuna's performance metrics were evaluated using the radiologists' consensus as the reference standard. Results Among the 2398 reports during the study period, radiologists identified 595 that included headaches in the indication (median age of patients, 35 years [IQR, 26-51 years]; 68% [403 of 595] women). A positive finding was reported in 227 of 595 (38%) cases, 136 of which could explain the headache. The LLM had a sensitivity of 98.0% (95% CI: 96.5, 99.0) and specificity of 99.3% (95% CI: 98.8, 99.7) for detecting the presence of headache in the clinical context, a sensitivity of 99.4% (95% CI: 98.3, 99.9) and specificity of 98.6% (95% CI: 92.2, 100.0) for the use of contrast medium injection, a sensitivity of 96.0% (95% CI: 92.5, 98.2) and specificity of 98.9% (95% CI: 97.2, 99.7) for study categorization as either normal or abnormal, and a sensitivity of 88.2% (95% CI: 81.6, 93.1) and specificity of 73% (95% CI: 62, 81) for causal inference between MRI findings and headache. Conclusion An open-source LLM was able to extract information from free-text radiology reports with excellent accuracy without requiring further training.","<method>Vicuna (open-source large language model, LLM)</method>","<method>Vicuna (open-source large language model, LLM)</method>"
2024,https://openalex.org/W4399667220,Medicine,"Triage Performance Across Large Language Models, ChatGPT, and Untrained Doctors in Emergency Medicine: Comparative Study","Background Large language models (LLMs) have demonstrated impressive performances in various medical domains, prompting an exploration of their potential utility within the high-demand setting of emergency department (ED) triage. This study evaluated the triage proficiency of different LLMs and ChatGPT, an LLM-based chatbot, compared to professionally trained ED staff and untrained personnel. We further explored whether LLM responses could guide untrained staff in effective triage. Objective This study aimed to assess the efficacy of LLMs and the associated product ChatGPT in ED triage compared to personnel of varying training status and to investigate if the models’ responses can enhance the triage proficiency of untrained personnel. Methods A total of 124 anonymized case vignettes were triaged by untrained doctors; different versions of currently available LLMs; ChatGPT; and professionally trained raters, who subsequently agreed on a consensus set according to the Manchester Triage System (MTS). The prototypical vignettes were adapted from cases at a tertiary ED in Germany. The main outcome was the level of agreement between raters’ MTS level assignments, measured via quadratic-weighted Cohen κ. The extent of over- and undertriage was also determined. Notably, instances of ChatGPT were prompted using zero-shot approaches without extensive background information on the MTS. The tested LLMs included raw GPT-4, Llama 3 70B, Gemini 1.5, and Mixtral 8x7b. Results GPT-4–based ChatGPT and untrained doctors showed substantial agreement with the consensus triage of professional raters (κ=mean 0.67, SD 0.037 and κ=mean 0.68, SD 0.056, respectively), significantly exceeding the performance of GPT-3.5–based ChatGPT (κ=mean 0.54, SD 0.024; P&lt;.001). When untrained doctors used this LLM for second-opinion triage, there was a slight but statistically insignificant performance increase (κ=mean 0.70, SD 0.047; P=.97). Other tested LLMs performed similar to or worse than GPT-4–based ChatGPT or showed odd triaging behavior with the used parameters. LLMs and ChatGPT models tended toward overtriage, whereas untrained doctors undertriaged. Conclusions While LLMs and the LLM-based product ChatGPT do not yet match professionally trained raters, their best models’ triage proficiency equals that of untrained ED doctors. In its current form, LLMs or ChatGPT thus did not demonstrate gold-standard performance in ED triage and, in the setting of this study, failed to significantly improve untrained doctors’ triage when used as decision support. Notable performance enhancements in newer LLM versions over older ones hint at future improvements with further technological development and specific training.","<method>Large language models (LLMs)</method>, <method>ChatGPT</method>, <method>zero-shot approaches</method>, <method>GPT-4</method>, <method>Llama 3 70B</method>, <method>Gemini 1.5</method>, <method>Mixtral 8x7b</method>, <method>GPT-3.5</method>",<method>zero-shot approaches</method><method>GPT-4</method><method>Llama 3 70B</method><method>GPT-3.5</method>
2024,https://openalex.org/W4403545332,Medicine,Evaluating AI and Machine Learning Models in Breast Cancer Detection: A Review of Convolutional Neural Networks (CNN) and Global Research Trends,"Numerous studies have highlighted the significance of artificial intelligence (AI) in breast cancer diagnosis. However, systematic reviews of AI applications in this field often lack cohesion, with each study adopting a unique approach. The aim of this study is to provide a detailed examination of AI's role in breast cancer diagnosis through citation analysis, helping to categorize the key areas that attract academic attention. It also includes a thematic analysis to identify the specific research topics within each category. A total of 30,200 studies related to breast cancer and AI, published between 2015 and 2024, were sourced from databases such as IEEE, Scopus, PubMed, Springer, and Google Scholar. After applying inclusion and exclusion criteria, 32 relevant studies were identified. Most of these studies utilized classification models for breast cancer prediction, with high accuracy being the most commonly reported performance metric. Convolutional Neural Networks (CNN) emerged as the preferred model in many studies. The findings indicate that both the quantity and quality of AI-based algorithms in breast cancer diagnosis are increases in the given years. AI is increasingly seen as a complement to healthcare sector and clinical expertise, with the target of enhancing the accessibility and affordability of quality healthcare worldwide.","<method>classification models</method>, <method>Convolutional Neural Networks (CNN)</method>",<method>Convolutional Neural Networks (CNN)</method>
2024,https://openalex.org/W4390777660,Medicine,Unlocking the Potential of XAI for Improved Alzheimer’s Disease Detection and Classification Using a ViT-GRU Model,"Alzheimer's Disease (AD) is a significant cause of dementia worldwide, and its progression from mild to severe affects an individual's ability to perform daily activities independently. The accurate and early diagnosis of AD is crucial for effective clinical intervention. However, interpreting AD from medical images can be challenging, even for experienced radiologists. Therefore, there is a need for an automatic diagnosis of AD, and researchers have investigated the potential of utilizing Artificial Intelligence (AI) techniques, particularly deep learning models, to address this challenge. This study proposes a framework that combines a Vision Transformer (ViT) and a Gated Recurrent Unit (GRU) to detect AD characteristics from Magnetic Resonance Imaging (MRI) images accurately and reliably. The ViT identifies crucial features from the input image, and the GRU establishes clear correlations between these features. The proposed model overcomes the class imbalance issue in the MRI image dataset and achieves superior accuracy and performance compared to existing methods. The model was trained on the Alzheimer's MRI Preprocessed Dataset obtained from Kaggle, achieving notable accuracies of 99.53% for 4-class and 99.69% for binary classification. It also demonstrated a high accuracy of 99.26% for 3-class on the AD Neuroimaging Initiative (ADNI) Baseline Database. These results were validated through a thorough 10-fold cross-validation process. Furthermore, Explainable AI (XAI) techniques were incorporated to make the model interpretable and explainable. This allows clinicians to understand the model's decision-making process and gain insights into the underlying factors driving the AD diagnosis.","<method>Vision Transformer (ViT)</method>, <method>Gated Recurrent Unit (GRU)</method>, <method>Explainable AI (XAI) techniques</method>",<method>Vision Transformer (ViT)</method><method>Gated Recurrent Unit (GRU)</method>
2024,https://openalex.org/W4391166899,Medicine,"Prediction of atmospheric PM2.5 level by machine learning techniques in Isfahan, Iran","Abstract With increasing levels of air pollution, air quality prediction has attracted more attention. Mathematical models are being developed by researchers to achieve precise predictions. Monitoring and prediction of atmospheric PM 2.5 levels, as a predominant pollutant, is essential in emission mitigation programs. In this study, meteorological datasets from 9 years in Isfahan city, a large metropolis of Iran, were applied to predict the PM 2.5 levels, using four machine learning algorithms including Artificial Neural |Networks (ANNs), K-Nearest-Neighbors (KNN), Support Vector |Machines (SVMs) and ensembles of classification trees Random Forest (RF). The data from 7 air quality monitoring stations located in Isfahan City were taken into consideration. The Confusion Matrix and Cross-Entropy Loss were used to analyze the performance of classification models. Several parameters, including sensitivity, specificity, accuracy, F1 score, precision, and the area under the curve (AUC), are computed to assess model performance. Finally, by introducing the predicted data for 2020 into ArcGIS software and using the IDW (Inverse Distance Weighting) method, interpolation was conducted for the area of Isfahan city and the pollution map was illustrated for each month of the year. The results showed that, based on the accuracy percentage, the ANN model has a better performance (90.1%) in predicting PM 2.5 grades compared to the other models for the applied meteorological dataset, followed by RF (86.1%), SVM (84.6%) and KNN (82.2%) models, respectively. Therefore, ANN modelling provides a feasible procedure for the managerial planning of air pollution control.","<method>Artificial Neural Networks (ANNs)</method>, <method>K-Nearest-Neighbors (KNN)</method>, <method>Support Vector Machines (SVMs)</method>, <method>Random Forest (RF)</method>",<method>Artificial Neural Networks (ANNs)</method><method>K-Nearest-Neighbors (KNN)</method><method>Support Vector Machines (SVMs)</method><method>Random Forest (RF)</method>
2024,https://openalex.org/W4391810207,Medicine,Machine Learning–Based Prediction of Suicidality in Adolescents With Allergic Rhinitis: Derivation and Validation in 2 Independent Nationwide Cohorts,"Background Given the additional risk of suicide-related behaviors in adolescents with allergic rhinitis (AR), it is important to use the growing field of machine learning (ML) to evaluate this risk. Objective This study aims to evaluate the validity and usefulness of an ML model for predicting suicide risk in patients with AR. Methods We used data from 2 independent survey studies, Korea Youth Risk Behavior Web-based Survey (KYRBS; n=299,468) for the original data set and Korea National Health and Nutrition Examination Survey (KNHANES; n=833) for the external validation data set, to predict suicide risks of AR in adolescents aged 13 to 18 years, with 3.45% (10,341/299,468) and 1.4% (12/833) of the patients attempting suicide in the KYRBS and KNHANES studies, respectively. The outcome of interest was the suicide attempt risks. We selected various ML-based models with hyperparameter tuning in the discovery and performed an area under the receiver operating characteristic curve (AUROC) analysis in the train, test, and external validation data. Results The study data set included 299,468 (KYRBS; original data set) and 833 (KNHANES; external validation data set) patients with AR recruited between 2005 and 2022. The best-performing ML model was the random forest model with a mean AUROC of 84.12% (95% CI 83.98%-84.27%) in the original data set. Applying this result to the external validation data set revealed the best performance among the models, with an AUROC of 89.87% (sensitivity 83.33%, specificity 82.58%, accuracy 82.59%, and balanced accuracy 82.96%). While looking at feature importance, the 5 most important features in predicting suicide attempts in adolescent patients with AR are depression, stress status, academic achievement, age, and alcohol consumption. Conclusions This study emphasizes the potential of ML models in predicting suicide risks in patients with AR, encouraging further application of these models in other conditions to enhance adolescent health and decrease suicide rates.",<method>random forest</method>,<method>random forest</method>
2024,https://openalex.org/W4393033647,Medicine,Optimized Brain Tumor Detection: A Dual-Module Approach for MRI Image Enhancement and Tumor Classification,"Neurological and brain-related cancers are one of the main causes of death worldwide. A commonly used tool in diagnosing these conditions is Magnetic Resonance Imaging (MRI), yet the manual evaluation of MRI images by medical experts presents difficulties due to time constraints and variability. This research introduces a novel, two-module computerized method aimed at increasing the speed and accuracy of brain tumor detection. The first module, termed the Image Enhancement Technique, utilizes a trio of machine learning and imaging strategies—adaptive Wiener filtering, neural networks, and independent component analysis—to normalize images and combat issues such as noise and varying low region contrast. The second module uses Support Vector Machines to validate the output of the first module and perform tumor segmentation and classification. Applied to various types of brain tumors, including meningiomas and pituitary tumors, our method exhibited significant improvements in contrast and classification efficiency. It achieved an average sensitivity and specificity of 0.991, accuracy of 0.989, and a Dice score (DSC) of 0.981. Furthermore, the processing time of our method, averaging at 0.43 seconds, was markedly lower compared to existing methods. These results underscore the superior performance of our approach over current state-of-the-art methods in terms of sensitivity, specificity, precision, and DSC. Future enhancements will seek to increase the robustness of the tumor classification method by employing a standardized approach across a suite of classifiers.","<method>adaptive Wiener filtering</method>, <method>neural networks</method>, <method>independent component analysis</method>, <method>Support Vector Machines</method>",<method>neural networks</method><method>independent component analysis</method><method>Support Vector Machines</method>
2024,https://openalex.org/W4393141882,Medicine,Artificial Intelligence (AI) for Early Diagnosis of Retinal Diseases,"Artificial intelligence (AI) has emerged as a transformative tool in the field of ophthalmology, revolutionizing disease diagnosis and management. This paper provides a comprehensive overview of AI applications in various retinal diseases, highlighting its potential to enhance screening efficiency, facilitate early diagnosis, and improve patient outcomes. Herein, we elucidate the fundamental concepts of AI, including machine learning (ML) and deep learning (DL), and their application in ophthalmology, underscoring the significance of AI-driven solutions in addressing the complexity and variability of retinal diseases. Furthermore, we delve into the specific applications of AI in retinal diseases such as diabetic retinopathy (DR), age-related macular degeneration (AMD), Macular Neovascularization, retinopathy of prematurity (ROP), retinal vein occlusion (RVO), hypertensive retinopathy (HR), Retinitis Pigmentosa, Stargardt disease, best vitelliform macular dystrophy, and sickle cell retinopathy. We focus on the current landscape of AI technologies, including various AI models, their performance metrics, and clinical implications. Furthermore, we aim to address challenges and pitfalls associated with the integration of AI in clinical practice, including the “black box phenomenon”, biases in data representation, and limitations in comprehensive patient assessment. In conclusion, this review emphasizes the collaborative role of AI alongside healthcare professionals, advocating for a synergistic approach to healthcare delivery. It highlights the importance of leveraging AI to augment, rather than replace, human expertise, thereby maximizing its potential to revolutionize healthcare delivery, mitigate healthcare disparities, and improve patient outcomes in the evolving landscape of medicine.","<method>artificial intelligence (AI)</method>, <method>machine learning (ML)</method>, <method>deep learning (DL)</method>",<method>machine learning (ML)</method><method>deep learning (DL)</method>
2024,https://openalex.org/W4393405326,Medicine,"Developing Deep LSTMs With Later Temporal Attention for Predicting COVID-19 Severity, Clinical Outcome, and Antibody Level by Screening Serological Indicators Over Time","Objective: The clinical course of COVID-19, as well as the immunological reaction, is notable for its extreme variability. Identifying the main associated factors might help understand the disease progression and physiological status of COVID-19 patients. The dynamic changes of the antibody against Spike protein are crucial for understanding the immune response. This work explores a temporal attention (TA) mechanism of deep learning to predict COVID-19 disease severity, clinical outcomes, and Spike antibody levels by screening serological indicators over time. Methods: We use feature selection techniques to filter feature subsets that are highly correlated with the target. The specific deep Long Short-Term Memory (LSTM) models are employed to capture the dynamic changes of disease severity, clinical outcome, and Spike antibody level. We also propose deep LSTMs with a TA mechanism to emphasize the later blood test records because later records often attract more attention from doctors. Results: Risk factors highly correlated with COVID-19 are revealed. LSTM achieves the highest classification accuracy for disease severity prediction. Temporal Attention Long Short-Term Memory (TA-LSTM) achieves the best performance for clinical outcome prediction. For Spike antibody level prediction, LSTM achieves the best permanence. Conclusion: The experimental results demonstrate the effectiveness of the proposed models. The proposed models can provide a computer-aided medical diagnostics system by simply using time series of serological indicators.","<method>feature selection techniques</method>, <method>deep Long Short-Term Memory (LSTM) models</method>, <method>deep LSTMs with a temporal attention (TA) mechanism</method>",<method>deep Long Short-Term Memory (LSTM) models</method><method>deep LSTMs with a temporal attention (TA) mechanism</method>
2024,https://openalex.org/W4401537518,Medicine,A New Brain Network Construction Paradigm for Brain Disorder via Diffusion-Based Graph Contrastive Learning,"Brain network analysis plays an increasingly important role in studying brain function and the exploring of disease mechanisms. However, existing brain network construction tools have some limitations, including dependency on empirical users, weak consistency in repeated experiments and time-consuming processes. In this work, a diffusion-based brain network pipeline, DGCL is designed for end-to-end construction of brain networks. Initially, the brain region-aware module (BRAM) precisely determines the spatial locations of brain regions by the diffusion process, avoiding subjective parameter selection. Subsequently, DGCL employs graph contrastive learning to optimize brain connections by eliminating individual differences in redundant connections unrelated to diseases, thereby enhancing the consistency of brain networks within the same group. Finally, the node-graph contrastive loss and classification loss jointly constrain the learning process of the model to obtain the reconstructed brain network, which is then used to analyze important brain connections. Validation on two datasets, ADNI and ABIDE, demonstrates that DGCL surpasses traditional methods and other deep learning models in predicting disease development stages. Significantly, the proposed model improves the efficiency and generalization of brain network construction. In summary, the proposed DGCL can be served as a universal brain network construction scheme, which can effectively identify important brain connections through generative paradigms and has the potential to provide disease interpretability support for neuroscience research.","<method>diffusion process</method>, <method>graph contrastive learning</method>, <method>node-graph contrastive loss</method>, <method>classification loss</method>",<method>diffusion process</method><method>graph contrastive learning</method>
2024,https://openalex.org/W4386592162,Medicine,"Patient-Specific, Mechanistic Models of Tumor Growth Incorporating Artificial Intelligence and Big Data","Despite the remarkable advances in cancer diagnosis, treatment, and management over the past decade, malignant tumors remain a major public health problem. Further progress in combating cancer may be enabled by personalizing the delivery of therapies according to the predicted response for each individual patient. The design of personalized therapies requires the integration of patient-specific information with an appropriate mathematical model of tumor response. A fundamental barrier to realizing this paradigm is the current lack of a rigorous yet practical mathematical theory of tumor initiation, development, invasion, and response to therapy. We begin this review with an overview of different approaches to modeling tumor growth and treatment, including mechanistic as well as data-driven models based on big data and artificial intelligence. We then present illustrative examples of mathematical models manifesting their utility and discuss the limitations of stand-alone mechanistic and data-driven models. We then discuss the potential of mechanistic models for not only predicting but also optimizing response to therapy on a patient-specific basis. We describe current efforts and future possibilities to integrate mechanistic and data-driven models. We conclude by proposing five fundamental challenges that must be addressed to fully realize personalized care for cancer patients driven by computational models.","<method>artificial intelligence</method>, <method>data-driven models</method>",No methods remaining
2024,https://openalex.org/W4390659128,Medicine,Multi-Class Kidney Abnormalities Detecting Novel System Through Computed Tomography,"Impaired renal function poses a risk across all age groups. Because of the global shortage of nephrologists, the growing public health concern over renal failure, and technological improvements, there is a demand for an AI-driven system capable of autonomously detecting kidney abnormalities. Chronic kidney disease, commonly known as chronic renal failure, is characterized by a progressive decline in kidney function. Renal failure can be caused by a variety of reasons, including cysts, stones, and tumors. Chronic kidney disease may not have apparent symptoms at first, resulting in instances staying untreated until they reach an advanced state. Tumors are dense clumps of tissue that can cause direct injury to glands, spinal cells, and other organs. The presence of a substantial number of solids in the digestive tract causes kidney stone disease, also known as urolithiasis. This study used a deep learning model to detect kidney illnesses to solve the global scarcity of urologists. The project entailed obtaining and annotating a large dataset of 12,446 CT whole abdomen and urogram images, with an emphasis on kidney stones, cysts, and tumors, which are the most common types of renal illness. The dataset was divided into four categories: cyst, tumor, stone, and normal. Data was collected from several hospitals in the Dhaka area. This work presents an innovative and customizable platform for the clinical diagnosis of kidney diseases such as tumors, stones, and cysts. Our YOLOv8 model's enhanced accuracy opens up new possibilities for identifying kidney cysts, stones, and tumors. We used criteria like accuracy, precision, recall, F1 score, and specificity to evaluate its performance. The network attained an accuracy rate of 82.52%, 85.76% precision, 75.28% recall, 75.72% F1 score, and 93.12% specificity.","<method>deep learning model</method>, <method>YOLOv8</method>",<method>deep learning model</method><method>YOLOv8</method>
2024,https://openalex.org/W4390670279,Medicine,Awareness and level of digital literacy among students receiving health-based education,"Abstract Background Being digitally literate allows health-based science students to access reliable, up-to-date information efficiently and expands the capacity for continuous learning. Digital literacy facilitates effective communication and collaboration among other healthcare providers. It helps to navigate the ethical implications of using digital technologies and aids the use of digital tools in managing healthcare processes. Our aim in this study is to determine the digital literacy level and awareness of our students receiving health-based education in our university and to pave the way for supporting the current curriculum with courses on digital literacy when necessary. Method Students from Acibadem University who were registered undergraduate education for at least four years of health-based education, School of Medicine, Nutrition and Dietetics, Nursing, Physiotherapy and Rehabilitation, Psychology, Biomedical Engineering, Molecular Biology, and Genetics were included. The questionnaire consisted of 24 queries evaluating digital literacy in 7 fields: software and multimedia, hardware and technical problem solving, network and communication/collaboration, ethics, security, artificial intelligence (A.I.), and interest/knowledge. Two student groups representing all departments were invited for interviews according to the Delphi method. Results The survey was completed by 476 students. Female students had less computer knowledge and previous coding education. Spearman correlation test showed that there were weak positive correlations between the years and the “software and multimedia,” “ethics,” “interest and knowledge” domains, and the average score. The students from Nursing scored lowest in the query after those from the Nutrition and Dietetics department. The highest scores were obtained by Biomedical Engineering students, followed by the School of Medicine. Participants scored the highest in “network” and “A.I.” and lowest in “interest-knowledge” domains. Conclusion It is necessary to define the level of computer skills who start health-based education and shape the curriculum by determining which domains are weak. Creating an educational environment that fosters females’ digital knowledge is recommended. Elective courses across faculties may be offered to enable students to progress and discuss various digital literacy topics. The extent to which students benefit from the digital literacy-supported curriculum may be evaluated. Thus, health-based university students are encouraged to acquire the computer skills required by today’s clinical settings. Registration This study was approved by Acıbadem University and Acıbadem Healthcare Institutions Medical Research Ethics Committee (ATADEK) (11 November 2022, ATADEK registration: 2022-17-138) All methods were carried out in accordance with relevant guidelines and regulations. Informed consent was obtained from the participants.","<method>Delphi method</method>, <method>Spearman correlation test</method>",No methods remaining
2024,https://openalex.org/W4390823043,Medicine,Evaluating the Accuracy of ChatGPT and Google BARD in Fielding Oculoplastic Patient Queries: A Comparative Study on Artificial versus Human Intelligence,"Purpose: This study evaluates and compares the accuracy of responses from 2 artificial intelligence platforms to patients’ oculoplastics-related questions. Methods: Questions directed toward oculoplastic surgeons were collected, rephrased, and input independently into ChatGPT-3.5 and BARD chatbots, using the prompt: “As an oculoplastic surgeon, how can I respond to my patient’s question?.” Responses were independently evaluated by 4 experienced oculoplastic specialists as comprehensive, correct but inadequate, mixed correct and incorrect/outdated data, and completely incorrect. Additionally, the empathy level, length, and automated readability index of the responses were assessed. Results: A total of 112 patient questions underwent evaluation. The rates of comprehensive, correct but inadequate, mixed, and completely incorrect answers for ChatGPT were 71.4%, 12.9%, 10.5%, and 5.1%, respectively, compared with 53.1%, 18.3%, 18.1%, and 10.5%, respectively, for BARD. ChatGPT showed more empathy (48.9%) than BARD (13.2%). All graders found that ChatGPT outperformed BARD in question categories of postoperative healing, medical eye conditions, and medications. Categorizing questions by anatomy, ChatGPT excelled in answering lacrimal questions (83.8%), while BARD performed best in the eyelid group (60.4%). ChatGPT’s answers were longer and potentially more challenging to comprehend than BARD’s. Conclusion: This study emphasizes the promising role of artificial intelligence-powered chatbots in oculoplastic patient education and support. With continued development, these chatbots may potentially assist physicians and offer patients accurate information, ultimately contributing to improved patient care while alleviating surgeon burnout. However, it is crucial to highlight that artificial intelligence may be good at answering questions, but physician oversight remains essential to ensure the highest standard of care and address complex medical cases.","<method>ChatGPT-3.5</method>, <method>BARD chatbots</method>",No methods remaining
2024,https://openalex.org/W4391437034,Medicine,A methodical exploration of imaging modalities from dataset to detection through machine learning paradigms in prominent lung disease diagnosis: a review,"Abstract Background Lung diseases, both infectious and non-infectious, are the most prevalent cause of mortality overall in the world. Medical research has identified pneumonia, lung cancer, and Corona Virus Disease 2019 (COVID-19) as prominent lung diseases prioritized over others. Imaging modalities, including X-rays, computer tomography (CT) scans, magnetic resonance imaging (MRIs), positron emission tomography (PET) scans, and others, are primarily employed in medical assessments because they provide computed data that can be utilized as input datasets for computer-assisted diagnostic systems. Imaging datasets are used to develop and evaluate machine learning (ML) methods to analyze and predict prominent lung diseases. Objective This review analyzes ML paradigms, imaging modalities' utilization, and recent developments for prominent lung diseases. Furthermore, the research also explores various datasets available publically that are being used for prominent lung diseases. Methods The well-known databases of academic studies that have been subjected to peer review, namely ScienceDirect, arXiv, IEEE Xplore, MDPI, and many more, were used for the search of relevant articles. Applied keywords and combinations used to search procedures with primary considerations for review, such as pneumonia, lung cancer, COVID-19, various imaging modalities, ML, convolutional neural networks (CNNs), transfer learning, and ensemble learning. Results This research finding indicates that X-ray datasets are preferred for detecting pneumonia, while CT scan datasets are predominantly favored for detecting lung cancer. Furthermore, in COVID-19 detection, X-ray datasets are prioritized over CT scan datasets. The analysis reveals that X-rays and CT scans have surpassed all other imaging techniques. It has been observed that using CNNs yields a high degree of accuracy and practicability in identifying prominent lung diseases. Transfer learning and ensemble learning are complementary techniques to CNNs to facilitate analysis. Furthermore, accuracy is the most favored metric for assessment.","<method>machine learning (ML)</method>, <method>convolutional neural networks (CNNs)</method>, <method>transfer learning</method>, <method>ensemble learning</method>",<method>machine learning (ML)</method><method>convolutional neural networks (CNNs)</method><method>transfer learning</method><method>ensemble learning</method>
2024,https://openalex.org/W4392056032,Medicine,A novel fusion framework of deep bottleneck residual convolutional neural network for breast cancer classification from mammogram images,"With over 2.1 million new cases of breast cancer diagnosed annually, the incidence and mortality rate of this disease pose severe global health issues for women. Identifying the disease’s influence is the only practical way to lessen it immediately. Numerous research works have developed automated methods using different medical imaging to identify BC. Still, the precision of each strategy differs based on the available resources, the issue’s nature, and the dataset being used. We proposed a novel deep bottleneck convolutional neural network with a quantum optimization algorithm for breast cancer classification and diagnosis from mammogram images. Two novel deep architectures named three-residual blocks bottleneck and four-residual blocks bottle have been proposed with parallel and single paths. Bayesian Optimization (BO) has been employed to initialize hyperparameter values and train the architectures on the selected dataset. Deep features are extracted from the global average pool layer of both models. After that, a kernel-based canonical correlation analysis and entropy technique is proposed for the extracted deep features fusion. The fused feature set is further refined using an optimization technique named quantum generalized normal distribution optimization. The selected features are finally classified using several neural network classifiers, such as bi-layered and wide-neural networks. The experimental process was conducted on a publicly available mammogram imaging dataset named INbreast, and a maximum accuracy of 96.5% was obtained. Moreover, for the proposed method, the sensitivity rate is 96.45, the precision rate is 96.5, the F1 score value is 96.64, the MCC value is 92.97%, and the Kappa value is 92.97%, respectively. The proposed architectures are further utilized for the diagnosis process of infected regions. In addition, a detailed comparison has been conducted with a few recent techniques showing the proposed framework’s higher accuracy and precision rate.","<method>deep bottleneck convolutional neural network</method>, <method>quantum optimization algorithm</method>, <method>three-residual blocks bottleneck</method>, <method>four-residual blocks bottleneck</method>, <method>Bayesian Optimization (BO)</method>, <method>kernel-based canonical correlation analysis</method>, <method>entropy technique</method>, <method>quantum generalized normal distribution optimization</method>, <method>bi-layered neural network classifier</method>, <method>wide-neural network classifier</method>",<method>deep bottleneck convolutional neural network</method><method>Bayesian Optimization (BO)</method><method>kernel-based canonical correlation analysis</method><method>bi-layered neural network classifier</method><method>wide-neural network classifier</method>
2024,https://openalex.org/W4392139441,Medicine,Artificial intelligence for radiographic imaging detection of caries lesions: a systematic review,"Abstract Background The aim of this systematic review is to evaluate the diagnostic performance of Artificial Intelligence (AI) models designed for the detection of caries lesion (CL). Materials and methods An electronic literature search was conducted on PubMed, Web of Science, SCOPUS, LILACS and Embase databases for retrospective, prospective and cross-sectional studies published until January 2023, using the following keywords: artificial intelligence (AI), machine learning (ML), deep learning (DL), artificial neural networks (ANN), convolutional neural networks (CNN), deep convolutional neural networks (DCNN), radiology, detection, diagnosis and dental caries (DC). The quality assessment was performed using the guidelines of QUADAS-2. Results Twenty articles that met the selection criteria were evaluated. Five studies were performed on periapical radiographs, nine on bitewings, and six on orthopantomography. The number of imaging examinations included ranged from 15 to 2900. Four studies investigated ANN models, fifteen CNN models, and two DCNN models. Twelve were retrospective studies, six cross-sectional and two prospective. The following diagnostic performance was achieved in detecting CL: sensitivity from 0.44 to 0.86, specificity from 0.85 to 0.98, precision from 0.50 to 0.94, PPV (Positive Predictive Value) 0.86, NPV (Negative Predictive Value) 0.95, accuracy from 0.73 to 0.98, area under the curve (AUC) from 0.84 to 0.98, intersection over union of 0.3–0.4 and 0.78, Dice coefficient 0.66 and 0.88, F1-score from 0.64 to 0.92. According to the QUADAS-2 evaluation, most studies exhibited a low risk of bias. Conclusion AI-based models have demonstrated good diagnostic performance, potentially being an important aid in CL detection. Some limitations of these studies are related to the size and heterogeneity of the datasets. Future studies need to rely on comparable, large, and clinically meaningful datasets. Protocol PROSPERO identifier: CRD42023470708","<method>Artificial Neural Networks (ANN)</method>, <method>Convolutional Neural Networks (CNN)</method>, <method>Deep Convolutional Neural Networks (DCNN)</method>",<method>Artificial Neural Networks (ANN)</method><method>Convolutional Neural Networks (CNN)</method><method>Deep Convolutional Neural Networks (DCNN)</method>
2024,https://openalex.org/W4393175789,Medicine,"A deep-learning model for intracranial aneurysm detection on CT angiography images in China: a stepwise, multicentre, early-stage clinical validation study","BackgroundArtificial intelligence (AI) models in real-world implementation are scarce. Our study aimed to develop a CT angiography (CTA)-based AI model for intracranial aneurysm detection, assess how it helps clinicians improve diagnostic performance, and validate its application in real-world clinical implementation.MethodsWe developed a deep-learning model using 16 546 head and neck CTA examination images from 14 517 patients at eight Chinese hospitals. Using an adapted, stepwise implementation and evaluation, 120 certified clinicians from 15 geographically different hospitals were recruited. Initially, the AI model was externally validated with images of 900 digital subtraction angiography-verified CTA cases (examinations) and compared with the performance of 24 clinicians who each viewed 300 of these cases (stage 1). Next, as a further external validation a multi-reader multi-case study enrolled 48 clinicians to individually review 298 digital subtraction angiography-verified CTA cases (stage 2). The clinicians reviewed each CTA examination twice (ie, with and without the AI model), separated by a 4-week washout period. Then, a randomised open-label comparison study enrolled 48 clinicians to assess the acceptance and performance of this AI model (stage 3). Finally, the model was prospectively deployed and validated in 1562 real-world clinical CTA cases.FindingsThe AI model in the internal dataset achieved a patient-level diagnostic sensitivity of 0·957 (95% CI 0·939–0·971) and a higher patient-level diagnostic sensitivity than clinicians (0·943 [0·921–0·961] vs 0·658 [0·644–0·672]; p<0·0001) in the external dataset. In the multi-reader multi-case study, the AI-assisted strategy improved clinicians' diagnostic performance both on a per-patient basis (the area under the receiver operating characteristic curves [AUCs]; 0·795 [0·761–0·830] without AI vs 0·878 [0·850–0·906] with AI; p<0·0001) and a per-aneurysm basis (the area under the weighted alternative free-response receiver operating characteristic curves; 0·765 [0·732–0·799] vs 0·865 [0·839–0·891]; p<0·0001). Reading time decreased with the aid of the AI model (87·5 s vs 82·7 s, p<0·0001). In the randomised open-label comparison study, clinicians in the AI-assisted group had a high acceptance of the AI model (92·6% adoption rate), and a higher AUC when compared with the control group (0·858 [95% CI 0·850–0·866] vs 0·789 [0·780–0·799]; p<0·0001). In the prospective study, the AI model had a 0·51% (8/1570) error rate due to poor-quality CTA images and recognition failure. The model had a high negative predictive value of 0·998 (0·994–1·000) and significantly improved the diagnostic performance of clinicians; AUC improved from 0·787 (95% CI 0·766–0·808) to 0·909 (0·894–0·923; p<0·0001) and patient-level sensitivity improved from 0·590 (0·511–0·666) to 0·825 (0·759–0·880; p<0·0001).InterpretationThis AI model demonstrated strong clinical potential for intracranial aneurysm detection with improved clinician diagnostic performance, high acceptance, and practical implementation in real-world clinical cases.FundingNational Natural Science Foundation of China.TranslationFor the Chinese translation of the abstract see Supplementary Materials section.",<method>deep-learning model</method>,No methods remaining
2024,https://openalex.org/W4394967854,Medicine,Potential of Large Language Models in Health Care: Delphi Study,"Background A large language model (LLM) is a machine learning model inferred from text data that captures subtle patterns of language use in context. Modern LLMs are based on neural network architectures that incorporate transformer methods. They allow the model to relate words together through attention to multiple words in a text sequence. LLMs have been shown to be highly effective for a range of tasks in natural language processing (NLP), including classification and information extraction tasks and generative applications. Objective The aim of this adapted Delphi study was to collect researchers’ opinions on how LLMs might influence health care and on the strengths, weaknesses, opportunities, and threats of LLM use in health care. Methods We invited researchers in the fields of health informatics, nursing informatics, and medical NLP to share their opinions on LLM use in health care. We started the first round with open questions based on our strengths, weaknesses, opportunities, and threats framework. In the second and third round, the participants scored these items. Results The first, second, and third rounds had 28, 23, and 21 participants, respectively. Almost all participants (26/28, 93% in round 1 and 20/21, 95% in round 3) were affiliated with academic institutions. Agreement was reached on 103 items related to use cases, benefits, risks, reliability, adoption aspects, and the future of LLMs in health care. Participants offered several use cases, including supporting clinical tasks, documentation tasks, and medical research and education, and agreed that LLM-based systems will act as health assistants for patient education. The agreed-upon benefits included increased efficiency in data handling and extraction, improved automation of processes, improved quality of health care services and overall health outcomes, provision of personalized care, accelerated diagnosis and treatment processes, and improved interaction between patients and health care professionals. In total, 5 risks to health care in general were identified: cybersecurity breaches, the potential for patient misinformation, ethical concerns, the likelihood of biased decision-making, and the risk associated with inaccurate communication. Overconfidence in LLM-based systems was recognized as a risk to the medical profession. The 6 agreed-upon privacy risks included the use of unregulated cloud services that compromise data security, exposure of sensitive patient data, breaches of confidentiality, fraudulent use of information, vulnerabilities in data storage and communication, and inappropriate access or use of patient data. Conclusions Future research related to LLMs should not only focus on testing their possibilities for NLP-related tasks but also consider the workflows the models could contribute to and the requirements regarding quality, integration, and regulations needed for successful implementation in practice.","<method>large language model (LLM)</method>, <method>neural network architectures</method>, <method>transformer methods</method>",<method>large language model (LLM)</method><method>transformer methods</method>
2024,https://openalex.org/W4396753423,Medicine,ChatCAD+: Toward a Universal and Reliable Interactive CAD Using LLMs,"The integration of Computer-Aided Diagnosis (CAD) with Large Language Models (LLMs) presents a promising frontier in clinical applications, notably in automating diagnostic processes akin to those performed by radiologists and providing consultations similar to a virtual family doctor. Despite the promising potential of this integration, current works face at least two limitations: (1) From the perspective of a radiologist, existing studies typically have a restricted scope of applicable imaging domains, failing to meet the diagnostic needs of different patients. Also, the insufficient diagnostic capability of LLMs further undermine the quality and reliability of the generated medical reports. (2) Current LLMs lack the requisite depth in medical expertise, rendering them less effective as virtual family doctors due to the potential unreliability of the advice provided during patient consultations. To address these limitations, we introduce ChatCAD+, to be universal and reliable. Specifically, it is featured by two main modules: (1) Reliable Report Generation and (2) Reliable Interaction. The Reliable Report Generation module is capable of interpreting medical images from diverse domains and generate high-quality medical reports via our proposed hierarchical in-context learning. Concurrently, the interaction module leverages up-to-date information from reputable medical websites to provide reliable medical advice. Together, these designed modules synergize to closely align with the expertise of human medical professionals, offering enhanced consistency and reliability for interpretation and advice. The source code is available at GitHub.",<method>hierarchical in-context learning</method>,No methods remaining
2024,https://openalex.org/W4399055889,Medicine,Tomato Leaf Disease Detection using Convolutional Neural Networks,"One of the most important crops that is grown in enormous amounts and has an excellent market value comprises the tomato. They are grown and eaten in large quantities not only in India but also globally. Disease is the primary factor affecting the quantity and quality of this crop’s production. In earlier research, the plant’s leaves solely were taken into account for disease identification; however, in many cases, the illness only affects the fruit, leaving the other plant parts healthy. Using the unaided eye to diagnose a disease can occasionally lead to a prognosis that is off, meaning the wrong pesticide is applied and the plant may get spoiled. The farmers find it challenging to diagnose the disease because specialists are scarce in many of the affected areas. It’s an expensive and time-consuming process, even though professionals are accessible in certain sectors. Early disease detection would lessen the impact on plants and increase agricultural yield. As a result, it is essential to recognise these illnesses accurately and use the appropriate pesticide. These is- sues can be resolved by an automated system. We have developed a system to tackle this problem, which employs a convolutional neural network (CNN) to detect the ailment and recommends a pesticide to aid in its eradication. Since CNN offers its highest level of accuracy, our system incorporates it.",<method>convolutional neural network (CNN)</method>,<method>convolutional neural network (CNN)</method>
2024,https://openalex.org/W4402559330,Medicine,Generative artificial intelligence in primary care: an online survey of UK general practitioners,"Objectives Following the launch of ChatGPT in November 2022, interest in large language model-powered chatbots has soared with increasing focus on the clinical potential of these tools. We sought to measure general practitioners’ (GPs) current use of this new generation of chatbots to assist with any aspect of clinical practice in the UK. Methods An online survey was distributed to a non-probability sample of GPs registered with the clinician marketing service Doctors.net.uk. The study was launched as a monthly ‘omnibus survey’ which has a predetermined sample size of 1000 participants. Results 531 (53%) respondents were men, 544 (54%) were 46 years or older. 20% (205) reported using generative artificial intelligence (AI) tools in clinical practice; of those who answered affirmatively and were invited to clarify further, 29% (47) reported using these tools to generate documentation after patient appointments and 28% (45) to suggest a differential diagnosis. Discussion Administered a year after ChatGPT was launched, this is the largest survey we know of conducted into doctors’ use of generative AI in clinical practice. Findings suggest that GPs may derive value from these tools, particularly with administrative tasks and to support clinical reasoning. Conclusion Despite a lack of guidance about these tools and unclear work policies, GPs report using generative AI to assist with their job. The medical community will need to find ways to both educate physicians and trainees and guide patients about the safe adoption of these tools.",<method>generative artificial intelligence (AI) tools</method>,No methods remaining
2024,https://openalex.org/W4391174596,Medicine,Generative Large Language Models for Detection of Speech Recognition Errors in Radiology Reports,"This study evaluated the ability of generative large language models (LLMs) to detect speech recognition errors in radiology reports. A dataset of 3233 CT and MRI reports was assessed by radiologists for speech recognition errors. Errors were categorized as clinically significant or not clinically significant. Performances of five generative LLMs—GPT-3.5-turbo, GPT-4, text-davinci-003, Llama-v2–70B-chat, and Bard—were compared in detecting these errors, using manual error detection as the reference standard. Prompt engineering was used to optimize model performance. GPT-4 demonstrated high accuracy in detecting clinically significant errors (precision, 76.9%; recall, 100%; F1 score, 86.9%) and not clinically significant errors (precision, 93.9%; recall, 94.7%; F1 score, 94.3%). Text-davinci-003 achieved F1 scores of 72% and 46.6% for clinically significant and not clinically significant errors, respectively. GPT-3.5-turbo obtained 59.1% and 32.2% F1 scores, while Llama-v2–70B-chat scored 72.8% and 47.7%. Bard showed the lowest accuracy, with F1 scores of 47.5% and 20.9%. GPT-4 effectively identified challenging errors of nonsense phrases and internally inconsistent statements. Longer reports, resident dictation, and overnight shifts were associated with higher error rates. In conclusion, advanced generative LLMs show potential for automatic detection of speech recognition errors in radiology reports. Keywords: CT, Large Language Model, Machine Learning, MRI, Natural Language Processing, Radiology Reports, Speech, Unsupervised Learning Supplemental material is available for this article. © RSNA, 2024","<method>generative large language models (LLMs)</method>, <method>GPT-3.5-turbo</method>, <method>GPT-4</method>, <method>text-davinci-003</method>, <method>Llama-v2–70B-chat</method>, <method>Bard</method>, <method>prompt engineering</method>",<method>generative large language models (LLMs)</method><method>GPT-3.5-turbo</method><method>GPT-4</method><method>text-davinci-003</method><method>Llama-v2–70B-chat</method>
2024,https://openalex.org/W4391480252,Medicine,Performance of convolutional neural networks for the classification of brain tumors using magnetic resonance imaging,"Brain tumors are a diverse group of neoplasms that are challenging to detect and classify due to their varying characteristics. Deep learning techniques have proven to be effective in tumor classification. However, there is a lack of studies that compare these techniques using a common methodology. This work aims to analyze the performance of convolutional neural networks in the classification of brain tumors. We propose a network consisting of a few convolutional layers, batch normalization, and max-pooling. Then, we explore recent deep architectures, such as VGG, ResNet, EfficientNet, or ConvNeXt. The study relies on two magnetic resonance imaging datasets with over 3000 images of three types of tumors –gliomas, meningiomas, and pituitary tumors–, as well as images without tumors. We determine the optimal hyperparameters of the networks using the training and validation sets. The training and test sets are used to assess the performance of the models from different perspectives, including training from scratch, data augmentation, transfer learning, and fine-tuning. The experiments are performed using the TensorFlow and Keras libraries in Python. We compare the accuracy of the models and analyze their complexity based on the capacity of the networks, their training times, and image throughput. Several networks achieve high accuracy rates on both datasets, with the best model achieving 98.7% accuracy, which is on par with state-of-the-art methods. The average precision for each type of tumor is 94.3% for gliomas, 93.8% for meningiomas, 97.9% for pituitary tumors, and 95.3% for images without tumors. VGG is the largest model with over 171 million parameters, whereas MobileNet and EfficientNetB0 are the smallest ones with 3.2 and 5.9 million parameters, respectively. These two neural networks are also the fastest to train with 23.7 and 25.4 seconds per epoch, respectively. On the other hand, ConvNext is the slowest model with 58.2 seconds per epoch. Our custom model obtained the highest image throughput with 234.37 images per second, followed by MobileNet with 226 images per second. ConvNext obtained the smallest throughput with 97.35 images per second. ResNet, MobileNet, and EfficientNet are the most accurate networks, with MobileNet and EfficientNet demonstrating superior performance in terms of complexity. Most models achieve the best accuracy using transfer learning followed by a fine-tuning step. However, data augmentation does not contribute to increasing the accuracy of the models in general.","<method>convolutional neural networks</method>, <method>VGG</method>, <method>ResNet</method>, <method>EfficientNet</method>, <method>ConvNeXt</method>, <method>training from scratch</method>, <method>data augmentation</method>, <method>transfer learning</method>, <method>fine-tuning</method>",<method>convolutional neural networks</method><method>VGG</method><method>ResNet</method><method>EfficientNet</method><method>ConvNeXt</method><method>transfer learning</method><method>fine-tuning</method>
2024,https://openalex.org/W4391697089,Medicine,A Minimal and Multi-Source Recording Setup for Ankle Joint Kinematics Estimation During Walking Using Only Proximal Information From Lower Limb,"In this study, a minimal setup for the ankle joint kinematics estimation is proposed relying only on proximal information of the lower-limb, i.e. thigh muscles activity and joint kinematics. To this purpose, myoelectric activity of Rectus Femoris (RF), Biceps Femoris (BF), and Vastus Medialis (VM) were recorded by surface electromyography (sEMG) from six healthy subjects during unconstrained walking task. For each subject, the angular kinematics of hip and ankle joints were synchronously recorded with sEMG signal for a total of 288 gait cycles. Two feature sets were extracted from sEMG signals, i.e. time domain (TD) and wavelet (WT) and compared to have a compromise between the reliability and computational capacity, they were used for feeding three regression models, i.e. Artificial Neural Networks, Random Forest, and Least Squares - Support Vector Machine (LS-SVM). BF together with LS-SVM provided the best ankle angle estimation in both TD and WT domains (RMSE < 5.6 deg). The inclusion of Hip joint trajectory significantly enhanced the regression performances of the model (RMSE < 4.5 deg). Results showed the feasibility of estimating the ankle trajectory using only proximal and limited information from the lower limb which would maximize a potential transfemoral amputee user's comfortability while facing the challenge of having a small amount of information thus requiring robust data-driven models. These findings represent a significant step towards the development of a minimal setup useful for the control design of ankle active prosthetics and rehabilitative solutions.","<method>Artificial Neural Networks</method>, <method>Random Forest</method>, <method>Least Squares - Support Vector Machine (LS-SVM)</method>",<method>Artificial Neural Networks</method><method>Random Forest</method><method>Least Squares - Support Vector Machine (LS-SVM)</method>
2024,https://openalex.org/W4399685394,Engineering,Advanced Modelling of Soil Organic Carbon Content in Coal Mining Areas Using Integrated Spectral Analysis: A Dengcao Coal Mine Case Study,"Effective modelling and integrated spectral analysis approaches can advance modelling precision. To develop an integrated spectral forecast modelling of soil organic carbon (SOC), this research investigated a mining coal in Dengcao Coal Mine Area, Zhengzhou. The study utilizes the Lasso and Ranger algorithms were utilized in spectral band analysis. Four primary models employed during this process include Artificial Neural Network (ANN), Support Vector Machine, Random Forest (RF), and Partial Least Squares Regression (PLSR). The ideal model was chosen. The results showed that, in contrast to when band collection was based on Lasso algorithm modelling, model precision was higher when it was based on the Ranger algorithm. ANN model had an ideal goodness acceptance, and the modelling developed by RF showed the steadiest modelling consequences. Based on the results, a distinct method is proposed in this study for band assortment at the earlier stage of integrated spectral modelling of SOC. The Ranger method can be used to check the spectral particles, and RF or ANN can be chosen to develop the prediction modelling based on different statistics sets, which is appropriate to create the prediction modelling of SOC content in Dengcao Coal Mine Area. This research avails a position for the integrated spectral of Analysis for Advanced Modelling of Soil Organic Carbon Content in Coal Sources alongside a theoretical foundation for innovating portable device for the integrated spectral assessment of SOC content in coal mining habitats. This study might be significant for the changing modelling and monitoring of SOC in mining and environmental areas.","<method>Lasso</method>, <method>Ranger</method>, <method>Artificial Neural Network (ANN)</method>, <method>Support Vector Machine</method>, <method>Random Forest (RF)</method>, <method>Partial Least Squares Regression (PLSR)</method>",<method>Lasso</method><method>Artificial Neural Network (ANN)</method><method>Support Vector Machine</method><method>Random Forest (RF)</method>
2024,https://openalex.org/W4399657851,Engineering,Fusion of finite element and machine learning methods to predict rock shear strength parameters,"Abstract The trial-and-error method for calibrating rock mechanics parameters has the disadvantages of complexity, being time-consuming, and difficulty in ensuring accuracy. Harnessing the repeatability and scalability intrinsic to numerical simulation calculations and amalgamating them with the data-driven attributes of machine learning methods, this study uses the finite element analysis software RS2 to establish 252 sets of sandstone sample data. The recursive feature elimination and cross-validation method is employed for feature selection. The shear strength parameters of sandstone are predicted using machine learning models optimized by the particle swarm optimization (PSO) algorithm, including the backpropagation neural network, Bayesian ridge regression, support vector regression (SVR), and light gradient boosting machine. The predicted value of cohesion is proposed as the input feature to predict the friction angle. The results indicate that the optimal input characteristics for predicting cohesion are elastic modulus, Poisson's ratio, peak stress, and peak strain, while the optimal input characteristics for predicting friction angle are peak stress and cohesion. The PSO-SVR model demonstrates the best performance. The maximum error between the predicted values of cohesion and friction angle and the calculated results of RSData program are 3.5% and 4.31%, respectively. The finite element calculation is in good agreement with the stress–strain curve obtained in the laboratory. The sensitivity analysis indicates that SVR's prediction performance for cohesion and friction angle tends to be stable when the sample size is &amp;gt;25. These results offer a valuable reference for accurately predicting rock mechanics parameters.","<method>recursive feature elimination</method>, <method>cross-validation</method>, <method>particle swarm optimization (PSO)</method>, <method>backpropagation neural network</method>, <method>Bayesian ridge regression</method>, <method>support vector regression (SVR)</method>, <method>light gradient boosting machine</method>",<method>recursive feature elimination</method><method>backpropagation neural network</method><method>Bayesian ridge regression</method><method>support vector regression (SVR)</method><method>light gradient boosting machine</method>
2024,https://openalex.org/W4392872715,Engineering,GLC_FCS30D: the first global 30 m land-cover dynamics monitoring product with a fine classification system for the period from 1985 to 2022 generated using dense-time-series Landsat imagery and the continuous change-detection method,"Abstract. Land-cover change has been identified as an important cause or driving force of global climate change and is a significant research topic. Over the past few decades, global land-cover mapping has progressed; however, long-time-series global land-cover-change monitoring data are still sparse, especially those at 30 m resolution. In this study, we describe GLC_FCS30D, a novel global 30 m land-cover dynamics monitoring dataset containing 35 land-cover subcategories and covering the period 1985–2022 in 26 time steps (maps were updated every 5 years before 2000 and annually after 2000). GLC_FCS30D has been developed using continuous change detection and all available Landsat imagery based on the Google Earth Engine platform. Specifically, we first take advantage of the continuous change-detection model and the full time series of Landsat observations to capture the time points of changed pixels and identify the temporally stable areas. Then, we apply a spatiotemporal refinement method to derive the globally distributed and high-confidence training samples from these temporally stable areas. Next, local adaptive classification models are used to update the land-cover information for the changed pixels, and a temporal-consistency optimization algorithm is adopted to improve their temporal stability and suppress some false changes. Further, the GLC_FCS30D product is validated using 84 526 globally distributed validation samples from 2020. It achieves an overall accuracy of 80.88 % (±0.27 %) for the basic classification system (10 major land-cover types) and 73.04 % (±0.30 %) for the LCCS (Land Cover Classification System) level-1 validation system (17 LCCS land-cover types). Meanwhile, two third-party time-series datasets used for validation from the United States and Europe Union are also collected for analyzing accuracy variations, and the results show that GLC_FCS30D offers significant stability in terms of variation across the accuracy time series and achieves mean accuracies of 79.50 % (±0.50 %) and 81.91 % (±0.09 %) over the two regions. Lastly, we draw conclusions about the global land-cover-change information from the GLC_FCS30D dataset; namely, that forest and cropland variations have dominated global land-cover change over past 37 years, the net loss of forests reached about 2.5 million km2, and the net gain in cropland area is approximately 1.3 million km2. Therefore, the novel dataset GLC_FCS30D is an accurate land-cover-dynamics time-series monitoring product that benefits from its diverse classification system, high spatial resolution, and long time span (1985–2022); thus, it will effectively support global climate change research and promote sustainable development analysis. The GLC_FCS30D dataset is available via https://doi.org/10.5281/zenodo.8239305 (Liu et al., 2023).","<method>continuous change-detection model</method>, <method>spatiotemporal refinement method</method>, <method>local adaptive classification models</method>, <method>temporal-consistency optimization algorithm</method>",No methods remaining
2024,https://openalex.org/W4399450035,Engineering,Power Hungry Processing: Watts Driving the Cost of AI Deployment?,"Recent years have seen a surge in the popularity of commercial AI products based on generative, multi-purpose AI systems promising a unified approach to building machine learning (ML) models into technology. However, this ambition of ""generality"" comes at a steep cost to the environment, given the amount of energy these systems require and the amount of carbon that they emit. In this work, we propose the first systematic comparison of the ongoing inference cost of various categories of ML systems, covering both task-specific (i.e. finetuned models that carry out a single task) and 'general-purpose' models, (i.e. those trained for multiple tasks). We measure deployment cost as the amount of energy and carbon required to perform 1,000 inferences on representative benchmark dataset using these models. We find that multi-purpose, generative architectures are orders of magnitude more expensive than task-specific systems for a variety of tasks, even when controlling for the number of model parameters. We conclude with a discussion around the current trend of deploying multi-purpose generative ML systems, and caution that their utility should be more intentionally weighed against increased costs in terms of energy and emissions. All the data from our study can be accessed via an interactive demo to carry out further exploration and analysis.","<method>finetuned models</method>, <method>multi-purpose generative architectures</method>",No methods remaining
2024,https://openalex.org/W4401070841,Engineering,Transformer-Based Visual Segmentation: A Survey,"Visual segmentation seeks to partition images, video frames, or point clouds into multiple segments or groups. This technique has numerous real-world applications, such as autonomous driving, image editing, robot sensing, and medical analysis. Over the past decade, deep learning-based methods have made remarkable strides in this area. Recently, transformers, a type of neural network based on self-attention originally designed for natural language processing, have considerably surpassed previous convolutional or recurrent approaches in various vision processing tasks. Specifically, vision transformers offer robust, unified, and even simpler solutions for various segmentation tasks. This survey provides a thorough overview of transformer-based visual segmentation, summarizing recent advancements. We first review the background, encompassing problem definitions, datasets, and prior convolutional methods. Next, we summarize a meta-architecture that unifies all recent transformer-based approaches. Based on this meta-architecture, we examine various method designs, including modifications to the meta-architecture and associated applications. We also present several specific subfields, including 3D point cloud segmentation, foundation model tuning, domain-aware segmentation, efficient segmentation, and medical segmentation. Additionally, we compile and re-evaluate the reviewed methods on several well-established datasets. Finally, we identify open challenges in this field and propose directions for future research. The project page can be found at <uri xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">https://github.com/lxtGH/Awesome-Segmentation-With-Transformer</uri> .","<method>deep learning-based methods</method>, <method>transformers</method>, <method>convolutional approaches</method>, <method>recurrent approaches</method>, <method>vision transformers</method>",<method>transformers</method><method>convolutional approaches</method><method>recurrent approaches</method><method>vision transformers</method>
2024,https://openalex.org/W4390837884,Engineering,The deep learning applications in IoT-based bio- and medical informatics: a systematic literature review,"Abstract Nowadays, machine learning (ML) has attained a high level of achievement in many contexts. Considering the significance of ML in medical and bioinformatics owing to its accuracy, many investigators discussed multiple solutions for developing the function of medical and bioinformatics challenges using deep learning (DL) techniques. The importance of DL in Internet of Things (IoT)-based bio- and medical informatics lies in its ability to analyze and interpret large amounts of complex and diverse data in real time, providing insights that can improve healthcare outcomes and increase efficiency in the healthcare industry. Several applications of DL in IoT-based bio- and medical informatics include diagnosis, treatment recommendation, clinical decision support, image analysis, wearable monitoring, and drug discovery. The review aims to comprehensively evaluate and synthesize the existing body of the literature on applying deep learning in the intersection of the IoT with bio- and medical informatics. In this paper, we categorized the most cutting-edge DL solutions for medical and bioinformatics issues into five categories based on the DL technique utilized: convolutional neural network , recurrent neural network , generative adversarial network , multilayer perception , and hybrid methods. A systematic literature review was applied to study each one in terms of effective properties, like the main idea, benefits, drawbacks, methods, simulation environment, and datasets. After that, cutting-edge research on DL approaches and applications for bioinformatics concerns was emphasized. In addition, several challenges that contributed to DL implementation for medical and bioinformatics have been addressed, which are predicted to motivate more studies to develop medical and bioinformatics research progressively. According to the findings, most articles are evaluated using features like accuracy, sensitivity, specificity, F -score, latency, adaptability, and scalability.","<method>convolutional neural network</method>, <method>recurrent neural network</method>, <method>generative adversarial network</method>, <method>multilayer perception</method>, <method>hybrid methods</method>",<method>convolutional neural network</method><method>recurrent neural network</method><method>generative adversarial network</method><method>hybrid methods</method>
2024,https://openalex.org/W4391018556,Engineering,Battery safety: Machine learning-based prognostics,"Lithium-ion batteries play a pivotal role in a wide range of applications, from electronic devices to large-scale electrified transportation systems and grid-scale energy storage. Nevertheless, they are vulnerable to both progressive aging and unexpected failures, which can result in catastrophic events such as explosions or fires. Given their expanding global presence, the safety of these batteries and potential hazards from serious malfunctions are now major public concerns. Over the past decade, scholars and industry experts are intensively exploring methods to monitor battery safety, spanning from materials to cell, pack and system levels and across various spectral, spatial, and temporal scopes. In this Review, we start by summarizing the mechanisms and nature of battery failures. Following this, we explore the intricacies in predicting battery system evolution and delve into the specialized knowledge essential for data-driven, machine learning models. We offer an exhaustive review spotlighting the latest strides in battery fault diagnosis and failure prognosis via an array of machine learning approaches. Our discussion encompasses: (1) supervised and reinforcement learning integrated with battery models, apt for predicting faults/failures and probing into failure causes and safety protocols at the cell level; (2) unsupervised, semi-supervised, and self-supervised learning, advantageous for harnessing vast data sets from battery modules/packs; (3) few-shot learning tailored for gleaning insights from scarce examples, alongside physics-informed machine learning to bolster model generalization and optimize training in data-scarce settings. We conclude by casting light on the prospective horizons of comprehensive, real-world battery prognostics and management.","<method>supervised learning</method>, <method>reinforcement learning</method>, <method>unsupervised learning</method>, <method>semi-supervised learning</method>, <method>self-supervised learning</method>, <method>few-shot learning</method>, <method>physics-informed machine learning</method>",<method>supervised learning</method><method>reinforcement learning</method><method>unsupervised learning</method><method>semi-supervised learning</method><method>self-supervised learning</method><method>few-shot learning</method><method>physics-informed machine learning</method>
2024,https://openalex.org/W4391804837,Engineering,Towards sustainable power generation: Recent advancements in floating photovoltaic technologies,"Floating solar photovoltaic systems are rapidly gaining traction due to their potential for higher energy yield and efficiency compared to conventional land-based solar photovoltaic systems. Recent studies indicate that this technology generates 0.6% to 4.4% more energy and exhibits efficiency improvements ranging from 0.1% to 4.45% over its land-based counterpart. Numerous studies conducted on evaluating this innovative technology have been reported, providing various insights required for further development. Unfortunately, these important pieces of information have been scattered: a comprehensive compilation of these findings is currently unavailable, resulting in a significant gap in knowledge and information. Thus, the main objective of this work is to provide a comprehensive insight into this new technology, various research and developments that have been reported and potential future development. The critical review indicates that advancements in this technology shall focus on improved floating structure design, robust instrumentation, wireless monitoring, and sensing capabilities. Moreover, novel technological solutions such as tracking systems, bi-facial solar panels, satellite-based array optimization, programming algorithms for grid integration, and artificial intelligence shall be further explored. Additionally, it was found that the integration of floating photovoltaic in marine environments and hydropower reservoirs holds significant promise for transforming global energy production. Despite these advancements, several hurdles remain, including safety concerns, risks associated with electricity–water interactions, standardization issues, national policy considerations, and potential increases in surrounding ground temperatures. It is vital to address the remaining challenges and leverage technological innovations to realize the full potential of floating photovoltaics in the transition towards sustainable energy production.",<method>artificial intelligence</method>,No methods remaining
2024,https://openalex.org/W4394935921,Engineering,Machine learning-based predictive model for thermal comfort and energy optimization in smart buildings,"In the current context of energy transition and increasing climate change, optimizing building performance has become a critical objective. Efficient energy use and occupant comfort are paramount considerations in building design and operation. To address these challenges, this study introduces a predictive model leveraging Machine Learning (ML) algorithms. The model aims to predict thermal comfort levels and optimize energy consumption in Heating, Ventilation, and Air Conditioning (HVAC) systems. Four distinct ML algorithms Support Vector Machine (SVM), Artificial Neural Network (ANN), Random Forest (RF), and EXtreme Gradient Boosting (XGBOOST) are employed for this purpose. Data for the model is collected using a network of Raspberry Pi boards equipped with multiple sensors. Performance evaluation of the ML algorithms is conducted using statistical error metrics, including, Root Mean Square Error (RMSE), Mean Square Error (MSE), Mean Absolute Error (MAE), and coefficient of determination (R2). Results reveal that the RF and XGBOOST algorithms exhibit superior performance, achieving accuracies of 96.7% and 9.64% respectively. In contrast, the SVM algorithm demonstrates inferior performance with a R2 of 81.1%. These findings underscore the predictive capability of the RF and XGBOOST model in forecasting Predicted Mean Vote (PMV) values. The proposed model holds promise for enhancing occupant thermal comfort in buildings while simultaneously optimizing energy consumption in HVAC systems. Further research could explore the practical applications of these findings in building design and operation.","<method>Support Vector Machine (SVM)</method>, <method>Artificial Neural Network (ANN)</method>, <method>Random Forest (RF)</method>, <method>EXtreme Gradient Boosting (XGBOOST)</method>",<method>Support Vector Machine (SVM)</method><method>Artificial Neural Network (ANN)</method><method>Random Forest (RF)</method><method>EXtreme Gradient Boosting (XGBOOST)</method>
2024,https://openalex.org/W4400020165,Engineering,"Big data, machine learning, and digital twin assisted additive manufacturing: A review","Additive manufacturing (AM) has undergone significant development over the past decades, resulting in vast amounts of data that carry valuable information. Numerous research studies have been conducted to extract insights from AM data and utilize it for optimizing various aspects such as the manufacturing process, supply chain, and real-time monitoring. Data integration into proposed digital twin frameworks and the application of machine learning techniques is expected to play pivotal roles in advancing AM in the future. In this paper, we provide an overview of machine learning and digital twin-assisted AM. On one hand, we discuss the research domain and highlight the machine-learning methods utilized in this field, including material analysis, design optimization, process parameter optimization, defect detection and monitoring, and sustainability. On the other hand, we examine the status of digital twin-assisted AM from the current research status to the technical approach and offer insights into future developments and perspectives in this area. This review paper aims to examine present research and development in the convergence of big data, machine learning, and digital twin-assisted AM. Although there are numerous review papers on machine learning for additive manufacturing and others on digital twins for AM, no existing paper has considered how these concepts are intrinsically connected and interrelated. Our paper is the first to integrate the three concepts big data, machine learning, and digital twins and propose a cohesive framework for how they can work together to improve the efficiency, accuracy, and sustainability of AM processes. By exploring latest advancements and applications within these domains, our objective is to emphasize the potential advantages and future possibilities associated with integration of these technologies in AM.",<method>machine learning</method>,<method>machine learning</method>
2024,https://openalex.org/W4390494339,Engineering,"A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection in Industrial Time Series: Methods, Applications, and Directions","Automating the monitoring of industrial processes has the potential to enhance efficiency and optimize quality by promptly detecting abnormal events and thus facilitating timely interventions. Deep learning, with its capacity to discern non-trivial patterns within large datasets, plays a pivotal role in this process. Standard deep learning methods are suitable to solve a specific task given a specific type of data. During training, deep learning demands large volumes of labeled data. However, due to the dynamic nature of the industrial processes and environment, it is impractical to acquire large-scale labeled data for standard deep learning training for every slightly different case anew. Deep transfer learning offers a solution to this problem. By leveraging knowledge from related tasks and accounting for variations in data distributions, the transfer learning framework solves new tasks with little or even no additional labeled data. The approach bypasses the need to retrain a model from scratch for every new setup and dramatically reduces the labeled data requirement. This survey first provides an in-depth review of deep transfer learning, examining the problem settings of transfer learning and classifying the prevailing deep transfer learning methods. Moreover, we delve into applications of deep transfer learning in the context of a broad spectrum of time series anomaly detection tasks prevalent in primary industrial domains, e.g., manufacturing process monitoring, predictive maintenance, energy management, and infrastructure facility monitoring. We discuss the challenges and limitations of deep transfer learning in industrial contexts and conclude the survey with practical directions and actionable suggestions to address the need to leverage diverse time series data for anomaly detection in an increasingly dynamic production environment.","<method>deep learning</method>, <method>standard deep learning methods</method>, <method>deep transfer learning</method>, <method>transfer learning framework</method>",<method>deep learning</method><method>deep transfer learning</method><method>transfer learning framework</method>
2024,https://openalex.org/W4399326707,Engineering,Enhancing precision agriculture: A comprehensive review of machine learning and AI vision applications in all-terrain vehicle for farm automation,"The automation of all-terrain vehicles (ATVs) through the integration of advanced technologies such as machine learning (ML) and artificial intelligence (AI) vision has significantly changed precision agriculture. This paper aims to analyse and develop trends to provide comprehensive knowledge of the current state of ATV-based precision agriculture and the future possibilities of ML and AI. A bibliometric analysis was conducted through network diagram with keywords taken from previous publications in the domain. This review comprehensively analyses the potential of machine learning and artificial intelligence in transforming farming operations through the automation of tasks and the deployment of all-terrain vehicles. The research extensively analyses how machine learning methods have influenced several aspects of agricultural activities, such as planting, harvesting, spraying, weeding, crop monitoring, and others. AI vision systems are being researched for their ability to enhance precise and prompt decision-making in ATV-driven agricultural automation. These technologies have been thoroughly tested to show how they can improve crop yield, reducing overall investment, and make farming more efficient. Examples include machine learning-based seeding accuracy, AI-enabled crop health monitoring, and the use of AI vision for accurate pesticide application. The assessment examines challenges such as data privacy problems and scalability constraints, along with potential advancements and future prospects in the field. This will assist researchers and practitioners in making well-informed judgments regarding farming practices that are efficient, sustainable, and technologically robust.","<method>machine learning</method>, <method>artificial intelligence vision</method>, <method>machine learning methods</method>, <method>AI vision systems</method>, <method>machine learning-based seeding accuracy</method>, <method>AI-enabled crop health monitoring</method>, <method>AI vision for accurate pesticide application</method>",<method>machine learning</method>
2024,https://openalex.org/W4391332961,Engineering,A novel framework for developing environmentally sustainable and cost-effective ultra-high-performance concrete (UHPC) using advanced machine learning and multi-objective optimization techniques,"This study aims to propose a novel framework for strength prediction and multi-objective optimization (MOO) of economical and environmentally sustainable ultra-high-performance concrete (UHPC) which aids in intelligent, sustainable, and resilient construction. Different tree- and boosting ensemble-based machine learning (ML) models are integrated to form an accurate and reliable prediction model for the uniaxial compressive strength of UHPC. The optimized models are integrated into a super learner model, resulting in a robust predictive model that is used as one of the objective functions in the MOO problem. A total of 19 objective functions are considered, including cost, uniaxial compressive strength, and 17 environmental impact categories that comprehensively evaluate the environmental sustainability of the UHPC mix. The resulting impacts from the mid-point indicators were calculated using the Eco-invent v3.7 Life Cycle Inventory database. The results showed that the super learner model accurately predicted the uniaxial compressive strength of UHPC. The MOO resulted in Pareto fronts, demonstrating the trade-off among the uniaxial compressive strength, cost, and environmental sustainability of the mix and a broad range of solutions that can be obtained for the 19 objectives. The study provides a useful tool for designers and decision-makers to select the optimal UHPC mixture that meets specific project requirements. Finally, for the practical application of the ML predictive model and MOO algorithm for UHPC, a graphical user interface-based software tool, FAI-OSUSCONCRET, was developed. This software tool offers fast, accurate, and intelligent predictions and multi-objective optimizations tailored to specific project requirements, thus resulting in a UHPC mixture that perfectly meets project needs.","<method>tree-based ensemble machine learning models</method>, <method>boosting ensemble-based machine learning models</method>, <method>super learner model</method>, <method>multi-objective optimization (MOO)</method>",<method>tree-based ensemble machine learning models</method><method>boosting ensemble-based machine learning models</method><method>super learner model</method>
2024,https://openalex.org/W4391168980,Engineering,Utilizing Hybrid Machine Learning and Soft Computing Techniques for Landslide Susceptibility Mapping in a Drainage Basin,"The hydrological system of thebasin of Lake Urmia is complex, deriving its supply from a network comprising 13 perennial rivers, along withnumerous small springs and direct precipitation onto the lake’s surface. Among these contributors, approximately half of the inflow is attributed to the Zarrineh River and the Simineh River. Remarkably, Lake Urmia lacks a natural outlet, with its water loss occurring solely through evaporation processes. This study employed a comprehensive methodology integrating ground surveys, remote sensing analyses, and meticulous documentation of historical landslides within the basin as primary information sources. Through this investigative approach, we preciselyidentified and geolocated a total of 512 historical landslide occurrences across the Urmia Lake drainage basin, leveraging GPS technology for precision. Thisarticle introduces a suite of hybrid machine learning predictive models, such as support-vector machine (SVM), random forest (RF), decision trees (DT), logistic regression (LR), fuzzy logic (FL), and the technique for order of preference by similarity to the ideal solution (TOPSIS). These models were strategically deployed to assess landslide susceptibility within the region. The outcomes of the landslide susceptibility assessment reveal that the main high susceptible zones for landslide occurrence are concentrated in the northwestern, northern, northeastern, and some southern and southeastern areas of the region. Moreover, when considering the implementation of predictions using different algorithms, it became evident that SVM exhibited superior performance regardingboth accuracy (0.89) and precision (0.89), followed by RF, with and accuracy of 0.83 and a precision of 0.83. However, it is noteworthy that TOPSIS yielded the lowest accuracy value among the algorithms assessed.","<method>support-vector machine (SVM)</method>, <method>random forest (RF)</method>, <method>decision trees (DT)</method>, <method>logistic regression (LR)</method>, <method>fuzzy logic (FL)</method>, <method>technique for order of preference by similarity to the ideal solution (TOPSIS)</method>",<method>support-vector machine (SVM)</method><method>random forest (RF)</method><method>decision trees (DT)</method><method>logistic regression (LR)</method>
2024,https://openalex.org/W4391558404,Engineering,Exploring the Potential of ChatGPT in Automated Code Refinement: An Empirical Study,"Code review is an essential activity for ensuring the quality and maintainability of software projects. However, it is a time-consuming and often error-prone task that can significantly impact the development process. Recently, ChatGPT, a cutting-edge language model, has demonstrated impressive performance in various natural language processing tasks, suggesting its potential to automate code review processes. However, it is still unclear how well ChatGPT performs in code review tasks. To fill this gap, in this paper, we conduct the first empirical study to understand the capabilities of ChatGPT in code review tasks, specifically focusing on automated code refinement based on given code reviews. To conduct the study, we select the existing benchmark CodeReview and construct a new code review dataset with high quality. We use CodeReviewer, a state-of-the-art code review tool, as a baseline for comparison with ChatGPT. Our results show that ChatGPT outperforms CodeReviewer in code refinement tasks. Specifically, our results show that ChatGPT achieves higher EM and BLEU scores of 22.78 and 76.44 respectively, while the state-of-the-art method achieves only 15.50 and 62.88 on a high-quality code review dataset. We further identify the root causes for ChatGPT's underperformance and propose several strategies to mitigate these challenges. Our study provides insights into the potential of ChatGPT in automating the code review process, and highlights the potential research directions.","<method>ChatGPT</method>, <method>CodeReviewer</method>",No methods remaining
2024,https://openalex.org/W4391831565,Engineering,Comparison of Random Forest and XGBoost Classifiers Using Integrated Optical and SAR Features for Mapping Urban Impervious Surface,"The integration of optical and SAR datasets through ensemble machine learning models shows promising results in urban remote sensing applications. The integration of multi-sensor datasets enhances the accuracy of information extraction. This research presents a comparison of two ensemble machine learning classifiers (random forest and extreme gradient boost (XGBoost)) classifiers using an integration of optical and SAR features and simple layer stacking (SLS) techniques. Therefore, Sentinel-1 (SAR) and Landsat 8 (optical) datasets were used with SAR textures and enhanced modified indices to extract features for the year 2023. The classification process utilized two machine learning algorithms, random forest and XGBoost, for urban impervious surface extraction. The study focused on three significant East Asian cities with diverse urban dynamics: Jakarta, Manila, and Seoul. This research proposed a novel index called the Normalized Blue Water Index (NBWI), which distinguishes water from other features and was utilized as an optical feature. Results showed an overall accuracy of 81% for UIS classification using XGBoost and 77% with RF while classifying land use land cover into four major classes (water, vegetation, bare soil, and urban impervious). However, the proposed framework with the XGBoost classifier outperformed the RF algorithm and Dynamic World (DW) data product and comparatively showed higher classification accuracy. Still, all three results show poor separability with bare soil class compared to ground truth data. XGBoost outperformed random forest and Dynamic World in classification accuracy, highlighting its potential use in urban remote sensing applications.","<method>ensemble machine learning models</method>, <method>random forest</method>, <method>extreme gradient boost (XGBoost)</method>, <method>simple layer stacking (SLS)</method>",<method>ensemble machine learning models</method><method>random forest</method><method>extreme gradient boost (XGBoost)</method>
2024,https://openalex.org/W4390511794,Engineering,Firefly algorithm based WSN-IoT security enhancement with machine learning for intrusion detection,"Abstract A Wireless Sensor Network (WSN) aided by the Internet of Things (IoT) is a collaborative system of WSN systems and IoT networks are work to exchange, gather, and handle data. The primary objective of this collaboration is to enhance data analysis and automation to facilitate improved decision-making. Securing IoT with the assistance of WSN necessitates the implementation of protective measures to confirm the safety and reliability of the interconnected WSN and IoT components. This research significantly advances the current state of the art in IoT and WSN security by synergistically harnessing the potential of machine learning and the Firefly Algorithm. The contributions of this work are twofold: firstly, the proposed FA-ML technique exhibits an exceptional capability to enhance intrusion detection accuracy within the WSN-IoT landscape. Secondly, the amalgamation of the Firefly Algorithm and machine learning introduces a novel dimension to the domain of security-oriented optimization techniques. The implications of this research resonate across various sectors, ranging from critical infrastructure protection to industrial automation and beyond, where safeguarding the integrity of interconnected systems are of paramount importance. The amalgamation of cutting-edge machine learning and bio-inspired algorithms marks a pivotal step forward in crafting robust and intelligent security measures for the evolving landscape of IoT-driven technologies. For intrusion detection in the WSN-IoT, the FA-ML method employs a support vector machine (SVM) machine model for classification with parameter tuning accomplished using a Grey Wolf Optimizer (GWO) algorithm. The experimental evaluation is simulated using NSL-KDD Dataset, revealing the remarkable enhancement of the FA-ML technique, achieving a maximum accuracy of 99.34%. In comparison, the KNN-PSO and XGBoost models achieved lower accuracies of 96.42% and 95.36%, respectively. The findings validate the potential of the FA-ML technique as an active security solution for WSN-IoT systems, harnessing the power of machine learning and the Firefly Algorithm to bolster intrusion detection capabilities.","<method>Firefly Algorithm</method>, <method>machine learning</method>, <method>FA-ML technique</method>, <method>support vector machine (SVM)</method>, <method>Grey Wolf Optimizer (GWO)</method>, <method>KNN-PSO</method>, <method>XGBoost</method>",<method>Firefly Algorithm</method><method>machine learning</method><method>support vector machine (SVM)</method><method>Grey Wolf Optimizer (GWO)</method><method>XGBoost</method>
2024,https://openalex.org/W4391512775,Engineering,Peak and ultimate stress-strain model of confined ultra-high-performance concrete (UHPC) using hybrid machine learning model with conditional tabular generative adversarial network,"Ultra-high-performance concrete (UHPC) has gained prominence owing to its exceptional physical and mechanical properties and improved sustainability, making it ideal for large-scale structural applications. While numerous analytical studies have focused on predicting the stress-strain response of unconfined UHPC, there remains a lack of a reliable model for predicting the stress-strain response of confined UHPC, which poses challenges to efficient design and broader adoption, particularly in seismically active regions. To bridge this gap, the present study introduces a framework that implements machine learning (ML) models augmented by a state-of-the-art conditional tabular generative adversarial network (CTGAN) and Optuna, which a next-generation optimization framework, to accurately predict the peak and ultimate axial stress-strain responses of UHPC confined with either normal-strength steel or high-strength steel. The Optuna-optimized CTGAN is employed to address the issue of limited data by generating synthetic datasets of hypothetical confined UHPC specimens. A comprehensive database of confined UHPC stress-strain responses was compiled from existing literature and used to condition the CTGAN. The augmented database is then leveraged to develop a hybrid ML model that integrates extreme gradient boosting, gradient boosting machine, support vector regression, and K-nearest neighbors for predicting peak and ultimate stress-strain responses of confined UHPC. The predictive accuracy of the proposed hybrid ML model is evaluated and compared with a diverse set of ML models of varying complexity, and the results demonstrate its superior performance in predicting the peak and ultimate stress-strain response of confined UHPC. Furthermore, a graphical user interface of the proposed model is developed to facilitate its practical implementation and provide a rapid, autonomous, and accurate prediction of the stress-strain response of confined UHPC at both peak and ultimate states.","<method>conditional tabular generative adversarial network (CTGAN)</method>, <method>Optuna</method>, <method>extreme gradient boosting</method>, <method>gradient boosting machine</method>, <method>support vector regression</method>, <method>K-nearest neighbors</method>",<method>conditional tabular generative adversarial network (CTGAN)</method><method>extreme gradient boosting</method><method>gradient boosting machine</method><method>support vector regression</method><method>K-nearest neighbors</method>
2024,https://openalex.org/W4393001808,Engineering,Multi-Source and Multi-modal Deep Network Embedding for Cross-Network Node Classification,"In recent years, to address the issue of networked data sparsity in node classification tasks, cross-network node classification (CNNC) leverages the richer information from a source network to enhance the performance of node classification in the target network, which typically has sparser information. However, in real-world applications, labeled nodes may be collected from multiple sources with multiple modalities (e.g., text, vision, and video). Naive application of single-source and single-modal CNNC methods may result in sub-optimal solutions. To this end, in this article, we propose a model called Multi-source and Multi-modal Cross-network Deep Network Embedding (M 2 CDNE) for cross-network node classification. In M 2 CDNE, we propose a deep multi-modal network embedding approach that combines the extracted deep multi-modal features to make the node vector representations network invariant. In addition, we apply dynamic adversarial adaptation to assess the significance of marginal and conditional probability distributions between each source and target network to make node vector representations label discriminative. Furthermore, we devise to classify nodes in the target network through the related source classifier and aggregate different predictions utilizing respective network weights, corresponding to the discrepancy between each source and target network. Extensive experiments performed on real-world datasets demonstrate that the proposed M 2 CDNE significantly outperforms the state-of-the-art approaches.","<method>cross-network node classification (CNNC)</method>, <method>Multi-source and Multi-modal Cross-network Deep Network Embedding (M 2 CDNE)</method>, <method>deep multi-modal network embedding</method>, <method>dynamic adversarial adaptation</method>",<method>deep multi-modal network embedding</method>
2024,https://openalex.org/W4390533101,Engineering,A vehicular network based intelligent transport system for smart cities using machine learning algorithms,"Abstract Smart cities and the Internet of Things have enabled the integration of communicating devices for efficient decision-making. Notably, traffic congestion is one major problem faced by daily commuters in urban cities. In developed countries, specialized sensors are deployed to gather traffic information to predict traffic patterns. Any traffic updates are shared with the commuters via the Internet. Such solutions become impracticable when physical infrastructure and Internet connectivity are either non-existent or very limited. In case of developing countries, no roadside units are available and Internet connectivity is still an issue in remote areas. Internet traffic analysis is a thriving field of study due to the myriad ways in which it may be put to practical use. In the intelligent Internet-of-Vehicles (IOVs), traffic congestion can be predicted and identified using cutting-edge technologies. Using tree-based decision-tree, random-forest, extra-tree, and XGBoost machine learning (ML) strategies, this research proposes an intelligent-transport-system for the IOVs-based vehicular network traffic in a smart city set-up. The suggested system uses ensemble learning and averages the selection of crucial features to give high detection accuracy at minimal computational costs, as demonstrated by the simulation results. For IOV-based vehicular network traffic, the tree-based ML approaches with feature-selection (FS) outperformed those without FS. When contrasted to the lowest KNN accuracy of 96.6% and the highest SVM accuracy of 98.01%, the Stacking approach demonstrates superior accuracy as 99.05%.","<method>decision-tree</method>, <method>random-forest</method>, <method>extra-tree</method>, <method>XGBoost</method>, <method>ensemble learning</method>, <method>feature-selection (FS)</method>, <method>KNN</method>, <method>SVM</method>, <method>Stacking</method>",<method>decision-tree</method><method>random-forest</method><method>extra-tree</method><method>XGBoost</method><method>ensemble learning</method><method>feature-selection (FS)</method><method>KNN</method><method>SVM</method><method>Stacking</method>
2024,https://openalex.org/W4390817508,Engineering,Conventional to Deep Ensemble Methods for Hyperspectral Image Classification: A Comprehensive Survey,"Hyperspectral image classification has become a hot research topic. HSI has been widely used in a wide range of real-world application areas due to the in-depth spectral information stored within each pixel. Noticeably, the detailed features - i.e., a nonlinear correlation between the obtained spectral data and the correlating HSI data object, generate efficient classification results that are complex for traditional techniques. Deep Learning (DL) has recently been validated as an influential feature extractor that efficiently identifies the nonlinear issues that have arisen in various computer vision challenges. This motivates using DL for Hyperspectral Image Classification (HSIC), which shows promising results. This survey provides a brief description of DL for HSIC and compares cutting-edge methodologies in the field. We will first summarize the key challenges for HSIC, and then we will discuss the superiority of DL and DL-ensemble in addressing these issues. In this article, we divide the state-of-the-art DL methodologies and DL with ensemble into spectral features, spatial features, and combined spatial-spectral features in order to comprehensively and critically evaluate the progress (future research directions as well) of such methodologies for HSIC. Furthermore, we will take into account that DL involves a substantial percentage of labeled training images, whereas obtaining such a number for HSI is time and cost-consuming. As a result, this survey describes some methodologies for improving the classification performance of DL techniques, which can serve as future recommendations.","<method>Deep Learning (DL)</method>, <method>DL-ensemble</method>",<method>Deep Learning (DL)</method>
2024,https://openalex.org/W4391318991,Engineering,Optimization of 3D printed parameters for socket prosthetic manufacturing using the taguchi method and response surface methodology,"The most prevalent 3D printing technology on the market currently is Fused deposition modeling (FDM). The main objective of this study is to analyze the effect of the FDM process parameters on the printing time and socket weight of the printed socket prosthetic process as a component of the transtibial prosthesis. Optimization and modeling of the 3D printing prosthetic socket process were carried out using the Taguchi and RSM methods. The Taguchi method was used to evaluate the influence of various factors (socket thickness, layer height, infill density, print speed, and nozzle temperature) on the amount of printing time and socket weight. Furthermore, the factors that have a significant effect are selected and modeled using the RSM method to obtain the highest percentage of printing time and socket weight. The applied material is polylactic acid (PLA) filament. Five printing process parameters were socket thickness (3 mm, 4 mm, 5 mm), layer height (0.1 mm, 0.15 mm, 0.3 mm), infill density (80 %, 90 %, 100 %), print speed (70 mm/s, 80 mm/s, 90 mm/s) and nozzle temperature (190 °C, 200 °C, 210 °C). The proposed quadratic models for reducing both printing time and socket weight were in good accordance with the actual experimental data. The coefficients of determination (R2) for test data were 0.9743 and 0.9993 for printing time and socket weight, respectively.","<method>Taguchi method</method>, <method>RSM method</method>",No methods remaining
2024,https://openalex.org/W4391301691,Engineering,AI-Driven Digital Twin Model for Reliable Lithium-Ion Battery Discharge Capacity Predictions,"The present study proposes a novel method for predicting the discharge capabilities of lithium-ion (Li-ion) batteries using a digital twin model in practice. By combining cutting-edge machine learning techniques, such as AdaBoost and long short-term memory (LSTM) network, with a semiempirical mathematical structure, the digital twin (DT)—a virtual representation that mimics the behavior of actual batteries in real time is constructed. Various metaheuristic optimization methods, such as antlion, grey wolf optimization (GWO), and improved grey wolf optimization (IGWO), are used to adjust hyperparameters in order to optimize the models. As indicators of performance, mean absolute error (MAE) and root-mean-square error (RMSE) are applied to the models after they have undergone extensive training and ten-fold cross-validation. The models are rigorously trained and cross-validated using the NASA battery aging dataset, a widely accepted benchmark dataset for battery research. The IGWO-AdaBoost digital twin model emerges as the standout performer, achieving exceptional accuracy in predicting the discharge capacity. This model demonstrates the lowest mean absolute error (MAE) of 0.01, showcasing its superior precision in estimating discharge capabilities. Additionally, the root mean square error (RMSE) for the IGWO-AdaBoost DT model is also the lowest at 0.01. The findings of this study offer insightful information about the potential utilization of the digital twin model to accurately predict the discharge capacity of batteries.","<method>AdaBoost</method>, <method>long short-term memory (LSTM) network</method>, <method>antlion optimization</method>, <method>grey wolf optimization (GWO)</method>, <method>improved grey wolf optimization (IGWO)</method>",<method>AdaBoost</method><method>long short-term memory (LSTM) network</method><method>antlion optimization</method><method>grey wolf optimization (GWO)</method><method>improved grey wolf optimization (IGWO)</method>
2024,https://openalex.org/W4390667445,Engineering,Automated data processing and feature engineering for deep learning and big data applications: A survey,"Modern approach to artificial intelligence (AI) aims to design algorithms that learn directly from data. This approach has achieved impressive results and has contributed significantly to the progress of AI, particularly in the sphere of supervised deep learning. It has also simplified the design of machine learning systems as the learning process is highly automated. However, not all data processing tasks in conventional deep learning pipelines have been automated. In most cases data has to be manually collected, preprocessed and further extended through data augmentation before they can be effective for training. Recently, special techniques for automating these tasks have emerged. The automation of data processing tasks is driven by the need to utilize large volumes of complex, heterogeneous data for machine learning and big data applications. Today, end-to-end automated data processing systems based on automated machine learning (AutoML) techniques are capable of taking raw data and transforming them into useful features for Big Data tasks by automating all intermediate processing stages. In this work, we present a thorough review of approaches for automating data processing tasks in deep learning pipelines, including automated data preprocessing– e.g., data cleaning, labeling, missing data imputation, and categorical data encoding–as well as data augmentation (including synthetic data generation using generative AI methods) and feature engineering–specifically, automated feature extraction, feature construction and feature selection. In addition to automating specific data processing tasks, we discuss the use of AutoML methods and tools to simultaneously optimize all stages of the machine learning pipeline.","<method>supervised deep learning</method>, <method>data augmentation</method>, <method>automated machine learning (AutoML)</method>, <method>automated data preprocessing</method>, <method>data cleaning</method>, <method>labeling</method>, <method>missing data imputation</method>, <method>categorical data encoding</method>, <method>synthetic data generation using generative AI methods</method>, <method>automated feature extraction</method>, <method>feature construction</method>, <method>feature selection</method>",<method>supervised deep learning</method><method>automated machine learning (AutoML)</method><method>synthetic data generation using generative AI methods</method><method>feature construction</method><method>feature selection</method>
2024,https://openalex.org/W4392980686,Engineering,Data-driven evolution of water quality models: An in-depth investigation of innovative outlier detection approaches-A case study of Irish Water Quality Index (IEWQI) model,"Recently, there has been a significant advancement in the water quality index (WQI) models utilizing data-driven approaches, especially those integrating machine learning and artificial intelligence (ML/AI) technology. Although, several recent studies have revealed that the data-driven model has produced inconsistent results due to the data outliers, which significantly impact model reliability and accuracy. The present study was carried out to assess the impact of data outliers on a recently developed Irish Water Quality Index (IEWQI) model, which relies on data-driven techniques. To the author's best knowledge, there has been no systematic framework for evaluating the influence of data outliers on such models. For the purposes of assessing the outlier impact of the data outliers on the water quality (WQ) model, this was the first initiative in research to introduce a comprehensive approach that combines machine learning with advanced statistical techniques. The proposed framework was implemented in Cork Harbour, Ireland, to evaluate the IEWQI model's sensitivity to outliers in input indicators to assess the water quality. In order to detect the data outlier, the study utilized two widely used ML techniques, including Isolation Forest (IF) and Kernel Density Estimation (KDE) within the dataset, for predicting WQ with and without these outliers. For validating the ML results, the study used five commonly used statistical measures. The performance metric (R2) indicates that the model performance improved slightly (R2 increased from 0.92 to 0.95) in predicting WQ after removing the data outlier from the input. But the IEWQI scores revealed that there were no statistically significant differences among the actual values, predictions with outliers, and predictions without outliers, with a 95% confidence interval at p < 0.05. The results of model uncertainty also revealed that the model contributed <1% uncertainty to the final assessment results for using both datasets (with and without outliers). In addition, all statistical measures indicated that the ML techniques provided reliable results that can be utilized for detecting outliers and their impacts on the IEWQI model. The findings of the research reveal that although the data outliers had no significant impact on the IEWQI model architecture, they had moderate impacts on the rating schemes' of the model. This finding indicated that detecting the data outliers could improve the accuracy of the IEWQI model in rating WQ as well as be helpful in mitigating the model eclipsing problem. In addition, the results of the research provide evidence of how the data outliers influenced the data-driven model in predicting WQ and reliability, particularly since the study confirmed that the IEWQI model's could be effective for accurately rating WQ despite the presence of the data outliers in the input. It could occur due to the spatio-temporal variability inherent in WQ indicators. However, the research assesses the influence of data input outliers on the IEWQI model and underscores important areas for future investigation. These areas include expanding temporal analysis using multi-year data, examining spatial outlier patterns, and evaluating detection methods. Moreover, it is essential to explore the real-world impacts of revised rating categories, involve stakeholders in outlier management, and fine-tune model parameters. Analysing model performance across varying temporal and spatial resolutions and incorporating additional environmental data can significantly enhance the accuracy of WQ assessment. Consequently, this study offers valuable insights to strengthen the IEWQI model's robustness and provides avenues for enhancing its utility in broader WQ assessment applications. Moreover, the study successfully adopted the framework for evaluating how data input outliers affect the data-driven model, such as the IEWQI model. The current study has been carried out in Cork Harbour for only a single year of WQ data. The framework should be tested across various domains for evaluating the response of the IEWQI model's in terms of the spatio-temporal resolution of the domain. Nevertheless, the study recommended that future research should be conducted to adjust or revise the IEWQI model's rating schemes and investigate the practical effects of data outliers on updated rating categories. However, the study provides potential recommendations for enhancing the IEWQI model's adaptability and reveals its effectiveness in expanding its applicability in more general WQ assessment scenarios.","<method>Isolation Forest (IF)</method>, <method>Kernel Density Estimation (KDE)</method>",<method>Isolation Forest (IF)</method>
2024,https://openalex.org/W4391226403,Engineering,Machine learning for multi-dimensional performance optimization and predictive modelling of nanopowder-mixed electric discharge machining (EDM),"Abstract Aluminium 6061 (Al6061) is a widely used material for various industrial applications due to low density and high strength. Nevertheless, the conventional machining operations are not the best choice for the machining purposes. Therefore, amongst all the non-conventional machining operations, electric discharge machining (EDM) is opted to carry out the research due to its wide ability to cut the materials. But the high electrode wear rate (EWR) and high dimensional inaccuracy or overcut (OC) of EDM limit its usage. Consequently, nanopowder is added to the dielectric medium to address the abovementioned issues. Nanopowder mixed EDM (NPMEDM) process is a complex process in terms of performance predictability for different materials. Similarly, the interactions between the process parameters such as peak current ( I p ), spark voltage ( S v ), pulse on time ( P on ) and powder concentration ( C p ) in dielectric enhance the parametric sensitivity. In addition, the cryogenic treatment (CT) of electrodes makes the process complex limiting conventional simulation approaches for modelling inter-relationships. An alternative approach requires experimental exploration and systematic investigation to model EWR and overcutting problems of EDM. Thus, artificial neural networks (ANNs) are used for predictive modelling of the process which are integrated with multi-objective genetic algorithm (MOGA) for parametric optimization. The approach uses experimental data based on response surface methodology (RSM) design of experiments. Moreover, the process physics is thoroughly discussed with parametric effect analysis supported with evidence of microscopic images, scanning electron microscopy (SEM) and 3D surface topographic images. Based on multi-dimensional optimization results, the NT brass electrode showed an improvement of 65.02% in EWR and 59.73% in OC using deionized water. However, CT brass electrode showed 78.41% reduction in EWR and 67.79% improved dimensional accuracy in deionized water. In addition to that, CT brass electrode gave 27.69% less EWR and 81.40% improved OC in deionized water compared to kerosene oil.","<method>artificial neural networks (ANNs)</method>, <method>multi-objective genetic algorithm (MOGA)</method>, <method>response surface methodology (RSM)</method>",<method>artificial neural networks (ANNs)</method><method>multi-objective genetic algorithm (MOGA)</method>
2024,https://openalex.org/W4394015596,Engineering,Predicting the mechanical properties of plastic concrete: An optimization method by using genetic programming and ensemble learners,"This study presents a comparative analysis of individual and ensemble learning algorithms (ELAs) to predict the compressive strength (CS) and flexural strength (FS) of plastic concrete. Multilayer perceptron neuron network (MLPNN), Support vector machine (SVM), random forest (RF), and decision tree (DT) were used as base learners, which were then combined with bagging and Adaboost methods to improve the predictive performance. In addition, gene expression programming (GEP) was used to develop computational equations that can be used to predict the CS and FS of plastic concrete. An extensive database containing 357 and 125 data points was obtained from the literature, and the eight most impactful ingredients were used in the model's development. The accuracy of all models was assessed using several statistical measures, including an error matrix, Akaike information criterion (AIC), K-fold cross-validation, and other external validation equations. Furthermore, sensitivity and SHAP analysis were performed to evaluate input variables' relative significance and impact on the anticipated CS and FS. Based on statistical measures and other validation criteria, GEP outpaces all other individual models, whereas, in ELAs, the SVR ensemble with Adaboost and RF modified with the Bagging technique demonstrated superior performance. SHapley Additive exPlanations (SHAP) and sensitivity analysis reveal that plastic, cement, water, and the age of the specimens have the highest influence, while superplasticizer has the lowest impact, which is consistent with experimental studies. Moreover, GUI and GEP-based simple mathematical correlation can enhance the practical scope of this study and be an effective tool for the pre-mix design of plastic concrete.","<method>Multilayer perceptron neuron network (MLPNN)</method>, <method>Support vector machine (SVM)</method>, <method>random forest (RF)</method>, <method>decision tree (DT)</method>, <method>bagging</method>, <method>Adaboost</method>, <method>gene expression programming (GEP)</method>, <method>SVR ensemble with Adaboost</method>, <method>RF modified with the Bagging technique</method>",<method>Multilayer perceptron neuron network (MLPNN)</method><method>Support vector machine (SVM)</method><method>random forest (RF)</method><method>decision tree (DT)</method><method>bagging</method><method>Adaboost</method><method>gene expression programming (GEP)</method><method>SVR ensemble with Adaboost</method>
2024,https://openalex.org/W4391855187,Engineering,Machine learning-assisted in-situ adaptive strategies for the control of defects and anomalies in metal additive manufacturing,"In metal additive manufacturing (AM), the material microstructure and part geometry are formed incrementally. Consequently, the resulting part could be defect- and anomaly-free if sufficient care is taken to deposit each layer under optimal process conditions. Conventional closed-loop control (CLC) engineering solutions which sought to achieve this were deterministic and rule-based, thus resulting in limited success in the stochastic environment experienced in the highly dynamic AM process. On the other hand, emerging machine learning (ML) based strategies are better suited to providing the robustness, scope, flexibility, and scalability required for process control in an uncertain environment. Offline ML models that help optimise AM process parameters before a build begins and online ML models that efficiently processed in-situ sensory data to detect and diagnose flaws in real-time (or near-real-time) have been developed. However, ML models that enable a process to take evasive or corrective actions in relation to flaws via on the fly decision-making are only emerging. These models must possess prognostic capabilities to provide context-sensitive recommendations for in-situ process control based on real-time diagnostics. In this article, we pinpoint the shortcomings in traditional CLC strategies, and provide a framework for defect and anomaly control through ML-assisted CLC in AM. We discuss flaws in terms of their causes, in-situ detectability, and controllability, and examine their management under three scenarios: avoidance, mitigation, and repair. Then, we summarise the research into ML models developed for offline optimisation and in-situ diagnosis before initiating a detailed conversation on the implementation of ML-assisted in-situ process control. We found that researchers favoured reinforcement learning approaches or inverse ML models for making rapid, situation-aware control decisions. We also observed that, to-date, the defects addressed were those that may be quantified relatively easily autonomously, and that mitigation (rather than avoidance or repair) was the aim of ML-assisted in-situ control strategies. Additionally, we highlight the various technologies that must seamlessly combine to advance the field of autonomous in-situ control so that it becomes a reality in industrial settings. Finally, we raise awareness of seldom discussed, yet highly pertinent, topics relevant to adaptive control. Our work closes a significant gap in the current AM literature by broaching wide-ranging discussions on matters relevant to in-situ adaptive control in AM.","<method>machine learning (ML) based strategies</method>, <method>offline ML models</method>, <method>online ML models</method>, <method>reinforcement learning approaches</method>, <method>inverse ML models</method>",<method>online ML models</method><method>reinforcement learning approaches</method>
2024,https://openalex.org/W4392640075,Engineering,Performance assessment of machine learning algorithms for mapping of land use/land cover using remote sensing data,"The rapid increase in population accelerates the rate of change of Land use/Land cover (LULC) in various parts of the world. This phenomenon caused a huge strain for natural resources. Hence, continues monitoring of LULC changes gained a significant importance for management of natural resources and assessing the climate change impacts. Recently, application of machine learning algorithms on RS (remote sensing) data for rapid and accurate mapping of LULC gained significant importance due to growing need of LULC estimation for ecosystem services, natural resource management and environmental management. Hence, it is crucial to access and compare the performance of different machine learning classifiers for accurate mapping of LULC. The primary objective of this study was to compare the performance of CART (Classification and Regression Tree), RF (Random Forest) and SVM (Support Vector Machine) for LULC estimation by processing RS data on Google Earth Engine (GEE). In total four classes of LULC (Water Bodies, Vegetation Cover, Urban Land and Barren Land) for city of Lahore were extracted using satellite images from Landsat-7, Landsat-8 and Landsat-9 for years 2008, 2015 and 2022, respectively. According to results, RF is the best performing classifier with maximum overall accuracy of 95.2% and highest Kappa coefficient value of 0.87, SVM achieved maximum accuracy of 89.8% with highest Kappa of 0.84 and CART showed maximum overall accuracy of 89.7% with Kappa value of 0.79. Results from this study can give assistance for decision makers, planners and RS experts to choose a suitable machine learning algorithm for LULC classification in an unplanned urbanized city like Lahore.","<method>Classification and Regression Tree (CART)</method>, <method>Random Forest (RF)</method>, <method>Support Vector Machine (SVM)</method>",<method>Classification and Regression Tree (CART)</method><method>Random Forest (RF)</method><method>Support Vector Machine (SVM)</method>
2024,https://openalex.org/W4390754233,Engineering,Groundwater Quality Assessment and Irrigation Water Quality Index Prediction Using Machine Learning Algorithms,"The evaluation of groundwater quality is crucial for irrigation purposes; however, due to financial constraints in developing countries, such evaluations suffer from insufficient sampling frequency, hindering comprehensive assessments. Therefore, associated with machine learning approaches and the irrigation water quality index (IWQI), this research aims to evaluate the groundwater quality in Naama, a region in southwest Algeria. Hydrochemical parameters (cations, anions, pH, and EC), qualitative indices (SAR,RSC,Na%,MH,and PI), as well as geospatial representations were used to determine the groundwater’s suitability for irrigation in the study area. In addition, efficient machine learning approaches for forecasting IWQI utilizing Extreme Gradient Boosting (XGBoost), Support vector regression (SVR), and K-Nearest Neighbours (KNN) models were implemented. In this research, 166 groundwater samples were used to calculate the irrigation index. The results showed that 42.18% of them were of excellent quality, 34.34% were of very good quality, 6.63% were good quality, 9.64% were satisfactory, and 4.21% were considered unsuitable for irrigation. On the other hand, results indicate that XGBoost excels in accuracy and stability, with a low RMSE (of 2.8272 and a high R of 0.9834. SVR with only four inputs (Ca2+, Mg2+, Na+, and K) demonstrates a notable predictive capability with a low RMSE of 2.6925 and a high R of 0.98738, while KNN showcases robust performance. The distinctions between these models have important implications for making informed decisions in agricultural water management and resource allocation within the region.","<method>Extreme Gradient Boosting (XGBoost)</method>, <method>Support Vector Regression (SVR)</method>, <method>K-Nearest Neighbours (KNN)</method>",<method>Extreme Gradient Boosting (XGBoost)</method><method>Support Vector Regression (SVR)</method><method>K-Nearest Neighbours (KNN)</method>
2024,https://openalex.org/W4391248672,Engineering,Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning,"Recent development in computing power has resulted in performance improvements on holistic(none-occluded) person Re-Identification (ReID) tasks. Nevertheless, the precision of the recent research will diminish when a pedestrian is obstructed by obstacles. Within the realm of 2D space, the loss of information from obstructed objects continues to pose significant challenges in the context of person ReID. Person is a 3D non-grid object, and thus semantic representation learning in only 2D space limits the understanding of occluded person. In the present work, we propose a network based on 3D multi-view learning, allowing it to acquire geometric and shape details of an occluded pedestrian from 3D space. Simultaneously, it capitalizes on advancements in 2D-based networks to extract semantic representations from 3D multi-views. Specifically, the surface random selection strategy is proposed to convert images of 2D RGB into 3D multi-views. Using this strategy, we build four extensive 3D multi-view data collections for person ReID. After that, Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning(MV-3DSReID), is proposed for identifying the person by learning person geometry and structure representation from the groups of multi-view images. In comparison to alternative data formats (e.g., 2D RGB, 3D point cloud), multi-view images complement each other's detailed features of the 3D object by adjusting rendering viewpoints, thus facilitating a more comprehensive understanding of the person for both holistic and occluded ReID situations. Experiments on occluded and holistic ReID tasks demonstrate performance levels comparable to state-of-the-art methods, validating the effectiveness of our proposed approach in tackling challenges related to occlusion. The code is available at https://github.com/hangjiaqi1/MV-TransReID.","<method>3D multi-view learning</method>, <method>2D-based networks</method>, <method>surface random selection strategy</method>, <method>Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning (MV-3DSReID)</method>",<method>3D multi-view learning</method>
2024,https://openalex.org/W4391973098,Engineering,The use of machine learning techniques to investigate the properties of metakaolin-based geopolymer concrete,"The construction industry significantly contributes to global greenhouse gas emissions, highlighting the imperative for developing environmentally friendly construction materials. Geopolymers, particularly those utilizing metakaolin (MK), have emerged as a promising green alternative to conventional concrete. However, the acquisition of MK-based geopolymer concrete with optimal mechanical properties poses challenges due to numerous influential factors, disagreement over various findings, and the lack of a reliable predictive model. This study aimed to address this gap by employing a wide range of machine learning methods, namely gradient boosting machine, random forest, decision tree, artificial neural network, and support vector machine. Different optimization and regularization techniques were used to comprehensively understand the factors affecting the compressive strength of MK-based geopolymer concrete, including mixture design, chemical characteristics of the initial binder and activators, and different curing regimes. The results demonstrated the exceptional performance of the gradient boosting machine in predicting the compressive strength of MK-based geopolymer concrete, achieving a coefficient of determination of 0.983 and a mean absolute error of 1.615 MPa. Additionally, the study employed partial dependence plots, feature importance analysis, and SHapley Additive exPlanations (SHAP) to elucidate the proposed models. The coarse-to-fine aggregate ratio, H2O/Na2O molar ratio, extra water content, and sodium hydroxide concentration were identified as the most critical parameters affecting the compressive strength of MK-based geopolymer concrete. This research contributes to advancing the development of sustainable construction materials, streamlining experimental tasks, minimizing the need for labor and materials, improving time efficiency, and providing valuable insights for optimizing the design of MK-based geopolymer concrete.","<method>gradient boosting machine</method>, <method>random forest</method>, <method>decision tree</method>, <method>artificial neural network</method>, <method>support vector machine</method>",<method>gradient boosting machine</method><method>random forest</method><method>decision tree</method><method>artificial neural network</method><method>support vector machine</method>
2024,https://openalex.org/W4392529708,Engineering,A machine learning-based framework for clustering residential electricity load profiles to enhance demand response programs,"Load shapes derived from smart meter data are frequently employed to analyze daily energy consumption patterns, particularly in the context of applications like Demand Response (DR). Nevertheless, one of the most important challenges to this endeavor lies in identifying the most suitable consumer clusters with similar consumption behaviors. In this paper, we present a novel machine learning based framework in order to achieve optimal load profiling through a real case study, utilizing data from almost 5000 households in London. Four widely used clustering algorithms are applied specifically K-means, K-medoids, Hierarchical Agglomerative Clustering and Density-based Spatial Clustering. An empirical analysis as well as multiple evaluation metrics are leveraged to assess those algorithms. Following that, we redefine the problem as a probabilistic classification one, with the classifier emulating the behavior of a clustering algorithm, leveraging Explainable AI (xAI) to enhance the interpretability of our solution. According to the clustering algorithm analysis the optimal number of clusters for this case is seven. Despite that, our methodology shows that two of the clusters, almost 10% of the dataset, exhibit significant internal dissimilarity. As a result, these clusters have been excluded from consideration for DR programs. The scalability and versatility of our solution makes it an ideal choice for power utility companies aiming to segment their users for creating more targeted DR programs.","<method>K-means</method>, <method>K-medoids</method>, <method>Hierarchical Agglomerative Clustering</method>, <method>Density-based Spatial Clustering</method>, <method>probabilistic classification</method>, <method>Explainable AI (xAI)</method>",<method>K-means</method><method>K-medoids</method><method>Hierarchical Agglomerative Clustering</method><method>Density-based Spatial Clustering</method><method>probabilistic classification</method><method>Explainable AI (xAI)</method>
2024,https://openalex.org/W4399035606,Engineering,Multivariate Gaidai hazard assessment method in combination with deconvolution scheme to predict extreme wave heights,"Current study advocates novel Gaidai hazards assessment methodology that may be utilized for excessive wave-heights spatiotemporal risk analysis, thus advancing climate change studies. Gaidai hazards assessment methodology being particularly suitable for multivariate dynamic environmental ocean systems, that have been MC (i.e., Monte Carlo) numerically simulated, either physically measured across a representative time period, resulting in synchronous quasi-ergodic timeseries. Offshore waves affect reliable production and operational safety of offshore and marine structures. Current study presents two reliability methods: first, state-of-the-art spatiotemporal reliability methodology, designed for multi-dimensional dynamic systems, to be presented in the current study; second, novel deconvolution extrapolation technique to follow. Primary target being accurate environmental ocean system's hazard hazards assessment. Classic risk assessment methods, dealing with measured timeseries may not always possess advantages of dealing efficiently with the environmental ocean system's high dimensionality, along with nonlinear cross-correlation patterns between various environmental ocean system's components. In-situ significant wave-height measured dataset, measured in different offshore areas, to be analyzed in the current study by means of application of advocated reliability methodology. Offshore waves representing complex highly-nonlinear, cross-correlated environmental dynamic system. Global climate change being also an important factor, affecting offshore wave-heights. Primary purpose of the current study had been to benchmark novel hazards assessment methodology, while utilizing efficiently underlying raw measured dataset. Methods put forth in the current study may be utilized for hazard hazards assessments for a large variety of nonlinear high dimensional environmental ocean systems.","<method>Monte Carlo (MC) simulation</method>, <method>spatiotemporal reliability methodology</method>, <method>deconvolution extrapolation technique</method>",No methods remaining
2024,https://openalex.org/W4400937555,Engineering,The diagnostic and triage accuracy of the GPT-3 artificial intelligence model: an observational study,"BackgroundArtificial intelligence (AI) applications in health care have been effective in many areas of medicine, but they are often trained for a single task using labelled data, making deployment and generalisability challenging. How well a general-purpose AI language model performs diagnosis and triage relative to physicians and laypeople is not well understood.MethodsWe compared the predictive accuracy of Generative Pre-trained Transformer 3 (GPT-3)'s diagnostic and triage ability for 48 validated synthetic case vignettes (<50 words; sixth-grade reading level or below) of both common (eg, viral illness) and severe (eg, heart attack) conditions to a nationally representative sample of 5000 lay people from the USA who could use the internet to find the correct options and 21 practising physicians at Harvard Medical School. There were 12 vignettes for each of four triage categories: emergent, within one day, within 1 week, and self-care. The correct diagnosis and triage category (ie, ground truth) for each vignette was determined by two general internists at Harvard Medical School. For each vignette, human respondents and GPT-3 were prompted to list diagnoses in order of likelihood, and the vignette was marked as correct if the ground-truth diagnosis was in the top three of the listed diagnoses. For triage accuracy, we examined whether the human respondents' and GPT-3's selected triage was exactly correct according to the four triage categories, or matched a dichotomised triage variable (emergent or within 1 day vs within 1 week or self-care). We estimated GPT-3's diagnostic and triage confidence on a given vignette using a modified bootstrap resampling procedure, and examined how well calibrated GPT-3's confidence was by computing calibration curves and Brier scores. We also performed subgroup analysis by case acuity, and an error analysis for triage advice to characterise how its advice might affect patients using this tool to decide if they should seek medical care immediately.FindingsAmong all cases, GPT-3 replied with the correct diagnosis in its top three for 88% (42/48, 95% CI 75–94) of cases, compared with 54% (2700/5000, 53–55) for lay individuals (p<0.0001) and 96% (637/666, 94–97) for physicians (p=0·012). GPT-3 triaged 70% correct (34/48, 57–82) versus 74% (3706/5000, 73–75; p=0.60) for lay individuals and 91% (608/666, 89–93%; p<0.0001) for physicians. As measured by the Brier score, GPT-3 confidence in its top prediction was reasonably well calibrated for diagnosis (Brier score=0·18) and triage (Brier score=0·22). We observed an inverse relationship between case acuity and GPT-3 accuracy (p<0·0001) with a fitted trend line of –8·33% decrease in accuracy for every level of increase in case acuity. For triage error analysis, GPT-3 deprioritised truly emergent cases in seven instances.InterpretationA general-purpose AI language model without any content-specific training could perform diagnosis at levels close to, but below, physicians and better than lay individuals. We found that GPT-3's performance was inferior to physicians for triage, sometimes by a large margin, and its performance was closer to that of lay individuals. Although the diagnostic performance of GPT-3 was comparable to physicians, it was significantly better than a typical person using a search engine.FundingThe National Heart, Lung, and Blood Institute.","<method>Generative Pre-trained Transformer 3 (GPT-3)</method>, <method>modified bootstrap resampling procedure</method>",<method>Generative Pre-trained Transformer 3 (GPT-3)</method>
2024,https://openalex.org/W4390738871,Engineering,Internet of things sensors and support vector machine integrated intelligent irrigation system for agriculture industry,"Abstract Because there is more demand for freshwater around the world and the world’s population is growing at the same time, there is a severe lack of freshwater resources in the central part of the planet. The world’s current population of 7.2 billion people is expected to grow to over 9 billion by the year 2050. The vast majority of freshwater is used for things like cooking, cleaning, and farming. Most industrialised countries are in desperate need of smart irrigation systems, which are now a must-have because of how quickly technology is improving. In article presents IoT based Sensor integrated intelligent irrigation system for agriculture industry. IoT based humidity and soil sensors are used to collect soil related data. This data is stored in a centralized cloud. Features are selected by CFS algorithm. This will help in discarding irrelevant data. Clustering of data is performed by K means algorithm. This will help in keeping similar data together. Then classification model is build using the SVM, Random Forest and Naïve Bayes algorithm. Model is trained, validated and tested using the acquired data. Historical soil and humidity related data is also used in training the model. K-means SVM hybrid classifier is achieving better results for classification, prediction of water demand and saving fresh water by intelligent irrigation. K-means SVM hybrid classifier has achieved accuracy rate of 98.5 percent. Specificity, recall and precision of K-means SVM hybrid classifier is also higher than random forest and naïve bayes classifier.","<method>CFS algorithm</method>, <method>K means algorithm</method>, <method>SVM</method>, <method>Random Forest</method>, <method>Naïve Bayes algorithm</method>, <method>K-means SVM hybrid classifier</method>",<method>CFS algorithm</method><method>K means algorithm</method><method>SVM</method><method>Random Forest</method><method>Naïve Bayes algorithm</method>
2024,https://openalex.org/W4391796054,Engineering,Optical remote sensing of crop biophysical and biochemical parameters: An overview of advances in sensor technologies and machine learning algorithms for precision agriculture,"This paper provides an overview of the recent developments in remote sensing technology and machine learning algorithms for estimating important biophysical and biochemical parameters for precision farming. The objectives are (i) to provide an overview of recent advances in remotely sensed retrieval of biophysical and biochemical parameters brought by the developments in sensor technologies and robust machine learning algorithms and (ii) to identify the sources of uncertainty in retrieving biophysical and biochemical parameters and implications for precision agriculture. The review revealed that developments in crop biophysical and biochemical parameters retrieval techniques were mainly driven by announcements and the availability of new sensors. Two ground-breaking events can be identified, i.e., the availability of Sentinel-2 and the SuperDove constellation. The two provide high temporal-high spatial resolution data relevant for site-specific management and super-spectral configuration, enabling retrieval of crop growth and health parameters. The free availability of Sentinel-2 triggered the testing of its spectral configurations and upscaling of retrieval approaches using simulated data from field spectrometers and airborne hyperspectral sensors. SuperDoves will likely reduce the cost of very high-resolution data while providing unprecedented capabilities for detailed, accurate and frequent characterisation of field variability. Studies showed that the red-edge bands and hybrid models coupling Radiative Transfer Model (RTM) and machine learning regression algorithms (MLRA) are promising for operational and accurate monitoring of stress-related crop parameters to aid time-sensitive agronomic decisions. However, such models were tested in Mediterranean climates and performed poorly in African semi-arid areas and China's temperate continental semi-humid monsoon climates. Therefore, locally-calibrated RTM models incorporating crop-type maps and other spatio-temporal constraints may reduce uncertainties when adapted to data-scarce regions. Generally, permanent experimental sites and a lack of systematic calibration data on various crops are some limiting factors to using remote sensing technologies for PA in Sub-Saharan Africa. Other complexities arise from farm configurations, such as small field sizes and mixed cropping practices. Therefore, future studies should develop generic, scalable and transferable models, especially within under-studied areas.",<method>machine learning regression algorithms (MLRA)</method>,No methods remaining
2024,https://openalex.org/W4393167823,Engineering,Risk analysis and assessment of water resource carrying capacity based on weighted gray model with improved entropy weighting method in the central plains region of China,"The issue of global water shortage is a serious concern. The scientific evaluation of water resource carrying capacity (WRCC) serves as the foundation for implementing measures to protect water resources. In addition, most of the studies are based on the analysis and research of regional WRCC from the aspects of water quantity and water quality. There are few studies on the four aspects of water resources endowment conditions, society, economy and ecological environment, which is difficult to scientifically and accurately reflect the analysis and evaluation of regional WRCC by the four systems. Therefore, it is necessary to conduct a deeper discussion and Analysis on this topic. This study presents a WRCC index system and corresponding ranking criteria based on 20 influencing factors from four aspects: water resources endowment (WRE), economy, society, and ecological environment. In addition, by combining the improved entropy weighting method (EWM) with gray correlation analysis, the weighted gray technique for order preference by similarity to an ideal solution (TOPSIS) model is proposed for analyzing and assessing WRCC risk. Finally, the WRCC of the study area from 2012 to 2021 is comprehensively evaluated in the central plains region of China (CPROC) as an example. The results show that the comprehensive evaluation obtained a multi-year average value of 0.2935, and the water resources shortage in the CPROC is generally in grade III status. The comprehensive average value of Beijing is 0.345, and the comprehensive average value of Henan is 0.397. The overall degree of water resources shortage is in the state of grade V shortage, Shaanxi is in the state of grade IV shortage, and the degree of water resources in Tianjin and Shanxi is relatively good. This study provides corresponding scientific basis and methodological guidance for the sustainable utilization of water resources and healthy socio-economic performance in the CPROC.","<method>improved entropy weighting method (EWM)</method>, <method>gray correlation analysis</method>, <method>weighted gray technique for order preference by similarity to an ideal solution (TOPSIS) model</method>",No methods remaining
2024,https://openalex.org/W4393210635,Engineering,Energy and economic analysis of building integrated photovoltaic thermal system: Seasonal dynamic modeling assisted with machine learning-aided method and multi-objective genetic optimization,"Building integrated photovoltaic thermal (BIPV/T) systems offer a highly effective means of generating clean energy for both electricity and heating purposes in residential buildings. Hence, this article introduces a new BIPV/T system to optimally minimize the energy consumption of a household residential building. The meticulous design of the proposed BIPV/T system is accomplished through MATLAB/Simulink® dynamic modeling. Performance analysis for the BIPV/T system is performed under different seasonal conditions with in-depth techno-economic analyses to estimate the expected enhancement in the thermal, electrical, and economic performance of the system. Moreover, a sensitivity analysis is conducted to explore the impact of various factors on the energetic and economic performances of the proposed BIPV/T system. More so, the two-layer feed-forward back-propagation artificial neural network modeling is developed to accurately predict the hourly solar radiation and ambient temperature for the BIPV/T. Additionally, a multi-objective optimization using the NSGA-II method is also conducted for the minimization of the total BIPV/T plant area and maximization of the total efficiency and net thermal power of the system as well as to estimate the optimized operating conditions for input variables across different seasons within the provided ranges. The sensitivity analysis revealed that higher solar flux levels lead to increased electric output power of the BIPV/T plant, but total efficiency decreases due to higher thermal losses. Moreover, the proposed NSGA-II shows a feasible method to attain a maximum net thermal power and optimal total efficiency of 5320 W and 63% with a minimal total plant area of 32.89 m2 that attained a very low deviation index from the ideal solution. The levelised cost of electricity is obtained as 0.10 $/kWh under the optimal conditions. Thus, these findings offer valuable insights into the potential of BIPV/T systems as a sustainable and efficient energy solution for residential applications.","<method>two-layer feed-forward back-propagation artificial neural network</method>, <method>NSGA-II</method>",<method>two-layer feed-forward back-propagation artificial neural network</method>
2024,https://openalex.org/W4390607226,Engineering,RanMerFormer: Randomized vision transformer with token merging for brain tumor classification,"Brains are the control center of the nervous system in human bodies, and brain tumor is one of the most deadly diseases. Currently, magnetic resonance imaging (MRI) is the most effective way to brain tumors early detection in clinical diagnoses due to its superior imaging quality for soft tissues. Manual analysis of brain MRI is error-prone which depends on empirical experience and the fatigue state of the radiologists to a large extent. Computer-aided diagnosis (CAD) systems are becoming more and more impactful because they can provide accurate prediction results based on medical images with advanced techniques from computer vision. Therefore, a novel CAD method for brain tumor classification named RanMerFormer is presented in this paper. A pre-trained vision transformer is used as the backbone model. Then, a merging mechanism is proposed to remove the redundant tokens in the vision transformer, which improves computing efficiency substantially. Finally, a randomized vector functional-link serves as the head in the proposed RanMerFormer, which can be trained swiftly. All the simulation results are obtained from two public benchmark datasets, which reveal that the proposed RanMerFormer can achieve state-of-the-art performance for brain tumor classification. The trained RanMerFormer can be applied in real-world scenarios to assist in brain tumor diagnosis.","<method>pre-trained vision transformer</method>, <method>merging mechanism to remove redundant tokens in the vision transformer</method>, <method>randomized vector functional-link</method>",<method>pre-trained vision transformer</method><method>randomized vector functional-link</method>
2024,https://openalex.org/W4394627421,Engineering,Multiobjective Scheduling of Energy-Efficient Stochastic Hybrid Open Shop With Brain Storm Optimization and Simulation Evaluation,"Recently, energy conservation in manufacturing industry, particular in energy-intensive industries, receives much attention in order to meet the environmental protection and sustainable development needs. Optimal job scheduling is of great importance in reducing unnecessary energy consumption. To this end, both energy and time-related criteria need to be taken into consideration to achieve an efficient and sustainable production process. Generally, it is difficult to obtain the accurate processing time of jobs in advance due to various uncertainties in open shop scheduling problems arising from manufacturing and service systems. This work formulates a stochastic multiobjective hybrid open shop scheduling problem that consists of open shop and parallel-machine models. First, a multiobjective chance-constrained program is established to minimize total tardiness and energy consumption while meeting makespan requirements. Second, we newly develop a multiobjective framework integrating a brain storm optimizer and a simulation system to solve this problem. We combine population evolution to enhance exploration and external archive evolution to strengthen exploitation into the brain storm optimizer to seek for promising solutions. A simulation system is accordingly designed by using stochastic simulation and discrete-event simulation to assess the searched solutions. Finally, by conducting experiments and comparing the proposed method with several existing algorithms and an exact solver, our results confirm that it significantly outperforms its peers in tackling the considered problem.","<method>brain storm optimizer</method>, <method>stochastic simulation</method>, <method>discrete-event simulation</method>",No methods remaining
2024,https://openalex.org/W4399303474,Engineering,Improving Forest Above-Ground Biomass Estimation by Integrating Individual Machine Learning Models,"The accurate estimation of forest above-ground biomass (AGB) is crucial for sustainable forest management and tracking the carbon cycle of forest ecosystem. Machine learning algorithms have been proven to have great potential in forest AGB estimation with remote sensing data. Though many studies have demonstrated that a single machine learning model can produce highly accurate estimations of forest AGB in many situations, efforts are still required to explore the possible improvement in forest AGB estimation for a specific scenario under study. This study aims to investigate the performance of novel ensemble machine learning methods for forest AGB estimation and analyzes whether these methods are affected by forest types, independent variables, and spatial autocorrelation. Four well-known machine learning models (CatBoost, LightGBM, random forest (RF), and XGBoost) were compared for forest AGB estimation in the study using eight scenarios devised on the basis of two study regions, two variable types, and two validation strategies. Subsequently, a hybrid model combining the strengths of these individual models was proposed for forest AGB estimation. The findings indicated that no individual model outperforms the others in all scenarios. The RF model demonstrates superior performance in scenarios 5, 6, and 7, while the CatBoost model shows the best performance in the remaining scenarios. Moreover, the proposed hybrid model consistently has the best performance in all scenarios in spite of some uncertainties. The ensemble strategy developed in this study for the hybrid model substantially improves estimation accuracy and exhibits greater stability, effectively addressing the challenge of model selection encountered in the forest AGB forecasting process.","<method>CatBoost</method>, <method>LightGBM</method>, <method>random forest (RF)</method>, <method>XGBoost</method>, <method>ensemble machine learning methods</method>, <method>hybrid model</method>",<method>CatBoost</method><method>LightGBM</method><method>random forest (RF)</method><method>XGBoost</method><method>ensemble machine learning methods</method>
2024,https://openalex.org/W4391018616,Engineering,Short-term power load forecasting based on AC-BiLSTM model,"The practice of ultra-short-term power load forecasting serves as a critical strategy for enabling rapid response and real-time dispatch in power systems. By improving the accuracy of load forecasting, both the safety of power systems and the efficiency of electricity usage can be significantly enhanced. Addressing the challenges posed by the non-linear and temporal characteristics of grid load data, this study introduces a novel ultra-short-term power load forecasting model, integrating Convolutional Neural Networks (CNN), Bidirectional Long Short-Term Memory networks (BiLSTM), and an Attention mechanism, referred to as the AC-BiLSTM model. This innovative approach harnesses the power of CNN and BiLSTM to extract spatio-temporal features of load data, while the Attention mechanism allocates optimal weights to the hidden states of the BiLSTM model, thereby amplifying crucial historical load sequence data and minimizing information loss. The final output of the model is then determined through a fully connected layer. To validate the efficacy of this approach, an empirical study was conducted using real load data from a specific region. The results, obtained from two contrasting experimental scenarios, demonstrate a significant enhancement in forecasting accuracy. This finding underscores the potential of the AC-BiLSTM model as a reliable tool for both strategic planning and maintaining operational stability in power systems.","<method>Convolutional Neural Networks (CNN)</method>, <method>Bidirectional Long Short-Term Memory networks (BiLSTM)</method>, <method>Attention mechanism</method>",<method>Convolutional Neural Networks (CNN)</method><method>Bidirectional Long Short-Term Memory networks (BiLSTM)</method><method>Attention mechanism</method>
2024,https://openalex.org/W4391178461,Engineering,Assessment of surrogate models for flood inundation: The physics-guided LSG model vs. state-of-the-art machine learning models,"Hydrodynamic models can accurately simulate flood inundation but are limited by their high computational demand that scales non-linearly with model complexity, resolution, and domain size. Therefore, it is often not feasible to use high-resolution hydrodynamic models for real-time flood predictions or when a large number of predictions are needed for probabilistic flood design. Computationally efficient surrogate models have been developed to address this issue. The recently developed Low-fidelity, Spatial analysis, and Gaussian Process Learning (LSG) model has shown strong performance in both computational efficiency and simulation accuracy. The LSG model is a physics-guided surrogate model that simulates flood inundation by first using an extremely coarse and simplified (i.e. low-fidelity) hydrodynamic model to provide an initial estimate of flood inundation. Then, the low-fidelity estimate is upskilled via Empirical Orthogonal Functions (EOF) analysis and Sparse Gaussian Process models to provide accurate high-resolution predictions. Despite the promising results achieved thus far, the LSG model has not been benchmarked against other surrogate models. Such a comparison is needed to fully understand the value of the LSG model and to provide guidance for future research efforts in flood inundation simulation. This study compares the LSG model to four state-of-the-art surrogate flood inundation models. The surrogate models are assessed for their ability to simulate the temporal and spatial evolution of flood inundation for events both within and beyond the range used for model training. The models are evaluated for three distinct case studies in Australia and the United Kingdom. The LSG model is found to be superior in accuracy for both flood extent and water depth, including when applied to flood events outside the range of training data used, while achieving high computational efficiency. In addition, the low-fidelity model is found to play a crucial role in achieving the overall superior performance of the LSG model.","<method>Gaussian Process Learning</method>, <method>Empirical Orthogonal Functions (EOF) analysis</method>, <method>Sparse Gaussian Process models</method>",<method>Gaussian Process Learning</method><method>Sparse Gaussian Process models</method>
2024,https://openalex.org/W4391592188,Engineering,Prompt Engineering or Fine-Tuning? A Case Study on Phishing Detection with Large Language Models,"Large Language Models (LLMs) are reshaping the landscape of Machine Learning (ML) application development. The emergence of versatile LLMs capable of undertaking a wide array of tasks has reduced the necessity for intensive human involvement in training and maintaining ML models. Despite these advancements, a pivotal question emerges: can these generalized models negate the need for task-specific models? This study addresses this question by comparing the effectiveness of LLMs in detecting phishing URLs when utilized with prompt-engineering techniques versus when fine-tuned. Notably, we explore multiple prompt-engineering strategies for phishing URL detection and apply them to two chat models, GPT-3.5-turbo and Claude 2. In this context, the maximum result achieved was an F1-score of 92.74% by using a test set of 1000 samples. Following this, we fine-tune a range of base LLMs, including GPT-2, Bloom, Baby LLaMA, and DistilGPT-2—all primarily developed for text generation—exclusively for phishing URL detection. The fine-tuning approach culminated in a peak performance, achieving an F1-score of 97.29% and an AUC of 99.56% on the same test set, thereby outperforming existing state-of-the-art methods. These results highlight that while LLMs harnessed through prompt engineering can expedite application development processes, achieving a decent performance, they are not as effective as dedicated, task-specific LLMs.","<method>prompt-engineering techniques</method>, <method>fine-tuning</method>",<method>fine-tuning</method>
2024,https://openalex.org/W4391708456,Engineering,Delineation of groundwater potential zonation using geoinformatics and AHP techniques with remote sensing data,"Among all other valuable natural resources, groundwater is crucial for global economic growth and food security. This study aimed to delineate groundwater potential zones (GWPZ) in the Gidabo watershed of the Main Ethiopian Rift. The demand for groundwater supplies for various applications has risen recently in the watershed due to rapid population upsurge. An integrated Geographical Information System, Remote Sensing, and Analytical Hierarchy Process (AHP) has been utilized. Eight groundwater regulating factors, including rainfall, elevation, drainage density, soil types, lineament density, slope, lithology, and land use/land cover, have been taken in the analysis. To assign suitable weights to each factor, AHP was employed, as each element contributes differently to groundwater occurrence. The weighted overlay analysis (WOA) technique was then used in the ArcGIS environment to integrate all thematic layers and generate a GWPZ map. The delineated GWPZ in the watershed was classified into five categories. The poor GWPZ covered 18.7 %, the low GWPZ covered 33.8 %, the moderate GWPZ covered 23.4 %, the high GWPZ covered 18.1 %, and the very high GWPZ covered 5.8 % of the area. Well and spring data were used to validate the model, and the ROC (Receiver Operating Characteristic) curve method was applied. The results showed good accuracy of 76.8 %. The result of this research can be valuable for planning and managing groundwater resources in the Gidabo watershed.","<method>Analytical Hierarchy Process (AHP)</method>, <method>Receiver Operating Characteristic (ROC) curve method</method>",No methods remaining
2024,https://openalex.org/W4391720077,Engineering,Artificial intelligence-based evaluation of the factors affecting the sales of an iron and steel company,"It is important to predict the sales of an iron and steel company and to identify the variables that influence these sales for future planning. The aim in this study was to identify and model the key factors that influence the sales volume of an iron and steel company using artificial neural networks (ANNs). We attempted to obtain an integrated result from the performance/sales levels of 5 models, to use the ANN approach with hybrid algorithms, and also to present an exemplary application in the base metals industry, where there is a limited number of studies. This study contributes to the literature as the first application of artificial intelligence methods in the iron and steel industry. The ANN models incorporated 6 macroeconomic variables and price-to-sales data and their results were evaluated. An ordinary least squares regression model was also used to facilitate the comparison of results, while gray relational analysis (GRA) was used to draw a comprehensive conclusion based on the ANN results. The results showed that the variables USD/TL exchange rate, product prices, and interest rates, in descending order, had the highest degree of influence in determining the sales of the iron and steel company. Furthermore, these variables are crucial for forecasting future sales and strategic planning. The study showed that the ANN outperformed classical regression models in terms of prediction accuracy. In the model applications conducted for 5 different product groups, it was observed that 3 models (models 2, 3, and 4), including model 4, which sold a higher volume of products than the total of the other products, had an overall performance above 80%. In addition, GRA was found to be a valuable tool for synthesizing insights from different ANN models based on their respective performance levels.","<method>artificial neural networks (ANNs)</method>, <method>ordinary least squares regression model</method>, <method>gray relational analysis (GRA)</method>",<method>artificial neural networks (ANNs)</method><method>ordinary least squares regression model</method>
2024,https://openalex.org/W4391997375,Engineering,A machine learning approach to predict the efficiency of corrosion inhibition by natural product-based organic inhibitors,"Abstract This paper presents a quantitative structure–property relationship (QSPR)-based machine learning (ML) framework designed for predicting corrosion inhibition efficiency (CIE) values in natural organic inhibitor compounds. The modeling dataset comprises 50 natural organic compounds, with 11 quantum chemical properties (QCP) serving as input features, and the target variable being the corrosion inhibition efficiency (CIE) value. To enhance the predictive accuracy of the ML model, the kernel density estimation (KDE) function is employed to generate virtual samples during the training process, with the overarching goal of refining the precision of the ML model. Three distinct models, namely random forest (RF), gradient boosting (GB), and k-nearest neighbor (KNN), are tested in the study. The results demonstrate a noteworthy enhancement in the prediction performance of the models, attributable to the incorporation of virtual samples that effectively improve the correlation between input features and target values. Consequently, the accuracy of the predicted CIE values is significantly augmented, aligning more closely with the actual CIE values. Performance improvements were evident across all models after the incorporation of virtual samples. The GB, RF, and KNN models exhibited increments in R 2 values from 0.557 to 0.996, 0.522 to 0.999, and 0.415 to 0.994, respectively, concomitant with the introduction of 500 virtual samples. Additionally, each model demonstrated a notable reduction in RMSE values, transitioning from 1.41 to 0.19, 1.27 to 0.10, and 1.22 to 0.16, respectively. While the GB model initially outperformed others before the addition of virtual samples, the performance of the model exhibited fluctuation as the number of virtual samples varied. This behavior suggests that the KDE function provides a certain level of resilience against model variations. The proposed approach contributes to the effective design and exploration of corrosion inhibitor candidates, offering a reliable and accurate predictive tool that bridges the gap between theoretical studies and experimental synthesis.","<method>random forest (RF)</method>, <method>gradient boosting (GB)</method>, <method>k-nearest neighbor (KNN)</method>",<method>random forest (RF)</method><method>gradient boosting (GB)</method><method>k-nearest neighbor (KNN)</method>
2024,https://openalex.org/W4392356648,Engineering,Cost-sensitive learning for imbalanced medical data: a review,"Abstract Integrating Machine Learning (ML) in medicine has unlocked many opportunities to harness complex medical data, enhancing patient outcomes and advancing the field. However, the inherent imbalanced distribution of medical data poses a significant challenge, resulting in biased ML models that perform poorly on minority classes. Mitigating the impact of class imbalance has prompted researchers to explore various strategies, wherein Cost-Sensitive Learning (CSL) arises as a promising approach to improve the accuracy and reliability of ML models. This paper presents the first review of CSL for imbalanced medical data. A comprehensive exploration of the existing literature encompassed papers published from January 2010 to December 2022 and sourced from five major digital libraries. A total of 173 papers were selected, analysed, and classified based on key criteria, including publication years, channels and sources, research types, empirical types, medical sub-fields, medical tasks, CSL approaches, strengths and weaknesses of CSL, frequently used datasets and data types, evaluation metrics, and development tools. The results indicate a noteworthy publication rise, particularly since 2020, and a strong preference for CSL direct approaches. Data type analysis unveiled diverse modalities, with medical images prevailing. The underutilisation of cost-related metrics and the prevalence of Python as the primary programming tool are highlighted. The strengths and weaknesses analysis covered three aspects: CSL strategy, CSL approaches, and relevant works. This study serves as a valuable resource for researchers seeking to explore the current state of research, identify strengths and gaps in the existing literature and advance CSL’s application for imbalanced medical data.","<method>Machine Learning (ML)</method>, <method>Cost-Sensitive Learning (CSL)</method>",<method>Machine Learning (ML)</method><method>Cost-Sensitive Learning (CSL)</method>
2024,https://openalex.org/W4394598286,Engineering,Performance analysis and optimization of thermal barrier coated piston diesel engine fuelled with biodiesel using RSM,"The current research investigates diesel and simarouba biodiesel blends (10%, 20%, & 30% by volume) in conventional and Low Heat Rejection (LHR) diesel engines, each rated at 4.4 kW. While optimization techniques like Response Surface Method and Taguchi have been extensively studied, the impact of LHR and optimization on LHR engine performance and emissions is rarely explored. Converting the conventional engine to LHR involved applying 300 μm of stabilized zirconia to the piston crown to enhance combustion efficiency. Performance and emissions were analyzed at rated injection pressure (200 bar) and timing (23° before top dead center - btdc). Experiments were continued on LHR engine by varying injection timings (advancing - 26°btdc and retarding - 20°btdc). Advanced injection timing showed significant improvement in performance of Low heat rejection engine. MINITAB statistical tool is used to optimize engine performance using Response Surface Method. The 20% blend showed improved performance in both engines. The optimum values for Low heat rejection engine responses are 26.8%, 0.32 kg/kW-h, 0.018%, 59.59 ppm, and 1419.03 ppm for brake thermal efficiency, brake specific fuel consumption, carbon monoxide, and unburnt hydrocarbons, respectively. Confirmation experiments aligned well with model predictions, indicating the potential of LHR engines to enhance thermal efficiency and reduce emissions.","<method>Response Surface Method</method>, <method>Taguchi</method>",No methods remaining
2024,https://openalex.org/W4401593044,Engineering,Overcoming the Limits of Cross-Sensitivity: Pattern Recognition Methods for Chemiresistive Gas Sensor Array,"Abstract As information acquisition terminals for artificial olfaction, chemiresistive gas sensors are often troubled by their cross-sensitivity, and reducing their cross-response to ambient gases has always been a difficult and important point in the gas sensing area. Pattern recognition based on sensor array is the most conspicuous way to overcome the cross-sensitivity of gas sensors. It is crucial to choose an appropriate pattern recognition method for enhancing data analysis, reducing errors and improving system reliability, obtaining better classification or gas concentration prediction results. In this review, we analyze the sensing mechanism of cross-sensitivity for chemiresistive gas sensors. We further examine the types, working principles, characteristics, and applicable gas detection range of pattern recognition algorithms utilized in gas-sensing arrays. Additionally, we report, summarize, and evaluate the outstanding and novel advancements in pattern recognition methods for gas identification. At the same time, this work showcases the recent advancements in utilizing these methods for gas identification, particularly within three crucial domains: ensuring food safety, monitoring the environment, and aiding in medical diagnosis. In conclusion, this study anticipates future research prospects by considering the existing landscape and challenges. It is hoped that this work will make a positive contribution towards mitigating cross-sensitivity in gas-sensitive devices and offer valuable insights for algorithm selection in gas recognition applications.",<method>pattern recognition</method>,No methods remaining
2024,https://openalex.org/W4390483800,Engineering,Comprehensive Risk Analysis and Decision-Making Model for Hydroelectricity Energy Investments,"The risks of hydroelectricity energy investments should be managed effectively to increase the performance of these projects. Thus, more significant risks should be identified to take effective measures for risk management without experiencing high costs. Accordingly, the purpose of this study is to define critical risks in hydroelectricity energy investment projects by making a priority analysis. Within this scope, a new decision-making model is created. In the first stage, five different risks are examined by considering Spherical fuzzy Entropy. Moreover, the second stage consists of ranking emerging seven countries with the help of Spherical fuzzy multi-attribute ideal-real comparative assessment (MAIRCA). The main contribution of this study is that more important risks of hydroelectricity energy investments can be identified by the help of the priority analysis. This situation provides an opportunity to implement effective strategies to increase these investments without having high costs. Additionally, considering Spherical fuzzy sets has a positive impact on the appropriateness of the results. Since these numbers use a wider data range, the effectiveness of the analysis results can increase. It is determined that the most important risk is environmental risk with the highest weight value of 0.2478. Financial risks and personnel risks are other significant factors that affect the performance of the hydroelectricity energy investments. Furthermore, as a result of ranking the alternatives, it is seen that China is the most suitable country for hydroelectric energy investments. India and Mexico are other successful countries in this respect. However, Turkey and Indonesia have lower performance for this situation.","<method>Spherical fuzzy Entropy</method>, <method>Spherical fuzzy multi-attribute ideal-real comparative assessment (MAIRCA)</method>",No methods remaining
2024,https://openalex.org/W4390501772,Engineering,Remote sensing based forest cover classification using machine learning,"Abstract Pakistan falls significantly below the recommended forest coverage level of 20 to 30 percent of total area, with less than 6 percent of its land under forest cover. This deficiency is primarily attributed to illicit deforestation for wood and charcoal, coupled with a failure to embrace advanced techniques for forest estimation, monitoring, and supervision. Remote sensing techniques leveraging Sentinel-2 satellite images were employed. Both single-layer stacked images and temporal layer stacked images from various dates were utilized for forest classification. The application of an artificial neural network (ANN) supervised classification algorithm yielded notable results. Using a single-layer stacked image from Sentinel-2, an impressive 91.37% training overall accuracy and 0.865 kappa coefficient were achieved, along with 93.77% testing overall accuracy and a 0.902 kappa coefficient. Furthermore, the temporal layer stacked image approach demonstrated even better results. This method yielded 98.07% overall training accuracy, 97.75% overall testing accuracy, and kappa coefficients of 0.970 and 0.965, respectively. The random forest (RF) algorithm, when applied, achieved 99.12% overall training accuracy, 92.90% testing accuracy, and kappa coefficients of 0.986 and 0.882. Notably, with the temporal layer stacked image of the Sentinel-2 satellite, the RF algorithm reached exceptional performance with 99.79% training accuracy, 96.98% validation accuracy, and kappa coefficients of 0.996 and 0.954. In terms of forest cover estimation, the ANN algorithm identified 31.07% total forest coverage in the District Abbottabad region. In comparison, the RF algorithm recorded a slightly higher 31.17% of the total forested area. This research highlights the potential of advanced remote sensing techniques and machine learning algorithms in improving forest cover assessment and monitoring strategies.","<method>artificial neural network (ANN) supervised classification algorithm</method>, <method>random forest (RF) algorithm</method>",<method>artificial neural network (ANN) supervised classification algorithm</method><method>random forest (RF) algorithm</method>
2024,https://openalex.org/W4392714183,Engineering,Explainability and Interpretability in Electric Load Forecasting Using Machine Learning Techniques – A Review,"Electric Load Forecasting (ELF) is the central instrument for planning and controlling demand response programs, electricity trading, and consumption optimization. Due to the increasing automation of these processes, meaningful and transparent forecasts become more and more important. Still, at the same time, the complexity of the used machine learning models and architectures increases. Because there is an increasing interest in interpretable and explainable load forecasting methods, this work conducts a literature review to present already applied approaches regarding explainability and interpretability for load forecasts using Machine Learning. Based on extensive literature research covering eight publication portals, recurring modeling approaches, trends, and modeling techniques are identified and clustered by properties to achieve more interpretable and explainable load forecasts. The results on interpretability show an increase in the use of probabilistic models, methods for time series decomposition and the use of fuzzy logic in addition to classically interpretable models. Dominant explainable approaches are Feature Importance and Attention mechanisms. The discussion shows that a lot of knowledge from the related field of time series forecasting still needs to be adapted to the problems in ELF. Compared to other applications of explainable and interpretable methods such as clustering, there are currently relatively few research results, but with an increasing trend.","<method>probabilistic models</method>, <method>time series decomposition</method>, <method>fuzzy logic</method>, <method>Feature Importance</method>, <method>Attention mechanisms</method>",<method>probabilistic models</method><method>Attention mechanisms</method>
2024,https://openalex.org/W4392830014,Engineering,A Deep Learning-Based CAE Approach for Simulating 3D Vehicle Wheels Under Real-World Conditions,"The implementation of deep learning (DL) in computer-aided engineering (CAE) can significantly improve the accuracy and efficiency of simulating 3D vehicle wheels under real-world conditions. While traditional CAE methods can be time-consuming and computationally expensive, DL can reduce simulation time and development cycles across all industries. This work explores the role of DL and AI in virtual manufacturing and CAE and investigates how they can be used to improve the accuracy and efficiency of simulations for 3D vehicle wheels. Deep learning models can learn the complex relationships between different wheel design parameters, such as tire load distribution, stress distribution, and fatigue life. Once trained, these models can be embedded into CAE software, allowing for faster and more accurate simulations of wheel performance. This interdisciplinary study uses various deep learning techniques, including convolutional neural networks (CNNs), generative adversarial networks (GANs), and recurrent neural networks (RNNs), to create a more efficient and accurate relationship between CAD modeling and CAE simulation. The research aims to leverage the potential of deep learning models to automate 3D CAD design, accurately predict CAE results, and provide in-depth explanations and verifications. The benefits of this research are expected to extend to the automotive industry's pursuit of more robust and resilient wheel designs. By streamlining the product development process from conceptual design to engineering performance evaluation, this study has the potential to revolutionize the automotive industry's product development cycle.","<method>deep learning (DL)</method>, <method>convolutional neural networks (CNNs)</method>, <method>generative adversarial networks (GANs)</method>, <method>recurrent neural networks (RNNs)</method>",<method>deep learning (DL)</method><method>convolutional neural networks (CNNs)</method><method>generative adversarial networks (GANs)</method><method>recurrent neural networks (RNNs)</method>
2024,https://openalex.org/W4393055891,Engineering,A new intelligently optimized model reference adaptive controller using GA and WOA-based MPPT techniques for photovoltaic systems,"Recently, the integration of renewable energy sources, specifically photovoltaic (PV) systems, into power networks has grown in significance for sustainable energy generation. Researchers have investigated different control algorithms for maximum power point tracking (MPPT) to enhance the efficiency of PV systems. This article presents an innovative method to address the problem of maximum power point tracking in photovoltaic systems amidst swiftly changing weather conditions. MPPT techniques supply maximum power to the load during irradiance fluctuations and ambient temperatures. A novel optimal model reference adaptive controller is developed and designed based on the MIT rule to seek global maximum power without ripples rapidly. The suggested controller is also optimized through two popular meta-heuristic algorithms: The genetic algorithm (GA) and the whale optimization algorithm (WOA). These meta-heuristic approaches have been exploited to overcome the difficulty of selecting the adaptation gain of the MRAC controller. The reference voltage for MPPT is generated in the study through an adaptive neuro-fuzzy inference system. The suggested controller's performance is tested via MATLAB/Simulink software under varying temperature and radiation circumstances. Simulation is carried out using a Soltech 1sth-215-p module coupled to a boost converter, which powers a resistive load. Furthermore, to emphasize the recommended algorithm's performance, a comparative study was done between the optimal MRAC using GA and WOA and the conventional incremental conductance (INC) method.","<method>genetic algorithm (GA)</method>, <method>whale optimization algorithm (WOA)</method>, <method>adaptive neuro-fuzzy inference system</method>",<method>genetic algorithm (GA)</method><method>whale optimization algorithm (WOA)</method><method>adaptive neuro-fuzzy inference system</method>
2024,https://openalex.org/W4393339929,Engineering,Optimizing landslide susceptibility mapping using machine learning and geospatial techniques,"Landslides present a substantial risk to human lives, the environment, and infrastructure. Consequently, it is crucial to highlight the regions prone to future landslides by examining the correlation between past landslides and various geo-environmental factors. This study aims to investigate the optimal data selection and machine learning model, or ensemble technique, for evaluating the vulnerability of areas to landslides and determining the most accurate approach. To attain our objectives, we considered two different scenarios for selecting landslide-free random points (a slope threshold and a buffer-based approach) and performed a comparative analysis of five machine learning models for landslide susceptibility mapping, namely: Support Vector Machine (SVM), Logistic Regression (LR), Linear Discriminant Analysis (LDA), Random Forest (RF), and Extreme Gradient Boosting (XGBoost). The study area for this research is an area in Polk County in Western North Carolina that has experienced fatal landslides, leading to casualties and significant damage to infrastructure, properties, and road networks. The model construction process involves the utilization of a dataset comprising 1215 historical landslide occurrences and 1215 non-landslide points. We integrated a total of fourteen geospatial data layers, consisting of topographic variables, soil data, geological data, and land cover attributes. We use various metrics to assess the models' performance, including accuracy, F1-score, Kappa score, and AUC-ROC. In addition, we used the seeded-cell area index (SCAI) to evaluate map consistency. The ensemble of the five models using Weighted Average produces outstanding results, with an AUC-ROC of 99.4% for the slope threshold scenario and 91.8% for the buffer-based scenario. Our findings emphasize the significant impact of non-landslide random sampling on model performance in landslide susceptibility mapping. Furthermore, by optimally identifying landslide-prone regions and hotspots that need urgent risk management and land use planning, our study demonstrates the effectiveness of machine learning models in analyzing landslide susceptibility and providing valuable insights for informed decision-making and disaster risk reduction initiatives.","<method>Support Vector Machine (SVM)</method>, <method>Logistic Regression (LR)</method>, <method>Linear Discriminant Analysis (LDA)</method>, <method>Random Forest (RF)</method>, <method>Extreme Gradient Boosting (XGBoost)</method>, <method>ensemble technique using Weighted Average</method>",<method>Support Vector Machine (SVM)</method><method>Logistic Regression (LR)</method><method>Linear Discriminant Analysis (LDA)</method><method>Random Forest (RF)</method><method>Extreme Gradient Boosting (XGBoost)</method><method>ensemble technique using Weighted Average</method>
2024,https://openalex.org/W4399144385,Engineering,Assessment of technical water quality in mining based on machine learning methods,"Introduction. Mining requires water treatment and wastewater processing, abstraction and discharge during mining increases consumption several times. Since water consumption in mining and processing is usually associated with domestic, industrial and technical needs, the need for water supply systems required for water treatment increases. Water from different sources can be used for treatment: incoming water, process and reused water, and wastewater. But the water obtained from any of the sources must meet all the norms and requirements. Water quality is determined by physical, chemical and bacteriological properties. The main directions for improving water consumption by mining enterprises are to reduce the consumption of drinking water from rivers, lakes and municipal water supply, as well as to expand the use of mine and quarry water for domestic and technical needs. Materials and methods. As training data for training the neural network, a dataset that includes water quality data obtained from fresh water sources was selected for the methods work, and using machine learning, develops a model that predicts whether the water is suitable for technical use in mines. This dataset includes 2293 values (samples) as well as 9 attributes. Correlation, neural network, and decision tree methods were used to build the models in this study. Results. Various machine learning methods (neural network and decision trees) were used to build a predictive model to assess the quality of water that would be suitable for use in the mining industry for technical purposes. With the help of the built models were processed data obtained from public sources, when analyzing which it was found that the method of decision trees was more accurate. The constructed model, for determining dependencies, thus, has high accuracy (small error). To increase the practical significance of the study, a number of transformations of the initial data set were carried out, in particular, an experiment with the division of attributes into groups of importance, in relation to the data, taking into account the subject area. The results obtained made it clear that checking only for hazardous impurities does not guarantee the suitability of water, but almost completely excludes (low significance factor) samples with impurities that do not meet the requirements, and the model can have practical significance. Allocation of the group for rapid quality determination, showed that for the express test, in an emergency situation or under time constraints, the possibility of practical use of the obtained model, has a justification, due to the small error. In general, the conducted experiments have shown that when taking into account the costs (total) for data collection, it makes sense to use models, taking into account the reduction of collected data, on the parameters (factors) of technical water. Discussion. In general, on the basis of the conducted research, we can talk about the successful application of machine learning methods in determining the suitability of technical water in the mining industry. During the experiments, the decision tree method performed particularly well, with the lowest error values. In addition, further work can be carried out to reduce the error in the models, in particular, by possibly increasing the number of attributes, as well as more fine-tuning of the applied machine learning methods. Conclusions. The authors conclude that machine learning techniques can be successfully integrated to determine the quality and suitability of process water in the mining industry in today’s world. Resume. The paper compares machine learning methods such as decision trees and neural network method. The comparative analysis of these methods and their quality of information processing is shown on the example of a set of data on water quality in the mining industry. With the help of built models were processed data obtained from open sources, when analyzing which it was found that the method of decision trees was more accurate. The constructed model for determining dependencies has high accuracy (small error). Suggestions for practical applications and future research directions. This study can form the basis for research in this or related fields to conduct further studies on the reliability and accuracy of using machine learning to predict the quality of water used in the mining industry. Continued work in the above direction may be the rationale for wider use of the above methods to improve various meaningful production performance in this or related areas.","<method>neural network</method>, <method>decision tree</method>",<method>neural network</method><method>decision tree</method>
2024,https://openalex.org/W4401386421,Engineering,Machine learning prediction of mechanical properties in metal additive manufacturing,"Predicting mechanical properties in metal additive manufacturing (MAM) is essential for ensuring the performance and reliability of printed parts, as well as their suitability for specific applications. However, conducting experiments to estimate mechanical properties in MAM processes can be laborious and expensive, and they are often limited to specific materials and processes. Machine learning (ML) methods offer a more flexible and cost-effective approach to predicting mechanical properties based on processing parameters and material properties. In this study, we introduce a comprehensive framework for benchmarking ML models for predicting mechanical properties. We compiled an extensive experimental dataset from over 90 MAM articles and data sheets from a diverse range of sources, encompassing 140 different MAM data sheets. This dataset includes information on MAM processing conditions, machines, materials, and resulting mechanical properties such as yield strength, ultimate tensile strength, elastic modulus, elongation, hardness, and surface roughness. Our framework incorporates physics-aware featurization specific to MAM, adjustable ML models, and tailored evaluation metrics to construct a comprehensive learning framework for predicting mechanical properties. Additionally, we explore the Explainable AI method, specifically SHAP analysis, to elucidate and interpret the predicted values of ML models for mechanical properties. Furthermore, data-driven explicit models were developed to estimate mechanical properties based on processing parameters and material properties, offering enhanced interpretability compared to conventional ML models.","<method>Machine learning (ML) methods</method>, <method>Explainable AI method</method>, <method>SHAP analysis</method>, <method>data-driven explicit models</method>",<method>SHAP analysis</method>
2024,https://openalex.org/W4390748349,Engineering,Charging management of electric vehicles with the presence of renewable resources,"Considering the increasing use of electric vehicles, the establishment of charging stations to exchange power between the grid and electric devices, and the integration of charging stations with solar power generation sources, the optimal use of electric vehicle charging stations in the power system. The purpose of cost reduction in the presence of the intelligent environment is a challenge that must be investigated so that this platform is suitable for predicting the behaviour of vehicles and, as a result, optimizing their presence in the power network. This research presents a relatively complete radial distribution network development planning model in two scenarios. In the first scenario, the effects of electric vehicles are not considered, and only the effects of distributed production (renewable and dispatchable) are considered. Studies have been done on a sample 54-bus network, a common system in most Distribution expansion planning (DEP) articles for distribution networks. In addition, the real data of American highways have been used to create raw input data. Also, due to the distance limit, the information on vehicles under 100 miles has been received as electric vehicle information. The clustering method and Capiola multivariate probability distribution functions have created suitable vehicle scenarios during different planning years. Capiola's method increases the accuracy of vehicle load forecasting according to a predetermined growth rate. The DEP problem in this research is modeled as an optimization problem based on scenario, dynamic, and in 5 one-year time frames (5-year time horizon and one-year accuracy). The results indicate that, in the presence of electric vehicles and distributed production sources, the technical characteristics of the network are improved. Similarly, the use of DGs, in addition to reducing the cost of equipment, has reduced undistributed energy in the system. But 10,000 vehicles, which have been applied to the network as an uncontrolled load, have caused an increase in undistributed energy. The cost of equipment required for the network development is almost as much as 5%.","<method>clustering method</method>, <method>Capiola multivariate probability distribution functions</method>, <method>Capiola's method</method>",<method>clustering method</method>
2024,https://openalex.org/W4391612257,Engineering,Machine learning for the management of biochar yield and properties of biomass sources for sustainable energy,"Abstract Biochar is emerging as a potential solution for biomass conversion to meet the ever increasing demand for sustainable energy. Efficient management systems are needed in order to exploit fully the potential of biochar. Modern machine learning (ML) techniques, and in particular ensemble approaches and explainable AI methods, are valuable for forecasting the properties and efficiency of biochar properly. Machine‐learning‐based forecasts, optimization, and feature selection are critical for improving biomass management techniques. In this research, we explore the influences of these techniques on the accurate forecasting of biochar yield and properties for a range of biomass sources. We emphasize the importance of the interpretability of a model, as this improves human comprehension and trust in ML predictions. Sensitivity analysis is shown to be an effective technique for finding crucial biomass characteristics that influence the synthesis of biochar. Precision prognostics have far‐reaching ramifications, influencing industries such as biomass logistics, conversion technologies, and the successful use of biomass as renewable energy. These advances can make a substantial contribution to a greener future and can encourage the development of a circular biobased economy. This work emphasizes the importance of using sophisticated data‐driven methodologies such as ML in biochar synthesis, to usher in ecologically friendly energy solutions. These breakthroughs hold the key to a more sustainable and environmentally friendly future.","<method>ensemble approaches</method>, <method>explainable AI methods</method>, <method>machine-learning-based forecasts</method>, <method>optimization</method>, <method>feature selection</method>, <method>sensitivity analysis</method>",<method>ensemble approaches</method><method>feature selection</method>
2024,https://openalex.org/W4391878291,Engineering,Effective lung nodule detection using deep CNN with dual attention mechanisms,"Abstract Novel methods are required to enhance lung cancer detection, which has overtaken other cancer-related causes of death as the major cause of cancer-related mortality. Radiologists have long-standing methods for locating lung nodules in patients with lung cancer, such as computed tomography (CT) scans. Radiologists must manually review a significant amount of CT scan pictures, which makes the process time-consuming and prone to human error. Computer-aided diagnosis (CAD) systems have been created to help radiologists with their evaluations in order to overcome these difficulties. These systems make use of cutting-edge deep learning architectures. These CAD systems are designed to improve lung nodule diagnosis efficiency and accuracy. In this study, a bespoke convolutional neural network (CNN) with a dual attention mechanism was created, which was especially crafted to concentrate on the most important elements in images of lung nodules. The CNN model extracts informative features from the images, while the attention module incorporates both channel attention and spatial attention mechanisms to selectively highlight significant features. After the attention module, global average pooling is applied to summarize the spatial information. To evaluate the performance of the proposed model, extensive experiments were conducted using benchmark dataset of lung nodules. The results of these experiments demonstrated that our model surpasses recent models and achieves state-of-the-art accuracy in lung nodule detection and classification tasks.","<method>convolutional neural network (CNN)</method>, <method>dual attention mechanism</method>, <method>channel attention</method>, <method>spatial attention</method>, <method>global average pooling</method>",<method>convolutional neural network (CNN)</method><method>dual attention mechanism</method><method>channel attention</method><method>spatial attention</method><method>global average pooling</method>
2024,https://openalex.org/W4391097018,Engineering,Optimal energy management strategies for hybrid electric vehicles: A recent survey of machine learning approaches,"Hybrid Electric Vehicles (HEVs) have emerged as a viable option for reducing pollution and attaining fuel savings in addition to reducing emissions. The effectiveness of HEVs heavily relies on the energy management strategies (EMSs) employed, as it directly impacts vehicle fuel consumption. Developing suitable EMSs for HEVs poses a challenge, as the goal is to maximize fuel economy yet optimize vehicle performance. EMSs algorithms are critical in determining power distribution between the engine and motor in HEVs. Traditionally, EMSs for HEVs have been developed based on optimal control theory. However, in recent years, a rising number of people have been interested in utilizing machine-learning techniques to enhance EMSs performance. This article presents a current analysis of various EMSs proposed in the literature. It highlights the shift towards integrating machine learning and artificial intelligence (AI) breakthroughs in EMSs development. The study examines numerous case studies, and research works employing machine learning techniques across different categories to develop energy management strategies for HEVs. By leveraging advancements in machine learning and AI, researchers have explored innovative approaches to optimize HEVs' performance and fuel economy. Key conclusions from our investigation show that machine learning has made a substantial contribution to solving the complex problems associated with HEV energy management. We emphasize how machine learning algorithms may be adjusted to dynamic operating environments, how well they can identify intricate patterns in hybrid electric vehicle systems, and how well they can manage non-linear behaviors.","<method>optimal control theory</method>, <method>machine learning techniques</method>, <method>machine learning algorithms</method>",No methods remaining
2024,https://openalex.org/W4392157869,Engineering,Transfer learning with graph neural networks for improved molecular property prediction in the multi-fidelity setting,"Abstract We investigate the potential of graph neural networks for transfer learning and improving molecular property prediction on sparse and expensive to acquire high-fidelity data by leveraging low-fidelity measurements as an inexpensive proxy for a targeted property of interest. This problem arises in discovery processes that rely on screening funnels for trading off the overall costs against throughput and accuracy. Typically, individual stages in these processes are loosely connected and each one generates data at different scale and fidelity. We consider this setup holistically and demonstrate empirically that existing transfer learning techniques for graph neural networks are generally unable to harness the information from multi-fidelity cascades. Here, we propose several effective transfer learning strategies and study them in transductive and inductive settings. Our analysis involves a collection of more than 28 million unique experimental protein-ligand interactions across 37 targets from drug discovery by high-throughput screening and 12 quantum properties from the dataset QMugs. The results indicate that transfer learning can improve the performance on sparse tasks by up to eight times while using an order of magnitude less high-fidelity training data. Moreover, the proposed methods consistently outperform existing transfer learning strategies for graph-structured data on drug discovery and quantum mechanics datasets.","<method>graph neural networks</method>, <method>transfer learning</method>, <method>transfer learning strategies</method>",<method>graph neural networks</method><method>transfer learning</method><method>transfer learning strategies</method>
2024,https://openalex.org/W4396686667,Engineering,Optimal design of steel exoskeleton for the retrofitting of RC buildings via genetic algorithm,"In recent decades, steel exoskeletons have gathered significant attention as a seismic retrofitting technique for existing structures. The design methods proposed so far are focused on the identification of the system's overall parameters through simplified models. Although these methodologies provide helpful guidance at the preliminary design stage, they do not consider aspects such as the distribution of the exoskeletons and sizing of their components. To overcome these limitations, an optimization process based on the Genetic Algorithm is proposed in this paper to identify the optimal exoskeleton number and spatial arrangement, and to determine the optimal size of their constituent elements. The algorithm aims to minimize the weight of the retrofit solution while keeping the whole existing structure in the elastic field and ensuring the structural verification of the exoskeleton's elements. The analyses have been conducted using a finite-element code with an Open Application Programming Interface, which allows the models to be handled through automatic routines. The proposed optimization tool has been applied to several case studies, considering two different layouts for the exoskeletons. Finally, the effectiveness of the retrofit method has been demonstrated, and the proposed optimization tool has been able to significantly reduce the weight and cost of the intervention.",<method>Genetic Algorithm</method>,<method>Genetic Algorithm</method>
2024,https://openalex.org/W4398787803,Engineering,Transformer-based Generative Adversarial Networks in Computer Vision: A Comprehensive Survey,"Generative Adversarial Networks (GANs) have been very successful for synthesizing the images in a given dataset. The artificially generated images by GANs are very realistic. The GANs have shown potential usability in several computer vision applications, including image generation, image-to-image translation, video synthesis, etc. Conventionally, the generator network is the backbone of GANs, which generates the samples and the discriminator network is used to facilitate the training of the generator network. The generator and discriminator networks are usually a Convolutional Neural Network (CNN). The convolution-based networks exploit the local relationship in a layer, which requires the deep networks to extract the abstract features. However, recently developed Transformer networks are able to exploit the global relationship with tremendous performance improvement for several problems in computer vision. Motivated from the success of Transformer networks and GANs, recent works have tried to exploit the Transformers in GAN framework for the image/video synthesis. This paper presents a comprehensive survey on the developments and advancements in GANs utilizing the Transformer networks for computer vision applications. The performance comparison for several applications on benchmark datasets is also performed and analyzed. The conducted survey will be very useful to understand the research trends & gaps related with Transformer-based GANs and to develop the advanced GAN architectures by exploiting the global and local relationships for different applications.","<method>Generative Adversarial Networks (GANs)</method>, <method>Convolutional Neural Network (CNN)</method>, <method>Transformer networks</method>",<method>Generative Adversarial Networks (GANs)</method><method>Convolutional Neural Network (CNN)</method><method>Transformer networks</method>
2024,https://openalex.org/W4400110237,Engineering,A new integrated intelligent computing paradigm for predicting joints shear strength,"Joints shear strength is a critical parameter during the design and construction of geotechnical engineering structures. The prevailing models mostly adopt the form of empirical functions, employing mathematical regression techniques to represent experimental data. As an alternative approach, this paper proposes a new integrated intelligent computing paradigm that aims to predict joints shear strength. Five metaheuristic optimization algorithms, including the chameleon swarm algorithm (CSA), slime mold algorithm, transient search optimization algorithm, equilibrium optimizer and social network search algorithm, were employed to enhance the performance of the multilayered perception (MLP) model. Efficiency comparisons were conducted between the proposed CSA-MLP model and twelve classical models, employing statistical indicators such as root mean square error (RMSE), correlation coefficient (R2), mean absolute error (MAE), and variance accounted for (VAF) to evaluate the performance of each model. The sensitivity analysis of parameters that impact joints shear strength was conducted. Finally, the feasibility and limitations of this study were discussed. The results revealed that, in comparison to other models, the CSA-MLP model exhibited the most appropriate performance in terms of R2 (0.88), RMSE (0.19), MAE (0.15), and VAF (90.32%) values. The result of sensitivity analysis showed that the normal stress and the joint roughness coefficient were the most critical factors influencing joints shear strength. This paper presented an efficacious attempt toward swift prediction of joints shear strength, thus avoiding the need for costly in-site and laboratory tests.","<method>chameleon swarm algorithm (CSA)</method>, <method>slime mold algorithm</method>, <method>transient search optimization algorithm</method>, <method>equilibrium optimizer</method>, <method>social network search algorithm</method>, <method>multilayered perception (MLP) model</method>",<method>slime mold algorithm</method><method>equilibrium optimizer</method>
2024,https://openalex.org/W4400721646,Engineering,"A Comprehensive Review on the Role of Artificial Intelligence in Power System Stability, Control, and Protection: Insights and Future Directions","This review comprehensively examines the burgeoning field of intelligent techniques to enhance power systems’ stability, control, and protection. As global energy demands increase and renewable energy sources become more integrated, maintaining the stability and reliability of both conventional power systems and smart grids is crucial. Traditional methods are increasingly insufficient for handling today’s power grids’ complex, dynamic nature. This paper discusses the adoption of advanced intelligence methods, including artificial intelligence (AI), deep learning (DL), machine learning (ML), metaheuristic optimization algorithms, and other AI techniques such as fuzzy logic, reinforcement learning, and model predictive control to address these challenges. It underscores the critical importance of power system stability and the new challenges of integrating diverse energy sources. The paper reviews various intelligent methods used in power system analysis, emphasizing their roles in predictive maintenance, fault detection, real-time control, and monitoring. It details extensive research on the capabilities of AI and ML algorithms to enhance the precision and efficiency of protection systems, showing their effectiveness in accurately identifying and resolving faults. Additionally, it explores the potential of fuzzy logic in decision-making under uncertainty, reinforcement learning for dynamic stability control, and the integration of IoT and big data analytics for real-time system monitoring and optimization. Case studies from the literature are presented, offering valuable insights into practical applications. The review concludes by identifying current limitations and suggesting areas for future research, highlighting the need for more robust, flexible, and scalable intelligent systems in the power sector. This paper is a valuable resource for researchers, engineers, and policymakers, providing a detailed understanding of the current and future potential of intelligent techniques in power system stability, control, and protection.","<method>artificial intelligence (AI)</method>, <method>deep learning (DL)</method>, <method>machine learning (ML)</method>, <method>metaheuristic optimization algorithms</method>, <method>fuzzy logic</method>, <method>reinforcement learning</method>, <method>model predictive control</method>",<method>deep learning (DL)</method><method>machine learning (ML)</method><method>reinforcement learning</method>
2024,https://openalex.org/W4401289975,Engineering,Application of ANFIS approach for prediction of performance measures in wire electric discharge machining of SAE 1010,"Due to its exceptional quality, SAE 1010 is highly recommended for automotive applications, particularly in the manufacturing of headed fasteners and bolts. The primary application of this technology is in automobiles, while it also holds significant potential for various other technological disciplines. Utilizing alternative techniques for removing material has proven to be essential in overcoming numerous machining challenges that were previously difficult to solve. It possesses numerous practical applications in aircraft engineering and exhibits significant potential for implementation in other technical domains. Manufacturing complicated curved components using traditional machining methods might provide challenges. In order to prevent such issues, a wide range of cutting-edge machining methods have been developed. Wire Electrical Discharge Machining (WEDM) is a variance of Electrical Discharge Machining (EDM) that is suitable for this particular use. This study employs Taguchi's technique to examine the Wire Electrical Discharge Machining (WEDM) of SAE 1010 steel from an environmentally friendly viewpoint by employing a natural dielectric fluid in order to minimize its ecological footprint. This study aims to optimize the process variable and develop a hybrid predictive model based on grey approach for foretelling the necessary performance measures by considering various performance metrics, including material removal rate, surface roughness, and tolerance errors. The significance of process variables has been determined with the help of Analysis of variance (ANOVA) and it is inferred that pulse on duration is the most contributing factor for all the desired performance measures. A hybrid technique was used by an artificial intelligence technology to project the selected output measure. The outcomes on performance of the evolved ANFIS model shows the prediction capability of the model developed with least errors (MAPE – 0.0417, RMSE − 0.00023, MAE – 0.000419, Correlation coefficient 0.9997). The outcomes of the analysis indicate that the model is both efficient and accurate in its predictions, could be valuable to the manufacturer since it establishes targets for important performance indicators.","<method>Taguchi's technique</method>, <method>Analysis of variance (ANOVA)</method>, <method>hybrid predictive model based on grey approach</method>, <method>ANFIS model</method>",<method>hybrid predictive model based on grey approach</method><method>ANFIS model</method>
2024,https://openalex.org/W4390870882,Engineering,A domain adaptation approach to damage classification with an application to bridge monitoring,"Data-driven machine-learning algorithms generally suffer from a lack of labelled health-state data, mainly those referring to damage conditions. To address such an issue, population-based structural health monitoring seeks to enrich the original dataset by transferring knowledge from a population of monitored structures. Within this context, this paper presents a transfer learning approach, based on domain adaptation, to leverage information from completely-labelled bridge structure data to accurately predict new instances of an unknown target domain. Since intrinsic structural differences may cause distribution shifts, domain adaptation attempts to minimise the distance between the domains and to learn a mapping within a shared feature space. Specifically, the methodology involves the long-term acquisition of natural frequencies from several structural scenarios. Such damage-sensitive features are then aligned via domain adaptation so that a machine-learning algorithm can effectively utilise the labelled source domain data and generalise well to the unlabelled target-domain data. The described procedure is applied to two case studies, including the Z24 and the S101 benchmark bridges and their finite element models, respectively. The results demonstrate the successful exchange of health-state labels to identify the damage class within a population of bridges equipped with SHM systems, showing potential to reduce computational efforts and to deal with scarce or poor data sets in application to bridge network monitoring.","<method>transfer learning</method>, <method>domain adaptation</method>, <method>machine-learning algorithm</method>",<method>transfer learning</method><method>domain adaptation</method>
2024,https://openalex.org/W4391478629,Engineering,Enhancing photovoltaic parameter estimation: integration of non-linear hunting and reinforcement learning strategies with golden jackal optimizer,"Abstract The advancement of Photovoltaic (PV) systems hinges on the precise optimization of their parameters. Among the numerous optimization techniques, the effectiveness of each often rests on their inherent parameters. This research introduces a new methodology, the Reinforcement Learning-based Golden Jackal Optimizer (RL-GJO). This approach uniquely combines reinforcement learning with the Golden Jackal Optimizer to enhance its efficiency and adaptability in handling various optimization problems. Furthermore, the research incorporates an advanced non-linear hunting strategy to optimize the algorithm’s performance. The proposed algorithm is first validated using 29 CEC2017 benchmark test functions and five engineering-constrained design problems. Secondly, rigorous testing on PV parameter estimation benchmark datasets, including the single-diode model, double-diode model, three-diode model, and a representative PV module, was carried out to highlight the superiority of RL-GJO. The results were compelling: the root mean square error values achieved by RL-GJO were markedly lower than those of the original algorithm and other prevalent optimization methods. The synergy between reinforcement learning and GJO in this approach facilitates faster convergence and improved solution quality. This integration not only improves the performance metrics but also ensures a more efficient optimization process, especially in complex PV scenarios. With an average Freidman’s rank test values of 1.564 for numerical and engineering design problems and 1.742 for parameter estimation problems, the proposed RL-GJO is performing better than the original GJO and other peers. The proposed RL-GJO stands out as a reliable tool for PV parameter estimation. By seamlessly combining reinforcement learning with the golden jackal optimizer, it sets a new benchmark in PV optimization, indicating a promising avenue for future research and applications.","<method>Reinforcement Learning</method>, <method>Golden Jackal Optimizer</method>",<method>Reinforcement Learning</method>
2024,https://openalex.org/W4391734045,Engineering,Novel hybrid kepler optimization algorithm for parameter estimation of photovoltaic modules,"Abstract The parameter identification problem of photovoltaic (PV) models is classified as a complex nonlinear optimization problem that cannot be accurately solved by traditional techniques. Therefore, metaheuristic algorithms have been recently used to solve this problem due to their potential to approximate the optimal solution for several complicated optimization problems. Despite that, the existing metaheuristic algorithms still suffer from sluggish convergence rates and stagnation in local optima when applied to tackle this problem. Therefore, this study presents a new parameter estimation technique, namely HKOA, based on integrating the recently published Kepler optimization algorithm (KOA) with the ranking-based update and exploitation improvement mechanisms to accurately estimate the unknown parameters of the third-, single-, and double-diode models. The former mechanism aims at promoting the KOA’s exploration operator to diminish getting stuck in local optima, while the latter mechanism is used to strengthen its exploitation operator to faster converge to the approximate solution. Both KOA and HKOA are validated using the RTC France solar cell and five PV modules, including Photowatt-PWP201, Ultra 85-P, Ultra 85-P, STP6-120/36, and STM6-40/36, to show their efficiency and stability. In addition, they are extensively compared to several optimization techniques to show their effectiveness. According to the experimental findings, HKOA is a strong alternative method for estimating the unknown parameters of PV models because it can yield substantially different and superior findings for the third-, single-, and double-diode models.","<method>Kepler optimization algorithm (KOA)</method>, <method>HKOA</method>",No methods remaining
2024,https://openalex.org/W4392106623,Engineering,Machine learning assisted prediction of solar to liquid fuel production: a case study,"In this era of heightened environmental awareness, the global community faces the critical challenge of climate change. Renewable energy (RE) emerges as a vital contender to mitigate global warming and meet increasing energy needs. Nonetheless, the fluctuating nature of renewable energy sources underscores the necessity for efficient conversion and storage strategies. This pioneering research focuses on the transformation of solar energy (SE) into liquid fuels, with a specific emphasis on formic acid (FA) as a case study, done in Binh Thuan, Vietnam. The paper unveils a technology designed to convert solar energy into formic acid, ensuring its stability and storage at ambient conditions. It involves detailed simulations to quantify the daily and monthly electricity output from photovoltaic (PV) systems and the corresponding mass of formic acid producible through solar energy. The simulation of a dual-axis solar tracking system for the PV panels, intended to maximize solar energy capture, is one of the project's illustrations. The elevation and azimuth angles, which are two essential tracking system parameters, are extensively studied in the present research. The project makes use of machine learning algorithms in the field of predictive modeling, specifically Artificial Neural Networks (ANN) and Support Vector Machines (SVM). These tools play a crucial role in modeling PV power output and formic acid production while accounting for a variety of influencing factors. A comparative study shows that SVM outperforms ANN in accurately predicting the production of FA and PV power generation, both of which are the major goals. This model is a predictive tool that can be used to forecast these goals based on certain causal variables. Overall, it is observed that the maximum power produced with 2-axis solar tracker was achieved in February as 2355 kW resulting in the highest formic acid production of 2.25 ×106 grams. The study's broad ramifications demonstrate solar liquid fuel technology's potential as a long-term fix in the field of renewable energy. In addition to advancing the field of renewable energy storage, the study represents a major step toward tackling the global challenge of climate change.","<method>Artificial Neural Networks (ANN)</method>, <method>Support Vector Machines (SVM)</method>",<method>Artificial Neural Networks (ANN)</method><method>Support Vector Machines (SVM)</method>
2024,https://openalex.org/W4394585959,Engineering,Statistical Machine Learning for Power Flow Analysis Considering the Influence of Weather Factors on Photovoltaic Power Generation,"It is generally accepted that the impact of weather variation is gradually increasing in modern distribution networks with the integration of high-proportion photovoltaic (PV) power generation and weather-sensitive loads. This article analyzes power flow using a novel stochastic weather generator (SWG) based on statistical machine learning (SML). The proposed SML model, which incorporates generative adversarial networks (GANs), probability theory, and information theory, enables the generation and evaluation of simulated hourly weather data throughout the year. The GAN model captures various weather variation characteristics, including weather uncertainties, diurnal variations, and seasonal patterns. Compared to shallow learning models, the proposed deep learning model exhibits significant advantages in stochastic weather simulation. The simulated data generated by the proposed model closely resemble real data in terms of time-series regularity, integrity, and stochasticity. The SWG is applied to model PV power generation and weather-sensitive loads. Then, we actively conduct a power flow analysis (PFA) on a real distribution network in Guangdong, China, using simulated data for an entire year. The results provide evidence that the GAN-based SWG surpasses the shallow machine learning approach in terms of accuracy. The proposed model ensures accurate analysis of weather-related power flow and provides valuable insights for the analysis, planning, and design of distribution networks.","<method>statistical machine learning (SML)</method>, <method>generative adversarial networks (GANs)</method>, <method>shallow learning models</method>, <method>deep learning model</method>",<method>statistical machine learning (SML)</method><method>generative adversarial networks (GANs)</method><method>shallow learning models</method><method>deep learning model</method>
2024,https://openalex.org/W4391206025,Engineering,Short-term wind speed forecasting using an optimized three-phase convolutional neural network fused with bidirectional long short-term memory network model,"Wind energy is an environment friendly, low-carbon, and cost-effective renewable energy source. It is, however, difficult to integrate wind energy into a mixed energy grid due to its high volatility and intermittency. For wind energy conversion systems to be reliable and efficient, accurate wind speed (WS) forecasting is fundamental. This study cascades a convolutional neural network (CNN) with a bidirectional long short-term memory (BiLSTM) in order to obtain a model for hourly WS forecasting by utilizing several meteorological variables as model inputs to study their effects on predicted WS. For input selection, the mutation grey wolf optimizer (TMGWO) is used. For efficient optimization of CBiLSTM hyperparameters, a hybrid Bayesian Optimization and HyperBand (BOHB) algorithm is used. The combined usage of TMGWO, BOHB, and CBiLSTM leads to a three-phase hybrid model (i.e., 3P-CBiLSTM). The performance of 3P-CBiLSTM is benchmarked against the standalone and hybrid BiLSTMs, LSTMs, gradient boosting (GBRs), random forest (RFRs), and decision tree regressors (DTRs). The statistical analysis of forecasted WS reveals that the 3P-CBiLSTM is highly effective over the other benchmark forecasting methods. This objective model also registers the highest percentage of forecasted errors (≈ 53.4 – 81.8%) within the smallest error range ≤ |0.25| ms−1 amongst all tested study sites. Despite the remarkable results achieved, the CBiLSTM model cannot be generally understood, so the eXplainable Artificial Intelligence (xAI) technique was used for explaining local and global model outputs, based on Local Interpretable Model-Agnostic Explanations (LIME) and SHapley Additive exPlanations (SHAP). Both of the xAI methods determined that the antecedent WS is the most significant predictor of the short-term WS forecasting. Therefore, we aver that the proposed model can be employed to help wind farm operators in making quality decisions in maximizing wind power integration into the grid with reduced intermittency.","<method>convolutional neural network (CNN)</method>, <method>bidirectional long short-term memory (BiLSTM)</method>, <method>mutation grey wolf optimizer (TMGWO)</method>, <method>hybrid Bayesian Optimization and HyperBand (BOHB) algorithm</method>, <method>3P-CBiLSTM (three-phase hybrid model combining TMGWO, BOHB, and CBiLSTM)</method>, <method>long short-term memory (LSTM)</method>, <method>gradient boosting regressors (GBRs)</method>, <method>random forest regressors (RFRs)</method>, <method>decision tree regressors (DTRs)</method>, <method>Local Interpretable Model-Agnostic Explanations (LIME)</method>, <method>SHapley Additive exPlanations (SHAP)</method>",<method>convolutional neural network (CNN)</method><method>bidirectional long short-term memory (BiLSTM)</method><method>mutation grey wolf optimizer (TMGWO)</method><method>hybrid Bayesian Optimization and HyperBand (BOHB) algorithm</method><method>long short-term memory (LSTM)</method><method>gradient boosting regressors (GBRs)</method><method>random forest regressors (RFRs)</method><method>decision tree regressors (DTRs)</method><method>Local Interpretable Model-Agnostic Explanations (LIME)</method><method>SHapley Additive exPlanations (SHAP)</method>
2024,https://openalex.org/W4392450360,Engineering,Geographically weighted machine learning for modeling spatial heterogeneity in traffic crash frequency and determinants in US,"Spatial analyses of traffic crashes have drawn much interest due to the nature of the spatial dependence and spatial heterogeneity in the crash data. This study makes the best of Geographically Weighted Random Forest (GW-RF) model to explore the local associations between crash frequency and various influencing factors in the US, including road network attributes, socio-economic characteristics, and land use factors collected from multiple data sources. Special emphasis is put on modeling the spatial heterogeneity in the effects of a factor on crash frequency in different geographical areas in a data-driven way. The GW-RF model outperforms global models (e.g. Random Forest) and conventional geographically weighted regression, demonstrating superior predictive accuracy and elucidating spatial variations. The GW-RF model reveals spatial distinctions in the effects of certain factors on crash frequency. For example, the importance of intersection density varies significantly across regions, with high significance in the southern and northeastern areas. Low-grade road density emerges as influential in specific cities. The findings highlight the significance of different factors in influencing crash frequency across zones. Road network factors, particularly intersection density, exhibit high importance universally, while socioeconomic variables demonstrate moderate effects. Interestingly, land use variables show relatively lower importance. The outcomes could help to allocate resources and implement tailored interventions to reduce the likelihood of crashes.","<method>Geographically Weighted Random Forest (GW-RF)</method>, <method>Random Forest</method>, <method>geographically weighted regression</method>",<method>Geographically Weighted Random Forest (GW-RF)</method><method>Random Forest</method>
2024,https://openalex.org/W4392714432,Engineering,"Hybrid physics-machine learning models for predicting rate of penetration in the Halahatang oil field, Tarim Basin","Abstract Rate of penetration (ROP) is a key factor in drilling optimization, cost reduction and drilling cycle shortening. Due to the systematicity, complexity and uncertainty of drilling operations, however, it has always been a problem to establish a highly accurate and interpretable ROP prediction model to guide and optimize drilling operations. To solve this problem in the Tarim Basin, this study proposes four categories of hybrid physics-machine learning (ML) methods for modeling. One of which is residual modeling, in which an ML model learns to predict errors or residuals, via a physical model; the second is integrated coupling, in which the output of the physical model is used as an input to the ML model; the third is simple average, in which predictions from both the physical model and the ML model are combined; and the last is bootstrap aggregating (bagging), which follows the idea of ensemble learning to combine different physical models’ advantages. A total of 5655 real data points from the Halahatang oil field were used to test the performance of the various models. The results showed that the residual modeling model, with an R 2 of 0.9936, had the best performance, followed by the simple average model and bagging with R 2 values of 0.9394 and 0.5998, respectively. From the view of prediction accuracy, and model interpretability, the hybrid physics-ML model with residual modeling is the optimal method for ROP prediction.","<method>residual modeling</method>, <method>integrated coupling</method>, <method>simple average</method>, <method>bootstrap aggregating (bagging)</method>",<method>residual modeling</method><method>bootstrap aggregating (bagging)</method>
2024,https://openalex.org/W4391243967,Engineering,Reviews and syntheses: Remotely sensed optical time series for monitoring vegetation productivity,"Abstract. Vegetation productivity is a critical indicator of global ecosystem health and is impacted by human activities and climate change. A wide range of optical sensing platforms, from ground-based to airborne and satellite, provide spatially continuous information on terrestrial vegetation status and functioning. As optical Earth observation (EO) data are usually routinely acquired, vegetation can be monitored repeatedly over time, reflecting seasonal vegetation patterns and trends in vegetation productivity metrics. Such metrics include gross primary productivity, net primary productivity, biomass, or yield. To summarize current knowledge, in this paper we systematically reviewed time series (TS) literature for assessing state-of-the-art vegetation productivity monitoring approaches for different ecosystems based on optical remote sensing (RS) data. As the integration of solar-induced fluorescence (SIF) data in vegetation productivity processing chains has emerged as a promising source, we also include this relatively recent sensor modality. We define three methodological categories to derive productivity metrics from remotely sensed TS of vegetation indices or quantitative traits: (i) trend analysis and anomaly detection, (ii) land surface phenology, and (iii) integration and assimilation of TS-derived metrics into statistical and process-based dynamic vegetation models (DVMs). Although the majority of used TS data streams originate from data acquired from satellite platforms, TS data from aircraft and unoccupied aerial vehicles have found their way into productivity monitoring studies. To facilitate processing, we provide a list of common toolboxes for inferring productivity metrics and information from TS data. We further discuss validation strategies of the RS data derived productivity metrics: (1) using in situ measured data, such as yield; (2) sensor networks of distinct sensors, including spectroradiometers, flux towers, or phenological cameras; and (3) inter-comparison of different productivity metrics. Finally, we address current challenges and propose a conceptual framework for productivity metrics derivation, including fully integrated DVMs and radiative transfer models here labelled as “Digital Twin”. This novel framework meets the requirements of multiple ecosystems and enables both an improved understanding of vegetation temporal dynamics in response to climate and environmental drivers and enhances the accuracy of vegetation productivity monitoring.","<method>trend analysis and anomaly detection</method>, <method>land surface phenology</method>, <method>integration and assimilation of time series-derived metrics into statistical and process-based dynamic vegetation models (DVMs)</method>, <method>fully integrated dynamic vegetation models (DVMs) and radiative transfer models (“Digital Twin” framework)</method>",No methods remaining
2024,https://openalex.org/W4391404217,Engineering,Wildfire spreading prediction using multimodal data and deep neural network approach,"Predicting wildfire spread behavior is an extremely important task for many countries. On a small scale, it is possible to ensure constant monitoring of the natural landscape through ground means. However, on the scale of large countries, this becomes practically impossible due to remote and vast forest territories. The most promising source of data in this case that can provide global monitoring is remote sensing data. Currently, the main challenge is the development of an effective pipeline that combines geospatial data collection and the application of advanced machine learning algorithms. Most approaches focus on short-term fire spreading prediction and utilize data from unmanned aerial vehicles (UAVs) for this purpose. In this study, we address the challenge of predicting fire spread on a large scale and consider a forecasting horizon ranging from 1 to 5 days. We train a neural network model based on the MA-Net architecture to predict wildfire spread based on environmental and climate data, taking into account spatial distribution features. Estimating the importance of features is another critical issue in fire behavior prediction, so we analyze their contribution to the model's results. According to the experimental results, the most significant features are wind direction and land cover parameters. The F1-score for the predicted burned area varies from 0.64 to 0.68 depending on the day of prediction (from 1 to 5 days). The study was conducted in northern Russian regions and shows promise for further transfer and adaptation to other regions. This geospatial data-based artificial intelligence (AI) approach can be beneficial for supporting emergency systems and facilitating rapid decision-making.",<method>neural network model based on the MA-Net architecture</method>,No methods remaining
2024,https://openalex.org/W4391429082,Engineering,Simulation-based multi-objective genetic optimization for promoting energy efficiency and thermal comfort in existing buildings of hot climate,"This study conducts a detailed analysis to improve to enhance the energy performance of residential buildings in UAE through various retrofit measures. The applied methodology involved developing a calibrated building energy model for a two-story residential building, followed by a parametric analysis of six design variables, including wall and roof insulation, glazing, infiltration rate, window shading, and setpoint and setback temperatures to evaluate their impact on annual energy consumption. Additionally, a sensitivity analysis was conducted to assess the importance of the investigated design variables on building energy use. An optimization approach using the non-dominated sorting genetic algorithm (NSGA-II) was then implemented to optimize energy consumption while minimizing discomfort conditions. The key findings from the parametric simulations show significant energy savings: a 38.8 % reduction from improved wall insulation (achieving a U-value of 0.14 W/m2K), a 2.3 % decrease with better roof insulation, a 9.8 % saving from using triple clear glass glazing, a 9.6 % reduction by lowering the infiltration rate to 2.5 m³/h.m2, 7.5 % savings from window shading, and a 25.7 % decrease by optimizing cooling setpoints. A sensitivity analysis highlighted the dominant impact of wall insulation and cooling setpoint temperatures on energy usage. Followed by the cooling setpoint temperature. The subsequent NSGA-II optimization yielded 106 Pareto optimal solutions from 1897 iterations, offering a balance between reducing energy consumption (10,942 to 20,250 kWh/year, averaging 60 % savings) and minimizing discomfort hours (296–1230 h). These results provide actionable insights for stakeholders in the retrofitting process, emphasizing the significant energy-saving potential of specific retrofit measures.",<method>non-dominated sorting genetic algorithm (NSGA-II)</method>,<method>non-dominated sorting genetic algorithm (NSGA-II)</method>
2024,https://openalex.org/W4391665000,Engineering,A comprehensive review of critical analysis of biodegradable waste PCM for thermal energy storage systems using machine learning and deep learning to predict dynamic behavior,"This article explores the use of phase change materials (PCMs) derived from waste, in energy storage systems. It emphasizes the potential of these PCMs in addressing concerns related to fossil fuel usage and environmental impact. This article also highlights the aspects of these PCMs including reduced reliance on renewable resources minimized greenhouse gas emissions and waste reduction. The study also discusses approaches such as integrating nanotechnology to enhance thermal conductivity and utilizing machine learning and deep learning techniques for predicting dynamic behavior. The article provides an overall view of research on biodegradable waste-based PCMs and how they can play a promising role in achieving energy-efficient and sustainable thermal storage systems. However, specific conclusions drawn from the presented results are not explicitly outlined, leaving room, for investigation and exploration in this evolving field. Artificial neural network (ANN) predictive models for thermal energy storage devices perform differently. With a 4% adjusted mean absolute error, the Gaussian radial basis function kernel Support Vector Regression (SVR) model captured heat-related charging and discharging issues. The ANN model predicted finned tube heat and heat flux better than the numerical model. SVM models outperformed ANN and ANFIS in some datasets. Material property predictions favored gradient boosting, but Linear Regression and SVR models performed better, emphasizing application- and dataset-specific model selection. These predictive models provide insights into the complex thermal performance of building structures, aiding in the design and operation of energy-efficient systems. Biodegradable waste-based PCMs' sustainability includes carbon footprint, waste reduction, biodegradability, and circular economy alignment. Nanotechnology, machine learning, and deep learning improve thermal conductivity and prediction. Circular economy principles include waste reduction and carbon footprint reduction. Specific results-based conclusions are not stated. Presenting a comprehensive overview of current research highlights biodegradable waste-based PCMs' potential for energy-efficient and sustainable thermal storage systems.","<method>machine learning</method>, <method>deep learning</method>, <method>Artificial neural network (ANN)</method>, <method>Gaussian radial basis function kernel Support Vector Regression (SVR)</method>, <method>ANN model</method>, <method>numerical model</method>, <method>SVM models</method>, <method>ANFIS</method>, <method>gradient boosting</method>, <method>Linear Regression</method>",<method>machine learning</method><method>deep learning</method><method>Artificial neural network (ANN)</method><method>Gaussian radial basis function kernel Support Vector Regression (SVR)</method><method>ANN model</method><method>SVM models</method><method>ANFIS</method><method>gradient boosting</method><method>Linear Regression</method>
2024,https://openalex.org/W4399369266,Engineering,Enhancing Skin Cancer Diagnosis Using Swin Transformer with Hybrid Shifted Window-Based Multi-head Self-attention and SwiGLU-Based MLP,"Abstract Skin cancer is one of the most frequently occurring cancers worldwide, and early detection is crucial for effective treatment. Dermatologists often face challenges such as heavy data demands, potential human errors, and strict time limits, which can negatively affect diagnostic outcomes. Deep learning–based diagnostic systems offer quick, accurate testing and enhanced research capabilities, providing significant support to dermatologists. In this study, we enhanced the Swin Transformer architecture by implementing the hybrid shifted window-based multi-head self-attention (HSW-MSA) in place of the conventional shifted window-based multi-head self-attention (SW-MSA). This adjustment enables the model to more efficiently process areas of skin cancer overlap, capture finer details, and manage long-range dependencies, while maintaining memory usage and computational efficiency during training. Additionally, the study replaces the standard multi-layer perceptron (MLP) in the Swin Transformer with a SwiGLU-based MLP, an upgraded version of the gated linear unit (GLU) module, to achieve higher accuracy, faster training speeds, and better parameter efficiency. The modified Swin model-base was evaluated using the publicly accessible ISIC 2019 skin dataset with eight classes and was compared against popular convolutional neural networks (CNNs) and cutting-edge vision transformer (ViT) models. In an exhaustive assessment on the unseen test dataset, the proposed Swin-Base model demonstrated exceptional performance, achieving an accuracy of 89.36%, a recall of 85.13%, a precision of 88.22%, and an F1-score of 86.65%, surpassing all previously reported research and deep learning models documented in the literature.","<method>Deep learning–based diagnostic systems</method>, <method>Swin Transformer architecture</method>, <method>hybrid shifted window-based multi-head self-attention (HSW-MSA)</method>, <method>shifted window-based multi-head self-attention (SW-MSA)</method>, <method>multi-layer perceptron (MLP)</method>, <method>SwiGLU-based MLP</method>, <method>gated linear unit (GLU) module</method>, <method>convolutional neural networks (CNNs)</method>, <method>vision transformer (ViT) models</method>",<method>Swin Transformer architecture</method><method>shifted window-based multi-head self-attention (SW-MSA)</method><method>multi-layer perceptron (MLP)</method><method>SwiGLU-based MLP</method><method>gated linear unit (GLU) module</method><method>convolutional neural networks (CNNs)</method><method>vision transformer (ViT) models</method>
2024,https://openalex.org/W4400227316,Engineering,FPSO/LNG hawser system lifetime assessment by Gaidai multivariate risk assessment method,"Abstract Floating Production Storage and Offloading (FPSO) unit being an offshore vessel, storing and producing crude oil, prior to crude oil being transported by accompanying shuttle tanker. Critical mooring/hawser strains during offloading operation have to be accurately predicted, in order to maintain operational safety and reliability. During certain types of offloading, excessive hawser tensions may occur, causing operational risks. Current study examines FPSO vessel’s dynamic reactions to hydrodynamic wave-induced loads, given realistic in situ environmental conditions, utilizing the AQWA software package. Current study advocates novel multi-dimensional spatiotemporal risks assessment approach, that is particularly well suited for large dataset analysis, based on numerical simulations (or measurements). Advocated multivariate reliability methodology may be useful for a variety of marine and offshore systems that must endure severe environmental stressors during their intended operational lifespan. Methodology, presented in this study provides advanced capability to efficiently, yet accurately evaluate dynamic system failure, hazard and damage risks, given representative dynamic record of multidimensional system’s inter-correlated critical components. Gaidai risk assessment method being novel dynamic multidimensional system’s lifetime assessment methodology. In order to validate and benchmark Gaidai risk assessment method, in this study it was applied to FPSO and potentially LNG (i.e., Liquid Natural Gas) vessels dynamics. Major advantage of the advocated approach is that there are no existing alternative risk assessment methods, able to tackle unlimited number of system’s dimensions. Accurate multi-dimensional risk assessment had been carried out, based on numerically simulated data, partially verified by available laboratory experiments. Confidence intervals had been given for predicted dynamic high-dimensional system risk levels.",<method>Gaidai risk assessment method</method>,No methods remaining
2024,https://openalex.org/W4391304535,Engineering,Sustainable electric discharge machining using alumina-mixed deionized water as dielectric: Process modelling by artificial neural networks underpinning net-zero from industry,"The requirement for materials possessing both high strength and low density has garnered significant attention from industries and researchers in recent times. Among these materials, aluminum 6061 (Al6061) exhibits the desired properties. However, due to its diverse machining capabilities, powder-mixed electric discharge machining (PMEDM) has emerged as a viable option for cutting such materials. This method has been criticized for its high energy consumption and limited cutting efficiency. Furthermore, conventional dielectric (kerosene) employed in EDM has drastic environmental and operator's health concerns. To address the abovementioned issues, deionized water has been employed in this study which enhances the reusability of resources and minimizes the cost of the dielectric. Herein, to make the process sustainable, and to keep the environment free from hazardous fumes, generated during the machining process, deionized water has been used. In addition to that, to uplift the machining responses, alumina (Al2O3) nano-powder has been engaged. To conduct the study, response surface methodology (RSM) was employed. This investigation aimed to analyze the impact on the material removal rate (MRR), surface roughness (SR), and specific energy consumption (SEC) by using microscopy analysis, scanning electron microscopy (SEM), 3D surfaces profilometry, energy dispersive x-ray (EDX) analysis and after that, the machining responses are modelled using the artificial neural networks (ANN) technique. It was observed that by utilizing non-dominated sorting genetic algorithms (NSGA-II) an improvement of 87.42 % in MRR, 3.4 % better surface finish and 0.7 % better SEC have been obtained. Notably, CO2 emissions were found to be 94.27 % lower by using the deionized water as dielectric compared to those produced by kerosene oil.","<method>response surface methodology (RSM)</method>, <method>artificial neural networks (ANN)</method>, <method>non-dominated sorting genetic algorithms (NSGA-II)</method>",<method>artificial neural networks (ANN)</method><method>non-dominated sorting genetic algorithms (NSGA-II)</method>
2024,https://openalex.org/W4391708122,Engineering,Application of machine learning approaches in supporting irrigation decision making: A review,"Irrigation decision-making has evolved from solely depending on farmers' decisions taken based on the visual analysis of field conditions to making decisions based on crop water need predictions generated using machine learning (ML) techniques. This paper reviews ML related articles to discuss how ML has been used to enhance irrigation decision making. We reviewed 16 studies that used ML approaches for irrigation scheduling prediction and decision-making focusing on the input features, algorithms used and their applicability in real world conditions. ML performances in terms of accuracy, water conservation compared to fixed or threshold-based methods are discussed along with modeling performances. Informed by the 16 research studies, we assessed constraints to the adoption of ML in irrigation decision making at field scale, which include limited data availability coupled with data sharing constraints, and a lack of uncertainty quantification as well as the need for physics informed ML based irrigation scheduling models. To address these limitations, we discussed approaches in future research such as integrating process-based models with ML, incorporating expert knowledge into the modeling procedure, and making data and tools Findable, Accessible, Interoperable, and Reusable (FAIR). These approaches will improve ML modeling outcomes and boost the availability of farm-related data and tools for FAIRer data-driven applications of irrigation modeling.","<method>machine learning (ML) techniques</method>, <method>ML approaches</method>, <method>process-based models integrated with ML</method>, <method>physics informed ML based irrigation scheduling models</method>",No methods remaining
2024,https://openalex.org/W4393144919,Engineering,A Novel Fuzzy Neural Network Architecture Search Framework for Defect Recognition With Uncertainties,"Defect recognition is an important task in intelligent manufacturing. Due to the subjectivity of human annotation, the collected defect data usually contains a lot of noise and unpredictable uncertainties, which have a great negative influence on defect recognition. It is a significant challenge to discover an effective defect recognition model with satisfactory uncertainty processing ability. A natural way is to automatically search for an efficient deep model, which can be realized by neural architecture search (NAS). To achieve this, we propose an efficient fuzzy NAS framework for defect recognition, where the searched architecture can effectively handle uncertain information from the given datasets. Specifically, we first design a fuzzy search space and the related encoding strategy for fuzzy NAS. Then, we propose a comparator-based evolutionary search approach, where an online end-to-end comparator is learned to directly determine the selection of candidate architectures from the evolutionary population. The comparator works in an end-to-end way and it transforms the complex ranking problem of evaluating architectures into a simple classification task, which overcomes the rank disorder issue suffered from traditional performance predictors. A series of experimental results demonstrate that the architecture with fewer #Params (1.22 M) search by fuzzy neural architecture search framework for defect recognition method achieves higher accuracy (92.26%) compared to the state-of-the-art results (i.e., DARTS-PV) on the ELPV dataset, as well as competitive results (accuracy = 76.4%, #Params = 1.04 M) on the CODEBRIM dataset. Experimental results show the effectiveness and efficiency of our proposed method in handling uncertain problems.","<method>neural architecture search (NAS)</method>, <method>fuzzy neural architecture search (fuzzy NAS)</method>, <method>comparator-based evolutionary search approach</method>",<method>neural architecture search (NAS)</method>
2024,https://openalex.org/W4395479913,Engineering,Machinability investigation of natural fibers reinforced polymer matrix composite under drilling: Leveraging machine learning in bioengineering applications,"The growing demand for fiber-reinforced polymer (FRP) in industrial applications has prompted the exploration of natural fiber-based composites as a viable alternative to synthetic fibers. Using jute–rattan fiber-reinforced composite offers the potential for environmentally sustainable waste material decomposition and cost reduction compared to conventional fiber materials. This article focuses on the impact of different machining constraints on surface roughness and delamination during the drilling process of the jute–rattan FRP composite. Inspired by this unexplored research area, this article emphasizes the influence of various machining constraints on surface roughness and delamination in drilling jute–rattan FRP composite. Response surface methodology designs the experiment using drill bit material, spindle speed, and feed rate as input variables to measure surface roughness and delamination factors. The technique of order of preference by similarity to the ideal solution method is used to optimize the machining parameters, and for predicting surface roughness and delamination, two machine learning-based models named random forest (RF) and support vector machine (SVM) are utilized. To evaluate the accuracy of the predicted values, the correlation coefficient (R2), mean absolute percentage error, and mean squared error were used. RF performed better in comparison with SVM, with a higher value of R2 for both testing and training datasets, which is 0.997, 0.981, and 0.985 for surface roughness, entry delamination, and exit delamination, respectively. Hence, this study presents an innovative methodology for predicting surface roughness and delamination through machine learning techniques.","<method>random forest (RF)</method>, <method>support vector machine (SVM)</method>",<method>random forest (RF)</method><method>support vector machine (SVM)</method>
2024,https://openalex.org/W4396634174,Engineering,AISClean: AIS data-driven vessel trajectory reconstruction under uncertain conditions,"In maritime transportation, intelligent vessel surveillance has become increasingly prevalent and widespread by collecting and analyzing high massive spatial data from automatic identification system (AIS). The state-of-the-art AIS devices contain various functionalities, such as position transmission, tracking navigation, etc. Widely equipped shipboard AIS devices provide a large amount of real-time and historical vessel trajectory data for maritime management. However, the original AIS data often suffers from unwanted noise (i.e., poorly tracked timestamped points for vessel trajectories) and missing (i.e., no data is received or transmitted for a long term) data during signal acquisition, transmission, and analog-to-digital conversion. This degradation in data quality poses significant risks, including potential miscalculations in vessel collision avoidance systems, inaccuracies in emission calculations, and challenges in port management. In this work, a data-driven vessel trajectory reconstruction framework considering historical features is proposed to enhance the reliability of vessel trajectory. Specifically, a series of statistical methods are proposed to identify noisy data and missing data. Then, a model combining Geohash and dynamic time warping algorithms is developed to restore the trajectories degraded by random noise and missing data in vessel trajectories. Comparative experiments with baseline methods on multiple datasets verify the effectiveness of the proposed data-driven model.",<method>dynamic time warping</method>,<method>dynamic time warping</method>
2024,https://openalex.org/W4399568894,Engineering,Artificial intelligence capability and organizational performance: unraveling the mediating mechanisms of decision-making processes,"Purpose This study investigates the profound impact of artificial intelligence (AI) capabilities on decision-making processes and organizational performance, addressing a crucial gap in the literature by exploring the mediating role of decision-making speed and quality. Design/methodology/approach Drawing upon resource-based theory and prior research, this study constructs a comprehensive model and hypotheses to illuminate the influence of AI capabilities within organizations on decision-making speed, decision quality, and, ultimately, organizational performance. A dataset comprising 230 responses from diverse organizations forms the basis of the analysis, with the study employing a partial least squares structural equation model (PLS-SEM) for robust data examination. Findings The results demonstrate the pivotal role of AI capabilities in shaping organizational decision-making processes and performance. AI capability significantly and positively affects decision-making speed, decision quality, and overall organizational performance. Notably, decision-making speed is a critical factor contributing significantly to enhanced organizational performance. The study further uncovered partial mediation effects, suggesting that decision-making processes partially mediate the relationship between AI capabilities and organizational performance through decision-making speed. Originality/value This study contributes to the existing body of literature by providing empirical evidence of the multifaceted impact of AI capabilities on organizational decision-making and performance. Elucidating the mediating role of decision-making processes advances our understanding of the complex mechanisms through which AI capabilities drive organizational success.",<method>partial least squares structural equation model (PLS-SEM)</method>,No methods remaining
2024,https://openalex.org/W4400234709,Engineering,Eco-friendly mix design of slag-ash-based geopolymer concrete using explainable deep learning,"Geopolymer concrete is a sustainable and eco-friendly substitute for traditional OPC (Ordinary Portland Cement) based concrete, as it reduces greenhouse gas emissions. With various supplementary cementitious materials, the compressive strength of geopolymer concrete should be accurately predicted. Recent studies have applied deep learning techniques to predict the compressive strength of geopolymer concrete yet its hidden decision-making criteria diminish the end-users' trust in predictions. To bridge this gap, the authors first developed three deep learning models: an artificial neural network (ANN), a deep neural network (DNN), and a 1D convolution neural network (CNN) to predict the compressive strength of slag ash-based geopolymer concrete. The performance indices for accuracy revealed that the DNN model outperforms the other two models. Subsequently, Shapley additive explanations (SHAP) were used to explain the best-performed deep learning model, DNN, and its compressive strength predictions. SHAP exhibited how the importance of each feature and its relationship contributes to the compressive strength prediction of the DNN model. Finally, the authors developed a novel DNN-based open-source software interface to predict the mix design proportions for a given target compressive strength (using inverse modeling technique) for slag ash-based geopolymer concrete. Additionally, the software calculates the Global Warming Potential (kg CO2 equivalent) for each mix design to select the mix designs with low greenhouse emissions.","<method>artificial neural network (ANN)</method>, <method>deep neural network (DNN)</method>, <method>1D convolution neural network (CNN)</method>, <method>Shapley additive explanations (SHAP)</method>",<method>artificial neural network (ANN)</method><method>deep neural network (DNN)</method><method>1D convolution neural network (CNN)</method><method>Shapley additive explanations (SHAP)</method>
2024,https://openalex.org/W4400496339,Engineering,Metal–Organic Framework Stability in Water and Harsh Environments from Data-Driven Models Trained on the Diverse WS24 Data Set,"Metal-organic frameworks (MOFs) are porous materials with applications in gas separations and catalysis, but a lack of water stability often limits their practical use given the ubiquity of water. Consequently, it is useful to predict whether a MOF is water-stable before investing time and resources into synthesis. Existing heuristics for designing water-stable MOFs lack generality and limit the diversity of explored chemistry due to narrowly defined criteria. Machine learning (ML) models offer the promise to improve the generality of predictions but require data. In an improvement on previous efforts, we enlarge the available training data for MOF water stability prediction by over 400%, adding 911 MOFs with water stability labels assigned through semiautomated manuscript analysis to curate the new data set WS24. The additional data are shown to improve ML model performance (test ROC-AUC > 0.8) over diverse chemistry for the prediction of both water stability and stability in harsher acidic conditions. We illustrate how the expanded data set and models can be used with a previously developed activation stability model in combination with genetic algorithms to quickly screen ∼10,000 MOFs from a space of hundreds of thousands for candidates with multivariate stability (upon activation, in water, and in acid). We uncover metal- and geometry-specific design rules for robust MOFs. The data set and ML models developed in this work, which we disseminate through an easy-to-use web interface, are expected to contribute toward the accelerated discovery of novel, water-stable MOFs for applications such as direct air gas capture and water treatment.","<method>Machine learning (ML) models</method>, <method>genetic algorithms</method>",<method>genetic algorithms</method>
2024,https://openalex.org/W4401015316,Engineering,Deep learning approaches for visual faults diagnosis of photovoltaic systems: State-of-the-Art review,"PV systems are prone to external environmental conditions that affect PV system operations. Visual inspection of the impacts of faults on PV system is considered a better practice rather than onsite fault detection mechanisms. Faults such as hotspot, dark area, cracks, glass break, wavy lines, snail tracks, corrosion, discoloration, junction box failure and delamination faults have different visual symptoms. EL technology, infrared thermography, and photoluminescence approaches are used to extract and visualize the impact of faults on PV modules. DL based algorithms such as, CNN, ANN, RNN, AE, DBN, TL and hybrid algorithms have shown promising results in domain of visual PV fault detection. This article critically overviews working mechanism of DL algorithms in terms of their limitations, complexity, interpretability, training dataset requirements and capability to work with another DL algorithms. This research article also reviews, critically analyzes, and systematically presents different clustering algorithms based on their clustering mechanism, distance metrics, convergence criteria. Additionally, their performance is also evaluated in terms of DI, CHI, DBI, S-score, and homogeneity. Moreover, this research work explicitly identifies and explains the limitations and contributions of recent and older techniques employed for features extraction, data preprocessing, and decision making by performing SWOT analysis. This research work also recommends future research directions for industry and academia.","<method>CNN</method>, <method>ANN</method>, <method>RNN</method>, <method>AE</method>, <method>DBN</method>, <method>TL</method>, <method>hybrid algorithms</method>, <method>clustering algorithms</method>",<method>CNN</method><method>ANN</method><method>RNN</method><method>AE</method><method>clustering algorithms</method>
2024,https://openalex.org/W4401075136,Engineering,Metaheuristic optimization algorithms-based prediction modeling for titanium dioxide-Assisted photocatalytic degradation of air contaminants,"Airborne contaminants pose significant environmental and health challenges. Titanium dioxide (TiO2) has emerged as a leading photocatalyst in the degradation of air contaminants compared to other photocatalysts due to its inherent inertness, cost-effectiveness, and photostability. To assess its effectiveness, laboratory examinations are frequently employed to measure the photocatalytic degradation rate of TiO2. However, this approach involves time-consuming requirements, labor-intensive tasks, and high costs. In literature, ensemble or standalone models are commonly used for assessing the performance of TiO2 photocatalytic degradation of water and air contaminants. Nonetheless, the application of metaheuristic hybrid models has the potential to be more effective in predictive accuracy and efficiency. Accordingly, this research utilized hybrid machine learning (ML) algorithms to estimate the photo-degradation rate constants of organic air pollutants using TiO2 nanoparticles and exposure to ultraviolet light. Six metaheuristics optimization algorithms, namely, nuclear reaction optimization (NRO), differential evolution algorithm (DEA), human felicity algorithm (HFA), lightning search algorithm (LSA), Harris hawks algorithm (HHA), and tunicate swarm algorithm (TSA) were combined with random forest (RF) technique to establish the hybrid models. A database of 200 data points was acquired from experimental studies for model training and testing. Furthermore, multiple statistical indicators and 10-fold cross-validation were employed to examine the established hybrid model's accuracy and robustness. The TSA-RF model demonstrated superior prediction accuracy among the six suggested models, achieving an impressive correlation (R) of 0.90 and a lower root mean square error (RMSE) of 0.25. In contrast, the HFA-RF, HHA-RF, and NRO-RF models exhibited a slightly lower R-value of 0.88, with RMSE scores of 0.32. The DEA-RF and LSA-RF models, while effective, showed a marginally lower R-value of 0.85, with RMSE values of 0.45 and 0.44, respectively. Moreover, the SHapley Additive exPlanation (SHAP) results indicated that the degradation rates of air contaminants through photocatalysis were most notably influenced by factors such as the reactor sizes, photocatalyst dosage, humidity, and intensity.","<method>random forest (RF)</method>, <method>nuclear reaction optimization (NRO)</method>, <method>differential evolution algorithm (DEA)</method>, <method>human felicity algorithm (HFA)</method>, <method>lightning search algorithm (LSA)</method>, <method>Harris hawks algorithm (HHA)</method>, <method>tunicate swarm algorithm (TSA)</method>, <method>SHapley Additive exPlanation (SHAP)</method>",<method>random forest (RF)</method><method>differential evolution algorithm (DEA)</method><method>Harris hawks algorithm (HHA)</method><method>SHapley Additive exPlanation (SHAP)</method>
2024,https://openalex.org/W4403158403,Engineering,Artificial intelligence alphafold model for molecular biology and drug discovery: a machine-learning-driven informatics investigation,"AlphaFold model has reshaped biological research. However, vast unstructured data in the entire AlphaFold field requires further analysis to fully understand the current research landscape and guide future exploration. Thus, this scientometric analysis aimed to identify critical research clusters, track emerging trends, and highlight underexplored areas in this field by utilizing machine-learning-driven informatics methods. Quantitative statistical analysis reveals that the AlphaFold field is enjoying an astonishing development trend (Annual Growth Rate = 180.13%) and global collaboration (International Co-authorship = 33.33%). Unsupervised clustering algorithm, time series tracking, and global impact assessment point out that Cluster 3 (Artificial Intelligence-Powered Advancements in AlphaFold for Structural Biology) has the greatest influence (Average Citation = 48.36 ± 184.98). Additionally, regression curve and hotspot burst analysis highlight ""structure prediction"" (s = 12.40, R2 = 0.9480, p = 0.0051), ""artificial intelligence"" (s = 5.00, R2 = 0.8096, p = 0.0375), ""drug discovery"" (s = 1.90, R2 = 0.7987, p = 0.0409), and ""molecular dynamics"" (s = 2.40, R2 = 0.8000, p = 0.0405) as core hotspots driving the research frontier. More importantly, the Walktrap algorithm further reveals that ""structure prediction, artificial intelligence, molecular dynamics"" (Relevance Percentage[RP] = 100%, Development Percentage[DP] = 25.0%), ""sars-cov-2, covid-19, vaccine design"" (RP = 97.8%, DP = 37.5%), and ""homology modeling, virtual screening, membrane protein"" (RP = 89.9%, DP = 26.1%) are closely intertwined with the AlphaFold model but remain underexplored, which implies a broad exploration space. In conclusion, through the machine-learning-driven informatics methods, this scientometric analysis offers an objective and comprehensive overview of global AlphaFold research, identifying critical research clusters and hotspots while prospectively pointing out underexplored critical areas.","<method>unsupervised clustering algorithm</method>, <method>Walktrap algorithm</method>",<method>unsupervised clustering algorithm</method>
2024,https://openalex.org/W4390663168,Engineering,Review of Prediction of Stress Corrosion Cracking in Gas Pipelines Using Machine Learning,"Pipeline integrity and safety depend on the detection and prediction of stress corrosion cracking (SCC) and other defects. In oil and gas pipeline systems, a variety of corrosion-monitoring techniques are used. The observed data exhibit characteristics of nonlinearity, multidimensionality, and noise. Hence, data-driven modeling techniques have been widely utilized. To accomplish intelligent corrosion prediction and enhance corrosion control, machine learning (ML)-based approaches have been developed. Some published papers related to SCC have discussed ML techniques and their applications, but none of the works has shown the real ability of ML to detect or predict SCC in energy pipelines, though fewer researchers have tested their models to prove them under controlled environments in laboratories, which is completely different from real work environments in the field. Looking at the current research status, the authors believe that there is a need to explore the best technologies and modeling approaches and to identify clear gaps; a critical review is, therefore, required. The objective of this study is to assess the current status of machine learning’s applications in SCC detection, identify current research gaps, and indicate future directions from a scientific research and application point of view. This review will highlight the limitations and challenges of employing machine learning for SCC prediction and also discuss the importance of incorporating domain knowledge and expert inputs to enhance the accuracy and reliability of predictions. Finally, a framework is proposed to demonstrate the process of the application of ML to condition assessments of energy pipelines.","<method>machine learning (ML)-based approaches</method>, <method>machine learning (ML) techniques</method>",No methods remaining
2024,https://openalex.org/W4390776100,Engineering,Hybrid KNN-SVM machine learning approach for solar power forecasting,"Predictions about solar power will have a significant impact on large-scale renewable energy plants. Photovoltaic (PV) power generation forecasting is particularly sensitive to measuring the uncertainty in weather conditions. Although several conventional techniques like long short-term memory (LSTM), support vector machine (SVM), etc. are available, but due to some restrictions, their application is limited. To enhance the precision of forecasting solar power from solar farms, a hybrid machine learning model that includes blends of the K-Nearest Neighbor (KNN) machine learning technique with the SVM to increase reliability for power system operators is proposed in this investigation. The conventional LSTM technique is also implemented to compare the performance of the proposed hybrid technique. The suggested hybrid model is improved by the use of structural diversity and data diversity in KNN and SVM, respectively. For the solar power predictions, the suggested method was tested on the Jodhpur real-time series dataset obtained from the data centers of weather stations using Meteonorm. The data set includes metrics such as Hourly Average Temperature (HAT), Hourly Total Sunlight Duration (HTSD), Hourly Total Global Solar Radiation (HTGSR), and Hourly Total Photovoltaic Energy Generation (HTPEG). The collated data has been segmented into training data, validation data, and testing data. Furthermore, the proposed technique performed better when evaluated on the three performance indices, viz., accuracy, sensitivity, and specificity. Compared with the conventional LSTM technique, the hybrid technique improved the prediction with 98% accuracy.","<method>long short-term memory (LSTM)</method>, <method>support vector machine (SVM)</method>, <method>K-Nearest Neighbor (KNN)</method>, <method>hybrid machine learning model (KNN + SVM)</method>",<method>long short-term memory (LSTM)</method><method>support vector machine (SVM)</method><method>K-Nearest Neighbor (KNN)</method><method>hybrid machine learning model (KNN + SVM)</method>
2024,https://openalex.org/W4390939303,Engineering,A Reliable and Robust Deep Learning Model for Effective Recyclable Waste Classification,"In response to the growing waste problem caused by industrialization and modernization, the need for an automated waste sorting and recycling system for sustainable waste management has become ever more pressing. Deep learning has made significant advancements in image classification, making it ideally suited for waste sorting applications. This application depends on the development of a suitable deep learning model capable of accurately categorizing various categories of waste. In this study, we present RWC-Net (recyclable waste classification network), a novel deep learning model designed for the classification of six distinct waste categories using the TrashNet dataset of 2,527 images of waste. The performance of our model is subjected to intensive quantitative and qualitative evaluations and is compared to various state-of-art waste classification techniques. The proposed model outperformed several state-of-the-art models by obtaining a remarkable overall accuracy rate of 95.01 percent. In addition, it receives high F1-scores for each of the six waste categories: 97.24% for cardboard, 96.18% for glass, 94% for metal, 95.73% for paper, 93.67% for plastic, and 88.55% for litter. The reliability of the model is demonstrated qualitatively through the saliency maps generated by Score-CAM (class activation mapping) model, which provide visual insights into its performance across various waste categories. These results highlight the model's accuracy and demonstrate its potential as an effective automated waste classification and management solution.","<method>Deep learning</method>, <method>RWC-Net (recyclable waste classification network)</method>, <method>Score-CAM (class activation mapping)</method>",<method>Deep learning</method><method>Score-CAM (class activation mapping)</method>
2024,https://openalex.org/W4391202802,Engineering,Learning optimal inter-class margin adaptively for few-shot class-incremental learning via neural collapse-based meta-learning,"Few-Shot Class-Incremental Learning (FSCIL) aims to learn new classes incrementally with a limited number of samples per class. It faces issues of forgetting previously learned classes and overfitting on few-shot classes. An efficient strategy is to learn features that are discriminative in both base and incremental sessions. Current methods improve discriminability by manually designing inter-class margins based on empirical observations, which can be suboptimal. The emerging Neural Collapse (NC) theory provides a theoretically optimal inter-class margin for classification, serving as a basis for adaptively computing the margin. Yet, it is designed for closed, balanced data, not for sequential or few-shot imbalanced data. To address this gap, we propose a Meta-learning- and NC-based FSCIL method, MetaNC-FSCIL, to compute the optimal margin adaptively and maintain it at each incremental session. Specifically, we first compute the theoretically optimal margin based on the NC theory. Then we introduce a novel loss function to ensure that the loss value is minimized precisely when the inter-class margin reaches its theoretically best. Motivated by the intuition that ""learn how to preserve the margin"" matches the meta-learning's goal of ""learn how to learn"", we embed the loss function in base-session meta-training to preserve the margin for future meta-testing sessions. Experimental results demonstrate the effectiveness of MetaNC-FSCIL, achieving superior performance on multiple datasets. The code is available at https://github.com/qihangran/metaNC-FSCIL.","<method>Few-Shot Class-Incremental Learning (FSCIL)</method>, <method>Neural Collapse (NC) theory</method>, <method>Meta-learning</method>",<method>Few-Shot Class-Incremental Learning (FSCIL)</method><method>Neural Collapse (NC) theory</method><method>Meta-learning</method>
2024,https://openalex.org/W4392081637,Engineering,Hybrid deep learning models for time series forecasting of solar power,"Abstract Forecasting solar power production accurately is critical for effectively planning and managing renewable energy systems. This paper introduces and investigates novel hybrid deep learning models for solar power forecasting using time series data. The research analyzes the efficacy of various models for capturing the complex patterns present in solar power data. In this study, all of the possible combinations of convolutional neural network (CNN), long short-term memory (LSTM), and transformer (TF) models are experimented. These hybrid models also compared with the single CNN, LSTM and TF models with respect to different kinds of optimizers. Three different evaluation metrics are also employed for performance analysis. Results show that the CNN–LSTM–TF hybrid model outperforms the other models, with a mean absolute error (MAE) of 0.551% when using the Nadam optimizer. However, the TF–LSTM model has relatively low performance, with an MAE of 16.17%, highlighting the difficulties in making reliable predictions of solar power. This result provides valuable insights for optimizing and planning renewable energy systems, highlighting the significance of selecting appropriate models and optimizers for accurate solar power forecasting. This is the first time such a comprehensive work presented that also involves transformer networks in hybrid models for solar power forecasting.","<method>convolutional neural network (CNN)</method>, <method>long short-term memory (LSTM)</method>, <method>transformer (TF)</method>, <method>CNN–LSTM–TF hybrid model</method>, <method>TF–LSTM model</method>",<method>convolutional neural network (CNN)</method><method>long short-term memory (LSTM)</method><method>transformer (TF)</method><method>CNN–LSTM–TF hybrid model</method>
2024,https://openalex.org/W4392499245,Engineering,Exploring the role of skin temperature in thermal sensation and thermal comfort: A comprehensive review,"The role of skin temperature as a determinant of human thermal sensation and comfort has gained increasing recognition, prompting a need for a systematic review. This review examines the relationship between skin temperature and thermal sensation, synthesizing insights from 172 studies published since 2000. It uniquely focuses on the indispensable roles of local and mean skin temperatures, a perspective not comprehensively explored in previous literature. The review reveals that the most common measurement points for skin temperature are the face and hands, attributed to their higher thermal sensitivity and the practical ease of measurement. It establishes a clear linear relationship between mean skin temperature and user thermal sensation, though affected by the choice of measurement locations and number of points. A notable finding is the varying impact of local skin temperature on overall thermal sensation in changing environments, with local heating less influential than cooling. The review also uncovers significant demographic variations in thermal sensation, strongly influenced by differing skin temperatures across age groups, genders, and climatic regions. For example, elderly populations exhibit a decreased temperature sensitivity, especially towards warmth. Gender differences are also significant, with females experiencing higher skin temperatures in warmer environments and lower in colder ones. Machine learning (ML)-based methods, especially classification tree-based and support vector machine (SVM) techniques, dominate in predicting thermal sensation and comfort, leveraging skin temperature data. While ML methods are prevalent, statistical regression-based approaches offer valuable empirical insights. Thermo-physiological model-based methods provide reliable results by incorporating detailed skin temperature dynamics. The review identifies a gap in understanding how gender, age, and regional differences influence thermal comfort in diverse environments. The study recommends conducting more nuanced experiments to dissect the impact of these factors and proposes the integration of individual demographic variables into ML models to personalize thermal comfort predictions.","<method>classification tree-based</method>, <method>support vector machine (SVM)</method>, <method>statistical regression-based approaches</method>, <method>thermo-physiological model-based methods</method>",<method>support vector machine (SVM)</method><method>statistical regression-based approaches</method>
2024,https://openalex.org/W4392509422,Engineering,A novel framework for predicting active flow control by combining deep reinforcement learning and masked deep neural network,"Active flow control (AFC) through deep reinforcement learning (DRL) is computationally demanding. To address this, a masked deep neural network (MDNN), aiming to replace the computational fluid dynamics (CFD) environment, is developed to predict unsteady flow fields under the influence of arbitrary object motion. Then, a novel DRL-MDNN framework that combines the MDNN-based environment with the DRL algorithm is proposed. To validate the reliability of the framework, a blind test in a pulsating baffle system is designed. Vibration damping is considered to be the objective, and a traditional DRL-CFD framework is constructed for comparison. After training, a spatiotemporal evolution of 200 time steps under the influence of arbitrary object motion is predicted by the MDNN. The details of the flow field are compared with the CFD results, and a relative error within 5% is achieved, which satisfies the accuracy of serving as an interactive environment for DRL algorithms. The DRL-MDNN and traditional DRL-CFD frameworks are then applied to the pulsating baffle system to find the optimal control strategy. The results indicate that both frameworks achieve similar control performance, reducing vibration by 90%. Considering the resources expended in establishing the database, the computational resource consumption of the DRL-MDNN framework is reduced by 95%, and the interactive response time during each episode is decreased by 98.84% compared to the traditional DRL-CFD framework.","<method>deep reinforcement learning (DRL)</method>, <method>masked deep neural network (MDNN)</method>, <method>DRL-MDNN framework</method>, <method>traditional DRL-CFD framework</method>",<method>deep reinforcement learning (DRL)</method>
2024,https://openalex.org/W4392890128,Engineering,"Motivation, work experience, and teacher performance: A comparative study","This research study investigates the effect of intrinsic and extrinsic motivation on employee performance, with a specific focus on the moderating role of employees' work experience. This investigation utilizes a proposed framework, focusing on higher educational institutions in West Bengal, India. It contributes to the human resource management field by comparing teacher performance in private and government academic institutions based on their motivation levels. The study employs a quantitative approach, collecting data from 250 teachers in West Bengal, India, using a structured questionnaire. The dataset underwent analysis employing Partial Least Squares Structural Equation Modeling (PLS-SEM) due to its inherent capacity to accommodate smaller sample sizes while delivering precise and insightful outcomes. The results indicate a strong positive relationship between intrinsic and extrinsic motivation and teacher performance in both types of institutions. Work experience moderates the connection between intrinsic motivation and performance in both sectors but has no significant impact on the relationship between extrinsic motivation and performance in private academic institutions. This study links a gap in the literature by empirically exploring the impact of teacher motivation on their performance and provides valuable insights into the complex interplay among motivation, work experience, and performance. Practically, it emphasizes the importance of employee motivation and accumulated work experience in enhancing performance. This study attempts to underscore the role of work experience as a moderating variable, thereby contributing to the novel discourse in the educational landscape of the post-pandemic era. The findings demand to identification of diverse organizational developmental drivers as work experience does not exhibit a strong mediation effect. However, limitations such as potential response bias should be considered in future research in this area.",<method>Partial Least Squares Structural Equation Modeling (PLS-SEM)</method>,No methods remaining
2024,https://openalex.org/W4395069357,Engineering,Characterizing land use/land cover change dynamics by an enhanced random forest machine learning model: a Google Earth Engine implementation,"Abstract Land use and land cover (LULC) analysis is crucial for understanding societal development and assessing changes during the Anthropocene era. Conventional LULC mapping faces challenges in capturing changes under cloud cover and limited ground truth data. To enhance the accuracy and comprehensiveness of the descriptions of LULC changes, this investigation employed a combination of advanced techniques. Specifically, multitemporal 30 m resolution Landsat-8 satellite imagery was utilized, in addition to the cloud computing capabilities of the Google Earth Engine (GEE) platform. Additionally, the study incorporated the random forest (RF) algorithm. This study aimed to generate continuous LULC maps for 2014 and 2020 for the Shrirampur area of Maharashtra, India. A novel multiple composite RF approach based on LULC classification was utilized to generate the final LULC classification maps utilizing the RF-50 and RF-100 tree models. Both RF models utilized seven input bands (B1 to B7) as the dataset for LULC classification. By incorporating these bands, the models were able to influence the spectral information captured by each band to classify the LULC categories accurately. The inclusion of multiple bands enhanced the discrimination capabilities of the classifiers, increasing the comprehensiveness of the assessment of the LULC classes. The analysis indicated that RF-100 exhibited higher training and validation/testing accuracy for 2014 and 2020 (0.99 and 0.79/0.80, respectively). The study further revealed that agricultural land, built-up land, and water bodies have changed adequately and have undergone substantial variation among the LULC classes in the study area. Overall, this research provides novel insights into the application of machine learning (ML) models for LULC mapping and emphasizes the importance of selecting the optimal tree combination for enhancing the accuracy and reliability of LULC maps based on the GEE and different RF tree models. The present investigation further enabled the interpretation of pixel-level LULC interactions while improving image classification accuracy and suggested the best models for the classification of LULC maps through the identification of changes in LULC classes.","<method>random forest (RF) algorithm</method>, <method>multiple composite RF approach</method>, <method>RF-50 tree model</method>, <method>RF-100 tree model</method>, <method>machine learning (ML) models</method>",<method>random forest (RF) algorithm</method>
2024,https://openalex.org/W4396656165,Engineering,Analysing LULC transformations using remote sensing data: insights from a multilayer perceptron neural network approach,"The study examines the complex dynamics of changes in LULC over three decades, focused on the years 1992, 2002, 2012, and 2022. The research highlights the significance of comprehending these alterations within the framework of environmental and socio-economic consequences. The changes in land use and land cover (LULC) have significant and far-reaching effects on ecosystems, biodiversity, and human livelihoods. This study offers useful information for politicians, conservationists, and urban planners by examining historical patterns and forecasting future changes. The study utilized a Multilayer Perceptron Neural Network (MLP-NN), a well-known machine learning technique that excels at collecting intricate patterns. This model's design had three layers: input, hidden, and output. The model underwent 10,000 iterations during its training process, and a thorough statistical analysis was conducted to assess the impact of each driving component. The MLP-NN model demonstrated impressive performance, with a skill measure of 0.8724 and an accuracy rate of 89.08%. The accuracy of the LULC estimates for 2022 was verified by comparing them with observed data, ensuring the model's reliability. Moreover, the presence of evidence likely was found to be a significant factor that had a substantial impact on the accuracy of the model. The study highlights the effectiveness of the MLP-NN model in accurately predicting changes in LULC. The model's exceptional accuracy and proficiency make it a powerful tool for future LULC forecasts. Identifying the primary causes of model performance and understanding their implications may help to enhance land management strategies, encourage spatial planning, guide accurate decision-making, and facilitate the development of policies that align with sustainable growth and development.",<method>Multilayer Perceptron Neural Network (MLP-NN)</method>,<method>Multilayer Perceptron Neural Network (MLP-NN)</method>
2024,https://openalex.org/W4399154552,Engineering,Seeking in Ride-on-Demand Service: A Reinforcement Learning Model With Dynamic Price Prediction,"Recent years witness the increasing popularity of ride-on-demand (RoD) services such as Uber and Didi. Compared with traditional taxi, RoD service is more ""data-driven"" and adopts dynamic pricing to manipulate the supply and demand in real time. Dynamic price could be viewed as an accurate and quantitative indicator of the supply and demand, and could provide clues to drivers, passengers, and the service providers, possibly reshaping the ways in which some problems are solved. In this paper, we focus on the seeking route recommendation problem that aims at increasing driver revenue by recommending highly profitable seeking routes to drivers of vacant cars with the help of dynamic prices. We first justify our motivation by showing the importance of route recommendation and answering why it is necessary to consider dynamic prices, based on the analysis of real service data. We then design a dynamic price prediction model to generate the dynamic prices at any given time and location based on multi-source urban data. After that, a reinforcement learning model is adopted to perform seeking route recommendation based on predicted dynamic prices. We conduct extensive experiments in different spatio-temporal combinations and make comparisons with multiple baselines. Results first show that our dynamic price prediction model achieves an accuracy ranging from 83.82% to 90.67% under different settings. It also proves that considering the real-time predicted dynamic prices significantly increases driver revenue by, for example, 12% and 47.5% during weekday evening rush hours, than merely using the average prices or completely ignoring dynamic prices.","<method>dynamic price prediction model</method>, <method>reinforcement learning model</method>",<method>reinforcement learning model</method>
2024,https://openalex.org/W4399734362,Engineering,Data oversampling and imbalanced datasets: an investigation of performance for machine learning and feature engineering,"Abstract The classification of imbalanced datasets is a prominent task in text mining and machine learning. The number of samples in each class is not uniformly distributed; one class contains a large number of samples while the other has a small number. Overfitting of the model occurs as a result of imbalanced datasets, resulting in poor performance. In this study, we compare different oversampling techniques like synthetic minority oversampling technique (SMOTE), support vector machine SMOTE (SVM-SMOTE), Border-line SMOTE, K-means SMOTE, and adaptive synthetic (ADASYN) oversampling to address the issue of imbalanced datasets and enhance the performance of machine learning models. Preprocessing significantly enhances the quality of input data by reducing noise, redundant data, and unnecessary data. This enables the machines to identify crucial patterns that facilitate the extraction of significant and pertinent information from the preprocessed data. This study preprocesses the data using various top-level preprocessing steps. Furthermore, two imbalanced Twitter datasets are used to compare the performance of oversampling techniques with six machine learning models including random forest (RF), SVM, K-nearest neighbor (KNN), AdaBoost (ADA), logistic regression (LR), and decision tree (DT). In addition, the bag of words (BoW) and term frequency and inverse document frequency (TF-IDF) features extraction approaches are used to extract features from the tweets. The experiments indicate that SMOTE and ADASYN perform much better than other techniques thus providing higher accuracy. Additionally, overall results show that SVM with ’linear’ kernel tends to attain the highest accuracy and recall score of 99.67% and 1.00% on ADASYN oversampled datasets and 99.57% accuracy on SMOTE oversampled dataset with TF-IDF features. The SVM model using 10-fold cross-validation experiments achieved 97.40 mean accuracy with a 0.008 standard deviation. Our approach achieved 2.62% greater accuracy as compared to other current methods.","<method>synthetic minority oversampling technique (SMOTE)</method>, <method>support vector machine SMOTE (SVM-SMOTE)</method>, <method>Border-line SMOTE</method>, <method>K-means SMOTE</method>, <method>adaptive synthetic (ADASYN) oversampling</method>, <method>random forest (RF)</method>, <method>SVM</method>, <method>K-nearest neighbor (KNN)</method>, <method>AdaBoost (ADA)</method>, <method>logistic regression (LR)</method>, <method>decision tree (DT)</method>",<method>synthetic minority oversampling technique (SMOTE)</method><method>Border-line SMOTE</method><method>K-means SMOTE</method><method>adaptive synthetic (ADASYN) oversampling</method><method>random forest (RF)</method><method>SVM</method><method>K-nearest neighbor (KNN)</method><method>AdaBoost (ADA)</method><method>logistic regression (LR)</method><method>decision tree (DT)</method>
2024,https://openalex.org/W4401437558,Engineering,Wind turbine gearbox reliability verification by multivariate Gaidai reliability method,"Reliability research is essential since WT (Wind turbines) are built to endure high wind and wave-induced stresses. Novel multivariate and 2D (bivariate) reliability methods presented in this investigation being conceived by authors to assist designers in accurately assessment of crucial stressors, acting inside key mechanical WT parts, such as gearbox and drivetrain. Current study made use of the recently created 2D modified Weibull-type approach. Since multivariate statistical analysis takes into consideration cross-correlations between various system components, it is more suited for design than univariate statistical analysis. To cross-validate 10-MW semi-submersible type FWT (i.e., Floating Wind Turbine) gearbox system failure or damage probability, forecasted by the multivariate Gaidai reliability methodology, current study employed 2D modified Weibull approach. Typical load types that FWTs and related parts are prone, include longitudinal, bending, twisting, and cyclic stresses. Stochastic nature of environmental loads, acting on FWTs in terms of windspeed, direction, shear, vorticity may cause excessive nonlinear structural dynamic effects, hence multivariate reliability analysis for FWT key components like gearbox and drivetrain is necessary. In this investigation dynamic, structural, aerodynamic, and control aspects of the FWT system had been modeled, using advanced numerical techniques – FWT drivetrain dynamics has been modeled utilizing SIMPACK (Multibody Simulation Method) software. Novel multivariate Gaidai risk assessment approach provided a reliable reliability evaluation for the coupled drivetrain's dynamics, given design return periods of interest. Weakness of bivariate approach has been highlighted, comprehensive solution has been presented in a form of novel multivariate reliability method.","<method>2D modified Weibull-type approach</method>, <method>multivariate Gaidai reliability methodology</method>, <method>multivariate reliability analysis</method>",No methods remaining
2024,https://openalex.org/W4390618081,Engineering,Making Sense of Machine Learning: A Review of Interpretation Techniques and Their Applications,"Transparency in AI models is essential for promoting human–AI collaboration and ensuring regulatory compliance. However, interpreting these models is a complex process influenced by various methods and datasets. This study presents a comprehensive overview of foundational interpretation techniques, meticulously referencing the original authors and emphasizing their pivotal contributions. Recognizing the seminal work of these pioneers is imperative for contextualizing the evolutionary trajectory of interpretation in the field of AI. Furthermore, this research offers a retrospective analysis of interpretation techniques, critically evaluating their inherent strengths and limitations. We categorize these techniques into model-based, representation-based, post hoc, and hybrid methods, delving into their diverse applications. Furthermore, we analyze publication trends over time to see how the adoption of advanced computational methods within various categories of interpretation techniques has shaped the development of AI interpretability over time. This analysis highlights a notable preference shift towards data-driven approaches in the field. Moreover, we consider crucial factors such as the suitability of these techniques for generating local or global insights and their compatibility with different data types, including images, text, and tabular data. This structured categorization serves as a guide for practitioners navigating the landscape of interpretation techniques in AI. In summary, this review not only synthesizes various interpretation techniques but also acknowledges the contributions of their original authors. By emphasizing the origins of these techniques, we aim to enhance AI model explainability and underscore the importance of recognizing biases, uncertainties, and limitations inherent in the methods and datasets. This approach promotes the ethical and practical use of interpretation insights, empowering AI practitioners, researchers, and professionals to make informed decisions when selecting techniques for responsible AI implementation in real-world scenarios.","<method>model-based methods</method>, <method>representation-based methods</method>, <method>post hoc methods</method>, <method>hybrid methods</method>, <method>data-driven approaches</method>",<method>model-based methods</method><method>representation-based methods</method><method>hybrid methods</method>
2024,https://openalex.org/W4390686423,Engineering,Real-life data-driven model predictive control for building energy systems comparing different machine learning models,"By considering forecasts and exploiting storage effects, model predictive control can achieve significant energy and cost savings in the building sector. However, due to the high individual modeling effort, model predictive control lacks practical applicability. For that reason, data-driven process models, approximating the system behavior based on measurements, have become increasingly popular in recent years. Still, scientific literature lacks consent about the most promising model types and efficient workflows to integrate different machine learning models into a model predictive controller. With this work, we present a workflow to provide efficient model predictive controllers based on measurement data automatically. The main idea is to translate different machine learning models into optimization syntax to enable efficient optimization with full access to gradients. We currently consider artificial neural networks, gaussian process regression, and simple linear regression process models. We use a generic model ontology to automatize the controller generation further and test the methodology on two real-life use cases. The first use case is the application of five office rooms with smart thermostat valves. The second use case is a test hall with an air handling unit and a concrete core activation. Using only two days of initial training data, we deploy controllers based on the different model types for six weeks in the offices and apply online learning to improve the models continuously. We observe only minor differences in controller performance despite the artificial neural networks showing the highest prediction accuracy. The second use case shows that the simple linear models require less controller tuning effort. Thus, for practical applications, we recommend linear regression models.","<method>model predictive control</method>, <method>artificial neural networks</method>, <method>gaussian process regression</method>, <method>linear regression</method>",<method>artificial neural networks</method><method>gaussian process regression</method><method>linear regression</method>
2024,https://openalex.org/W4391684052,Engineering,Enhancing MPPT performance for partially shaded photovoltaic arrays through backstepping control with Genetic Algorithm-optimized gains,"As the significance and complexity of solar panel performance, particularly at their maximum power point (MPP), continue to grow, there is a demand for improved monitoring systems. The presence of variable weather conditions in Maroua, including potential partial shadowing caused by cloud cover or urban buildings, poses challenges to the efficiency of solar systems. This study introduces a new approach to tracking the Global Maximum Power Point (GMPP) in photovoltaic systems within the context of solar research conducted in Cameroon. The system utilizes Genetic Algorithm (GA) and Backstepping Controller (BSC) methodologies. The Backstepping Controller (BSC) dynamically adjusts the duty cycle of the Single Ended Primary Inductor Converter (SEPIC) to align with the reference voltage of the Genetic Algorithm (GA) in Maroua's dynamic environment. This environment, characterized by intermittent sunlight and the impact of local factors and urban shadowing, affects the production of energy. The Genetic Algorithm is employed to enhance the efficiency of BSC gains in Maroua's solar environment. This optimization technique expedites the tracking process and minimizes oscillations in the GMPP. The adaptability of the learning algorithm to specific conditions improves energy generation, even in the challenging environment of Maroua. This study introduces a novel approach to enhance the efficiency of photovoltaic systems in Maroua, Cameroon, by tailoring them to the specific solar dynamics of the region. In terms of performance, our approach surpasses the INC-BSC, P&O-BSC, GA-BSC, and PSO-BSC methodologies. In practice, the stabilization period following shadowing typically requires fewer than three iterations. Additionally, our Maximum Power Point Tracking (MPPT) technology is based on the Global Maximum Power Point (GMPP) methodology, contrasting with alternative technologies that prioritize the Local Maximum Power Point (LMPP). This differentiation is particularly relevant in areas with partial shading, such as Maroua, where the use of LMPP-based technologies can result in power losses. The proposed method demonstrates significant performance by achieving a minimum 33% reduction in power losses.","<method>Genetic Algorithm (GA)</method>, <method>Backstepping Controller (BSC)</method>, <method>INC-BSC</method>, <method>P&O-BSC</method>, <method>GA-BSC</method>, <method>PSO-BSC</method>, <method>Maximum Power Point Tracking (MPPT) based on Global Maximum Power Point (GMPP) methodology</method>",<method>Genetic Algorithm (GA)</method>
2024,https://openalex.org/W4399685394,Engineering,Advanced Modelling of Soil Organic Carbon Content in Coal Mining Areas Using Integrated Spectral Analysis: A Dengcao Coal Mine Case Study,"Effective modelling and integrated spectral analysis approaches can advance modelling precision. To develop an integrated spectral forecast modelling of soil organic carbon (SOC), this research investigated a mining coal in Dengcao Coal Mine Area, Zhengzhou. The study utilizes the Lasso and Ranger algorithms were utilized in spectral band analysis. Four primary models employed during this process include Artificial Neural Network (ANN), Support Vector Machine, Random Forest (RF), and Partial Least Squares Regression (PLSR). The ideal model was chosen. The results showed that, in contrast to when band collection was based on Lasso algorithm modelling, model precision was higher when it was based on the Ranger algorithm. ANN model had an ideal goodness acceptance, and the modelling developed by RF showed the steadiest modelling consequences. Based on the results, a distinct method is proposed in this study for band assortment at the earlier stage of integrated spectral modelling of SOC. The Ranger method can be used to check the spectral particles, and RF or ANN can be chosen to develop the prediction modelling based on different statistics sets, which is appropriate to create the prediction modelling of SOC content in Dengcao Coal Mine Area. This research avails a position for the integrated spectral of Analysis for Advanced Modelling of Soil Organic Carbon Content in Coal Sources alongside a theoretical foundation for innovating portable device for the integrated spectral assessment of SOC content in coal mining habitats. This study might be significant for the changing modelling and monitoring of SOC in mining and environmental areas.","<method>Lasso</method>, <method>Ranger</method>, <method>Artificial Neural Network (ANN)</method>, <method>Support Vector Machine</method>, <method>Random Forest (RF)</method>, <method>Partial Least Squares Regression (PLSR)</method>",<method>Lasso</method><method>Artificial Neural Network (ANN)</method><method>Support Vector Machine</method><method>Random Forest (RF)</method>
2024,https://openalex.org/W4391359414,Engineering,Autopilot control unmanned aerial vehicle system for sewage defect detection using deep learning,"Abstract This work proposes the use of an unmanned aerial vehicle (UAV) with an autopilot to identify the defects present in municipal sewerage pipes. The framework also includes an effective autopilot control mechanism that can direct the flight path of a UAV within a sewer line. Both of these breakthroughs have been addressed throughout this work. The UAV's camera proved useful throughout a sewage inspection, providing important contextual data that helped analyze the sewerage line's internal condition. A plethora of information useful for understanding the sewerage line's inner functioning and extracting interior visual details can be obtained from camera‐recorded sewerage imagery if a defect is present. In the case of sewerage inspections, nevertheless, the impact of a false negative is significantly higher than that of a false positive. One of the trickiest parts of the procedure is identifying defective sewerage pipelines and false negatives. In order to get rid of the false negative outcome or false positive outcome, a guided image filter (GIF) is implemented in this proposed method during the pre‐processing stage. Afterwards, the algorithms Gabor transform (GT) and stroke width transform (SWT) were used to obtain the features of the UAV‐captured surveillance image. The UAV camera's sewerage image is then classified as “defective” or “not defective” using the obtained features by a Weighted Naive Bayes Classifier (WNBC). Next, images of the sewerage lines captured by the UAV are analyzed using speed‐up robust features (SURF) and deep learning to identify different types of defects. As a result, the proposed methodology achieved more favorable outcomes than prior existing approaches in terms of the following metrics: mean PSNR (71.854), mean MSE (0.0618), mean RMSE (0.2485), mean SSIM (98.71%), mean accuracy (98.372), mean specificity (97.837%), mean precision (93.296%), mean recall (94.255%), mean F1‐score (93.773%), and mean processing time (35.43 min).","<method>Weighted Naive Bayes Classifier (WNBC)</method>, <method>deep learning</method>",<method>Weighted Naive Bayes Classifier (WNBC)</method><method>deep learning</method>
2024,https://openalex.org/W4391092744,Engineering,DEA-Net: Single Image Dehazing Based on Detail-Enhanced Convolution and Content-Guided Attention,"Single image dehazing is a challenging ill-posed problem which estimates latent haze-free images from observed hazy images. Some existing deep learning based methods are devoted to improving the model performance via increasing the depth or width of convolution. The learning ability of Convolutional Neural Network (CNN) structure is still under-explored. In this paper, a Detail-Enhanced Attention Block (DEAB) consisting of Detail-Enhanced Convolution (DEConv) and Content-Guided Attention (CGA) is proposed to boost the feature learning for improving the dehazing performance. Specifically, the DEConv contains difference convolutions which can integrate prior information to complement the vanilla one and enhance the representation capacity. Then by using the re-parameterization technique, DEConv is equivalently converted into a vanilla convolution to reduce parameters and computational cost. By assigning the unique Spatial Importance Map (SIM) to every channel, CGA can attend more useful information encoded in features. In addition, a CGA-based mixup fusion scheme is presented to effectively fuse the features and aid the gradient flow. By combining above mentioned components, we propose our Detail-Enhanced Attention Network (DEA-Net) for recovering high-quality haze-free images. Extensive experimental results demonstrate the effectiveness of our DEA-Net, outperforming the state-of-the-art (SOTA) methods by boosting the PSNR index over 41 dB with only 3.653 M parameters. (The source code of our DEA-Net is available at https://github.com/cecret3350/DEA-Net.).","<method>Convolutional Neural Network (CNN)</method>, <method>Detail-Enhanced Attention Block (DEAB)</method>, <method>Detail-Enhanced Convolution (DEConv)</method>, <method>Content-Guided Attention (CGA)</method>, <method>re-parameterization technique</method>, <method>Spatial Importance Map (SIM)</method>, <method>CGA-based mixup fusion scheme</method>, <method>Detail-Enhanced Attention Network (DEA-Net)</method>",<method>Convolutional Neural Network (CNN)</method><method>re-parameterization technique</method>
2024,https://openalex.org/W4392367648,Engineering,Hardware implementation of memristor-based artificial neural networks,"Abstract Artificial Intelligence (AI) is currently experiencing a bloom driven by deep learning (DL) techniques, which rely on networks of connected simple computing units operating in parallel. The low communication bandwidth between memory and processing units in conventional von Neumann machines does not support the requirements of emerging applications that rely extensively on large sets of data. More recent computing paradigms, such as high parallelization and near-memory computing, help alleviate the data communication bottleneck to some extent, but paradigm- shifting concepts are required. Memristors, a novel beyond-complementary metal-oxide-semiconductor (CMOS) technology, are a promising choice for memory devices due to their unique intrinsic device-level properties, enabling both storing and computing with a small, massively-parallel footprint at low power. Theoretically, this directly translates to a major boost in energy efficiency and computational throughput, but various practical challenges remain. In this work we review the latest efforts for achieving hardware-based memristive artificial neural networks (ANNs), describing with detail the working principia of each block and the different design alternatives with their own advantages and disadvantages, as well as the tools required for accurate estimation of performance metrics. Ultimately, we aim to provide a comprehensive protocol of the materials and methods involved in memristive neural networks to those aiming to start working in this field and the experts looking for a holistic approach.","<method>deep learning (DL)</method>, <method>artificial neural networks (ANNs)</method>",<method>deep learning (DL)</method><method>artificial neural networks (ANNs)</method>
2024,https://openalex.org/W4400881081,Engineering,TransUNet: Rethinking the U-Net architecture design for medical image segmentation through the lens of transformers,"Medical image segmentation is crucial for healthcare, yet convolution-based methods like U-Net face limitations in modeling long-range dependencies. To address this, Transformers designed for sequence-to-sequence predictions have been integrated into medical image segmentation. However, a comprehensive understanding of Transformers' self-attention in U-Net components is lacking. TransUNet, first introduced in 2021, is widely recognized as one of the first models to integrate Transformer into medical image analysis. In this study, we present the versatile framework of TransUNet that encapsulates Transformers' self-attention into two key modules: (1) a Transformer encoder tokenizing image patches from a convolution neural network (CNN) feature map, facilitating global context extraction, and (2) a Transformer decoder refining candidate regions through cross-attention between proposals and U-Net features. These modules can be flexibly inserted into the U-Net backbone, resulting in three configurations: Encoder-only, Decoder-only, and Encoder+Decoder. TransUNet provides a library encompassing both 2D and 3D implementations, enabling users to easily tailor the chosen architecture. Our findings highlight the encoder's efficacy in modeling interactions among multiple abdominal organs and the decoder's strength in handling small targets like tumors. It excels in diverse medical applications, such as multi-organ segmentation, pancreatic tumor segmentation, and hepatic vessel segmentation. Notably, our TransUNet achieves a significant average Dice improvement of 1.06% and 4.30% for multi-organ segmentation and pancreatic tumor segmentation, respectively, when compared to the highly competitive nn-UNet, and surpasses the top-1 solution in the BrasTS2021 challenge. 2D/3D Code and models are available at https://github.com/Beckschen/TransUNet and https://github.com/Beckschen/TransUNet-3D, respectively.","<method>U-Net</method>, <method>Transformers</method>, <method>TransUNet</method>, <method>Transformer encoder</method>, <method>Transformer decoder</method>, <method>convolution neural network (CNN)</method>, <method>nn-UNet</method>",<method>U-Net</method><method>Transformers</method><method>TransUNet</method><method>Transformer encoder</method><method>Transformer decoder</method><method>convolution neural network (CNN)</method><method>nn-UNet</method>
2024,https://openalex.org/W4390587679,Engineering,"A Systematic Review and Meta-Analysis of Artificial Intelligence Tools in Medicine and Healthcare: Applications, Considerations, Limitations, Motivation and Challenges","Artificial intelligence (AI) has emerged as a transformative force in various sectors, including medicine and healthcare. Large language models like ChatGPT showcase AI’s potential by generating human-like text through prompts. ChatGPT’s adaptability holds promise for reshaping medical practices, improving patient care, and enhancing interactions among healthcare professionals, patients, and data. In pandemic management, ChatGPT rapidly disseminates vital information. It serves as a virtual assistant in surgical consultations, aids dental practices, simplifies medical education, and aids in disease diagnosis. A total of 82 papers were categorised into eight major areas, which are G1: treatment and medicine, G2: buildings and equipment, G3: parts of the human body and areas of the disease, G4: patients, G5: citizens, G6: cellular imaging, radiology, pulse and medical images, G7: doctors and nurses, and G8: tools, devices and administration. Balancing AI’s role with human judgment remains a challenge. A systematic literature review using the PRISMA approach explored AI’s transformative potential in healthcare, highlighting ChatGPT’s versatile applications, limitations, motivation, and challenges. In conclusion, ChatGPT’s diverse medical applications demonstrate its potential for innovation, serving as a valuable resource for students, academics, and researchers in healthcare. Additionally, this study serves as a guide, assisting students, academics, and researchers in the field of medicine and healthcare alike.","<method>Large language models</method>, <method>ChatGPT</method>, <method>systematic literature review using the PRISMA approach</method>",No methods remaining
2024,https://openalex.org/W4399657851,Engineering,Fusion of finite element and machine learning methods to predict rock shear strength parameters,"Abstract The trial-and-error method for calibrating rock mechanics parameters has the disadvantages of complexity, being time-consuming, and difficulty in ensuring accuracy. Harnessing the repeatability and scalability intrinsic to numerical simulation calculations and amalgamating them with the data-driven attributes of machine learning methods, this study uses the finite element analysis software RS2 to establish 252 sets of sandstone sample data. The recursive feature elimination and cross-validation method is employed for feature selection. The shear strength parameters of sandstone are predicted using machine learning models optimized by the particle swarm optimization (PSO) algorithm, including the backpropagation neural network, Bayesian ridge regression, support vector regression (SVR), and light gradient boosting machine. The predicted value of cohesion is proposed as the input feature to predict the friction angle. The results indicate that the optimal input characteristics for predicting cohesion are elastic modulus, Poisson's ratio, peak stress, and peak strain, while the optimal input characteristics for predicting friction angle are peak stress and cohesion. The PSO-SVR model demonstrates the best performance. The maximum error between the predicted values of cohesion and friction angle and the calculated results of RSData program are 3.5% and 4.31%, respectively. The finite element calculation is in good agreement with the stress–strain curve obtained in the laboratory. The sensitivity analysis indicates that SVR's prediction performance for cohesion and friction angle tends to be stable when the sample size is &amp;gt;25. These results offer a valuable reference for accurately predicting rock mechanics parameters.","<method>recursive feature elimination</method>, <method>cross-validation</method>, <method>particle swarm optimization (PSO)</method>, <method>backpropagation neural network</method>, <method>Bayesian ridge regression</method>, <method>support vector regression (SVR)</method>, <method>light gradient boosting machine</method>",<method>recursive feature elimination</method><method>backpropagation neural network</method><method>Bayesian ridge regression</method><method>support vector regression (SVR)</method><method>light gradient boosting machine</method>
2024,https://openalex.org/W4392611940,Engineering,Deep learning-based structural health monitoring,"This article provides a comprehensive review of deep learning-based structural health monitoring (DL-based SHM). It encompasses a broad spectrum of DL theories and applications including nondestructive approaches; computer vision-based methods, digital twins, unmanned aerial vehicles (UAVs), and their integration with DL; vibration-based strategies including sensor fault and data recovery methods; and physics-informed DL approaches. Connections between traditional machine learning and DL-based methods as well as relations of local to global approaches including their extensive integrations are established. The state-of-the-art methods, including their advantages and limitations are presented. The review draws on current literature on the topic, also providing a synergistic analysis leading to the understanding of the evolution of DL as a basis for presenting the future research and development needs. Our overall finding is that despite the rapid progression of digital technology along with the progression of DL, the DL-based SHM appears to be in its infant stages with enormous potential for future developments to bring the SHM technology to a common practical use with wide scope applications, performance reliability, cost, and degree of automation. It is anticipated that this review paper will serve as a basic resource for readers seeking comprehensive and holistic understanding of the subject matter.","<method>deep learning-based structural health monitoring (DL-based SHM)</method>, <method>deep learning (DL)</method>, <method>computer vision-based methods</method>, <method>digital twins</method>, <method>vibration-based strategies</method>, <method>sensor fault and data recovery methods</method>, <method>physics-informed deep learning (DL) approaches</method>, <method>traditional machine learning</method>, <method>local to global approaches</method>",<method>deep learning (DL)</method><method>physics-informed deep learning (DL) approaches</method>
2024,https://openalex.org/W4392872715,Engineering,GLC_FCS30D: the first global 30 m land-cover dynamics monitoring product with a fine classification system for the period from 1985 to 2022 generated using dense-time-series Landsat imagery and the continuous change-detection method,"Abstract. Land-cover change has been identified as an important cause or driving force of global climate change and is a significant research topic. Over the past few decades, global land-cover mapping has progressed; however, long-time-series global land-cover-change monitoring data are still sparse, especially those at 30 m resolution. In this study, we describe GLC_FCS30D, a novel global 30 m land-cover dynamics monitoring dataset containing 35 land-cover subcategories and covering the period 1985–2022 in 26 time steps (maps were updated every 5 years before 2000 and annually after 2000). GLC_FCS30D has been developed using continuous change detection and all available Landsat imagery based on the Google Earth Engine platform. Specifically, we first take advantage of the continuous change-detection model and the full time series of Landsat observations to capture the time points of changed pixels and identify the temporally stable areas. Then, we apply a spatiotemporal refinement method to derive the globally distributed and high-confidence training samples from these temporally stable areas. Next, local adaptive classification models are used to update the land-cover information for the changed pixels, and a temporal-consistency optimization algorithm is adopted to improve their temporal stability and suppress some false changes. Further, the GLC_FCS30D product is validated using 84 526 globally distributed validation samples from 2020. It achieves an overall accuracy of 80.88 % (±0.27 %) for the basic classification system (10 major land-cover types) and 73.04 % (±0.30 %) for the LCCS (Land Cover Classification System) level-1 validation system (17 LCCS land-cover types). Meanwhile, two third-party time-series datasets used for validation from the United States and Europe Union are also collected for analyzing accuracy variations, and the results show that GLC_FCS30D offers significant stability in terms of variation across the accuracy time series and achieves mean accuracies of 79.50 % (±0.50 %) and 81.91 % (±0.09 %) over the two regions. Lastly, we draw conclusions about the global land-cover-change information from the GLC_FCS30D dataset; namely, that forest and cropland variations have dominated global land-cover change over past 37 years, the net loss of forests reached about 2.5 million km2, and the net gain in cropland area is approximately 1.3 million km2. Therefore, the novel dataset GLC_FCS30D is an accurate land-cover-dynamics time-series monitoring product that benefits from its diverse classification system, high spatial resolution, and long time span (1985–2022); thus, it will effectively support global climate change research and promote sustainable development analysis. The GLC_FCS30D dataset is available via https://doi.org/10.5281/zenodo.8239305 (Liu et al., 2023).","<method>continuous change-detection model</method>, <method>spatiotemporal refinement method</method>, <method>local adaptive classification models</method>, <method>temporal-consistency optimization algorithm</method>",No methods remaining
2024,https://openalex.org/W4390706297,Engineering,TTST: A Top-<i>k</i> Token Selective Transformer for Remote Sensing Image Super-Resolution,"Transformer-based method has demonstrated promising performance in image super-resolution tasks, due to its long-range and global aggregation capability. However, the existing Transformer brings two critical challenges for applying it in large-area earth observation scenes: (1) redundant token representation due to most irrelevant tokens; (2) single-scale representation which ignores scale correlation modeling of similar ground observation targets. To this end, this paper proposes to adaptively eliminate the interference of irreverent tokens for a more compact self-attention calculation. Specifically, we devise a Residual Token Selective Group (RTSG) to grasp the most crucial token by dynamically selecting the top- <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> <tex-math notation=""LaTeX"">$k$ </tex-math></inline-formula> keys in terms of score ranking for each query. For better feature aggregation, a Multi-scale Feed-forward Layer (MFL) is developed to generate an enriched representation of multi-scale feature mixtures during feed-forward process. Moreover, we also proposed a Global Context Attention (GCA) to fully explore the most informative components, thus introducing more inductive bias to the RTSG for an accurate reconstruction. In particular, multiple cascaded RTSGs form our final Top- <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> <tex-math notation=""LaTeX"">$k$ </tex-math></inline-formula> Token Selective Transformer (TTST) to achieve progressive representation. Extensive experiments on simulated and real-world remote sensing datasets demonstrate our TTST could perform favorably against state-of-the-art CNN-based and Transformer-based methods, both qualitatively and quantitatively. In brief, TTST outperforms the state-of-the-art approach (HAT-L) in terms of PSNR by 0.14 dB on average, but only accounts for 47.26% and 46.97% of its computational cost and parameters. The code and pre-trained TTST will be available at <uri xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">https://github.com/XY-boy/TTST</uri> for validation.","<method>Transformer-based method</method>, <method>Residual Token Selective Group (RTSG)</method>, <method>Multi-scale Feed-forward Layer (MFL)</method>, <method>Global Context Attention (GCA)</method>, <method>Top-k Token Selective Transformer (TTST)</method>",<method>Transformer-based method</method><method>Global Context Attention (GCA)</method>
2024,https://openalex.org/W4393993191,Engineering,Generative AI for Customizable Learning Experiences,"The introduction of accessible generative artificial intelligence opens promising opportunities for the implementation of personalized learning methods in any educational environment. Personalized learning has been conceptualized for a long time, but it has only recently become realistic and truly achievable. In this paper, we propose an affordable and sustainable approach toward personalizing learning materials as part of the complete educational process. We have created a tool within a pre-existing learning management system at a software engineering college that automatically generates learning materials based on the learning outcomes provided by the professor for a particular class. The learning materials were composed in three distinct styles, the initial one being the traditional professor style and the other two variations adopting a pop-culture influence, namely Batman and Wednesday Addams. Each lesson, besides being delivered in three different formats, contained automatically generated multiple-choice questions that students could use to check their progress. This paper contains complete instructions for developing such a tool with the help of large language models using OpenAI’s API and an analysis of the preliminary experiment of its usage performed with the help of 20 college students studying software engineering at a European university. Participation in the study was optional and on voluntary basis. Each student’s tool usage was quantified, and two questionnaires were conducted: one immediately after subject completion and another 6 months later to assess both immediate and long-term effects, perceptions, and preferences. The results indicate that students found the multiple variants of the learning materials really engaging. While predominantly utilizing the traditional variant of the learning materials, they found this approach inspiring, would recommend it to other students, and would like to see it more in classes. The most popular feature were the automatically generated quiz-style tests that they used to assess their understanding. Preliminary evidence suggests that the use of various versions of learning materials leads to an increase in students’ study time, especially for students who have not mastered the topic otherwise. The study’s small sample size of 20 students restricts its ability to generalize its findings, but its results provide useful early insights and lay the groundwork for future research on AI-supported educational strategies.",<method>large language models</method>,No methods remaining
2024,https://openalex.org/W4399450035,Engineering,Power Hungry Processing: Watts Driving the Cost of AI Deployment?,"Recent years have seen a surge in the popularity of commercial AI products based on generative, multi-purpose AI systems promising a unified approach to building machine learning (ML) models into technology. However, this ambition of ""generality"" comes at a steep cost to the environment, given the amount of energy these systems require and the amount of carbon that they emit. In this work, we propose the first systematic comparison of the ongoing inference cost of various categories of ML systems, covering both task-specific (i.e. finetuned models that carry out a single task) and 'general-purpose' models, (i.e. those trained for multiple tasks). We measure deployment cost as the amount of energy and carbon required to perform 1,000 inferences on representative benchmark dataset using these models. We find that multi-purpose, generative architectures are orders of magnitude more expensive than task-specific systems for a variety of tasks, even when controlling for the number of model parameters. We conclude with a discussion around the current trend of deploying multi-purpose generative ML systems, and caution that their utility should be more intentionally weighed against increased costs in terms of energy and emissions. All the data from our study can be accessed via an interactive demo to carry out further exploration and analysis.","<method>finetuned models</method>, <method>multi-purpose generative architectures</method>",No methods remaining
2024,https://openalex.org/W4401070841,Engineering,Transformer-Based Visual Segmentation: A Survey,"Visual segmentation seeks to partition images, video frames, or point clouds into multiple segments or groups. This technique has numerous real-world applications, such as autonomous driving, image editing, robot sensing, and medical analysis. Over the past decade, deep learning-based methods have made remarkable strides in this area. Recently, transformers, a type of neural network based on self-attention originally designed for natural language processing, have considerably surpassed previous convolutional or recurrent approaches in various vision processing tasks. Specifically, vision transformers offer robust, unified, and even simpler solutions for various segmentation tasks. This survey provides a thorough overview of transformer-based visual segmentation, summarizing recent advancements. We first review the background, encompassing problem definitions, datasets, and prior convolutional methods. Next, we summarize a meta-architecture that unifies all recent transformer-based approaches. Based on this meta-architecture, we examine various method designs, including modifications to the meta-architecture and associated applications. We also present several specific subfields, including 3D point cloud segmentation, foundation model tuning, domain-aware segmentation, efficient segmentation, and medical segmentation. Additionally, we compile and re-evaluate the reviewed methods on several well-established datasets. Finally, we identify open challenges in this field and propose directions for future research. The project page can be found at <uri xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">https://github.com/lxtGH/Awesome-Segmentation-With-Transformer</uri> .","<method>deep learning-based methods</method>, <method>transformers</method>, <method>convolutional approaches</method>, <method>recurrent approaches</method>, <method>vision transformers</method>",<method>transformers</method><method>convolutional approaches</method><method>recurrent approaches</method><method>vision transformers</method>
2024,https://openalex.org/W4391974599,Engineering,"Generative AI for Transformative Healthcare: A Comprehensive Study of Emerging Models, Applications, Case Studies, and Limitations","Generative artificial intelligence (GAI) can be broadly described as an artificial intelligence system capable of generating images, text, and other media types with human prompts. GAI models like ChatGPT, DALL-E, and Bard have recently caught the attention of industry and academia equally. GAI applications span various industries like art, gaming, fashion, and healthcare. In healthcare, GAI shows promise in medical research, diagnosis, treatment, and patient care and is already making strides in real-world deployments. There has yet to be any detailed study concerning the applications and scope of GAI in healthcare. Addressing this research gap, we explore several applications, real-world scenarios, and limitations of GAI in healthcare. We examine how GAI models like ChatGPT and DALL-E can be leveraged to aid in the applications of medical imaging, drug discovery, personalized patient treatment, medical simulation and training, clinical trial optimization, mental health support, healthcare operations and research, medical chatbots, human movement simulation, and a few more applications. Along with applications, we cover four real-world healthcare scenarios that employ GAI: visual snow syndrome diagnosis, molecular drug optimization, medical education, and dentistry. We also provide an elaborate discussion on seven healthcare-customized LLMs like Med-PaLM, BioGPT, DeepHealth, etc.,Since GAI is still evolving, it poses challenges like the lack of professional expertise in decision making, risk of patient data privacy, issues in integrating with existing healthcare systems, and the problem of data bias which are elaborated on in this work along with several other challenges. We also put forward multiple directions for future research in GAI for healthcare.","<method>Generative artificial intelligence (GAI)</method>, <method>GAI models like ChatGPT</method>, <method>GAI models like DALL-E</method>, <method>healthcare-customized LLMs like Med-PaLM</method>, <method>healthcare-customized LLMs like BioGPT</method>, <method>healthcare-customized LLMs like DeepHealth</method>",<method>healthcare-customized LLMs like Med-PaLM</method><method>healthcare-customized LLMs like BioGPT</method>
2024,https://openalex.org/W4390837884,Engineering,The deep learning applications in IoT-based bio- and medical informatics: a systematic literature review,"Abstract Nowadays, machine learning (ML) has attained a high level of achievement in many contexts. Considering the significance of ML in medical and bioinformatics owing to its accuracy, many investigators discussed multiple solutions for developing the function of medical and bioinformatics challenges using deep learning (DL) techniques. The importance of DL in Internet of Things (IoT)-based bio- and medical informatics lies in its ability to analyze and interpret large amounts of complex and diverse data in real time, providing insights that can improve healthcare outcomes and increase efficiency in the healthcare industry. Several applications of DL in IoT-based bio- and medical informatics include diagnosis, treatment recommendation, clinical decision support, image analysis, wearable monitoring, and drug discovery. The review aims to comprehensively evaluate and synthesize the existing body of the literature on applying deep learning in the intersection of the IoT with bio- and medical informatics. In this paper, we categorized the most cutting-edge DL solutions for medical and bioinformatics issues into five categories based on the DL technique utilized: convolutional neural network , recurrent neural network , generative adversarial network , multilayer perception , and hybrid methods. A systematic literature review was applied to study each one in terms of effective properties, like the main idea, benefits, drawbacks, methods, simulation environment, and datasets. After that, cutting-edge research on DL approaches and applications for bioinformatics concerns was emphasized. In addition, several challenges that contributed to DL implementation for medical and bioinformatics have been addressed, which are predicted to motivate more studies to develop medical and bioinformatics research progressively. According to the findings, most articles are evaluated using features like accuracy, sensitivity, specificity, F -score, latency, adaptability, and scalability.","<method>convolutional neural network</method>, <method>recurrent neural network</method>, <method>generative adversarial network</method>, <method>multilayer perception</method>, <method>hybrid methods</method>",<method>convolutional neural network</method><method>recurrent neural network</method><method>generative adversarial network</method><method>hybrid methods</method>
2024,https://openalex.org/W4391018556,Engineering,Battery safety: Machine learning-based prognostics,"Lithium-ion batteries play a pivotal role in a wide range of applications, from electronic devices to large-scale electrified transportation systems and grid-scale energy storage. Nevertheless, they are vulnerable to both progressive aging and unexpected failures, which can result in catastrophic events such as explosions or fires. Given their expanding global presence, the safety of these batteries and potential hazards from serious malfunctions are now major public concerns. Over the past decade, scholars and industry experts are intensively exploring methods to monitor battery safety, spanning from materials to cell, pack and system levels and across various spectral, spatial, and temporal scopes. In this Review, we start by summarizing the mechanisms and nature of battery failures. Following this, we explore the intricacies in predicting battery system evolution and delve into the specialized knowledge essential for data-driven, machine learning models. We offer an exhaustive review spotlighting the latest strides in battery fault diagnosis and failure prognosis via an array of machine learning approaches. Our discussion encompasses: (1) supervised and reinforcement learning integrated with battery models, apt for predicting faults/failures and probing into failure causes and safety protocols at the cell level; (2) unsupervised, semi-supervised, and self-supervised learning, advantageous for harnessing vast data sets from battery modules/packs; (3) few-shot learning tailored for gleaning insights from scarce examples, alongside physics-informed machine learning to bolster model generalization and optimize training in data-scarce settings. We conclude by casting light on the prospective horizons of comprehensive, real-world battery prognostics and management.","<method>supervised learning</method>, <method>reinforcement learning</method>, <method>unsupervised learning</method>, <method>semi-supervised learning</method>, <method>self-supervised learning</method>, <method>few-shot learning</method>, <method>physics-informed machine learning</method>",<method>supervised learning</method><method>reinforcement learning</method><method>unsupervised learning</method><method>semi-supervised learning</method><method>self-supervised learning</method><method>few-shot learning</method><method>physics-informed machine learning</method>
2024,https://openalex.org/W4394018687,Engineering,"Exploring the synergies between collaborative robotics, digital twins, augmentation, and industry 5.0 for smart manufacturing: A state-of-the-art review","Industry 5.0 aims at establishing an inclusive, smart and sustainable production process that encourages human creativity and expertise by leveraging enhanced automation and machine intelligence. Collaborative robotics, or ""cobotics"",is a major enabling technology of Industry 5.0, which aspires at improving human dexterity by elevating robots to extensions of human capabilities and, ultimately, even as team members. A pivotal element that has the potential to operate as an interface for the teaming aspiration of Industry 5.0 is the adoption of novel technologies such as virtual reality (VR), augmented reality (AR), mixed reality (MR) and haptics, together known as ""augmentation"". Industry 5.0 also benefit from Digital Twins (DTs), which are digital representations of a physical assets that serves as their counterpart — or twins. Another essential component of Industry 5.0 is artificial intelligence (AI), which has the potential to create a more intelligent and efficient manufacturing process. In this study, a systematic review of the state of the art is presented to explore the synergies between cobots, DTs, augmentation, and Industry 5.0 for smart manufacturing. To the best of the author's knowledge, this is the first attempt in the literature to provide a comprehensive review of the synergies between the various components of Industry 5.0. This work aims at increasing the global efforts to realize the large variety of application possibilities offered by Industry 5.0 and to provide an up-to-date reference as a stepping-stone for new research and development within this field.",<method>artificial intelligence (AI)</method>,No methods remaining
2024,https://openalex.org/W4391385913,Engineering,Chained machine learning model for predicting load capacity and ductility of steel fiber–reinforced concrete beams,"Abstract One of the main issues associated with steel fiber–reinforced concrete (SFRC) beams is the ability to anticipate their flexural response. With a comprehensive grid search, several stacked models (i.e., chained, parallel) consisting of various machine learning (ML) algorithms and artificial neural networks (ANNs) were developed to predict the flexural response of SFRC beams. The flexural performance of SFRC beams under bending was assessed based on 193 experimental specimens from real‐life beam models. The ML techniques were applied to predict SFRC beam responses to bending load as functions of the steel fiber properties, concrete elastic modulus, beam dimensions, and reinforcement details. The accuracy of the models was evaluated using the coefficient of determination (), mean absolute error (MAE), and root mean square error (RMSE) of actual versus predicted values. The findings revealed that the proposed technique exhibited notably superior performance, delivering faster and more accurate predictions compared to both the ANNs and parallel models. Shapley diagrams were used to analyze variable contributions quantitatively. Shapley values show that the chained model prediction of ductility index is highly affected by two other targets (peak load and peak deflection) that show the chained algorithm utilizing the prediction of previous steps for enhancing the prediction of the target feature. The proposed model can be viewed as a function of significant input variables that permit the quick assessment of the likely performance of SFRC beams in bending.","<method>stacked models (chained)</method>, <method>stacked models (parallel)</method>, <method>machine learning (ML) algorithms</method>, <method>artificial neural networks (ANNs)</method>",<method>stacked models (chained)</method><method>artificial neural networks (ANNs)</method>
2024,https://openalex.org/W4391968719,Engineering,Artificial intelligence and IoT driven technologies for environmental pollution monitoring and management,"Detecting hazardous substances in the environment is crucial for protecting human wellbeing and ecosystems. As technology continues to advance, artificial intelligence (AI) has emerged as a promising tool for creating sensors that can effectively detect and analyze these hazardous substances. The increasing advancements in information technology have led to a growing interest in utilizing this technology for environmental pollution detection. AI-driven sensor systems, AI and Internet of Things (IoT) can be efficiently used for environmental monitoring, such as those for detecting air pollutants, water contaminants, and soil toxins. With the increasing concerns about the detrimental impact of legacy and emerging hazardous substances on ecosystems and human health, it is necessary to develop advanced monitoring systems that can efficiently detect, analyze, and respond to potential risks. Therefore, this review aims to explore recent advancements in using AI, sensors and IOTs for environmental pollution monitoring, taking into account the complexities of predicting and tracking pollution changes due to the dynamic nature of the environment. Integrating machine learning (ML) methods has the potential to revolutionize environmental science, but it also poses challenges. Important considerations include balancing model performance and interpretability, understanding ML model requirements, selecting appropriate models, and addressing concerns related to data sharing. Through examining these issues, this study seeks to highlight the latest trends in leveraging AI and IOT for environmental pollution monitoring.","<method>artificial intelligence (AI)</method>, <method>machine learning (ML) methods</method>",No methods remaining
2024,https://openalex.org/W4392386497,Engineering,Clinical applications of artificial intelligence in robotic surgery,"Abstract Artificial intelligence (AI) is revolutionizing nearly every aspect of modern life. In the medical field, robotic surgery is the sector with some of the most innovative and impactful advancements. In this narrative review, we outline recent contributions of AI to the field of robotic surgery with a particular focus on intraoperative enhancement. AI modeling is allowing surgeons to have advanced intraoperative metrics such as force and tactile measurements, enhanced detection of positive surgical margins, and even allowing for the complete automation of certain steps in surgical procedures. AI is also Query revolutionizing the field of surgical education. AI modeling applied to intraoperative surgical video feeds and instrument kinematics data is allowing for the generation of automated skills assessments. AI also shows promise for the generation and delivery of highly specialized intraoperative surgical feedback for training surgeons. Although the adoption and integration of AI show promise in robotic surgery, it raises important, complex ethical questions. Frameworks for thinking through ethical dilemmas raised by AI are outlined in this review. AI enhancements in robotic surgery is some of the most groundbreaking research happening today, and the studies outlined in this review represent some of the most exciting innovations in recent years.",<method>AI modeling</method>,No methods remaining
2024,https://openalex.org/W4396973073,Engineering,DA-TransUNet: integrating spatial and channel dual attention with transformer U-net for medical image segmentation,"Accurate medical image segmentation is critical for disease quantification and treatment evaluation. While traditional U-Net architectures and their transformer-integrated variants excel in automated segmentation tasks. Existing models also struggle with parameter efficiency and computational complexity, often due to the extensive use of Transformers. However, they lack the ability to harness the image’s intrinsic position and channel features. Research employing Dual Attention mechanisms of position and channel have not been specifically optimized for the high-detail demands of medical images. To address these issues, this study proposes a novel deep medical image segmentation framework, called DA-TransUNet, aiming to integrate the Transformer and dual attention block (DA-Block) into the traditional U-shaped architecture. Also, DA-TransUNet tailored for the high-detail requirements of medical images, optimizes the intermittent channels of Dual Attention (DA) and employs DA in each skip-connection to effectively filter out irrelevant information. This integration significantly enhances the model’s capability to extract features, thereby improving the performance of medical image segmentation. DA-TransUNet is validated in medical image segmentation tasks, consistently outperforming state-of-the-art techniques across 5 datasets. In summary, DA-TransUNet has made significant strides in medical image segmentation, offering new insights into existing techniques. It strengthens model performance from the perspective of image features, thereby advancing the development of high-precision automated medical image diagnosis. The codes and parameters of our model will be publicly available at https://github.com/SUN-1024/DA-TransUnet .","<method>U-Net architectures</method>, <method>Transformer-integrated variants</method>, <method>Dual Attention mechanisms</method>, <method>DA-TransUNet</method>",<method>U-Net architectures</method><method>Dual Attention mechanisms</method><method>DA-TransUNet</method>
2024,https://openalex.org/W4401819987,Engineering,"Artificial intelligence for geoscience: Progress, challenges and perspectives","Public summary•What does AI bring to geoscience? AI has been accelerating and deepening our understanding of Earth Systems in an unprecedented way, including the atmosphere, lithosphere, hydrosphere, cryosphere, biosphere, anthroposphere and the interactions between spheres.•What are the noteworthy challenges of AI in geoscience? As we embrace the huge potential of AI in geoscience, several challenges arise including reliability and interpretability, ethical issues, data security, and high demand and cost.•What is the future of AI in geoscience? The synergy between traditional principles and modern AI-driven techniques holds immense promise and will shape the trajectory of geoscience in upcoming years.AbstractThis paper explores the evolution of geoscientific inquiry, tracing the progression from traditional physics-based models to modern data-driven approaches facilitated by significant advancements in artificial intelligence (AI) and data collection techniques. Traditional models, which are grounded in physical and numerical frameworks, provide robust explanations by explicitly reconstructing underlying physical processes. However, their limitations in comprehensively capturing Earth's complexities and uncertainties pose challenges in optimization and real-world applicability. In contrast, contemporary data-driven models, particularly those utilizing machine learning (ML) and deep learning (DL), leverage extensive geoscience data to glean insights without requiring exhaustive theoretical knowledge. ML techniques have shown promise in addressing Earth science-related questions. Nevertheless, challenges such as data scarcity, computational demands, data privacy concerns, and the ""black-box"" nature of AI models hinder their seamless integration into geoscience. The integration of physics-based and data-driven methodologies into hybrid models presents an alternative paradigm. These models, which incorporate domain knowledge to guide AI methodologies, demonstrate enhanced efficiency and performance with reduced training data requirements. This review provides a comprehensive overview of geoscientific research paradigms, emphasizing untapped opportunities at the intersection of advanced AI techniques and geoscience. It examines major methodologies, showcases advances in large-scale models, and discusses the challenges and prospects that will shape the future landscape of AI in geoscience. The paper outlines a dynamic field ripe with possibilities, poised to unlock new understandings of Earth's complexities and further advance geoscience exploration.Graphical abstract","<method>machine learning (ML)</method>, <method>deep learning (DL)</method>, <method>hybrid models</method>",<method>machine learning (ML)</method><method>deep learning (DL)</method><method>hybrid models</method>
2024,https://openalex.org/W4398243924,Engineering,Optimizing renewable energy systems through artificial intelligence: Review and future prospects,"The global transition toward sustainable energy sources has prompted a surge in the integration of renewable energy systems (RES) into existing power grids. To improve the efficiency, reliability, and economic viability of these systems, the synergistic application of artificial intelligence (AI) methods has emerged as a promising avenue. This study presents a comprehensive review of the current state of research at the intersection of renewable energy and AI, highlighting key methodologies, challenges, and achievements. It covers a spectrum of AI utilizations in optimizing different facets of RES, including resource assessment, energy forecasting, system monitoring, control strategies, and grid integration. Machine learning algorithms, neural networks, and optimization techniques are explored for their role in complex data sets, enhancing predictive capabilities, and dynamically adapting RES. Furthermore, the study discusses the challenges faced in the implementation of AI in RES, such as data variability, model interpretability, and real-time adaptability. The potential benefits of overcoming these challenges include increased energy yield, reduced operational costs, and improved grid stability. The review concludes with an exploration of prospects and emerging trends in the field. Anticipated advancements in AI, such as explainable AI, reinforcement learning, and edge computing, are discussed in the context of their potential impact on optimizing RES. Additionally, the paper envisions the integration of AI-driven solutions into smart grids, decentralized energy systems, and the development of autonomous energy management systems. This investigation provides important insights into the current landscape of AI applications in RES.","<method>machine learning algorithms</method>, <method>neural networks</method>, <method>optimization techniques</method>, <method>explainable AI</method>, <method>reinforcement learning</method>",<method>neural networks</method><method>reinforcement learning</method>
2024,https://openalex.org/W4392931267,Engineering,Dynamic Event-Triggered Control for a Class of Uncertain Strict-Feedback Systems via an Improved Adaptive Neural Networks Backstepping Approach,"This article focuses on a dynamic event-triggered adaptive neural networks backstepping control for a class of uncertain strict-feedback systems with communication constraints. The uncertain terms including external disturbances and unknown nonlinear functions are approximated by radial basis function neural networks, in which the weight update laws are obtained via the gradient descent algorithm, ensuring the local boundedness of the approximation error of neural networks. Then, to enhance the transmission efficiency of control signals, a dynamic event-triggered mechanism is introduced, which enables the dynamic adjustment of threshold parameters in response to the actual tracking performance. It is strictly proved via the Lyapunov stability criterion that the tracking error can converge to a desired small neighborhood of the origin, and all signals in the closed-loop system are bounded. Finally, the validity of the control strategy is demonstrated through a simulation example. <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">Note to Practitioners</i> — In practical network control systems, control signals are typically transmitted continuously or periodically to devices through the communication network in the form of data packets. As communication networks are usually shared by various system nodes, and resources such as communication channel bandwidth and computational capabilities are limited, improving the transmission efficiency of control signals becomes a crucial design problem for controllers in network control systems. Therefore, This study introduces a control method via event-triggered sampling, aiming to enhance sampling efficiency while ensuring the stability and reliability of the system. The proposed control method is suitable for a broad category of strict-feedback nonlinear systems with communication constraints, offering notable advantages such as low-complexity design and straightforward implementation.","<method>radial basis function neural networks</method>, <method>gradient descent algorithm</method>",<method>radial basis function neural networks</method><method>gradient descent algorithm</method>
2024,https://openalex.org/W4391244205,Engineering,Research on the evolution of China's photovoltaic technology innovation network from the perspective of patents,"Photovoltaic (PV) technology, as a low-carbon energy technology, is crucial to mitigating climate change and achieving sustainable development. China has the largest total number of PV technology patents in the world, but the lack of core technologies has restricted the further innovative development of China's PV industry. Therefore, it is necessary to clarify China's current PV technology accumulation to better catch up with key technology areas. To clearly describe the structural characteristics of China's PV technology innovation network, this study uses China's patent PV technology data over the past 20 years from the Incopat global patent database and analyses the structural characteristics of the network from the perspectives of one-mode and two-mode networks, using method of social network analysis (SNA). The results show that 1) the leading PV enterprises have basically formed relatively stable internal collaborations and that the scale of innovation network development has expanded rapidly, with very strong stamina; 2) with the development of China's PV industry, many innovative PV techniques have been developed by leading enterprises in the field of innovation and research and development (R&D) of PV technology, and among patent applicants with strong collaboration, kinship collaboration with investment relationships is dominant; 3) provinces participating in PV technology innovation are increasing significantly, the network is more influenced by leading nodes, and the eastern coastal provinces are pioneers in the innovation and R&D of PV technology; and 4) PV technological innovation collaboration between patent applicants and cities has changed from local collaboration to cross-regional collaboration, high-value areas are basically concentrated in the eastern coastal region of China, with scattered spatial characteristics, and cross-regional collaboration presents a ""triangular"" spatial structure, with the Yangtze River Delta, Pearl River Delta, and Beijing-Tianjin-Hebei as cores. The conclusions can provide patent information support for scientific research on energy conservation and emission reduction to achieve low-carbon goals, and can also provide reference for policy formulation of renewable energy development and green development strategies.",<method>social network analysis (SNA)</method>,No methods remaining
2024,https://openalex.org/W4392503764,Engineering,Mental-LLM,"Advances in large language models (LLMs) have empowered a variety of applications. However, there is still a significant gap in research when it comes to understanding and enhancing the capabilities of LLMs in the field of mental health. In this work, we present a comprehensive evaluation of multiple LLMs on various mental health prediction tasks via online text data, including Alpaca, Alpaca-LoRA, FLAN-T5, GPT-3.5, and GPT-4. We conduct a broad range of experiments, covering zero-shot prompting, few-shot prompting, and instruction fine-tuning. The results indicate a promising yet limited performance of LLMs with zero-shot and few-shot prompt designs for mental health tasks. More importantly, our experiments show that instruction finetuning can significantly boost the performance of LLMs for all tasks simultaneously. Our best-finetuned models, Mental-Alpaca and Mental-FLAN-T5, outperform the best prompt design of GPT-3.5 (25 and 15 times bigger) by 10.9% on balanced accuracy and the best of GPT-4 (250 and 150 times bigger) by 4.8%. They further perform on par with the state-of-the-art task-specific language model. We also conduct an exploratory case study on LLMs' capability on mental health reasoning tasks, illustrating the promising capability of certain models such as GPT-4. We summarize our findings into a set of action guidelines for potential methods to enhance LLMs' capability for mental health tasks. Meanwhile, we also emphasize the important limitations before achieving deployability in real-world mental health settings, such as known racial and gender bias. We highlight the important ethical risks accompanying this line of research.","<method>zero-shot prompting</method>, <method>few-shot prompting</method>, <method>instruction fine-tuning</method>",<method>zero-shot prompting</method><method>few-shot prompting</method><method>instruction fine-tuning</method>
2024,https://openalex.org/W4392239564,Engineering,Human-AI collaboration patterns in AI-assisted academic writing,"Artificial Intelligence (AI) has increasingly influenced higher education, notably in academic writing where AI-powered assisting tools offer both opportunities and challenges. Recently, the rapid growth of generative AI (GAI) has brought its impacts into sharper focus, yet the dynamics of its utilisation in academic writing remain largely unexplored. This paper focuses on examining the nature of human-AI interactions in academic writing, specifically investigating the strategies doctoral students employ when collaborating with a GAI-powered assisting tool. This study involves 626 recorded activities on how ten doctoral students interact with GAI-powered assisting tool during academic writing. AI-driven learning analytics approach was adopted for three layered analyses: (1) data pre-processing and analysis with quantitative content analysis, (2) sequence analysis with Hidden Markov Model (HMM) and hierarchical sequence clustering, and (3) pattern analysis with process mining. Findings indicate that doctoral students engaging in iterative, highly interactive processes with the GAI-powered assisting tool generally achieve better performance in the writing task. In contrast, those who use GAI merely as a supplementary information source, maintaining a linear writing approach, tend to get lower writing performance. This study points to the need for further investigations into human-AI collaboration in learning in higher education, with implications for tailored educational strategies and solutions.","<method>AI-driven learning analytics</method>, <method>quantitative content analysis</method>, <method>Hidden Markov Model (HMM)</method>, <method>hierarchical sequence clustering</method>, <method>process mining</method>",<method>Hidden Markov Model (HMM)</method>
2024,https://openalex.org/W4393072087,Engineering,FI-NPI: Exploring Optimal Control in Parallel Platform Systems,"Typically, the current and speed loop closure of servo motor of the parallel platform is accomplished with incremental PI regulation. The control method has strong robustness, but the parameter tuning process is cumbersome, and it is difficult to achieve the optimal control state. In order to further optimize the performance, this paper proposes a double-loop control structure based on fuzzy integral and neuron proportional integral (FI-NPI). The structure makes full use of the control advantages of the fuzzy controller and integrator to improve the performance of speed closed-loop control. And through the feedforward branch, the speed error is used as the teacher signal for neuron supervised learning, which improves the effect of current closed-loop control. Through comparative simulation experiments, this paper verifies that the FI-NPI controller has a faster dynamic response speed than the traditional PI controller. Finally, in this paper, the FI-NPI controller is implemented in C language in the servo-driven lower computer, and the speed closed-loop test of the BLDC motor is carried out. The experimental results show that the FI-NPI double-loop controller is better than the traditional double-PI controller in performance indicators such as convergence rate and RMSE, which confirms that the FI-NPI double-loop controller is more suitable for BLDC servo control.","<method>fuzzy integral</method>, <method>neuron proportional integral (FI-NPI)</method>, <method>neuron supervised learning</method>",<method>fuzzy integral</method>
2024,https://openalex.org/W4399039179,Engineering,Distributed Event-Triggered Output-Feedback Time-Varying Formation Fault-Tolerant Control for Nonlinear Multi-Agent Systems,"This paper studies the event-triggered time-varying formation control problem for nonlinear multi-agent systems with actuator faults. Based on the neural network approximation technique, a neural observer is constructed to estimate the unmeasured states of systems. Then, a distributed adaptive event-triggered time-varying formation control manner is proposed utilizing the intermittent estimated states information from the agent and its neighbors. To overcome the problem that estimated states triggering leads to virtual control laws is non-differentiable, a distributed continuous control scheme under regular output-feedback is designed firstly, upon which a distributed event-triggered controller is constructed by replacing estimated states with intermittent estimated ones. It is shown that the designed event-triggered output-feedback time-varying formation fault-tolerant controller can compensate for actuator faults, and all signals in closed-loop systems are semi-globally uniformly ultimately bounded. Finally, simulation results of a practical example are given to verify the effectiveness of the proposed control manner. <italic xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">Note to Practitioners</i> —Formation control has broad application prospects in modern military and civilian fields, such as combat aircraft flying formation, satellite formation, autonomous vehicle formation, etc. In formation control systems, when agents occur actuator faults, it may break the original formation and even cause collision between agents. As a result, the security of formation control systems is facing great challenges in practical engineering applications. On the other hand, communication bandwidth is limited in practical engineering systems, and how to make systems quickly form formation under the limited communication bandwidth has become a key topic. Inspired by the above discussions, a distributed state-triggered output-feedback time-varying formation fault-tolerant control scheme is designed in this paper, in which actuator faults are compensated by using adaptive technology. Meanwhile, to sufficiently save the usage of system communication resources, a dual-channel event-triggered mechanism is designed.","<method>neural network approximation technique</method>, <method>neural observer</method>, <method>distributed adaptive event-triggered time-varying formation control</method>, <method>distributed continuous control scheme under regular output-feedback</method>, <method>distributed event-triggered controller</method>, <method>distributed state-triggered output-feedback time-varying formation fault-tolerant control scheme</method>, <method>adaptive technology</method>, <method>dual-channel event-triggered mechanism</method>",No methods remaining
2024,https://openalex.org/W4390770894,Engineering,"A review on microgrid optimization with meta-heuristic techniques: Scopes, trends and recommendation","Microgrids (MGs) use renewable sources to meet the growing demand for energy with increasing consumer needs and technological advancement. They operate independently as small-scale energy networks using distributed energy resources. However, the intermittent nature of renewable energy sources and poor power quality are essential operational problems that must be mitigated to improve the MG's performance. To address these challenges, researchers have introduced heuristic optimization mechanisms for MGs. However, local minima and the inability to find a global minimum in heuristic methods create errors in non-linear and nonconvex optimization, posing challenges in dealing with several operational aspects of MG such as energy management optimization, cost-effective dispatch, dependability, storage sizing, cyber-attack minimization, and grid integration. These challenges affect MG's performance by adding complexity to the management of storage capacity, cost minimization, reliability assurance, and balance of renewable sources, which accelerates the need for meta-heuristic optimization algorithms (MHOAs). This paper presents a state-of-the-art review of MHOAs and their role in improving the operational performance of MGs. Firstly, the fundamentals of MG optimization are discussed to explore the scopes, requisites, and opportunities of MHOAs in MG networks. Secondly, several MHOAs in the MG domain are described, and their recent trends in MG's techno-economic analysis, load forecasting, resiliency improvement, control operation, fault diagnosis, and energy management are summarized. The summary reveals that nearly 25% of the research in these areas utilizes the particle swarm optimization method, while the genetic and grey wolf algorithms are utilized by nearly 10% and 5% of the works studied in this paper, respectively, for optimizing the MG's performance. This result summarizes that MHOA presents a system-agnostic optimization approach, offering a new avenue for enhancing the effectiveness of future MGs. Finally, we highlight some challenges that emerge during the integration of MHOAs into MGs, potentially motivating researchers to conduct further studies in this area.","<method>particle swarm optimization</method>, <method>genetic algorithm</method>, <method>grey wolf algorithm</method>",<method>genetic algorithm</method><method>grey wolf algorithm</method>
2024,https://openalex.org/W4392465065,Engineering,A novel Swin transformer approach utilizing residual multi-layer perceptron for diagnosing brain tumors in MRI images,"Abstract Serious consequences due to brain tumors necessitate a timely and accurate diagnosis. However, obstacles such as suboptimal imaging quality, issues with data integrity, varying tumor types and stages, and potential errors in interpretation hinder the achievement of precise and prompt diagnoses. The rapid identification of brain tumors plays a pivotal role in ensuring patient safety. Deep learning-based systems hold promise in aiding radiologists to make diagnoses swiftly and accurately. In this study, we present an advanced deep learning approach based on the Swin Transformer. The proposed method introduces a novel Hybrid Shifted Windows Multi-Head Self-Attention module (HSW-MSA) along with a rescaled model. This enhancement aims to improve classification accuracy, reduce memory usage, and simplify training complexity. The Residual-based MLP (ResMLP) replaces the traditional MLP in the Swin Transformer, thereby improving accuracy, training speed, and parameter efficiency. We evaluate the Proposed-Swin model on a publicly available brain MRI dataset with four classes, using only test data. Model performance is enhanced through the application of transfer learning and data augmentation techniques for efficient and robust training. The Proposed-Swin model achieves a remarkable accuracy of 99.92%, surpassing previous research and deep learning models. This underscores the effectiveness of the Swin Transformer with HSW-MSA and ResMLP improvements in brain tumor diagnosis. This method introduces an innovative diagnostic approach using HSW-MSA and ResMLP in the Swin Transformer, offering potential support to radiologists in timely and accurate brain tumor diagnosis, ultimately improving patient outcomes and reducing risks.","<method>Deep learning-based systems</method>, <method>Swin Transformer</method>, <method>Hybrid Shifted Windows Multi-Head Self-Attention module (HSW-MSA)</method>, <method>Residual-based MLP (ResMLP)</method>, <method>transfer learning</method>, <method>data augmentation</method>",<method>Swin Transformer</method><method>Residual-based MLP (ResMLP)</method><method>transfer learning</method>
2024,https://openalex.org/W4394935921,Engineering,Machine learning-based predictive model for thermal comfort and energy optimization in smart buildings,"In the current context of energy transition and increasing climate change, optimizing building performance has become a critical objective. Efficient energy use and occupant comfort are paramount considerations in building design and operation. To address these challenges, this study introduces a predictive model leveraging Machine Learning (ML) algorithms. The model aims to predict thermal comfort levels and optimize energy consumption in Heating, Ventilation, and Air Conditioning (HVAC) systems. Four distinct ML algorithms Support Vector Machine (SVM), Artificial Neural Network (ANN), Random Forest (RF), and EXtreme Gradient Boosting (XGBOOST) are employed for this purpose. Data for the model is collected using a network of Raspberry Pi boards equipped with multiple sensors. Performance evaluation of the ML algorithms is conducted using statistical error metrics, including, Root Mean Square Error (RMSE), Mean Square Error (MSE), Mean Absolute Error (MAE), and coefficient of determination (R2). Results reveal that the RF and XGBOOST algorithms exhibit superior performance, achieving accuracies of 96.7% and 9.64% respectively. In contrast, the SVM algorithm demonstrates inferior performance with a R2 of 81.1%. These findings underscore the predictive capability of the RF and XGBOOST model in forecasting Predicted Mean Vote (PMV) values. The proposed model holds promise for enhancing occupant thermal comfort in buildings while simultaneously optimizing energy consumption in HVAC systems. Further research could explore the practical applications of these findings in building design and operation.","<method>Support Vector Machine (SVM)</method>, <method>Artificial Neural Network (ANN)</method>, <method>Random Forest (RF)</method>, <method>EXtreme Gradient Boosting (XGBOOST)</method>",<method>Support Vector Machine (SVM)</method><method>Artificial Neural Network (ANN)</method><method>Random Forest (RF)</method><method>EXtreme Gradient Boosting (XGBOOST)</method>
2024,https://openalex.org/W4391071215,Engineering,Automatic assessment of text-based responses in post-secondary education: A systematic review,"Text-based open-ended questions in academic formative and summative assessments help students become deep learners and prepare them to understand concepts for a subsequent conceptual assessment. However, grading text-based questions, especially in large (>50 enrolled students) courses, is tedious and time-consuming for instructors. Text processing models continue progressing with the rapid development of Artificial Intelligence (AI) tools and Natural Language Processing (NLP) algorithms. Especially after breakthroughs in Large Language Models (LLM), there is immense potential to automate rapid assessment and feedback of text-based responses in education. This systematic review adopts a scientific and reproducible literature search strategy based on the PRISMA process using explicit inclusion and exclusion criteria to study text-based automatic assessment systems in post-secondary education, screening 838 papers and synthesizing 93 studies. To understand how text-based automatic assessment systems have been developed and applied in education in recent years, three research questions are considered: 1) What types of automated assessment systems can be identified using input, output, and processing framework? 2) What are the educational focus and research motivations of studies with automated assessment systems? 3) What are the reported research outcomes in automated assessment systems and the next steps for educational applications? All included studies are summarized and categorized according to a proposed comprehensive framework, including the input and output of the system, research motivation, and research outcomes, aiming to answer the research questions accordingly. Additionally, the typical studies of automated assessment systems, research methods, and application domains in these studies are investigated and summarized. This systematic review provides an overview of recent educational applications of text-based assessment systems for understanding the latest AI/NLP developments assisting in text-based assessments in higher education. Findings will particularly benefit researchers and educators incorporating LLMs such as ChatGPT into their educational activities.","<method>Natural Language Processing (NLP) algorithms</method>, <method>Large Language Models (LLM)</method>",No methods remaining
2024,https://openalex.org/W4400020165,Engineering,"Big data, machine learning, and digital twin assisted additive manufacturing: A review","Additive manufacturing (AM) has undergone significant development over the past decades, resulting in vast amounts of data that carry valuable information. Numerous research studies have been conducted to extract insights from AM data and utilize it for optimizing various aspects such as the manufacturing process, supply chain, and real-time monitoring. Data integration into proposed digital twin frameworks and the application of machine learning techniques is expected to play pivotal roles in advancing AM in the future. In this paper, we provide an overview of machine learning and digital twin-assisted AM. On one hand, we discuss the research domain and highlight the machine-learning methods utilized in this field, including material analysis, design optimization, process parameter optimization, defect detection and monitoring, and sustainability. On the other hand, we examine the status of digital twin-assisted AM from the current research status to the technical approach and offer insights into future developments and perspectives in this area. This review paper aims to examine present research and development in the convergence of big data, machine learning, and digital twin-assisted AM. Although there are numerous review papers on machine learning for additive manufacturing and others on digital twins for AM, no existing paper has considered how these concepts are intrinsically connected and interrelated. Our paper is the first to integrate the three concepts big data, machine learning, and digital twins and propose a cohesive framework for how they can work together to improve the efficiency, accuracy, and sustainability of AM processes. By exploring latest advancements and applications within these domains, our objective is to emphasize the potential advantages and future possibilities associated with integration of these technologies in AM.",<method>machine learning</method>,<method>machine learning</method>
2024,https://openalex.org/W4390494339,Engineering,"A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection in Industrial Time Series: Methods, Applications, and Directions","Automating the monitoring of industrial processes has the potential to enhance efficiency and optimize quality by promptly detecting abnormal events and thus facilitating timely interventions. Deep learning, with its capacity to discern non-trivial patterns within large datasets, plays a pivotal role in this process. Standard deep learning methods are suitable to solve a specific task given a specific type of data. During training, deep learning demands large volumes of labeled data. However, due to the dynamic nature of the industrial processes and environment, it is impractical to acquire large-scale labeled data for standard deep learning training for every slightly different case anew. Deep transfer learning offers a solution to this problem. By leveraging knowledge from related tasks and accounting for variations in data distributions, the transfer learning framework solves new tasks with little or even no additional labeled data. The approach bypasses the need to retrain a model from scratch for every new setup and dramatically reduces the labeled data requirement. This survey first provides an in-depth review of deep transfer learning, examining the problem settings of transfer learning and classifying the prevailing deep transfer learning methods. Moreover, we delve into applications of deep transfer learning in the context of a broad spectrum of time series anomaly detection tasks prevalent in primary industrial domains, e.g., manufacturing process monitoring, predictive maintenance, energy management, and infrastructure facility monitoring. We discuss the challenges and limitations of deep transfer learning in industrial contexts and conclude the survey with practical directions and actionable suggestions to address the need to leverage diverse time series data for anomaly detection in an increasingly dynamic production environment.","<method>deep learning</method>, <method>standard deep learning methods</method>, <method>deep transfer learning</method>, <method>transfer learning framework</method>",<method>deep learning</method><method>deep transfer learning</method><method>transfer learning framework</method>
2024,https://openalex.org/W4393162950,Engineering,Predicting the thermal distribution in a convective wavy fin using a novel training physics-informed neural network method,"Abstract Fins are widely used in many industrial applications, including heat exchangers. They benefit from a relatively economical design cost, are lightweight, and are quite miniature. Thus, this study investigates the influence of a wavy fin structure subjected to convective effects with internal heat generation. The thermal distribution, considered a steady condition in one dimension, is described by a unique implementation of a physics-informed neural network (PINN) as part of machine-learning intelligent strategies for analyzing heat transfer in a convective wavy fin. This novel research explores the use of PINNs to examine the effect of the nonlinearity of temperature equation and boundary conditions by altering the hyperparameters of the architecture. The non-linear ordinary differential equation (ODE) involved with heat transfer is reduced into a dimensionless form utilizing the non-dimensional variables to simplify the problem. Furthermore, Runge–Kutta Fehlberg’s fourth–fifth order (RKF-45) approach is implemented to evaluate the simplified equations numerically. To predict the wavy fin's heat transfer properties, an advanced neural network model is created without using a traditional data-driven approach, the ability to solve ODEs explicitly by incorporating a mean squared error-based loss function. The obtained results divulge that an increase in the thermal conductivity variable upsurges the thermal distribution. In contrast, a decrease in temperature profile is caused due to the augmentation in the convective-conductive variable values.","<method>physics-informed neural network (PINN)</method>, <method>Runge–Kutta Fehlberg’s fourth–fifth order (RKF-45) approach</method>",<method>physics-informed neural network (PINN)</method>
2024,https://openalex.org/W4399326707,Engineering,Enhancing precision agriculture: A comprehensive review of machine learning and AI vision applications in all-terrain vehicle for farm automation,"The automation of all-terrain vehicles (ATVs) through the integration of advanced technologies such as machine learning (ML) and artificial intelligence (AI) vision has significantly changed precision agriculture. This paper aims to analyse and develop trends to provide comprehensive knowledge of the current state of ATV-based precision agriculture and the future possibilities of ML and AI. A bibliometric analysis was conducted through network diagram with keywords taken from previous publications in the domain. This review comprehensively analyses the potential of machine learning and artificial intelligence in transforming farming operations through the automation of tasks and the deployment of all-terrain vehicles. The research extensively analyses how machine learning methods have influenced several aspects of agricultural activities, such as planting, harvesting, spraying, weeding, crop monitoring, and others. AI vision systems are being researched for their ability to enhance precise and prompt decision-making in ATV-driven agricultural automation. These technologies have been thoroughly tested to show how they can improve crop yield, reducing overall investment, and make farming more efficient. Examples include machine learning-based seeding accuracy, AI-enabled crop health monitoring, and the use of AI vision for accurate pesticide application. The assessment examines challenges such as data privacy problems and scalability constraints, along with potential advancements and future prospects in the field. This will assist researchers and practitioners in making well-informed judgments regarding farming practices that are efficient, sustainable, and technologically robust.","<method>machine learning</method>, <method>artificial intelligence vision</method>, <method>machine learning methods</method>, <method>AI vision systems</method>, <method>machine learning-based seeding accuracy</method>, <method>AI-enabled crop health monitoring</method>, <method>AI vision for accurate pesticide application</method>",<method>machine learning</method>
2024,https://openalex.org/W4390604402,Engineering,A novel and dynamic land use/cover change research framework based on an improved PLUS model and a fuzzy multiobjective programming model,"Spatial reconstruction and scenario simulation of historical processes and future trends of land use/cover change (LUCC) can help to reveal the historical background of land conversion and the spatial distribution of future land. Moreover, there is a close relationship between the spatiotemporal dynamics of land use/cover and changes in different ecosystem services (ESs). Using this relationship to simulate future land use scenarios is important. In this study, an LUCC dynamic analysis framework (LSTM-PLUS-FMOP) was constructed based on a deep learning time series forecasting model (LSTM), a parallelized urban land use simulation (PLUS) model and a fuzzy multiobjective programming (FMOP) model. The PLUS model was used to analyze the driving mechanism of land expansion and explore the land conversion pattern. In addition, three land conversion scenarios were established: natural land expansion (NLE), economic development priority (EDP) and regional sustainable development (RSD). The FMOP model and the relationship between LUCC and ES were used to perform a spatial simulation of land conversion. The uncertainty parameters in the model were treated by intuitionistic fuzzy numbers (IFSs). This study applied the constructed framework to the Yellow River Basin of Shaanxi Province (YRB-SX). The results showed that (1) from 2000 to 2020, the cropland area of the YRB-SX continuously decreased by 12.67 × 104 ha, while the built-up area continuously increased by 28.25 × 104 ha. The net reduction in woodland and grassland area was 13.90 × 104 ha. (2) The relative error range of land prediction using the LSTM model was 0.0003– 0.0042. This model had better accuracy than the Markov chain prediction model. (3) The cropland area decreased by 0.26% (NLE), 0.85% (EDP) and 1.68% (RSD) under the three scenarios. The built-up area increased by 25.01%, 32.76% and 14.72%, respectively. The RSD scenario followed the principles of ecological protection and spatial constraints, which mitigated the degradation of the ecosystem to some extent. This coupled simulation framework will help to obtain land allocation schemes that meet the requirements of ecological protection and provide solutions for rational land management.","<method>LSTM</method>, <method>PLUS model</method>, <method>fuzzy multiobjective programming (FMOP) model</method>",<method>LSTM</method>
2024,https://openalex.org/W4391168980,Engineering,Utilizing Hybrid Machine Learning and Soft Computing Techniques for Landslide Susceptibility Mapping in a Drainage Basin,"The hydrological system of thebasin of Lake Urmia is complex, deriving its supply from a network comprising 13 perennial rivers, along withnumerous small springs and direct precipitation onto the lake’s surface. Among these contributors, approximately half of the inflow is attributed to the Zarrineh River and the Simineh River. Remarkably, Lake Urmia lacks a natural outlet, with its water loss occurring solely through evaporation processes. This study employed a comprehensive methodology integrating ground surveys, remote sensing analyses, and meticulous documentation of historical landslides within the basin as primary information sources. Through this investigative approach, we preciselyidentified and geolocated a total of 512 historical landslide occurrences across the Urmia Lake drainage basin, leveraging GPS technology for precision. Thisarticle introduces a suite of hybrid machine learning predictive models, such as support-vector machine (SVM), random forest (RF), decision trees (DT), logistic regression (LR), fuzzy logic (FL), and the technique for order of preference by similarity to the ideal solution (TOPSIS). These models were strategically deployed to assess landslide susceptibility within the region. The outcomes of the landslide susceptibility assessment reveal that the main high susceptible zones for landslide occurrence are concentrated in the northwestern, northern, northeastern, and some southern and southeastern areas of the region. Moreover, when considering the implementation of predictions using different algorithms, it became evident that SVM exhibited superior performance regardingboth accuracy (0.89) and precision (0.89), followed by RF, with and accuracy of 0.83 and a precision of 0.83. However, it is noteworthy that TOPSIS yielded the lowest accuracy value among the algorithms assessed.","<method>support-vector machine (SVM)</method>, <method>random forest (RF)</method>, <method>decision trees (DT)</method>, <method>logistic regression (LR)</method>, <method>fuzzy logic (FL)</method>, <method>technique for order of preference by similarity to the ideal solution (TOPSIS)</method>",<method>support-vector machine (SVM)</method><method>random forest (RF)</method><method>decision trees (DT)</method><method>logistic regression (LR)</method>
2024,https://openalex.org/W4391473457,Engineering,"“HOT” ChatGPT: The Promise of ChatGPT in Detecting and Discriminating Hateful, Offensive, and Toxic Comments on Social Media","Harmful textual content is pervasive on social media, poisoning online communities and negatively impacting participation. A common approach to this issue is developing detection models that rely on human annotations. However, the tasks required to build such models expose annotators to harmful and offensive content and may require significant time and cost to complete. Generative AI models have the potential to understand and detect harmful textual content. We used ChatGPT to investigate this potential and compared its performance with MTurker annotations for three frequently discussed concepts related to harmful textual content on social media: Hateful, Offensive, and Toxic (HOT). We designed five prompts to interact with ChatGPT and conducted four experiments eliciting HOT classifications. Our results show that ChatGPT can achieve an accuracy of approximately 80% when compared to MTurker annotations. Specifically, the model displays a more consistent classification for non-HOT comments than HOT comments compared to human annotations. Our findings also suggest that ChatGPT classifications align with the provided HOT definitions. However, ChatGPT classifies “hateful” and “offensive” as subsets of “toxic.” Moreover, the choice of prompts used to interact with ChatGPT impacts its performance. Based on these insights, our study provides several meaningful implications for employing ChatGPT to detect HOT content, particularly regarding the reliability and consistency of its performance, its understanding and reasoning of the HOT concept, and the impact of prompts on its performance. Overall, our study provides guidance on the potential of using generative AI models for moderating large volumes of user-generated textual content on social media.","<method>Generative AI models</method>, <method>ChatGPT</method>",No methods remaining
2024,https://openalex.org/W4391558404,Engineering,Exploring the Potential of ChatGPT in Automated Code Refinement: An Empirical Study,"Code review is an essential activity for ensuring the quality and maintainability of software projects. However, it is a time-consuming and often error-prone task that can significantly impact the development process. Recently, ChatGPT, a cutting-edge language model, has demonstrated impressive performance in various natural language processing tasks, suggesting its potential to automate code review processes. However, it is still unclear how well ChatGPT performs in code review tasks. To fill this gap, in this paper, we conduct the first empirical study to understand the capabilities of ChatGPT in code review tasks, specifically focusing on automated code refinement based on given code reviews. To conduct the study, we select the existing benchmark CodeReview and construct a new code review dataset with high quality. We use CodeReviewer, a state-of-the-art code review tool, as a baseline for comparison with ChatGPT. Our results show that ChatGPT outperforms CodeReviewer in code refinement tasks. Specifically, our results show that ChatGPT achieves higher EM and BLEU scores of 22.78 and 76.44 respectively, while the state-of-the-art method achieves only 15.50 and 62.88 on a high-quality code review dataset. We further identify the root causes for ChatGPT's underperformance and propose several strategies to mitigate these challenges. Our study provides insights into the potential of ChatGPT in automating the code review process, and highlights the potential research directions.","<method>ChatGPT</method>, <method>CodeReviewer</method>",No methods remaining
2024,https://openalex.org/W4391831565,Engineering,Comparison of Random Forest and XGBoost Classifiers Using Integrated Optical and SAR Features for Mapping Urban Impervious Surface,"The integration of optical and SAR datasets through ensemble machine learning models shows promising results in urban remote sensing applications. The integration of multi-sensor datasets enhances the accuracy of information extraction. This research presents a comparison of two ensemble machine learning classifiers (random forest and extreme gradient boost (XGBoost)) classifiers using an integration of optical and SAR features and simple layer stacking (SLS) techniques. Therefore, Sentinel-1 (SAR) and Landsat 8 (optical) datasets were used with SAR textures and enhanced modified indices to extract features for the year 2023. The classification process utilized two machine learning algorithms, random forest and XGBoost, for urban impervious surface extraction. The study focused on three significant East Asian cities with diverse urban dynamics: Jakarta, Manila, and Seoul. This research proposed a novel index called the Normalized Blue Water Index (NBWI), which distinguishes water from other features and was utilized as an optical feature. Results showed an overall accuracy of 81% for UIS classification using XGBoost and 77% with RF while classifying land use land cover into four major classes (water, vegetation, bare soil, and urban impervious). However, the proposed framework with the XGBoost classifier outperformed the RF algorithm and Dynamic World (DW) data product and comparatively showed higher classification accuracy. Still, all three results show poor separability with bare soil class compared to ground truth data. XGBoost outperformed random forest and Dynamic World in classification accuracy, highlighting its potential use in urban remote sensing applications.","<method>ensemble machine learning models</method>, <method>random forest</method>, <method>extreme gradient boost (XGBoost)</method>, <method>simple layer stacking (SLS)</method>",<method>ensemble machine learning models</method><method>random forest</method><method>extreme gradient boost (XGBoost)</method>
2024,https://openalex.org/W4392543906,Engineering,A Multilevel Multimodal Fusion Transformer for Remote Sensing Semantic Segmentation,"Accurate semantic segmentation of remote sensing data plays a crucial role in the success of geoscience research and applications. Recently, multimodal fusion-based segmentation models have attracted much attention due to their outstanding performance as compared to conventional single-modal techniques. However, most of these models perform their fusion operation using convolutional neural networks (CNN) or the vision transformer (Vit), resulting in insufficient local-global contextual modeling and representative capabilities. In this work, a multilevel multimodal fusion scheme called FTransUNet is proposed to provide a robust and effective multimodal fusion backbone for semantic segmentation by integrating both CNN and Vit into one unified fusion framework. Firstly, the shallow-level features are first extracted and fused through convolutional layers and shallow-level feature fusion (SFF) modules. After that, deep-level features characterizing semantic information and spatial relationships are extracted and fused by a well-designed Fusion Vit (FVit). It applies Adaptively Mutually Boosted Attention (Ada-MBA) layers and Self-Attention (SA) layers alternately in a three-stage scheme to learn cross-modality representations of high inter-class separability and low intra-class variations. Specifically, the proposed Ada-MBA computes SA and Cross-Attention (CA) in parallel to enhance intra- and cross-modality contextual information simultaneously while steering attention distribution towards semantic-aware regions. As a result, FTransUNet can fuse shallow-level and deep-level features in a multilevel manner, taking full advantage of CNN and transformer to accurately characterize local details and global semantics, respectively. Extensive experiments confirm the superior performance of the proposed FTransUNet compared with other multimodal fusion approaches on two fine-resolution remote sensing datasets, namely ISPRS Vaihingen and Potsdam. The source code in this work is available at https://github.com/sstary/SSRS.","<method>convolutional neural networks (CNN)</method>, <method>vision transformer (Vit)</method>, <method>FTransUNet</method>, <method>shallow-level feature fusion (SFF) modules</method>, <method>Fusion Vit (FVit)</method>, <method>Adaptively Mutually Boosted Attention (Ada-MBA) layers</method>, <method>Self-Attention (SA) layers</method>, <method>Cross-Attention (CA)</method>",<method>convolutional neural networks (CNN)</method><method>vision transformer (Vit)</method><method>Self-Attention (SA) layers</method><method>Cross-Attention (CA)</method>
2024,https://openalex.org/W4392627614,Engineering,How to conduct a bibliometric content analysis: Guidelines and contributions of content co‐occurrence or co‐word literature reviews,"Abstract Literature reviews summarize existing literature, uncover research gaps, and offer future research directions, thus aiding in theoretical and methodological development. Informetric research including bibliometric, scientometric, webometric, cybermetric, patentometric, and altmetric methods are becoming increasingly prevalent in conducting literature review studies. Looking at the common informetric literature review methods—citation, co‐citation, co‐author, bibliographic coupling, and content co‐occurrence analyses, this study aims to serve as a guide in using content co‐occurrence also known as co‐word analysis to conduct literature reviews. This study outlines a variety of informetric research methods and how they are utilized to conduct review and evidence‐based conceptual studies. In addition to the analyses, the study highlights different informetric software packages like Bibliometrix, Biblioshiny, Leximancer, NVivo, and CiteSpace including their comparison. The study further discusses contributions of algorithm‐based content analyses including offering taxonomies, definitions, classifications, typologies, comparisons, and theoretical development to constitute integrative literature reviews. Finally, this study offers step‐by‐step guidelines for conducting a review study using VOSviewer content co‐occurrence analysis while providing a systems view of informetric research in social science. The study also notes the emergence of generative artificial intelligence (AI) like Open AI's ChatGPT, Google's Bard, Elicit, Scite, Research Rabbit, and ChatPDF among others, and its potential in contributing to the literature review methods and, as such, being an interesting direction for future research.","<method>content co‐occurrence analysis (co‐word analysis)</method>, <method>algorithm‐based content analyses</method>, <method>generative artificial intelligence (AI)</method>",No methods remaining
2024,https://openalex.org/W4390584313,Engineering,A Conceptual Model for Inclusive Technology: Advancing Disability Inclusion through Artificial Intelligence,"Artificial intelligence (AI) has ushered in transformative changes, championing inclusion and accessibility for individuals with disabilities. This article delves into the remarkable AI-driven solutions that have revolutionized their lives across various domains. From assistive technologies such as voice recognition and AI-powered smart glasses catering to diverse needs, to healthcare benefiting from early disease detection algorithms and wearable devices that monitor vital signs and alert caregivers in emergencies, AI has steered in significant enhancements. Moreover, AI-driven prosthetics and exoskeletons have substantially improved mobility for those with limb impairments. The realm of education has not been left untouched, with AI tools creating inclusive learning environments that adapt to individual learning styles, paving the way for academic success among students with disabilities. However, the boundless potential of AI also presents ethical concerns and challenges. Issues like safeguarding data privacy, mitigating algorithmic bias, and bridging the digital divide must be thoughtfully addressed to fully harness AI’s potential in empowering individuals with disabilities. To complement these achievements, a robust conceptual model for AI disability inclusion serves as the theoretical framework, guiding the development of tailored AI solutions. By striking a harmonious balance between innovation and ethics, AI has the power to significantly enhance the overall quality of life for individuals with disabilities across a spectrum of vital areas.","<method>voice recognition</method>, <method>early disease detection algorithms</method>",No methods remaining
2024,https://openalex.org/W4390511794,Engineering,Firefly algorithm based WSN-IoT security enhancement with machine learning for intrusion detection,"Abstract A Wireless Sensor Network (WSN) aided by the Internet of Things (IoT) is a collaborative system of WSN systems and IoT networks are work to exchange, gather, and handle data. The primary objective of this collaboration is to enhance data analysis and automation to facilitate improved decision-making. Securing IoT with the assistance of WSN necessitates the implementation of protective measures to confirm the safety and reliability of the interconnected WSN and IoT components. This research significantly advances the current state of the art in IoT and WSN security by synergistically harnessing the potential of machine learning and the Firefly Algorithm. The contributions of this work are twofold: firstly, the proposed FA-ML technique exhibits an exceptional capability to enhance intrusion detection accuracy within the WSN-IoT landscape. Secondly, the amalgamation of the Firefly Algorithm and machine learning introduces a novel dimension to the domain of security-oriented optimization techniques. The implications of this research resonate across various sectors, ranging from critical infrastructure protection to industrial automation and beyond, where safeguarding the integrity of interconnected systems are of paramount importance. The amalgamation of cutting-edge machine learning and bio-inspired algorithms marks a pivotal step forward in crafting robust and intelligent security measures for the evolving landscape of IoT-driven technologies. For intrusion detection in the WSN-IoT, the FA-ML method employs a support vector machine (SVM) machine model for classification with parameter tuning accomplished using a Grey Wolf Optimizer (GWO) algorithm. The experimental evaluation is simulated using NSL-KDD Dataset, revealing the remarkable enhancement of the FA-ML technique, achieving a maximum accuracy of 99.34%. In comparison, the KNN-PSO and XGBoost models achieved lower accuracies of 96.42% and 95.36%, respectively. The findings validate the potential of the FA-ML technique as an active security solution for WSN-IoT systems, harnessing the power of machine learning and the Firefly Algorithm to bolster intrusion detection capabilities.","<method>Firefly Algorithm</method>, <method>machine learning</method>, <method>FA-ML technique</method>, <method>support vector machine (SVM)</method>, <method>Grey Wolf Optimizer (GWO)</method>, <method>KNN-PSO</method>, <method>XGBoost</method>",<method>Firefly Algorithm</method><method>machine learning</method><method>support vector machine (SVM)</method><method>Grey Wolf Optimizer (GWO)</method><method>XGBoost</method>
2024,https://openalex.org/W4391512775,Engineering,Peak and ultimate stress-strain model of confined ultra-high-performance concrete (UHPC) using hybrid machine learning model with conditional tabular generative adversarial network,"Ultra-high-performance concrete (UHPC) has gained prominence owing to its exceptional physical and mechanical properties and improved sustainability, making it ideal for large-scale structural applications. While numerous analytical studies have focused on predicting the stress-strain response of unconfined UHPC, there remains a lack of a reliable model for predicting the stress-strain response of confined UHPC, which poses challenges to efficient design and broader adoption, particularly in seismically active regions. To bridge this gap, the present study introduces a framework that implements machine learning (ML) models augmented by a state-of-the-art conditional tabular generative adversarial network (CTGAN) and Optuna, which a next-generation optimization framework, to accurately predict the peak and ultimate axial stress-strain responses of UHPC confined with either normal-strength steel or high-strength steel. The Optuna-optimized CTGAN is employed to address the issue of limited data by generating synthetic datasets of hypothetical confined UHPC specimens. A comprehensive database of confined UHPC stress-strain responses was compiled from existing literature and used to condition the CTGAN. The augmented database is then leveraged to develop a hybrid ML model that integrates extreme gradient boosting, gradient boosting machine, support vector regression, and K-nearest neighbors for predicting peak and ultimate stress-strain responses of confined UHPC. The predictive accuracy of the proposed hybrid ML model is evaluated and compared with a diverse set of ML models of varying complexity, and the results demonstrate its superior performance in predicting the peak and ultimate stress-strain response of confined UHPC. Furthermore, a graphical user interface of the proposed model is developed to facilitate its practical implementation and provide a rapid, autonomous, and accurate prediction of the stress-strain response of confined UHPC at both peak and ultimate states.","<method>conditional tabular generative adversarial network (CTGAN)</method>, <method>Optuna</method>, <method>extreme gradient boosting</method>, <method>gradient boosting machine</method>, <method>support vector regression</method>, <method>K-nearest neighbors</method>",<method>conditional tabular generative adversarial network (CTGAN)</method><method>extreme gradient boosting</method><method>gradient boosting machine</method><method>support vector regression</method><method>K-nearest neighbors</method>
2024,https://openalex.org/W4392462461,Engineering,Sentiment Analysis in the Age of Generative AI,"Abstract In the rapidly advancing age of Generative AI, Large Language Models (LLMs) such as ChatGPT stand at the forefront of disrupting marketing practice and research. This paper presents a comprehensive exploration of LLMs’ proficiency in sentiment analysis, a core task in marketing research for understanding consumer emotions, opinions, and perceptions. We benchmark the performance of three state-of-the-art LLMs, i.e., GPT-3.5, GPT-4, and Llama 2, against established, high-performing transfer learning models. Despite their zero-shot nature, our research reveals that LLMs can not only compete with but in some cases also surpass traditional transfer learning methods in terms of sentiment classification accuracy. We investigate the influence of textual data characteristics and analytical procedures on classification accuracy, shedding light on how data origin, text complexity, and prompting techniques impact LLM performance. We find that linguistic features such as the presence of lengthy, content-laden words improve classification performance, while other features such as single-sentence reviews and less structured social media text documents reduce performance. Further, we explore the explainability of sentiment classifications generated by LLMs. The findings indicate that LLMs, especially Llama 2, offer remarkable classification explanations, highlighting their advanced human-like reasoning capabilities. Collectively, this paper enriches the current understanding of sentiment analysis, providing valuable insights and guidance for the selection of suitable methods by marketing researchers and practitioners in the age of Generative AI.","<method>Large Language Models (LLMs)</method>, <method>GPT-3.5</method>, <method>GPT-4</method>, <method>Llama 2</method>, <method>transfer learning models</method>",<method>GPT-3.5</method><method>GPT-4</method><method>Llama 2</method><method>transfer learning models</method>
2024,https://openalex.org/W4393001808,Engineering,Multi-Source and Multi-modal Deep Network Embedding for Cross-Network Node Classification,"In recent years, to address the issue of networked data sparsity in node classification tasks, cross-network node classification (CNNC) leverages the richer information from a source network to enhance the performance of node classification in the target network, which typically has sparser information. However, in real-world applications, labeled nodes may be collected from multiple sources with multiple modalities (e.g., text, vision, and video). Naive application of single-source and single-modal CNNC methods may result in sub-optimal solutions. To this end, in this article, we propose a model called Multi-source and Multi-modal Cross-network Deep Network Embedding (M 2 CDNE) for cross-network node classification. In M 2 CDNE, we propose a deep multi-modal network embedding approach that combines the extracted deep multi-modal features to make the node vector representations network invariant. In addition, we apply dynamic adversarial adaptation to assess the significance of marginal and conditional probability distributions between each source and target network to make node vector representations label discriminative. Furthermore, we devise to classify nodes in the target network through the related source classifier and aggregate different predictions utilizing respective network weights, corresponding to the discrepancy between each source and target network. Extensive experiments performed on real-world datasets demonstrate that the proposed M 2 CDNE significantly outperforms the state-of-the-art approaches.","<method>cross-network node classification (CNNC)</method>, <method>Multi-source and Multi-modal Cross-network Deep Network Embedding (M2CDNE)</method>, <method>deep multi-modal network embedding</method>, <method>dynamic adversarial adaptation</method>",<method>deep multi-modal network embedding</method>
2024,https://openalex.org/W4390533101,Engineering,A vehicular network based intelligent transport system for smart cities using machine learning algorithms,"Abstract Smart cities and the Internet of Things have enabled the integration of communicating devices for efficient decision-making. Notably, traffic congestion is one major problem faced by daily commuters in urban cities. In developed countries, specialized sensors are deployed to gather traffic information to predict traffic patterns. Any traffic updates are shared with the commuters via the Internet. Such solutions become impracticable when physical infrastructure and Internet connectivity are either non-existent or very limited. In case of developing countries, no roadside units are available and Internet connectivity is still an issue in remote areas. Internet traffic analysis is a thriving field of study due to the myriad ways in which it may be put to practical use. In the intelligent Internet-of-Vehicles (IOVs), traffic congestion can be predicted and identified using cutting-edge technologies. Using tree-based decision-tree, random-forest, extra-tree, and XGBoost machine learning (ML) strategies, this research proposes an intelligent-transport-system for the IOVs-based vehicular network traffic in a smart city set-up. The suggested system uses ensemble learning and averages the selection of crucial features to give high detection accuracy at minimal computational costs, as demonstrated by the simulation results. For IOV-based vehicular network traffic, the tree-based ML approaches with feature-selection (FS) outperformed those without FS. When contrasted to the lowest KNN accuracy of 96.6% and the highest SVM accuracy of 98.01%, the Stacking approach demonstrates superior accuracy as 99.05%.","<method>decision-tree</method>, <method>random-forest</method>, <method>extra-tree</method>, <method>XGBoost</method>, <method>ensemble learning</method>, <method>feature-selection (FS)</method>, <method>KNN</method>, <method>SVM</method>, <method>Stacking</method>",<method>decision-tree</method><method>random-forest</method><method>extra-tree</method><method>XGBoost</method><method>ensemble learning</method><method>feature-selection (FS)</method><method>KNN</method><method>SVM</method><method>Stacking</method>
2024,https://openalex.org/W4390817508,Engineering,Conventional to Deep Ensemble Methods for Hyperspectral Image Classification: A Comprehensive Survey,"Hyperspectral image classification has become a hot research topic. HSI has been widely used in a wide range of real-world application areas due to the in-depth spectral information stored within each pixel. Noticeably, the detailed features - i.e., a nonlinear correlation between the obtained spectral data and the correlating HSI data object, generate efficient classification results that are complex for traditional techniques. Deep Learning (DL) has recently been validated as an influential feature extractor that efficiently identifies the nonlinear issues that have arisen in various computer vision challenges. This motivates using DL for Hyperspectral Image Classification (HSIC), which shows promising results. This survey provides a brief description of DL for HSIC and compares cutting-edge methodologies in the field. We will first summarize the key challenges for HSIC, and then we will discuss the superiority of DL and DL-ensemble in addressing these issues. In this article, we divide the state-of-the-art DL methodologies and DL with ensemble into spectral features, spatial features, and combined spatial-spectral features in order to comprehensively and critically evaluate the progress (future research directions as well) of such methodologies for HSIC. Furthermore, we will take into account that DL involves a substantial percentage of labeled training images, whereas obtaining such a number for HSI is time and cost-consuming. As a result, this survey describes some methodologies for improving the classification performance of DL techniques, which can serve as future recommendations.","<method>Deep Learning (DL)</method>, <method>DL-ensemble</method>",<method>Deep Learning (DL)</method>
2024,https://openalex.org/W4392232974,Engineering,Business analytics and decision science: A review of techniques in strategic business decision making,"Business analytics and decision science have emerged as pivotal domains in enhancing strategic business decision-making processes. This review delves into various techniques that organizations employ to optimize their operations and achieve competitive advantages. At the forefront of strategic decision-making is data analytics, where vast amounts of data are analyzed to extract valuable insights. Descriptive analytics provides a historical perspective by examining past data trends, enabling businesses to understand their performance over time. This retrospective analysis serves as a foundation for predictive analytics, which utilizes statistical models and machine learning algorithms to forecast future trends and outcomes. By leveraging predictive analytics, organizations can anticipate market shifts, customer preferences, and potential risks, thereby making informed decisions. Prescriptive analytics uses predictive models to guide strategic decision-making, utilizing optimization algorithms and simulation tools to identify optimal actions. Decision science integrates analytical techniques with human judgment, focusing on consumer behavior and psychological factors to tailor marketing strategies and product offerings. Additionally, artificial intelligence (AI) and machine learning (ML) technologies are revolutionizing strategic decision-making by automating complex tasks and providing real-time insights. Natural language processing (NLP) algorithms analyze unstructured data sources, such as customer reviews and social media posts, to extract valuable information and sentiment analysis. This enables businesses to gauge customer satisfaction levels and identify areas for improvement promptly. Decision trees, regression analysis, and clustering techniques are widely used in business analytics to segment customers, identify patterns, forecast sales trends, evaluate alternatives, assess risks, and optimize resource allocation. In conclusion, business analytics and decision science offer a plethora of techniques that empower organizations to make informed, data-driven decisions. By leveraging descriptive, predictive, and prescriptive analytics, along with AI and ML technologies, businesses can navigate complex environments, capitalize on opportunities, and mitigate risks effectively. This review underscores the importance of integrating analytical techniques with human expertise to achieve strategic objectives and sustainable growth.","<method>machine learning algorithms</method>, <method>artificial intelligence (AI)</method>, <method>machine learning (ML) technologies</method>, <method>natural language processing (NLP) algorithms</method>, <method>decision trees</method>, <method>regression analysis</method>, <method>clustering techniques</method>",<method>decision trees</method><method>regression analysis</method><method>clustering techniques</method>
2024,https://openalex.org/W4394776334,Engineering,Emerging underwater survey technologies: A review and future outlook,"Emerging underwater survey technologies are revolutionizing the way we explore and understand the underwater world. This review examines the latest advancements in underwater survey equipment, highlighting their operational benefits and potential areas for future development. Recent developments in underwater survey technologies have led to significant improvements in accuracy, efficiency, and data quality. Advanced sonar systems, such as multibeam and sidescan sonars, provide high-resolution images of the seafloor, allowing for detailed mapping of underwater features. Autonomous underwater vehicles (AUVs) equipped with sophisticated sensors and cameras enable precise data collection in challenging environments, such as deep-sea areas or complex underwater structures. The operational benefits of these technologies are vast. They allow for faster surveying, reduced costs, and improved safety for personnel. Additionally, the high-quality data obtained from these surveys can lead to better decision-making in various industries, including offshore energy, marine research, and underwater archaeology. Looking ahead, the future of underwater survey technologies is promising. There is a growing interest in developing integrated systems that combine multiple sensors and data processing capabilities to provide a more comprehensive view of underwater environments. Artificial intelligence and machine learning algorithms are also being increasingly utilized to analyze large datasets and extract valuable insights. However, several challenges remain, such as the need for better underwater communication systems, improved battery life for autonomous vehicles, and enhanced data processing capabilities. Addressing these challenges will be crucial for the continued advancement of underwater survey technologies. In conclusion, the latest advancements in underwater survey technologies offer exciting opportunities for enhancing our understanding of the underwater world. By leveraging these technologies and addressing key challenges, we can unlock new possibilities for underwater exploration and research.","<method>Artificial intelligence</method>, <method>machine learning algorithms</method>",No methods remaining
2024,https://openalex.org/W4395683385,Engineering,NAVIGATING THE FUTURE: INTEGRATING AI AND MACHINE LEARNING IN HR PRACTICES FOR A DIGITAL WORKFORCE,"As organizations navigate the complexities of the digital age, the role of Human Resources (HR) is evolving to meet the demands of a digital workforce. This review explores the integration of Artificial Intelligence (AI) and Machine Learning (ML) in HR practices to enhance efficiency, effectiveness, and employee satisfaction in the digital era. AI and ML technologies offer HR departments the opportunity to streamline operations, improve decision-making processes, and enhance employee experiences. By leveraging AI and ML, HR professionals can automate routine tasks such as recruitment, onboarding, training, and performance evaluation, allowing them to focus on more strategic initiatives that drive organizational success. One of the key advantages of integrating AI and ML in HR practices is the ability to personalize employee experiences. These technologies can analyze large volumes of data to identify patterns and trends, enabling HR professionals to tailor programs and policies to meet the unique needs of individual employees. This personalization can lead to higher levels of employee engagement, satisfaction, and retention. Furthermore, AI and ML can help HR departments make more informed decisions by providing data-driven insights. These technologies can analyze employee data to identify areas for improvement, predict future trends, and develop strategies to address challenges proactively. By leveraging these insights, HR professionals can make strategic decisions that align with the organization's goals and objectives. However, integrating AI and ML in HR practices also presents challenges, such as data privacy concerns, ethical considerations, and the need for upskilling HR professionals to use these technologies effectively. Organizations must address these challenges to realize the full potential of AI and ML in HR practices. In conclusion, integrating AI and ML in HR practices offers organizations the opportunity to enhance efficiency, effectiveness, and employee satisfaction in the digital age. By leveraging these technologies, HR departments can streamline operations, personalize employee experiences, and make more informed decisions that drive organizational success. As organizations increasingly turn to digital solutions, the role of artificial intelligence (AI) and machine learning (ML) in Human Resources becomes pivotal. This paper will focus on how AI and ML are being integrated into HR functions such as recruitment, onboarding, and employee engagement. It will also discuss the ethical implications and the challenges of maintaining human touch in an increasingly automated workplace. Case studies of companies leading in digital HR practices will be highlighted to provide real-world insights. Keywords: Digital Force, HR Practices, AI, Machine Learning, Future.","<method>Artificial Intelligence (AI)</method>, <method>Machine Learning (ML)</method>",<method>Machine Learning (ML)</method>
2024,https://openalex.org/W4391301691,Engineering,AI-Driven Digital Twin Model for Reliable Lithium-Ion Battery Discharge Capacity Predictions,"The present study proposes a novel method for predicting the discharge capabilities of lithium-ion (Li-ion) batteries using a digital twin model in practice. By combining cutting-edge machine learning techniques, such as AdaBoost and long short-term memory (LSTM) network, with a semiempirical mathematical structure, the digital twin (DT)—a virtual representation that mimics the behavior of actual batteries in real time is constructed. Various metaheuristic optimization methods, such as antlion, grey wolf optimization (GWO), and improved grey wolf optimization (IGWO), are used to adjust hyperparameters in order to optimize the models. As indicators of performance, mean absolute error (MAE) and root-mean-square error (RMSE) are applied to the models after they have undergone extensive training and ten-fold cross-validation. The models are rigorously trained and cross-validated using the NASA battery aging dataset, a widely accepted benchmark dataset for battery research. The IGWO-AdaBoost digital twin model emerges as the standout performer, achieving exceptional accuracy in predicting the discharge capacity. This model demonstrates the lowest mean absolute error (MAE) of 0.01, showcasing its superior precision in estimating discharge capabilities. Additionally, the root mean square error (RMSE) for the IGWO-AdaBoost DT model is also the lowest at 0.01. The findings of this study offer insightful information about the potential utilization of the digital twin model to accurately predict the discharge capacity of batteries.","<method>AdaBoost</method>, <method>long short-term memory (LSTM) network</method>, <method>antlion optimization</method>, <method>grey wolf optimization (GWO)</method>, <method>improved grey wolf optimization (IGWO)</method>",<method>AdaBoost</method><method>long short-term memory (LSTM) network</method><method>antlion optimization</method><method>grey wolf optimization (GWO)</method><method>improved grey wolf optimization (IGWO)</method>
2024,https://openalex.org/W4391559452,Engineering,Multi-USV Task Planning Method Based on Improved Deep Reinforcement Learning,"A safe and reliable task planning method is a prerequisite for the collaborative execution of ocean observation data collection tasks by multiple unmanned surface vessels (multi-USVs). Deep Reinforcement Learning (DRL) combines the powerful nonlinear function-fitting capabilities of deep neural networks with the decision-making and control abilities of reinforcement learning, providing a novel approach to solving the multi-USV task planning problem. However, when applied to the field of multi-USV task planning, it faces challenges such as a vast exploration space, extended training times, and unstable training process. To this end, this paper proposes a multi-USV task planning method based on improved deep reinforcement learning. The proposed method draws on the idea of a value decomposition network, breaking down the multi-USV task planning problem into two subproblems: task allocation and autonomous collision avoidance. Different state spaces, action spaces, and reward functions are designed for the various subproblems. Based on this, a deep neural network is used to map the state space of each subproblem to the action space of each USV, and the generated strategy of the deep neural network is assessed based on the corresponding reward function. This successfully integrates task allocation and path planning into a comprehensive task planning framework. Deep neural networks consist of the Actor networks and the Critic networks. During the training phase of the Critic network, different methods are used to train different Critic networks to improve the convergence speed of the algorithm. An improved temporal difference error method is specifically applied to train the Critic network for evaluating autonomous collision avoidance strategies, resulting in improving the autonomous collision avoidance ability of USVs. At the same time, to improve the efficiency of task allocation, hierarchical mechanisms, and regional division mechanisms are introduced to construct sub-system task planning models, which further decompose the task planning problem. A combination of successor features and an improved temporal difference error method is specifically applied to train another Critic network for evaluating the sub-systems task allocation schemes and collaborative motion trajectories, aiming to enhance the allocation efficiency of the sub-systems. Furthermore, transfer learning is employed to merge the sub-system task planning, using it as a constraint to direct the exploration and assessment of both the cluster task allocation schemes and the cluster collaborative motion trajectories. This enables rapid and accurate learning for task allocation within the multi-USV cluster. During the training phase of the Actor network, the introduction of the experience replay method and target network technique is employed to enhance the proximal policy optimization algorithm. This facilitates distributed joint training of the Actor network, thereby improving the accuracy of the algorithm. Simulation results validate the effectiveness and superiority of this method.","<method>Deep Reinforcement Learning (DRL)</method>, <method>value decomposition network</method>, <method>deep neural network</method>, <method>Actor networks</method>, <method>Critic networks</method>, <method>improved temporal difference error method</method>, <method>hierarchical mechanisms</method>, <method>regional division mechanisms</method>, <method>successor features</method>, <method>transfer learning</method>, <method>experience replay method</method>, <method>target network technique</method>, <method>proximal policy optimization algorithm</method>",<method>Deep Reinforcement Learning (DRL)</method><method>deep neural network</method><method>Actor networks</method><method>Critic networks</method><method>successor features</method><method>transfer learning</method><method>experience replay method</method><method>target network technique</method><method>proximal policy optimization algorithm</method>
2024,https://openalex.org/W4401691402,Engineering,Optimal truss design with MOHO: A multi-objective optimization perspective,"This research article presents the Multi-Objective Hippopotamus Optimizer (MOHO), a unique approach that excels in tackling complex structural optimization problems. The Hippopotamus Optimizer (HO) is a novel approach in meta-heuristic methodology that draws inspiration from the natural behaviour of hippos. The HO is built upon a trinary-phase model that incorporates mathematical representations of crucial aspects of Hippo's behaviour, including their movements in aquatic environments, defense mechanisms against predators, and avoidance strategies. This conceptual framework forms the basis for developing the multi-objective (MO) variant MOHO, which was applied to optimize five well-known truss structures. Balancing safety precautions and size constraints concerning stresses on individual sections and constituent parts, these problems also involved competing objectives, such as reducing the weight of the structure and the maximum nodal displacement. The findings of six popular optimization methods were used to compare the results. Four industry-standard performance measures were used for this comparison and qualitative examination of the finest Pareto-front plots generated by each algorithm. The average values obtained by the Friedman rank test and comparison analysis unequivocally showed that MOHO outperformed other methods in resolving significant structure optimization problems quickly. In addition to finding and preserving more Pareto-optimal sets, the recommended algorithm produced excellent convergence and variance in the objective and decision fields. MOHO demonstrated its potential for navigating competing objectives through diversity analysis. Additionally, the swarm plots effectively visualize MOHO's solution distribution of MOHO across iterations, highlighting its superior convergence behaviour. Consequently, MOHO exhibits promise as a valuable method for tackling complex multi-objective structure optimization issues.","<method>Multi-Objective Hippopotamus Optimizer (MOHO)</method>, <method>Hippopotamus Optimizer (HO)</method>",No methods remaining
2024,https://openalex.org/W4390667445,Engineering,Automated data processing and feature engineering for deep learning and big data applications: A survey,"Modern approach to artificial intelligence (AI) aims to design algorithms that learn directly from data. This approach has achieved impressive results and has contributed significantly to the progress of AI, particularly in the sphere of supervised deep learning. It has also simplified the design of machine learning systems as the learning process is highly automated. However, not all data processing tasks in conventional deep learning pipelines have been automated. In most cases data has to be manually collected, preprocessed and further extended through data augmentation before they can be effective for training. Recently, special techniques for automating these tasks have emerged. The automation of data processing tasks is driven by the need to utilize large volumes of complex, heterogeneous data for machine learning and big data applications. Today, end-to-end automated data processing systems based on automated machine learning (AutoML) techniques are capable of taking raw data and transforming them into useful features for Big Data tasks by automating all intermediate processing stages. In this work, we present a thorough review of approaches for automating data processing tasks in deep learning pipelines, including automated data preprocessing– e.g., data cleaning, labeling, missing data imputation, and categorical data encoding–as well as data augmentation (including synthetic data generation using generative AI methods) and feature engineering–specifically, automated feature extraction, feature construction and feature selection. In addition to automating specific data processing tasks, we discuss the use of AutoML methods and tools to simultaneously optimize all stages of the machine learning pipeline.","<method>supervised deep learning</method>, <method>data augmentation</method>, <method>automated machine learning (AutoML)</method>, <method>automated data preprocessing</method>, <method>data cleaning</method>, <method>labeling</method>, <method>missing data imputation</method>, <method>categorical data encoding</method>, <method>synthetic data generation using generative AI methods</method>, <method>automated feature extraction</method>, <method>feature construction</method>, <method>feature selection</method>",<method>supervised deep learning</method><method>automated machine learning (AutoML)</method><method>synthetic data generation using generative AI methods</method><method>feature construction</method><method>feature selection</method>
2024,https://openalex.org/W4392980686,Engineering,Data-driven evolution of water quality models: An in-depth investigation of innovative outlier detection approaches-A case study of Irish Water Quality Index (IEWQI) model,"Recently, there has been a significant advancement in the water quality index (WQI) models utilizing data-driven approaches, especially those integrating machine learning and artificial intelligence (ML/AI) technology. Although, several recent studies have revealed that the data-driven model has produced inconsistent results due to the data outliers, which significantly impact model reliability and accuracy. The present study was carried out to assess the impact of data outliers on a recently developed Irish Water Quality Index (IEWQI) model, which relies on data-driven techniques. To the author's best knowledge, there has been no systematic framework for evaluating the influence of data outliers on such models. For the purposes of assessing the outlier impact of the data outliers on the water quality (WQ) model, this was the first initiative in research to introduce a comprehensive approach that combines machine learning with advanced statistical techniques. The proposed framework was implemented in Cork Harbour, Ireland, to evaluate the IEWQI model's sensitivity to outliers in input indicators to assess the water quality. In order to detect the data outlier, the study utilized two widely used ML techniques, including Isolation Forest (IF) and Kernel Density Estimation (KDE) within the dataset, for predicting WQ with and without these outliers. For validating the ML results, the study used five commonly used statistical measures. The performance metric (R2) indicates that the model performance improved slightly (R2 increased from 0.92 to 0.95) in predicting WQ after removing the data outlier from the input. But the IEWQI scores revealed that there were no statistically significant differences among the actual values, predictions with outliers, and predictions without outliers, with a 95% confidence interval at p < 0.05. The results of model uncertainty also revealed that the model contributed <1% uncertainty to the final assessment results for using both datasets (with and without outliers). In addition, all statistical measures indicated that the ML techniques provided reliable results that can be utilized for detecting outliers and their impacts on the IEWQI model. The findings of the research reveal that although the data outliers had no significant impact on the IEWQI model architecture, they had moderate impacts on the rating schemes' of the model. This finding indicated that detecting the data outliers could improve the accuracy of the IEWQI model in rating WQ as well as be helpful in mitigating the model eclipsing problem. In addition, the results of the research provide evidence of how the data outliers influenced the data-driven model in predicting WQ and reliability, particularly since the study confirmed that the IEWQI model's could be effective for accurately rating WQ despite the presence of the data outliers in the input. It could occur due to the spatio-temporal variability inherent in WQ indicators. However, the research assesses the influence of data input outliers on the IEWQI model and underscores important areas for future investigation. These areas include expanding temporal analysis using multi-year data, examining spatial outlier patterns, and evaluating detection methods. Moreover, it is essential to explore the real-world impacts of revised rating categories, involve stakeholders in outlier management, and fine-tune model parameters. Analysing model performance across varying temporal and spatial resolutions and incorporating additional environmental data can significantly enhance the accuracy of WQ assessment. Consequently, this study offers valuable insights to strengthen the IEWQI model's robustness and provides avenues for enhancing its utility in broader WQ assessment applications. Moreover, the study successfully adopted the framework for evaluating how data input outliers affect the data-driven model, such as the IEWQI model. The current study has been carried out in Cork Harbour for only a single year of WQ data. The framework should be tested across various domains for evaluating the response of the IEWQI model's in terms of the spatio-temporal resolution of the domain. Nevertheless, the study recommended that future research should be conducted to adjust or revise the IEWQI model's rating schemes and investigate the practical effects of data outliers on updated rating categories. However, the study provides potential recommendations for enhancing the IEWQI model's adaptability and reveals its effectiveness in expanding its applicability in more general WQ assessment scenarios.","<method>Isolation Forest (IF)</method>, <method>Kernel Density Estimation (KDE)</method>",<method>Isolation Forest (IF)</method>
2024,https://openalex.org/W4400058707,Engineering,Computer vision in smart agriculture and precision farming: Techniques and applications,"The transformation of age-old farming practices through the integration of digitization and automation has sparked a revolution in agriculture that is driven by cutting-edge computer vision and artificial intelligence (AI) technologies. This transformation not only promises increased productivity and economic growth, but also has the potential to address important global issues such as food security and sustainability. This survey paper aims to provide a holistic understanding of the integration of vision-based intelligent systems in various aspects of precision agriculture. By providing a detailed discussion on key areas of digital life cycle of crops, this survey contributes to a deeper understanding of the complexities associated with the implementation of vision-guided intelligent systems in challenging agricultural environments. The focus of this survey is to explore widely used imaging and image analysis techniques being utilized for precision farming tasks. This paper first discusses various salient crop metrics used in digital agriculture. Then this paper illustrates the usage of imaging and computer vision techniques in various phases of digital life cycle of crops in precision agriculture, such as image acquisition, image stitching and photogrammetry, image analysis, decision making, treatment, and planning. After establishing a thorough understanding of related terms and techniques involved in the implementation of vision-based intelligent systems for precision agriculture, the survey concludes by outlining the challenges associated with implementing generalized computer vision models for real-time deployment of fully autonomous farms.",<method>computer vision</method>,No methods remaining
2024,https://openalex.org/W4394015596,Engineering,Predicting the mechanical properties of plastic concrete: An optimization method by using genetic programming and ensemble learners,"This study presents a comparative analysis of individual and ensemble learning algorithms (ELAs) to predict the compressive strength (CS) and flexural strength (FS) of plastic concrete. Multilayer perceptron neuron network (MLPNN), Support vector machine (SVM), random forest (RF), and decision tree (DT) were used as base learners, which were then combined with bagging and Adaboost methods to improve the predictive performance. In addition, gene expression programming (GEP) was used to develop computational equations that can be used to predict the CS and FS of plastic concrete. An extensive database containing 357 and 125 data points was obtained from the literature, and the eight most impactful ingredients were used in the model's development. The accuracy of all models was assessed using several statistical measures, including an error matrix, Akaike information criterion (AIC), K-fold cross-validation, and other external validation equations. Furthermore, sensitivity and SHAP analysis were performed to evaluate input variables' relative significance and impact on the anticipated CS and FS. Based on statistical measures and other validation criteria, GEP outpaces all other individual models, whereas, in ELAs, the SVR ensemble with Adaboost and RF modified with the Bagging technique demonstrated superior performance. SHapley Additive exPlanations (SHAP) and sensitivity analysis reveal that plastic, cement, water, and the age of the specimens have the highest influence, while superplasticizer has the lowest impact, which is consistent with experimental studies. Moreover, GUI and GEP-based simple mathematical correlation can enhance the practical scope of this study and be an effective tool for the pre-mix design of plastic concrete.","<method>Multilayer perceptron neuron network (MLPNN)</method>, <method>Support vector machine (SVM)</method>, <method>random forest (RF)</method>, <method>decision tree (DT)</method>, <method>bagging</method>, <method>Adaboost</method>, <method>gene expression programming (GEP)</method>, <method>K-fold cross-validation</method>, <method>SHapley Additive exPlanations (SHAP)</method>",<method>Multilayer perceptron neuron network (MLPNN)</method><method>Support vector machine (SVM)</method><method>random forest (RF)</method><method>decision tree (DT)</method><method>bagging</method><method>Adaboost</method><method>gene expression programming (GEP)</method><method>SHapley Additive exPlanations (SHAP)</method>
2024,https://openalex.org/W4391089359,Engineering,Groundwater level prediction using an improved SVR model integrated with hybrid particle swarm optimization and firefly algorithm,"The demand for water resources has increased due to rapid increase of metropolitan areas brought on by growth in population and industrialisation. In addition, the groundwater recharge is being afftected by shifting land use pattern caused by urban development. Using precise and trustworthy estimates of groundwater level is vital for the sustainable groundwater resources management in the face of changing climatic circumstances. In this context, machine learning (ML) methods offer a new and promising approach for accurately forecasting long-term changes in the groundwater level (GWL) without computational effort of developing a comprehensive flow model. In order to simulate GWL, five data-driven (DD) models, including the hybridization of support vector regression (SVR) with two optimisation algorithms i.e., firefly algorithm and particle swarm optimisation (FFAPSO), SVR-FFA, SVR-PSO, SVR and Multilayer perception (MLP), have been examined in the present study. Spatial clustering was utilised to choose four observation wells within Cuttack district in order to study and assess the water levels. Six scenarios were created by incorporating numerous variables, such as GWL in the previous months, evapotranspiration, temperature, precipitation, and river discharge. The goal was to identify the variables that were most efficient in predicting GWL. The SVR-FFAPSO model performs best in GWL forecasting for Khuntuni station, according to the quantitative analysis with correlation coefficient (R) = 0.9978, Nash–Sutcliffe efficiency (NSE) = 0.9933, mean absolute error (MAE) = 0.00025 (m), root mean squared error (RMSE) = 0.00775 (m) during the training phase. It is advised that groundwater monitoring network and data collecting system are strengthen in India for ensuring effective modelling of long-term management of groundwater resources.","<method>support vector regression (SVR)</method>, <method>firefly algorithm</method>, <method>particle swarm optimisation (PSO)</method>, <method>SVR-FFA</method>, <method>SVR-PSO</method>, <method>Multilayer perception (MLP)</method>",<method>support vector regression (SVR)</method><method>firefly algorithm</method><method>SVR-PSO</method>
2024,https://openalex.org/W4391855187,Engineering,Machine learning-assisted in-situ adaptive strategies for the control of defects and anomalies in metal additive manufacturing,"In metal additive manufacturing (AM), the material microstructure and part geometry are formed incrementally. Consequently, the resulting part could be defect- and anomaly-free if sufficient care is taken to deposit each layer under optimal process conditions. Conventional closed-loop control (CLC) engineering solutions which sought to achieve this were deterministic and rule-based, thus resulting in limited success in the stochastic environment experienced in the highly dynamic AM process. On the other hand, emerging machine learning (ML) based strategies are better suited to providing the robustness, scope, flexibility, and scalability required for process control in an uncertain environment. Offline ML models that help optimise AM process parameters before a build begins and online ML models that efficiently processed in-situ sensory data to detect and diagnose flaws in real-time (or near-real-time) have been developed. However, ML models that enable a process to take evasive or corrective actions in relation to flaws via on the fly decision-making are only emerging. These models must possess prognostic capabilities to provide context-sensitive recommendations for in-situ process control based on real-time diagnostics. In this article, we pinpoint the shortcomings in traditional CLC strategies, and provide a framework for defect and anomaly control through ML-assisted CLC in AM. We discuss flaws in terms of their causes, in-situ detectability, and controllability, and examine their management under three scenarios: avoidance, mitigation, and repair. Then, we summarise the research into ML models developed for offline optimisation and in-situ diagnosis before initiating a detailed conversation on the implementation of ML-assisted in-situ process control. We found that researchers favoured reinforcement learning approaches or inverse ML models for making rapid, situation-aware control decisions. We also observed that, to-date, the defects addressed were those that may be quantified relatively easily autonomously, and that mitigation (rather than avoidance or repair) was the aim of ML-assisted in-situ control strategies. Additionally, we highlight the various technologies that must seamlessly combine to advance the field of autonomous in-situ control so that it becomes a reality in industrial settings. Finally, we raise awareness of seldom discussed, yet highly pertinent, topics relevant to adaptive control. Our work closes a significant gap in the current AM literature by broaching wide-ranging discussions on matters relevant to in-situ adaptive control in AM.","<method>machine learning (ML) based strategies</method>, <method>offline ML models</method>, <method>online ML models</method>, <method>reinforcement learning approaches</method>, <method>inverse ML models</method>",<method>online ML models</method><method>reinforcement learning approaches</method>
2024,https://openalex.org/W4391973028,Engineering,A comprehensive evaluation of large Language models on benchmark biomedical text processing tasks,"Recently, Large Language Models (LLMs) have demonstrated impressive capability to solve a wide range of tasks. However, despite their success across various tasks, no prior work has investigated their capability in the biomedical domain yet. To this end, this paper aims to evaluate the performance of LLMs on benchmark biomedical tasks. For this purpose, a comprehensive evaluation of 4 popular LLMs in 6 diverse biomedical tasks across 26 datasets has been conducted. To the best of our knowledge, this is the first work that conducts an extensive evaluation and comparison of various LLMs in the biomedical domain. Interestingly, we find based on our evaluation that in biomedical datasets that have smaller training sets, zero-shot LLMs even outperform the current state-of-the-art models when they were fine-tuned only on the training set of these datasets. This suggests that pre-training on large text corpora makes LLMs quite specialized even in the biomedical domain. We also find that not a single LLM can outperform other LLMs in all tasks, with the performance of different LLMs may vary depending on the task. While their performance is still quite poor in comparison to the biomedical models that were fine-tuned on large training sets, our findings demonstrate that LLMs have the potential to be a valuable tool for various biomedical tasks that lack large annotated data.","<method>Large Language Models (LLMs)</method>, <method>zero-shot learning</method>, <method>fine-tuning</method>",<method>zero-shot learning</method><method>fine-tuning</method>
2024,https://openalex.org/W4392640075,Engineering,Performance assessment of machine learning algorithms for mapping of land use/land cover using remote sensing data,"The rapid increase in population accelerates the rate of change of Land use/Land cover (LULC) in various parts of the world. This phenomenon caused a huge strain for natural resources. Hence, continues monitoring of LULC changes gained a significant importance for management of natural resources and assessing the climate change impacts. Recently, application of machine learning algorithms on RS (remote sensing) data for rapid and accurate mapping of LULC gained significant importance due to growing need of LULC estimation for ecosystem services, natural resource management and environmental management. Hence, it is crucial to access and compare the performance of different machine learning classifiers for accurate mapping of LULC. The primary objective of this study was to compare the performance of CART (Classification and Regression Tree), RF (Random Forest) and SVM (Support Vector Machine) for LULC estimation by processing RS data on Google Earth Engine (GEE). In total four classes of LULC (Water Bodies, Vegetation Cover, Urban Land and Barren Land) for city of Lahore were extracted using satellite images from Landsat-7, Landsat-8 and Landsat-9 for years 2008, 2015 and 2022, respectively. According to results, RF is the best performing classifier with maximum overall accuracy of 95.2% and highest Kappa coefficient value of 0.87, SVM achieved maximum accuracy of 89.8% with highest Kappa of 0.84 and CART showed maximum overall accuracy of 89.7% with Kappa value of 0.79. Results from this study can give assistance for decision makers, planners and RS experts to choose a suitable machine learning algorithm for LULC classification in an unplanned urbanized city like Lahore.","<method>Classification and Regression Tree (CART)</method>, <method>Random Forest (RF)</method>, <method>Support Vector Machine (SVM)</method>",<method>Classification and Regression Tree (CART)</method><method>Random Forest (RF)</method><method>Support Vector Machine (SVM)</method>
2024,https://openalex.org/W4393405236,Engineering,Transformer and Graph Convolution-Based Unsupervised Detection of Machine Anomalous Sound Under Domain Shifts,"Thanks to the development of deep learning, machine abnormal sound detection (MASD) based on unsupervised learning has exhibited excellent performance. However, in the task of unsupervised MASD, there are discrepancies between the acoustic characteristics of the test set and the training set under the physical parameter changes (domain shifts) of the same machine's operating conditions. Existing methods not only struggle to stably learn the sound signal features under various domain shifts but also inevitably increase computational overhead. To address these issues, we propose an unsupervised machine abnormal sound detection model based on Transformer and Dynamic Graph Convolution (Unsuper-TDGCN) in this paper. Firstly, we design a network that models time-frequency domain features to capture both global and local spatial and time-frequency interactions, thus improving the model's stability under domain shifts. Then, we introduce a Dynamic Graph Convolutional Network (DyGCN) to model the dependencies between features under domain shifts, enhancing the model's ability to perceive changes in domain features. Finally, a Domain Self-adaptive Network (DSN) is employed to compensate for the performance decline caused by domain shifts, thereby improving the model's adaptive ability for detecting anomalous sounds in MASD tasks under domain shifts. The effectiveness of our proposed model has been validated on multiple datasets.","<method>unsupervised learning</method>, <method>Transformer</method>, <method>Dynamic Graph Convolutional Network (DyGCN)</method>, <method>Domain Self-adaptive Network (DSN)</method>",<method>unsupervised learning</method><method>Transformer</method><method>Dynamic Graph Convolutional Network (DyGCN)</method>
2024,https://openalex.org/W4401667275,Engineering,Artificial intelligence for literature reviews: opportunities and challenges,"Abstract This paper presents a comprehensive review of the use of Artificial Intelligence (AI) in Systematic Literature Reviews (SLRs). A SLR is a rigorous and organised methodology that assesses and integrates prior research on a given topic. Numerous tools have been developed to assist and partially automate the SLR process. The increasing role of AI in this field shows great potential in providing more effective support for researchers, moving towards the semi-automatic creation of literature reviews. Our study focuses on how AI techniques are applied in the semi-automation of SLRs, specifically in the screening and extraction phases. We examine 21 leading SLR tools using a framework that combines 23 traditional features with 11 AI features. We also analyse 11 recent tools that leverage large language models for searching the literature and assisting academic writing. Finally, the paper discusses current trends in the field, outlines key research challenges, and suggests directions for future research. We highlight three primary research challenges: integrating advanced AI solutions, such as large language models and knowledge graphs, improving usability, and developing a standardised evaluation framework. We also propose best practices to ensure more robust evaluations in terms of performance, usability, and transparency. Overall, this review offers a detailed overview of AI-enhanced SLR tools for researchers and practitioners, providing a foundation for the development of next-generation AI solutions in this field.","<method>large language models</method>, <method>knowledge graphs</method>",<method>knowledge graphs</method>
2024,https://openalex.org/W4390480832,Engineering,Joint Optimization Risk Factor and Energy Consumption in IoT Networks With TinyML-Enabled Internet of UAVs,"The high mobility of Internet of Unmanned Aerial Vehicles (IUAVs) has attracted attention in the field of data collection. With the rapid development of the Internet of Things (IoT), more and more data are generated by IoT networks. IUAV-aided IoT networks can efficiently collect data in specific areas, which is of great significance in disaster relief. In the data collection task, it is necessary to plan the flight trajectory for the data collector—IUAV, so that the IUAV can collect data efficiently. However, existing research basically only considers the efficiency of data collection by IUAVs, but rarely considers the safety of IUAVs during flight. Therefore, this paper proposes an IUAV trajectory planning algorithm that integrates energy efficiency and safety using local search to address the issues mentioned above. At the same time, a Tiny Machine Learning (TinyML) algorithm is designed to assist the IUAV in making real-time decisions during flight. First, we build a general mathematical model that describes the risk in a particular region. Then consider guiding the IUAV to a safer trajectory by introducing virtual nodes in the flight trajectory. Furthermore, we designed a local search algorithm for the three tasks of IUAV access sequence, IoT Networks cluster heads selection and virtual nodes selection, and solved them through iterative optimization. We also consider the unreachable situation of the virtual nodes and use TinyML technology to help the IUAV adjust the position of the virtual nodes in real time in case of an emergency.In the end, an IUAV trajectory is obtained that can efficiently collect IoT networks' data and fly safely. We have conducted a large number of simulation experiments to demonstrate the efficiency of the proposed algorithm compared to the baseline algorithm.","<method>Tiny Machine Learning (TinyML)</method>, <method>local search algorithm</method>",<method>Tiny Machine Learning (TinyML)</method>
2024,https://openalex.org/W4390754233,Engineering,Groundwater Quality Assessment and Irrigation Water Quality Index Prediction Using Machine Learning Algorithms,"The evaluation of groundwater quality is crucial for irrigation purposes; however, due to financial constraints in developing countries, such evaluations suffer from insufficient sampling frequency, hindering comprehensive assessments. Therefore, associated with machine learning approaches and the irrigation water quality index (IWQI), this research aims to evaluate the groundwater quality in Naama, a region in southwest Algeria. Hydrochemical parameters (cations, anions, pH, and EC), qualitative indices (SAR,RSC,Na%,MH,and PI), as well as geospatial representations were used to determine the groundwater’s suitability for irrigation in the study area. In addition, efficient machine learning approaches for forecasting IWQI utilizing Extreme Gradient Boosting (XGBoost), Support vector regression (SVR), and K-Nearest Neighbours (KNN) models were implemented. In this research, 166 groundwater samples were used to calculate the irrigation index. The results showed that 42.18% of them were of excellent quality, 34.34% were of very good quality, 6.63% were good quality, 9.64% were satisfactory, and 4.21% were considered unsuitable for irrigation. On the other hand, results indicate that XGBoost excels in accuracy and stability, with a low RMSE (of 2.8272 and a high R of 0.9834. SVR with only four inputs (Ca2+, Mg2+, Na+, and K) demonstrates a notable predictive capability with a low RMSE of 2.6925 and a high R of 0.98738, while KNN showcases robust performance. The distinctions between these models have important implications for making informed decisions in agricultural water management and resource allocation within the region.","<method>Extreme Gradient Boosting (XGBoost)</method>, <method>Support Vector Regression (SVR)</method>, <method>K-Nearest Neighbours (KNN)</method>",<method>Extreme Gradient Boosting (XGBoost)</method><method>Support Vector Regression (SVR)</method><method>K-Nearest Neighbours (KNN)</method>
2024,https://openalex.org/W4391262045,Engineering,Monolithic 2D Perovskites Enabled Artificial Photonic Synapses for Neuromorphic Vision Sensors,"Abstract Neuromorphic visual sensors (NVS) based on photonic synapses hold a significant promise to emulate the human visual system. However, current photonic synapses rely on exquisite engineering of the complex heterogeneous interface to realize learning and memory functions, resulting in high fabrication cost, reduced reliability, high energy consumption and uncompact architecture, severely limiting the up‐scaled manufacture, and on‐chip integration. Here a photo‐memory fundamental based on ion‐exciton coupling is innovated to simplify synaptic structure and minimize energy consumption. Due to the intrinsic organic/inorganic interface within the crystal, the photodetector based on monolithic 2D perovskite exhibits a persistent photocurrent lasting about 90 s, enabling versatile synaptic functions. The electrical power consumption per synaptic event is estimated to be≈1.45 × 10 −16 J, one order of magnitude lower than that in a natural biological system. Proof‐of‐concept image preprocessing using the neuromorphic vision sensors enabled by photonic synapse demonstrates 4 times enhancement of classification accuracy. Furthermore, getting rid of the artificial neural network, an expectation‐based thresholding model is put forward to mimic the human visual system for facial recognition. This conceptual device unveils a new mechanism to simplify synaptic structure, promising the transformation of the NVS and fostering the emergence of next generation neural networks.",<method>expectation-based thresholding model</method>,No methods remaining
2024,https://openalex.org/W4391312031,Engineering,Artificial intelligence (AI) in renewable energy: A review of predictive maintenance and energy optimization,"The integration of Artificial Intelligence (AI) in the renewable energy sector has emerged as a transformative force, enhancing the efficiency and sustainability of energy systems. This paper provides a comprehensive review of the application of AI in two critical aspects of renewable energy in relation to predictive maintenance and energy optimization. Predictive maintenance, enabled by AI, has revolutionized the renewable energy landscape by predicting and preventing equipment failures before they occur. Utilizing machine learning algorithms, AI analyzes vast amounts of data from sensors and historical performance to identify patterns indicative of potential faults. This proactive approach not only minimizes downtime but also extends the lifespan of renewable energy infrastructure, resulting in substantial cost savings and improved reliability. Furthermore, AI plays a pivotal role in optimizing the energy output of renewable sources. Through advanced data analytics and real-time monitoring, AI algorithms can adapt to changing environmental conditions, predicting energy production patterns and optimizing resource allocation. This ensures maximum energy yield from renewable sources, making them more competitive with traditional energy sources. The paper delves into specific AI techniques such as deep learning, neural networks, and predictive analytics employed for predictive maintenance and energy optimization in various renewable energy systems like solar, wind, and hydropower. Challenges and opportunities associated with implementing AI in renewable energy are discussed, including data security, interoperability, and the need for standardized frameworks. The synthesis of AI technologies with renewable energy not only addresses operational challenges but also contributes to the global transition towards sustainable and clean energy solutions. This review serves as a valuable resource for researchers, practitioners, and policymakers seeking insights into the evolving landscape of AI applications in the renewable energy sector. As technology continues to advance, the synergies between AI and renewable energy are poised to shape the future of the global energy paradigm.","<method>machine learning algorithms</method>, <method>deep learning</method>, <method>neural networks</method>, <method>predictive analytics</method>",<method>deep learning</method><method>neural networks</method>
2024,https://openalex.org/W4391679299,Engineering,Generative Pre-Trained Transformer (GPT) in Research: A Systematic Review on Data Augmentation,"GPT (Generative Pre-trained Transformer) represents advanced language models that have significantly reshaped the academic writing landscape. These sophisticated language models offer invaluable support throughout all phases of research work, facilitating idea generation, enhancing drafting processes, and overcoming challenges like writer’s block. Their capabilities extend beyond conventional applications, contributing to critical analysis, data augmentation, and research design, thereby elevating the efficiency and quality of scholarly endeavors. Strategically narrowing its focus, this review explores alternative dimensions of GPT and LLM applications, specifically data augmentation and the generation of synthetic data for research. Employing a meticulous examination of 412 scholarly works, it distills a selection of 77 contributions addressing three critical research questions: (1) GPT on Generating Research data, (2) GPT on Data Analysis, and (3) GPT on Research Design. The systematic literature review adeptly highlights the central focus on data augmentation, encapsulating 48 pertinent scholarly contributions, and extends to the proactive role of GPT in critical analysis of research data and shaping research design. Pioneering a comprehensive classification framework for “GPT’s use on Research Data”, the study classifies existing literature into six categories and 14 sub-categories, providing profound insights into the multifaceted applications of GPT in research data. This study meticulously compares 54 pieces of literature, evaluating research domains, methodologies, and advantages and disadvantages, providing scholars with profound insights crucial for the seamless integration of GPT across diverse phases of their scholarly pursuits.","<method>Generative Pre-trained Transformer (GPT)</method>, <method>Large Language Models (LLM)</method>",<method>Generative Pre-trained Transformer (GPT)</method>
2024,https://openalex.org/W4390480870,Engineering,GraphGST: Graph Generative Structure-Aware Transformer for Hyperspectral Image Classification,"Transformer holds significance in deep learning (DL) research. Node embedding (NE) and positional encoding (PE) are usually two indispensable components in a Transformer. The former can excavate hidden correlations from the data, while the latter can store locational relationships between nodes. Recently, the Transformer has been applied for hyperspectral image (HSI) classification because the model can capture long-range dependencies to aggregate global features for representation learning. In an HSI, adjacent pixels tend to be homogeneous, while the NE does not identify the positional information of pixels. Therefore, PE is crucial for Transformers to understand locational relationships between pixels. However, in this area, most Transformer-based methods randomly generate PEs without considering their physical meaning, which leads to weak representations. This article proposes a new graph generative structure-aware Transformer (GraphGST) to solve the above-mentioned PE problem when implementing HSI classification. In our GraphGST, a new absolute PE (APE) is established to acquire pixels' absolute positional sequences (APSs) and is integrated into the Transformer architecture. Moreover, a generative mechanism with self-supervised learning is developed to achieve cross-view contrastive learning (CL), aiming to enhance the representation learning of the Transformer. The proposed GraphGST model can capture local-to-global correlations, and the extracted APSs can complement the spectral features of pixels to assist in NE. Several experiments with real HSIs are conducted to evaluate the effectiveness of our GraphGST. The proposed method demonstrates very competitive performance compared with other state-of-the-art (SOTA) approaches. Our source codes will be provided in the following link <uri xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">https://github.com/yuanchaosu/TGRS-graphGST</uri> .","<method>Transformer</method>, <method>Node embedding (NE)</method>, <method>Positional encoding (PE)</method>, <method>Graph generative structure-aware Transformer (GraphGST)</method>, <method>Absolute positional encoding (APE)</method>, <method>Self-supervised learning</method>, <method>Cross-view contrastive learning (CL)</method>",<method>Transformer</method><method>Node embedding (NE)</method><method>Absolute positional encoding (APE)</method><method>Self-supervised learning</method><method>Cross-view contrastive learning (CL)</method>
2024,https://openalex.org/W4391130239,Engineering,Learning to Aggregate Multi-Scale Context for Instance Segmentation in Remote Sensing Images,"The task of instance segmentation in remote sensing images, aiming at performing per-pixel labeling of objects at the instance level, is of great importance for various civil applications. Despite previous successes, most existing instance segmentation methods designed for natural images encounter sharp performance degradations when they are directly applied to top-view remote sensing images. Through careful analysis, we observe that the challenges mainly come from the lack of discriminative object features due to severe scale variations, low contrasts, and clustered distributions. In order to address these problems, a novel context aggregation network (CATNet) is proposed to improve the feature extraction process. The proposed model exploits three lightweight plug-and-play modules, namely, dense feature pyramid network (DenseFPN), spatial context pyramid (SCP), and hierarchical region of interest extractor (HRoIE), to aggregate global visual context at feature, spatial, and instance domains, respectively. DenseFPN is a multi-scale feature propagation module that establishes more flexible information flows by adopting interlevel residual connections, cross-level dense connections, and feature reweighting strategy. Leveraging the attention mechanism, SCP further augments the features by aggregating global spatial context into local regions. For each instance, HRoIE adaptively generates RoI features for different downstream tasks. Extensive evaluations of the proposed scheme on iSAID, DIOR, NWPU VHR-10, and HRSID datasets demonstrate that the proposed approach outperforms state-of-the-arts under similar computational costs. Source code and pretrained models are available at https://github.com/yeliudev/CATNet.","<method>context aggregation network (CATNet)</method>, <method>dense feature pyramid network (DenseFPN)</method>, <method>spatial context pyramid (SCP)</method>, <method>hierarchical region of interest extractor (HRoIE)</method>, <method>attention mechanism</method>",<method>dense feature pyramid network (DenseFPN)</method><method>attention mechanism</method>
2024,https://openalex.org/W4391248672,Engineering,Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning,"Recent development in computing power has resulted in performance improvements on holistic(none-occluded) person Re-Identification (ReID) tasks. Nevertheless, the precision of the recent research will diminish when a pedestrian is obstructed by obstacles. Within the realm of 2D space, the loss of information from obstructed objects continues to pose significant challenges in the context of person ReID. Person is a 3D non-grid object, and thus semantic representation learning in only 2D space limits the understanding of occluded person. In the present work, we propose a network based on 3D multi-view learning, allowing it to acquire geometric and shape details of an occluded pedestrian from 3D space. Simultaneously, it capitalizes on advancements in 2D-based networks to extract semantic representations from 3D multi-views. Specifically, the surface random selection strategy is proposed to convert images of 2D RGB into 3D multi-views. Using this strategy, we build four extensive 3D multi-view data collections for person ReID. After that, Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning(MV-3DSReID), is proposed for identifying the person by learning person geometry and structure representation from the groups of multi-view images. In comparison to alternative data formats (e.g., 2D RGB, 3D point cloud), multi-view images complement each other's detailed features of the 3D object by adjusting rendering viewpoints, thus facilitating a more comprehensive understanding of the person for both holistic and occluded ReID situations. Experiments on occluded and holistic ReID tasks demonstrate performance levels comparable to state-of-the-art methods, validating the effectiveness of our proposed approach in tackling challenges related to occlusion. The code is available at https://github.com/hangjiaqi1/MV-TransReID.","<method>3D multi-view learning</method>, <method>2D-based networks</method>, <method>surface random selection strategy</method>, <method>Pedestrian 3D Shape Understanding for Person Re-Identification via Multi-View Learning (MV-3DSReID)</method>",<method>3D multi-view learning</method>
2024,https://openalex.org/W4391973098,Engineering,The use of machine learning techniques to investigate the properties of metakaolin-based geopolymer concrete,"The construction industry significantly contributes to global greenhouse gas emissions, highlighting the imperative for developing environmentally friendly construction materials. Geopolymers, particularly those utilizing metakaolin (MK), have emerged as a promising green alternative to conventional concrete. However, the acquisition of MK-based geopolymer concrete with optimal mechanical properties poses challenges due to numerous influential factors, disagreement over various findings, and the lack of a reliable predictive model. This study aimed to address this gap by employing a wide range of machine learning methods, namely gradient boosting machine, random forest, decision tree, artificial neural network, and support vector machine. Different optimization and regularization techniques were used to comprehensively understand the factors affecting the compressive strength of MK-based geopolymer concrete, including mixture design, chemical characteristics of the initial binder and activators, and different curing regimes. The results demonstrated the exceptional performance of the gradient boosting machine in predicting the compressive strength of MK-based geopolymer concrete, achieving a coefficient of determination of 0.983 and a mean absolute error of 1.615 MPa. Additionally, the study employed partial dependence plots, feature importance analysis, and SHapley Additive exPlanations (SHAP) to elucidate the proposed models. The coarse-to-fine aggregate ratio, H2O/Na2O molar ratio, extra water content, and sodium hydroxide concentration were identified as the most critical parameters affecting the compressive strength of MK-based geopolymer concrete. This research contributes to advancing the development of sustainable construction materials, streamlining experimental tasks, minimizing the need for labor and materials, improving time efficiency, and providing valuable insights for optimizing the design of MK-based geopolymer concrete.","<method>gradient boosting machine</method>, <method>random forest</method>, <method>decision tree</method>, <method>artificial neural network</method>, <method>support vector machine</method>",<method>gradient boosting machine</method><method>random forest</method><method>decision tree</method><method>artificial neural network</method><method>support vector machine</method>
2024,https://openalex.org/W4394685122,Engineering,Sequence Training and Data Shuffling to Enhance the Accuracy of Recurrent Neural Network Based Battery Voltage Models,"&lt;div class=""section abstract""&gt;&lt;div class=""htmlview paragraph""&gt;Battery terminal voltage modelling is crucial for various applications, including electric vehicles, renewable energy systems, and portable electronics. Terminal voltage models are used to determine how a battery will respond under load and can be used to calculate run-time, power capability, and heat generation and as a component of state estimation approaches, such as for state of charge. Previous studies have shown better voltage modelling accuracy for long short-term memory (LSTM) recurrent neural networks than other traditional methods (e.g., equivalent circuit and electrochemical models). This study presents two new approaches – sequence training and data shuffling – to improve LSTM battery voltage models further, making them an even better candidate for the high-accuracy modelling of lithium-ion batteries. Because the LSTM memory captures information from past time steps, it must typically be trained using one series of continuous data. Instead, the proposed sequence training approach feeds a fixed window of prior data (e.g., 100 seconds) into the LSTM at each time step to initialize the memory states properly and then only uses the output at the current time step. With this method, the LSTM just requires the prior data window to be continuous, thereby allowing the handling of discontinuities. This also means that during the training process, the data can be shuffled randomly, enabling mini-batches to speed up the training significantly. When these approaches were applied, LSTM voltage estimation error was reduced by 22%, from 28.5 mV to 22.3 mV RMS error over four drive cycles and temperatures from -20 to 25°C.&lt;/div&gt;&lt;/div&gt;","<method>long short-term memory (LSTM) recurrent neural networks</method>, <method>sequence training</method>, <method>data shuffling</method>",<method>long short-term memory (LSTM) recurrent neural networks</method><method>sequence training</method>
2024,https://openalex.org/W4390975281,Engineering,Semantic and Instance Segmentation in Coastal Urban Spatial Perception: A Multi-Task Learning Framework with an Attention Mechanism,"With the continuous acceleration of urbanization, urban planning and design require more in-depth research and development. Street view images can express rich urban features and guide residents’ emotions toward a city, thereby providing the most intuitive reflection of their perception of the city’s spatial quality. However, current researchers mainly conduct research on urban spatial quality through subjective experiential judgment, which includes problems such as a high cost and a low judgment accuracy. In response to these problems, this study proposes a multi-task learning urban spatial attribute perception model that integrates an attention mechanism. Via this model, the existing attributes of urban street scenes are analyzed. Then, the model is improved by introducing semantic segmentation and instance segmentation to identify and match the qualities of the urban space. The experimental results show that the multi-task learning urban spatial attribute perception model with an integrated attention mechanism has prediction accuracies of 79.54%, 78.62%, 79.68%, 77.42%, 78.45%, and 76.98% for the urban spatial attributes of beauty, boredom, depression, liveliness, safety, and richness, respectively. The accuracy of the multi-task learning urban spatial scene feature image segmentation model with an integrated attention mechanism is 95.4, 94.8, 96.2, 92.1, and 96.7 for roads, walls, sky, vehicles, and buildings, respectively. The multi-task learning urban spatial scene feature image segmentation model with an integrated attention mechanism has a higher recognition accuracy for urban spatial buildings than other models. These research results indicate the model’s effectiveness in matching urban spatial quality with public perception.","<method>multi-task learning</method>, <method>attention mechanism</method>, <method>semantic segmentation</method>, <method>instance segmentation</method>",<method>multi-task learning</method><method>attention mechanism</method><method>semantic segmentation</method><method>instance segmentation</method>
2024,https://openalex.org/W4391404732,Engineering,"The Convergence of Intelligent Tutoring, Robotics, and IoT in Smart Education for the Transition from Industry 4.0 to 5.0","This review paper provides a comprehensive analysis of the automation of smart education in the context of Industry 5.0 from 78 papers, focusing on the integration of advanced technologies and the development of innovative, effective, and ethical educational solutions for the future workforce. As the world transitions into an era characterized by human–machine collaboration and rapidly evolving technologies, there is an urgent need to recognize the pivotal role of smart education in preparing individuals for the opportunities and challenges presented by the new industrial landscape. The paper examines key components of smart education, including intelligent tutoring systems, adaptive learning environments, learning analytics, and the application of the Internet of Things (IoT) in education. It also discusses the role of advanced technologies such as artificial intelligence (AI), machine learning (ML), robotics, and augmented and virtual reality (AR/VR) in shaping personalized and immersive learning experiences. The review highlights the importance of smart education in addressing the growing demand for upskilling and reskilling, fostering a culture of lifelong learning, and promoting adaptability, resilience, and self-improvement among learners. Furthermore, the paper delves into the challenges and ethical considerations associated with the implementation of smart education, addressing issues such as data privacy, the digital divide, teacher and student readiness, and the potential biases in AI-driven systems. Through a presentation of case studies and examples of successful smart education initiatives, the review aims to inspire educators, policymakers, and industry stakeholders to collaborate and innovate in the design and implementation of effective smart education solutions. Conclusively, the paper outlines emerging trends, future directions, and potential research opportunities in the field of smart education, emphasizing the importance of continuous improvement and the integration of new technologies to ensure that education remains relevant and effective in the context of Industry 5.0. By providing a holistic understanding of the key components, challenges, and potential solutions associated with smart education, this review paper seeks to contribute to the ongoing discourse surrounding the automation of smart education and its role in preparing the workforce for the future of work.","<method>artificial intelligence (AI)</method>, <method>machine learning (ML)</method>",<method>machine learning (ML)</method>
2024,https://openalex.org/W4391482136,Engineering,A comprehensive analysis of the emerging modern trends in research on photovoltaic systems and desalination in the era of artificial intelligence and machine learning,"Integration of photovoltaic (PV) systems, desalination technologies, and Artificial Intelligence (AI) combined with Machine Learning (ML) has introduced a new era of remarkable research and innovation. This review article thoroughly examines the recent advancements in the field, focusing on the interplay between PV systems and water desalination within the framework of AI and ML applications, along with it analyses current research to identify significant patterns, obstacles, and prospects in this interdisciplinary field. Furthermore, review examines the incorporation of AI and ML methods in improving the performance of PV systems. This includes raising their efficiency, implementing predictive maintenance strategies, and enabling real-time monitoring. It also explores the transformative influence of intelligent algorithms on desalination techniques, specifically addressing concerns pertaining to energy usage, scalability, and environmental sustainability. This article provides a thorough analysis of the current literature, identifying areas where research is lacking and suggesting potential future avenues for investigation. These advancements have resulted in increased efficiency, decreased expenses, and improved sustainability of PV system. By utilizing artificial intelligence technologies, freshwater productivity can increase by 10 % and efficiency. This review offers significant and informative perspectives for researchers, engineers, and policymakers involved in renewable energy and water technology. It sheds light on the latest advancements in photovoltaic systems and desalination, which are facilitated by AI and ML. The review aims to guide towards a more sustainable and technologically advanced future.","<method>Artificial Intelligence (AI)</method>, <method>Machine Learning (ML)</method>, <method>predictive maintenance strategies</method>, <method>intelligent algorithms</method>",<method>Machine Learning (ML)</method>
2024,https://openalex.org/W4391574742,Engineering,Optimum tuned mass damper inerter under near-fault pulse-like ground motions of buildings including soil-structure interaction,"This study investigates the effectiveness of the tuned mass damper inerter (TMDI) in mitigating building response, considering the soil structure interaction (SSI). Three types of models are examined: single degree of freedom (SDOF), low-rise multi-degree of freedom (MDOF), and high-rise MDOF. Additionally, the natural period of the SDOF model is varied to explore the TMDI's efficacy across different ranges. Frequency and time domain analysis are conducted under pulse-like ground motions. The H2 and genetic algorithm (GA) are used to optimize the parameters of the TMDI. In this optimization method the transfer function for displacement response is minimized. In time domain analysis we used Newmark's integration method to solve the equation of motion for all the cases considered. It is found that the optimized TMDI proves highly effective in mitigating the displacement response of the buildings, accounting for SSI. Notably, its efficiency is more pronounced when pulse period aligns closely with the buildings' natural period. In addition, a notable pattern emerges, wherein the TMDI excels in mitigating response for buildings experiencing large motion, thereby enhancing safety under severe conditions. These findings offer valuable insights into the application and optimization of the TMDI to enhance seismic performance in various buildings, while considering complex interaction with the soil.",<method>genetic algorithm (GA)</method>,<method>genetic algorithm (GA)</method>
2024,https://openalex.org/W4391693184,Engineering,3DUV-NetR+: A 3D hybrid semantic architecture using transformers for brain tumor segmentation with MultiModal MR images,"Brain tumor segmentation plays a substantial role in Medical Image Analysis (MIS). In this regard, automatic segmentation methods facilitate precise and efficient segmentation, significantly contributing to diagnosis and treatment planning in medical applications. Recently, several Deep Learning-based architectures have been proposed to revolutionize the MIS field. Particularly, the combination of Convolution Neural Networks (CNNs) and Transformers has greatly enhanced and developed segmentation results. Moreover, the Attention mechanism in Transformers allows the modeling of long-range contextual features extracted from CNNs' encoder part. This paper proposes a hybrid advanced 3D model for brain tumor segmentation using multi-modal magnetic resonance images. The model benefits from the features extracted from the encoder of 3DU-Net and V-Net architectures at each depth. Then, a concatenation between these features and their fusion is carried out at each decoder depth to build new significant features followed by a 3D convolution layer and Transformers block for more contextual information. In addition, a final convolution block is applied to get the segmented tumor. To this end, the model is evaluated on the BraTS 2020 dataset to segment different sub-regions of brain tumors. The obtained results demonstrate the effectiveness of the proposed model in terms of dice similarity coefficient (DSC) and Hausdorff Distance (HD). For DSC, 91.95% and 82.80% and 81.70% for Whole Tumor(WT), Tumor Core (TC), and Enhancing Tumor(ET), respectively are archived, while for HD, 4.9 mm, 6.0 mm and 3.8 mm for WT, TC and ET are accomplished.","<method>Deep Learning-based architectures</method>, <method>Convolution Neural Networks (CNNs)</method>, <method>Transformers</method>, <method>Attention mechanism in Transformers</method>, <method>3DU-Net</method>, <method>V-Net</method>, <method>3D convolution layer</method>, <method>Transformers block</method>",<method>Convolution Neural Networks (CNNs)</method><method>Transformers</method><method>Attention mechanism in Transformers</method><method>3DU-Net</method><method>V-Net</method><method>3D convolution layer</method>
2024,https://openalex.org/W4392529708,Engineering,A machine learning-based framework for clustering residential electricity load profiles to enhance demand response programs,"Load shapes derived from smart meter data are frequently employed to analyze daily energy consumption patterns, particularly in the context of applications like Demand Response (DR). Nevertheless, one of the most important challenges to this endeavor lies in identifying the most suitable consumer clusters with similar consumption behaviors. In this paper, we present a novel machine learning based framework in order to achieve optimal load profiling through a real case study, utilizing data from almost 5000 households in London. Four widely used clustering algorithms are applied specifically K-means, K-medoids, Hierarchical Agglomerative Clustering and Density-based Spatial Clustering. An empirical analysis as well as multiple evaluation metrics are leveraged to assess those algorithms. Following that, we redefine the problem as a probabilistic classification one, with the classifier emulating the behavior of a clustering algorithm, leveraging Explainable AI (xAI) to enhance the interpretability of our solution. According to the clustering algorithm analysis the optimal number of clusters for this case is seven. Despite that, our methodology shows that two of the clusters, almost 10% of the dataset, exhibit significant internal dissimilarity. As a result, these clusters have been excluded from consideration for DR programs. The scalability and versatility of our solution makes it an ideal choice for power utility companies aiming to segment their users for creating more targeted DR programs.","<method>K-means</method>, <method>K-medoids</method>, <method>Hierarchical Agglomerative Clustering</method>, <method>Density-based Spatial Clustering</method>, <method>probabilistic classification</method>, <method>Explainable AI (xAI)</method>",<method>K-means</method><method>K-medoids</method><method>Hierarchical Agglomerative Clustering</method><method>Density-based Spatial Clustering</method><method>probabilistic classification</method><method>Explainable AI (xAI)</method>
2024,https://openalex.org/W4400937555,Engineering,The diagnostic and triage accuracy of the GPT-3 artificial intelligence model: an observational study,"BackgroundArtificial intelligence (AI) applications in health care have been effective in many areas of medicine, but they are often trained for a single task using labelled data, making deployment and generalisability challenging. How well a general-purpose AI language model performs diagnosis and triage relative to physicians and laypeople is not well understood.MethodsWe compared the predictive accuracy of Generative Pre-trained Transformer 3 (GPT-3)'s diagnostic and triage ability for 48 validated synthetic case vignettes (<50 words; sixth-grade reading level or below) of both common (eg, viral illness) and severe (eg, heart attack) conditions to a nationally representative sample of 5000 lay people from the USA who could use the internet to find the correct options and 21 practising physicians at Harvard Medical School. There were 12 vignettes for each of four triage categories: emergent, within one day, within 1 week, and self-care. The correct diagnosis and triage category (ie, ground truth) for each vignette was determined by two general internists at Harvard Medical School. For each vignette, human respondents and GPT-3 were prompted to list diagnoses in order of likelihood, and the vignette was marked as correct if the ground-truth diagnosis was in the top three of the listed diagnoses. For triage accuracy, we examined whether the human respondents' and GPT-3's selected triage was exactly correct according to the four triage categories, or matched a dichotomised triage variable (emergent or within 1 day vs within 1 week or self-care). We estimated GPT-3's diagnostic and triage confidence on a given vignette using a modified bootstrap resampling procedure, and examined how well calibrated GPT-3's confidence was by computing calibration curves and Brier scores. We also performed subgroup analysis by case acuity, and an error analysis for triage advice to characterise how its advice might affect patients using this tool to decide if they should seek medical care immediately.FindingsAmong all cases, GPT-3 replied with the correct diagnosis in its top three for 88% (42/48, 95% CI 75–94) of cases, compared with 54% (2700/5000, 53–55) for lay individuals (p<0.0001) and 96% (637/666, 94–97) for physicians (p=0·012). GPT-3 triaged 70% correct (34/48, 57–82) versus 74% (3706/5000, 73–75; p=0.60) for lay individuals and 91% (608/666, 89–93%; p<0.0001) for physicians. As measured by the Brier score, GPT-3 confidence in its top prediction was reasonably well calibrated for diagnosis (Brier score=0·18) and triage (Brier score=0·22). We observed an inverse relationship between case acuity and GPT-3 accuracy (p<0·0001) with a fitted trend line of –8·33% decrease in accuracy for every level of increase in case acuity. For triage error analysis, GPT-3 deprioritised truly emergent cases in seven instances.InterpretationA general-purpose AI language model without any content-specific training could perform diagnosis at levels close to, but below, physicians and better than lay individuals. We found that GPT-3's performance was inferior to physicians for triage, sometimes by a large margin, and its performance was closer to that of lay individuals. Although the diagnostic performance of GPT-3 was comparable to physicians, it was significantly better than a typical person using a search engine.FundingThe National Heart, Lung, and Blood Institute.","<method>Generative Pre-trained Transformer 3 (GPT-3)</method>, <method>modified bootstrap resampling procedure</method>",<method>Generative Pre-trained Transformer 3 (GPT-3)</method>
2024,https://openalex.org/W4390492410,Engineering,Deep Learning for Integrated Origin–Destination Estimation and Traffic Sensor Location Problems,"Traffic control and management applications require the full realization of traffic flow data. Frequently, such data are acquired by traffic sensors with two issues: it is not practicable or even possible to place traffic sensors on every link in a network; sensors do not provide direct information about origin–destination (O–D) demand flows. Therefore, it is imperative to locate the best places to deploy traffic sensors and then augment the knowledge obtained from this link flow sample to predict the entire traffic flow of the network. This article provides a resilient deep learning (DL) architecture combined with a global sensitivity analysis tool to solve O–D estimation and sensor location problems simultaneously. The proposed DL architecture is based on the stacked sparse autoencoder (SAE) model for accurately estimating the entire O–D flows of the network using link flows, thus reversing the conventional traffic assignment problem. The SAE model extracts traffic flow characteristics and derives a meaningful relationship between traffic flow data and network topology. To train the proposed DL architecture, synthetic link flow data were created randomly from the historical demand data of the network. Finally, a global sensitivity analysis was implemented to prioritize the importance of each link in the O–D estimation step to solve the sensor location problem. Two networks of different sizes were used to validate the performance of the model. The efficiency of the proposed method for solving the combination of traffic flow estimation and sensor location problems was confirmed from a low root-mean-square error with a reduction in the number of link flows required.","<method>deep learning (DL) architecture</method>, <method>stacked sparse autoencoder (SAE) model</method>, <method>global sensitivity analysis</method>",<method>stacked sparse autoencoder (SAE) model</method>
2024,https://openalex.org/W4400798015,Engineering,Evaluation of artificial intelligence-powered screening for sexually transmitted infections-related skin lesions using clinical images and metadata,"Abstract Background Sexually transmitted infections (STIs) pose a significant global public health challenge. Early diagnosis and treatment reduce STI transmission, but rely on recognising symptoms and care-seeking behaviour of the individual. Digital health software that distinguishes STI skin conditions could improve health-seeking behaviour. We developed and evaluated a deep learning model to differentiate STIs from non-STIs based on clinical images and symptoms. Methods We used 4913 clinical images of genital lesions and metadata from the Melbourne Sexual Health Centre collected during 2010–2023. We developed two binary classification models to distinguish STIs from non-STIs: (1) a convolutional neural network (CNN) using images only and (2) an integrated model combining both CNN and fully connected neural network (FCN) using images and metadata. We evaluated the model performance by the area under the ROC curve (AUC) and assessed metadata contributions to the Image-only model. Results Our study included 1583 STI and 3330 non-STI images. Common STI diagnoses were syphilis (34.6%), genital warts (24.5%) and herpes (19.4%), while most non-STIs (80.3%) were conditions such as dermatitis, lichen sclerosis and balanitis. In both STI and non-STI groups, the most frequently observed groups were 25–34 years (48.6% and 38.2%, respectively) and heterosexual males (60.3% and 45.9%, respectively). The Image-only model showed a reasonable performance with an AUC of 0.859 (SD 0.013). The Image + Metadata model achieved a significantly higher AUC of 0.893 (SD 0.018) compared to the Image-only model ( p &lt; 0.01). Out of 21 metadata, the integration of demographic and dermatological metadata led to the most significant improvement in model performance, increasing AUC by 6.7% compared to the baseline Image-only model. Conclusions The Image + Metadata model outperformed the Image-only model in distinguishing STIs from other skin conditions. Using it as a screening tool in a clinical setting may require further development and evaluation with larger datasets.","<method>convolutional neural network (CNN)</method>, <method>fully connected neural network (FCN)</method>",<method>convolutional neural network (CNN)</method><method>fully connected neural network (FCN)</method>
2024,https://openalex.org/W4391243055,Social Sciences,Systematic literature review: Quantum machine learning and its applications,"Quantum physics has changed the way we understand our environment, and one of its branches, quantum mechanics, has demonstrated accurate and consistent theoretical results. Quantum computing is the process of performing calculations using quantum mechanics. This field studies the quantum behavior of certain subatomic particles (photons, electrons, etc.) for subsequent use in performing calculations, as well as for large-scale information processing. These advantages are achieved through the use of quantum features, such as entanglement or superposition. These capabilities can give quantum computers an advantage in terms of computational time and cost over classical computers. Nowadays, scientific challenges are impossible to perform by classical computation due to computational complexity (more bytes than atoms in the observable universe) or the time it would take (thousands of years), and quantum computation is the only known answer. However, current quantum devices do not have yet the necessary qubits and are not fault-tolerant enough to achieve these goals. Nonetheless, there are other fields like machine learning, finance, or chemistry where quantum computation could be useful with current quantum devices. This manuscript aims to present a review of the literature published between 2017 and 2023 to identify, analyze, and classify the different types of algorithms used in quantum machine learning and their applications. The methodology follows the guidelines related to Systematic Literature Review methods, such as the one proposed by Kitchenham and other authors in the software engineering field. Consequently, this study identified 94 articles that used quantum machine learning techniques and algorithms and shows their implementation using computational quantum circuits or ansatzs. The main types of found algorithms are quantum implementations of classical machine learning algorithms, such as support vector machines or the k-nearest neighbor model, and classical deep learning algorithms, like quantum neural networks. One of the most relevant applications in the machine learning field is image classification. Many articles, especially within the classification, try to solve problems currently answered by classical machine learning but using quantum devices and algorithms. Even though results are promising, quantum machine learning is far from achieving its full potential. An improvement in quantum hardware is required for this potential to be achieved since the existing quantum computers lack enough quality, speed, and scale to allow quantum computing to achieve its full potential.","<method>support vector machines</method>, <method>k-nearest neighbor model</method>, <method>quantum neural networks</method>",<method>support vector machines</method><method>k-nearest neighbor model</method><method>quantum neural networks</method>
2024,https://openalex.org/W4391528827,Social Sciences,Deep learning-aided decision support for diagnosis of skin disease across skin tones,"Abstract Although advances in deep learning systems for image-based medical diagnosis demonstrate their potential to augment clinical decision-making, the effectiveness of physician–machine partnerships remains an open question, in part because physicians and algorithms are both susceptible to systematic errors, especially for diagnosis of underrepresented populations. Here we present results from a large-scale digital experiment involving board-certified dermatologists ( n = 389) and primary-care physicians ( n = 459) from 39 countries to evaluate the accuracy of diagnoses submitted by physicians in a store-and-forward teledermatology simulation. In this experiment, physicians were presented with 364 images spanning 46 skin diseases and asked to submit up to four differential diagnoses. Specialists and generalists achieved diagnostic accuracies of 38% and 19%, respectively, but both specialists and generalists were four percentage points less accurate for the diagnosis of images of dark skin as compared to light skin. Fair deep learning system decision support improved the diagnostic accuracy of both specialists and generalists by more than 33%, but exacerbated the gap in the diagnostic accuracy of generalists across skin tones. These results demonstrate that well-designed physician–machine partnerships can enhance the diagnostic accuracy of physicians, illustrating that success in improving overall diagnostic accuracy does not necessarily address bias.",<method>deep learning system decision support</method>,No methods remaining
2024,https://openalex.org/W4394681533,Social Sciences,REVIEWING THE IMPACT OF HEALTH INFORMATION TECHNOLOGY ON HEALTHCARE MANAGEMENT EFFICIENCY,"This research paper explores the intricate relationship between Health Information Technology (HIT) and healthcare management efficiency, investigating current trends, emerging technologies, and their potential implications. The study encompasses a thorough literature review, highlighting the impact of HIT on operational and clinical aspects of healthcare delivery. Key findings reveal the transformative role of technology in streamlining administrative processes, improving communication, and enhancing overall patient care. Ethical considerations, patient privacy, and regulation compliance are crucial factors in successfully implementing HIT. Looking towards the future, the paper anticipates the integration of emerging technologies such as Artificial Intelligence, Blockchain, and the Internet of Things, signalling a paradigm shift in healthcare management. While acknowledging the potential benefits, the research also underscores the importance of ethical frameworks, transparency, and user-centred design in adopting these technologies. The study concludes with reflections on the limitations of the research, suggesting avenues for future exploration. Recommendations emphasize the need for ongoing research, longitudinal studies, and a global perspective to ensure healthcare organizations effectively leverage technology while maintaining ethical standards. The findings of this research carry implications for healthcare practitioners, policymakers, and technology innovators, encouraging a strategic and ethical approach to the ever-evolving landscape of health information technology.&#x0D; Keywords: Health Information Technology, Healthcare Management Efficiency, Emerging Technologies, Ethical Considerations, Patient Privacy.",<method>Artificial Intelligence</method>,No methods remaining
2024,https://openalex.org/W4390637043,Social Sciences,Blockchain meets machine learning: a survey,"Abstract Blockchain and machine learning are two rapidly growing technologies that are increasingly being used in various industries. Blockchain technology provides a secure and transparent method for recording transactions, while machine learning enables data-driven decision-making by analyzing large amounts of data. In recent years, researchers and practitioners have been exploring the potential benefits of combining these two technologies. In this study, we cover the fundamentals of blockchain and machine learning and then discuss their integrated use in finance, medicine, supply chain, and security, including a literature review and their contribution to the field such as increased security, privacy, and decentralization. Blockchain technology enables secure and transparent decentralized record-keeping, while machine learning algorithms can analyze vast amounts of data to derive valuable insights. Together, they have the potential to revolutionize industries by enhancing efficiency through automated and trustworthy processes, enabling data-driven decision-making, and strengthening security measures by reducing vulnerabilities and ensuring the integrity of information. However, there are still some important challenges to be handled prior to the common use of blockchain and machine learning such as security issues, strategic planning, information processing, and scalable workflows. Nevertheless, until the difficulties that have been identified are resolved, their full potential will not be achieved.",<method>machine learning algorithms</method>,No methods remaining
2024,https://openalex.org/W4393119757,Social Sciences,Unmasking bias in artificial intelligence: a systematic review of bias detection and mitigation strategies in electronic health record-based models,"Abstract Objectives Leveraging artificial intelligence (AI) in conjunction with electronic health records (EHRs) holds transformative potential to improve healthcare. However, addressing bias in AI, which risks worsening healthcare disparities, cannot be overlooked. This study reviews methods to handle various biases in AI models developed using EHR data. Materials and Methods We conducted a systematic review following the Preferred Reporting Items for Systematic Reviews and Meta-analyses guidelines, analyzing articles from PubMed, Web of Science, and IEEE published between January 01, 2010 and December 17, 2023. The review identified key biases, outlined strategies for detecting and mitigating bias throughout the AI model development, and analyzed metrics for bias assessment. Results Of the 450 articles retrieved, 20 met our criteria, revealing 6 major bias types: algorithmic, confounding, implicit, measurement, selection, and temporal. The AI models were primarily developed for predictive tasks, yet none have been deployed in real-world healthcare settings. Five studies concentrated on the detection of implicit and algorithmic biases employing fairness metrics like statistical parity, equal opportunity, and predictive equity. Fifteen studies proposed strategies for mitigating biases, especially targeting implicit and selection biases. These strategies, evaluated through both performance and fairness metrics, predominantly involved data collection and preprocessing techniques like resampling and reweighting. Discussion This review highlights evolving strategies to mitigate bias in EHR-based AI models, emphasizing the urgent need for both standardized and detailed reporting of the methodologies and systematic real-world testing and evaluation. Such measures are essential for gauging models’ practical impact and fostering ethical AI that ensures fairness and equity in healthcare.","<method>resampling</method>, <method>reweighting</method>",<method>resampling</method><method>reweighting</method>
2024,https://openalex.org/W4402827393,Social Sciences,Larger and more instructable language models become less reliable,"Abstract The prevailing methods to make large language models more powerful and amenable have been based on continuous scaling up (that is, increasing their size, data volume and computational resources 1 ) and bespoke shaping up (including post-filtering 2,3 , fine tuning or use of human feedback 4,5 ). However, larger and more instructable large language models may have become less reliable. By studying the relationship between difficulty concordance, task avoidance and prompting stability of several language model families, here we show that easy instances for human participants are also easy for the models, but scaled-up, shaped-up models do not secure areas of low difficulty in which either the model does not err or human supervision can spot the errors. We also find that early models often avoid user questions but scaled-up, shaped-up models tend to give an apparently sensible yet wrong answer much more often, including errors on difficult questions that human supervisors frequently overlook. Moreover, we observe that stability to different natural phrasings of the same question is improved by scaling-up and shaping-up interventions, but pockets of variability persist across difficulty levels. These findings highlight the need for a fundamental shift in the design and development of general-purpose artificial intelligence, particularly in high-stakes areas for which a predictable distribution of errors is paramount.","<method>continuous scaling up</method>, <method>post-filtering</method>, <method>fine tuning</method>, <method>use of human feedback</method>",<method>post-filtering</method><method>fine tuning</method><method>use of human feedback</method>
2024,https://openalex.org/W4392343921,Social Sciences,Data extraction for evidence synthesis using a large language model: A proof‐of‐concept study,"Abstract Data extraction is a crucial, yet labor‐intensive and error‐prone part of evidence synthesis. To date, efforts to harness machine learning for enhancing efficiency of the data extraction process have fallen short of achieving sufficient accuracy and usability. With the release of large language models (LLMs), new possibilities have emerged to increase efficiency and accuracy of data extraction for evidence synthesis. The objective of this proof‐of‐concept study was to assess the performance of an LLM (Claude 2) in extracting data elements from published studies, compared with human data extraction as employed in systematic reviews. Our analysis utilized a convenience sample of 10 English‐language, open‐access publications of randomized controlled trials included in a single systematic review. We selected 16 distinct types of data, posing varying degrees of difficulty (160 data elements across 10 studies). We used the browser version of Claude 2 to upload the portable document format of each publication and then prompted the model for each data element. Across 160 data elements, Claude 2 demonstrated an overall accuracy of 96.3% with a high test–retest reliability (replication 1: 96.9%; replication 2: 95.0% accuracy). Overall, Claude 2 made 6 errors on 160 data items. The most common errors ( n = 4) were missed data items. Importantly, Claude 2's ease of use was high; it required no technical expertise or labeled training data for effective operation (i.e., zero‐shot learning). Based on findings of our proof‐of‐concept study, leveraging LLMs has the potential to substantially enhance the efficiency and accuracy of data extraction for evidence syntheses.","<method>large language models (LLMs)</method>, <method>zero‐shot learning</method>",<method>zero‐shot learning</method>
2024,https://openalex.org/W4390569131,Social Sciences,Rapport with a chatbot? The underlying role of anthropomorphism in socio-cognitive perceptions of rapport and e-word of mouth,"This study examines the impact of rapport with chatbots on electronic word of mouth (e-WOM), in the first phase, by considering several antecedents including anthropomorphism. In the second phase, deeper insights are provided into the moderated mediation role of rapport and the moderated moderation effect of value creation and hedonic motivation on e-WOM engagement. With tourism services as the research context, a survey was conducted among 257 visitors from three countries (China, India and New Zealand), selected due to their diverse cultural backgrounds and higher number of inbound visitors to Australia. The partial least squares method was used for data analysis along with multi-group analysis. Findings report the positive role of anthropomorphism in developing rapport with chatbots in digital interactions. Interestingly, rapport had the highest moderated mediation impact in the data from China followed by the data from India. The moderated moderation impact of hedonic motivation was only significant in the data from China, whereas value creation was a significant moderator in the data from both China and New Zealand. The study extends social exchange theory in a human–chatbot or artificial intelligence (AI) interaction context with cultural implications. The findings are useful for organizations relying on customer rapport with AI-based chatbots to ensure long-term customer service through digital interactions.","<method>partial least squares method</method>, <method>multi-group analysis</method>",No methods remaining
2024,https://openalex.org/W4391508432,Social Sciences,Artificial intelligence-driven virtual rehabilitation for people living in the community: A scoping review,"Abstract Virtual Rehabilitation (VRehab) is a promising approach to improving the physical and mental functioning of patients living in the community. The use of VRehab technology results in the generation of multi-modal datasets collected through various devices. This presents opportunities for the development of Artificial Intelligence (AI) techniques in VRehab, namely the measurement, detection, and prediction of various patients’ health outcomes. The objective of this scoping review was to explore the applications and effectiveness of incorporating AI into home-based VRehab programs. PubMed/MEDLINE, Embase, IEEE Xplore, Web of Science databases, and Google Scholar were searched from inception until June 2023 for studies that applied AI for the delivery of VRehab programs to the homes of adult patients. After screening 2172 unique titles and abstracts and 51 full-text studies, 13 studies were included in the review. A variety of AI algorithms were applied to analyze data collected from various sensors and make inferences about patients’ health outcomes, most involving evaluating patients’ exercise quality and providing feedback to patients. The AI algorithms used in the studies were mostly fuzzy rule-based methods, template matching, and deep neural networks. Despite the growing body of literature on the use of AI in VRehab, very few studies have examined its use in patients’ homes. Current research suggests that integrating AI with home-based VRehab can lead to improved rehabilitation outcomes for patients. However, further research is required to fully assess the effectiveness of various forms of AI-driven home-based VRehab, taking into account its unique challenges and using standardized metrics.","<method>fuzzy rule-based methods</method>, <method>template matching</method>, <method>deep neural networks</method>",<method>fuzzy rule-based methods</method><method>deep neural networks</method>
2024,https://openalex.org/W4390483800,Social Sciences,Comprehensive Risk Analysis and Decision-Making Model for Hydroelectricity Energy Investments,"The risks of hydroelectricity energy investments should be managed effectively to increase the performance of these projects. Thus, more significant risks should be identified to take effective measures for risk management without experiencing high costs. Accordingly, the purpose of this study is to define critical risks in hydroelectricity energy investment projects by making a priority analysis. Within this scope, a new decision-making model is created. In the first stage, five different risks are examined by considering Spherical fuzzy Entropy. Moreover, the second stage consists of ranking emerging seven countries with the help of Spherical fuzzy multi-attribute ideal-real comparative assessment (MAIRCA). The main contribution of this study is that more important risks of hydroelectricity energy investments can be identified by the help of the priority analysis. This situation provides an opportunity to implement effective strategies to increase these investments without having high costs. Additionally, considering Spherical fuzzy sets has a positive impact on the appropriateness of the results. Since these numbers use a wider data range, the effectiveness of the analysis results can increase. It is determined that the most important risk is environmental risk with the highest weight value of 0.2478. Financial risks and personnel risks are other significant factors that affect the performance of the hydroelectricity energy investments. Furthermore, as a result of ranking the alternatives, it is seen that China is the most suitable country for hydroelectric energy investments. India and Mexico are other successful countries in this respect. However, Turkey and Indonesia have lower performance for this situation.","<method>Spherical fuzzy Entropy</method>, <method>Spherical fuzzy multi-attribute ideal-real comparative assessment (MAIRCA)</method>",No methods remaining
2024,https://openalex.org/W4393092671,Social Sciences,CFSSynergy: Combining Feature-Based and Similarity-Based Methods for Drug Synergy Prediction,"Drug synergy prediction plays a vital role in cancer treatment. Because experimental approaches are labor-intensive and expensive, computational-based approaches get more attention. There are two types of computational methods for drug synergy prediction: feature-based and similarity-based. In feature-based methods, the main focus is to extract more discriminative features from drug pairs and cell lines to pass to the task predictor. In similarity-based methods, the similarities among all drugs and cell lines are utilized as features and fed into the task predictor. In this work, a novel approach, called CFSSynergy, that combines these two viewpoints is proposed. First, a discriminative representation is extracted for paired drugs and cell lines as input. We have utilized transformer-based architecture for drugs. For cell lines, we have created a similarity matrix between proteins using the Node2Vec algorithm. Then, the new cell line representation is computed by multiplying the protein–protein similarity matrix and the initial cell line representation. Next, we compute the similarity between unique drugs and unique cells using the learned representation for paired drugs and cell lines. Then, we compute a new representation for paired drugs and cell lines based on the similarity-based features and the learned features. Finally, these features are fed to XGBoost as a task predictor. Two well-known data sets were used to evaluate the performance of our proposed method: DrugCombDB and OncologyScreen. The CFSSynergy approach consistently outperformed existing methods in comparative evaluations. This substantiates the efficacy of our approach in capturing complex synergistic interactions between drugs and cell lines, setting it apart from conventional similarity-based or feature-based methods.","<method>transformer-based architecture</method>, <method>Node2Vec algorithm</method>, <method>XGBoost</method>",<method>transformer-based architecture</method><method>Node2Vec algorithm</method><method>XGBoost</method>
2024,https://openalex.org/W4400015499,Social Sciences,Building entrepreneurial resilience during crisis using generative AI: An empirical study on SMEs,"Recently, Gen AI has garnered significant attention across various sectors of society, particularly capturing the interest of small business due to its capacity to allow them to reassess their business models with minimal investment. To understand how small and medium-sized firms have utilised Gen AI-based tools to cope with the market's high level of turbulence caused by the COVID-19 pandemic, geopolitical crises, and economic slowdown, researchers have conducted an empirical study. Although Gen AI is receiving more attention, there remains a dearth of empirical studies that investigate how it influences the entrepreneurial orientation of firms and their ability to cultivate entrepreneurial resilience amidst market turbulence. Most of the literature offers anecdotal evidence. To address this research gap, the authors have grounded their theoretical model and research hypotheses in the contingent view of dynamic capability. They tested the research hypotheses using cross-sectional data from a pre-tested survey instrument, which yielded 87 useable responses from small and medium enterprises in France. The authors used variance-based structural equation modelling with the commercial WarpPLS 7.0 software to test the theoretical model. The study's findings suggest that Gen AI and EO have a significant influence on building entrepreneurial resilience as higher-order and lower-order dynamic capabilities. However, market turbulence has a negative moderating effect on the path that joins entrepreneurial orientation and entrepreneurial resilience. The results suggest that the assumption that high market turbulence will have positive effects on dynamic capabilities and competitive advantage is not always true, and the linear assumption does not hold, which is consistent with some scholars' assumptions. The study's results offer significant contributions to the contingent view of dynamic capabilities and open new research avenues that require further investigation into the non-linear relationship of market turbulence.",<method>variance-based structural equation modelling</method>,No methods remaining
2024,https://openalex.org/W4390755438,Social Sciences,A voting gray wolf optimizer-based ensemble learning models for intrusion detection in the Internet of Things,"Abstract The Internet of Things (IoT) has garnered considerable attention from academic and industrial circles as a pivotal technology in recent years. The escalation of security risks is observed to be associated with the growing interest in IoT applications. Intrusion detection systems (IDS) have been devised as viable instruments for identifying and averting malicious actions in this context. Several techniques described in academic papers are thought to be very accurate, but they cannot be used in the real world because the datasets used to build and test the models do not accurately reflect and simulate the IoT network. Existing methods, on the other hand, deal with these issues, but they are not good enough for commercial use because of their lack of precision, low detection rate, receiver operating characteristic (ROC), and false acceptance rate (FAR). The effectiveness of these solutions is predominantly dependent on individual learners and is consequently influenced by the inherent limitations of each learning algorithm. This study introduces a new approach for detecting intrusion attacks in an IoT network, which involves the use of an ensemble learning technique based on gray wolf optimizer (GWO). The novelty of this study lies in the proposed voting gray wolf optimizer (GWO) ensemble model, which incorporates two crucial components: a traffic analyzer and a classification phase engine. The model employs a voting technique to combine the probability averages of the base learners. Secondly, the combination of feature selection and feature extraction techniques is to reduce dimensionality. Thirdly, the utilization of GWO is employed to optimize the parameters of ensemble models. Similarly, the approach employs the most authentic intrusion detection datasets that are accessible and amalgamates multiple learners to generate ensemble learners. The hybridization of information gain (IG) and principal component analysis (PCA) was employed to reduce dimensionality. The study utilized a novel GWO ensemble learning approach that incorporated a decision tree, random forest, K-nearest neighbor, and multilayer perceptron for classification. To evaluate the efficacy of the proposed model, two authentic datasets, namely, BoT-IoT and UNSW-NB15, were scrutinized. The GWO-optimized ensemble model demonstrates superior accuracy when compared to other machine learning-based and deep learning models. Specifically, the model achieves an accuracy rate of 99.98%, a DR of 99.97%, a precision rate of 99.94%, an ROC rate of 99.99%, and an FAR rate of 1.30 on the BoT-IoT dataset. According to the experimental results, the proposed ensemble model optimized by GWO achieved an accuracy of 100%, a DR of 99.9%, a precision of 99.59%, an ROC of 99.40%, and an FAR of 1.5 when tested on the UNSW-NB15 dataset.","<method>ensemble learning technique</method>, <method>gray wolf optimizer (GWO)</method>, <method>voting technique</method>, <method>feature selection</method>, <method>feature extraction</method>, <method>information gain (IG)</method>, <method>principal component analysis (PCA)</method>, <method>decision tree</method>, <method>random forest</method>, <method>K-nearest neighbor</method>, <method>multilayer perceptron</method>",<method>ensemble learning technique</method><method>gray wolf optimizer (GWO)</method><method>voting technique</method><method>feature selection</method><method>information gain (IG)</method><method>principal component analysis (PCA)</method><method>decision tree</method><method>random forest</method><method>K-nearest neighbor</method><method>multilayer perceptron</method>
2024,https://openalex.org/W4390843293,Social Sciences,Assessing the Banking Sector of Bosnia and Herzegovina: An Analysis of Financial Indicators through the MEREC and MARCOS Methods,"Abstract The banking sector assumes a pivotal role in the economic development of nations. The assessment of financial indicators pertaining to banks holds fundamental importance in the evaluation of bank stability and sustainability. This research employs the MEREC (Method based on the Removal Effects of Criteria) and MARCOS (Measurement of Alternatives and Ranking according to COmpromise Solution) methodologies to delve deeper into the financial landscape of the banking sector in Bosnia and Herzegovina (BiH). Specifically, the objective is to rank banks according to their financial indicators, utilizing financial data from the year 2022. The MEREC method is applied to gauge the significance of financial indicators and ascertain their respective weights, while the MARCOS method is employed to rank banks within BiH based on their financial indicators. The examination of financial indicators within the BiH banking sector, facilitated by the MEREC and MARCOS methodologies, yields a more comprehensive understanding of the sector’s present condition. Limitations of this research, which primarily stem from its reliance on available financial data and predefined methodologies, lies within limited consideration for external factors. To provide a broader contextual perspective, the inclusion of additional financial indicators and comparative analyses with banking sectors of other nations would be imperative. The findings of this research reveal that Raiffeisen Bank exhibits the most favourable financial indicators and demonstrates the highest level of efficiency within this context. Consequently, this research offers insights into identifying exemplary banks that can serve as models for enhancing the performance of others.","<method>MEREC (Method based on the Removal Effects of Criteria)</method>, <method>MARCOS (Measurement of Alternatives and Ranking according to COmpromise Solution)</method>",No methods remaining
2024,https://openalex.org/W4391454392,Social Sciences,UANet: An Uncertainty-Aware Network for Building Extraction From Remote Sensing Images,"Building extraction aims to segment building pixels from remote sensing images and plays an essential role in many applications, such as city planning and urban dynamic monitoring. Over the past few years, deep learning methods with encoder–decoder architectures have achieved remarkable performance due to their powerful feature representation capability. Nevertheless, due to the varying scales and styles of buildings, conventional deep learning models always suffer from uncertain predictions and cannot accurately distinguish the complete footprints of the building from the complex distribution of ground objects, leading to a large degree of omission and commission. In this paper, we realize the importance of uncertain prediction and propose a novel and straightforward Uncertainty-Aware Network (UANet) to alleviate this problem. Specifically, we first apply a general encoder–decoder network to obtain a building extraction map with relatively high uncertainty. Second, in order to aggregate the useful information in the highest-level features, we design a Prior Information Guide Module to guide the highest-level features in learning the prior information from the conventional extraction map. Third, based on the uncertain extraction map, we introduce an Uncertainty Rank Algorithm to measure the uncertainty level of each pixel belonging to the foreground and the background. We further combine this algorithm with the proposed Uncertainty-Aware Fusion Module to facilitate level-by-level feature refinement and obtain the final refined extraction map with low uncertainty. To verify the performance of our proposed UANet, we conduct extensive experiments on three public building datasets, including the WHU building dataset, the Massachusetts building dataset, and the Inria aerial image dataset. Results demonstrate that the proposed UANet outperforms other state-of-the-art algorithms by a large margin. The source code of the proposed UANet is available at https://github.com/Henryjiepanli/Uncertainty-aware-Network.","<method>deep learning methods with encoder–decoder architectures</method>, <method>encoder–decoder network</method>, <method>Uncertainty-Aware Network (UANet)</method>, <method>Prior Information Guide Module</method>, <method>Uncertainty Rank Algorithm</method>, <method>Uncertainty-Aware Fusion Module</method>",<method>deep learning methods with encoder–decoder architectures</method><method>encoder–decoder network</method>
2024,https://openalex.org/W4393380945,Social Sciences,One-Step Multi-View Clustering With Diverse Representation,"Multi-View clustering has attracted broad attention due to its capacity to utilize consistent and complementary information among views. Although tremendous progress has been made recently, most existing methods undergo high complexity, preventing them from being applied to large-scale tasks. Multi-View clustering via matrix factorization is a representative to address this issue. However, most of them map the data matrices into a fixed dimension, limiting the model's expressiveness. Moreover, a range of methods suffers from a two-step process, i.e., multimodal learning and the subsequent <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> <tex-math notation=""LaTeX"">$k$</tex-math> </inline-formula> -means, inevitably causing a suboptimal clustering result. In light of this, we propose a one-step multi-view clustering with diverse representation (OMVCDR) method, which incorporates multi-view learning and <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> <tex-math notation=""LaTeX"">$k$</tex-math> </inline-formula> -means into a unified framework. Specifically, we first project original data matrices into various latent spaces to attain comprehensive information and auto-weight them in a self-supervised manner. Then, we directly use the information matrices under diverse dimensions to obtain consensus discrete clustering labels. The unified work of representation learning and clustering boosts the quality of the final results. Furthermore, we develop an efficient optimization algorithm with proven convergence to solve the resultant problem. Comprehensive experiments on various datasets demonstrate the promising clustering performance of our proposed method. The code is publicly available at https://github.com/wanxinhang/OMVCDR.","<method>Multi-View clustering via matrix factorization</method>, <method>k-means</method>, <method>one-step multi-view clustering with diverse representation (OMVCDR)</method>, <method>multi-view learning</method>, <method>self-supervised auto-weighting</method>, <method>representation learning</method>",<method>Multi-View clustering via matrix factorization</method><method>k-means</method><method>multi-view learning</method><method>representation learning</method>
2024,https://openalex.org/W4401434014,Social Sciences,Crafting personalized learning paths with AI for lifelong learning: a systematic literature review,"The rapid evolution of knowledge requires constantly acquiring and updating skills, making lifelong learning crucial. Despite decades of artificial intelligence, recent advances promote new solutions to personalize learning in this context. The purpose of this article is to explore the current state of research on the development of artificial intelligence-mediated solutions for the design of personalized learning paths. To achieve this, a systematic literature review (SRL) of 78 articles published between 2019 and 2024 from the Scopus and Web or Science databases was conducted, answering seven questions grouped into three themes: characteristics of the published research, context of the research, and type of solution analyzed. This study identified that: (a) the greatest production of scientific research on the topic is developed in China, India and the United States, (b) the focus is mainly directed towards the educational context at the higher education level with areas of opportunity for application in the work context, and (c) the development of adaptive learning technologies predominates; however, there is a growing interest in the application of generative language models. This article contributes to the growing interest and literature related to personalized learning under artificial intelligence mediated solutions that will serve as a basis for academic institutions and organizations to design programs under this model.","<method>adaptive learning technologies</method>, <method>generative language models</method>",<method>generative language models</method>
2024,https://openalex.org/W4391071022,Social Sciences,Weaving a greener future: The impact of green human resources management and green supply chain management on sustainable performance in Bangladesh's textile industry,"The purpose of this study is to investigate the impact of Green Human Resource Management (GHRM) and Green Supply Chain Management (GSCM) on the sustainable performance of the Bangladeshi textile sector. Specifically, the study focuses on environmental and employee-related aspects. Additionally, we examine how environmental performance and employee performance mediate the relationship between GHRM and GSCM. This study draws upon data collected from 450 employees across various textile enterprises in Bangladesh. Structural Equation Modeling is employed using the Amos 24 software to analyze the relationships and interactions among these variables. These findings demonstrate that using environmentally sustainable practices in human resource management and supply chain management results in enhanced sustainability. The study indicates that environmental performance significantly influences the relationship between GHRM and GSCM regarding sustainable performance. The study findings indicate that firms operating in the textile industry should implement GHRM and GSCM practices to enhance their sustainability performance. Additionally, it is recommended that these organizations prioritize the well-being and engagement of their employees. Implementing such a strategy can bolster the organization's comprehensive sustainability initiatives and raise its standing among stakeholders. This study contributes to the expanding body of literature on textile sustainability by investigating the mediating role of employee and environmental performance. It emphasizes the significance of GHRM and GSCM techniques in improving sustainable performance. The findings provide valuable insights for firms seeking to develop more effective sustainability initiatives.",<method>Structural Equation Modeling</method>,No methods remaining
2024,https://openalex.org/W4392124217,Social Sciences,A structural equation modeling framework for exploring the industry 5.0 and sustainable supply chain determinants,"Sustainable Supply Chain and Industry 5.0 are two important concepts reshaping how businesses operate in the modern world. Together, these two concepts drive the advancement of a highly sustainable and robust worldwide economy. Companies are now becoming more sustainable in supply chain management, using technologies like blockchain and co-bots to track the origin of goods, ensure ethical and sustainable sourcing, and work with humans safely and effectively. This study develops a theoretical model highlighting the determinants of Industry 5.0, Sustainable Supply Chain Practices, by combining theoretical frameworks from the manufacturing, supply chain, and information systems literature. The study's analytic sample comprises 342 responses collected from professionals working in the electronics industry's supply chain. Hypotheses were constructed employing deductive reasoning, leveraging insights gleaned from prior research. The study is conducted utilizing the Structural Equation Modeling (SEM) to substantiate the presumed connections among various constructs, namely, Industry 5.0 innovations, Sustainable Supply Chain Practices (SSCP), Sustainable Supply Chain Performance (SCP), and Supply Chain Risks (SCR). The Structural Equation Modeling analysis results show a direct impact of Industry 5.0 technologies through Sustainable Supply Chain Practices can enhance Supply Chain Performance and mitigate Supply Chain Risks. Combining the two paradigms can foster the development of new business models that prioritize sustainability and contribute to a more equitable and environmentally friendly economy that brings positive change for both businesses and society.",<method>Structural Equation Modeling (SEM)</method>,No methods remaining
2024,https://openalex.org/W4390742710,Social Sciences,Machine Learning as a Tool for Hypothesis Generation,"Abstract While hypothesis testing is a highly formalized activity, hypothesis generation remains largely informal. We propose a systematic procedure to generate novel hypotheses about human behavior, which uses the capacity of machine learning algorithms to notice patterns people might not. We illustrate the procedure with a concrete application: judge decisions about whom to jail. We begin with a striking fact: the defendant’s face alone matters greatly for the judge’s jailing decision. In fact, an algorithm given only the pixels in the defendant’s mug shot accounts for up to half of the predictable variation. We develop a procedure that allows human subjects to interact with this black-box algorithm to produce hypotheses about what in the face influences judge decisions. The procedure generates hypotheses that are both interpretable and novel: they are not explained by demographics (e.g., race) or existing psychology research, nor are they already known (even if tacitly) to people or experts. Though these results are specific, our procedure is general. It provides a way to produce novel, interpretable hypotheses from any high-dimensional data set (e.g., cell phones, satellites, online behavior, news headlines, corporate filings, and high-frequency time series). A central tenet of our article is that hypothesis generation is a valuable activity, and we hope this encourages future work in this largely “prescientific” stage of science.",<method>machine learning algorithms</method>,No methods remaining
2024,https://openalex.org/W4394961856,Social Sciences,Applications and challenges of neural networks in otolaryngology (Review),"Artificial Intelligence (AI) has become a topic of interest that is frequently debated in all research fields. The medical field is no exception, where several unanswered questions remain. When and how this field can benefit from AI support in daily routines are the most frequently asked questions. The present review aims to present the types of neural networks (NNs) available for development, discussing their advantages, disadvantages and how they can be applied practically. In addition, the present review summarizes how NNs (combined with various other features) have already been applied in studies in the ear nose throat research field, from assisting diagnosis to treatment management. Although the answer to this question regarding AI remains elusive, understanding the basics and types of applicable NNs can lead to future studies possibly using more than one type of NN. This approach may bypass the actual limitations in accuracy and relevance of information generated by AI. The proposed studies, the majority of which used convolutional NNs, obtained accuracies varying 70-98%, with a number of studies having the AI trained on a limited number of cases (<100 patients). The lack of standardization in AI protocols for research negatively affects data homogeneity and transparency of databases.","<method>neural networks (NNs)</method>, <method>convolutional neural networks (convolutional NNs)</method>",<method>neural networks (NNs)</method><method>convolutional neural networks (convolutional NNs)</method>
2024,https://openalex.org/W4390913521,Social Sciences,A Review of Intraocular Lens Power Calculation Formulas Based on Artificial Intelligence,"Purpose: The proper selection of an intraocular lens power calculation formula is an essential aspect of cataract surgery. This study evaluated the accuracy of artificial intelligence-based formulas. Design: Systematic review. Methods: This review comprises articles evaluating the exactness of artificial intelligence-based formulas published from 2017 to July 2023. The papers were identified by a literature search of various databases (Pubmed/MEDLINE, Google Scholar, Crossref, Cochrane Library, Web of Science, and SciELO) using the terms “IOL formulas”, “FullMonte”, “Ladas”, “Hill-RBF”, “PEARL-DGS”, “Kane”, “Karmona”, “Hoffer QST”, and “Nallasamy”. In total, 25 peer-reviewed articles in English with the maximum sample and the largest number of compared formulas were examined. Results: The scores of the mean absolute error and percentage of patients within ±0.5 D and ±1.0 D were used to estimate the exactness of the formulas. In most studies the Kane formula obtained the smallest mean absolute error and the highest percentage of patients within ±0.5 D and ±1.0 D. Second place was typically achieved by the PEARL DGS formula. The limitations of the studies were also discussed. Conclusions: Kane seems to be the most accurate artificial intelligence-based formula. PEARL DGS also gives very good results. Hoffer QST, Karmona, and Nallasamy are the newest, and need further evaluation.","<method>FullMonte</method>, <method>Ladas</method>, <method>Hill-RBF</method>, <method>PEARL-DGS</method>, <method>Kane</method>, <method>Karmona</method>, <method>Hoffer QST</method>, <method>Nallasamy</method>",No methods remaining
2024,https://openalex.org/W4392516399,Social Sciences,Artificial intelligence in dermatology: advancements and challenges in skin of color,"Abstract Artificial intelligence (AI) uses algorithms and large language models in computers to simulate human‐like problem‐solving and decision‐making. AI programs have recently acquired widespread popularity in the field of dermatology through the application of online tools in the assessment, diagnosis, and treatment of skin conditions. A literature review was conducted using PubMed and Google Scholar analyzing recent literature (from the last 10 years through October 2023) to evaluate current AI programs in use for dermatologic purposes, identifying challenges in this technology when applied to skin of color (SOC), and proposing future steps to enhance the role of AI in dermatologic practice. Challenges surrounding AI and its application to SOC stem from the underrepresentation of SOC in datasets and issues with image quality and standardization. With these existing issues, current AI programs inevitably do worse at identifying lesions in SOC. Additionally, only 30% of the programs identified in this review had data reported on their use in dermatology, specifically in SOC. Significant development of these applications is required for the accurate depiction of darker skin tone images in datasets. More research is warranted in the future to better understand the efficacy of AI in aiding diagnosis and treatment options for SOC patients.","<method>algorithms</method>, <method>large language models</method>",No methods remaining
2024,https://openalex.org/W4390618081,Social Sciences,Making Sense of Machine Learning: A Review of Interpretation Techniques and Their Applications,"Transparency in AI models is essential for promoting human–AI collaboration and ensuring regulatory compliance. However, interpreting these models is a complex process influenced by various methods and datasets. This study presents a comprehensive overview of foundational interpretation techniques, meticulously referencing the original authors and emphasizing their pivotal contributions. Recognizing the seminal work of these pioneers is imperative for contextualizing the evolutionary trajectory of interpretation in the field of AI. Furthermore, this research offers a retrospective analysis of interpretation techniques, critically evaluating their inherent strengths and limitations. We categorize these techniques into model-based, representation-based, post hoc, and hybrid methods, delving into their diverse applications. Furthermore, we analyze publication trends over time to see how the adoption of advanced computational methods within various categories of interpretation techniques has shaped the development of AI interpretability over time. This analysis highlights a notable preference shift towards data-driven approaches in the field. Moreover, we consider crucial factors such as the suitability of these techniques for generating local or global insights and their compatibility with different data types, including images, text, and tabular data. This structured categorization serves as a guide for practitioners navigating the landscape of interpretation techniques in AI. In summary, this review not only synthesizes various interpretation techniques but also acknowledges the contributions of their original authors. By emphasizing the origins of these techniques, we aim to enhance AI model explainability and underscore the importance of recognizing biases, uncertainties, and limitations inherent in the methods and datasets. This approach promotes the ethical and practical use of interpretation insights, empowering AI practitioners, researchers, and professionals to make informed decisions when selecting techniques for responsible AI implementation in real-world scenarios.","<method>model-based methods</method>, <method>representation-based methods</method>, <method>post hoc methods</method>, <method>hybrid methods</method>, <method>data-driven approaches</method>",<method>model-based methods</method><method>representation-based methods</method><method>hybrid methods</method>
2024,https://openalex.org/W4391723759,Social Sciences,Artificial Intelligence to Automate Network Meta-Analyses: Four Case Studies to Evaluate the Potential Application of Large Language Models,"The emergence of artificial intelligence, capable of human-level performance on some tasks, presents an opportunity to revolutionise development of systematic reviews and network meta-analyses (NMAs). In this pilot study, we aim to assess use of a large-language model (LLM, Generative Pre-trained Transformer 4 [GPT-4]) to automatically extract data from publications, write an R script to conduct an NMA and interpret the results. We considered four case studies involving binary and time-to-event outcomes in two disease areas, for which an NMA had previously been conducted manually. For each case study, a Python script was developed that communicated with the LLM via application programming interface (API) calls. The LLM was prompted to extract relevant data from publications, to create an R script to be used to run the NMA and then to produce a small report describing the analysis. The LLM had a > 99% success rate of accurately extracting data across 20 runs for each case study and could generate R scripts that could be run end-to-end without human input. It also produced good quality reports describing the disease area, analysis conducted, results obtained and a correct interpretation of the results. This study provides a promising indication of the feasibility of using current generation LLMs to automate data extraction, code generation and NMA result interpretation, which could result in significant time savings and reduce human error. This is provided that routine technical checks are performed, as recommend for human-conducted analyses. Whilst not currently 100% consistent, LLMs are likely to improve with time.","<method>large-language model (LLM, Generative Pre-trained Transformer 4 [GPT-4])</method>","<method>large-language model (LLM, Generative Pre-trained Transformer 4 [GPT-4])</method>"
2024,https://openalex.org/W4391731380,Social Sciences,What do we know about cryptocurrency investment? An empirical study of its adoption among Indian retail investors,"Purpose This study aims to examine the cryptocurrency adoption (CA) level among Indian retail investors who use cryptocurrency as an investment and mode of transaction. Design/methodology/approach Through self-administered survey questionnaires, data is collected from 397 retail investors of Haryana (India). This study adopted a quantitative method using partial least squares structural equation modeling (PLS-SEM). Findings This paper offered a robust model with a high explanatory value for CA in which four of the five proposed factors of diffusion of innovation theory (trialability, compatibility, complexity and observability) and one of the two proposed factors of consumer behavioral theory (perceived value) significantly influences CA. More specifically, the absence of regulatory support is a barrier to the broad adoption of cryptocurrencies, as its regulations are necessary to mitigate or minimize uncertain outcomes. Research limitations/implications This research primarily focuses on CA in India. Thus, it can be extended to cover diverse other countries for more precise results. Practical implications The results provide insights to the government to design the policies, better regulate and make investment strategies that can ultimately enhance CA. In addition, the study’s results also inform financial educators, policymakers, employers and academicians about the significance of several variables affecting CA in India. Social implications From a social standpoint, this study is an advance that directs central banks and governments to develop, regulate and manage digital currencies and implement a digital currency ecosystem. Moreover, the results assist in understanding investors’ perceptions and decision-making perspectives toward cryptocurrencies through the country’s digitalization. Originality/value This paper fills the study gap to assist policymakers and cryptocurrency experts in broadening their knowledge base and recognizing prioritized intentions. Additionally, this study provides a theoretical model with the latent variable for a present and pertinent matter.",<method>partial least squares structural equation modeling (PLS-SEM)</method>,No methods remaining
2024,https://openalex.org/W4393281169,Social Sciences,Artificial intelligence techniques in financial trading: A systematic literature review,"Artificial Intelligence (AI) approaches have been increasingly used in financial markets as technology advances. In this research paper, we conduct a Systematic Literature Review (SLR) that studies financial trading approaches through AI techniques. It reviews 143 research articles that implemented AI techniques in financial trading markets. Accordingly, it presents several findings and observations after reviewing the papers from the following perspectives: the financial trading market and the asset type, the trading analysis type considered along with the AI technique, and the AI techniques utilized in the trading market, the estimation and performance metrics of the proposed models. The selected research articles were published between 2015 and 2023, and this review addresses four RQs. After analyzing the selected research articles, we observed 8 financial markets used in building predictive models. Moreover, we found that technical analysis is more adopted compared to fundamental analysis. Furthermore, 16% of the selected research articles entirely automate the trading process. In addition, we identified 40 different AI techniques that are used as standalone and hybrid models. Among these techniques, deep learning techniques are the most frequently used in financial trading markets. Building prediction models for financial markets using AI is a promising field of research, and academics have already deployed several machine learning models. As a result of this evaluation, we provide recommendations and guidance to researchers.","<method>deep learning techniques</method>, <method>machine learning models</method>",No methods remaining
2024,https://openalex.org/W4394620240,Social Sciences,Human-AI interaction in skin cancer diagnosis: a systematic review and meta-analysis,"Abstract The development of diagnostic tools for skin cancer based on artificial intelligence (AI) is increasing rapidly and will likely soon be widely implemented in clinical use. Even though the performance of these algorithms is promising in theory, there is limited evidence on the impact of AI assistance on human diagnostic decisions. Therefore, the aim of this systematic review and meta-analysis was to study the effect of AI assistance on the accuracy of skin cancer diagnosis. We searched PubMed, Embase, IEE Xplore, Scopus and conference proceedings for articles from 1/1/2017 to 11/8/2022. We included studies comparing the performance of clinicians diagnosing at least one skin cancer with and without deep learning-based AI assistance. Summary estimates of sensitivity and specificity of diagnostic accuracy with versus without AI assistance were computed using a bivariate random effects model. We identified 2983 studies, of which ten were eligible for meta-analysis. For clinicians without AI assistance, pooled sensitivity was 74.8% (95% CI 68.6–80.1) and specificity was 81.5% (95% CI 73.9–87.3). For AI-assisted clinicians, the overall sensitivity was 81.1% (95% CI 74.4–86.5) and specificity was 86.1% (95% CI 79.2–90.9). AI benefitted medical professionals of all experience levels in subgroup analyses, with the largest improvement among non-dermatologists. No publication bias was detected, and sensitivity analysis revealed that the findings were robust. AI in the hands of clinicians has the potential to improve diagnostic accuracy in skin cancer diagnosis. Given that most studies were conducted in experimental settings, we encourage future studies to further investigate these potential benefits in real-life settings.","<method>deep learning-based AI assistance</method>, <method>bivariate random effects model</method>",No methods remaining
2024,https://openalex.org/W4390506438,Social Sciences,Artificial intelligence for oral squamous cell carcinoma detection based on oral photographs: A comprehensive literature review,"Abstract Introduction Oral squamous cell carcinoma (OSCC) presents a significant global health challenge. The integration of artificial intelligence (AI) and computer vision holds promise for the early detection of OSCC through the analysis of digitized oral photographs. This literature review explores the landscape of AI‐driven OSCC automatic detection, assessing both the performance and limitations of the current state of the art. Materials and Methods An electronic search using several data base was conducted, and a systematic review performed in accordance with PRISMA guidelines (CRD42023441416). Results Several studies have demonstrated remarkable results for this task, consistently achieving sensitivity rates exceeding 85% and accuracy rates surpassing 90%, often encompassing around 1000 images. The review scrutinizes these studies, shedding light on their methodologies, including the use of recent machine learning and pattern recognition approaches coupled with different supervision strategies. However, comparing the results from different papers is challenging due to variations in the datasets used. Discussion Considering these findings, this review underscores the urgent need for more robust and reliable datasets in the field of OSCC detection. Furthermore, it highlights the potential of advanced techniques such as multi‐task learning, attention mechanisms, and ensemble learning as crucial tools in enhancing the accuracy and sensitivity of OSCC detection through oral photographs. Conclusion These insights collectively emphasize the transformative impact of AI‐driven approaches on early OSCC diagnosis, with the potential to significantly improve patient outcomes and healthcare practices.","<method>machine learning</method>, <method>pattern recognition</method>, <method>multi-task learning</method>, <method>attention mechanisms</method>, <method>ensemble learning</method>",<method>machine learning</method><method>multi-task learning</method><method>attention mechanisms</method><method>ensemble learning</method>
2024,https://openalex.org/W4391096835,Social Sciences,Diagnostic Performance Comparison between Generative AI and Physicians: A Systematic Review and Meta-Analysis,"Abstract Background The rapid advancement of generative artificial intelligence (AI) has led to the wide dissemination of models with exceptional understanding and generation of human language. Their integration into healthcare has shown potential for improving medical diagnostics, yet a comprehensive diagnostic performance evaluation of generative AI models and the comparison of their diagnostic performance with that of physicians has not been extensively explored. Methods In this systematic review and meta-analysis, a comprehensive search of Medline, Scopus, Web of Science, Cochrane Central, and MedRxiv was conducted for studies published from June 2018 through December 2023, focusing on those that validate generative AI models for diagnostic tasks. The risk of bias was assessed using the Prediction Model Study Risk of Bias Assessment Tool. Meta-regression was performed to summarize the performance of the models and to compare the accuracy of the models with that of physicians. Results The search resulted in 54 studies being included in the meta-analysis. Nine generative AI models were evaluated across 17 medical specialties. The quality assessment indicated a high risk of bias in the majority of studies, primarily due to small sample sizes. The overall accuracy for generative AI models across 54 studies was 56.9% (95% confidence interval [CI]: 51.0–62.7%). The meta-analysis demonstrated that, on average, physicians exceeded the accuracy of the models (difference in accuracy: 14.4% [95% CI: 4.9–23.8%], p-value =0.004). However, both Prometheus (Bing) and GPT-4 showed slightly better performance compared to non-experts (-2.3% [95% CI: -27.0–22.4%], p-value = 0.848 and -0.32% [95% CI: -14.4–13.7%], p-value = 0.962), but slightly underperformed when compared to experts (10.9% [95% CI: -13.1–35.0%], p-value = 0.356 and 12.9% [95% CI: 0.15–25.7%], p-value = 0.048). The sub-analysis revealed significantly improved accuracy in the fields of Gynecology, Pediatrics, Orthopedic surgery, Plastic surgery, and Otolaryngology, while showing reduced accuracy for Neurology, Psychiatry, Rheumatology, and Endocrinology compared to that of General Medicine. No significant heterogeneity was observed based on the risk of bias. Conclusions Generative AI exhibits promising diagnostic capabilities, with accuracy varying significantly by model and medical specialty. Although they have not reached the reliability of expert physicians, the findings suggest that generative AI models have the potential to enhance healthcare delivery and medical education, provided they are integrated with caution and their limitations are well-understood. Key Points Question: What is the diagnostic accuracy of generative AI models and how does this accuracy compare to that of physicians? Findings: This meta-analysis found that generative AI models have a pooled accuracy of 56.9% (95% confidence interval: 51.0–62.7%). The accuracy of expert physicians exceeds that of AI in all specialties, however, some generative AI models are comparable to non-expert physicians. Meaning: The diagnostic performance of generative AI models suggests that they do not match the level of experienced physicians but that they may have potential applications in healthcare delivery and medical education.",<method>generative AI models</method>,<method>generative AI models</method>
2024,https://openalex.org/W4392714393,Social Sciences,Fostering a Safety Culture in Manufacturing Industry through Safety Behavior: A Structural Equation Modelling Approach,"Creating a robust safety management system is crucial for fostering a culture of safety in the workplace, particularly in industries like manufacturing where improvements are still needed. This study aimed to assess the impact of safety behavior on safety culture within the manufacturing sector. Employing a quantitative approach, questionnaires were distributed to 342 employees in manufacturing firms during data collection. The collected data underwent analysis using Structural Equation Modeling through IBM-SPSS-AMOS 24.0 to test the proposed model. The study findings revealed that components of safety behavior, specifically safety compliance and safety leadership, have a significant influence on safety culture. This implies that prioritizing safety behavior and culture is vital for occupational safety and health, aligning with guidelines set by responsible entities to ensure a secure work environment. The insights gained from this research can be instrumental in highlighting the importance of safety culture, the pivotal role of leadership, the complex nature of safety culture, and the potential for measuring and enhancing it. By understanding these implications, organizations can foster a safety-centric culture that not only protects employees but also enhances overall performance. Additionally, this research contributed to the existing literature by examining an integrated higher-order construct model using the SEM technique, predicting the model by 53 percent. The insights garnered from this study are applicable to various types of firms, emphasizing the integral role of safety culture in any organization.",<method>Structural Equation Modeling</method>,No methods remaining
2024,https://openalex.org/W4393222088,Social Sciences,Methodological insights into ChatGPT’s screening performance in systematic reviews,"Abstract Background The screening process for systematic reviews and meta-analyses in medical research is a labor-intensive and time-consuming task. While machine learning and deep learning have been applied to facilitate this process, these methods often require training data and user annotation. This study aims to assess the efficacy of ChatGPT, a large language model based on the Generative Pretrained Transformers (GPT) architecture, in automating the screening process for systematic reviews in radiology without the need for training data. Methods A prospective simulation study was conducted between May 2nd and 24th, 2023, comparing ChatGPT’s performance in screening abstracts against that of general physicians (GPs). A total of 1198 abstracts across three subfields of radiology were evaluated. Metrics such as sensitivity, specificity, positive and negative predictive values (PPV and NPV), workload saving, and others were employed. Statistical analyses included the Kappa coefficient for inter-rater agreement, ROC curve plotting, AUC calculation, and bootstrapping for p-values and confidence intervals. Results ChatGPT completed the screening process within an hour, while GPs took an average of 7–10 days. The AI model achieved a sensitivity of 95% and an NPV of 99%, slightly outperforming the GPs’ sensitive consensus (i.e., including records if at least one person includes them). It also exhibited remarkably low false negative counts and high workload savings, ranging from 40 to 83%. However, ChatGPT had lower specificity and PPV compared to human raters. The average Kappa agreement between ChatGPT and other raters was 0.27. Conclusions ChatGPT shows promise in automating the article screening phase of systematic reviews, achieving high sensitivity and workload savings. While not entirely replacing human expertise, it could serve as an efficient first-line screening tool, particularly in reducing the burden on human resources. Further studies are needed to fine-tune its capabilities and validate its utility across different medical subfields.","<method>machine learning</method>, <method>deep learning</method>, <method>ChatGPT</method>, <method>Generative Pretrained Transformers (GPT) architecture</method>",<method>machine learning</method><method>deep learning</method><method>Generative Pretrained Transformers (GPT) architecture</method>
2024,https://openalex.org/W4394835724,Social Sciences,Machine Learning-Assisted Design of Advanced Polymeric Materials,"ConspectusPolymeric material research is encountering a new paradigm driven by machine learning (ML) and big data. The ML-assisted design has proven to be a successful approach for designing novel high-performance polymeric materials. This goal is mainly achieved through the following procedure: structure representation and database construction, establishment of a ML-based property prediction model, virtual design and high-throughput screening. The key to this approach lies in training ML models that delineate structure–property relationships based on available polymer data (e.g., structure, component, and property data), enabling the screening of promising polymers that satisfy the targeted property requirements. However, the relative scarcity of high-quality polymer data and the complex polymeric multiscale structure–property relationships pose challenges for this ML-assisted design method, such as data and modeling challenges.In this Account, we summarize the state-of-the-art advancements concerning the ML-assisted design of polymeric materials. Regarding structure representation and database construction, the digital representations of polymers are the predominant methods in cheminformatics along with some newly developed methods that integrate the polymeric multiscale structure characteristics. When establishing a ML-based property prediction model, the key is choosing and optimizing ML models to attain high-precision predictions across a vast chemical structure space. Advanced ML algorithms, such as transfer learning and multitask learning, have been utilized to address the data and modeling challenges. During the ML-assisted screening process, by defining and combining polymer genes, virtual polymer candidates are generated, and subsequently, their properties are predicted and high-throughput screened using ML property prediction models. Finally, the promising polymers identified through this approach are verified by computer simulations and experiments.We provide an overview of our recent efforts toward developing ML-assisted design approaches for discovering advanced polymeric materials and emphasize the intricate nature of polymer structural design. To well describe the multiscale structures of polymers, new structure representation methods, such as polymer fingerprint and cross-linking descriptors, were developed. Moreover, a multifidelity learning method was proposed to leverage the multisource isomerous polymer data from experiments and simulations. Additionally, graph neural networks and Bayesian optimization methods have been developed and applied for predicting polymer properties as well as designing polymer structures and compositions.Finally, we identify the current challenges and point out the development directions in this emerging field. It is highly desirable to establish new structure representation and advanced ML modeling methods for polymeric materials, particularly when constructing polymer large models based on chemical language. Through this Account, we seek to stimulate further interest and foster active collaborations for developing ML-assisted design approaches and realizing the innovation of advanced polymeric materials.","<method>transfer learning</method>, <method>multitask learning</method>, <method>multifidelity learning</method>, <method>graph neural networks</method>, <method>Bayesian optimization</method>",<method>transfer learning</method><method>multifidelity learning</method><method>graph neural networks</method><method>Bayesian optimization</method>
2024,https://openalex.org/W4398169659,Social Sciences,The Sociodemographic Biases in Machine Learning Algorithms: A Biomedical Informatics Perspective,"Artificial intelligence models represented in machine learning algorithms are promising tools for risk assessment used to guide clinical and other health care decisions. Machine learning algorithms, however, may house biases that propagate stereotypes, inequities, and discrimination that contribute to socioeconomic health care disparities. The biases include those related to some sociodemographic characteristics such as race, ethnicity, gender, age, insurance, and socioeconomic status from the use of erroneous electronic health record data. Additionally, there is concern that training data and algorithmic biases in large language models pose potential drawbacks. These biases affect the lives and livelihoods of a significant percentage of the population in the United States and globally. The social and economic consequences of the associated backlash cannot be underestimated. Here, we outline some of the sociodemographic, training data, and algorithmic biases that undermine sound health care risk assessment and medical decision-making that should be addressed in the health care system. We present a perspective and overview of these biases by gender, race, ethnicity, age, historically marginalized communities, algorithmic bias, biased evaluations, implicit bias, selection/sampling bias, socioeconomic status biases, biased data distributions, cultural biases and insurance status bias, conformation bias, information bias and anchoring biases and make recommendations to improve large language model training data, including de-biasing techniques such as counterfactual role-reversed sentences during knowledge distillation, fine-tuning, prefix attachment at training time, the use of toxicity classifiers, retrieval augmented generation and algorithmic modification to mitigate the biases moving forward.","<method>knowledge distillation</method>, <method>fine-tuning</method>, <method>prefix attachment at training time</method>, <method>toxicity classifiers</method>, <method>retrieval augmented generation</method>, <method>algorithmic modification</method>",<method>knowledge distillation</method><method>fine-tuning</method><method>retrieval augmented generation</method>
2024,https://openalex.org/W4399244247,Social Sciences,Investigating influencing factors of learning satisfaction in AI ChatGPT for research: University students perspective,"This study investigates the determinants of ChatGPT adoption among university students and its impact on learning satisfaction. Utilizing the Technology Acceptance Model (TAM) and incorporating insights from interaction learning, collaborative learning, and information quality, a structural equation modeling approach was employed. This research collected valuable responses from 262 students at King Faisal University in Saudi Arabia through the use of self-report questionnaires. The data's reliability and validity were assessed using confirmation factor analysis, followed by path analysis to explore the hypotheses in the proposed model. The results indicate the pivotal roles of interaction learning and collaborative learning in fostering ChatGPT adoption. Social interaction played a significant role, as researchers engaging in conversations and knowledge-sharing expressed increased comfort with ChatGPT. Information quality was found to substantially influence researchers' decisions to continue using ChatGPT, emphasizing the need for ongoing improvement in the accuracy and relevance of content provided. Perceived ease of use and perceived usefulness played intermediary roles in linking ChatGPT engagement to learning satisfaction. User-friendly interfaces and perceived utility were identified as crucial factors affecting overall satisfaction levels. Notably, ChatGPT positively impacted learning motivation, indicating its potential to enhance student engagement and interest in learning. The study's findings have implications for educational practitioners seeking to improve the implementation of AI technologies in university students, emphasizing user-friendly design, collaborative learning, and factors influencing satisfaction. The study concludes with insights into the complex interplay between AI-powered tools, learning objectives, and motivation, highlighting the need for continued research to comprehensively understand these dynamics. This study investigates the determinants of ChatGPT adoption among university students and its impact on learning satisfaction. Utilizing the Technology Acceptance Model (TAM) and incorporating insights from interaction learning, collaborative learning, and information quality, a structural equation modeling approach was employed. This research collected valuable responses from 262 students at King Faisal University in Saudi Arabia through the use of self-report questionnaires. The data's reliability and validity were assessed using confirmation factor analysis, followed by path analysis to explore the hypotheses in the proposed model. The results indicate the pivotal roles of interaction learning and collaborative learning in fostering ChatGPT adoption. Social interaction played a significant role, as researchers engaging in conversations and knowledge-sharing expressed increased comfort with ChatGPT. Information quality was found to substantially influence researchers' decisions to continue using ChatGPT, emphasizing the need for ongoing improvement in the accuracy and relevance of content provided. Perceived ease of use and perceived usefulness played intermediary roles in linking ChatGPT engagement to learning satisfaction. User-friendly interfaces and perceived utility were identified as crucial factors affecting overall satisfaction levels. Notably, ChatGPT positively impacted learning motivation, indicating its potential to enhance student engagement and interest in learning. The study's findings have implications for educational practitioners seeking to improve the implementation of AI technologies in university students, emphasizing user-friendly design, collaborative learning, and factors influencing satisfaction. The study concludes with insights into the complex interplay between AI-powered tools, learning objectives, and motivation, highlighting the need for continued research to comprehensively understand these dynamics.","<method>Technology Acceptance Model (TAM)</method>, <method>structural equation modeling</method>, <method>confirmation factor analysis</method>, <method>path analysis</method>",No methods remaining
2024,https://openalex.org/W4399363436,Social Sciences,Collective Constitutional AI: Aligning a Language Model with Public Input,"There is growing consensus that language model (LM) developers should not be the sole deciders of LM behavior, creating a need for methods that enable the broader public to collectively shape the behavior of LM systems that affect them. To address this need, we present Collective Constitutional AI (CCAI): a multi-stage process for sourcing and integrating public input into LMs—from identifying a target population to sourcing principles to training and evaluating a model. We demonstrate the real-world practicality of this approach by creating what is, to our knowledge, the first LM fine-tuned with collectively sourced public input and evaluating this model against a baseline model trained with established principles from a LM developer. Our quantitative evaluations demonstrate several benefits of our approach: the CCAI-trained model shows lower bias across nine social dimensions compared to the baseline model, while maintaining equivalent performance on language, math, and helpful-harmless evaluations. Qualitative comparisons of the models suggest that the models differ on the basis of their respective constitutions, e.g., when prompted with contentious topics, the CCAI-trained model tends to generate responses that reframe the matter positively instead of a refusal. These results demonstrate a promising, tractable pathway toward publicly informed development of language models.","<method>Collective Constitutional AI (CCAI)</method>, <method>fine-tuning</method>",<method>fine-tuning</method>
2024,https://openalex.org/W4399715357,Social Sciences,AI-POWERED FRAUD DETECTION IN BANKING: SAFEGUARDING FINANCIAL TRANSACTIONS,"The banking industry's metamorphosis through digitalization has unquestionably revolutionized accessibility and convenience for customers worldwide. However, this paradigm shift has ushered in a new era of challenges, most notably in the realm of cybersecurity. Conventional rule-based fraud detection strategies have struggled to keep pace with the rapid evolution of cyber threats, prompting a surge of interest in more adaptive approaches like unsupervised learning. Furthermore, the COVID-19 pandemic has exacerbated the issue of bank fraud due to the widespread transition to online platforms and the proliferation of charitable funds, which present ripe opportunities for exploitation by cybercriminals. In response to these pressing concerns, this study delves into the realm of machine learning algorithms for the analysis and identification of fraudulent banking transactions. Notably, it contributes scientific novelty by developing models specifically tailored to this purpose and implementing innovative preprocessing techniques to enhance detection accuracy. Utilizing a diverse array of algorithms, including Random Forest, K-Nearest Neighbor (KNN), Naïve Bayes, Decision Trees, and Logistic Regression, the study showcases promising results. In particular, logistic regression and decision tree models exhibit impressive accuracy and Area Under the Curve (AUC) values of approximately 0.98, 0.97 and 0.95, 0.94, respectively. Given the pervasive nature of banking fraud in our digital society, the utilization of artificial intelligence algorithms for fraud detection stands as a critical and timely endeavor, promising enhanced security and trust in the financial ecosystem.","<method>unsupervised learning</method>, <method>Random Forest</method>, <method>K-Nearest Neighbor (KNN)</method>, <method>Naïve Bayes</method>, <method>Decision Trees</method>, <method>Logistic Regression</method>",<method>unsupervised learning</method><method>Random Forest</method><method>K-Nearest Neighbor (KNN)</method><method>Naïve Bayes</method><method>Decision Trees</method><method>Logistic Regression</method>
2024,https://openalex.org/W4391560128,Social Sciences,Analyzing Preceding factors affecting behavioral intention on communicational artificial intelligence as an educational tool,"During the pandemic, artificial intelligence was employed and utilized by students around the globe. Students' conduct changed in a variety of ways when schooling returned to regular instruction. This study aimed to analyze the student's behavioral intention and actual academic use of communicational AI (CAI) as an educational tool. This study identified the variables by utilizing an integrated framework based on the Unified Theory of Acceptance and Use of Technology (UTAUT2) and self-determination theory. Through the use of an online survey and Structural Equation Modeling, data from 533 respondents were analyzed. The results showed that perceived relatedness has the most significant effect on the behavioral intention of students in using CAI as an educational tool, followed by perceived autonomy. It showed that students use CAI based on the objective and the possibility of increasing their productivity, rather than any other purpose in the education setting. Among the UTAUT2 domains, only facilitating conditions, habit, and performance expectancy provided a significant direct effect on behavioral intention and an indirect effect on actual academic use. Further implications were presented. Moreover, the methodology and framework of this study could be extended and applied to educational technology-related studies. Lastly, the outcome of this study may be considered in analyzing the behavioral intention of the students as the teaching-learning environment is still continuously expanding and developing.",<method>Structural Equation Modeling</method>,No methods remaining
2024,https://openalex.org/W4391655051,Social Sciences,Do large language models show decision heuristics similar to humans? A case study using GPT-3.5.,"A Large Language Model (LLM) is an artificial intelligence system trained on vast amounts of natural language data, enabling it to generate human-like responses to written or spoken language input. Generative Pre-Trained Transformer (GPT)-3.5 is an example of an LLM that supports a conversational agent called ChatGPT. In this work, we used a series of novel prompts to determine whether ChatGPT shows heuristics and other context-sensitive responses. We also tested the same prompts on human participants. Across four studies, we found that ChatGPT was influenced by random anchors in making estimates (anchoring, Study 1); it judged the likelihood of two events occurring together to be higher than the likelihood of either event occurring alone, and it was influenced by anecdotal information (representativeness and availability heuristic, Study 2); it found an item to be more efficacious when its features were presented positively rather than negatively-even though both presentations contained statistically equivalent information (framing effect, Study 3); and it valued an owned item more than a newly found item even though the two items were objectively identical (endowment effect, Study 4). In each study, human participants showed similar effects. Heuristics and context-sensitive responses in humans are thought to be driven by cognitive and affective processes such as loss aversion and effort reduction. The fact that an LLM-which lacks these processes-also shows such responses invites consideration of the possibility that language is sufficiently rich to carry these effects and may play a role in generating these effects in humans. (PsycInfo Database Record (c) 2024 APA, all rights reserved).","<method>Large Language Model (LLM)</method>, <method>Generative Pre-Trained Transformer (GPT)-3.5</method>",<method>Generative Pre-Trained Transformer (GPT)-3.5</method>
2024,https://openalex.org/W4401941326,Social Sciences,Predicting ground vibration during rock blasting using relevance vector machine improved with dual kernels and metaheuristic algorithms,"The ground vibration caused by rock blasting is an extremely hazardous outcome of the blasting operation. Blasting activity has detrimental effects on both the ecology and the human population living in proximity to the area. Evaluating the magnitude of blasting vibrations requires careful evaluation of the peak particle velocity (PPV) as a fundamental and essential parameter for quantifying vibration velocity. Therefore, this study employs models using the relevance vector machine (RVM) approach for predicting the PPV resulting from quarry blasting. This investigation utilized the conventional and optimized RVM models for the first time in ground vibration prediction. This work compares thirty-three RVM models to choose the most efficient performance model. The following conclusions have been mapped from the outcomes of the several analyses. The performance evaluation of each RVM model demonstrates each model achieved a performance of more than 0.85 during the testing phase, there was a strong correlation observed between the actual ground vibrations and the predicted ones. The analysis of performance metrics (RMSE = 21.2999 mm/s, 16.2272 mm/s, R = 0.9175, PI = 1.59, IOA = 0.8239, IOS = 0.2541), score analysis (= 93), REC curve (= 6.85E-03, close to the actual, i.e., 0), curve fitting (= 1.05 close to best fit, i.e., 1), AD test (= 11.607 close to the actual, i.e., 9.790), Wilcoxon test (= 95%), Uncertainty analysis (WCB = 0.0134), and computational cost (= 0.0180) demonstrate that PSO_DRVM model MD29 outperformed better than other RVM models in the testing phase. This study will help mining and civil engineers and blasting experts to select the best kernel function and its hyperparameters in estimating ground vibration during rock blasting project. In the context of the mining and civil industry, the application of this study offers significant potential for enhancing safety protocols and optimizing operational efficiency.","<method>relevance vector machine (RVM)</method>, <method>conventional RVM</method>, <method>optimized RVM</method>, <method>PSO_DRVM</method>",<method>relevance vector machine (RVM)</method><method>conventional RVM</method><method>optimized RVM</method>
2024,https://openalex.org/W4402305045,Social Sciences,Triplet Contrastive Representation Learning for Unsupervised Vehicle Re-identification,"Part feature learning plays a crucial role in achieving fine-grained semantic understanding in unsupervised vehicle re-identification. However, existing approaches directly model part and global features, which can easily lead to severe gradient vanishing issues due to their unequal feature information and unreliable pseudo-labels. To address this problem, in this paper, we propose a triplet contrastive representation learning (TCRL) framework, which leverages cluster features to bridge the part features and global features for unsupervised vehicle re-identification. Specifically, TCRL devises three memory banks to store the instance/cluster features and proposes a proxy contrastive loss (PCL) to make contrastive learning between adjacent memory banks, thus presenting the associations between the part and global features as a transition of the part-cluster and cluster-global associations. Since the cluster memory bank copes with all the vehicle features, it can summarize them into a discriminative feature representation. To deeply exploit the instance/cluster information, TCRL proposes two additional loss functions. For the instance-level feature, a hybrid contrastive loss (HCL) re-defines the sample correlations by approaching the positive instance features and pushing all negative instance features away. For the cluster-level feature, a weighted regularization cluster contrastive loss (WRCCL) refines the pseudo labels by penalizing the mislabeled images according to the instance similarity. Extensive experiments show that TCRL outperforms many state-of-the-art unsupervised vehicle re-identification approaches.","<method>triplet contrastive representation learning (TCRL)</method>, <method>contrastive learning</method>, <method>proxy contrastive loss (PCL)</method>, <method>hybrid contrastive loss (HCL)</method>, <method>weighted regularization cluster contrastive loss (WRCCL)</method>",<method>contrastive learning</method><method>proxy contrastive loss (PCL)</method><method>hybrid contrastive loss (HCL)</method>
2024,https://openalex.org/W4391618879,Social Sciences,Likelihood-based feature representation learning combined with neighborhood information for predicting circRNA–miRNA associations,"Connections between circular RNAs (circRNAs) and microRNAs (miRNAs) assume a pivotal position in the onset, evolution, diagnosis and treatment of diseases and tumors. Selecting the most potential circRNA-related miRNAs and taking advantage of them as the biological markers or drug targets could be conducive to dealing with complex human diseases through preventive strategies, diagnostic procedures and therapeutic approaches. Compared to traditional biological experiments, leveraging computational models to integrate diverse biological data in order to infer potential associations proves to be a more efficient and cost-effective approach. This paper developed a model of Convolutional Autoencoder for CircRNA-MiRNA Associations (CA-CMA) prediction. Initially, this model merged the natural language characteristics of the circRNA and miRNA sequence with the features of circRNA-miRNA interactions. Subsequently, it utilized all circRNA-miRNA pairs to construct a molecular association network, which was then fine-tuned by labeled samples to optimize the network parameters. Finally, the prediction outcome is obtained by utilizing the deep neural networks classifier. This model innovatively combines the likelihood objective that preserves the neighborhood through optimization, to learn the continuous feature representation of words and preserve the spatial information of two-dimensional signals. During the process of 5-fold cross-validation, CA-CMA exhibited exceptional performance compared to numerous prior computational approaches, as evidenced by its mean area under the receiver operating characteristic curve of 0.9138 and a minimal SD of 0.0024. Furthermore, recent literature has confirmed the accuracy of 25 out of the top 30 circRNA-miRNA pairs identified with the highest CA-CMA scores during case studies. The results of these experiments highlight the robustness and versatility of our model.","<method>Convolutional Autoencoder</method>, <method>deep neural networks classifier</method>, <method>5-fold cross-validation</method>",<method>Convolutional Autoencoder</method><method>deep neural networks classifier</method>
2024,https://openalex.org/W4401567811,Social Sciences,DisenSemi: Semi-Supervised Graph Classification via Disentangled Representation Learning,"Graph classification is a critical task in numerous multimedia applications, where graphs are employed to represent diverse types of multimedia data, including images, videos, and social networks. Nevertheless, in the real world, labeled graph data are always limited or scarce. To address this issue, we focus on the semi-supervised graph classification task, which involves both supervised and unsupervised models learning from labeled and unlabeled data. In contrast to recent approaches that transfer the entire knowledge from the unsupervised model to the supervised one, we argue that an effective transfer should only retain the relevant semantics that align well with the supervised task. We introduce a novel framework termed in this article, which learns disentangled representation for semi-supervised graph classification. Specifically, a disentangled graph encoder is proposed to generate factorwise graph representations for both supervised and unsupervised models. Then, we train two models via supervised objective and mutual information (MI)-based constraints, respectively. To ensure the meaningful transfer of knowledge from the unsupervised encoder to the supervised one, we further define an MI-based disentangled consistency regularization between two models and identify the corresponding rationale that aligns well with the current graph classification task. Experiments conducted on various publicly available datasets demonstrate the effectiveness of our .","<method>semi-supervised graph classification</method>, <method>disentangled graph encoder</method>, <method>supervised objective</method>, <method>mutual information (MI)-based constraints</method>, <method>MI-based disentangled consistency regularization</method>",<method>semi-supervised graph classification</method><method>disentangled graph encoder</method>
2024,https://openalex.org/W4391029001,Social Sciences,Smart energy management in residential buildings: the impact of knowledge and behavior,"Abstract A new technology called smart energy management makes use of IoT concepts to enhance energy efficiency and lower waste in structures. The goal of this study is to comprehend how household energy management knowledge affects energy usage, user behavior, related expenses, and environmental effect. Through a survey of 100 valid replies in Palestine, the research model assessed the knowledge and consumption habits of building occupants. Smart PLS software was used to analyze the research model using partial least squares structural equation modeling (PLS-SEM). Using path coefficients and behavior as a mediating variable, the structural model connected the latent variables. The mediation hypotheses were tested using the Preacher and Hayes method, and the indirect effect and confidence intervals were estimated and calculated using bootstrapping. The findings demonstrated that by lowering energy use and enhancing overall building performance, residential buildings that implement smart energy consumption management systems may move toward a more sustainable future. Furthermore, the study found that education and awareness campaigns are necessary to increase residents’ knowledge of these systems to promote energy savings. The results also indicated statistically significant indirect effects, supporting the existence of mediation of the behavior construct. Path coefficient values and P -values were presented to further support the study’s hypotheses. Such smart energy management systems represent an important innovation in building management and can help create more sustainable and efficient buildings.","<method>partial least squares structural equation modeling (PLS-SEM)</method>, <method>Preacher and Hayes method</method>, <method>bootstrapping</method>",<method>bootstrapping</method>
2024,https://openalex.org/W4392955615,Social Sciences,Variation in social media sensitivity across people and contexts,"Abstract Social media impacts people’s wellbeing in different ways, but relatively little is known about why this is the case. Here we introduce the construct of “social media sensitivity” to understand how social media and wellbeing associations differ across people and the contexts in which these platforms are used. In a month-long large-scale intensive longitudinal study (total n = 1632; total number of observations = 120,599), we examined for whom and under which circumstances social media was associated with positive and negative changes in social and affective wellbeing. Applying a combination of frequentist and Bayesian multilevel models, we found a small negative average association between social media use AND subsequent wellbeing, but the associations were heterogenous across people. People with psychologically vulnerable dispositions (e.g., those who were depressed, lonely, not satisfied with life) tended to experience heightened negative social media sensitivity in comparison to people who were not psychologically vulnerable. People also experienced heightened negative social media sensitivity when in certain types of places (e.g., in social places, in nature) and while around certain types of people (e.g., around family members, close ties), as compared to using social media in other contexts. Our results suggest that an understanding of the effects of social media on wellbeing should account for the psychological dispositions of social media users, and the physical and social contexts surrounding their use. We discuss theoretical and practical implications of social media sensitivity for scholars, policymakers, and those in the technology industry.","<method>frequentist multilevel models</method>, <method>Bayesian multilevel models</method>",<method>Bayesian multilevel models</method>
2024,https://openalex.org/W4395074044,Social Sciences,"The Value of Political Connections of Developers in Residential Land Leasing: Case of Chengdu, China","The graduate approach applied in China for the economic transition poses the risk of continued government influence on the market. The land reform and the following adjustment in China have introduced a seemingly complete market for residential land. However, a widely practiced coalition between the local developmental states and developers might impact residential land leasing in a more hidden way. Taking central Chengdu as the study area, this study takes the enterprise ownership and affiliations as two explanatory factors that impact the land leasing prices and builds an MGWR model to evaluate the premium of political connections for the developers to obtain the land. The result gives a clue to the local protectionism and preference for state-owned enterprises that might exist in land leasing in Chengdu. It is proved in this study that the average purchase price by state-owned enterprises is 8.9% lower than the prices that private enterprises could enjoy, and the average land leasing price by local enterprises is 14.2% lower than that enjoyed by non-local enterprises. The preceding conceptual and empirical discussion in this study advocates for a review and rethinking of the public sector’s intervention in China’s land market. In-depth analyses of the factors that define the land leasing behaviors of the local government are needed.",<method>MGWR model</method>,No methods remaining
2024,https://openalex.org/W4390506124,Social Sciences,Machine learning models for predicting preeclampsia: a systematic review,"Abstract Background This systematic review provides an overview of machine learning (ML) approaches for predicting preeclampsia. Method This review adhered to the Preferred Reporting Items for Systematic Reviews and Meta-Analyzes (PRISMA) guidelines. We searched the Cochrane Central Register, PubMed, EMBASE, ProQuest, Scopus, and Google Scholar up to February 2023. Search terms were limited to “preeclampsia” AND “artificial intelligence” OR “machine learning” OR “deep learning.” All studies that used ML-based analysis for predicting preeclampsia in pregnant women were considered. Non-English articles and those that are unrelated to the topic were excluded. The PROBAST was used to assess the risk of bias and applicability of each included study. Results The search strategy yielded 128 citations; after duplicates were removed and title and abstract screening was completed, 18 full-text articles were evaluated for eligibility. Four studies were included in this review. Two studies were at low risk of bias, and two had low to moderate risk. All of the study designs included were retrospective cohort studies. Nine distinct models were chosen as ML models from the four studies. Maternal characteristics, medical history, medication intake, obstetrical history, and laboratory and ultrasound findings obtained during prenatal care visits were candidate predictors to train the ML model. Elastic net, stochastic gradient boosting, extreme gradient boosting, and Random forest were among the best models to predict preeclampsia. All four studies used metrics such as the area under the curve, true positive rate, negative positive rate, accuracy, precision, recall, and F1 score. The AUC of ML models varied from 0.860 to 0.973 in four studies. Conclusion The results of studies yielded high prediction performance of ML models for preeclampsia risk from routine early pregnancy information.","<method>Elastic net</method>, <method>stochastic gradient boosting</method>, <method>extreme gradient boosting</method>, <method>Random forest</method>",<method>Elastic net</method><method>stochastic gradient boosting</method><method>extreme gradient boosting</method><method>Random forest</method>
2024,https://openalex.org/W4391558438,Social Sciences,UniLog: Automatic Logging via LLM and In-Context Learning,"Logging, which aims to determine the position of logging statements, the verbosity levels, and the log messages, is a crucial process for software reliability enhancement. In recent years, numerous automatic logging tools have been designed to assist developers in one of the logging tasks (e.g., providing suggestions on whether to log in try-catch blocks). These tools are useful in certain situations yet cannot provide a comprehensive logging solution in general. Moreover, although recent research has started to explore end-to-end logging, it is still largely constrained by the high cost of fine-tuning, hindering its practical usefulness in software development. To address these problems, this paper proposes UniLog, an automatic logging framework based on the in-context learning (ICL) paradigm of large language models (LLMs). Specifically, UniLog can generate an appropriate logging statement with only a prompt containing five demonstration examples without any model tuning. In addition, UniLog can further enhance its logging ability after warmup with only a few hundred random samples. We evaluated UniLog on a large dataset containing 12,012 code snippets extracted from 1,465 GitHub repositories. The results show that UniLog achieved the state-of-the-art performance in automatic logging: (1) 76.9% accuracy in selecting logging positions, (2) 72.3% accuracy in predicting verbosity levels, and (3) 27.1 BLEU-4 score in generating log messages. Meanwhile, UniLog requires less than 4% of the parameter tuning time needed by fine-tuning the same LLM.","<method>in-context learning (ICL) paradigm of large language models (LLMs)</method>, <method>fine-tuning</method>",<method>in-context learning (ICL) paradigm of large language models (LLMs)</method><method>fine-tuning</method>
2024,https://openalex.org/W4398183551,Social Sciences,A Survey on Malware Detection with Graph Representation Learning,"Malware detection has become a major concern due to the increasing number and complexity of malware. Traditional detection methods based on signatures and heuristics are used for malware detection, but unfortunately, they suffer from poor generalization to unknown attacks and can be easily circumvented using obfuscation techniques. In recent years, Machine Learning (ML) and notably Deep Learning (DL) achieved impressive results in malware detection by learning useful representations from data and have become a solution preferred over traditional methods. Recently, the application of Graph Representation Learning (GRL) techniques on graph-structured data has demonstrated impressive capabilities in malware detection. This success benefits notably from the robust structure of graphs, which are challenging for attackers to alter, and their intrinsic explainability capabilities. In this survey, we provide an in-depth literature review to summarize and unify existing works under the common approaches and architectures. We notably demonstrate that Graph Neural Networks (GNNs) reach competitive results in learning robust embeddings from malware represented as expressive graph structures such as Function Call Graphs (FCGs) and Control Flow Graphs (CFGs). This study also discusses the robustness of GRL-based methods to adversarial attacks, contrasts their effectiveness with other ML/DL approaches, and outlines future research for practical deployment.","<method>Machine Learning (ML)</method>, <method>Deep Learning (DL)</method>, <method>Graph Representation Learning (GRL)</method>, <method>Graph Neural Networks (GNNs)</method>",<method>Machine Learning (ML)</method><method>Deep Learning (DL)</method><method>Graph Representation Learning (GRL)</method><method>Graph Neural Networks (GNNs)</method>
2024,https://openalex.org/W4390662926,Social Sciences,Artificial intelligence performance in detecting lymphoma from medical imaging: a systematic review and meta-analysis,"Abstract Background Accurate diagnosis and early treatment are essential in the fight against lymphatic cancer. The application of artificial intelligence (AI) in the field of medical imaging shows great potential, but the diagnostic accuracy of lymphoma is unclear. This study was done to systematically review and meta-analyse researches concerning the diagnostic performance of AI in detecting lymphoma using medical imaging for the first time. Methods Searches were conducted in Medline, Embase, IEEE and Cochrane up to December 2023. Data extraction and assessment of the included study quality were independently conducted by two investigators. Studies that reported the diagnostic performance of an AI model/s for the early detection of lymphoma using medical imaging were included in the systemic review. We extracted the binary diagnostic accuracy data to obtain the outcomes of interest: sensitivity (SE), specificity (SP), and Area Under the Curve (AUC). The study was registered with the PROSPERO, CRD42022383386. Results Thirty studies were included in the systematic review, sixteen of which were meta-analyzed with a pooled sensitivity of 87% (95%CI 83–91%), specificity of 94% (92–96%), and AUC of 97% (95–98%). Satisfactory diagnostic performance was observed in subgroup analyses based on algorithms types (machine learning versus deep learning, and whether transfer learning was applied), sample size (≤ 200 or &gt; 200), clinicians versus AI models and geographical distribution of institutions (Asia versus non-Asia). Conclusions Even if possible overestimation and further studies with a better standards for application of AI algorithms in lymphoma detection are needed, we suggest the AI may be useful in lymphoma diagnosis.","<method>machine learning</method>, <method>deep learning</method>, <method>transfer learning</method>",<method>machine learning</method><method>deep learning</method><method>transfer learning</method>
2024,https://openalex.org/W4390939347,Social Sciences,Adaptive Attention-Based Graph Representation Learning to Detect Phishing Accounts on the Ethereum Blockchain,"With Ethereum blockchain advancement, the Ethereum platform gathers numerous users. In this context, traditional phishing appears new fraud methods, resulting in significant losses. Currently, network embedding methods are considered effective solutions in the field of phishing detection. However, investigating existing Ethereum phishing node detection algorithms finds they are not optimal and still face two issues. Firstly, the Ethereum network's topology is unsatisfactory, with nodes exhibiting a long-tail distribution in their degree. Current technologies typically allow high-degree nodes to acquire high-quality embeddings, while low-degree nodes, constrained by limited structure, obtain embeddings of lower quality, significantly impacting the detection accuracy of downstream tasks. Secondly, different features of nodes will suffer losses during the fusion process, resulting in the final learned feature embedding being suboptimal. This paper presents an attention-based graphical representation learning approach (ABGRL) to address these problems. ABGRL extracts different feature information by means of multiple channels, and fuses the different feature information using adaptive attention convolution to select the feature information that has the greatest impact on the downstream task. Then the tail node feature information is enhanced by a self-supervised regression model with robust tail node embedding. Finally, the effectiveness of the proposed model was validated through extensive experiments.","<method>network embedding methods</method>, <method>attention-based graphical representation learning approach (ABGRL)</method>, <method>adaptive attention convolution</method>, <method>self-supervised regression model</method>",<method>network embedding methods</method>
2024,https://openalex.org/W4391127198,Social Sciences,Risk predictions of surgical wound complications based on a machine learning algorithm: A systematic review,"Abstract Surgical wounds may arise due to harm inflicted upon soft tissue during surgical intervention, and many complications and injuries may accompany them. These complications can lead to prolonged hospitalization and poorer clinical outcomes. Also, Machine learning (ML) is a Section of artificial intelligence (AI) that has emerged in medical care and is increasingly used for diagnosis, complications, prognosis and recurrence prediction. This study aims to investigate surgical wound risk predictions and management using a ML algorithm by R programming language analysis. The systematic review, following PRISMA guidelines, spanned electronic databases using search terms like ‘machine learning’, ‘surgical’ and ‘wound’. Inclusion criteria covered experimental studies from 1990 to the present on ML's application in surgical wound evaluation. Exclusion criteria included studies lacking full text, focusing on ML in all surgeries, neglecting wound assessment and duplications. Two authors rigorously assessed titles, abstracts and full texts, excluding reviews and guidelines. Ultimately, relevant articles were then analysed. The present study identified nine articles employing ML for surgical wound management. The analysis encompassed various surgical procedures, including Cardiothoracic, Caesarean total abdominal colectomy, Burn plastic surgery, facial plastic surgery, laparotomy, minimal invasive surgery, hernia repair and unspecified surgeries. ML was skillful in evaluating surgical site infections (SSI) in seven studies, while two extended its use to burn‐grade diagnosis and wound classification. Support Vector Machine (SVM) and Convolutional Neural Network (CNN) were the most utilized algorithms. ANN achieved a 96% accuracy in facial plastic surgery wound management. CNN demonstrated commendable accuracies in various surgeries, and SVM exhibited high accuracy in multiple surgeries and burn plastic surgery. In sum, these findings underscore ML's potential for significant improvements in postoperative management and the development of enhanced care techniques, particularly in surgical wound management.","<method>Support Vector Machine (SVM)</method>, <method>Convolutional Neural Network (CNN)</method>, <method>Artificial Neural Network (ANN)</method>",<method>Support Vector Machine (SVM)</method><method>Convolutional Neural Network (CNN)</method><method>Artificial Neural Network (ANN)</method>
2024,https://openalex.org/W4392449443,Social Sciences,RGBT Tracking via Challenge-Based Appearance Disentanglement and Interaction,"RGB and thermal source data suffer from both shared and specific challenges, and how to explore and exploit them plays a critical role in representing the target appearance in RGBT tracking. In this paper, we propose a novel approach, which performs target appearance representation disentanglement and interaction via both modality-shared and modality-specific challenge attributes, for robust RGBT tracking. In particular, we disentangle the target appearance representations via five challenge-based branches with different structures according to their properties, including three parameter-shared branches to model modality-shared challenges and two parameter-independent branches to model modality-specific challenges. Considering the complementary advantages between modality-specific cues, we propose a guidance interaction module to transfer discriminative features from one modality to another one to enhance the discriminative ability of weak modality. Moreover, we design an aggregation interaction module to combine all challenge-based target representations, which could form more discriminative target representations and fit the challenge-agnostic tracking process. These challenge-based branches are able to model the target appearance under certain challenges so that the target representations can be learned by a few parameters even in the situation of insufficient training data. In addition, to relieve labor costs and avoid label ambiguity, we design a generation strategy to generate training data with different challenge attributes. Comprehensive experiments demonstrate the superiority of the proposed tracker against the state-of-the-art methods on four benchmark datasets.","<method>target appearance representation disentanglement</method>, <method>guidance interaction module</method>, <method>aggregation interaction module</method>, <method>generation strategy to generate training data with different challenge attributes</method>",No methods remaining
2024,https://openalex.org/W4394948580,Social Sciences,Inductive Cognitive Diagnosis for Fast Student Learning in Web-Based Intelligent Education Systems,"Cognitive diagnosis aims to gauge students' mastery levels based on their response logs.Serving as a pivotal module in web-based online intelligent education systems (WOIESs), it plays an upstream and fundamental role in downstream tasks like learning item recommendation and computerized adaptive testing.WOIESs are open learning environment where numerous new students constantly register and complete exercises.In WOIESs, efficient cognitive diagnosis is crucial to fast feedback and accelerating student learning.However, the existing cognitive diagnosis methods always employ intrinsically transductive student-specific embeddings, which become slow and costly due to retraining when dealing with new students who are unseen during training.To this end, this paper proposes an inductive cognitive diagnosis model (ICDM) for fast new students' mastery levels inference in WOIESs.Specifically, in ICDM, we propose a novel student-centered graph (SCG).Rather than inferring mastery levels through updating student-specific embedding, we derive the inductive mastery levels as the aggregated outcomes of students' neighbors in SCG.Namely, SCG enables to shift the task from finding the most suitable student-specific embedding that fits the response logs to finding the most suitable representations for different node types in SCG, and the latter is more efficient since it no longer requires retraining.To obtain this representation, ICDM consists of a construction-aggregation-generationtransformation process to learn the final representation of students, exercises and concepts.Extensive experiments across real-world datasets show that, compared with the existing cognitive diagnosis methods that are always transductive, ICDM is much more faster while maintains the competitive inference performance for new students.","<method>inductive cognitive diagnosis model (ICDM)</method>, <method>student-centered graph (SCG)</method>",No methods remaining
2024,https://openalex.org/W4400617823,Social Sciences,Wind farm site selection using geographic information system and fuzzy decision making model,"As the demand for renewable energy sources increases, finding the right places to install wind turbines becomes more and more important. The goal of this research is to create and implement a technique that uses geographic information system (GIS) technology to discover appropriate wind farm locations utilizing multi-criteria decision-making (MCDM) approaches. The complexity of this decision-making process, which includes multiple criteria and uncertainty, requires the use of advanced techniques. Fuzzy MCDM methods provide a framework for evaluating and prioritizing potential wind farm sites, taking into account subjective judgments and linguistic terms. In this article, Fuzzy Stepwise Weight Evaluation Ratio Analysis (F-SWARA) is preferred for prioritizing and ranking the criteria in the wind farm installation, while Fuzzy Measurement Alternatives and Ranking by Compromise Solution (F-MARCOS) are used to determine the most suitable location for the wind farm. A database of alternatives and criteria was created using GIS, which was converted into a fuzzy decision matrix via triangular fuzzy numbers. In order to make this evaluation, Sivas province, located in the middle of Turkey, was chosen as the study area. Results obtained show that 36,5% of the whole study area is very suitable for wind farm, and Gürün and Kangal districts are suitable for wind farm. According to the result of F-SWARA method used to evaluate the criteria, wind speed is the most important criteria with a weight of 0,45039. According to the F-MARCOS method used for wind farm site selection, Ulaş district was determined the most suitable location. Furthermore, a sensitivity analysis was performed to test the robustness of the proposed methodology and the results revealed that the proposed integrated MCDM framework is feasible.","<method>Fuzzy Stepwise Weight Evaluation Ratio Analysis (F-SWARA)</method>, <method>Fuzzy Measurement Alternatives and Ranking by Compromise Solution (F-MARCOS)</method>",<method>Fuzzy Stepwise Weight Evaluation Ratio Analysis (F-SWARA)</method><method>Fuzzy Measurement Alternatives and Ranking by Compromise Solution (F-MARCOS)</method>
2024,https://openalex.org/W4401487891,Social Sciences,CARLA: Self-supervised contrastive representation learning for time series anomaly detection,"One main challenge in time series anomaly detection (TSAD) is the lack of labelled data in many real-life scenarios. Most of the existing anomaly detection methods focus on learning the normal behaviour of unlabelled time series in an unsupervised manner. The normal boundary is often defined tightly, resulting in slight deviations being classified as anomalies, consequently leading to a high false positive rate and a limited ability to generalise normal patterns. To address this, we introduce a novel end-to-end self-supervised ContrAstive Representation Learning approach for time series Anomaly detection (CARLA). While existing contrastive learning methods assume that augmented time series windows are positive samples and temporally distant windows are negative samples, we argue that these assumptions are limited as augmentation of time series can transform them to negative samples, and a temporally distant window can represent a positive sample. Existing approaches to contrastive learning for time series have directly copied methods developed for image analysis. We argue that these methods do not transfer well. Instead, our contrastive approach leverages existing generic knowledge about time series anomalies and injects various types of anomalies as negative samples. Therefore, CARLA not only learns normal behaviour but also learns deviations indicating anomalies. It creates similar representations for temporally close windows and distinct ones for anomalies. Additionally, it leverages the information about representations' neighbours through a self-supervised approach to classify windows based on their nearest/furthest neighbours to further enhance the performance of anomaly detection. In extensive tests on seven major real-world TSAD datasets, CARLA shows superior performance (F1 and AU-PR) over state-of-the-art self-supervised, semi-supervised, and unsupervised TSAD methods for univariate time series and multivariate time series. Our research highlights the immense potential of contrastive representation learning in advancing the TSAD field, thus paving the way for novel applications and in-depth exploration.","<method>self-supervised ContrAstive Representation Learning</method>, <method>contrastive learning</method>, <method>self-supervised approach</method>, <method>semi-supervised methods</method>, <method>unsupervised methods</method>",<method>self-supervised ContrAstive Representation Learning</method><method>contrastive learning</method><method>self-supervised approach</method><method>semi-supervised methods</method><method>unsupervised methods</method>
2024,https://openalex.org/W4391097175,Social Sciences,Toward Improving Breast Cancer Classification Using an Adaptive Voting Ensemble Learning Algorithm,"Over the past decade, breast cancer has been the most common type of cancer in women. Different methods were proposed for breast cancer detection. These methods mainly classify and categorize malignant and Benign tumors. Machine learning is a practical approach for breast cancer classification. Data mining and classification are effective methods to predict and categorize breast cancer. The optimum classification for detecting Breast Cancer (BC) is ensemble-based. The ensemble approach involves using multiple ways to find the best possible solution. This study used the Wisconsin Breast Cancer Diagnostic (WBCD) dataset. We created a voting ensemble classifier that combines four different machine learning models: Extra Trees Classifier (ETC), Light Gradient Boosting Machine (LightGBM), Ridge Classifier (RC), and Linear Discriminant Analysis (LDA). The proposed ELRL-E approach achieved an accuracy of 97.6%, a precision of 96.4%, a recall of 100%, and an F1 score of 98.1%. Various output evaluations are used to evaluate the performance and efficiency of the proposed model and other classifiers. Overall, the recommended strategy performed better. Results are directly compared with the individual classifier and different recognized state-of-the-art classifiers. The primary objective of this study is to identify the most influential ensemble machine learning classifier for breast cancer detection and diagnosis in terms of accuracy and AUC score.","<method>Machine learning</method>, <method>Data mining</method>, <method>classification</method>, <method>ensemble-based classification</method>, <method>voting ensemble classifier</method>, <method>Extra Trees Classifier (ETC)</method>, <method>Light Gradient Boosting Machine (LightGBM)</method>, <method>Ridge Classifier (RC)</method>, <method>Linear Discriminant Analysis (LDA)</method>",<method>Machine learning</method><method>ensemble-based classification</method><method>voting ensemble classifier</method><method>Extra Trees Classifier (ETC)</method><method>Light Gradient Boosting Machine (LightGBM)</method><method>Ridge Classifier (RC)</method><method>Linear Discriminant Analysis (LDA)</method>
2024,https://openalex.org/W4392514027,Social Sciences,Introducing machine‐learning‐based data fusion methods for analyzing multimodal data: An application of measuring trustworthiness of microenterprises,"Abstract Research Summary Multimodal data, comprising interdependent unstructured text, image, and audio data that collectively characterize the same source, with video being a prominent example, offer a wealth of information for strategy researchers. We emphasize the theoretical importance of capturing the interdependencies between different modalities when evaluating multimodal data. To automate the analysis of video data, we introduce advanced deep machine learning and data fusion methods that comprehensively account for all intra‐ and inter‐modality interdependencies. Through an empirical demonstration focused on measuring the trustworthiness of grassroots sellers in live streaming commerce on Tik Tok, we highlight the crucial role of interpersonal interactions in the business success of microenterprises. We provide access to our data and algorithms to facilitate data fusion in strategy research that relies on multimodal data. Managerial Summary Our study highlights the vital role of both verbal and nonverbal communication in attaining strategic objectives. Through the analysis of multimodal data—incorporating text, images, and audio—we demonstrate the essential nature of interpersonal interactions in bolstering trustworthiness, thus facilitating the success of microenterprises. Leveraging advanced machine learning techniques, such as data fusion for multimodal data and explainable artificial intelligence, we notably enhance predictive accuracy and theoretical interpretability in assessing trustworthiness. By bridging strategic research with cutting‐edge computational techniques, we provide practitioners with actionable strategies for enhancing communication effectiveness and fostering trust‐based relationships. Access our data and code for further exploration.","<method>deep machine learning</method>, <method>data fusion</method>, <method>advanced machine learning techniques</method>, <method>explainable artificial intelligence</method>",No methods remaining
2024,https://openalex.org/W4396767636,Social Sciences,From explainable to interpretable deep learning for natural language processing in healthcare: How far from reality?,"Deep learning (DL) has substantially enhanced natural language processing (NLP) in healthcare research. However, the increasing complexity of DL-based NLP necessitates transparent model interpretability, or at least explainability, for reliable decision-making. This work presents a thorough scoping review of explainable and interpretable DL in healthcare NLP. The term ""eXplainable and Interpretable Artificial Intelligence"" (XIAI) is introduced to distinguish XAI from IAI. Different models are further categorized based on their functionality (model-, input-, output-based) and scope (local, global). Our analysis shows that attention mechanisms are the most prevalent emerging IAI technique. The use of IAI is growing, distinguishing it from XAI. The major challenges identified are that most XIAI does not explore ""global"" modelling processes, the lack of best practices, and the lack of systematic evaluation and benchmarks. One important opportunity is to use attention mechanisms to enhance multi-modal XIAI for personalized medicine. Additionally, combining DL with causal logic holds promise. Our discussion encourages the integration of XIAI in Large Language Models (LLMs) and domain-specific smaller models. In conclusion, XIAI adoption in healthcare requires dedicated in-house expertise. Collaboration with domain experts, end-users, and policymakers can lead to ready-to-use XIAI methods across NLP and medical tasks. While challenges exist, XIAI techniques offer a valuable foundation for interpretable NLP algorithms in healthcare.","<method>deep learning (DL)</method>, <method>attention mechanisms</method>, <method>combining DL with causal logic</method>, <method>Large Language Models (LLMs)</method>",<method>deep learning (DL)</method><method>attention mechanisms</method>
2024,https://openalex.org/W4400903160,Social Sciences,Deep Learning for Pneumonia Detection in Chest X-ray Images: A Comprehensive Survey,"This paper addresses the significant problem of identifying the relevant background and contextual literature related to deep learning (DL) as an evolving technology in order to provide a comprehensive analysis of the application of DL to the specific problem of pneumonia detection via chest X-ray (CXR) imaging, which is the most common and cost-effective imaging technique available worldwide for pneumonia diagnosis. This paper in particular addresses the key period associated with COVID-19, 2020–2023, to explain, analyze, and systematically evaluate the limitations of approaches and determine their relative levels of effectiveness. The context in which DL is applied as both an aid to and an automated substitute for existing expert radiography professionals, who often have limited availability, is elaborated in detail. The rationale for the undertaken research is provided, along with a justification of the resources adopted and their relevance. This explanatory text and the subsequent analyses are intended to provide sufficient detail of the problem being addressed, existing solutions, and the limitations of these, ranging in detail from the specific to the more general. Indeed, our analysis and evaluation agree with the generally held view that the use of transformers, specifically, vision transformers (ViTs), is the most promising technique for obtaining further effective results in the area of pneumonia detection using CXR images. However, ViTs require extensive further research to address several limitations, specifically the following: biased CXR datasets, data and code availability, the ease with which a model can be explained, systematic methods of accurate model comparison, the notion of class imbalance in CXR datasets, and the possibility of adversarial attacks, the latter of which remains an area of fundamental research.","<method>deep learning (DL)</method>, <method>transformers</method>, <method>vision transformers (ViTs)</method>",<method>deep learning (DL)</method><method>transformers</method><method>vision transformers (ViTs)</method>
2024,https://openalex.org/W4390659208,Social Sciences,GraphCL-DTA: A Graph Contrastive Learning With Molecular Semantics for Drug-Target Binding Affinity Prediction,"Drug-target binding affinity prediction plays an important role in the early stages of drug discovery, which can infer the strength of interactions between new drugs and new targets. However, the performance of previous computational models is limited by the following drawbacks. The learning of drug representation relies only on supervised data without considering the information in the molecular graph itself. Moreover, most previous studies tended to design complicated representation learning modules, while uniformity used to measure representation quality is ignored. In this study, we propose GraphCL-DTA, a graph contrastive learning with molecular semantics for drug-target binding affinity prediction. This graph contrastive learning framework replaces the dropout-based data augmentation strategy by performing data augmentation in the embedding space, thereby better preserving the semantic information of the molecular graph. A more essential and effective drug representation can be learned through this graph contrastive framework without additional supervised data. Next, we design a new loss function that can be directly used to adjust the uniformity of drug and target representations. By directly optimizing the uniformity of representations, the representation quality of drugs and targets can be improved. The effectiveness of the above innovative elements is verified on two real datasets, KIBA and Davis. Compared with the GraphDTA model, the relative improvement of the GraphCL-DTA model on the two datasets is 2.7% and 4.5%. The graph contrastive learning framework and uniformity function in the GraphCL-DTA model can be embedded into other computational models as independent modules to improve their generalization capability.","<method>graph contrastive learning</method>, <method>data augmentation in the embedding space</method>, <method>loss function to adjust uniformity of representations</method>",<method>graph contrastive learning</method><method>data augmentation in the embedding space</method>
2024,https://openalex.org/W4390738651,Social Sciences,Enhancing Multi-UAV Reconnaissance and Search Through Double Critic DDPG With Belief Probability Maps,"Unmanned Aerial Vehicles (UAVs) have recently attracted significant attention due to their potential applications in reconnaissance and search. This paper aims to investigate the issue of multi-UAV cooperative reconnaissance and search (MCRS) to ensure ample coverage of the mission area and precise localization of static targets. The MCRS problem is modeled as a multi-objective optimization problem, taking into account the credibility of search results. To achieve this, we design a belief probability map based on the Dempster-Shafer (DS) evidence theory, comprising an uncertainty map and two target maps. This representation enables a clear depiction of both the presence of the target and the uncertainty within the map. Subsequently, we reformulate this multi-objective optimization problem within the framework of Decentralized Partially Observable Markov Decision Process (Dec-POMDP). To address this reformulation, a new deep reinforcement learning approach called Double Critic Deep Deterministic Policy Gradient (DCDDPG) is proposed. Specifically, we introduce both a centralized critic and a local critic for each UAV agent to estimate the action-value function. This approach helps balance the bias in the action-value function estimation and the variance in the policy updates, thereby improving the coordination effect. Extensive simulation results demonstrate that DCDDPG outperforms existing techniques in terms of search efficiency and coverage.","<method>Dempster-Shafer (DS) evidence theory</method>, <method>Decentralized Partially Observable Markov Decision Process (Dec-POMDP)</method>, <method>Double Critic Deep Deterministic Policy Gradient (DCDDPG)</method>",<method>Decentralized Partially Observable Markov Decision Process (Dec-POMDP)</method>
2024,https://openalex.org/W4390825338,Social Sciences,PEGA: A Privacy-Preserving Genetic Algorithm for Combinatorial Optimization,"Evolutionary algorithms (EAs), such as the genetic algorithm (GA), offer an elegant way to handle combinatorial optimization problems (COPs). However, limited by expertise and resources, most users lack the capability to implement EAs for solving COPs. An intuitive and promising solution is to outsource evolutionary operations to a cloud server, however, it poses privacy concerns. To this end, this article proposes a novel computing paradigm called evolutionary computation as a service (ECaaS), where a cloud server renders evolutionary computation services for users while ensuring their privacy. Following the concept of ECaaS, this article presents privacy-preserving genetic algorithm (PEGA), a privacy-preserving GA designed specifically for COPs. PEGA enables users, regardless of their domain expertise or resource availability, to outsource COPs to the cloud server that holds a competitive GA and approximates the optimal solution while safeguarding privacy. Notably, PEGA features the following characteristics. First, PEGA empowers users without domain expertise or sufficient resources to solve COPs effectively. Second, PEGA protects the privacy of users by preventing the leakage of optimization problem details. Third, PEGA performs comparably to the conventional GA when approximating the optimal solution. To realize its functionality, we implement PEGA falling in a twin-server architecture and evaluate it on two widely known COPs: 1) the traveling Salesman problem (TSP) and 2) the 0/1 knapsack problem (KP). Particularly, we utilize encryption cryptography to protect users' privacy and carefully design a suite of secure computing protocols to support evolutionary operators of GA on encrypted chromosomes. Privacy analysis demonstrates that PEGA successfully preserves the confidentiality of COP contents. Experimental evaluation results on several TSP datasets and KP datasets reveal that PEGA performs equivalently to the conventional GA in approximating the optimal solution.","<method>evolutionary algorithms (EAs)</method>, <method>genetic algorithm (GA)</method>, <method>privacy-preserving genetic algorithm (PEGA)</method>",<method>evolutionary algorithms (EAs)</method><method>genetic algorithm (GA)</method>
2024,https://openalex.org/W4390961691,Social Sciences,"E-government quality from the citizen's perspective: the role of perceived factors, demographic variables and the digital divide","Purpose Governments globally are adopting e-Government services to streamline administrative processes and meet citizens' expectations. This study investigates e-Government service quality from citizens' perspectives in 50 Greek municipalities, using the technology acceptance model (TAM) and cognitive theory. Design/methodology/approach The data from 707 respondents across 50 Greek municipalities are analyzed using structural equation modeling (SEM), ANOVA and moderation analysis. The study assesses the relationships between key factors and citizens' intentions to use e-Government services, examining the impact of demographics and the digital divide. Findings The study reveals that perceived attractiveness (PA), perceived usefulness (PU), perceived ease of use (PEOU) and awareness (AWA) significantly influence citizens' behavioral intentions (BINTs) toward municipal e-Government services. Interestingly, PEOU negatively impacts users' intentions, suggesting dissatisfaction with portal attractiveness and utility. The study explores the influence of demographic variables and the digital divide on citizens' BINTs, highlighting economic activity and income as crucial determinants. Practical implications The study emphasizes the significance of user-friendly design, PU, PEOU and AWA campaigns for the development of effective e-Government platforms. Strategies to address the digital divide and promote citizen engagement are essential for enhancing user experience, service utility and AWA, ultimately fostering a positive attitude toward e-Government. Social implications Addressing demographic differences ensures inclusive e-Government systems, while bridging the digital divide promotes equitable service delivery and citizen engagement. Originality/value This research provides insights into factors influencing citizens' BINTs toward e-Government services. The study's examination of demographic attributes and the digital divide enhances understanding, contributing to the development of citizen-centric e-Government services and supporting inclusive digital transformations.","<method>structural equation modeling (SEM)</method>, <method>ANOVA</method>, <method>moderation analysis</method>",No methods remaining
2024,https://openalex.org/W4391430106,Social Sciences,A soft voting ensemble learning approach for credit card fraud detection,"With the advancement of e-commerce and modern technological development, credit cards are widely used for both online and offline purchases, which has increased the number of daily fraudulent transactions. Many organizations and financial institutions worldwide lose billions of dollars annually because of credit card fraud. Due to the global distribution of both legitimate and fraudulent transactions, it is difficult to discern between the two. Furthermore, because only a small proportion of transactions are fraudulent, there is a problem of class imbalance. Hence, an effective fraud-detection methodology is required to sustain the reliability of the payment system. Machine learning has recently emerged as a viable substitute for identifying this type of fraud. However, ML approaches have difficulty identifying fraud with high prediction accuracy, while also decreasing misclassification costs due to the size of the imbalanced data. In this research, a soft voting ensemble learning approach for detecting credit card fraud on imbalanced data is proposed. To do this, the proposed approach is evaluated and compared with numerous sophisticated sampling techniques (i.e., oversampling, undersampling, and hybrid sampling) to overcome the class imbalance problem. We develop several credit card fraud classifiers, including ensemble classifiers, with and without sampling techniques. According to the experimental results, the proposed soft-voting approach outperforms individual classifiers. With a false negative rate (FNR) of 0.0306, it achieves a precision of 0.9870, recall of 0.9694, f1-score of 0.8764, and AUROC of 0.9936.","<method>soft voting ensemble learning</method>, <method>oversampling</method>, <method>undersampling</method>, <method>hybrid sampling</method>, <method>ensemble classifiers</method>",<method>soft voting ensemble learning</method><method>undersampling</method><method>ensemble classifiers</method>
2024,https://openalex.org/W4392245149,Social Sciences,Towards development of functional climate-driven early warning systems for climate-sensitive infectious diseases: Statistical models and recommendations,"Climate, weather and environmental change have significantly influenced patterns of infectious disease transmission, necessitating the development of early warning systems to anticipate potential impacts and respond in a timely and effective way. Statistical modelling plays a pivotal role in understanding the intricate relationships between climatic factors and infectious disease transmission. For example, time series regression modelling and spatial cluster analysis have been employed to identify risk factors and predict spatial and temporal patterns of infectious diseases. Recently advanced spatio-temporal models and machine learning offer an increasingly robust framework for modelling uncertainty, which is essential in climate-driven disease surveillance due to the dynamic and multifaceted nature of the data. Moreover, Artificial Intelligence (AI) techniques, including deep learning and neural networks, excel in capturing intricate patterns and hidden relationships within climate and environmental data sets. Web-based data has emerged as a powerful complement to other datasets encompassing climate variables and disease occurrences. However, given the complexity and non-linearity of climate-disease interactions, advanced techniques are required to integrate and analyse these diverse data to obtain more accurate predictions of impending outbreaks, epidemics or pandemics. This article presents an overview of an approach to creating climate-driven early warning systems with a focus on statistical model suitability and selection, along with recommendations for utilizing spatio-temporal and machine learning techniques. By addressing the limitations and embracing the recommendations for future research, we could enhance preparedness and response strategies, ultimately contributing to the safeguarding of public health in the face of evolving climate challenges.","<method>time series regression modelling</method>, <method>spatial cluster analysis</method>, <method>spatio-temporal models</method>, <method>machine learning</method>, <method>Artificial Intelligence (AI) techniques</method>, <method>deep learning</method>, <method>neural networks</method>",<method>spatio-temporal models</method><method>machine learning</method><method>deep learning</method><method>neural networks</method>
2024,https://openalex.org/W4392791479,Social Sciences,Health equity assessment of machine learning performance (HEAL): a framework and dermatology AI model case study,"BackgroundArtificial intelligence (AI) has repeatedly been shown to encode historical inequities in healthcare. We aimed to develop a framework to quantitatively assess the performance equity of health AI technologies and to illustrate its utility via a case study.MethodsHere, we propose a methodology to assess whether health AI technologies prioritise performance for patient populations experiencing worse outcomes, that is complementary to existing fairness metrics. We developed the Health Equity Assessment of machine Learning performance (HEAL) framework designed to quantitatively assess the performance equity of health AI technologies via a four-step interdisciplinary process to understand and quantify domain-specific criteria, and the resulting HEAL metric. As an illustrative case study (analysis conducted between October 2022 and January 2023), we applied the HEAL framework to a dermatology AI model. A set of 5420 teledermatology cases (store-and-forward cases from patients of 20 years or older, submitted from primary care providers in the USA and skin cancer clinics in Australia), enriched for diversity in age, sex and race/ethnicity, was used to retrospectively evaluate the AI model's HEAL metric, defined as the likelihood that the AI model performs better for subpopulations with worse average health outcomes as compared to others. The likelihood that AI performance was anticorrelated to pre-existing health outcomes was estimated using bootstrap methods as the probability that the negated Spearman's rank correlation coefficient (i.e., ""R"") was greater than zero. Positive values of R suggest that subpopulations with poorer health outcomes have better AI model performance. Thus, the HEAL metric, defined as p (R >0), measures how likely the AI technology is to prioritise performance for subpopulations with worse average health outcomes as compared to others (presented as a percentage below). Health outcomes were quantified as disability-adjusted life years (DALYs) when grouping by sex and age, and years of life lost (YLLs) when grouping by race/ethnicity. AI performance was measured as top-3 agreement with the reference diagnosis from a panel of 3 dermatologists per case.FindingsAcross all dermatologic conditions, the HEAL metric was 80.5% for prioritizing AI performance of racial/ethnic subpopulations based on YLLs, and 92.1% and 0.0% respectively for prioritizing AI performance of sex and age subpopulations based on DALYs. Certain dermatologic conditions were significantly associated with greater AI model performance compared to a reference category of less common conditions. For skin cancer conditions, the HEAL metric was 73.8% for prioritizing AI performance of age subpopulations based on DALYs.InterpretationAnalysis using the proposed HEAL framework showed that the dermatology AI model prioritised performance for race/ethnicity, sex (all conditions) and age (cancer conditions) subpopulations with respect to pre-existing health disparities. More work is needed to investigate ways of promoting equitable AI performance across age for non-cancer conditions and to better understand how AI models can contribute towards improving equity in health outcomes.FundingGoogle LLC.","<method>Health Equity Assessment of machine Learning performance (HEAL) framework</method>, <method>bootstrap methods</method>",<method>bootstrap methods</method>
2024,https://openalex.org/W4392960540,Social Sciences,A sentiment analysis approach for understanding users’ perception of metaverse marketplace,"This research explores the user perceptions of the Metaverse Marketplace, analyzing a substantial dataset of over 860,000 Twitter posts through sentiment analysis and topic modeling techniques. The study aims to uncover the driving factors behind user engagement and sentiment in this novel digital trading space. Key findings highlight a predominantly positive user sentiment, with significant enthusiasm for the marketplace's revenue generation and entertainment potential, particularly within the gaming sector. Users express appreciation for the innovative opportunities the Metaverse Marketplace offers for artists, designers, and traders in handling and trading digital assets. This positive outlook is tempered by notable concerns regarding security and privacy within the Metaverse, pointing to a critical area for development and assurance. The study also reveals a substantial neutral sentiment, reflecting users' cautious but interested stance, particularly regarding the marketplace's role in investment and passive income opportunities. This balanced view underscores the evolving nature of user perceptions in this emerging field. Theoretically, the research enriches the discourse on technology adoption, particularly in virtual environments, by highlighting perceived benefits and enjoyment as significant adoption drivers. These insights are invaluable for stakeholders in the Metaverse Marketplace, guiding the development of more secure, engaging, and user-friendly platforms. While providing a pioneering perspective on Metaverse user perceptions, the study acknowledges its limitation to Twitter data, suggesting the need for broader research methodologies for a more holistic understanding.","<method>sentiment analysis</method>, <method>topic modeling</method>",<method>topic modeling</method>
2024,https://openalex.org/W4392979783,Social Sciences,BEVSOC: Self-Supervised Contrastive Learning for Calibration-Free BEV 3-D Object Detection,"3D object detection based on multi-view cameras and bird's-eye view (BEV) representation is a key task for autonomous driving, as it enables the perception systems to understand the surrounding scenes. However, most existing BEV representation methods rely on the projection matrix of camera intrinsic and extrinsic parameters, which requires a complex and time-consuming calibration process that may introduce errors and degrade the detection performance. Moreover, the calibration results may vary due to environmental changes and affect the stability of the detection system. To address this problem, we propose a calibration-free 3D object detection method that leverages a group-equivariant convolutional network to extract features from multi-view images and a projection network module to learn the implicit 3D-to-2D projection relationship for obtaining BEV representation. Furthermore, we employ contrastive learning to pre-train the projection network module without using manually annotated data. By exploiting the multi-view camera data through contrastive learning, our proposed method eliminates the need for tedious calibration, avoids calibration errors, and reduces the dependence on a large amount of annotated data for calibration-free 3D object detection. We evaluate our method on the nuScenes dataset and demonstrate its competitive performance. Our method improves the stability and reliability of 3D object detection in long-term autonomous driving.","<method>group-equivariant convolutional network</method>, <method>projection network module</method>, <method>contrastive learning</method>",<method>group-equivariant convolutional network</method><method>contrastive learning</method>
2024,https://openalex.org/W4395110469,Social Sciences,ac4C-AFL: A high-precision identification of human mRNA N4-acetylcytidine sites based on adaptive feature representation learning,"RNA N4-acetylcytidine (ac4C) is a highly conserved RNA modification that plays a crucial role in controlling mRNA stability, processing, and translation. Consequently, accurate identification of ac4C sites across the genome is critical for understanding gene expression regulation mechanisms. In this study, we have developed ac4C-AFL, a bioinformatics tool that precisely identifies ac4C sites from primary RNA sequences. In ac4C-AFL, we identified the optimal sequence length for model building and implemented an adaptive feature representation strategy that is capable of extracting the most representative features from RNA. To identify the most relevant features, we proposed a novel ensemble feature importance scoring strategy to rank features effectively. We then used this information to conduct the sequential forward search, which individually determine the optimal feature set from the 16 sequence-derived feature descriptors. Utilizing these optimal feature descriptors, we constructed 176 baseline models using 11 popular classifiers. The most efficient baseline models were identified using the two-step feature selection approach, whose predicted scores were integrated and trained with the appropriate classifier to develop the final prediction model. Our rigorous cross-validations and independent tests demonstrate that ac4C-AFL surpasses contemporary tools in predicting ac4C sites. Moreover, we have developed a publicly accessible web server at https://balalab-skku.org/ac4C-AFL/.","<method>ensemble feature importance scoring strategy</method>, <method>sequential forward search</method>, <method>classifiers</method>, <method>two-step feature selection approach</method>",<method>sequential forward search</method>
2024,https://openalex.org/W4396919944,Social Sciences,CrossHAR: Generalizing Cross-dataset Human Activity Recognition via Hierarchical Self-Supervised Pretraining,"The increasing availability of low-cost wearable devices and smartphones has significantly advanced the field of sensor-based human activity recognition (HAR), attracting considerable research interest. One of the major challenges in HAR is the domain shift problem in cross-dataset activity recognition, which occurs due to variations in users, device types, and sensor placements between the source dataset and the target dataset. Although domain adaptation methods have shown promise, they typically require access to the target dataset during the training process, which might not be practical in some scenarios. To address these issues, we introduce CrossHAR, a new HAR model designed to improve model performance on unseen target datasets. CrossHAR involves three main steps: (i) CrossHAR explores the sensor data generation principle to diversify the data distribution and augment the raw sensor data. (ii) CrossHAR then employs a hierarchical self-supervised pretraining approach with the augmented data to develop a generalizable representation. (iii) Finally, CrossHAR fine-tunes the pretrained model with a small set of labeled data in the source dataset, enhancing its performance in cross-dataset HAR. Our extensive experiments across multiple real-world HAR datasets demonstrate that CrossHAR outperforms current state-of-the-art methods by 10.83% in accuracy, demonstrating its effectiveness in generalizing to unseen target datasets.","<method>domain adaptation methods</method>, <method>data augmentation</method>, <method>hierarchical self-supervised pretraining</method>, <method>fine-tuning</method>",<method>domain adaptation methods</method><method>fine-tuning</method>
2024,https://openalex.org/W4398257517,Social Sciences,Transferable deep generative modeling of intrinsically disordered protein conformations,"Intrinsically disordered proteins have dynamic structures through which they play key biological roles. The elucidation of their conformational ensembles is a challenging problem requiring an integrated use of computational and experimental methods. Molecular simulations are a valuable computational strategy for constructing structural ensembles of disordered proteins but are highly resource-intensive. Recently, machine learning approaches based on deep generative models that learn from simulation data have emerged as an efficient alternative for generating structural ensembles. However, such methods currently suffer from limited transferability when modeling sequences and conformations absent in the training data. Here, we develop a novel generative model that achieves high levels of transferability for intrinsically disordered protein ensembles. The approach, named idpSAM, is a latent diffusion model based on transformer neural networks. It combines an autoencoder to learn a representation of protein geometry and a diffusion model to sample novel conformations in the encoded space. IdpSAM was trained on a large dataset of simulations of disordered protein regions performed with the ABSINTH implicit solvent model. Thanks to the expressiveness of its neural networks and its training stability, idpSAM faithfully captures 3D structural ensembles of test sequences with no similarity in the training set. Our study also demonstrates the potential for generating full conformational ensembles from datasets with limited sampling and underscores the importance of training set size for generalization. We believe that idpSAM represents a significant progress in transferable protein ensemble modeling through machine learning.","<method>deep generative models</method>, <method>latent diffusion model</method>, <method>transformer neural networks</method>, <method>autoencoder</method>, <method>diffusion model</method>",<method>deep generative models</method><method>latent diffusion model</method><method>transformer neural networks</method><method>autoencoder</method><method>diffusion model</method>
2024,https://openalex.org/W4400009952,Social Sciences,Trust beyond Technology Algorithms: A Theoretical Exploration of Consumer Trust and Behavior in Technological Consumption and AI Projects,"In an era dominated by artificial intelligence (AI), establishing customer confidence is crucial for the integration and acceptance of AI technologies. This interdisciplinary study examines factors influencing customer trust in AI systems through a mixed-methods approach, blending quantitative analysis with qualitative insights to create a comprehensive conceptual framework. Quantitatively, the study analyzes responses from 1248 participants using structural equation modeling (SEM), exploring interactions between technological factors like perceived usefulness and transparency, psychological factors including perceived risk and domain expertise, and organizational factors such as leadership support and ethical accountability. The results confirm the model, showing significant impacts of these factors on consumer trust and AI adoption attitudes. Qualitatively, the study includes 35 semi-structured interviews and five case studies, providing deeper insight into the dynamics shaping trust. Key themes identified include the necessity of explainability, domain competence, corporate culture, and stakeholder engagement in fostering trust. The qualitative findings complement the quantitative data, highlighting the complex interplay between technology capabilities, human perceptions, and organizational practices in establishing trust in AI. By integrating these findings, the study proposes a novel conceptual model that elucidates how various elements collectively influence consumer trust in AI. This model not only advances theoretical understanding but also offers practical implications for businesses and policymakers. The research contributes to the discourse on trust creation and decision-making in technology, emphasizing the need for interdisciplinary efforts to address societal challenges associated with technological advancements. It lays the groundwork for future research, including longitudinal, cross-cultural, and industry-specific studies, to further explore consumer trust in AI.",<method>structural equation modeling (SEM)</method>,No methods remaining
2024,https://openalex.org/W4390496539,Social Sciences,A machine learning-based classification model to support university students with dyslexia with personalized tools and strategies,"Abstract Dyslexia is a specific learning disorder that causes issues related to reading, which affects around 10% of the worldwide population. This can compromise comprehension and memorization skills, and result in anxiety and lack of self-esteem, if no support is provided. Moreover, this support should be highly personalized, to be actually helpful. In this paper, a model to classify the most useful methodologies to support students with dyslexia has been created, with a focus on university alumni. The prediction algorithm is based on supervised machine learning techniques; starting from the issues that dyslexic students experience during their career, it is capable of suggesting customized support digital tools and learning strategies for each of them. The algorithm was trained and tested on data acquired through a self-evaluation questionnaire, which was designed and then spread to more than 1200 university students. It allowed 17 useful tools and 22 useful strategies to be detected. The results of the testing showed an average prediction accuracy higher than 90%, which rises to 94% by renouncing to guess the less-predictable 8 tools/strategies. In the light of this, it is possible to state that the implemented algorithm can achieve the set goal and, thus, reduce the gap between dyslexic and non-dyslexic students. This achievement paves the way for a new modality of facing the problem of dyslexia by university institutions, which aims at modifying teaching activities toward students’ needs, instead of simply reducing their study load or duties. This complies with the definition and the aims of inclusivity.",<method>supervised machine learning techniques</method>,<method>supervised machine learning techniques</method>
2024,https://openalex.org/W4390500011,Social Sciences,Offshore wind farm site selection in Norway: Using a fuzzy trigonometric weighted assessment model,"Maximising the energy potential of offshore wind farms requires an in-depth assessment of technological, economic, sociopolitical, and environmental aspects. Given the large economic impact of large-scale projects, a robust site selection procedure is critical for limiting financial risks while supporting informed investments. This research uncovers a novel and multidisciplinary approach for boosting the efficacy of Norwegian and global offshore wind farm siting investments. The proposed method uses a two-stage fuzzy mathematical model that considers technical, economic, logistical, and environmental factors. It combines the Ordinal Priority Approach (F-OPA) and Trigonometric Weighted Assessment (TRWA) technique by using an in-depth techno-economic assessment. An alternative reactive power compensation model, power loss calculations, and associated techno-economic analysis were performed for the investigated offshore wind farm locations. Furthermore, the energy economic calculations are carried out to provide support for the proposed decision-making framework. The proposed methodology was tested through a case study, focusing on ranking Norwegian offshore wind farm sites selected from potential locations announced by The Norwegian Water Resources and Energy Directorate (NVE). Within the Norwegian offshore wind farm sites, the approach demonstrated a versatile and efficient decision-making process at both individual and collective levels, identifying the Sandskallen-Sørøya Nord project as a pivotal investment priority and providing valuable managerial insights to enhance Norway's offshore wind initiatives. The model's stability was affirmed through a sensitivity analysis, underscoring its potential to enhance renewable energy policy and decision-making globally.","<method>two-stage fuzzy mathematical model</method>, <method>Ordinal Priority Approach (F-OPA)</method>, <method>Trigonometric Weighted Assessment (TRWA) technique</method>",No methods remaining
2024,https://openalex.org/W4390571563,Social Sciences,Employee work engagement in the digital transformation of enterprises: a fuzzy-set qualitative comparative analysis,"Abstract Information technology has brought about significant changes in enterprises, and new work situations have led to new problems. Employee resistance to new technologies, their ability to learn, and their ability to utilize personal resources to improve work engagement in the face of technological pressure are important factors that companies need to consider when undergoing digital transformation. The influence mechanism of configuration effects on factors around employee work engagement has not been explored, and technostress creators have rarely been included in the configuration as influencing factors in previous studies. On the basis of the job demands-resources (JD-R) model and trait activation theory, this study explored the factors that affect employees’ work engagement at the level of job demands and personal resources. The fuzzy-set qualitative comparative analysis (fsQCA) method was used to investigate the influence of technical stressors, self-efficacy, and the Big Five personality traits on employees’ work engagement. Through a survey of 225 employees in the context of enterprise digital transformation, the results show three driving paths that promote employees’ work engagement: openness to experience conscientiousness, self-efficacy driven, and inhibition to technical stressors. The study also analyzed employees’ low work engagement state, which is driven by an inhibition of agreeableness and extraversion. This research enriches the study of factors influencing work engagement in the digital transformation of enterprises.",<method>fuzzy-set qualitative comparative analysis (fsQCA)</method>,No methods remaining
2024,https://openalex.org/W4391131339,Social Sciences,Supervised Machine Learning Approaches for Predicting Key Pollutants and for the Sustainable Enhancement of Urban Air Quality: A Systematic Review,"Urban air pollution is a pressing global issue driven by factors such as swift urbanization, population expansion, and heightened industrial activities. To address this challenge, the integration of Machine Learning (ML) into smart cities presents a promising avenue. Our article offers comprehensive insights into recent advancements in air quality research, employing the PRISMA method as a cornerstone for the reviewing process, while simultaneously exploring the application of frequently employed ML methodologies. Focusing on supervised learning algorithms, the study meticulously analyzes air quality data, elucidating their unique benefits and challenges. These frequently employed ML techniques, including LSTM (Long Short-Term Memory), RF (Random Forest), ANN (Artificial Neural Networks), and SVR (Support Vector Regression), are instrumental in our quest for cleaner, healthier urban environments. By accurately predicting key pollutants such as particulate matter (PM), nitrogen oxides (NOx), carbon monoxide (CO), and ozone (O3), these methods offer tangible solutions for society. They enable informed decision-making for urban planners and policymakers, leading to proactive, sustainable strategies to combat urban air pollution. As a result, the well-being and health of urban populations are significantly improved. In this revised abstract, the importance of frequently employed ML methods in the context of air quality is explicitly emphasized, underlining their role in improving urban environments and enhancing the well-being of urban populations.","<method>LSTM (Long Short-Term Memory)</method>, <method>RF (Random Forest)</method>, <method>ANN (Artificial Neural Networks)</method>, <method>SVR (Support Vector Regression)</method>",<method>LSTM (Long Short-Term Memory)</method><method>RF (Random Forest)</method><method>ANN (Artificial Neural Networks)</method><method>SVR (Support Vector Regression)</method>
2024,https://openalex.org/W4391255815,Social Sciences,"Real Estate Industry Sustainable Solution (Environmental, Social, and Governance) Significance Assessment—AI-Powered Algorithm Implementation","As the global imperative for sustainable development intensifies, the real estate industry stands at the intersection of environmental responsibility and economic viability. This paper presents a comprehensive exploration of the significance of sustainable solutions within the real estate sector, employing advanced artificial intelligence (AI) algorithms to assess their impact. This study focuses on the integration of AI-powered tools in a decision-making process analysis. The research methodology involves the development and implementation of AI algorithms capable of analyzing vast datasets related to real estate attributes. By leveraging machine learning techniques, the algorithm assesses the significance of energy efficiency solutions along with other intrinsic and extrinsic attributes. This paper examines the effectiveness of these solutions in relation to the influence on property prices with a framework based on an AI-driven algorithm. The findings aim to inform real estate professionals and investors about the tangible advantages of integrating AI technologies into sustainable solutions, promoting a more informed and responsible approach to industry practices. This research contributes to the growing interest in the connection of the real estate sector, sustainability, and AI, offering insights that can guide strategic decision making. By implementing the random forest method in the real estate feature significance assessment original methodology, it has been shown that AI-powered algorithms can be a useful tool from the perspective of real estate price prediction. The methodology’s ability to handle non-linear relationships and provide insights into feature importance proved advantageous in comparison to the multiple regression analysis.","<method>artificial intelligence (AI) algorithms</method>, <method>machine learning techniques</method>, <method>random forest method</method>, <method>multiple regression analysis</method>",<method>random forest method</method>
2024,https://openalex.org/W4391655925,Social Sciences,Governance in the exploration of global and regional determinants of ICT development,"The present study assesses how governance affects information and communication technology (ICT) at the global level contingent on macroeconomic policy factors such as trade, foreign investment (FDI), manufacturing value added, and agricultural value added. The study focuses on 183 countries from 2003 to 2021, and the empirical evidence is based on the generalized method of moments (GMM). The following main findings are established. For the full sample, governance unconditionally promotes ICT development, while trade openness (industrial added value) moderates governance to promote (dampen) ICT development. In sub-Saharan Africa, only trade openness effectively moderates governance to induce an overall positive effect on ICT, while in the Middle East and North Africa (MENA) region, all policy variables moderate governance for an overall positive incidence on ICT sector development. The findings for the MENA region are confirmed in the Europe and Central Asia (ECA) region, with the exception of the moderating role of industrial added value, which engenders an overall negative effect. In the East and South Asia and the Pacific (ESAP) countries, one overall positive incidence is apparent in the role of trade openness, while net negative effects are established from the moderating roles of industrial added value and agricultural added value. In the American sub-sample, a positive (negative) net effect is apparent from the role of industrial added value (trade) in moderating the incidence of governance on ICT sector development. Finally, policy implications are discussed.",<method>generalized method of moments (GMM)</method>,No methods remaining
2024,https://openalex.org/W4391691888,Social Sciences,Highly Accurate Prediction of NMR Chemical Shifts from Low-Level Quantum Mechanics Calculations Using Machine Learning,"Theoretical predictions of NMR chemical shifts from first-principles can greatly facilitate experimental interpretation and structure identification of molecules in gas, solution, and solid-state phases. However, accurate prediction of chemical shifts using the gold-standard coupled cluster with singles, doubles, and perturbative triple excitations [CCSD(T)] method with a complete basis set (CBS) can be prohibitively expensive. By contrast, machine learning (ML) methods offer inexpensive alternatives for chemical shift predictions but are hampered by generalization to molecules outside the original training set. Here, we propose several new ideas in ML of the chemical shift prediction for H, C, N, and O that first introduce a novel feature representation, based on the atomic chemical shielding tensors within a molecular environment using an inexpensive quantum mechanics (QM) method, and train it to predict NMR chemical shieldings of a high-level composite theory that approaches the accuracy of CCSD(T)/CBS. In addition, we train the ML model through a new progressive active learning workflow that reduces the total number of expensive high-level composite calculations required while allowing the model to continuously improve on unseen data. Furthermore, the algorithm provides an error estimation, signaling potential unreliability in predictions if the error is large. Finally, we introduce a novel approach to keep the rotational invariance of the features using tensor environment vectors (TEVs) that yields a ML model with the highest accuracy compared to a similar model using data augmentation. We illustrate the predictive capacity of the resulting inexpensive shift machine learning (iShiftML) models across several benchmarks, including unseen molecules in the NS372 data set, gas-phase experimental chemical shifts for small organic molecules, and much larger and more complex natural products in which we can accurately differentiate between subtle diastereomers based on chemical shift assignments.","<method>machine learning (ML) methods</method>, <method>progressive active learning workflow</method>",No methods remaining
2024,https://openalex.org/W4391853581,Social Sciences,A Survey on Information Bottleneck,"This survey is for the remembrance of one of the creators of the information bottleneck theory, Prof. Naftali Tishby, passing away at the age of 68 on August, 2021. Information bottleneck (IB), a novel information theoretic approach for pattern analysis and representation learning, has gained widespread popularity since its birth in 1999. It provides an elegant balance between data compression and information preservation, and improves its prediction or representation ability accordingly. This survey summarizes both the theoretical progress and practical applications on IB over the past 20-plus years, where its basic theory, optimization, extensive models and task-oriented algorithms are systematically explored. Existing IB methods are roughly divided into two parts: traditional and deep IB, where the former contains the IBs optimized by traditional machine learning analysis techniques without involving any neural networks, and the latter includes the IBs involving the interpretation, optimization and improvement of deep neural works (DNNs). Specifically, based on the technique taxonomy, traditional IBs are further classified into three categories: Basic, Informative and Propagating IB; While the deep IBs, based on the taxonomy of problem settings, contain Debate: Understanding DNNs with IB, Optimizing DNNs Using IB, and DNN-based IB methods. Furthermore, some potential issues deserving future research are discussed. This survey attempts to draw a more complete picture of IB, from which the subsequent studies can benefit.","<method>Information bottleneck (IB)</method>, <method>traditional IBs</method>, <method>Basic IB</method>, <method>Informative IB</method>, <method>Propagating IB</method>, <method>deep IBs</method>, <method>Debate: Understanding DNNs with IB</method>, <method>Optimizing DNNs Using IB</method>, <method>DNN-based IB methods</method>",<method>Information bottleneck (IB)</method>
2024,https://openalex.org/W4392242086,Social Sciences,"Geographic and Demographic Differences in the Proportion of Individuals Living in Households With a Firearm, 1990-2018","Importance Measures of the proportion of individuals living in households with a firearm (HFR), over time, across states, and by demographic groups are needed to evaluate disparities in firearm violence and the effects of firearm policies. Objective To estimate HFR across states, years, and demographic groups in the US. Design, Setting, and Participants In this survey study, substate HFR totals from 1990 to 2018 were estimated using bayesian multilevel regression with poststratification to analyze survey data on HFR from the Behavioral Risk Factor Surveillance System and the General Social Survey. HFR was estimated for 16 substate demographic groups defined by gender, race, marital status, and urbanicity in each state and year. Exposures Survey responses indicating household firearm ownership were analyzed and compared with a common proxy for firearm ownership, the fraction of suicides completed with a firearm (FSS). Main Outcome and Measure HFR, FSS, and their correlations and differences. Results Among US adults in 2018, HFR was significantly higher among married, nonurban, non-Hispanic White and American Indian male individuals (65.0%; 95% credible interval [CI], 61.5%-68.7%) compared with their unmarried, urban, female counterparts from other racial and ethnic groups (7.3%; 95% CIs, 6.0%-9.2%). Marginal HFR rates for larger demographic groups also revealed important differences, with racial minority groups and urban dwellers having less than half the HFR of either White and American Indian (39.5%; 95% CI, 37.4%-42.9% vs 17.2%; 95% CI, 15.5%-19.9%) or nonurban populations (46.0%; 95% CI, 43.8%-49.5% vs 23.1%; 95% CI, 21.3%-26.2%). Population growth among groups less likely to own firearms, rather than changes in ownership within demographic groups, explains 30% of the 7 percentage point decline in HFR nationally from 1990 to 2018. Comparing HFR estimates with FSS revealed the expected high overall correlation across states (r = 0.84), but scaled FSS differed from HFR by as many as 20 percentage points for some states and demographic groups. Conclusions and Relevance This survey study of HFR providing detailed, publicly available HFR estimates highlights key disparities among individuals in households with firearms across states and demographic groups; it also identifies potential biases in the use of FSS as a proxy for firearm ownership rates. These findings are essential for researchers, policymakers, and public health experts looking to address geographic and demographic disparities in firearm violence.",<method>bayesian multilevel regression with poststratification</method>,<method>bayesian multilevel regression with poststratification</method>
2024,https://openalex.org/W4392449656,Social Sciences,Augmenting Reinforcement Learning With Transformer-Based Scene Representation Learning for Decision-Making of Autonomous Driving,"Decision-making for urban autonomous driving is challenging due to the stochastic nature of interactive traffic participants and the complexity of road structures. Although reinforcement learning (RL)-based decision-making schemes are promising to handle urban driving scenarios, they suffer from low sample efficiency and poor adaptability. In this paper, we propose the Scene-Rep Transformer to enhance RL decision-making capabilities through improved scene representation encoding and sequential predictive latent distillation. Specifically, a multi-stage Transformer (MST) encoder is constructed to model not only the interaction awareness between the ego vehicle and its neighbors but also intention awareness between the agents and their candidate routes. A sequential latent Transformer (SLT) with self-supervised learning objectives is employed to distill future predictive information into the latent scene representation, in order to reduce the exploration space and speed up training. The final decision-making module based on soft actor-critic (SAC) takes as input the refined latent scene representation from the Scene-Rep Transformer and generates decisions. The framework is validated in five challenging simulated urban scenarios with dense traffic, and its performance is manifested quantitatively by substantial improvements in data efficiency and performance in terms of success rate, safety, and efficiency. Qualitative results reveal that our framework is able to extract the intentions of neighbor agents, enabling better decision-making and more diversified driving behaviors.","<method>reinforcement learning (RL)</method>, <method>Transformer</method>, <method>multi-stage Transformer (MST) encoder</method>, <method>sequential latent Transformer (SLT)</method>, <method>self-supervised learning</method>, <method>soft actor-critic (SAC)</method>",<method>reinforcement learning (RL)</method><method>Transformer</method><method>self-supervised learning</method><method>soft actor-critic (SAC)</method>
2024,https://openalex.org/W4392714571,Social Sciences,Machine learning study using 2020 SDHS data to determine poverty determinants in Somalia,"Abstract Extensive research has been conducted on poverty in developing countries using conventional regression analysis, which has limited prediction capability. This study aims to address this gap by applying advanced machine learning (ML) methods to predict poverty in Somalia. Utilizing data from the first-ever 2020 Somalia Demographic and Health Survey (SDHS), a cross-sectional study design is considered. ML methods, including random forest (RF), decision tree (DT), support vector machine (SVM), and logistic regression, are tested and applied using R software version 4.1.2, while conventional methods are analyzed using STATA version 17. Evaluation metrics, such as confusion matrix, accuracy, precision, sensitivity, specificity, recall, F1 score, and area under the receiver operating characteristic (AUROC), are employed to assess the performance of predictive models. The prevalence of poverty in Somalia is notable, with approximately seven out of ten Somalis living in poverty, making it one of the highest rates in the region. Among nomadic pastoralists, agro-pastoralists, and internally displaced persons (IDPs), the poverty average stands at 69%, while urban areas have a lower poverty rate of 60%. The accuracy of prediction ranged between 67.21% and 98.36% for the advanced ML methods, with the RF model demonstrating the best performance. The results reveal geographical region, household size, respondent age group, husband employment status, age of household head, and place of residence as the top six predictors of poverty in Somalia. The findings highlight the potential of ML methods to predict poverty and uncover hidden information that traditional statistical methods cannot detect, with the RF model identified as the best classifier for predicting poverty in Somalia.","<method>random forest (RF)</method>, <method>decision tree (DT)</method>, <method>support vector machine (SVM)</method>, <method>logistic regression</method>",<method>random forest (RF)</method><method>decision tree (DT)</method><method>support vector machine (SVM)</method><method>logistic regression</method>
2024,https://openalex.org/W4393153153,Social Sciences,TimesURL: Self-Supervised Contrastive Learning for Universal Time Series Representation Learning,"Learning universal time series representations applicable to various types of downstream tasks is challenging but valuable in real applications. Recently, researchers have attempted to leverage the success of self-supervised contrastive learning (SSCL) in Computer Vision(CV) and Natural Language Processing(NLP) to tackle time series representation. Nevertheless, due to the special temporal characteristics, relying solely on empirical guidance from other domains may be ineffective for time series and difficult to adapt to multiple downstream tasks. To this end, we review three parts involved in SSCL including 1) designing augmentation methods for positive pairs, 2) constructing (hard) negative pairs, and 3) designing SSCL loss. For 1) and 2), we find that unsuitable positive and negative pair construction may introduce inappropriate inductive biases, which neither preserve temporal properties nor provide sufficient discriminative features. For 3), just exploring segment- or instance-level semantics information is not enough for learning universal representation. To remedy the above issues, we propose a novel self-supervised framework named TimesURL. Specifically, we first introduce a frequency-temporal-based augmentation to keep the temporal property unchanged. And then, we construct double Universums as a special kind of hard negative to guide better contrastive learning. Additionally, we introduce time reconstruction as a joint optimization objective with contrastive learning to capture both segment-level and instance-level information. As a result, TimesURL can learn high-quality universal representations and achieve state-of-the-art performance in 6 different downstream tasks, including short- and long-term forecasting, imputation, classification, anomaly detection and transfer learning.","<method>self-supervised contrastive learning (SSCL)</method>, <method>frequency-temporal-based augmentation</method>, <method>double Universums as a special kind of hard negative</method>, <method>time reconstruction as a joint optimization objective with contrastive learning</method>",<method>self-supervised contrastive learning (SSCL)</method>
2024,https://openalex.org/W4394749617,Social Sciences,MS-BACL: enhancing metabolic stability prediction through bond graph augmentation and contrastive learning,"Abstract Motivation Accurately predicting molecular metabolic stability is of great significance to drug research and development, ensuring drug safety and effectiveness. Existing deep learning methods, especially graph neural networks, can reveal the molecular structure of drugs and thus efficiently predict the metabolic stability of molecules. However, most of these methods focus on the message passing between adjacent atoms in the molecular graph, ignoring the relationship between bonds. This makes it difficult for these methods to estimate accurate molecular representations, thereby being limited in molecular metabolic stability prediction tasks. Results We propose the MS-BACL model based on bond graph augmentation technology and contrastive learning strategy, which can efficiently and reliably predict the metabolic stability of molecules. To our knowledge, this is the first time that bond-to-bond relationships in molecular graph structures have been considered in the task of metabolic stability prediction. We build a bond graph based on ‘atom-bond-atom’, and the model can simultaneously capture the information of atoms and bonds during the message propagation process. This enhances the model’s ability to reveal the internal structure of the molecule, thereby improving the structural representation of the molecule. Furthermore, we perform contrastive learning training based on the molecular graph and its bond graph to learn the final molecular representation. Multiple sets of experimental results on public datasets show that the proposed MS-BACL model outperforms the state-of-the-art model. Availability and Implementation The code and data are publicly available at https://github.com/taowang11/MS.","<method>deep learning</method>, <method>graph neural networks</method>, <method>bond graph augmentation technology</method>, <method>contrastive learning strategy</method>",<method>deep learning</method><method>graph neural networks</method><method>contrastive learning strategy</method>
2024,https://openalex.org/W4394893217,Social Sciences,"Advancements in machine visions for fruit sorting and grading: A bibliometric analysis, systematic review, and future research directions","This research conducted a bibliometric analysis of scholarly literature on fruit sorting and grading using machine vision, identifying primary themes, sources, most-cited publications, and countries. The literature and bibliometric analysis were thoroughly evaluated to consolidate knowledge, identify research trends, and propose specific research opportunities within the context of machine vision for fruit sorting and grading. Research articles from 2011 to 2023, indexed in the main collections of the Dimensions, Web-of-science, and Scopus databases, were examined. Findings were presented quantitatively, using tables and graphs to emphasize the key performance factors for article writing and citation. Upon applying inclusion and exclusion criteria, 129 out of 1,812 discovered articles were included for examination, while 1,683 studies were excluded due to non-compliance with the requirements and duplicates. Thirty-four (34) case study publications on machine vision applications for fruit sorting and grading were comprehensively examined to identify the adopted methodologies and future research opportunities. Covered methodologies include fruit varieties, data volumes, data collection, classification methods, and accuracy metrics. The study's findings indicate a significant increase in deep learning applications for fruit recognition in the recent five years (2019-2023), with excellent results achieved either by utilizing new models or with pre-trained networks for transfer learning. The research also identifies gaps and future directions for machine vision in fruit sorting and grading, such as enhancing system robustness, scalability, and adaptability, integrating multiple sensors and technological methods, and developing evaluation and comparison standards and criteria. The paper concludes that machine vision holds promise as a potent tool for fruit quality assessment, but further research and development are needed to address existing challenges and meet the growing demands of the fruit industry.","<method>deep learning</method>, <method>pre-trained networks for transfer learning</method>",<method>deep learning</method><method>pre-trained networks for transfer learning</method>
2024,https://openalex.org/W4395027859,Social Sciences,"Digital Economy, Entrepreneurship, and High-Quality Development of the Manufacturing Industry","The digital economy has emerged as a significant catalyst for economic expansion on a global scale, and this trend is evident in China.China is emerging as a dominant force in the digital economy and manufacturing industry due to its burgeoning entrepreneurial culture and emphasis on top-notch development.The present study investigates the interplay among the digital economy, entrepreneurship, and the high-quality development of the manufacturing industry in China.This paper comprehensively analyzes the current digital economy and entrepreneurship status in China.It examines the policies and initiatives to foster high-quality development in the manufacturing sector.This paper investigates the influence of digital technologies on productivity and efficiency within the manufacturing industry.It presents an analysis of data and case studies to underscore the notable advancements achieved by China in the digital economy and manufacturing sector while acknowledging the obstacles that remain to be overcome.The results indicate that prioritizing digital technologies, innovation, and entrepreneurship can bolster the manufacturing sector's competitiveness, resulting in sustainable economic expansion and progress.The investigation recognizes the obstacles that necessitate resolution to completely actualize the possibilities of the digital economy and entrepreneurship within the manufacturing sector, utilizing the Multi-Criteria Decision Making (MCDM) approach.The paper advocates for increased cooperation among government, industry, and academia to cultivate a conducive environment for digital entrepreneurship.This collaboration facilitates the manufacturing industry's ability to leverage the digital era's opportunities.",<method>Multi-Criteria Decision Making (MCDM)</method>,No methods remaining
2024,https://openalex.org/W4396240923,Social Sciences,Sequential predictive learning is a unifying theory for hippocampal representation and replay,"Abstract The mammalian hippocampus contains a cognitive map that represents an animal’s position in the environment 1 and generates offline “replay” 2,3 for the purposes of recall 4 , planning 5,6 , and forming long term memories 7 . Recently, it’s been found that artificial neural networks trained to predict sensory inputs develop spatially tuned cells 8 , aligning with predictive theories of hippocampal function 9–11 . However, whether predictive learning can also account for the ability to produce offline replay is unknown. Here, we find that spatially-tuned cells, which robustly emerge from all forms of predictive learning, do not guarantee the presence of a cognitive map with the ability to generate replay. Offline simulations only emerged in networks that used recurrent connections and head-direction information to predict multi-step observation sequences, which promoted the formation of a continuous attractor reflecting the geometry of the environment. These offline trajectories were able to show wake-like statistics, autonomously replay recently experienced locations, and could be directed by a virtual head direction signal. Further, we found that networks trained to make cyclical predictions of future observation sequences were able to rapidly learn a cognitive map and produced sweeping representations of future positions reminiscent of hippocampal theta sweeps 12 . These results demonstrate how hippocampal-like representation and replay can emerge in neural networks engaged in predictive learning, and suggest that hippocampal theta sequences reflect a circuit that implements a data-efficient algorithm for sequential predictive learning. Together, this framework provides a unifying theory for hippocampal functions and hippocampal-inspired approaches to artificial intelligence.","<method>artificial neural networks</method>, <method>predictive learning</method>, <method>recurrent connections</method>, <method>cyclical predictions of future observation sequences</method>",<method>artificial neural networks</method><method>recurrent connections</method>
2024,https://openalex.org/W4399501912,Social Sciences,Combating the Challenges of False Positives in AI-Driven Anomaly Detection Systems and Enhancing Data Security in the Cloud,"Anomaly detection is critical for network security, fraud detection, and system health monitoring applications. Traditional methods like statistical approaches and distance-based techniques often struggle with high-dimensional and complex data, leading to high false positive rates. This study addresses the challenge by investigating advanced AI-driven techniques to reduce false positives and enhance data security within cloud computing environments. This study employs deep learning models, integrates contextual data, and incorporates comprehensive security measures to enhance anomaly detection performance. Data from synthetic sources, such as the NSL-KDD dataset and real-world cloud environments, were utilized to capture user behavior logs, system states, and network traffic. Over 50 academic journals were reviewed, and 21 were selected based on inclusion criteria, such as relevance to AI-driven anomaly detection, empirical performance metrics, and the focus on cloud environments, and exclusion criteria that filtered out studies lacking empirical data or not specific to cloud-based systems. Methodologically, the research involves a comparative analysis of different AI techniques and their impact on false positive rates, accuracy, precision, and recall. The findings demonstrate that deep learning techniques significantly outperform traditional methods, achieving a lower false positive rate and higher accuracy. The results underscore the importance of contextual data and robust security protocols in reliable anomaly detection. This research fills a gap by thoroughly evaluating advanced AI techniques for reducing false positives in cloud environments. The study's significance lies in guiding the development of more effective anomaly detection systems, thereby enhancing security and reliability across various applications. Additionally, organizations should invest in continuously developing and integrating AI-driven anomaly detection systems with comprehensive security measures to improve their effectiveness the study suggests that further study be conducted with large datasets to evaluate the effectiveness of Hybrid anomaly detection systems in detecting and addressing false positives.","<method>deep learning models</method>, <method>deep learning techniques</method>, <method>AI-driven techniques</method>, <method>Hybrid anomaly detection systems</method>",<method>Hybrid anomaly detection systems</method>
2024,https://openalex.org/W4390905130,Social Sciences,Long-Term Preference Mining With Temporal and Spatial Fusion for Point-of-Interest Recommendation,"The growth of the tourism industry has greatly boosted the Point-of-Interest (POI) recommendation tasks using Location-based Social Networks (LBSNs). The ever-evolving nature of user preferences poses a major problem. To address this, we propose a Long-Term Preference Mining (LTPM) approach that utilizes the Temporal Recency (TR) measure in the visits along with the location-aware recommendation based on Spatial Proximity (SP) to the user's location. The temporal dynamics and changing preferences are exploited based on the modified Long Short-term Memory (LSTM) that utilizes the time decay. The spatial considerations are modeled in two aspects: geographical proximity based on enhanced representation learning using orthogonal mapping. Second, the Region-of-Interest (ROI) is based on spatial griding and metric learning to capture the spatial relationships between POIs to enhance the metric space representation. The final recommendations are based on a multi-head attention mechanism that allocates the weights to different features. The combination of three models, called, LTPM-TRSP approach captures the user-POI, POI-POI, and POI-time relationships by focusing on the informative representation of sequential and spatial data. The category-aware final recommendations based on comprehensive historical behavior and geographical context are quite efficacious. The experimentation on three real-world datasets, Gowalla, Foursquare, and Weeplaces, also suggests the potency compared to other state-of-the-art approaches.","<method>Long Short-term Memory (LSTM)</method>, <method>enhanced representation learning using orthogonal mapping</method>, <method>metric learning</method>, <method>multi-head attention mechanism</method>",<method>Long Short-term Memory (LSTM)</method><method>metric learning</method><method>multi-head attention mechanism</method>
2024,https://openalex.org/W4391256320,Social Sciences,Gas adsorption meets deep learning: voxelizing the potential energy surface of metal-organic frameworks,"Abstract Intrinsic properties of metal-organic frameworks (MOFs), such as their ultra porosity and high surface area, deem them promising solutions for problems involving gas adsorption. Nevertheless, due to their combinatorial nature, a huge number of structures is feasible which renders cumbersome the selection of the best candidates with traditional techniques. Recently, machine learning approaches have emerged as efficient tools to deal with this challenge, by allowing researchers to rapidly screen large databases of MOFs via predictive models. The performance of the latter is tightly tied to the mathematical representation of a material, thus necessitating the use of informative descriptors. In this work, a generalized framework to predict gaseous adsorption properties is presented, using as one and only descriptor the capstone of chemical information: the potential energy surface (PES). In order to be machine understandable, the PES is voxelized and subsequently a 3D convolutional neural network (CNN) is exploited to process this 3D energy image. As a proof of concept, the proposed pipeline is applied on predicting $${\hbox {CO}_{2}}$$ <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""> <mml:msub> <mml:mtext>CO</mml:mtext> <mml:mn>2</mml:mn> </mml:msub> </mml:math> uptake in MOFs. The resulting model outperforms a conventional model built with geometric descriptors and requires two orders of magnitude less training data to reach a given level of performance. Moreover, the transferability of the approach to different host-guest systems is demonstrated, examining $${\hbox {CH}_4}$$ <mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""> <mml:msub> <mml:mtext>CH</mml:mtext> <mml:mn>4</mml:mn> </mml:msub> </mml:math> uptake in COFs. The generic character of the proposed methodology, inherited from the PES, renders it applicable to fields other than reticular chemistry.","<method>machine learning approaches</method>, <method>3D convolutional neural network (CNN)</method>",<method>3D convolutional neural network (CNN)</method>
2024,https://openalex.org/W4391013663,Social Sciences,Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model,"Recently the state space models (SSMs) with efficient hardware-aware designs, i.e., the Mamba deep learning model, have shown great potential for long sequence modeling. Meanwhile building efficient and generic vision backbones purely upon SSMs is an appealing direction. However, representing visual data is challenging for SSMs due to the position-sensitivity of visual data and the requirement of global context for visual understanding. In this paper, we show that the reliance on self-attention for visual representation learning is not necessary and propose a new generic vision backbone with bidirectional Mamba blocks (Vim), which marks the image sequences with position embeddings and compresses the visual representation with bidirectional state space models. On ImageNet classification, COCO object detection, and ADE20k semantic segmentation tasks, Vim achieves higher performance compared to well-established vision transformers like DeiT, while also demonstrating significantly improved computation & memory efficiency. For example, Vim is 2.8$\times$ faster than DeiT and saves 86.8% GPU memory when performing batch inference to extract features on images with a resolution of 1248$\times$1248. The results demonstrate that Vim is capable of overcoming the computation & memory constraints on performing Transformer-style understanding for high-resolution images and it has great potential to be the next-generation backbone for vision foundation models. Code is available at https://github.com/hustvl/Vim.","<method>state space models (SSMs)</method>, <method>Mamba deep learning model</method>, <method>bidirectional state space models</method>, <method>vision transformers</method>, <method>DeiT</method>",<method>state space models (SSMs)</method><method>vision transformers</method><method>DeiT</method>
2024,https://openalex.org/W4390608362,Social Sciences,"Transformative Potential of AI in Healthcare: Definitions, Applications, and Navigating the Ethical Landscape and Public Perspectives","Artificial intelligence (AI) has emerged as a crucial tool in healthcare with the primary aim of improving patient outcomes and optimizing healthcare delivery. By harnessing machine learning algorithms, natural language processing, and computer vision, AI enables the analysis of complex medical data. The integration of AI into healthcare systems aims to support clinicians, personalize patient care, and enhance population health, all while addressing the challenges posed by rising costs and limited resources. As a subdivision of computer science, AI focuses on the development of advanced algorithms capable of performing complex tasks that were once reliant on human intelligence. The ultimate goal is to achieve human-level performance with improved efficiency and accuracy in problem-solving and task execution, thereby reducing the need for human intervention. Various industries, including engineering, media/entertainment, finance, and education, have already reaped significant benefits by incorporating AI systems into their operations. Notably, the healthcare sector has witnessed rapid growth in the utilization of AI technology. Nevertheless, there remains untapped potential for AI to truly revolutionize the industry. It is important to note that despite concerns about job displacement, AI in healthcare should not be viewed as a threat to human workers. Instead, AI systems are designed to augment and support healthcare professionals, freeing up their time to focus on more complex and critical tasks. By automating routine and repetitive tasks, AI can alleviate the burden on healthcare professionals, allowing them to dedicate more attention to patient care and meaningful interactions. However, legal and ethical challenges must be addressed when embracing AI technology in medicine, alongside comprehensive public education to ensure widespread acceptance.","<method>machine learning algorithms</method>, <method>natural language processing</method>, <method>computer vision</method>",No methods remaining
2024,https://openalex.org/W4392851477,Social Sciences,"Generative AI in healthcare: an implementation science informed translational path on application, integration and governance","Abstract Background Artificial intelligence (AI), particularly generative AI, has emerged as a transformative tool in healthcare, with the potential to revolutionize clinical decision-making and improve health outcomes. Generative AI, capable of generating new data such as text and images, holds promise in enhancing patient care, revolutionizing disease diagnosis and expanding treatment options. However, the utility and impact of generative AI in healthcare remain poorly understood, with concerns around ethical and medico-legal implications, integration into healthcare service delivery and workforce utilisation. Also, there is not a clear pathway to implement and integrate generative AI in healthcare delivery. Methods This article aims to provide a comprehensive overview of the use of generative AI in healthcare, focusing on the utility of the technology in healthcare and its translational application highlighting the need for careful planning, execution and management of expectations in adopting generative AI in clinical medicine. Key considerations include factors such as data privacy, security and the irreplaceable role of clinicians’ expertise. Frameworks like the technology acceptance model (TAM) and the Non-Adoption, Abandonment, Scale-up, Spread and Sustainability (NASSS) model are considered to promote responsible integration. These frameworks allow anticipating and proactively addressing barriers to adoption, facilitating stakeholder participation and responsibly transitioning care systems to harness generative AI’s potential. Results Generative AI has the potential to transform healthcare through automated systems, enhanced clinical decision-making and democratization of expertise with diagnostic support tools providing timely, personalized suggestions. Generative AI applications across billing, diagnosis, treatment and research can also make healthcare delivery more efficient, equitable and effective. However, integration of generative AI necessitates meticulous change management and risk mitigation strategies. Technological capabilities alone cannot shift complex care ecosystems overnight; rather, structured adoption programs grounded in implementation science are imperative. Conclusions It is strongly argued in this article that generative AI can usher in tremendous healthcare progress, if introduced responsibly. Strategic adoption based on implementation science, incremental deployment and balanced messaging around opportunities versus limitations helps promote safe, ethical generative AI integration. Extensive real-world piloting and iteration aligned to clinical priorities should drive development. With conscientious governance centred on human wellbeing over technological novelty, generative AI can enhance accessibility, affordability and quality of care. As these models continue advancing rapidly, ongoing reassessment and transparent communication around their strengths and weaknesses remain vital to restoring trust, realizing positive potential and, most importantly, improving patient outcomes.","<method>generative AI</method>, <method>technology acceptance model (TAM)</method>, <method>Non-Adoption, Abandonment, Scale-up, Spread and Sustainability (NASSS) model</method>, <method>implementation science</method>",No methods remaining
2024,https://openalex.org/W4392599656,Social Sciences,Generative AI in Medical Practice: In-Depth Exploration of Privacy and Security Challenges,"As advances in artificial intelligence (AI) continue to transform and revolutionize the field of medicine, understanding the potential uses of generative AI in health care becomes increasingly important. Generative AI, including models such as generative adversarial networks and large language models, shows promise in transforming medical diagnostics, research, treatment planning, and patient care. However, these data-intensive systems pose new threats to protected health information. This Viewpoint paper aims to explore various categories of generative AI in health care, including medical diagnostics, drug discovery, virtual health assistants, medical research, and clinical decision support, while identifying security and privacy threats within each phase of the life cycle of such systems (ie, data collection, model development, and implementation phases). The objectives of this study were to analyze the current state of generative AI in health care, identify opportunities and privacy and security challenges posed by integrating these technologies into existing health care infrastructure, and propose strategies for mitigating security and privacy risks. This study highlights the importance of addressing the security and privacy threats associated with generative AI in health care to ensure the safe and effective use of these systems. The findings of this study can inform the development of future generative AI systems in health care and help health care organizations better understand the potential benefits and risks associated with these systems. By examining the use cases and benefits of generative AI across diverse domains within health care, this paper contributes to theoretical discussions surrounding AI ethics, security vulnerabilities, and data privacy regulations. In addition, this study provides practical insights for stakeholders looking to adopt generative AI solutions within their organizations.","<method>generative adversarial networks</method>, <method>large language models</method>",<method>generative adversarial networks</method>
2024,https://openalex.org/W4390587679,Social Sciences,"A Systematic Review and Meta-Analysis of Artificial Intelligence Tools in Medicine and Healthcare: Applications, Considerations, Limitations, Motivation and Challenges","Artificial intelligence (AI) has emerged as a transformative force in various sectors, including medicine and healthcare. Large language models like ChatGPT showcase AI’s potential by generating human-like text through prompts. ChatGPT’s adaptability holds promise for reshaping medical practices, improving patient care, and enhancing interactions among healthcare professionals, patients, and data. In pandemic management, ChatGPT rapidly disseminates vital information. It serves as a virtual assistant in surgical consultations, aids dental practices, simplifies medical education, and aids in disease diagnosis. A total of 82 papers were categorised into eight major areas, which are G1: treatment and medicine, G2: buildings and equipment, G3: parts of the human body and areas of the disease, G4: patients, G5: citizens, G6: cellular imaging, radiology, pulse and medical images, G7: doctors and nurses, and G8: tools, devices and administration. Balancing AI’s role with human judgment remains a challenge. A systematic literature review using the PRISMA approach explored AI’s transformative potential in healthcare, highlighting ChatGPT’s versatile applications, limitations, motivation, and challenges. In conclusion, ChatGPT’s diverse medical applications demonstrate its potential for innovation, serving as a valuable resource for students, academics, and researchers in healthcare. Additionally, this study serves as a guide, assisting students, academics, and researchers in the field of medicine and healthcare alike.","<method>Large language models</method>, <method>ChatGPT</method>, <method>systematic literature review using the PRISMA approach</method>",No methods remaining
2024,https://openalex.org/W4392193191,Social Sciences,Challenges and barriers of using large language models (LLM) such as ChatGPT for diagnostic medicine with a focus on digital pathology – a recent scoping review,"Abstract Background The integration of large language models (LLMs) like ChatGPT in diagnostic medicine, with a focus on digital pathology, has garnered significant attention. However, understanding the challenges and barriers associated with the use of LLMs in this context is crucial for their successful implementation. Methods A scoping review was conducted to explore the challenges and barriers of using LLMs, in diagnostic medicine with a focus on digital pathology. A comprehensive search was conducted using electronic databases, including PubMed and Google Scholar, for relevant articles published within the past four years. The selected articles were critically analyzed to identify and summarize the challenges and barriers reported in the literature. Results The scoping review identified several challenges and barriers associated with the use of LLMs in diagnostic medicine. These included limitations in contextual understanding and interpretability, biases in training data, ethical considerations, impact on healthcare professionals, and regulatory concerns. Contextual understanding and interpretability challenges arise due to the lack of true understanding of medical concepts and lack of these models being explicitly trained on medical records selected by trained professionals, and the black-box nature of LLMs. Biases in training data pose a risk of perpetuating disparities and inaccuracies in diagnoses. Ethical considerations include patient privacy, data security, and responsible AI use. The integration of LLMs may impact healthcare professionals’ autonomy and decision-making abilities. Regulatory concerns surround the need for guidelines and frameworks to ensure safe and ethical implementation. Conclusion The scoping review highlights the challenges and barriers of using LLMs in diagnostic medicine with a focus on digital pathology. Understanding these challenges is essential for addressing the limitations and developing strategies to overcome barriers. It is critical for health professionals to be involved in the selection of data and fine tuning of the models. Further research, validation, and collaboration between AI developers, healthcare professionals, and regulatory bodies are necessary to ensure the responsible and effective integration of LLMs in diagnostic medicine.",<method>large language models (LLMs)</method>,No methods remaining
2024,https://openalex.org/W4392014897,Social Sciences,Comprehensive systematic review of information fusion methods in smart cities and urban environments,"Smart cities result from integrating advanced technologies and intelligent sensors into modern urban infrastructure. The Internet of Things (IoT) and data integration are pivotal in creating interconnected and intelligent urban spaces. In this literature review, we explore the different methods of information fusion used in smart cities, along with their advantages and challenges. However, there are notable challenges in managing diverse data sources, handling large data volumes, and meeting the near-real-time demands of various smart city applications. The review aims to examine smart city applications in detail, incorporating quality evaluation and information fusion techniques and identifying critical issues while outlining promising research directions. In order to accomplish our goal, we conducted a comprehensive search of literature and applied selective criteria. We identified 59 recent studies addressing machine learning (ML) and deep learning (DL) techniques in smart city applications. These studies were obtained from various databases such as ScienceDirect (SD), Scopus, Web of Science (WoS), and IEEE Xplore. The main objective of this study is to provide more detailed insights into smart cities by supplementing existing research. The word cloud visualisation of machine learning/deep learning and information fusion in smart cities papers shows a diverse landscape, covering both technical aspects of artificial intelligence and practical applications in urban settings. Apart from technical exploration, the study also delves into the ethical and privacy implications arising in smart cities. Moreover, it thoroughly examines the challenges that must be addressed to realise this urban revolution's potential fully.","<method>machine learning (ML)</method>, <method>deep learning (DL)</method>",<method>machine learning (ML)</method><method>deep learning (DL)</method>
2024,https://openalex.org/W4391243055,Social Sciences,Systematic literature review: Quantum machine learning and its applications,"Quantum physics has changed the way we understand our environment, and one of its branches, quantum mechanics, has demonstrated accurate and consistent theoretical results. Quantum computing is the process of performing calculations using quantum mechanics. This field studies the quantum behavior of certain subatomic particles (photons, electrons, etc.) for subsequent use in performing calculations, as well as for large-scale information processing. These advantages are achieved through the use of quantum features, such as entanglement or superposition. These capabilities can give quantum computers an advantage in terms of computational time and cost over classical computers. Nowadays, scientific challenges are impossible to perform by classical computation due to computational complexity (more bytes than atoms in the observable universe) or the time it would take (thousands of years), and quantum computation is the only known answer. However, current quantum devices do not have yet the necessary qubits and are not fault-tolerant enough to achieve these goals. Nonetheless, there are other fields like machine learning, finance, or chemistry where quantum computation could be useful with current quantum devices. This manuscript aims to present a review of the literature published between 2017 and 2023 to identify, analyze, and classify the different types of algorithms used in quantum machine learning and their applications. The methodology follows the guidelines related to Systematic Literature Review methods, such as the one proposed by Kitchenham and other authors in the software engineering field. Consequently, this study identified 94 articles that used quantum machine learning techniques and algorithms and shows their implementation using computational quantum circuits or ansatzs. The main types of found algorithms are quantum implementations of classical machine learning algorithms, such as support vector machines or the k-nearest neighbor model, and classical deep learning algorithms, like quantum neural networks. One of the most relevant applications in the machine learning field is image classification. Many articles, especially within the classification, try to solve problems currently answered by classical machine learning but using quantum devices and algorithms. Even though results are promising, quantum machine learning is far from achieving its full potential. An improvement in quantum hardware is required for this potential to be achieved since the existing quantum computers lack enough quality, speed, and scale to allow quantum computing to achieve its full potential.","<method>support vector machines</method>, <method>k-nearest neighbor model</method>, <method>quantum neural networks</method>",<method>support vector machines</method><method>k-nearest neighbor model</method><method>quantum neural networks</method>
2024,https://openalex.org/W4391974599,Social Sciences,"Generative AI for Transformative Healthcare: A Comprehensive Study of Emerging Models, Applications, Case Studies, and Limitations","Generative artificial intelligence (GAI) can be broadly described as an artificial intelligence system capable of generating images, text, and other media types with human prompts. GAI models like ChatGPT, DALL-E, and Bard have recently caught the attention of industry and academia equally. GAI applications span various industries like art, gaming, fashion, and healthcare. In healthcare, GAI shows promise in medical research, diagnosis, treatment, and patient care and is already making strides in real-world deployments. There has yet to be any detailed study concerning the applications and scope of GAI in healthcare. Addressing this research gap, we explore several applications, real-world scenarios, and limitations of GAI in healthcare. We examine how GAI models like ChatGPT and DALL-E can be leveraged to aid in the applications of medical imaging, drug discovery, personalized patient treatment, medical simulation and training, clinical trial optimization, mental health support, healthcare operations and research, medical chatbots, human movement simulation, and a few more applications. Along with applications, we cover four real-world healthcare scenarios that employ GAI: visual snow syndrome diagnosis, molecular drug optimization, medical education, and dentistry. We also provide an elaborate discussion on seven healthcare-customized LLMs like Med-PaLM, BioGPT, DeepHealth, etc.,Since GAI is still evolving, it poses challenges like the lack of professional expertise in decision making, risk of patient data privacy, issues in integrating with existing healthcare systems, and the problem of data bias which are elaborated on in this work along with several other challenges. We also put forward multiple directions for future research in GAI for healthcare.","<method>Generative artificial intelligence (GAI)</method>, <method>GAI models like ChatGPT</method>, <method>GAI models like DALL-E</method>, <method>healthcare-customized LLMs like Med-PaLM</method>, <method>healthcare-customized LLMs like BioGPT</method>, <method>healthcare-customized LLMs like DeepHealth</method>",<method>healthcare-customized LLMs like Med-PaLM</method><method>healthcare-customized LLMs like BioGPT</method>
2024,https://openalex.org/W4391572037,Social Sciences,Machine Learning Applications in Healthcare: Current Trends and Future Prospects,"The integration of machine learning (ML) in healthcare has witnessed remarkable advancements, transforming the landscape of medical diagnosis, treatment, and overall patient care. This article provides a comprehensive review of the current trends and future prospects of machine learning applications in the healthcare domain.The current landscape is characterized by the utilization of ML algorithms for disease diagnosis and risk prediction, personalized treatment plans, and efficient healthcare resource management. Notable applications include image recognition for radiology and pathology, predictive analytics for disease prognosis, and the development of precision medicine tailored to individual patient profiles.This review explores the evolving role of ML in improving patient outcomes, enhancing clinical decision-making, and optimizing healthcare workflows. It delves into the challenges faced in integrating ML into existing healthcare systems, such as data privacy concerns, interpretability of complex models, and the need for robust validation processes.Additionally, the article discusses future prospects and emerging trends in ML healthcare applications, including the potential for predictive analytics to preemptively identify health issues, the integration of wearable devices and remote monitoring for continuous patient care, and the intersection of ML with genomics for personalized medicine.The overarching goal of this article is to provide healthcare professionals, researchers, and policymakers with insights into the current state of ML applications in healthcare, along with an outlook on the transformative potential that machine learning holds for the future of healthcare delivery and patient outcomes.","<method>machine learning (ML) algorithms</method>, <method>image recognition</method>, <method>predictive analytics</method>",No methods remaining
2024,https://openalex.org/W4392239564,Social Sciences,Human-AI collaboration patterns in AI-assisted academic writing,"Artificial Intelligence (AI) has increasingly influenced higher education, notably in academic writing where AI-powered assisting tools offer both opportunities and challenges. Recently, the rapid growth of generative AI (GAI) has brought its impacts into sharper focus, yet the dynamics of its utilisation in academic writing remain largely unexplored. This paper focuses on examining the nature of human-AI interactions in academic writing, specifically investigating the strategies doctoral students employ when collaborating with a GAI-powered assisting tool. This study involves 626 recorded activities on how ten doctoral students interact with GAI-powered assisting tool during academic writing. AI-driven learning analytics approach was adopted for three layered analyses: (1) data pre-processing and analysis with quantitative content analysis, (2) sequence analysis with Hidden Markov Model (HMM) and hierarchical sequence clustering, and (3) pattern analysis with process mining. Findings indicate that doctoral students engaging in iterative, highly interactive processes with the GAI-powered assisting tool generally achieve better performance in the writing task. In contrast, those who use GAI merely as a supplementary information source, maintaining a linear writing approach, tend to get lower writing performance. This study points to the need for further investigations into human-AI collaboration in learning in higher education, with implications for tailored educational strategies and solutions.","<method>AI-driven learning analytics</method>, <method>quantitative content analysis</method>, <method>Hidden Markov Model (HMM)</method>, <method>hierarchical sequence clustering</method>, <method>process mining</method>",<method>Hidden Markov Model (HMM)</method>
2024,https://openalex.org/W4391071215,Social Sciences,Automatic assessment of text-based responses in post-secondary education: A systematic review,"Text-based open-ended questions in academic formative and summative assessments help students become deep learners and prepare them to understand concepts for a subsequent conceptual assessment. However, grading text-based questions, especially in large (>50 enrolled students) courses, is tedious and time-consuming for instructors. Text processing models continue progressing with the rapid development of Artificial Intelligence (AI) tools and Natural Language Processing (NLP) algorithms. Especially after breakthroughs in Large Language Models (LLM), there is immense potential to automate rapid assessment and feedback of text-based responses in education. This systematic review adopts a scientific and reproducible literature search strategy based on the PRISMA process using explicit inclusion and exclusion criteria to study text-based automatic assessment systems in post-secondary education, screening 838 papers and synthesizing 93 studies. To understand how text-based automatic assessment systems have been developed and applied in education in recent years, three research questions are considered: 1) What types of automated assessment systems can be identified using input, output, and processing framework? 2) What are the educational focus and research motivations of studies with automated assessment systems? 3) What are the reported research outcomes in automated assessment systems and the next steps for educational applications? All included studies are summarized and categorized according to a proposed comprehensive framework, including the input and output of the system, research motivation, and research outcomes, aiming to answer the research questions accordingly. Additionally, the typical studies of automated assessment systems, research methods, and application domains in these studies are investigated and summarized. This systematic review provides an overview of recent educational applications of text-based assessment systems for understanding the latest AI/NLP developments assisting in text-based assessments in higher education. Findings will particularly benefit researchers and educators incorporating LLMs such as ChatGPT into their educational activities.","<method>Natural Language Processing (NLP) algorithms</method>, <method>Large Language Models (LLM)</method>",No methods remaining
2024,https://openalex.org/W4393072609,Social Sciences,"A comprehensive survey of research towards AI-enabled unmanned aerial systems in pre-, active-, and post-wildfire management","Wildfires have emerged as one of the most destructive natural disasters worldwide, causing catastrophic losses. These losses have underscored the urgent need to improve public knowledge and advance existing techniques in wildfire management. Recently, the use of Artificial Intelligence (AI) in wildfires, propelled by the integration of Unmanned Aerial Vehicles (UAVs) and deep learning models, has created an unprecedented momentum to implement and develop more effective wildfire management. Although existing survey papers have explored learning-based approaches in wildfire, drone use in disaster management, and wildfire risk assessment, a comprehensive review emphasizing the application of AI-enabled UAV systems and investigating the role of learning-based methods throughout the overall workflow of multi-stage wildfire management, including pre-fire (e.g., vision-based vegetation fuel measurement), active-fire (e.g., fire growth modeling), and post-fire tasks (e.g., evacuation planning) is notably lacking. This survey synthesizes and integrates state-of-the-science reviews and research at the nexus of wildfire observations and modeling, AI, and UAVs - topics at the forefront of advances in wildfire management, elucidating the role of AI in performing monitoring and actuation tasks from pre-fire, through the active-fire stage, to post-fire management. To this aim, we provide an extensive analysis of the existing remote sensing systems with a particular focus on the UAV advancements, device specifications, and sensor technologies relevant to wildfire management. We also examine the pre-fire and post-fire management approaches, including fuel monitoring, prevention strategies, as well as evacuation planning, damage assessment, and operation strategies. Additionally, we review and summarize a wide range of computer vision techniques in active-fire management, with an emphasis on Machine Learning (ML), Reinforcement Learning (RL), and Deep Learning (DL) algorithms for wildfire classification, segmentation, detection, and monitoring tasks. Ultimately, we underscore the substantial advancement in wildfire modeling through the integration of cutting-edge AI techniques and UAV-based data, providing novel insights and enhanced predictive capabilities to understand dynamic wildfire behavior.","<method>Machine Learning (ML)</method>, <method>Reinforcement Learning (RL)</method>, <method>Deep Learning (DL)</method>",<method>Machine Learning (ML)</method><method>Reinforcement Learning (RL)</method><method>Deep Learning (DL)</method>
2024,https://openalex.org/W4394009485,Social Sciences,AI-Driven Clinical Decision Support Systems: An Ongoing Pursuit of Potential,"Clinical Decision Support Systems (CDSS) are essential tools in contemporary healthcare, enhancing clinicians' decisions and patient outcomes. The integration of artificial intelligence (AI) is now revolutionizing CDSS even further. This review delves into AI technologies transforming CDSS, their applications in healthcare decision-making, associated challenges, and the potential trajectory toward fully realizing AI-CDSS's potential. The review begins by laying the groundwork with a definition of CDSS and its function within the healthcare field. It then highlights the increasingly significant role that AI is playing in enhancing CDSS effectiveness and efficiency, underlining its evolving prominence in shaping healthcare practices. It examines the integration of AI technologies into CDSS, including machine learning algorithms like neural networks and decision trees, natural language processing, and deep learning. It also addresses the challenges associated with AI integration, such as interpretability and bias. We then shift to AI applications within CDSS, with real-life examples of AI-driven diagnostics, personalized treatment recommendations, risk prediction, early intervention, and AI-assisted clinical documentation. The review emphasizes user-centered design in AI-CDSS integration, addressing usability, trust, workflow, and ethical and legal considerations. It acknowledges prevailing obstacles and suggests strategies for successful AI-CDSS adoption, highlighting the need for workflow alignment and interdisciplinary collaboration. The review concludes by summarizing key findings, underscoring AI's transformative potential in CDSS, and advocating for continued research and innovation. It emphasizes the need for collaborative efforts to realize a future where AI-powered CDSS optimizes healthcare delivery and improves patient outcomes.","<method>neural networks</method>, <method>decision trees</method>, <method>natural language processing</method>, <method>deep learning</method>",<method>neural networks</method><method>decision trees</method><method>deep learning</method>
2024,https://openalex.org/W4400145965,Social Sciences,A systematic review of trustworthy artificial intelligence applications in natural disasters,"Artificial intelligence (AI) holds significant promise for advancing natural disaster management through the use of predictive models that analyze extensive datasets, identify patterns, and forecast potential disasters. These models facilitate proactive measures such as early warning systems (EWSs), evacuation planning, and resource allocation, addressing the substantial challenges associated with natural disasters. This study offers a comprehensive exploration of trustworthy AI applications in natural disasters, encompassing disaster management, risk assessment, and disaster prediction. This research is underpinned by an extensive review of reputable sources, including Science Direct (SD), Scopus, IEEE Xplore (IEEE), and Web of Science (WoS). Three queries were formulated to retrieve 981 papers from the earliest documented scientific production until February 2024. After meticulous screening, deduplication, and application of the inclusion and exclusion criteria, 108 studies were included in the quantitative synthesis. This study provides a specific taxonomy of AI applications in natural disasters and explores the motivations, challenges, recommendations, and limitations of recent advancements. It also offers an overview of recent techniques and developments in disaster management using explainable artificial intelligence (XAI), data fusion, data mining, machine learning (ML), deep learning (DL), fuzzy logic, and multicriteria decision-making (MCDM). This systematic contribution addresses seven open issues and provides critical solutions through essential insights, laying the groundwork for various future works in trustworthiness AI-based natural disaster management. Despite the potential benefits, challenges persist in the application of AI to natural disaster management. In these contexts, this study identifies several unused and used areas in natural disaster-based AI theory, collects the disaster datasets, ML, and DL techniques, and offers a valuable XAI approach to unravel the complex relationships and dynamics involved and the utilization of data fusion techniques in decision-making processes related to natural disasters. Finally, the study extensively analyzed ethical considerations, bias, and consequences in natural disaster-based AI.","<method>explainable artificial intelligence (XAI)</method>, <method>data fusion</method>, <method>data mining</method>, <method>machine learning (ML)</method>, <method>deep learning (DL)</method>, <method>fuzzy logic</method>, <method>multicriteria decision-making (MCDM)</method>",<method>machine learning (ML)</method><method>deep learning (DL)</method>
2024,https://openalex.org/W4390667862,Social Sciences,Integration of Generative AI Techniques and Applications in Student Behavior and Cognitive Achievement in Arab Higher Education,"The integration of Artificial Intelligence (AI) in higher education has the power to revolutionize the learning experience by fostering engagement, personalization, efficiency, and innovation. AI offers a wide range of exciting possibilities where AI-powered tools enable students to receive tailored feedback and guidance, enabling them to learn at their own pace and excel academically. This research aims to investigate the effects of generative AI techniques and applications on students' cognitive achievement through student behavior. Data was collected through surveys in three Arab countries including Oman, Jordan and Yemen. 768 students from these Arab country's universities were participated in completing surveys randomly. Structure Equation Modeling SEM-PLS was adopted to analysis data. Results reveal that generative AI techniques and applications have positive and significant effects on students' cognitive achievement in Arab higher education institutions. Results also reveal that student behavior enhances the relationship among AI techniques, applications and cognitive achievement. These results highlight the crucial role of AI applications among students in higher education while the integration of this emerging technology is still at the first stage, students' interaction with and utility of these applications show high satisfactory level of their impact on students' behavior and cognitive achievement. This research contributes to literature of generative AI applications giving evidence from Arab region and filling the gap regarding usage of these applications in higher education.","<method>generative AI techniques</method>, <method>Structure Equation Modeling SEM-PLS</method>",<method>generative AI techniques</method>
2024,https://openalex.org/W4398203672,Social Sciences,Hallucination Rates and Reference Accuracy of ChatGPT and Bard for Systematic Reviews: Comparative Analysis,"Background Large language models (LLMs) have raised both interest and concern in the academic community. They offer the potential for automating literature search and synthesis for systematic reviews but raise concerns regarding their reliability, as the tendency to generate unsupported (hallucinated) content persist. Objective The aim of the study is to assess the performance of LLMs such as ChatGPT and Bard (subsequently rebranded Gemini) to produce references in the context of scientific writing. Methods The performance of ChatGPT and Bard in replicating the results of human-conducted systematic reviews was assessed. Using systematic reviews pertaining to shoulder rotator cuff pathology, these LLMs were tested by providing the same inclusion criteria and comparing the results with original systematic review references, serving as gold standards. The study used 3 key performance metrics: recall, precision, and F1-score, alongside the hallucination rate. Papers were considered “hallucinated” if any 2 of the following information were wrong: title, first author, or year of publication. Results In total, 11 systematic reviews across 4 fields yielded 33 prompts to LLMs (3 LLMs×11 reviews), with 471 references analyzed. Precision rates for GPT-3.5, GPT-4, and Bard were 9.4% (13/139), 13.4% (16/119), and 0% (0/104) respectively (P&lt;.001). Recall rates were 11.9% (13/109) for GPT-3.5 and 13.7% (15/109) for GPT-4, with Bard failing to retrieve any relevant papers (P&lt;.001). Hallucination rates stood at 39.6% (55/139) for GPT-3.5, 28.6% (34/119) for GPT-4, and 91.4% (95/104) for Bard (P&lt;.001). Further analysis of nonhallucinated papers retrieved by GPT models revealed significant differences in identifying various criteria, such as randomized studies, participant criteria, and intervention criteria. The study also noted the geographical and open-access biases in the papers retrieved by the LLMs. Conclusions Given their current performance, it is not recommended for LLMs to be deployed as the primary or exclusive tool for conducting systematic reviews. Any references generated by such models warrant thorough validation by researchers. The high occurrence of hallucinations in LLMs highlights the necessity for refining their training and functionality before confidently using them for rigorous academic purposes.","<method>Large language models (LLMs)</method>, <method>ChatGPT</method>, <method>Bard (Gemini)</method>, <method>GPT-3.5</method>, <method>GPT-4</method>",<method>GPT-3.5</method><method>GPT-4</method>
2024,https://openalex.org/W4392627614,Social Sciences,How to conduct a bibliometric content analysis: Guidelines and contributions of content co‐occurrence or co‐word literature reviews,"Abstract Literature reviews summarize existing literature, uncover research gaps, and offer future research directions, thus aiding in theoretical and methodological development. Informetric research including bibliometric, scientometric, webometric, cybermetric, patentometric, and altmetric methods are becoming increasingly prevalent in conducting literature review studies. Looking at the common informetric literature review methods—citation, co‐citation, co‐author, bibliographic coupling, and content co‐occurrence analyses, this study aims to serve as a guide in using content co‐occurrence also known as co‐word analysis to conduct literature reviews. This study outlines a variety of informetric research methods and how they are utilized to conduct review and evidence‐based conceptual studies. In addition to the analyses, the study highlights different informetric software packages like Bibliometrix, Biblioshiny, Leximancer, NVivo, and CiteSpace including their comparison. The study further discusses contributions of algorithm‐based content analyses including offering taxonomies, definitions, classifications, typologies, comparisons, and theoretical development to constitute integrative literature reviews. Finally, this study offers step‐by‐step guidelines for conducting a review study using VOSviewer content co‐occurrence analysis while providing a systems view of informetric research in social science. The study also notes the emergence of generative artificial intelligence (AI) like Open AI's ChatGPT, Google's Bard, Elicit, Scite, Research Rabbit, and ChatPDF among others, and its potential in contributing to the literature review methods and, as such, being an interesting direction for future research.","<method>content co‐occurrence analysis (co‐word analysis)</method>, <method>algorithm‐based content analyses</method>, <method>generative artificial intelligence (AI)</method>",No methods remaining
2024,https://openalex.org/W4390584313,Social Sciences,A Conceptual Model for Inclusive Technology: Advancing Disability Inclusion through Artificial Intelligence,"Artificial intelligence (AI) has ushered in transformative changes, championing inclusion and accessibility for individuals with disabilities. This article delves into the remarkable AI-driven solutions that have revolutionized their lives across various domains. From assistive technologies such as voice recognition and AI-powered smart glasses catering to diverse needs, to healthcare benefiting from early disease detection algorithms and wearable devices that monitor vital signs and alert caregivers in emergencies, AI has steered in significant enhancements. Moreover, AI-driven prosthetics and exoskeletons have substantially improved mobility for those with limb impairments. The realm of education has not been left untouched, with AI tools creating inclusive learning environments that adapt to individual learning styles, paving the way for academic success among students with disabilities. However, the boundless potential of AI also presents ethical concerns and challenges. Issues like safeguarding data privacy, mitigating algorithmic bias, and bridging the digital divide must be thoughtfully addressed to fully harness AI’s potential in empowering individuals with disabilities. To complement these achievements, a robust conceptual model for AI disability inclusion serves as the theoretical framework, guiding the development of tailored AI solutions. By striking a harmonious balance between innovation and ethics, AI has the power to significantly enhance the overall quality of life for individuals with disabilities across a spectrum of vital areas.","<method>voice recognition</method>, <method>early disease detection algorithms</method>",No methods remaining
2024,https://openalex.org/W4391528827,Social Sciences,Deep learning-aided decision support for diagnosis of skin disease across skin tones,"Abstract Although advances in deep learning systems for image-based medical diagnosis demonstrate their potential to augment clinical decision-making, the effectiveness of physician–machine partnerships remains an open question, in part because physicians and algorithms are both susceptible to systematic errors, especially for diagnosis of underrepresented populations. Here we present results from a large-scale digital experiment involving board-certified dermatologists ( n = 389) and primary-care physicians ( n = 459) from 39 countries to evaluate the accuracy of diagnoses submitted by physicians in a store-and-forward teledermatology simulation. In this experiment, physicians were presented with 364 images spanning 46 skin diseases and asked to submit up to four differential diagnoses. Specialists and generalists achieved diagnostic accuracies of 38% and 19%, respectively, but both specialists and generalists were four percentage points less accurate for the diagnosis of images of dark skin as compared to light skin. Fair deep learning system decision support improved the diagnostic accuracy of both specialists and generalists by more than 33%, but exacerbated the gap in the diagnostic accuracy of generalists across skin tones. These results demonstrate that well-designed physician–machine partnerships can enhance the diagnostic accuracy of physicians, illustrating that success in improving overall diagnostic accuracy does not necessarily address bias.",<method>deep learning system decision support</method>,No methods remaining
2024,https://openalex.org/W4394681533,Social Sciences,REVIEWING THE IMPACT OF HEALTH INFORMATION TECHNOLOGY ON HEALTHCARE MANAGEMENT EFFICIENCY,"This research paper explores the intricate relationship between Health Information Technology (HIT) and healthcare management efficiency, investigating current trends, emerging technologies, and their potential implications. The study encompasses a thorough literature review, highlighting the impact of HIT on operational and clinical aspects of healthcare delivery. Key findings reveal the transformative role of technology in streamlining administrative processes, improving communication, and enhancing overall patient care. Ethical considerations, patient privacy, and regulation compliance are crucial factors in successfully implementing HIT. Looking towards the future, the paper anticipates the integration of emerging technologies such as Artificial Intelligence, Blockchain, and the Internet of Things, signalling a paradigm shift in healthcare management. While acknowledging the potential benefits, the research also underscores the importance of ethical frameworks, transparency, and user-centred design in adopting these technologies. The study concludes with reflections on the limitations of the research, suggesting avenues for future exploration. Recommendations emphasize the need for ongoing research, longitudinal studies, and a global perspective to ensure healthcare organizations effectively leverage technology while maintaining ethical standards. The findings of this research carry implications for healthcare practitioners, policymakers, and technology innovators, encouraging a strategic and ethical approach to the ever-evolving landscape of health information technology.&#x0D; Keywords: Health Information Technology, Healthcare Management Efficiency, Emerging Technologies, Ethical Considerations, Patient Privacy.",<method>Artificial Intelligence</method>,No methods remaining
2024,https://openalex.org/W4392764062,Social Sciences,"When artificial intelligence substitutes humans in higher education: the cost of loneliness, student success, and retention","Artificial intelligence (AI) may be the new-new-norm in a post-pandemic learning environment. There is a growing number of university students using AI like ChatGPT and Bard to support their academic experience. Much of the AI in higher education research to date has focused on academic integrity and matters of authorship; yet, there may be unintended consequences beyond these concerns for students. That is, there may be people who reduce their formal social interactions while using these tools. This study evaluates 387 university students and their relationship to – and with – artificial intelligence large-language model-based tools. Using structural equation modelling, the study finds evidence that while AI chatbots designed for information provision may be associated with student performance, when social support, psychological wellbeing, loneliness, and sense of belonging are considered it has a net negative effect on achievement. This study tests an AI-specific form of social support, and the cost it may pose to student success, wellbeing, and retention. Indeed, while AI chatbot usage may be associated with poorer social outcomes, human-substitution activity that may be occurring when a student chooses to seek support from an AI rather than a human (e.g. a librarian, professor, or student advisor) may pose interesting learning and teaching policy implications. We explore the implications of this from the lens of student success and belonging.",<method>structural equation modelling</method>,No methods remaining
2024,https://openalex.org/W4398183308,Social Sciences,The applications of nature‐inspired algorithms in Internet of Things‐based healthcare service: A systematic literature review,"Abstract Nature‐inspired algorithms revolve around the intersection of nature‐inspired algorithms and the IoT within the healthcare domain. This domain addresses the emerging trends and potential synergies between nature‐inspired computational approaches and IoT technologies for advancing healthcare services. Our research aims to fill gaps in addressing algorithmic integration challenges, real‐world implementation issues, and the efficacy of nature‐inspired algorithms in IoT‐based healthcare. We provide insights into the practical aspects and limitations of such applications through a systematic literature review. Specifically, we address the need for a comprehensive understanding of the applications of nature‐inspired algorithms in IoT‐based healthcare, identifying gaps such as the lack of standardized evaluation metrics and studies on integration challenges and security considerations. By bridging these gaps, our paper offers insights and directions for future research in this domain, exploring the diverse landscape of nature‐inspired algorithms in healthcare. Our chosen methodology is a Systematic Literature Review (SLR) to investigate related papers rigorously. Categorizing these algorithms into groups such as genetic algorithms, particle swarm optimization, cuckoo algorithms, ant colony optimization, other approaches, and hybrid methods, we employ meticulous classification based on critical criteria. MATLAB emerges as the predominant programming language, constituting 37.9% of cases, showcasing a prevalent choice among researchers. Our evaluation emphasizes adaptability as the paramount parameter, accounting for 18.4% of considerations. By shedding light on attributes, limitations, and potential directions for future research and development, this review aims to contribute to a comprehensive understanding of nature‐inspired algorithms in the dynamic landscape of IoT‐based healthcare services.","<method>genetic algorithms</method>, <method>particle swarm optimization</method>, <method>cuckoo algorithms</method>, <method>ant colony optimization</method>, <method>hybrid methods</method>",<method>genetic algorithms</method><method>cuckoo algorithms</method><method>hybrid methods</method>
2024,https://openalex.org/W4390637043,Social Sciences,Blockchain meets machine learning: a survey,"Abstract Blockchain and machine learning are two rapidly growing technologies that are increasingly being used in various industries. Blockchain technology provides a secure and transparent method for recording transactions, while machine learning enables data-driven decision-making by analyzing large amounts of data. In recent years, researchers and practitioners have been exploring the potential benefits of combining these two technologies. In this study, we cover the fundamentals of blockchain and machine learning and then discuss their integrated use in finance, medicine, supply chain, and security, including a literature review and their contribution to the field such as increased security, privacy, and decentralization. Blockchain technology enables secure and transparent decentralized record-keeping, while machine learning algorithms can analyze vast amounts of data to derive valuable insights. Together, they have the potential to revolutionize industries by enhancing efficiency through automated and trustworthy processes, enabling data-driven decision-making, and strengthening security measures by reducing vulnerabilities and ensuring the integrity of information. However, there are still some important challenges to be handled prior to the common use of blockchain and machine learning such as security issues, strategic planning, information processing, and scalable workflows. Nevertheless, until the difficulties that have been identified are resolved, their full potential will not be achieved.",<method>machine learning algorithms</method>,No methods remaining
2024,https://openalex.org/W4393119757,Social Sciences,Unmasking bias in artificial intelligence: a systematic review of bias detection and mitigation strategies in electronic health record-based models,"Abstract Objectives Leveraging artificial intelligence (AI) in conjunction with electronic health records (EHRs) holds transformative potential to improve healthcare. However, addressing bias in AI, which risks worsening healthcare disparities, cannot be overlooked. This study reviews methods to handle various biases in AI models developed using EHR data. Materials and Methods We conducted a systematic review following the Preferred Reporting Items for Systematic Reviews and Meta-analyses guidelines, analyzing articles from PubMed, Web of Science, and IEEE published between January 01, 2010 and December 17, 2023. The review identified key biases, outlined strategies for detecting and mitigating bias throughout the AI model development, and analyzed metrics for bias assessment. Results Of the 450 articles retrieved, 20 met our criteria, revealing 6 major bias types: algorithmic, confounding, implicit, measurement, selection, and temporal. The AI models were primarily developed for predictive tasks, yet none have been deployed in real-world healthcare settings. Five studies concentrated on the detection of implicit and algorithmic biases employing fairness metrics like statistical parity, equal opportunity, and predictive equity. Fifteen studies proposed strategies for mitigating biases, especially targeting implicit and selection biases. These strategies, evaluated through both performance and fairness metrics, predominantly involved data collection and preprocessing techniques like resampling and reweighting. Discussion This review highlights evolving strategies to mitigate bias in EHR-based AI models, emphasizing the urgent need for both standardized and detailed reporting of the methodologies and systematic real-world testing and evaluation. Such measures are essential for gauging models’ practical impact and fostering ethical AI that ensures fairness and equity in healthcare.","<method>resampling</method>, <method>reweighting</method>",<method>resampling</method><method>reweighting</method>
2024,https://openalex.org/W4401667275,Social Sciences,Artificial intelligence for literature reviews: opportunities and challenges,"Abstract This paper presents a comprehensive review of the use of Artificial Intelligence (AI) in Systematic Literature Reviews (SLRs). A SLR is a rigorous and organised methodology that assesses and integrates prior research on a given topic. Numerous tools have been developed to assist and partially automate the SLR process. The increasing role of AI in this field shows great potential in providing more effective support for researchers, moving towards the semi-automatic creation of literature reviews. Our study focuses on how AI techniques are applied in the semi-automation of SLRs, specifically in the screening and extraction phases. We examine 21 leading SLR tools using a framework that combines 23 traditional features with 11 AI features. We also analyse 11 recent tools that leverage large language models for searching the literature and assisting academic writing. Finally, the paper discusses current trends in the field, outlines key research challenges, and suggests directions for future research. We highlight three primary research challenges: integrating advanced AI solutions, such as large language models and knowledge graphs, improving usability, and developing a standardised evaluation framework. We also propose best practices to ensure more robust evaluations in terms of performance, usability, and transparency. Overall, this review offers a detailed overview of AI-enhanced SLR tools for researchers and practitioners, providing a foundation for the development of next-generation AI solutions in this field.","<method>large language models</method>, <method>knowledge graphs</method>",<method>knowledge graphs</method>
2024,https://openalex.org/W4402827393,Social Sciences,Larger and more instructable language models become less reliable,"Abstract The prevailing methods to make large language models more powerful and amenable have been based on continuous scaling up (that is, increasing their size, data volume and computational resources 1 ) and bespoke shaping up (including post-filtering 2,3 , fine tuning or use of human feedback 4,5 ). However, larger and more instructable large language models may have become less reliable. By studying the relationship between difficulty concordance, task avoidance and prompting stability of several language model families, here we show that easy instances for human participants are also easy for the models, but scaled-up, shaped-up models do not secure areas of low difficulty in which either the model does not err or human supervision can spot the errors. We also find that early models often avoid user questions but scaled-up, shaped-up models tend to give an apparently sensible yet wrong answer much more often, including errors on difficult questions that human supervisors frequently overlook. Moreover, we observe that stability to different natural phrasings of the same question is improved by scaling-up and shaping-up interventions, but pockets of variability persist across difficulty levels. These findings highlight the need for a fundamental shift in the design and development of general-purpose artificial intelligence, particularly in high-stakes areas for which a predictable distribution of errors is paramount.","<method>continuous scaling up</method>, <method>post-filtering</method>, <method>fine tuning</method>, <method>use of human feedback</method>",<method>post-filtering</method><method>fine tuning</method><method>use of human feedback</method>
2024,https://openalex.org/W4392343921,Social Sciences,Data extraction for evidence synthesis using a large language model: A proof‐of‐concept study,"Abstract Data extraction is a crucial, yet labor‐intensive and error‐prone part of evidence synthesis. To date, efforts to harness machine learning for enhancing efficiency of the data extraction process have fallen short of achieving sufficient accuracy and usability. With the release of large language models (LLMs), new possibilities have emerged to increase efficiency and accuracy of data extraction for evidence synthesis. The objective of this proof‐of‐concept study was to assess the performance of an LLM (Claude 2) in extracting data elements from published studies, compared with human data extraction as employed in systematic reviews. Our analysis utilized a convenience sample of 10 English‐language, open‐access publications of randomized controlled trials included in a single systematic review. We selected 16 distinct types of data, posing varying degrees of difficulty (160 data elements across 10 studies). We used the browser version of Claude 2 to upload the portable document format of each publication and then prompted the model for each data element. Across 160 data elements, Claude 2 demonstrated an overall accuracy of 96.3% with a high test–retest reliability (replication 1: 96.9%; replication 2: 95.0% accuracy). Overall, Claude 2 made 6 errors on 160 data items. The most common errors ( n = 4) were missed data items. Importantly, Claude 2's ease of use was high; it required no technical expertise or labeled training data for effective operation (i.e., zero‐shot learning). Based on findings of our proof‐of‐concept study, leveraging LLMs has the potential to substantially enhance the efficiency and accuracy of data extraction for evidence syntheses.","<method>large language models (LLMs)</method>, <method>zero-shot learning</method>",<method>zero-shot learning</method>
2024,https://openalex.org/W4399857583,Social Sciences,Integrating artificial intelligence to assess emotions in learning environments: a systematic literature review,"Introduction Artificial Intelligence (AI) is transforming multiple sectors within our society, including education. In this context, emotions play a fundamental role in the teaching-learning process given that they influence academic performance, motivation, information retention, and student well-being. Thus, the integration of AI in emotional assessment within educational environments offers several advantages that can transform how we understand and address the socio-emotional development of students. However, there remains a lack of comprehensive approach that systematizes advancements, challenges, and opportunities in this field. Aim This systematic literature review aims to explore how artificial intelligence (AI) is used to evaluate emotions within educational settings. We provide a comprehensive overview of the current state of research, focusing on advancements, challenges, and opportunities in the domain of AI-driven emotional assessment within educational settings. Method The review involved a search across the following academic databases: Pubmed, Web of Science, PsycINFO and Scopus. Forty-one articles were selected that meet the established inclusion criteria. These articles were analyzed to extract key insights related to the integration of AI and emotional assessment within educational environments. Results The findings reveal a variety of AI-driven approaches that were developed to capture and analyze students’ emotional states during learning activities. The findings are summarized in four fundamental topics: (1) emotion recognition in education, (2) technology integration and learning outcomes, (3) special education and assistive technology, (4) affective computing. Among the key AI techniques employed are machine learning and facial recognition, which are used to assess emotions. These approaches demonstrate promising potential in enhancing pedagogical strategies and creating adaptive learning environments that cater to individual emotional needs. The review identified emerging factors that, while important, require further investigation to understand their relationships and implications fully. These elements could significantly enhance the use of AI in assessing emotions within educational settings. Specifically, we are referring to: (1) federated learning, (2) convolutional neural network (CNN), (3) recurrent neural network (RNN), (4) facial expression databases, and (5) ethics in the development of intelligent systems. Conclusion This systematic literature review showcases the significance of AI in revolutionizing educational practices through emotion assessment. While advancements are evident, challenges related to accuracy, privacy, and cross-cultural validity were also identified. The synthesis of existing research highlights the need for further research into refining AI models for emotion recognition and emphasizes the importance of ethical considerations in implementing AI technologies within educational contexts.","<method>machine learning</method>, <method>facial recognition</method>, <method>federated learning</method>, <method>convolutional neural network (CNN)</method>, <method>recurrent neural network (RNN)</method>",<method>machine learning</method><method>federated learning</method><method>convolutional neural network (CNN)</method><method>recurrent neural network (RNN)</method>
2024,https://openalex.org/W4391508432,Social Sciences,Artificial intelligence-driven virtual rehabilitation for people living in the community: A scoping review,"Abstract Virtual Rehabilitation (VRehab) is a promising approach to improving the physical and mental functioning of patients living in the community. The use of VRehab technology results in the generation of multi-modal datasets collected through various devices. This presents opportunities for the development of Artificial Intelligence (AI) techniques in VRehab, namely the measurement, detection, and prediction of various patients’ health outcomes. The objective of this scoping review was to explore the applications and effectiveness of incorporating AI into home-based VRehab programs. PubMed/MEDLINE, Embase, IEEE Xplore, Web of Science databases, and Google Scholar were searched from inception until June 2023 for studies that applied AI for the delivery of VRehab programs to the homes of adult patients. After screening 2172 unique titles and abstracts and 51 full-text studies, 13 studies were included in the review. A variety of AI algorithms were applied to analyze data collected from various sensors and make inferences about patients’ health outcomes, most involving evaluating patients’ exercise quality and providing feedback to patients. The AI algorithms used in the studies were mostly fuzzy rule-based methods, template matching, and deep neural networks. Despite the growing body of literature on the use of AI in VRehab, very few studies have examined its use in patients’ homes. Current research suggests that integrating AI with home-based VRehab can lead to improved rehabilitation outcomes for patients. However, further research is required to fully assess the effectiveness of various forms of AI-driven home-based VRehab, taking into account its unique challenges and using standardized metrics.","<method>fuzzy rule-based methods</method>, <method>template matching</method>, <method>deep neural networks</method>",<method>fuzzy rule-based methods</method><method>deep neural networks</method>
2024,https://openalex.org/W4396908686,Social Sciences,Firefighter Skill Advancement through IoT-Enabled Virtual Reality and CNN-Based Training,"To maintain the safety and efficacy of firefighters in various circumstances, modern firefighting necessitates constantly improving skills and training techniques. Utilizing the Internet of Things (IoT), virtual reality (VR), and convolutional neural networks (CNN), this paper details a novel method for training firefighters. The proposed system collects real-time data on ambient variables, equipment state, and firefighter biometrics via integrating IoT sensors into firefighting equipment and training settings. Using this information, it can develop lifelike VR training simulations of difficult and potentially dangerous scenarios. To make the training settings more realistic and malleable, CNN-based algorithms are used to assess the data. The capacity to simulate a wide variety of firefighting situations, customize training difficulty depending on individual and team performance, and provide instant feedback and performance metrics to trainees are all major benefits of this method. The method also allows teachers to check in and evaluate their learners remotely, improving instruction quality. An IoT-enabled VR and CNN-based training technique has shown promising preliminary results in pilot trials, suggesting it might greatly enhance firefighter competence, situational awareness, and decision-making ability. Because of this, it has the potential to completely alter the way firefighters are informed and prepared for the ever-changing dangers users may encounter on the job.",<method>convolutional neural networks (CNN)</method>,<method>convolutional neural networks (CNN)</method>
2024,https://openalex.org/W4391753097,Social Sciences,Machine Vision—Moving from Industry 4.0 to Industry 5.0,"The Fourth Industrial Revolution combined with the advent of artificial intelligence brought significant changes to humans’ daily lives. Extended research in the field has aided in both documenting and presenting these changes, giving a more general picture of this new era. This work reviews the application field of the scientific research literature on the presence of machine vision in the Fourth Industrial Revolution and the changes it brought to each sector to which it contributed, determining the exact extent of its influence. Accordingly, an attempt is made to present an overview of its use in the Fifth Industrial Revolution to identify and present the changes between the two consequent periods. This work uses the PRISMA methodology and follows the form of a Scoping Review using sources from Scopus and Google Scholar. Most publications reveal the emergence of machine vision in almost every field of human life with significant influence and performance results. Undoubtedly, this review highlights the great influence and offer of machine vision in many sectors, establishing its use and searching for more ways to use it. It is also proven that machine vision systems can help industries to gain competitive advantage in terms of better product quality, higher customer satisfaction, and improved productivity.",<method>PRISMA methodology</method>,No methods remaining
2024,https://openalex.org/W4391936064,Social Sciences,Adaptive Segmentation Enhanced Asynchronous Federated Learning for Sustainable Intelligent Transportation Systems,"The proliferation of advanced embedded and communication technologies has facilitated the possibility of modern Intelligent Transportation System (ITS). The hierarchical nature of such large-scale and distributed systems brings obvious challenges in creating a scalable and sustainable computing environment, and hence the development and application of edge intelligence become critical. Federated learning (FL), as an emerging distributed machine learning paradigm, aims to offer secure knowledge sharing and effective learning across multiple devices. However, conventional FL may fall into trouble when facing large-scale and network-agnostic systems with fast moving devices and changing network attributes. In this study, we propose an Adaptive Segmentation enhanced Asynchronous Federated Learning (AS-AFL) model, aiming to improve the learning efficiency and reliability in sustainable ITS via a decentralized fashion. Specifically, a meta-learning based adaptive segmentation scheme is designed to automatically separate the client nodes (e.g., vehicles) into multiple edge groups according to their homogeneous attributes. An integrated aggregation mechanism is then developed to realize the horizontal FL among a group of similar client nodes via the so-called intra-group synchronous aggregation, while allowing the vertical FL across different groups via the so-called inter-group asynchronous aggregation. Experiment and evaluation results based on an open-source dataset demonstrate the outstanding learning and communication performance of our proposed model, compared with several conventional FL schemes in a distributed ITS application scenario.","<method>Federated learning (FL)</method>, <method>Adaptive Segmentation enhanced Asynchronous Federated Learning (AS-AFL)</method>, <method>meta-learning based adaptive segmentation</method>",<method>Federated learning (FL)</method><method>meta-learning based adaptive segmentation</method>
2024,https://openalex.org/W4393092671,Social Sciences,CFSSynergy: Combining Feature-Based and Similarity-Based Methods for Drug Synergy Prediction,"Drug synergy prediction plays a vital role in cancer treatment. Because experimental approaches are labor-intensive and expensive, computational-based approaches get more attention. There are two types of computational methods for drug synergy prediction: feature-based and similarity-based. In feature-based methods, the main focus is to extract more discriminative features from drug pairs and cell lines to pass to the task predictor. In similarity-based methods, the similarities among all drugs and cell lines are utilized as features and fed into the task predictor. In this work, a novel approach, called CFSSynergy, that combines these two viewpoints is proposed. First, a discriminative representation is extracted for paired drugs and cell lines as input. We have utilized transformer-based architecture for drugs. For cell lines, we have created a similarity matrix between proteins using the Node2Vec algorithm. Then, the new cell line representation is computed by multiplying the protein–protein similarity matrix and the initial cell line representation. Next, we compute the similarity between unique drugs and unique cells using the learned representation for paired drugs and cell lines. Then, we compute a new representation for paired drugs and cell lines based on the similarity-based features and the learned features. Finally, these features are fed to XGBoost as a task predictor. Two well-known data sets were used to evaluate the performance of our proposed method: DrugCombDB and OncologyScreen. The CFSSynergy approach consistently outperformed existing methods in comparative evaluations. This substantiates the efficacy of our approach in capturing complex synergistic interactions between drugs and cell lines, setting it apart from conventional similarity-based or feature-based methods.","<method>transformer-based architecture</method>, <method>Node2Vec algorithm</method>, <method>XGBoost</method>",<method>transformer-based architecture</method><method>Node2Vec algorithm</method><method>XGBoost</method>
2024,https://openalex.org/W4390905132,Social Sciences,LinK3D: Linear Keypoints Representation for 3D LiDAR Point Cloud,"Feature extraction and matching are the basic parts of many robotic vision tasks, such as 2D or 3D object detection, recognition, and registration. As is known, 2D feature extraction and matching have already achieved great success. Unfortunately, in the field of 3D, the current methods may fail to support the extensive application of 3D LiDAR sensors in robotic vision tasks due to their poor descriptiveness and inefficiency. To address this limitation, we propose a novel 3D feature representation method: <underline xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">Lin</u> ear <underline xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">K</u> eypoints representation for <underline xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">3D</u> LiDAR point cloud, called LinK3D. The novelty of LinK3D lies in that it fully considers the characteristics (such as the sparsity and complexity) of LiDAR point clouds and represents the keypoint with its robust neighbor keypoints, which provide strong constraints in the description of the keypoint. The proposed LinK3D has been evaluated on three public datasets, and the experimental results show that our method achieves great matching performance. More importantly, LinK3D also shows excellent real-time performance, faster than the sensor frame rate at 10 Hz of a typical rotating LiDAR sensor. LinK3D only takes an average of 30 milliseconds to extract features from the point cloud collected by a 64-beam LiDAR and takes merely about 20 milliseconds to match two LiDAR scans when executed on a computer with an Intel Core i7 processor. Moreover, our method can be extended to LiDAR odometry task, and shows good scalability.",<method>Linear Keypoints representation for 3D LiDAR point cloud (LinK3D)</method>,No methods remaining
2024,https://openalex.org/W4392169182,Social Sciences,Object Detection in Autonomous Vehicles under Adverse Weather: A Review of Traditional and Deep Learning Approaches,"Enhancing the environmental perception of autonomous vehicles (AVs) in intelligent transportation systems requires computer vision technology to be effective in detecting objects and obstacles, particularly in adverse weather conditions. Adverse weather circumstances present serious difficulties for object-detecting systems, which are essential to contemporary safety procedures, infrastructure for monitoring, and intelligent transportation. AVs primarily depend on image processing algorithms that utilize a wide range of onboard visual sensors for guidance and decisionmaking. Ensuring the consistent identification of critical elements such as vehicles, pedestrians, and road lanes, even in adverse weather, is a paramount objective. This paper not only provides a comprehensive review of the literature on object detection (OD) under adverse weather conditions but also delves into the ever-evolving realm of the architecture of AVs, challenges for automated vehicles in adverse weather, the basic structure of OD, and explores the landscape of traditional and deep learning (DL) approaches for OD within the realm of AVs. These approaches are essential for advancing the capabilities of AVs in recognizing and responding to objects in their surroundings. This paper further investigates previous research that has employed both traditional and DL methodologies for the detection of vehicles, pedestrians, and road lanes, effectively linking these approaches with the evolving field of AVs. Moreover, this paper offers an in-depth analysis of the datasets commonly employed in AV research, with a specific focus on the detection of key elements in various environmental conditions, and then summarizes the evaluation matrix. We expect that this review paper will help scholars to gain a better understanding of this area of research.","<method>traditional approaches for object detection</method>, <method>deep learning (DL) approaches for object detection</method>, <method>traditional methodologies for detection of vehicles, pedestrians, and road lanes</method>, <method>deep learning (DL) methodologies for detection of vehicles, pedestrians, and road lanes</method>",No methods remaining
2024,https://openalex.org/W4396831262,Social Sciences,GPT-4 Turbo with Vision fails to outperform text-only GPT-4 Turbo in the Japan Diagnostic Radiology Board Examination,"Abstract Purpose To assess the performance of GPT-4 Turbo with Vision (GPT-4TV), OpenAI’s latest multimodal large language model, by comparing its ability to process both text and image inputs with that of the text-only GPT-4 Turbo (GPT-4 T) in the context of the Japan Diagnostic Radiology Board Examination (JDRBE). Materials and methods The dataset comprised questions from JDRBE 2021 and 2023. A total of six board-certified diagnostic radiologists discussed the questions and provided ground-truth answers by consulting relevant literature as necessary. The following questions were excluded: those lacking associated images, those with no unanimous agreement on answers, and those including images rejected by the OpenAI application programming interface. The inputs for GPT-4TV included both text and images, whereas those for GPT-4 T were entirely text. Both models were deployed on the dataset, and their performance was compared using McNemar’s exact test. The radiological credibility of the responses was assessed by two diagnostic radiologists through the assignment of legitimacy scores on a five-point Likert scale. These scores were subsequently used to compare model performance using Wilcoxon's signed-rank test. Results The dataset comprised 139 questions. GPT-4TV correctly answered 62 questions (45%), whereas GPT-4 T correctly answered 57 questions (41%). A statistical analysis found no significant performance difference between the two models (P = 0.44). The GPT-4TV responses received significantly lower legitimacy scores from both radiologists than the GPT-4 T responses. Conclusion No significant enhancement in accuracy was observed when using GPT-4TV with image input compared with that of using text-only GPT-4 T for JDRBE questions.","<method>GPT-4 Turbo with Vision (GPT-4TV)</method>, <method>GPT-4 Turbo (GPT-4 T)</method>",<method>GPT-4 Turbo (GPT-4 T)</method>
2024,https://openalex.org/W4390755438,Social Sciences,A voting gray wolf optimizer-based ensemble learning models for intrusion detection in the Internet of Things,"Abstract The Internet of Things (IoT) has garnered considerable attention from academic and industrial circles as a pivotal technology in recent years. The escalation of security risks is observed to be associated with the growing interest in IoT applications. Intrusion detection systems (IDS) have been devised as viable instruments for identifying and averting malicious actions in this context. Several techniques described in academic papers are thought to be very accurate, but they cannot be used in the real world because the datasets used to build and test the models do not accurately reflect and simulate the IoT network. Existing methods, on the other hand, deal with these issues, but they are not good enough for commercial use because of their lack of precision, low detection rate, receiver operating characteristic (ROC), and false acceptance rate (FAR). The effectiveness of these solutions is predominantly dependent on individual learners and is consequently influenced by the inherent limitations of each learning algorithm. This study introduces a new approach for detecting intrusion attacks in an IoT network, which involves the use of an ensemble learning technique based on gray wolf optimizer (GWO). The novelty of this study lies in the proposed voting gray wolf optimizer (GWO) ensemble model, which incorporates two crucial components: a traffic analyzer and a classification phase engine. The model employs a voting technique to combine the probability averages of the base learners. Secondly, the combination of feature selection and feature extraction techniques is to reduce dimensionality. Thirdly, the utilization of GWO is employed to optimize the parameters of ensemble models. Similarly, the approach employs the most authentic intrusion detection datasets that are accessible and amalgamates multiple learners to generate ensemble learners. The hybridization of information gain (IG) and principal component analysis (PCA) was employed to reduce dimensionality. The study utilized a novel GWO ensemble learning approach that incorporated a decision tree, random forest, K-nearest neighbor, and multilayer perceptron for classification. To evaluate the efficacy of the proposed model, two authentic datasets, namely, BoT-IoT and UNSW-NB15, were scrutinized. The GWO-optimized ensemble model demonstrates superior accuracy when compared to other machine learning-based and deep learning models. Specifically, the model achieves an accuracy rate of 99.98%, a DR of 99.97%, a precision rate of 99.94%, an ROC rate of 99.99%, and an FAR rate of 1.30 on the BoT-IoT dataset. According to the experimental results, the proposed ensemble model optimized by GWO achieved an accuracy of 100%, a DR of 99.9%, a precision of 99.59%, an ROC of 99.40%, and an FAR of 1.5 when tested on the UNSW-NB15 dataset.","<method>ensemble learning technique</method>, <method>gray wolf optimizer (GWO)</method>, <method>voting technique</method>, <method>feature selection</method>, <method>feature extraction</method>, <method>information gain (IG)</method>, <method>principal component analysis (PCA)</method>, <method>decision tree</method>, <method>random forest</method>, <method>K-nearest neighbor</method>, <method>multilayer perceptron</method>",<method>ensemble learning technique</method><method>gray wolf optimizer (GWO)</method><method>voting technique</method><method>feature selection</method><method>information gain (IG)</method><method>principal component analysis (PCA)</method><method>decision tree</method><method>random forest</method><method>K-nearest neighbor</method><method>multilayer perceptron</method>
2024,https://openalex.org/W4392865184,Social Sciences,Artificial intelligence and multimodal data fusion for smart healthcare: topic modeling and bibliometrics,"Abstract Advancements in artificial intelligence (AI) have driven extensive research into developing diverse multimodal data analysis approaches for smart healthcare. There is a scarcity of large-scale analysis of literature in this field based on quantitative approaches. This study performed a bibliometric and topic modeling examination on 683 articles from 2002 to 2022, focusing on research topics and trends, journals, countries/regions, institutions, authors, and scientific collaborations. Results showed that, firstly, the number of articles has grown from 1 in 2002 to 220 in 2022, with a majority being published in interdisciplinary journals that link healthcare and medical research and information technology and AI. Secondly, the significant rise in the quantity of research articles can be attributed to the increasing contribution of scholars from non-English speaking countries/regions and the noteworthy contributions made by authors in the USA and India. Thirdly, researchers show a high interest in diverse research issues, especially, cross-modality magnetic resonance imaging (MRI) for brain tumor analysis, cancer prognosis through multi-dimensional data analysis, and AI-assisted diagnostics and personalization in healthcare, with each topic experiencing a significant increase in research interest. There is an emerging trend towards issues such as applying generative adversarial networks and contrastive learning for multimodal medical image fusion and synthesis and utilizing the combined spatiotemporal resolution of functional MRI and electroencephalogram in a data-centric manner. This study is valuable in enhancing researchers’ and practitioners’ understanding of the present focal points and upcoming trajectories in AI-powered smart healthcare based on multimodal data analysis.","<method>generative adversarial networks</method>, <method>contrastive learning</method>",<method>generative adversarial networks</method><method>contrastive learning</method>
2024,https://openalex.org/W4392884001,Social Sciences,Developing a Multi-Criteria Decision-Making model for nuclear power plant location selection using Fuzzy Analytic Hierarchy Process and Fuzzy VIKOR methods focused on socio-economic factors,"In response to its position as the fourth most populous country globally, Indonesia is exploring constructing nuclear power plants (NPPs) as a sustainable energy solution. A pivotal step in this initiative is selecting an appropriate NPP site. This study employs two Multi-Criteria Decision-Making (MCDM) methods, the Fuzzy Analytic Hierarchy Process (Fuzzy-AHP) and Fuzzy VIKOR, to identify the most suitable location for an NPP, focusing on socio-economic factors. The Fuzzy-AHP method is utilized to prioritize ten sub-criteria: transmission network, operating costs, economic impact, security, transportation network, legal considerations, the impact of tourism, land ownership, historical sites, and public acceptance. Following this, the Fuzzy VIKOR method leverages these prioritized criteria to evaluate two potential sites: East Kalimantan and West Kalimantan. The analysis reveals that security, transmission, and transportation networks emerge as the top priorities. The application of the Fuzzy VIKOR algorithm identifies West Kalimantan as the optimal site for NPP construction, evidenced by its lower VIKOR index of 0.3599, indicating a higher overall preference based on the evaluated criteria. The study demonstrates that the integration of Fuzzy-AHP and Fuzzy VIKOR methods prioritizes critical socio-economic factors and quantitatively assesses potential sites, offering a systematic and objective approach to support decision-making in NPP site selection.","<method>Fuzzy Analytic Hierarchy Process (Fuzzy-AHP)</method>, <method>Fuzzy VIKOR</method>",<method>Fuzzy VIKOR</method>
2024,https://openalex.org/W4402890475,Social Sciences,"Foundation models in robotics: Applications, challenges, and the future","We survey applications of pretrained foundation models in robotics. Traditional deep learning models in robotics are trained on small datasets tailored for specific tasks, which limits their adaptability across diverse applications. In contrast, foundation models pretrained on internet-scale data appear to have superior generalization capabilities, and in some instances display an emergent ability to find zero-shot solutions to problems that are not present in the training data. Foundation models may hold the potential to enhance various components of the robot autonomy stack, from perception to decision-making and control. For example, large language models can generate code or provide common sense reasoning, while vision-language models enable open-vocabulary visual recognition. However, significant open research challenges remain, particularly around the scarcity of robot-relevant training data, safety guarantees and uncertainty quantification, and real-time execution. In this survey, we study recent papers that have used or built foundation models to solve robotics problems. We explore how foundation models contribute to improving robot capabilities in the domains of perception, decision-making, and control. We discuss the challenges hindering the adoption of foundation models in robot autonomy and provide opportunities and potential pathways for future advancements. The GitHub project corresponding to this paper can be found here: https://github.com/robotics-survey/Awesome-Robotics-Foundation-Models .","<method>pretrained foundation models</method>, <method>traditional deep learning models</method>, <method>large language models</method>, <method>vision-language models</method>",<method>pretrained foundation models</method><method>vision-language models</method>
2024,https://openalex.org/W4391454392,Social Sciences,UANet: An Uncertainty-Aware Network for Building Extraction From Remote Sensing Images,"Building extraction aims to segment building pixels from remote sensing images and plays an essential role in many applications, such as city planning and urban dynamic monitoring. Over the past few years, deep learning methods with encoder–decoder architectures have achieved remarkable performance due to their powerful feature representation capability. Nevertheless, due to the varying scales and styles of buildings, conventional deep learning models always suffer from uncertain predictions and cannot accurately distinguish the complete footprints of the building from the complex distribution of ground objects, leading to a large degree of omission and commission. In this paper, we realize the importance of uncertain prediction and propose a novel and straightforward Uncertainty-Aware Network (UANet) to alleviate this problem. Specifically, we first apply a general encoder–decoder network to obtain a building extraction map with relatively high uncertainty. Second, in order to aggregate the useful information in the highest-level features, we design a Prior Information Guide Module to guide the highest-level features in learning the prior information from the conventional extraction map. Third, based on the uncertain extraction map, we introduce an Uncertainty Rank Algorithm to measure the uncertainty level of each pixel belonging to the foreground and the background. We further combine this algorithm with the proposed Uncertainty-Aware Fusion Module to facilitate level-by-level feature refinement and obtain the final refined extraction map with low uncertainty. To verify the performance of our proposed UANet, we conduct extensive experiments on three public building datasets, including the WHU building dataset, the Massachusetts building dataset, and the Inria aerial image dataset. Results demonstrate that the proposed UANet outperforms other state-of-the-art algorithms by a large margin. The source code of the proposed UANet is available at https://github.com/Henryjiepanli/Uncertainty-aware-Network.","<method>deep learning methods with encoder–decoder architectures</method>, <method>encoder–decoder network</method>, <method>Uncertainty-Aware Network (UANet)</method>, <method>Prior Information Guide Module</method>, <method>Uncertainty Rank Algorithm</method>, <method>Uncertainty-Aware Fusion Module</method>",<method>deep learning methods with encoder–decoder architectures</method><method>encoder–decoder network</method>
2024,https://openalex.org/W4393380945,Social Sciences,One-Step Multi-View Clustering With Diverse Representation,"Multi-View clustering has attracted broad attention due to its capacity to utilize consistent and complementary information among views. Although tremendous progress has been made recently, most existing methods undergo high complexity, preventing them from being applied to large-scale tasks. Multi-View clustering via matrix factorization is a representative to address this issue. However, most of them map the data matrices into a fixed dimension, limiting the model's expressiveness. Moreover, a range of methods suffers from a two-step process, i.e., multimodal learning and the subsequent <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> <tex-math notation=""LaTeX"">$k$</tex-math> </inline-formula> -means, inevitably causing a suboptimal clustering result. In light of this, we propose a one-step multi-view clustering with diverse representation (OMVCDR) method, which incorporates multi-view learning and <inline-formula xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink""> <tex-math notation=""LaTeX"">$k$</tex-math> </inline-formula> -means into a unified framework. Specifically, we first project original data matrices into various latent spaces to attain comprehensive information and auto-weight them in a self-supervised manner. Then, we directly use the information matrices under diverse dimensions to obtain consensus discrete clustering labels. The unified work of representation learning and clustering boosts the quality of the final results. Furthermore, we develop an efficient optimization algorithm with proven convergence to solve the resultant problem. Comprehensive experiments on various datasets demonstrate the promising clustering performance of our proposed method. The code is publicly available at https://github.com/wanxinhang/OMVCDR.","<method>Multi-View clustering via matrix factorization</method>, <method>k-means</method>, <method>one-step multi-view clustering with diverse representation (OMVCDR)</method>, <method>multi-view learning</method>, <method>self-supervised auto-weighting</method>, <method>representation learning</method>",<method>Multi-View clustering via matrix factorization</method><method>k-means</method><method>multi-view learning</method><method>representation learning</method>
2024,https://openalex.org/W4396827149,Social Sciences,Rehearsal: Simulating Conflict to Teach Conflict Resolution,"Interpersonal conflict is an uncomfortable but unavoidable fact of life. Navigating conflict successfully is a skill—one that can be learned through deliberate practice—but few have access to effective training or feedback. To expand this access, we introduce Rehearsal, a system that allows users to rehearse conflicts with a believable simulated interlocutor, explore counterfactual ""what if?"" scenarios to identify alternative conversational paths, and learn through feedback on how and when to apply specific conflict strategies. Users can utilize Rehearsal to practice handling a variety of predefined conflict scenarios, from office disputes to relationship issues, or they can choose to create their own setting. To enable Rehearsal, we develop IRP prompting, a method of conditioning output of a large language model on the influential Interest-Rights-Power (IRP) theory from conflict resolution. Rehearsal uses IRP to generate utterances grounded in conflict resolution theory, guiding users towards counterfactual conflict resolution strategies that help de-escalate difficult conversations. In a between-subjects evaluation, 40 participants engaged in an actual conflict with a confederate after training. Compared to a control group with lecture material covering the same IRP theory, participants with simulated training from Rehearsal significantly improved their performance in the unaided conflict: they reduced their use of escalating competitive strategies by an average of 67%, while doubling their use of cooperative strategies. Overall, Rehearsal highlights the potential effectiveness of language models as tools for learning and practicing interpersonal skills.",<method>IRP prompting</method>,No methods remaining
2024,https://openalex.org/W4399054302,Social Sciences,Artificial Intelligence in Point-of-Care Biosensing: Challenges and Opportunities,"The integration of artificial intelligence (AI) into point-of-care (POC) biosensing has the potential to revolutionize diagnostic methodologies by offering rapid, accurate, and accessible health assessment directly at the patient level. This review paper explores the transformative impact of AI technologies on POC biosensing, emphasizing recent computational advancements, ongoing challenges, and future prospects in the field. We provide an overview of core biosensing technologies and their use at the POC, highlighting ongoing issues and challenges that may be solved with AI. We follow with an overview of AI methodologies that can be applied to biosensing, including machine learning algorithms, neural networks, and data processing frameworks that facilitate real-time analytical decision-making. We explore the applications of AI at each stage of the biosensor development process, highlighting the diverse opportunities beyond simple data analysis procedures. We include a thorough analysis of outstanding challenges in the field of AI-assisted biosensing, focusing on the technical and ethical challenges regarding the widespread adoption of these technologies, such as data security, algorithmic bias, and regulatory compliance. Through this review, we aim to emphasize the role of AI in advancing POC biosensing and inform researchers, clinicians, and policymakers about the potential of these technologies in reshaping global healthcare landscapes.","<method>machine learning algorithms</method>, <method>neural networks</method>",<method>neural networks</method>
2024,https://openalex.org/W4399426804,Social Sciences,Evaluating the persuasive influence of political microtargeting with large language models,"Recent advancements in large language models (LLMs) have raised the prospect of scalable, automated, and fine-grained political microtargeting on a scale previously unseen; however, the persuasive influence of microtargeting with LLMs remains unclear. Here, we build a custom web application capable of integrating self-reported demographic and political data into GPT-4 prompts in real-time, facilitating the live creation of unique messages tailored to persuade individual users on four political issues. We then deploy this application in a preregistered randomized control experiment ( n = 8,587) to investigate the extent to which access to individual-level data increases the persuasive influence of GPT-4. Our approach yields two key findings. First, messages generated by GPT-4 were broadly persuasive, in some cases increasing support for an issue stance by up to 12 percentage points. Second, in aggregate, the persuasive impact of microtargeted messages was not statistically different from that of non-microtargeted messages (4.83 vs. 6.20 percentage points, respectively, P = 0.226). These trends hold even when manipulating the type and number of attributes used to tailor the message. These findings suggest—contrary to widespread speculation—that the influence of current LLMs may reside not in their ability to tailor messages to individuals but rather in the persuasiveness of their generic, nontargeted messages. We release our experimental dataset, GPTarget2024 , as an empirical baseline for future research.",<method>GPT-4</method>,<method>GPT-4</method>
2024,https://openalex.org/W4401434014,Social Sciences,Crafting personalized learning paths with AI for lifelong learning: a systematic literature review,"The rapid evolution of knowledge requires constantly acquiring and updating skills, making lifelong learning crucial. Despite decades of artificial intelligence, recent advances promote new solutions to personalize learning in this context. The purpose of this article is to explore the current state of research on the development of artificial intelligence-mediated solutions for the design of personalized learning paths. To achieve this, a systematic literature review (SRL) of 78 articles published between 2019 and 2024 from the Scopus and Web or Science databases was conducted, answering seven questions grouped into three themes: characteristics of the published research, context of the research, and type of solution analyzed. This study identified that: (a) the greatest production of scientific research on the topic is developed in China, India and the United States, (b) the focus is mainly directed towards the educational context at the higher education level with areas of opportunity for application in the work context, and (c) the development of adaptive learning technologies predominates; however, there is a growing interest in the application of generative language models. This article contributes to the growing interest and literature related to personalized learning under artificial intelligence mediated solutions that will serve as a basis for academic institutions and organizations to design programs under this model.","<method>adaptive learning technologies</method>, <method>generative language models</method>",<method>generative language models</method>
2024,https://openalex.org/W4390876710,Social Sciences,Utilisation of Deep Learning (DL) and Neural Networks (NN) Algorithms for Energy Power Generation: A Social Network and Bibliometric Analysis (2004-2022),"The research landscape on the applications of advanced computational tools (ACTs) such as machine/deep learning and neural network algorithms for energy and power generation (EPG) was critically examined through publication trends and bibliometrics data analysis. The Elsevier Scopus database and the PRISMA methodology were employed to identify and screen the published documents, whereas the bibliometric analysis software VOSviewer was used to analyse the co-authorships, citations, and keyword occurrences. The results showed that 152 documents have been published on the topic comprising conference proceedings (58.6%) and articles (41.4%) between 2004 and 2022. Publication trends analysis revealed the number of publications increased from 1 to 31 or by 3,000% over the same period, which was ascribed to the growing scientific interest and research impact of the topic. Stakeholder analysis revealed the top authors/researchers are Anvari M, Ghaderi SF and Saberi M, whereas the most prolific affiliation and nations actively engaged in the topic are the North China Electric Power University, and China, respectively. Conversely, the top funding agency actively backing research on the topic is the National Natural Science Foundation of China (NSFC). Co-authorship analysis revealed high levels of collaboration between researching nations compared to authors and affiliations. Hotspot analysis revealed three major thematic focus areas namely; Energy Grid Forecasting, Power Generation Control, and Intelligent Energy Optimization. In conclusion, the study showed that the application of ACTs in EPG is an active, multidisciplinary, and impact area of research with potential for more impactful contributions to research and society at large.","<method>machine learning</method>, <method>deep learning</method>, <method>neural network algorithms</method>",<method>machine learning</method><method>deep learning</method><method>neural network algorithms</method>
2024,https://openalex.org/W4392639228,Social Sciences,Application of Interval Valued Intuitionistic Fuzzy Uncertain MCDM Methodology for Ph.D Supervisor Selection Problem,"The selection of Ph.D (Doctor of Philosophy) supervisor is always a vital and interesting problem in academia and especially for students who want to carry out Ph.D. Nowadays, selecting a supervisor for Ph.D in a scientific manner becomes a challenge for any student because of the variety of options available to the scholar. In this context, the present study aims to formulate a model for Ph.D. supervisor selection from the offered alternatives in an academic institute. A hybrid multi-criteria decision making (MCDM) framework has been applied to select the suitable supervisor of the student's preferred criteria under interval-valued intuitionistic fuzzy (IVIF) scenario. The IVIF Analytic Hierarchy Process (AHP) has been employed to prioritize the criteria, whereas IVIF Technique for order preference by similarity to ideal solution (TOPSIS) technique is engaged to rank the available supervisors based on criteria weight. A set of eight criteria and five alternatives have been considered for modelling the problem. Moreover, the potential criteria are weighted and ranked by the multiple decision makers in the present study. To examine the consistency and robustness of the proposed integrated approach, sensitivity analysis and comparative analysis have been carried out. From all the analyses, it can be conferred that the suggested approach is quite useful to apply in different decision-making scenarios.","<method>IVIF Analytic Hierarchy Process (AHP)</method>, <method>IVIF Technique for order preference by similarity to ideal solution (TOPSIS)</method>",No methods remaining
2024,https://openalex.org/W4394967854,Social Sciences,Potential of Large Language Models in Health Care: Delphi Study,"Background A large language model (LLM) is a machine learning model inferred from text data that captures subtle patterns of language use in context. Modern LLMs are based on neural network architectures that incorporate transformer methods. They allow the model to relate words together through attention to multiple words in a text sequence. LLMs have been shown to be highly effective for a range of tasks in natural language processing (NLP), including classification and information extraction tasks and generative applications. Objective The aim of this adapted Delphi study was to collect researchers’ opinions on how LLMs might influence health care and on the strengths, weaknesses, opportunities, and threats of LLM use in health care. Methods We invited researchers in the fields of health informatics, nursing informatics, and medical NLP to share their opinions on LLM use in health care. We started the first round with open questions based on our strengths, weaknesses, opportunities, and threats framework. In the second and third round, the participants scored these items. Results The first, second, and third rounds had 28, 23, and 21 participants, respectively. Almost all participants (26/28, 93% in round 1 and 20/21, 95% in round 3) were affiliated with academic institutions. Agreement was reached on 103 items related to use cases, benefits, risks, reliability, adoption aspects, and the future of LLMs in health care. Participants offered several use cases, including supporting clinical tasks, documentation tasks, and medical research and education, and agreed that LLM-based systems will act as health assistants for patient education. The agreed-upon benefits included increased efficiency in data handling and extraction, improved automation of processes, improved quality of health care services and overall health outcomes, provision of personalized care, accelerated diagnosis and treatment processes, and improved interaction between patients and health care professionals. In total, 5 risks to health care in general were identified: cybersecurity breaches, the potential for patient misinformation, ethical concerns, the likelihood of biased decision-making, and the risk associated with inaccurate communication. Overconfidence in LLM-based systems was recognized as a risk to the medical profession. The 6 agreed-upon privacy risks included the use of unregulated cloud services that compromise data security, exposure of sensitive patient data, breaches of confidentiality, fraudulent use of information, vulnerabilities in data storage and communication, and inappropriate access or use of patient data. Conclusions Future research related to LLMs should not only focus on testing their possibilities for NLP-related tasks but also consider the workflows the models could contribute to and the requirements regarding quality, integration, and regulations needed for successful implementation in practice.","<method>large language model (LLM)</method>, <method>machine learning model</method>, <method>neural network architectures</method>, <method>transformer methods</method>",<method>large language model (LLM)</method><method>transformer methods</method>
2024,https://openalex.org/W4398796607,Social Sciences,Desirable Characteristics for AI Teaching Assistants in Programming Education,"Providing timely and personalized feedback to large numbers of students is a long-standing challenge in programming courses.Relying on human teaching assistants (TAs) has been extensively studied, revealing a number of potential shortcomings.These include inequitable access for students with low confidence when needing support, as well as situations where TAs provide direct solutions without helping students to develop their own problemsolving skills.With the advent of powerful large language models (LLMs), digital teaching assistants configured for programming contexts have emerged as an appealing and scalable way to provide instant, equitable, round-the-clock support.Although digital TAs can provide a variety of help for programming tasks, from high-level problem solving advice to direct solution generation, the effectiveness of such tools depends on their ability to promote meaningful learning experiences.If students find the guardrails implemented in digital TAs too constraining, or if other expectations are not met, they may seek assistance in ways that do not help them learn.Thus, it is essential to identify the features that students believe make digital teaching assistants valuable.We deployed an LLM-powered digital assistant in an introductory programming course and collected student feedback ( = 813) on the characteristics of the tool they perceived to be most important.Our results highlight that students value such tools for their ability to provide instant, engaging support, particularly during peak times such as before assessment deadlines.They also expressed a strong preference for features that enable them to retain autonomy in their learning journey, such as scaffolding that helps to guide them through problem-solving steps rather than simply being shown direct solutions.",<method>large language models (LLMs)</method>,No methods remaining
2024,https://openalex.org/W4399421825,Social Sciences,Integrating deep learning techniques for personalized learning pathways in higher education,"The rapid improvement of artificial intelligence (AI) in the educational domain has opened new possibilities for enhancing the learning experiences for students. This research discusses the critical need for personalized education in higher education by integrating deep learning (DL) techniques to create customized learning pathways for students. This research intends to bridge the gap between constant educational content and dynamic student needs. This research presents an AI-driven adaptive learning platform implemented across four different courses and 300 students at a university in Faisalabad-Pakistan. A controlled experiment compares student outcomes between those using the AI platform and those undergoing traditional instruction. Quantitative results demonstrate a 25 % improvement in grades, test scores, and engagement for the AI group, with a statistical significance of a p-value of 0.00045. Qualitative feedback highlights enhanced experiences attributed to personalized pathways. The DL analysis of student performance data highlights key parameters, including enhanced learning outcomes and engagement metrices over time. Surveys reveal increased satisfaction compared to one-size-fits-all content. Unlike prior AI research lacking rigorous validation, our methodology and significant results deliver a concrete framework for institutions to implement personalized, AI-driven education at scale. This data-driven approach builds on previous attempts by tying adaptations to actual student needs, yielding measurable improvements in key outcomes. Overall, this work empirically validates that AI platforms leveraging robust analytics to provide customized and adaptive learning can significantly enhance student academic performance, engagement, and satisfaction compared to traditional approaches. These findings have insightful consequences for the future of higher education. The research contributes to the growing demand for AI in education research and provides a practical framework for institutions seeking to implement more adaptive and student-centric teaching methodologies.",<method>deep learning (DL) techniques</method>,No methods remaining
2024,https://openalex.org/W4400853276,Social Sciences,Unveiling the dynamics of AI applications: A review of reviews using scientometrics and BERTopic modeling,"In a world that has rapidly transformed through the advent of artificial intelligence (AI), our systematic review, guided by the PRISMA protocol, investigates a decade of AI research, revealing insights into its evolution and impact. Our study, examining 3,767 articles, has drawn considerable attention, as evidenced by an impressive 63,577 citations, underscoring the scholarly community's profound engagement. Our study reveals a collaborative landscape with 18,189 contributing authors, reflecting a robust network of researchers advancing AI and machine learning applications. Review categories focus on systematic reviews and bibliometric analyses, indicating an increasing emphasis on comprehensive literature synthesis and quantitative analysis. The findings also suggest an opportunity to explore emerging methodologies such as topic modeling and meta-analysis. We dissect the state of the art presented in these reviews, finding themes throughout the broad scholarly discourse through thematic clustering and BERTopic modeling. Categorization of study articles across fields of research indicates dominance in Information and Computing Sciences, followed by Biomedical and Clinical Sciences. Subject categories reveal interconnected clusters across various sectors, notably in healthcare, engineering, business intelligence, and computational technologies. Semantic analysis via BERTopic revealed nineteen clusters mapped to themes such as AI in health innovations, AI for sustainable development, AI and deep learning, AI in education, and ethical considerations. Future research directions are suggested, emphasizing the need for intersectional bias mitigation, holistic health approaches, AI's role in environmental sustainability, and the ethical deployment of generative AI.","<method>topic modeling</method>, <method>meta-analysis</method>, <method>thematic clustering</method>, <method>BERTopic modeling</method>",<method>topic modeling</method><method>BERTopic modeling</method>
2024,https://openalex.org/W4403656816,Social Sciences,"Advancing the Sustainable Development Goals (SDGs) through artificial intelligence, machine learning, and deep learning","The use of Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) significantly has the touch of transformational potential towards bringing the Sustainable Development Goals (SDGs) to be addressed in various industries. This research investigates the new developments and applications of these technologies in advancing sustainability programs in industry-intensive domains. Industries are beginning to undergo a major change by making today with the help of AI, ML, and DL that resources can be optimized, energy efficiency can be improved, and environmental impacts can be mitigated. A number of other trends - including predictive analytics and intelligent automation, allow for smarter and more efficient production, waste minimization and circular economy practices. AI-powered solutions are also now being used in the energy sector to maximize the generation of renewable energy, optimize grid management, and aid in the transition to low carbon energy systems. This will enable industries achieve better environmental benefits and higher operational efficiencies through big data analytics and IoT. AI and ML are also crucial in smart cities, urban planning, public services that delivery efficiency and overall support the sustainability agenda. The results reinforce the importance of strong regulatory structures and interdisciplinary collaboration to optimally leverage AI, ML, and DL to the SDGs, which will be intrinsic to designing for resilience and sustainability.","<method>Artificial Intelligence (AI)</method>, <method>Machine Learning (ML)</method>, <method>Deep Learning (DL)</method>, <method>predictive analytics</method>, <method>intelligent automation</method>",<method>Machine Learning (ML)</method><method>Deep Learning (DL)</method>
2024,https://openalex.org/W4404105402,Social Sciences,Autonomous mobile robots for exploratory synthetic chemistry,"Abstract Autonomous laboratories can accelerate discoveries in chemical synthesis, but this requires automated measurements coupled with reliable decision-making 1,2 . Most autonomous laboratories involve bespoke automated equipment 3–6 , and reaction outcomes are often assessed using a single, hard-wired characterization technique 7 . Any decision-making algorithms 8 must then operate using this narrow range of characterization data 9,10 . By contrast, manual experiments tend to draw on a wider range of instruments to characterize reaction products, and decisions are rarely taken based on one measurement alone. Here we show that a synthesis laboratory can be integrated into an autonomous laboratory by using mobile robots 11–13 that operate equipment and make decisions in a human-like way. Our modular workflow combines mobile robots, an automated synthesis platform, a liquid chromatography–mass spectrometer and a benchtop nuclear magnetic resonance spectrometer. This allows robots to share existing laboratory equipment with human researchers without monopolizing it or requiring extensive redesign. A heuristic decision-maker processes the orthogonal measurement data, selecting successful reactions to take forward and automatically checking the reproducibility of any screening hits. We exemplify this approach in the three areas of structural diversification chemistry, supramolecular host–guest chemistry and photochemical synthesis. This strategy is particularly suited to exploratory chemistry that can yield multiple potential products, as for supramolecular assemblies, where we also extend the method to an autonomous function assay by evaluating host–guest binding properties.",<method>heuristic decision-maker</method>,No methods remaining
2024,https://openalex.org/W4390542282,Social Sciences,Unveiling energy efficiency and renewable electricity’s role in achieving sustainable development goals 7 and 13 policies,"Germany has not yet made significant progress toward achieving SDGs 7 and 13. This challenge can be attributed to the underlying financialization problem in Germany, as well as implementation issues related to energy efficiency, particularly in coal and gas, and renewable energy consumption. Given these circumstances, Germany is facing challenges in reducing greenhouse gas emissions. Addressing this issue may necessitate a policy realignment, which is the primary focus of this study. In this context, our study employs various wavelet-based tools, including wavelet coherence, multivariate wavelet coherence, and wavelet-based causality, to delve into the co-movements, causality, and direction of causality between the load capacity factor (LF) and key factors such as energy efficiency (gas and coal), technological innovation, renewable electricity, and financial development, focusing on Germany during the period from 1990Q1 to 2020Q4. The results from wavelet coherence, corroborated by wavelet cohesion, indicate that in the short and medium term, improvements in coal efficiency, gas efficiency, financial development, and renewable energy are associated with an increase in LF, thereby contributing to ecological quality. Furthermore, the multivariate wavelet coherence results underscore the significant impact of considering or not considering the effect of a third variable in the interrelationship between LF and its determinants, with the effect being more pronounced when the third variable is taken into account. Although this policy framework primarily targets the objectives of SDG 13 and 7, its applicability extends to other EU nations. The primary significance of this study is its proposal of an SDG-focused policy framework.","<method>wavelet coherence</method>, <method>multivariate wavelet coherence</method>, <method>wavelet-based causality</method>",No methods remaining
2024,https://openalex.org/W4390742710,Social Sciences,Machine Learning as a Tool for Hypothesis Generation,"Abstract While hypothesis testing is a highly formalized activity, hypothesis generation remains largely informal. We propose a systematic procedure to generate novel hypotheses about human behavior, which uses the capacity of machine learning algorithms to notice patterns people might not. We illustrate the procedure with a concrete application: judge decisions about whom to jail. We begin with a striking fact: the defendant’s face alone matters greatly for the judge’s jailing decision. In fact, an algorithm given only the pixels in the defendant’s mug shot accounts for up to half of the predictable variation. We develop a procedure that allows human subjects to interact with this black-box algorithm to produce hypotheses about what in the face influences judge decisions. The procedure generates hypotheses that are both interpretable and novel: they are not explained by demographics (e.g., race) or existing psychology research, nor are they already known (even if tacitly) to people or experts. Though these results are specific, our procedure is general. It provides a way to produce novel, interpretable hypotheses from any high-dimensional data set (e.g., cell phones, satellites, online behavior, news headlines, corporate filings, and high-frequency time series). A central tenet of our article is that hypothesis generation is a valuable activity, and we hope this encourages future work in this largely “prescientific” stage of science.",<method>machine learning algorithms</method>,No methods remaining
2024,https://openalex.org/W4394961856,Social Sciences,Applications and challenges of neural networks in otolaryngology (Review),"Artificial Intelligence (AI) has become a topic of interest that is frequently debated in all research fields. The medical field is no exception, where several unanswered questions remain. When and how this field can benefit from AI support in daily routines are the most frequently asked questions. The present review aims to present the types of neural networks (NNs) available for development, discussing their advantages, disadvantages and how they can be applied practically. In addition, the present review summarizes how NNs (combined with various other features) have already been applied in studies in the ear nose throat research field, from assisting diagnosis to treatment management. Although the answer to this question regarding AI remains elusive, understanding the basics and types of applicable NNs can lead to future studies possibly using more than one type of NN. This approach may bypass the actual limitations in accuracy and relevance of information generated by AI. The proposed studies, the majority of which used convolutional NNs, obtained accuracies varying 70-98%, with a number of studies having the AI trained on a limited number of cases (<100 patients). The lack of standardization in AI protocols for research negatively affects data homogeneity and transparency of databases.","<method>neural networks (NNs)</method>, <method>convolutional neural networks (convolutional NNs)</method>",<method>neural networks (NNs)</method><method>convolutional neural networks (convolutional NNs)</method>
2024,https://openalex.org/W4397028793,Social Sciences,A Hierarchical 3D Gaussian Representation for Real-Time Rendering of Very Large Datasets,"Novel view synthesis has seen major advances in recent years, with 3D Gaussian splatting offering an excellent level of visual quality, fast training and real-time rendering. However, the resources needed for training and rendering inevitably limit the size of the captured scenes that can be represented with good visual quality. We introduce a hierarchy of 3D Gaussians that preserves visual quality for very large scenes, while offering an efficient Level-of-Detail (LOD) solution for efficient rendering of distant content with effective level selection and smooth transitions between levels. We introduce a divide-and-conquer approach that allows us to train very large scenes in independent chunks. We consolidate the chunks into a hierarchy that can be optimized to further improve visual quality of Gaussians merged into intermediate nodes. Very large captures typically have sparse coverage of the scene, presenting many challenges to the original 3D Gaussian splatting training method; we adapt and regularize training to account for these issues. We present a complete solution, that enables real-time rendering of very large scenes and can adapt to available resources thanks to our LOD method. We show results for captured scenes with up to tens of thousands of images with a simple and affordable rig, covering trajectories of up to several kilometers and lasting up to one hour.","<method>3D Gaussian splatting</method>, <method>hierarchy of 3D Gaussians</method>, <method>Level-of-Detail (LOD) solution</method>, <method>divide-and-conquer approach</method>, <method>training adaptation and regularization</method>",<method>3D Gaussian splatting</method>
2024,https://openalex.org/W4401508155,Social Sciences,REAL TIME OBJECT DETECTION,"The capacity for cameras and computational frameworks to screen a given region has been set up and worked upon by the specialist for quite a long while.The capacity of the human mind to just classify and comprehend what an object is upon a basic look is something that has interested numerous scientists for quite a while.Indeed, even with the progressions in the areas of Artificial insight also ML is as yet a troublesome errand for researchers to make an object following and recognition framework that can work productively in rapidly.We have had the option to make models in the realm of ML which have been prepared thoroughly with a huge number of pictures inside datasets to perceive and comprehend a few objects however we have still neglected to appropriately set up one equivalent to that of the human mind.Although, the downside of computational elements is their capacity to share feelings we have likewise had the option to comprehend the human brain has undeniably more computational force then one can envision.In our task, we will be pursuing making a calculation that will actually want to perceive and portray the entirety of the pictures inside a given edge.To achieve this, we will be building up a module utilizing Python and a webcam that catches the pictures in the type of casings and perceive objects.We will make a calculation that will contrast the object inside the casing with that of a dataset set up inside Amazon AWS to perceive and comprehend what the object is.Through this paper, we will discuss the sorts of programming used to execute to make this conceivable alongside our discoveries alongside the future extent of this innovation.","<method>object tracking</method>, <method>object recognition</method>, <method>machine learning models trained on image datasets</method>",No methods remaining
2024,https://openalex.org/W4390500790,Social Sciences,Adoption of smart technologies in the cruise tourism services: a systematic review and future research agenda,"Purpose The purpose of this paper is to systematically analyze existing studies related to the adoption of smart technologies in cruise tourism services, particularly robots, artificial intelligence, service automation and virtual reality. More specifically, the authors intend to highlight the current state of research on this topic, present the findings within a conceptual framework and propose a research agenda. Design/methodology/approach The relevant literature was extracted using two major electronic databases, web of science (WoS) and Scopus. The authors identified 31 articles from high-quality journals and used a systematic review and the VOSviewer software to analyze them. Findings Since 2014, there has been an increase in the number of studies related to smart technologies in cruise tourism services. At first, researchers focused on Royal Caribbean’s robotic bartender arm, whereas other technologies such as digital signage, self-service options, facial recognition and virtual culinary experiences received less attention. However, the interest in exploring these last smart technologies has grown significantly since 2019. The adoption of RAISA in the cruise tourism service (ASCT) framework was proposed, identifying five major domains: cruise robotic technology, technology innovation, cruise passengers’ engagement behavior, cruise passengers’ technology readiness and privacy perception and knowledge expertise. These domains provide valuable guidance for future research in this field. Originality/value To the best of the authors’ knowledge, this is the first study to systematically analyze literature on the adoption of new technologies in cruise tourism services, specifically focusing on the major technologies available on cruise ships.",<method>artificial intelligence</method>,No methods remaining
2024,https://openalex.org/W4390913521,Social Sciences,A Review of Intraocular Lens Power Calculation Formulas Based on Artificial Intelligence,"Purpose: The proper selection of an intraocular lens power calculation formula is an essential aspect of cataract surgery. This study evaluated the accuracy of artificial intelligence-based formulas. Design: Systematic review. Methods: This review comprises articles evaluating the exactness of artificial intelligence-based formulas published from 2017 to July 2023. The papers were identified by a literature search of various databases (Pubmed/MEDLINE, Google Scholar, Crossref, Cochrane Library, Web of Science, and SciELO) using the terms “IOL formulas”, “FullMonte”, “Ladas”, “Hill-RBF”, “PEARL-DGS”, “Kane”, “Karmona”, “Hoffer QST”, and “Nallasamy”. In total, 25 peer-reviewed articles in English with the maximum sample and the largest number of compared formulas were examined. Results: The scores of the mean absolute error and percentage of patients within ±0.5 D and ±1.0 D were used to estimate the exactness of the formulas. In most studies the Kane formula obtained the smallest mean absolute error and the highest percentage of patients within ±0.5 D and ±1.0 D. Second place was typically achieved by the PEARL DGS formula. The limitations of the studies were also discussed. Conclusions: Kane seems to be the most accurate artificial intelligence-based formula. PEARL DGS also gives very good results. Hoffer QST, Karmona, and Nallasamy are the newest, and need further evaluation.","<method>FullMonte</method>, <method>Ladas</method>, <method>Hill-RBF</method>, <method>PEARL-DGS</method>, <method>Kane</method>, <method>Karmona</method>, <method>Hoffer QST</method>, <method>Nallasamy</method>",No methods remaining
2024,https://openalex.org/W4391065816,Social Sciences,Multi-criteria decision making for solar power - Wind power plant site selection using a GIS-intuitionistic fuzzy-based approach with an application in the Netherlands,"The development of a country cannot be realized only through the amount of energy it produces and its industrialization. In a country where its people are left homeless and poor, and its cultural and natural riches are destroyed, the electricity produced is not a measure of development on its own. Development and progress must be considered from a holistic perspective that includes the country's geographical structure, all its living creatures, culture, urban and social structure as a whole. In this respect, the transition to renewable energy is imperative. One of the most widely used renewable energies in the Netherlands is solar and wind energy. For these power plants, site selection is an important factor in reducing the installation cost of the wind and solar power plant and achieving maximum efficiency during operation. This paves the way for the study of a site selection problem. In this study, we first investigate possible locations for solar-wind power plant installation for 12 regions of the Netherlands, namely Noord Holland, Gelderland, Friesland, North Brabant, Drenthe, Groningen, Zeeland (Middelburg), Utrecht, Zuid Holland, Limburg, Over Ijssel and Flevoland, using GIS as a mapping method, and then apply a Intuitionistic fuzzy-based approach to the problem to obtain the optimal locations for both solar and wind energy. Furthermore, the results of two methods (GIS and Intuitionistic fuzzy-based approach) are compared to obtain more accurate results. The results show that 35317.2 km2 is suitable for solar power plant and 34844.5 km2 is suitable for wind turbine, but only 34875.8 km2 is suitable for solar-wind power plan installation.",<method>Intuitionistic fuzzy-based approach</method>,No methods remaining
2024,https://openalex.org/W4392516399,Social Sciences,Artificial intelligence in dermatology: advancements and challenges in skin of color,"Abstract Artificial intelligence (AI) uses algorithms and large language models in computers to simulate human‐like problem‐solving and decision‐making. AI programs have recently acquired widespread popularity in the field of dermatology through the application of online tools in the assessment, diagnosis, and treatment of skin conditions. A literature review was conducted using PubMed and Google Scholar analyzing recent literature (from the last 10 years through October 2023) to evaluate current AI programs in use for dermatologic purposes, identifying challenges in this technology when applied to skin of color (SOC), and proposing future steps to enhance the role of AI in dermatologic practice. Challenges surrounding AI and its application to SOC stem from the underrepresentation of SOC in datasets and issues with image quality and standardization. With these existing issues, current AI programs inevitably do worse at identifying lesions in SOC. Additionally, only 30% of the programs identified in this review had data reported on their use in dermatology, specifically in SOC. Significant development of these applications is required for the accurate depiction of darker skin tone images in datasets. More research is warranted in the future to better understand the efficacy of AI in aiding diagnosis and treatment options for SOC patients.","<method>algorithms</method>, <method>large language models</method>",No methods remaining
2024,https://openalex.org/W4392592756,Social Sciences,Beyond Discrimination: Generative AI Applications and Ethical Challenges in Forensic Psychiatry,"The advent and growing popularity of generative artificial intelligence (GenAI) holds the potential to revolutionise AI applications in forensic psychiatry and criminal justice, which traditionally relied on discriminative AI algorithms. Generative AI models mark a significant shift from the previously prevailing paradigm through their ability to generate seemingly new realistic data and analyse and integrate a vast amount of unstructured content from different data formats. This potential extends beyond reshaping conventional practices, like risk assessment, diagnostic support, and treatment and rehabilitation plans, to creating new opportunities in previously underexplored areas, such as training and education. This paper examines the transformative impact of generative artificial intelligence on AI applications in forensic psychiatry and criminal justice. First, it introduces generative AI and its prevalent models. Following this, it reviews the current applications of discriminative AI in forensic psychiatry. Subsequently, it presents a thorough exploration of the potential of generative AI to transform established practices and introduce novel applications through multimodal generative models, data generation and data augmentation. Finally, it provides a comprehensive overview of ethical and legal issues associated with deploying generative AI models, focusing on their impact on individuals as well as their broader societal implications. In conclusion, this paper aims to contribute to the ongoing discourse concerning the dynamic challenges of generative AI applications in forensic contexts, highlighting potential opportunities, risks, and challenges. It advocates for interdisciplinary collaboration and emphasises the necessity for thorough, responsible evaluations of generative AI models before widespread adoption into domains where decisions with substantial life-altering consequences are routinely made.","<method>generative artificial intelligence (GenAI)</method>, <method>discriminative AI algorithms</method>, <method>generative AI models</method>, <method>multimodal generative models</method>, <method>data generation</method>, <method>data augmentation</method>",<method>generative AI models</method><method>multimodal generative models</method>
2024,https://openalex.org/W4392911004,Social Sciences,Unlocking the Potential of Artificial Intelligence in Fashion Design and E-Commerce Applications: The Case of Midjourney,"The fashion industry has shown increasing interest in applying artificial intelligence (AI), yet there is a significant gap in exploring the potential of emerging diffusion-modeling-based AI image-generation systems for fashion design and commerce. Therefore, this study aims to assess the effectiveness of Midjourney, one such AI system, in both fashion design and related commerce applications. We employed the action research approach with the Functional, Expressive, and Aesthetic (FEA) Consumer Needs Model as the theoretical framework. Our research comprised three stages: refining an initial idea into well-defined textual design concepts, facilitating concept development, and validating the preceding observations and reflections by creating a new line of hemp-based products that were evaluated by targeted consumers through an online survey. Findings reveal that this AI tool can assist fashion designers in creating both visually expressive attire and ready-to-wear products, meeting defined design criteria and consumer needs. Midjourney shows promise in streamlining the fashion design process by enhancing ideation and optimizing design details. Potential e-commercial applications of such AI systems were proposed, benefiting physical and digital fashion businesses. It is noted that, to date, the major limitations of using Midjourney encompass its restriction to only facilitating early fashion design stages and necessitating substantial involvement from designers.","<method>diffusion-modeling-based AI image-generation systems</method>, <method>Midjourney</method>",<method>diffusion-modeling-based AI image-generation systems</method>
2024,https://openalex.org/W4394627367,Social Sciences,ETPNav: Evolving Topological Planning for Vision-Language Navigation in Continuous Environments,"Vision-language navigation is a task that requires an agent to follow instructions to navigate in environments. It becomes increasingly crucial in the field of embodied AI, with potential applications in autonomous navigation, search and rescue, and human-robot interaction. In this paper, we propose to address a more practical yet challenging counterpart setting - vision-language navigation in continuous environments (VLN-CE). To develop a robust VLN-CE agent, we propose a new navigation framework, ETPNav, which focuses on two critical skills: 1) the capability to abstract environments and generate long-range navigation plans, and 2) the ability of obstacle-avoiding control in continuous environments. ETPNav performs online topological mapping of environments by self-organizing predicted waypoints along a traversed path, without prior environmental experience. It privileges the agent to break down the navigation procedure into high-level planning and low-level control. Concurrently, ETPNav utilizes a transformer-based cross-modal planner to generate navigation plans based on topological maps and instructions. The plan is then performed through an obstacle-avoiding controller that leverages a trial-and-error heuristic to prevent navigation from getting stuck in obstacles. Experimental results demonstrate the effectiveness of the proposed method. ETPNav yields more than 10% and 20% improvements over prior state-of-the-art on R2R-CE and RxR-CE datasets, respectively. Our code is available at <uri xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">https://github.com/MarSaKi/ETPNav</uri> .","<method>transformer-based cross-modal planner</method>, <method>trial-and-error heuristic</method>",No methods remaining
2024,https://openalex.org/W4390618081,Social Sciences,Making Sense of Machine Learning: A Review of Interpretation Techniques and Their Applications,"Transparency in AI models is essential for promoting human–AI collaboration and ensuring regulatory compliance. However, interpreting these models is a complex process influenced by various methods and datasets. This study presents a comprehensive overview of foundational interpretation techniques, meticulously referencing the original authors and emphasizing their pivotal contributions. Recognizing the seminal work of these pioneers is imperative for contextualizing the evolutionary trajectory of interpretation in the field of AI. Furthermore, this research offers a retrospective analysis of interpretation techniques, critically evaluating their inherent strengths and limitations. We categorize these techniques into model-based, representation-based, post hoc, and hybrid methods, delving into their diverse applications. Furthermore, we analyze publication trends over time to see how the adoption of advanced computational methods within various categories of interpretation techniques has shaped the development of AI interpretability over time. This analysis highlights a notable preference shift towards data-driven approaches in the field. Moreover, we consider crucial factors such as the suitability of these techniques for generating local or global insights and their compatibility with different data types, including images, text, and tabular data. This structured categorization serves as a guide for practitioners navigating the landscape of interpretation techniques in AI. In summary, this review not only synthesizes various interpretation techniques but also acknowledges the contributions of their original authors. By emphasizing the origins of these techniques, we aim to enhance AI model explainability and underscore the importance of recognizing biases, uncertainties, and limitations inherent in the methods and datasets. This approach promotes the ethical and practical use of interpretation insights, empowering AI practitioners, researchers, and professionals to make informed decisions when selecting techniques for responsible AI implementation in real-world scenarios.","<method>model-based methods</method>, <method>representation-based methods</method>, <method>post hoc methods</method>, <method>hybrid methods</method>, <method>data-driven approaches</method>",<method>model-based methods</method><method>representation-based methods</method><method>hybrid methods</method>
2024,https://openalex.org/W4390938718,Social Sciences,A Credible and Fair Federated Learning Framework Based on Blockchain,"Federated learning enables cooperative computation between multiple participants while protecting user privacy. Currently, federated learning algorithms assume that all participants are trustworthy and their systems are secure. However, the following problems arise in real-world scenarios: (1) Malicious clients disrupt federated learning through model poisoning and data poisoning attacks. Although some research has proposed secure aggregation methods to solve this problem, most methods have limitations. (2) Due to the variance in data quality and computational resources among participants, rewards cannot be distributed equally. Some clients also exhibit free-rider behavior, seeking to cheat the reward system and manipulate global models. Evaluating client contribution and distributing rewards also present challenges. <p xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">To address these challenges, we design a trustworthy federated framework to ensure secure computing throughout the federated task process. First, we propose a malicious model detection method for secure model aggregation. Then, we also propose a fair method of assessing contribution to identify client-side free-riding behavior. Lastly, we develop a computation process grounded in blockchain and smart contracts to guarantee the trustworthiness and fairness of federated tasks. To validate the performance of our framework, we simulate different types of client attacks and contribution evaluation scenarios on several open-source datasets. The experiments show that our framework guarantees the federated task's credibility and achieves fair client contribution evaluation.","<method>malicious model detection method for secure model aggregation</method>, <method>fair method of assessing contribution to identify client-side free-riding behavior</method>",No methods remaining
2024,https://openalex.org/W4391723759,Social Sciences,Artificial Intelligence to Automate Network Meta-Analyses: Four Case Studies to Evaluate the Potential Application of Large Language Models,"The emergence of artificial intelligence, capable of human-level performance on some tasks, presents an opportunity to revolutionise development of systematic reviews and network meta-analyses (NMAs). In this pilot study, we aim to assess use of a large-language model (LLM, Generative Pre-trained Transformer 4 [GPT-4]) to automatically extract data from publications, write an R script to conduct an NMA and interpret the results. We considered four case studies involving binary and time-to-event outcomes in two disease areas, for which an NMA had previously been conducted manually. For each case study, a Python script was developed that communicated with the LLM via application programming interface (API) calls. The LLM was prompted to extract relevant data from publications, to create an R script to be used to run the NMA and then to produce a small report describing the analysis. The LLM had a > 99% success rate of accurately extracting data across 20 runs for each case study and could generate R scripts that could be run end-to-end without human input. It also produced good quality reports describing the disease area, analysis conducted, results obtained and a correct interpretation of the results. This study provides a promising indication of the feasibility of using current generation LLMs to automate data extraction, code generation and NMA result interpretation, which could result in significant time savings and reduce human error. This is provided that routine technical checks are performed, as recommend for human-conducted analyses. Whilst not currently 100% consistent, LLMs are likely to improve with time.","<method>large-language model (LLM, Generative Pre-trained Transformer 4 [GPT-4])</method>","<method>large-language model (LLM, Generative Pre-trained Transformer 4 [GPT-4])</method>"
2024,https://openalex.org/W4392186815,Social Sciences,BioLORD-2023: semantic textual representations fusing large language models and clinical knowledge graph insights,"Abstract Objective In this study, we investigate the potential of large language models (LLMs) to complement biomedical knowledge graphs in the training of semantic models for the biomedical and clinical domains. Materials and Methods Drawing on the wealth of the Unified Medical Language System knowledge graph and harnessing cutting-edge LLMs, we propose a new state-of-the-art approach for obtaining high-fidelity representations of biomedical concepts and sentences, consisting of 3 steps: an improved contrastive learning phase, a novel self-distillation phase, and a weight averaging phase. Results Through rigorous evaluations of diverse downstream tasks, we demonstrate consistent and substantial improvements over the previous state of the art for semantic textual similarity (STS), biomedical concept representation (BCR), and clinically named entity linking, across 15+ datasets. Besides our new state-of-the-art biomedical model for English, we also distill and release a multilingual model compatible with 50+ languages and finetuned on 7 European languages. Discussion Many clinical pipelines can benefit from our latest models. Our new multilingual model enables a range of languages to benefit from our advancements in biomedical semantic representation learning, opening a new avenue for bioinformatics researchers around the world. As a result, we hope to see BioLORD-2023 becoming a precious tool for future biomedical applications. Conclusion In this article, we introduced BioLORD-2023, a state-of-the-art model for STS and BCR designed for the clinical domain.","<method>contrastive learning</method>, <method>self-distillation</method>, <method>weight averaging</method>",<method>contrastive learning</method><method>self-distillation</method><method>weight averaging</method>
2024,https://openalex.org/W4393281169,Social Sciences,Artificial intelligence techniques in financial trading: A systematic literature review,"Artificial Intelligence (AI) approaches have been increasingly used in financial markets as technology advances. In this research paper, we conduct a Systematic Literature Review (SLR) that studies financial trading approaches through AI techniques. It reviews 143 research articles that implemented AI techniques in financial trading markets. Accordingly, it presents several findings and observations after reviewing the papers from the following perspectives: the financial trading market and the asset type, the trading analysis type considered along with the AI technique, and the AI techniques utilized in the trading market, the estimation and performance metrics of the proposed models. The selected research articles were published between 2015 and 2023, and this review addresses four RQs. After analyzing the selected research articles, we observed 8 financial markets used in building predictive models. Moreover, we found that technical analysis is more adopted compared to fundamental analysis. Furthermore, 16% of the selected research articles entirely automate the trading process. In addition, we identified 40 different AI techniques that are used as standalone and hybrid models. Among these techniques, deep learning techniques are the most frequently used in financial trading markets. Building prediction models for financial markets using AI is a promising field of research, and academics have already deployed several machine learning models. As a result of this evaluation, we provide recommendations and guidance to researchers.","<method>deep learning techniques</method>, <method>machine learning models</method>",No methods remaining
2024,https://openalex.org/W4394620240,Social Sciences,Human-AI interaction in skin cancer diagnosis: a systematic review and meta-analysis,"Abstract The development of diagnostic tools for skin cancer based on artificial intelligence (AI) is increasing rapidly and will likely soon be widely implemented in clinical use. Even though the performance of these algorithms is promising in theory, there is limited evidence on the impact of AI assistance on human diagnostic decisions. Therefore, the aim of this systematic review and meta-analysis was to study the effect of AI assistance on the accuracy of skin cancer diagnosis. We searched PubMed, Embase, IEE Xplore, Scopus and conference proceedings for articles from 1/1/2017 to 11/8/2022. We included studies comparing the performance of clinicians diagnosing at least one skin cancer with and without deep learning-based AI assistance. Summary estimates of sensitivity and specificity of diagnostic accuracy with versus without AI assistance were computed using a bivariate random effects model. We identified 2983 studies, of which ten were eligible for meta-analysis. For clinicians without AI assistance, pooled sensitivity was 74.8% (95% CI 68.6–80.1) and specificity was 81.5% (95% CI 73.9–87.3). For AI-assisted clinicians, the overall sensitivity was 81.1% (95% CI 74.4–86.5) and specificity was 86.1% (95% CI 79.2–90.9). AI benefitted medical professionals of all experience levels in subgroup analyses, with the largest improvement among non-dermatologists. No publication bias was detected, and sensitivity analysis revealed that the findings were robust. AI in the hands of clinicians has the potential to improve diagnostic accuracy in skin cancer diagnosis. Given that most studies were conducted in experimental settings, we encourage future studies to further investigate these potential benefits in real-life settings.","<method>deep learning-based AI assistance</method>, <method>bivariate random effects model</method>",No methods remaining
2024,https://openalex.org/W4401726216,Social Sciences,Improving accuracy of GPT-3/4 results on biomedical data using a retrieval-augmented language model,"Large language models (LLMs) have made a significant impact on the fields of general artificial intelligence. General purpose LLMs exhibit strong logic and reasoning skills and general world knowledge but can sometimes generate misleading results when prompted on specific subject areas. LLMs trained with domain-specific knowledge can reduce the generation of misleading information (i.e. hallucinations) and enhance the precision of LLMs in specialized contexts. Training new LLMs on specific corpora however can be resource intensive. Here we explored the use of a retrieval-augmented generation (RAG) model which we tested on literature specific to a biomedical research area. OpenAI’s GPT-3.5, GPT-4, Microsoft’s Prometheus, and a custom RAG model were used to answer 19 questions pertaining to diffuse large B-cell lymphoma (DLBCL) disease biology and treatment. Eight independent reviewers assessed LLM responses based on accuracy, relevance, and readability, rating responses on a 3-point scale for each category. These scores were then used to compare LLM performance. The performance of the LLMs varied across scoring categories. On accuracy and relevance, the RAG model outperformed other models with higher scores on average and the most top scores across questions. GPT-4 was more comparable to the RAG model on relevance versus accuracy. By the same measures, GPT-4 and GPT-3.5 had the highest scores for readability of answers when compared to the other LLMs. GPT-4 and 3.5 also had more answers with hallucinations than the other LLMs, due to non-existent references and inaccurate responses to clinical questions. Our findings suggest that an oncology research-focused RAG model may outperform general-purpose LLMs in accuracy and relevance when answering subject-related questions. This framework can be tailored to Q&amp;A in other subject areas. Further research will help understand the impact of LLM architectures, RAG methodologies, and prompting techniques in answering questions across different subject areas.","<method>retrieval-augmented generation (RAG) model</method>, <method>OpenAI’s GPT-3.5</method>, <method>OpenAI’s GPT-4</method>, <method>Microsoft’s Prometheus</method>",<method>retrieval-augmented generation (RAG) model</method><method>OpenAI’s GPT-3.5</method><method>OpenAI’s GPT-4</method><method>Microsoft’s Prometheus</method>
2024,https://openalex.org/W4403618367,Social Sciences,"Exploring Rich Subjective Quality Information for Image Quality
  Assessment in the Wild","Traditional in the wild image quality assessment (IQA) models are generally trained with the quality labels of mean opinion score (MOS), while missing the rich subjective quality information contained in the quality ratings, for example, the standard deviation of opinion scores (SOS) or even distribution of opinion scores (DOS). In this paper, we propose a novel IQA method named RichIQA to explore the rich subjective rating information beyond MOS to predict image quality in the wild. RichIQA is characterized by two key novel designs: (1) a three-stage image quality prediction network which exploits the powerful feature representation capability of the Convolutional vision Transformer (CvT) and mimics the short-term and long-term memory mechanisms of human brain; (2) a multi-label training strategy in which rich subjective quality information like MOS, SOS and DOS are concurrently used to train the quality prediction network. Powered by these two novel designs, RichIQA is able to predict the image quality in terms of a distribution, from which the mean image quality can be subsequently obtained. Extensive experimental results verify that the three-stage network is tailored to predict rich quality information, while the multi-label training strategy can fully exploit the potentials within subjective quality rating and enhance the prediction performance and generalizability of the network. RichIQA outperforms state-of-the-art competitors on multiple large-scale in the wild IQA databases with rich subjective rating labels. The code of RichIQA will be made publicly available on GitHub.","<method>Convolutional vision Transformer (CvT)</method>, <method>three-stage image quality prediction network</method>, <method>multi-label training strategy</method>",<method>Convolutional vision Transformer (CvT)</method>
2024,https://openalex.org/W4390506438,Social Sciences,Artificial intelligence for oral squamous cell carcinoma detection based on oral photographs: A comprehensive literature review,"Abstract Introduction Oral squamous cell carcinoma (OSCC) presents a significant global health challenge. The integration of artificial intelligence (AI) and computer vision holds promise for the early detection of OSCC through the analysis of digitized oral photographs. This literature review explores the landscape of AI‐driven OSCC automatic detection, assessing both the performance and limitations of the current state of the art. Materials and Methods An electronic search using several data base was conducted, and a systematic review performed in accordance with PRISMA guidelines (CRD42023441416). Results Several studies have demonstrated remarkable results for this task, consistently achieving sensitivity rates exceeding 85% and accuracy rates surpassing 90%, often encompassing around 1000 images. The review scrutinizes these studies, shedding light on their methodologies, including the use of recent machine learning and pattern recognition approaches coupled with different supervision strategies. However, comparing the results from different papers is challenging due to variations in the datasets used. Discussion Considering these findings, this review underscores the urgent need for more robust and reliable datasets in the field of OSCC detection. Furthermore, it highlights the potential of advanced techniques such as multi‐task learning, attention mechanisms, and ensemble learning as crucial tools in enhancing the accuracy and sensitivity of OSCC detection through oral photographs. Conclusion These insights collectively emphasize the transformative impact of AI‐driven approaches on early OSCC diagnosis, with the potential to significantly improve patient outcomes and healthcare practices.","<method>machine learning</method>, <method>pattern recognition</method>, <method>multi-task learning</method>, <method>attention mechanisms</method>, <method>ensemble learning</method>",<method>machine learning</method><method>multi-task learning</method><method>attention mechanisms</method><method>ensemble learning</method>
2024,https://openalex.org/W4390917123,Social Sciences,Decision-making for solar panel selection using Sugeno-Weber triangular norm-based on q-rung orthopair fuzzy information,"Solar power is an alternative energy derived from the sun. Solar power is more environmentally friendly and sustainable than burning fossil fuels which releases harmful greenhouse gas emissions. Therefore, this study aims to evaluate a reliable solar panel based on certain characteristics by incorporating the theory of the decision-making process. To serve this goal, this study discusses a well-known aggregation model of the q-rung orthopair fuzzy set, which is a broader and flexible environment of fuzzy sets and intuitionistic fuzzy sets used to handle unpredictable information of human opinions. The key components of this article are to demonstrate some realistic operations of Sugeno–Weber triangular norms considering q-rung orthopair fuzzy information. These operations provide authentic estimated information during the decision-making process. We developed a class of new aggregation operators using the q-rung orthopair fuzzy information system, including q-rung orthopair fuzzy Sugeno–Weber power weighted average and q-rung orthopair fuzzy Sugeno–Weber power weighted geometric operators. Some realistic characteristics and special cases are also demonstrated to show the compatibility of the proposed methodologies. An innovative approach to the multi-attribute decision-making problem is utilized to resolve different real-life applications considering various criteria or attributes. To show the intensity and applicability of the proposed approaches, we explored a numerical example for efficient solar panel selection based on the proposed methodologies. Furthermore, we presented a comprehensive comparison technique to compare the findings of the existing methods with the proposed aggregation approaches. Finally, the proposed research work is summarized, and the future prospects are discussed.","<method>q-rung orthopair fuzzy set</method>, <method>aggregation operators using the q-rung orthopair fuzzy information system</method>, <method>q-rung orthopair fuzzy Sugeno–Weber power weighted average</method>, <method>q-rung orthopair fuzzy Sugeno–Weber power weighted geometric operators</method>, <method>multi-attribute decision-making problem approach</method>",<method>q-rung orthopair fuzzy set</method><method>q-rung orthopair fuzzy Sugeno–Weber power weighted average</method><method>q-rung orthopair fuzzy Sugeno–Weber power weighted geometric operators</method>
2024,https://openalex.org/W4391096835,Social Sciences,Diagnostic Performance Comparison between Generative AI and Physicians: A Systematic Review and Meta-Analysis,"Abstract Background The rapid advancement of generative artificial intelligence (AI) has led to the wide dissemination of models with exceptional understanding and generation of human language. Their integration into healthcare has shown potential for improving medical diagnostics, yet a comprehensive diagnostic performance evaluation of generative AI models and the comparison of their diagnostic performance with that of physicians has not been extensively explored. Methods In this systematic review and meta-analysis, a comprehensive search of Medline, Scopus, Web of Science, Cochrane Central, and MedRxiv was conducted for studies published from June 2018 through December 2023, focusing on those that validate generative AI models for diagnostic tasks. The risk of bias was assessed using the Prediction Model Study Risk of Bias Assessment Tool. Meta-regression was performed to summarize the performance of the models and to compare the accuracy of the models with that of physicians. Results The search resulted in 54 studies being included in the meta-analysis. Nine generative AI models were evaluated across 17 medical specialties. The quality assessment indicated a high risk of bias in the majority of studies, primarily due to small sample sizes. The overall accuracy for generative AI models across 54 studies was 56.9% (95% confidence interval [CI]: 51.0–62.7%). The meta-analysis demonstrated that, on average, physicians exceeded the accuracy of the models (difference in accuracy: 14.4% [95% CI: 4.9–23.8%], p-value =0.004). However, both Prometheus (Bing) and GPT-4 showed slightly better performance compared to non-experts (-2.3% [95% CI: -27.0–22.4%], p-value = 0.848 and -0.32% [95% CI: -14.4–13.7%], p-value = 0.962), but slightly underperformed when compared to experts (10.9% [95% CI: -13.1–35.0%], p-value = 0.356 and 12.9% [95% CI: 0.15–25.7%], p-value = 0.048). The sub-analysis revealed significantly improved accuracy in the fields of Gynecology, Pediatrics, Orthopedic surgery, Plastic surgery, and Otolaryngology, while showing reduced accuracy for Neurology, Psychiatry, Rheumatology, and Endocrinology compared to that of General Medicine. No significant heterogeneity was observed based on the risk of bias. Conclusions Generative AI exhibits promising diagnostic capabilities, with accuracy varying significantly by model and medical specialty. Although they have not reached the reliability of expert physicians, the findings suggest that generative AI models have the potential to enhance healthcare delivery and medical education, provided they are integrated with caution and their limitations are well-understood. Key Points Question: What is the diagnostic accuracy of generative AI models and how does this accuracy compare to that of physicians? Findings: This meta-analysis found that generative AI models have a pooled accuracy of 56.9% (95% confidence interval: 51.0–62.7%). The accuracy of expert physicians exceeds that of AI in all specialties, however, some generative AI models are comparable to non-expert physicians. Meaning: The diagnostic performance of generative AI models suggests that they do not match the level of experienced physicians but that they may have potential applications in healthcare delivery and medical education.",<method>generative AI models</method>,<method>generative AI models</method>
2024,https://openalex.org/W4391560032,Social Sciences,Artificial Intelligence Language Model Performance for Rapid Intraoperative Queries in Plastic Surgery: ChatGPT and the Deep Inferior Epigastric Perforator Flap,"Background: The integration of artificial intelligence in healthcare has led to the development of large language models that can address various medical queries, including intraoperatively. This study investigates the potential of ChatGPT in addressing intraoperative questions during the deep inferior epigastric perforator flap procedure. Methods: A series of six intraoperative questions specific to the DIEP flap procedure, derived from real-world clinical scenarios, were proposed to ChatGPT. A panel of four experienced board-certified plastic surgeons evaluated ChatGPT’s performance in providing accurate, relevant, and comprehensible responses. Results: The Likert scale demonstrated to be medically accurate, systematic in presentation, and logical when providing alternative solutions. The mean readability score of the Flesch Reading Ease Score was 28.7 (±0.8), the Flesch–Kincaid Grade Level was 12.4 (±0.5), and the Coleman–Liau Index was 14.5 (±0.5). Suitability-wise, the DISCERN score of ChatGPT was 48 (±2.5) indicating suitable and comprehensible language for experts. Conclusions: Generative AI tools such as ChatGPT can serve as a supplementary tool for surgeons to offer valuable insights and foster intraoperative problem-solving abilities. However, it lacks consideration of individual patient factors and surgical nuances. Nevertheless, further refinement of its training data and rigorous scrutiny under experts to ensure the accuracy and up-to-date nature of the information holds the potential for it to be utilized in the surgical field.","<method>large language models</method>, <method>ChatGPT</method>",No methods remaining
2024,https://openalex.org/W4392447932,Social Sciences,Systematic Review of Large Language Models for Patient Care: Current Applications and Challenges,"Abstract The introduction of large language models (LLMs) into clinical practice promises to improve patient education and empowerment, thereby personalizing medical care and broadening access to medical knowledge. Despite the popularity of LLMs, there is a significant gap in systematized information on their use in patient care. Therefore, this systematic review aims to synthesize current applications and limitations of LLMs in patient care using a data-driven convergent synthesis approach. We searched 5 databases for qualitative, quantitative, and mixed methods articles on LLMs in patient care published between 2022 and 2023. From 4,349 initial records, 89 studies across 29 medical specialties were included, primarily examining models based on the GPT-3.5 (53.2%, n=66 of 124 different LLMs examined per study) and GPT-4 (26.6%, n=33/124) architectures in medical question answering, followed by patient information generation, including medical text summarization or translation, and clinical documentation. Our analysis delineates two primary domains of LLM limitations: design and output. Design limitations included 6 second-order and 12 third-order codes, such as lack of medical domain optimization, data transparency, and accessibility issues, while output limitations included 9 second-order and 32 third-order codes, for example, non-reproducibility, non-comprehensiveness, incorrectness, unsafety, and bias. In conclusion, this study is the first review to systematically map LLM applications and limitations in patient care, providing a foundational framework and taxonomy for their implementation and evaluation in healthcare settings.","<method>large language models (LLMs)</method>, <method>GPT-3.5</method>, <method>GPT-4</method>",<method>GPT-3.5</method><method>GPT-4</method>
2024,https://openalex.org/W4393159297,Social Sciences,PathAsst: A Generative Foundation AI Assistant towards Artificial General Intelligence of Pathology,"As advances in large language models (LLMs) and multimodal techniques continue to mature, the development of general-purpose multimodal large language models (MLLMs) has surged, offering significant applications in interpreting natural images. However, the field of pathology has largely remained untapped, particularly in gathering high-quality data and designing comprehensive model frameworks. To bridge the gap in pathology MLLMs, we present PathAsst, a multimodal generative foundation AI assistant to revolutionize diagnostic and predictive analytics in pathology. The development of PathAsst involves three pivotal steps: data acquisition, CLIP model adaptation, and the training of PathAsst's multimodal generative capabilities. Firstly, we collect over 207K high-quality pathology image-text pairs from authoritative sources. Leveraging the advanced power of ChatGPT, we generate over 180K instruction-following samples. Furthermore, we devise additional instruction-following data specifically tailored for invoking eight pathology-specific sub-models we prepared, allowing the PathAsst to effectively collaborate with these models, enhancing its diagnostic ability. Secondly, by leveraging the collected data, we construct PathCLIP, a pathology-dedicated CLIP, to enhance PathAsst's capabilities in interpreting pathology images. Finally, we integrate PathCLIP with the Vicuna-13b and utilize pathology-specific instruction-tuning data to enhance the multimodal generation capacity of PathAsst and bolster its synergistic interactions with sub-models. The experimental results of PathAsst show the potential of harnessing AI-powered generative foundation model to improve pathology diagnosis and treatment processes. We open-source our dataset, as well as a comprehensive toolkit for extensive pathology data collection and preprocessing at https://github.com/superjamessyx/Generative-Foundation-AI-Assistant-for-Pathology.","<method>CLIP model adaptation</method>, <method>multimodal generative foundation AI assistant</method>, <method>instruction-tuning</method>",<method>CLIP model adaptation</method><method>instruction-tuning</method>
2024,https://openalex.org/W4393222088,Social Sciences,Methodological insights into ChatGPT’s screening performance in systematic reviews,"Abstract Background The screening process for systematic reviews and meta-analyses in medical research is a labor-intensive and time-consuming task. While machine learning and deep learning have been applied to facilitate this process, these methods often require training data and user annotation. This study aims to assess the efficacy of ChatGPT, a large language model based on the Generative Pretrained Transformers (GPT) architecture, in automating the screening process for systematic reviews in radiology without the need for training data. Methods A prospective simulation study was conducted between May 2nd and 24th, 2023, comparing ChatGPT’s performance in screening abstracts against that of general physicians (GPs). A total of 1198 abstracts across three subfields of radiology were evaluated. Metrics such as sensitivity, specificity, positive and negative predictive values (PPV and NPV), workload saving, and others were employed. Statistical analyses included the Kappa coefficient for inter-rater agreement, ROC curve plotting, AUC calculation, and bootstrapping for p-values and confidence intervals. Results ChatGPT completed the screening process within an hour, while GPs took an average of 7–10 days. The AI model achieved a sensitivity of 95% and an NPV of 99%, slightly outperforming the GPs’ sensitive consensus (i.e., including records if at least one person includes them). It also exhibited remarkably low false negative counts and high workload savings, ranging from 40 to 83%. However, ChatGPT had lower specificity and PPV compared to human raters. The average Kappa agreement between ChatGPT and other raters was 0.27. Conclusions ChatGPT shows promise in automating the article screening phase of systematic reviews, achieving high sensitivity and workload savings. While not entirely replacing human expertise, it could serve as an efficient first-line screening tool, particularly in reducing the burden on human resources. Further studies are needed to fine-tune its capabilities and validate its utility across different medical subfields.","<method>machine learning</method>, <method>deep learning</method>, <method>ChatGPT</method>, <method>Generative Pretrained Transformers (GPT) architecture</method>",<method>machine learning</method><method>deep learning</method><method>Generative Pretrained Transformers (GPT) architecture</method>
2024,https://openalex.org/W4394835724,Social Sciences,Machine Learning-Assisted Design of Advanced Polymeric Materials,"ConspectusPolymeric material research is encountering a new paradigm driven by machine learning (ML) and big data. The ML-assisted design has proven to be a successful approach for designing novel high-performance polymeric materials. This goal is mainly achieved through the following procedure: structure representation and database construction, establishment of a ML-based property prediction model, virtual design and high-throughput screening. The key to this approach lies in training ML models that delineate structure–property relationships based on available polymer data (e.g., structure, component, and property data), enabling the screening of promising polymers that satisfy the targeted property requirements. However, the relative scarcity of high-quality polymer data and the complex polymeric multiscale structure–property relationships pose challenges for this ML-assisted design method, such as data and modeling challenges.In this Account, we summarize the state-of-the-art advancements concerning the ML-assisted design of polymeric materials. Regarding structure representation and database construction, the digital representations of polymers are the predominant methods in cheminformatics along with some newly developed methods that integrate the polymeric multiscale structure characteristics. When establishing a ML-based property prediction model, the key is choosing and optimizing ML models to attain high-precision predictions across a vast chemical structure space. Advanced ML algorithms, such as transfer learning and multitask learning, have been utilized to address the data and modeling challenges. During the ML-assisted screening process, by defining and combining polymer genes, virtual polymer candidates are generated, and subsequently, their properties are predicted and high-throughput screened using ML property prediction models. Finally, the promising polymers identified through this approach are verified by computer simulations and experiments.We provide an overview of our recent efforts toward developing ML-assisted design approaches for discovering advanced polymeric materials and emphasize the intricate nature of polymer structural design. To well describe the multiscale structures of polymers, new structure representation methods, such as polymer fingerprint and cross-linking descriptors, were developed. Moreover, a multifidelity learning method was proposed to leverage the multisource isomerous polymer data from experiments and simulations. Additionally, graph neural networks and Bayesian optimization methods have been developed and applied for predicting polymer properties as well as designing polymer structures and compositions.Finally, we identify the current challenges and point out the development directions in this emerging field. It is highly desirable to establish new structure representation and advanced ML modeling methods for polymeric materials, particularly when constructing polymer large models based on chemical language. Through this Account, we seek to stimulate further interest and foster active collaborations for developing ML-assisted design approaches and realizing the innovation of advanced polymeric materials.","<method>transfer learning</method>, <method>multitask learning</method>, <method>multifidelity learning</method>, <method>graph neural networks</method>, <method>Bayesian optimization</method>",<method>transfer learning</method><method>multifidelity learning</method><method>graph neural networks</method><method>Bayesian optimization</method>
2024,https://openalex.org/W4395663988,Social Sciences,Navigating the Power of Artificial Intelligence in Risk Management: A Comparative Analysis,"This study presents a responsive analysis of the role of artificial intelligence (AI) in risk management, contrasting traditional approaches with those augmented by AI and highlighting the challenges and opportunities that emerge. AI, intense learning methodologies such as convolutional neural networks (CNNs), have been identified as pivotal in extracting meaningful insights from image data, a form of analysis that holds significant potential in identifying and managing risks across various industries. The research methodology involves a strategic selection and processing of images for analysis and introduces three case studies that serve as benchmarks for evaluation. These case studies showcase the application of AI, in place of image processing capabilities, to identify hazards, evaluate risks, and suggest control measures. The comparative evaluation focuses on the accuracy, relevance, and practicality of the AI-generated findings alongside the system’s response time and comprehensive understanding of the context. Results reveal that AI can significantly enhance risk assessment processes, offering rapid and detailed insights. However, the study also recognises the intrinsic limitations of AI in contextual interpretation, advocating for a synergy between technological and domain-specific expertise. The conclusion underscores the transformative potential of AI in risk management, supporting continued research to further integrate AI effectively into risk assessment frameworks.",<method>convolutional neural networks (CNNs)</method>,<method>convolutional neural networks (CNNs)</method>
2024,https://openalex.org/W4398169659,Social Sciences,The Sociodemographic Biases in Machine Learning Algorithms: A Biomedical Informatics Perspective,"Artificial intelligence models represented in machine learning algorithms are promising tools for risk assessment used to guide clinical and other health care decisions. Machine learning algorithms, however, may house biases that propagate stereotypes, inequities, and discrimination that contribute to socioeconomic health care disparities. The biases include those related to some sociodemographic characteristics such as race, ethnicity, gender, age, insurance, and socioeconomic status from the use of erroneous electronic health record data. Additionally, there is concern that training data and algorithmic biases in large language models pose potential drawbacks. These biases affect the lives and livelihoods of a significant percentage of the population in the United States and globally. The social and economic consequences of the associated backlash cannot be underestimated. Here, we outline some of the sociodemographic, training data, and algorithmic biases that undermine sound health care risk assessment and medical decision-making that should be addressed in the health care system. We present a perspective and overview of these biases by gender, race, ethnicity, age, historically marginalized communities, algorithmic bias, biased evaluations, implicit bias, selection/sampling bias, socioeconomic status biases, biased data distributions, cultural biases and insurance status bias, conformation bias, information bias and anchoring biases and make recommendations to improve large language model training data, including de-biasing techniques such as counterfactual role-reversed sentences during knowledge distillation, fine-tuning, prefix attachment at training time, the use of toxicity classifiers, retrieval augmented generation and algorithmic modification to mitigate the biases moving forward.","<method>knowledge distillation</method>, <method>fine-tuning</method>, <method>prefix attachment at training time</method>, <method>toxicity classifiers</method>, <method>retrieval augmented generation</method>, <method>algorithmic modification</method>",<method>knowledge distillation</method><method>fine-tuning</method><method>retrieval augmented generation</method>
2024,https://openalex.org/W4399244247,Social Sciences,Investigating influencing factors of learning satisfaction in AI ChatGPT for research: University students perspective,"This study investigates the determinants of ChatGPT adoption among university students and its impact on learning satisfaction. Utilizing the Technology Acceptance Model (TAM) and incorporating insights from interaction learning, collaborative learning, and information quality, a structural equation modeling approach was employed. This research collected valuable responses from 262 students at King Faisal University in Saudi Arabia through the use of self-report questionnaires. The data's reliability and validity were assessed using confirmation factor analysis, followed by path analysis to explore the hypotheses in the proposed model. The results indicate the pivotal roles of interaction learning and collaborative learning in fostering ChatGPT adoption. Social interaction played a significant role, as researchers engaging in conversations and knowledge-sharing expressed increased comfort with ChatGPT. Information quality was found to substantially influence researchers' decisions to continue using ChatGPT, emphasizing the need for ongoing improvement in the accuracy and relevance of content provided. Perceived ease of use and perceived usefulness played intermediary roles in linking ChatGPT engagement to learning satisfaction. User-friendly interfaces and perceived utility were identified as crucial factors affecting overall satisfaction levels. Notably, ChatGPT positively impacted learning motivation, indicating its potential to enhance student engagement and interest in learning. The study's findings have implications for educational practitioners seeking to improve the implementation of AI technologies in university students, emphasizing user-friendly design, collaborative learning, and factors influencing satisfaction. The study concludes with insights into the complex interplay between AI-powered tools, learning objectives, and motivation, highlighting the need for continued research to comprehensively understand these dynamics. This study investigates the determinants of ChatGPT adoption among university students and its impact on learning satisfaction. Utilizing the Technology Acceptance Model (TAM) and incorporating insights from interaction learning, collaborative learning, and information quality, a structural equation modeling approach was employed. This research collected valuable responses from 262 students at King Faisal University in Saudi Arabia through the use of self-report questionnaires. The data's reliability and validity were assessed using confirmation factor analysis, followed by path analysis to explore the hypotheses in the proposed model. The results indicate the pivotal roles of interaction learning and collaborative learning in fostering ChatGPT adoption. Social interaction played a significant role, as researchers engaging in conversations and knowledge-sharing expressed increased comfort with ChatGPT. Information quality was found to substantially influence researchers' decisions to continue using ChatGPT, emphasizing the need for ongoing improvement in the accuracy and relevance of content provided. Perceived ease of use and perceived usefulness played intermediary roles in linking ChatGPT engagement to learning satisfaction. User-friendly interfaces and perceived utility were identified as crucial factors affecting overall satisfaction levels. Notably, ChatGPT positively impacted learning motivation, indicating its potential to enhance student engagement and interest in learning. The study's findings have implications for educational practitioners seeking to improve the implementation of AI technologies in university students, emphasizing user-friendly design, collaborative learning, and factors influencing satisfaction. The study concludes with insights into the complex interplay between AI-powered tools, learning objectives, and motivation, highlighting the need for continued research to comprehensively understand these dynamics.","<method>Technology Acceptance Model (TAM)</method>, <method>structural equation modeling</method>, <method>confirmation factor analysis</method>, <method>path analysis</method>",No methods remaining
2024,https://openalex.org/W4399363436,Social Sciences,Collective Constitutional AI: Aligning a Language Model with Public Input,"There is growing consensus that language model (LM) developers should not be the sole deciders of LM behavior, creating a need for methods that enable the broader public to collectively shape the behavior of LM systems that affect them. To address this need, we present Collective Constitutional AI (CCAI): a multi-stage process for sourcing and integrating public input into LMs—from identifying a target population to sourcing principles to training and evaluating a model. We demonstrate the real-world practicality of this approach by creating what is, to our knowledge, the first LM fine-tuned with collectively sourced public input and evaluating this model against a baseline model trained with established principles from a LM developer. Our quantitative evaluations demonstrate several benefits of our approach: the CCAI-trained model shows lower bias across nine social dimensions compared to the baseline model, while maintaining equivalent performance on language, math, and helpful-harmless evaluations. Qualitative comparisons of the models suggest that the models differ on the basis of their respective constitutions, e.g., when prompted with contentious topics, the CCAI-trained model tends to generate responses that reframe the matter positively instead of a refusal. These results demonstrate a promising, tractable pathway toward publicly informed development of language models.","<method>Collective Constitutional AI (CCAI)</method>, <method>fine-tuning</method>",<method>fine-tuning</method>
2024,https://openalex.org/W4399715357,Social Sciences,AI-POWERED FRAUD DETECTION IN BANKING: SAFEGUARDING FINANCIAL TRANSACTIONS,"The banking industry's metamorphosis through digitalization has unquestionably revolutionized accessibility and convenience for customers worldwide. However, this paradigm shift has ushered in a new era of challenges, most notably in the realm of cybersecurity. Conventional rule-based fraud detection strategies have struggled to keep pace with the rapid evolution of cyber threats, prompting a surge of interest in more adaptive approaches like unsupervised learning. Furthermore, the COVID-19 pandemic has exacerbated the issue of bank fraud due to the widespread transition to online platforms and the proliferation of charitable funds, which present ripe opportunities for exploitation by cybercriminals. In response to these pressing concerns, this study delves into the realm of machine learning algorithms for the analysis and identification of fraudulent banking transactions. Notably, it contributes scientific novelty by developing models specifically tailored to this purpose and implementing innovative preprocessing techniques to enhance detection accuracy. Utilizing a diverse array of algorithms, including Random Forest, K-Nearest Neighbor (KNN), Naïve Bayes, Decision Trees, and Logistic Regression, the study showcases promising results. In particular, logistic regression and decision tree models exhibit impressive accuracy and Area Under the Curve (AUC) values of approximately 0.98, 0.97 and 0.95, 0.94, respectively. Given the pervasive nature of banking fraud in our digital society, the utilization of artificial intelligence algorithms for fraud detection stands as a critical and timely endeavor, promising enhanced security and trust in the financial ecosystem.","<method>unsupervised learning</method>, <method>Random Forest</method>, <method>K-Nearest Neighbor (KNN)</method>, <method>Naïve Bayes</method>, <method>Decision Trees</method>, <method>Logistic Regression</method>",<method>unsupervised learning</method><method>Random Forest</method><method>K-Nearest Neighbor (KNN)</method><method>Naïve Bayes</method><method>Decision Trees</method><method>Logistic Regression</method>
2024,https://openalex.org/W4401059011,Social Sciences,A review of control strategies for proton exchange membrane (PEM) fuel cells and water electrolysers: From automation to autonomy,"Proton exchange membrane (PEM) based electrochemical systems have the capability to operate in fuel cell (PEMFC) and water electrolyser (PEMWE) modes, enabling efficient hydrogen energy utilisation and green hydrogen production. In addition to the essential cell stacks, the system of PEMFC or PEMWE consists of four sub-systems for managing gas supply, power, thermal, and water, respectively. Due to the system's complexity, even a small fluctuation in a certain sub-system can result in an unexpected response, leading to a reduced performance and stability. To improve the system's robustness and responsiveness, considerable efforts have been dedicated to developing advanced control strategies. This paper comprehensively reviews various control strategies proposed in literature, revealing that traditional control methods are widely employed in PEMFC and PEMWE due to their simplicity, yet they suffer from limitations in accuracy. Conversely, advanced control methods offer high accuracy but are hindered by poor dynamic performance. This paper highlights the recent advancements in control strategies incorporating machine learning algorithms. Additionally, the paper provides a perspective on the future development of control strategies, suggesting that hybrid control methods should be used for future research to leverage the strength of both sides. Notably, it emphasises the role of artificial intelligence (AI) in advancing control strategies, demonstrating its significant potential in facilitating the transition from automation to autonomy.","<method>machine learning algorithms</method>, <method>artificial intelligence (AI)</method>, <method>hybrid control methods</method>",No methods remaining
2024,https://openalex.org/W4390933379,Social Sciences,"A Systematic Review of Graph Neural Network in Healthcare-Based Applications: Recent Advances, Trends, and Future Directions","Graph neural network (GNN) is a formidable deep learning framework that enables the analysis and modeling of intricate relationships present in data structured as graphs. In recent years, a burgeoning interest has arisen in exploiting the latent capabilities of GNN for healthcare-based applications, capitalizing on their aptitude for modeling complex relationships and unearthing profound insights from graph-structured data. However, to the best of our knowledge, no study has systemically reviewed the GNN studies conducted in the healthcare domain. This study has furnished an all-encompassing and erudite overview of the prevailing cutting-edge research on GNN in healthcare. Through analysis and assimilation of studies, current research trends, recurrent challenges, and promising future opportunities in GNN for healthcare applications have been identified. China emerged as the leading country to conduct GNN-based studies in the healthcare domain, followed by the USA, UK, and Turkey. Among various aspects of healthcare, disease prediction and drug discovery emerge as the most prominent areas of focus for GNN application, indicating the potential of GNN for advancing diagnostic and therapeutic approaches. This study proposed research questions regarding diverse aspects of GNN in the healthcare domain and addressed them through an in-depth analysis. This study can provide practitioners and researchers with profound insights into the current landscape of GNN applications in healthcare and can guide healthcare institutes, researchers, and governments by demonstrating the ways in which GNN can contribute to the development of effective and efficient healthcare systems.",<method>Graph neural network (GNN)</method>,<method>Graph neural network (GNN)</method>
2024,https://openalex.org/W4393904218,Social Sciences,Multilevel analysis of COVID-19 vaccination intention: the moderating role of economic and cultural country characteristics,"Abstract Background Predictors of COVID-19 (coronavirus) vaccination have been extensively researched; however, the contextual factors contributing to understanding vaccination intention remain largely unexplored. The present study aimed to investigate the moderating role of economic development (Gross domestic product - GDP per capita), economic inequality (Gini index), the perceived corruption index and Hofstede’s measurements of cultural values—index of individualism/collectivism and power distance index—in the relationship between determinants of satisfaction with the healthcare system, trust in political institutions, conspiracy beliefs and COVID-19 vaccination intention. Methods A multilevel modelling approach was employed on a sample of approximately 51 000 individuals nested within 26 countries. Data were drawn from the European Social Survey Round 10. The model examined the effect of individual- and country-level predictors and their interaction on vaccination intention. Results Satisfaction with the healthcare system had a stronger positive effect on intention to get vaccinated in countries with lower perceived corruption and more individualistic countries. Trust in political institutions had a stronger positive effect on vaccination intention in countries with higher economic development and lower perceived corruption, while a negative effect of conspiracy beliefs on vaccination intention was stronger in countries with lower economic development, higher perceived corruption and a more collectivistic cultural orientation. Conclusion Our findings highlight the importance of considering individual and contextual factors when addressing vaccination intention.",<method>multilevel modelling</method>,No methods remaining
2024,https://openalex.org/W4390765902,Social Sciences,Pseudo-spectral angle mapping for automated pixel-level analysis of highly multiplexed tissue image data,"Abstract The rapid development of highly multiplexed microscopy systems has enabled the study of cells embedded within their native tissue, which is providing exciting insights into the spatial features of human disease [1]. However, computational methods for analyzing these high-content images are still emerging, and there is a need for more robust and generalizable tools for evaluating the cellular constituents and underlying stroma captured by high-plex imaging [2]. To address this need, we have adapted spectral angle mapping – an algorithm used widely in hyperspectral image analysis – to compress the channel dimension of high-plex immunofluorescence images. As many high-plex immunofluorescence imaging experiments probe unique sets of protein markers, existing cell and pixel classification models do not typically generalize well. Pseudospectral angle mapping (pSAM) uses reference pseudospectra – or pixel vectors – to assign each pixel in an image a similarity score to several cell class reference vectors, which are defined by each unique staining panel. Here, we demonstrate that the class maps provided by pSAM can directly provide insight into the prevalence of each class defined by reference pseudospectra. In a dataset of high-plex images of colon biopsies from patients with gut autoimmune conditions, sixteen pSAM class representation maps were combined with instance segmentation of cells to provide cell class predictions. Finally, pSAM detected a diverse set of structure and immune cells when applied to a novel dataset of kidney biopsies imaged with a 43-marker panel. In summary, pSAM provides a powerful and readily generalizable method for evaluating high-plex immunofluorescence image data. Significance Statement Understanding the cellular constituents captured by highly multiplexed tissue imaging is a major limitation affecting the usability of these novel imaging methods. Many imaging experiments have uniquely designed staining panels, reducing the generalizability of cell classification models to new datasets. We present pseudospectral angle mapping (pSAM), which can compress high-dimensional image data into class representations. We demonstrate that the class representations generated by pSAM can be used to interpret high-plex image data and guide cell classification. Importantly, we also demonstrate that pSAM can generalize to new image datasets—collected with a different staining panel in samples from different tissues—without manual image annotation, subjective intensity gating, or re-training an algorithm.","<method>spectral angle mapping</method>, <method>pseudospectral angle mapping (pSAM)</method>",<method>spectral angle mapping</method>
