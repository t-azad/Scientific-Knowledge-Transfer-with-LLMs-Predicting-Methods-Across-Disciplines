title,abstract,publication_year,oa_pdf,publisher_url,concepts,openalex_id,domain_source
"A Comprehensive Survey of Continual Learning: Theory, Method and Application","To cope with real-world dynamics, an intelligent system needs to incrementally acquire, update, accumulate, and exploit knowledge throughout its lifetime. This ability, known as continual learning, provides a foundation for AI systems to develop themselves adaptively. In a general sense, continual learning is explicitly limited by catastrophic forgetting, where learning a new task usually results in a dramatic performance drop of the old tasks. Beyond this, increasingly numerous advances have emerged in recent years that largely extend the understanding and application of continual learning. The growing and widespread interest in this direction demonstrates its realistic significance as well as complexity. In this work, we present a comprehensive survey of continual learning, seeking to bridge the basic settings, theoretical foundations, representative methods, and practical applications. Based on existing theoretical and empirical results, we summarize the general objectives of continual learning as ensuring a proper stability-plasticity trade-off and an adequate intra/inter-task generalizability in the context of resource efficiency. Then we provide a state-of-the-art and elaborated taxonomy, extensively analyzing how representative strategies address continual learning, and how they are adapted to particular challenges in various applications. Through an in-depth discussion of promising directions, we believe that such a holistic perspective can greatly facilitate subsequent exploration in this field and beyond.",2024,,https://doi.org/10.1109/tpami.2024.3367329,Computer science; Forgetting; Exploit; Artificial intelligence; Context (archaeology); Machine learning; Data science; Paleontology; Philosophy; Linguistics; Computer security; Biology,https://openalex.org/W4392173735,Biology
Global prediction of extreme floods in ungauged watersheds,"Abstract Floods are one of the most common natural disasters, with a disproportionate impact in developing countries that often lack dense streamflow gauge networks 1 . Accurate and timely warnings are critical for mitigating flood risks 2 , but hydrological simulation models typically must be calibrated to long data records in each watershed. Here we show that artificial intelligence-based forecasting achieves reliability in predicting extreme riverine events in ungauged watersheds at up to a five-day lead time that is similar to or better than the reliability of nowcasts (zero-day lead time) from a current state-of-the-art global modelling system (the Copernicus Emergency Management Service Global Flood Awareness System). In addition, we achieve accuracies over five-year return period events that are similar to or better than current accuracies over one-year return period events. This means that artificial intelligence can provide flood warnings earlier and over larger and more impactful events in ungauged basins. The model developed here was incorporated into an operational early warning system that produces publicly available (free and open) forecasts in real time in over 80 countries. This work highlights a need for increasing the availability of hydrological data to continue to improve global access to reliable flood warnings.",2024,https://www.nature.com/articles/s41586-024-07145-1.pdf,https://doi.org/10.1038/s41586-024-07145-1,Flood myth; Flood forecasting; Warning system; Environmental science; Flood warning; Reliability (semiconductor); Streamflow; Watershed; Natural disaster; Extreme weather; Computer science; Meteorology; Environmental resource management; Drainage basin; Geography; Climate change; Cartography; Telecommunications; Ecology; Power (physics); Physics; Archaeology; Quantum mechanics; Machine learning; Biology,https://openalex.org/W4392984771,Biology
GLC_FCS30D: the first global 30 m land-cover dynamics monitoring product with a fine classification system for the period from 1985 to 2022 generated using dense-time-series Landsat imagery and the continuous change-detection method,"Abstract. Land-cover change has been identified as an important cause or driving force of global climate change and is a significant research topic. Over the past few decades, global land-cover mapping has progressed; however, long-time-series global land-cover-change monitoring data are still sparse, especially those at 30 m resolution. In this study, we describe GLC_FCS30D, a novel global 30 m land-cover dynamics monitoring dataset containing 35 land-cover subcategories and covering the period 1985–2022 in 26 time steps (maps were updated every 5 years before 2000 and annually after 2000). GLC_FCS30D has been developed using continuous change detection and all available Landsat imagery based on the Google Earth Engine platform. Specifically, we first take advantage of the continuous change-detection model and the full time series of Landsat observations to capture the time points of changed pixels and identify the temporally stable areas. Then, we apply a spatiotemporal refinement method to derive the globally distributed and high-confidence training samples from these temporally stable areas. Next, local adaptive classification models are used to update the land-cover information for the changed pixels, and a temporal-consistency optimization algorithm is adopted to improve their temporal stability and suppress some false changes. Further, the GLC_FCS30D product is validated using 84 526 globally distributed validation samples from 2020. It achieves an overall accuracy of 80.88 % (±0.27 %) for the basic classification system (10 major land-cover types) and 73.04 % (±0.30 %) for the LCCS (Land Cover Classification System) level-1 validation system (17 LCCS land-cover types). Meanwhile, two third-party time-series datasets used for validation from the United States and Europe Union are also collected for analyzing accuracy variations, and the results show that GLC_FCS30D offers significant stability in terms of variation across the accuracy time series and achieves mean accuracies of 79.50 % (±0.50 %) and 81.91 % (±0.09 %) over the two regions. Lastly, we draw conclusions about the global land-cover-change information from the GLC_FCS30D dataset; namely, that forest and cropland variations have dominated global land-cover change over past 37 years, the net loss of forests reached about 2.5 million km2, and the net gain in cropland area is approximately 1.3 million km2. Therefore, the novel dataset GLC_FCS30D is an accurate land-cover-dynamics time-series monitoring product that benefits from its diverse classification system, high spatial resolution, and long time span (1985–2022); thus, it will effectively support global climate change research and promote sustainable development analysis. The GLC_FCS30D dataset is available via https://doi.org/10.5281/zenodo.8239305 (Liu et al., 2023).",2024,https://essd.copernicus.org/articles/16/1353/2024/essd-16-1353-2024.pdf,https://doi.org/10.5194/essd-16-1353-2024,Land cover; Change detection; Remote sensing; Pixel; Environmental science; Computer science; Stability (learning theory); Product (mathematics); Consistency (knowledge bases); Period (music); Earth system science; Cover (algebra); Temporal resolution; Land use; Geography; Artificial intelligence; Geology; Mathematics; Machine learning; Ecology; Mechanical engineering; Oceanography; Physics; Geometry; Quantum mechanics; Acoustics; Engineering; Biology,https://openalex.org/W4392872715,Biology
Cognitive Control and Neural Activity during Human Development: Evidence for Synaptic Pruning,"The modern world is full of distractions that steal our attention from important tasks. As a result, the world places ever-growing demands on cognitive control: the ability to coordinate mental resources to achieve our goals (Koechlin et al., 2003). A key mediator of cognitive control is the prefrontal cortex (PFC), which is heavily involved in processes like learning and memory, attention, and inhibition of improper responses (Koechlin et al., 2003). Yet the PFC, with its sophisticated circuitry that enables these roles, is one of the last brain regions to develop (Hill et al., 2010; Kolk and Rakic, 2022). Indeed, the maturation of the PFC is an important component of adolescent development (Larsen and Luna, 2018), as is the development of cognitive control. This delayed development of the PFC may lead to undesired outcomes, such as risky behaviors in teenagers (Larsen and Luna, 2018), which may be linked specifically to deficits in response inhibition or the suppression of competing responses during a given task or everyday situation (Luna and Sweeney, 2004). Therefore, understanding the developmental changes in the circuitry that underlies cognitive control, particularly response inhibition, is an important area of investigation. A major component of PFC maturation is the removal of excess connections via synaptic pruning (Kolk and Rakic, 2022). During early childhood, the PFC undergoes rapid expansion, with dorsolateral and medial PFC expanding to nearly double the surface area of other cortical regions such as occipital and insular cortices (Hill et al., 2010). Underlying this rapid expansion is a period of extensive synaptic growth (synaptogenesis), which begins prenatally but peaks postnatally (Teffer and Semendeferi, 2012), at ∼3.5 years of age in humans (Kolk and Rakic, 2022). PFC cortical thickness, which can serve as a measure of synaptic density, also shows rapid growth early in … Correspondence should be addressed to Leland L. Fleming at llfleming{at}mclean.harvard.edu.",2024,,https://doi.org/10.1523/jneurosci.0373-24.2024,Psychology; Neuroscience; Cognition; Prefrontal cortex; Synaptic pruning; Control (management); Cognitive psychology; Computer science; Biology; Microglia; Artificial intelligence; Immunology; Inflammation,https://openalex.org/W4400061112,Psychology
"“I Thought It Was Better to Be Safe Than Sorry”: Factors Influencing Parental Decisions on HPV and Other Adolescent Vaccinations for Students with Intellectual Disability and/or Autism in New South Wales, Australia","The uptake of human papilloma virus (HPV) and other adolescent vaccinations in special schools for young people with disability is significantly lower than in mainstream settings. This study explored the factors believed to influence parental decision making regarding vaccine uptake for students with intellectual disability and/or on the autism spectrum attending special schools in New South Wales, Australia, from the perspective of all stakeholders involved in the program. Focus groups and interviews were conducted with 40 participants, including parents, school staff, and immunisation providers. The thematic analysis identified two themes: (1) appreciating diverse parental attitudes towards vaccination and (2) educating parents and managing vaccination questions and concerns. While most parents were described as pro-vaccination, others were anti-vaccination or vaccination-hesitant, articulating a marked protectiveness regarding their child’s health. Reasons for vaccine hesitancy included beliefs that vaccines cause autism, concerns that the vaccination may be traumatic for the child, vaccination fatigue following COVID-19, and assumptions that children with disability will not be sexually active. Special school staff regarded the vaccination information pack as inadequate for families, and nurses described limited educational impact resulting from minimal direct communication with parents. More effective communication strategies are needed to address vaccine hesitancy among parents with children with disability.",2024,,https://doi.org/10.3390/vaccines12080922,Vaccination; Thematic analysis; Autism; Intellectual disability; Medicine; Mainstream; Autism spectrum disorder; Family medicine; Perspective (graphical); Psychology; Developmental psychology; Psychiatry; Qualitative research; Immunology; Social science; Philosophy; Theology; Sociology; Artificial intelligence; Computer science,https://openalex.org/W4401634453,Psychology
Combined Effect of Maternal Separation and Early-Life Immune Activation on Brain and Behaviour of Rat Offspring,"Adversity during early life, a critical period for brain development, increases vulnerability and can have a lasting impact on the brain and behaviour of a child. However, the long-term effects of cumulative early-life stressors on brain and behaviour are not well known. We studied a 2-hit rat model of early-life adversity using maternal separation (MS) and immune activation (lipopolysaccharide (LPS)). Rat pups underwent MS for 15 (control) or 180 (MS) minutes per day from postnatal day (P)2-14 and were administered saline or LPS (intraperitoneal) on P3. Open-field (OFT) and object-place recognition tests were performed on rat offspring at P33-35 and P42-50, respectively. The pre-frontal cortex (PFC) and hippocampus were removed at the experimental endpoint (P52-55) for mRNA expression. MS induced anxiety-like behaviour in OFT in male and reduced locomotor activity in both male and female offspring. LPS induced a subtle decline in memory in the object-place recognition test in male offspring. MS increased glial fibrillary acidic protein (GFAP) and brain-derived neurotrophic factor expression in PFC and ionised calcium-binding adapter molecule-1 expression in male hippocampus. MS and LPS resulted in distinct behavioural phenotypes in a sex-specific manner. The combination of MS and LPS had a synergistic effect on the anxiety-like behaviour, locomotor activity, and GFAP mRNA expression outcomes.",2024,https://www.mdpi.com/2218-273X/14/2/197/pdf?version=1707276819,https://doi.org/10.3390/biom14020197,Offspring; Immune system; Separation (statistics); Developmental psychology; Psychology; Biology; Immunology; Neuroscience; Pregnancy; Computer science; Genetics; Machine learning,https://openalex.org/W4391613813,Psychology
Determinants of HPV vaccine uptake intentions in Chinese clinical interns: an extended theory of planned behavior approach,"This study aims to utilize the extended Theory of Planned Behavior (TPB) model to examine the intentions of clinical interns in China towards Human papillomaviruses (HPV) vaccination. It also fills a significant gap in the literature concerning vaccine acceptance in this specific population. This cross-sectional study was carried out with clinical interns in Shandong Province, China, with a total of 1,619 participants. Data were collected through self-reported questionnaires, including demographic characteristics, TPB variables, and HPV-related health knowledge. Hierarchical regression analysis was employed to identify key factors influencing vaccination intentions, and Structural Equation Modeling (SEM) was used to analyze the interrelationships between these factors. This study initially identified key predictors affecting clinical interns' intentions to receive the HPV vaccine through hierarchical regression analysis. The preliminary model, which accounted for demographic factors, revealed foundational impacts of household income and HPV-related clinical experience on intentions. After integrating TPB variables-attitude, subjective norm, perceived behavioral control, and HPV-related health knowledge-the model's explanatory power was enhanced to 37.30%. SEM analysis focused on the interplay among TPB constructs and extended variables, confirming their significance in forming vaccination intentions, with subjective norm having the most substantial impact (β = 0.375, p < 0.001). The extended TPB model explained over half of the variance in vaccination intentions, substantiating the hypotheses and revealing the psychological determinants behind clinical interns' decision-making for HPV vaccination. The extended TPB model from this study effectively explains the vaccination intentions among clinical interns for HPV, offering theoretical support for public health strategies and educational interventions targeting this group. These findings are of significant importance for public health practice and future health promotion strategies.",2024,https://www.frontiersin.org/journals/public-health/articles/10.3389/fpubh.2024.1345530/pdf,https://doi.org/10.3389/fpubh.2024.1345530,Theory of planned behavior; Vaccination; Structural equation modeling; Explanatory power; Multilevel model; Psychology; Regression analysis; Social psychology; Explained variation; Norm (philosophy); Health belief model; Population; Public health; Medicine; Control (management); Environmental health; Health education; Immunology; Statistics; Computer science; Nursing; Artificial intelligence; Philosophy; Mathematics; Epistemology; Political science; Law,https://openalex.org/W4391881153,Psychology
Discovering biomarkers associated and predicting cardiovascular disease with high accuracy using a novel nexus of machine learning techniques for precision medicine,"Abstract Personalized interventions are deemed vital given the intricate characteristics, advancement, inherent genetic composition, and diversity of cardiovascular diseases (CVDs). The appropriate utilization of artificial intelligence (AI) and machine learning (ML) methodologies can yield novel understandings of CVDs, enabling improved personalized treatments through predictive analysis and deep phenotyping. In this study, we proposed and employed a novel approach combining traditional statistics and a nexus of cutting-edge AI/ML techniques to identify significant biomarkers for our predictive engine by analyzing the complete transcriptome of CVD patients. After robust gene expression data pre-processing, we utilized three statistical tests (Pearson correlation, Chi-square test, and ANOVA) to assess the differences in transcriptomic expression and clinical characteristics between healthy individuals and CVD patients. Next, the recursive feature elimination classifier assigned rankings to transcriptomic features based on their relation to the case–control variable. The top ten percent of commonly observed significant biomarkers were evaluated using four unique ML classifiers (Random Forest, Support Vector Machine, Xtreme Gradient Boosting Decision Trees, and k-Nearest Neighbors). After optimizing hyperparameters, the ensembled models, which were implemented using a soft voting classifier, accurately differentiated between patients and healthy individuals. We have uncovered 18 transcriptomic biomarkers that are highly significant in the CVD population that were used to predict disease with up to 96% accuracy. Additionally, we cross-validated our results with clinical records collected from patients in our cohort. The identified biomarkers served as potential indicators for early detection of CVDs. With its successful implementation, our newly developed predictive engine provides a valuable framework for identifying patients with CVDs based on their biomarker profiles.",2024,https://www.nature.com/articles/s41598-023-50600-8.pdf,https://doi.org/10.1038/s41598-023-50600-8,Random forest; Artificial intelligence; Machine learning; Computer science; Support vector machine; Decision tree; Hyperparameter; Matthews correlation coefficient; Classifier (UML); Correlation; Gradient boosting; Population; Medicine; Mathematics; Geometry; Environmental health,https://openalex.org/W4390506881,Medicine
Improving large language models for clinical named entity recognition via prompt engineering,"Abstract Importance The study highlights the potential of large language models, specifically GPT-3.5 and GPT-4, in processing complex clinical data and extracting meaningful information with minimal training data. By developing and refining prompt-based strategies, we can significantly enhance the models’ performance, making them viable tools for clinical NER tasks and possibly reducing the reliance on extensive annotated datasets. Objectives This study quantifies the capabilities of GPT-3.5 and GPT-4 for clinical named entity recognition (NER) tasks and proposes task-specific prompts to improve their performance. Materials and Methods We evaluated these models on 2 clinical NER tasks: (1) to extract medical problems, treatments, and tests from clinical notes in the MTSamples corpus, following the 2010 i2b2 concept extraction shared task, and (2) to identify nervous system disorder-related adverse events from safety reports in the vaccine adverse event reporting system (VAERS). To improve the GPT models' performance, we developed a clinical task-specific prompt framework that includes (1) baseline prompts with task description and format specification, (2) annotation guideline-based prompts, (3) error analysis-based instructions, and (4) annotated samples for few-shot learning. We assessed each prompt's effectiveness and compared the models to BioClinicalBERT. Results Using baseline prompts, GPT-3.5 and GPT-4 achieved relaxed F1 scores of 0.634, 0.804 for MTSamples and 0.301, 0.593 for VAERS. Additional prompt components consistently improved model performance. When all 4 components were used, GPT-3.5 and GPT-4 achieved relaxed F1 socres of 0.794, 0.861 for MTSamples and 0.676, 0.736 for VAERS, demonstrating the effectiveness of our prompt framework. Although these results trail BioClinicalBERT (F1 of 0.901 for the MTSamples dataset and 0.802 for the VAERS), it is very promising considering few training samples are needed. Discussion The study’s findings suggest a promising direction in leveraging LLMs for clinical NER tasks. However, while the performance of GPT models improved with task-specific prompts, there's a need for further development and refinement. LLMs like GPT-4 show potential in achieving close performance to state-of-the-art models like BioClinicalBERT, but they still require careful prompt engineering and understanding of task-specific knowledge. The study also underscores the importance of evaluation schemas that accurately reflect the capabilities and performance of LLMs in clinical settings. Conclusion While direct application of GPT models to clinical NER tasks falls short of optimal performance, our task-specific prompt framework, incorporating medical knowledge and training samples, significantly enhances GPT models' feasibility for potential clinical applications.",2024,https://academic.oup.com/jamia/advance-article-pdf/doi/10.1093/jamia/ocad259/56437671/ocad259.pdf,https://doi.org/10.1093/jamia/ocad259,Computer science; Task (project management); Annotation; Natural language processing; Baseline (sea); F1 score; Named-entity recognition; Artificial intelligence; Guideline; Adverse Event Reporting System; Machine learning; Adverse effect; Medicine; Pathology; Oceanography; Management; Internal medicine; Economics; Geology,https://openalex.org/W4391292768,Medicine
FDA-Approved Artificial Intelligence and Machine Learning (AI/ML)-Enabled Medical Devices: An Updated Landscape,"As artificial intelligence (AI) has been highly advancing in the last decade, machine learning (ML)-enabled medical devices are increasingly used in healthcare. In this study, we collected publicly available information on AI/ML-enabled medical devices approved by the FDA in the United States, as of the latest update on 19 October 2023. We performed comprehensive analysis of a total of 691 FDA-approved artificial intelligence and machine learning (AI/ML)-enabled medical devices and offer an in-depth analysis of clearance pathways, approval timeline, regulation type, medical specialty, decision type, recall history, etc. We found a significant surge in approvals since 2018, with clear dominance of the radiology specialty in the application of machine learning tools, attributed to the abundant data from routine clinical data. The study also reveals a reliance on the 510(k)-clearance pathway, emphasizing its basis on substantial equivalence and often bypassing the need for new clinical trials. Also, it notes an underrepresentation of pediatric-focused devices and trials, suggesting an opportunity for expansion in this demographic. Moreover, the geographical limitation of clinical trials, primarily within the United States, points to a need for more globally inclusive trials to encompass diverse patient demographics. This analysis not only maps the current landscape of AI/ML-enabled medical devices but also pinpoints trends, potential gaps, and areas for future exploration, clinical trial practices, and regulatory approaches. In conclusion, our analysis sheds light on the current state of FDA-approved AI/ML-enabled medical devices and prevailing trends, contributing to a wider comprehension.",2024,https://www.mdpi.com/2079-9292/13/3/498/pdf?version=1706111663,https://doi.org/10.3390/electronics13030498,Clinical trial; Demographics; Artificial intelligence; Specialty; Medicine; Timeline; Machine learning; Computer science; Family medicine; Pathology; Geography; Demography; Archaeology; Sociology,https://openalex.org/W4391221083,Medicine
A multinational study on the factors influencing university students’ attitudes and usage of ChatGPT,"Abstract Artificial intelligence models, like ChatGPT, have the potential to revolutionize higher education when implemented properly. This study aimed to investigate the factors influencing university students’ attitudes and usage of ChatGPT in Arab countries. The survey instrument “TAME-ChatGPT” was administered to 2240 participants from Iraq, Kuwait, Egypt, Lebanon, and Jordan. Of those, 46.8% heard of ChatGPT, and 52.6% used it before the study. The results indicated that a positive attitude and usage of ChatGPT were determined by factors like ease of use, positive attitude towards technology, social influence, perceived usefulness, behavioral/cognitive influences, low perceived risks, and low anxiety. Confirmatory factor analysis indicated the adequacy of the “TAME-ChatGPT” constructs. Multivariate analysis demonstrated that the attitude towards ChatGPT usage was significantly influenced by country of residence, age, university type, and recent academic performance. This study validated “TAME-ChatGPT” as a useful tool for assessing ChatGPT adoption among university students. The successful integration of ChatGPT in higher education relies on the perceived ease of use, perceived usefulness, positive attitude towards technology, social influence, behavioral/cognitive elements, low anxiety, and minimal perceived risks. Policies for ChatGPT adoption in higher education should be tailored to individual contexts, considering the variations in student attitudes observed in this study.",2024,https://www.nature.com/articles/s41598-024-52549-8.pdf,https://doi.org/10.1038/s41598-024-52549-8,Residence; Psychology; Multinational corporation; Confirmatory factor analysis; Anxiety; Higher education; Cognition; Usability; Multivariate analysis; Positive attitude; Applied psychology; Social psychology; Structural equation modeling; Medicine; Demography; Business; Computer science; Political science; Sociology; Finance; Human–computer interaction; Machine learning; Psychiatry; Neuroscience; Internal medicine; Law,https://openalex.org/W4391137578,Medicine
"Selection, optimization and validation of ten chronic disease polygenic risk scores for clinical implementation in diverse US populations","Polygenic risk scores (PRSs) have improved in predictive performance, but several challenges remain to be addressed before PRSs can be implemented in the clinic, including reduced predictive performance of PRSs in diverse populations, and the interpretation and communication of genetic results to both providers and patients. To address these challenges, the National Human Genome Research Institute-funded Electronic Medical Records and Genomics (eMERGE) Network has developed a framework and pipeline for return of a PRS-based genome-informed risk assessment to 25,000 diverse adults and children as part of a clinical study. From an initial list of 23 conditions, ten were selected for implementation based on PRS performance, medical actionability and potential clinical utility, including cardiometabolic diseases and cancer. Standardized metrics were considered in the selection process, with additional consideration given to strength of evidence in African and Hispanic populations. We then developed a pipeline for clinical PRS implementation (score transfer to a clinical laboratory, validation and verification of score performance), and used genetic ancestry to calibrate PRS mean and variance, utilizing genetically diverse data from 13,475 participants of the All of Us Research Program cohort to train and test model parameters. Finally, we created a framework for regulatory compliance and developed a PRS clinical report for return to providers and for inclusion in an additional genome-informed risk assessment. The initial experience from eMERGE can inform the approach needed to implement PRS-based testing in diverse clinical settings.",2024,https://www.nature.com/articles/s41591-024-02796-z.pdf,https://doi.org/10.1038/s41591-024-02796-z,Polygenic risk score; Pipeline (software); Computer science; Selection (genetic algorithm); Medicine; Machine learning; Biology; Biochemistry; Gene; Genotype; Single-nucleotide polymorphism; Programming language,https://openalex.org/W4391925496,Medicine
The diagnostic and triage accuracy of the GPT-3 artificial intelligence model: an observational study,"BackgroundArtificial intelligence (AI) applications in health care have been effective in many areas of medicine, but they are often trained for a single task using labelled data, making deployment and generalisability challenging. How well a general-purpose AI language model performs diagnosis and triage relative to physicians and laypeople is not well understood.MethodsWe compared the predictive accuracy of Generative Pre-trained Transformer 3 (GPT-3)'s diagnostic and triage ability for 48 validated synthetic case vignettes (<50 words; sixth-grade reading level or below) of both common (eg, viral illness) and severe (eg, heart attack) conditions to a nationally representative sample of 5000 lay people from the USA who could use the internet to find the correct options and 21 practising physicians at Harvard Medical School. There were 12 vignettes for each of four triage categories: emergent, within one day, within 1 week, and self-care. The correct diagnosis and triage category (ie, ground truth) for each vignette was determined by two general internists at Harvard Medical School. For each vignette, human respondents and GPT-3 were prompted to list diagnoses in order of likelihood, and the vignette was marked as correct if the ground-truth diagnosis was in the top three of the listed diagnoses. For triage accuracy, we examined whether the human respondents' and GPT-3's selected triage was exactly correct according to the four triage categories, or matched a dichotomised triage variable (emergent or within 1 day vs within 1 week or self-care). We estimated GPT-3's diagnostic and triage confidence on a given vignette using a modified bootstrap resampling procedure, and examined how well calibrated GPT-3's confidence was by computing calibration curves and Brier scores. We also performed subgroup analysis by case acuity, and an error analysis for triage advice to characterise how its advice might affect patients using this tool to decide if they should seek medical care immediately.FindingsAmong all cases, GPT-3 replied with the correct diagnosis in its top three for 88% (42/48, 95% CI 75–94) of cases, compared with 54% (2700/5000, 53–55) for lay individuals (p<0.0001) and 96% (637/666, 94–97) for physicians (p=0·012). GPT-3 triaged 70% correct (34/48, 57–82) versus 74% (3706/5000, 73–75; p=0.60) for lay individuals and 91% (608/666, 89–93%; p<0.0001) for physicians. As measured by the Brier score, GPT-3 confidence in its top prediction was reasonably well calibrated for diagnosis (Brier score=0·18) and triage (Brier score=0·22). We observed an inverse relationship between case acuity and GPT-3 accuracy (p<0·0001) with a fitted trend line of –8·33% decrease in accuracy for every level of increase in case acuity. For triage error analysis, GPT-3 deprioritised truly emergent cases in seven instances.InterpretationA general-purpose AI language model without any content-specific training could perform diagnosis at levels close to, but below, physicians and better than lay individuals. We found that GPT-3's performance was inferior to physicians for triage, sometimes by a large margin, and its performance was closer to that of lay individuals. Although the diagnostic performance of GPT-3 was comparable to physicians, it was significantly better than a typical person using a search engine.FundingThe National Heart, Lung, and Blood Institute.",2024,,https://doi.org/10.1016/s2589-7500(24)00097-9,Triage; Software deployment; Observational study; Task (project management); Artificial intelligence; Computer science; Machine learning; Data science; Medicine; Medical emergency; Pathology; Engineering; Systems engineering; Software engineering,https://openalex.org/W4400937555,Engineering
Deep Learning for Integrated Origin–Destination Estimation and Traffic Sensor Location Problems,"Traffic control and management applications require the full realization of traffic flow data. Frequently, such data are acquired by traffic sensors with two issues: it is not practicable or even possible to place traffic sensors on every link in a network; sensors do not provide direct information about origin–destination (O–D) demand flows. Therefore, it is imperative to locate the best places to deploy traffic sensors and then augment the knowledge obtained from this link flow sample to predict the entire traffic flow of the network. This article provides a resilient deep learning (DL) architecture combined with a global sensitivity analysis tool to solve O–D estimation and sensor location problems simultaneously. The proposed DL architecture is based on the stacked sparse autoencoder (SAE) model for accurately estimating the entire O–D flows of the network using link flows, thus reversing the conventional traffic assignment problem. The SAE model extracts traffic flow characteristics and derives a meaningful relationship between traffic flow data and network topology. To train the proposed DL architecture, synthetic link flow data were created randomly from the historical demand data of the network. Finally, a global sensitivity analysis was implemented to prioritize the importance of each link in the O–D estimation step to solve the sensor location problem. Two networks of different sizes were used to validate the performance of the model. The efficiency of the proposed method for solving the combination of traffic flow estimation and sensor location problems was confirmed from a low root-mean-square error with a reduction in the number of link flows required.",2024,,https://doi.org/10.1109/tits.2023.3344533,Autoencoder; Traffic flow (computer networking); Computer science; Sensitivity (control systems); Traffic generation model; Real-time computing; Realization (probability); Wireless sensor network; Data mining; Network topology; Deep learning; Engineering; Artificial intelligence; Computer network; Mathematics; Statistics; Electronic engineering,https://openalex.org/W4390492410,Engineering
Evaluation of artificial intelligence-powered screening for sexually transmitted infections-related skin lesions using clinical images and metadata,"Abstract Background Sexually transmitted infections (STIs) pose a significant global public health challenge. Early diagnosis and treatment reduce STI transmission, but rely on recognising symptoms and care-seeking behaviour of the individual. Digital health software that distinguishes STI skin conditions could improve health-seeking behaviour. We developed and evaluated a deep learning model to differentiate STIs from non-STIs based on clinical images and symptoms. Methods We used 4913 clinical images of genital lesions and metadata from the Melbourne Sexual Health Centre collected during 2010–2023. We developed two binary classification models to distinguish STIs from non-STIs: (1) a convolutional neural network (CNN) using images only and (2) an integrated model combining both CNN and fully connected neural network (FCN) using images and metadata. We evaluated the model performance by the area under the ROC curve (AUC) and assessed metadata contributions to the Image-only model. Results Our study included 1583 STI and 3330 non-STI images. Common STI diagnoses were syphilis (34.6%), genital warts (24.5%) and herpes (19.4%), while most non-STIs (80.3%) were conditions such as dermatitis, lichen sclerosis and balanitis. In both STI and non-STI groups, the most frequently observed groups were 25–34 years (48.6% and 38.2%, respectively) and heterosexual males (60.3% and 45.9%, respectively). The Image-only model showed a reasonable performance with an AUC of 0.859 (SD 0.013). The Image + Metadata model achieved a significantly higher AUC of 0.893 (SD 0.018) compared to the Image-only model ( p &lt; 0.01). Out of 21 metadata, the integration of demographic and dermatological metadata led to the most significant improvement in model performance, increasing AUC by 6.7% compared to the baseline Image-only model. Conclusions The Image + Metadata model outperformed the Image-only model in distinguishing STIs from other skin conditions. Using it as a screening tool in a clinical setting may require further development and evaluation with larger datasets.",2024,,https://doi.org/10.1186/s12916-024-03512-x,Medicine; Metadata; Genital warts; Convolutional neural network; Transmission (telecommunications); Artificial intelligence; Syphilis; Artificial neural network; Dermatology; Sex organ; Internal medicine; Immunology; Human immunodeficiency virus (HIV); Computer science; Biology; Electrical engineering; Genetics; Engineering; Operating system,https://openalex.org/W4400798015,Engineering
Perspectives in the Development of Tools to Assess Vaccine Literacy,"Vaccine literacy (VL) is the ability to find, understand, and evaluate vaccination-related information to make appropriate decisions about immunization. The tools developed so far for its evaluation have produced consistent results. However, some dimensions may be underestimated due to the complexity of factors influencing VL. Moreover, the heterogeneity of methods used in studies employing these tools hinders a comprehensive understanding of its role even more. To overcome these limitations, a path has been sought to propose new instruments. This has necessitated updating earlier literature reviews on VL and related tools, exploring its relationship with vaccine hesitancy (VH), and examining associated variables like beliefs, attitudes, and behaviors towards immunization. Based on the current literature, and supported by the re-analysis of a dataset from an earlier study, we propose a theoretical framework to serve as the foundation for creating future assessment tools. These instruments should not only evaluate the psychological factors underlying the motivational aspect of VL, but also encompass knowledge and competencies. The positioning of VL in the framework at the intersection between sociodemographic antecedents and attitudes, leading to behaviors and outcomes, explains why and how VL can directly or indirectly influence vaccination decisions by countering VH and operating at personal, as well as at organizational and community levels.",2024,https://www.mdpi.com/2076-393X/12/4/422/pdf?version=1713255355,https://doi.org/10.3390/vaccines12040422,Intersection (aeronautics); Literacy; Psychology; Vaccination; Path analysis (statistics); Immunization; Computer science; Knowledge management; Medicine; Immunology; Engineering; Pedagogy; Machine learning; Antigen; Aerospace engineering,https://openalex.org/W4394845368,Engineering
A multinational study on the factors influencing university students’ attitudes and usage of ChatGPT,"Abstract Artificial intelligence models, like ChatGPT, have the potential to revolutionize higher education when implemented properly. This study aimed to investigate the factors influencing university students’ attitudes and usage of ChatGPT in Arab countries. The survey instrument “TAME-ChatGPT” was administered to 2240 participants from Iraq, Kuwait, Egypt, Lebanon, and Jordan. Of those, 46.8% heard of ChatGPT, and 52.6% used it before the study. The results indicated that a positive attitude and usage of ChatGPT were determined by factors like ease of use, positive attitude towards technology, social influence, perceived usefulness, behavioral/cognitive influences, low perceived risks, and low anxiety. Confirmatory factor analysis indicated the adequacy of the “TAME-ChatGPT” constructs. Multivariate analysis demonstrated that the attitude towards ChatGPT usage was significantly influenced by country of residence, age, university type, and recent academic performance. This study validated “TAME-ChatGPT” as a useful tool for assessing ChatGPT adoption among university students. The successful integration of ChatGPT in higher education relies on the perceived ease of use, perceived usefulness, positive attitude towards technology, social influence, behavioral/cognitive elements, low anxiety, and minimal perceived risks. Policies for ChatGPT adoption in higher education should be tailored to individual contexts, considering the variations in student attitudes observed in this study.",2024,https://www.nature.com/articles/s41598-024-52549-8.pdf,https://doi.org/10.1038/s41598-024-52549-8,Residence; Psychology; Multinational corporation; Confirmatory factor analysis; Anxiety; Higher education; Cognition; Usability; Multivariate analysis; Positive attitude; Applied psychology; Social psychology; Structural equation modeling; Medicine; Demography; Business; Computer science; Political science; Sociology; Finance; Human–computer interaction; Machine learning; Psychiatry; Neuroscience; Internal medicine; Law,https://openalex.org/W4391137578,Social Sciences
Investigation of the moderation effect of gender and study level on the acceptance and use of generative <scp>AI</scp> by higher education students: Comparative evidence from Poland and Egypt,"Abstract This study delves into the implications of incorporating AI tools, specifically ChatGPT, in higher education contexts. With a primary focus on understanding the acceptance and utilization of ChatGPT among university students, the research utilizes the Unified Theory of Acceptance and Use of Technology (UTAUT) as the guiding framework. The investigation probes into four crucial constructs of UTAUT—performance expectancy, effort expectancy, social influence and facilitating conditions—to understand their impact on the intent and actual use behaviour of students. The study relies on data collected from six universities in two countries and assessed through descriptive statistics and structural equation modelling techniques, and also takes into account participants' gender and study level. The key findings show that performance expectancy, effort expectancy, and social influence significantly influence behavioural intention. Furthermore, behavioural intention, when considered alongside facilitating conditions, influences actual use behaviour. This research also explores the moderating impact of gender and study level on the relationships among these variables. The results not only augment our comprehension of technology acceptance in the context of AI tools but also provide valuable input for formulating strategies that promote effective incorporation of ChatGPT in higher education. The study underscores the need for effective awareness initiatives, bespoke training programmes, and intuitive tool designs to bolster students' perceptions and foster the wider adoption of AI tools in education. Practitioner notes What is already known about this topic ChatGPT is a tool that is quickly gaining worldwide recognition. ChatGPT helps with writing essays and solving assignments. ChatGPT raises ethical concerns about authorship, plagiarism and ethics. What this paper adds This study explores students' acceptance of ChatGPT as an aid in their education, which has not been studied previously. We used the extended Unified Technology Acceptance and Use of Technology theory to test what factors mostly influence the use of ChatGPT by students. We conducted a multiple study in Poland and Egypt based on sampling strategy from six universities. Implications for practice and/or policy ChatGPT is a global game changer and should be incorporated into study programmes. The limitations of ChatGPT should be well explained and known since it is prone to making mistakes. Higher education teachers should be aware of ChatGPT's capabilities.",2024,,https://doi.org/10.1111/bjet.13425,Expectancy theory; Unified theory of acceptance and use of technology; Moderation; Psychology; Bespoke; Social influence; Context (archaeology); Structural equation modeling; Social psychology; Knowledge management; Computer science; Political science; Paleontology; Machine learning; Law; Biology,https://openalex.org/W4390609372,Social Sciences
Theories of motivation: A comprehensive analysis of human behavior drivers,"This paper explores theories of motivation, including instinct theory, arousal theory, incentive theory, intrinsic theory, extrinsic theory, the ARCS model, self-determination theory, expectancy-value theory, and goal-orientation theory. Each theory is described in detail, along with its key concepts, assumptions, and implications for behavior. Intrinsic theory suggests that individuals are motivated by internal factors like enjoyment and satisfaction, while extrinsic theory suggests that external factors like rewards and social pressure drive behavior. Arousal theory says that to feel motivated, people try to keep an optimal level of activation or excitement. Incentive theory suggests that behavior is driven by the promise of rewards or the threat of punishment. The ARCS model, designed to motivate learners, incorporates elements of attention, relevance, confidence, and satisfaction. Self-determination theory proposes that individuals are motivated by their needs for autonomy, competence, and relatedness. The expectation-value theory suggests that behavior is influenced by individuals' beliefs about their ability to succeed and the value they place on the task. The goal-orientation theory suggests that individuals have different goals for engaging in a behavior. By understanding these different theories of motivation, educators, coaches, managers, and individuals may analyze what drives behavior and how to harness it to achieve their goals. In essence, a nuanced comprehension of these diverse motivation theories equips individuals across varied domains with a strategic toolkit to navigate the complex landscape of human behavior, fostering a more profound understanding of what propels actions and how to channel these insights toward the attainment of overarching goals.",2024,,https://doi.org/10.1016/j.actpsy.2024.104177,Self-determination theory; Expectancy theory; Psychology; Competence (human resources); Social psychology; Motivation theory; Incentive; Theory of planned behavior; Value (mathematics); Cognitive evaluation theory; Autonomy; Cognitive psychology; Control (management); Computer science; Artificial intelligence; Machine learning; Political science; Law; Economics; Microeconomics,https://openalex.org/W4391776447,Social Sciences
Systematic literature review: Quantum machine learning and its applications,"Quantum physics has changed the way we understand our environment, and one of its branches, quantum mechanics, has demonstrated accurate and consistent theoretical results. Quantum computing is the process of performing calculations using quantum mechanics. This field studies the quantum behavior of certain subatomic particles (photons, electrons, etc.) for subsequent use in performing calculations, as well as for large-scale information processing. These advantages are achieved through the use of quantum features, such as entanglement or superposition. These capabilities can give quantum computers an advantage in terms of computational time and cost over classical computers. Nowadays, scientific challenges are impossible to perform by classical computation due to computational complexity (more bytes than atoms in the observable universe) or the time it would take (thousands of years), and quantum computation is the only known answer. However, current quantum devices do not have yet the necessary qubits and are not fault-tolerant enough to achieve these goals. Nonetheless, there are other fields like machine learning, finance, or chemistry where quantum computation could be useful with current quantum devices. This manuscript aims to present a review of the literature published between 2017 and 2023 to identify, analyze, and classify the different types of algorithms used in quantum machine learning and their applications. The methodology follows the guidelines related to Systematic Literature Review methods, such as the one proposed by Kitchenham and other authors in the software engineering field. Consequently, this study identified 94 articles that used quantum machine learning techniques and algorithms and shows their implementation using computational quantum circuits or ansatzs. The main types of found algorithms are quantum implementations of classical machine learning algorithms, such as support vector machines or the k-nearest neighbor model, and classical deep learning algorithms, like quantum neural networks. One of the most relevant applications in the machine learning field is image classification. Many articles, especially within the classification, try to solve problems currently answered by classical machine learning but using quantum devices and algorithms. Even though results are promising, quantum machine learning is far from achieving its full potential. An improvement in quantum hardware is required for this potential to be achieved since the existing quantum computers lack enough quality, speed, and scale to allow quantum computing to achieve its full potential.",2024,,https://doi.org/10.1016/j.cosrev.2024.100619,Computer science; Systematic review; Artificial intelligence; Machine learning; MEDLINE; Law; Political science,https://openalex.org/W4391243055,Social Sciences
State Formation and Political Legitimacy,"evolution of the state from earlier forms of political organization is associated with revolutionary changes in the structure of inequality. These magnify distinctions in rank and power that outweigh anything previously known in so-called primitive societies. This volume explains how and why people came to accept and even identify themselves with this new form of authority. introduction provides a new theory of legitimacy by synthesizing and uniting earlier theories from psychological, cultural-materialist, rational choice, and Marxist approaches. case studies which follow present a wide range of materials on cultures in both Western and non-Western settings, and across a number of different historical periods. Included are examples from Africa, Asia, Europe, and the New World. Older states such as Ur, Inca, and medieval France are examined along with more contemporary states including Indonesia, Tanzania, and the revolutionary beginnings of the United States. Using a variety of approaches the contributors show in each instance how the state obtained and used its power, then attempted to have its power accepted as the natural order under the protection of supra-naturally ordained authority. No matter how tyrannical or benign, the cases show that state power must be justified by faith and experience that demonstrates its value to the participants. Through such analysis, the book demonstrates that states must be capable of enforcing their rule, but that they cannot deceive populations into accepting state domination. Indeed, the book suggests that social evolution moves toward less coercive rule and increased democratization. Ronald Cohen is a political anthropologist who has taught at the Universities of Toronto, McGill, Northwestern, and Ahmadu Bello, and is on the faculty of the University of Florida. He has carried out field research in Africa, the Arctic and Washington. His major works include The Kanuri of Borno, Dominance and Defiance, Origins of the State,  and a book in preparation on food policy and agricultural transformation in Africa. Judith D. Toland is a lecturer at University College, Northwestern University, and the College of Arts and Sciences, Loyola University of Chicago. She is the director of her own corporate and non-profit consulting firm. She has done fieldwork in Ayacucho, Peru and has written widely on the Inca State.",2024,,https://doi.org/10.4324/9781003575641,Legitimacy; Politics; State (computer science); Democratization; Marxist philosophy; Power (physics); Variety (cybernetics); Political science; Value (mathematics); Faith; Political economy; Sociology; Law; Democracy; Epistemology; Philosophy; Physics; Algorithm; Quantum mechanics; Artificial intelligence; Machine learning; Computer science,https://openalex.org/W638137987,Social Sciences
