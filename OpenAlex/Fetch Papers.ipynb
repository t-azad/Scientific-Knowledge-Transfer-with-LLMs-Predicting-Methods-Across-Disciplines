{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6cdd92f-ac27-44d9-8d57-6c6824490aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from typing import Union, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30665d72-57da-4de9-a50d-f719c2b946c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c9e46a0-3828-4d8f-8046-532230d43331",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Fetching page 1 for Biology (2023) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 2 for Biology (2023) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 3 for Biology (2023) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 4 for Biology (2023) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 5 for Biology (2023) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 1 for Biology (2023) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 2 for Biology (2023) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 3 for Biology (2023) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 4 for Biology (2023) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 5 for Biology (2023) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 1 for Biology (2023) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 2 for Biology (2023) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 3 for Biology (2023) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 4 for Biology (2023) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 5 for Biology (2023) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 1 for Psychology (2023) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 2 for Psychology (2023) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 3 for Psychology (2023) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 4 for Psychology (2023) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 5 for Psychology (2023) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 1 for Psychology (2023) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 2 for Psychology (2023) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 3 for Psychology (2023) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 4 for Psychology (2023) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 5 for Psychology (2023) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 1 for Psychology (2023) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 2 for Psychology (2023) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 3 for Psychology (2023) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 4 for Psychology (2023) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 5 for Psychology (2023) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 1 for Medicine (2023) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 2 for Medicine (2023) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 3 for Medicine (2023) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 4 for Medicine (2023) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 5 for Medicine (2023) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 1 for Medicine (2023) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 2 for Medicine (2023) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 3 for Medicine (2023) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 4 for Medicine (2023) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 5 for Medicine (2023) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 1 for Medicine (2023) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 2 for Medicine (2023) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 3 for Medicine (2023) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 4 for Medicine (2023) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 5 for Medicine (2023) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 1 for Engineering (2023) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 2 for Engineering (2023) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 3 for Engineering (2023) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 4 for Engineering (2023) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 5 for Engineering (2023) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 1 for Engineering (2023) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 2 for Engineering (2023) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 3 for Engineering (2023) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 4 for Engineering (2023) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 5 for Engineering (2023) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 1 for Engineering (2023) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 2 for Engineering (2023) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 3 for Engineering (2023) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 4 for Engineering (2023) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 5 for Engineering (2023) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 1 for Social Sciences (2023) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 2 for Social Sciences (2023) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 3 for Social Sciences (2023) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 4 for Social Sciences (2023) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 5 for Social Sciences (2023) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 1 for Social Sciences (2023) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 2 for Social Sciences (2023) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 3 for Social Sciences (2023) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 4 for Social Sciences (2023) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 5 for Social Sciences (2023) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 1 for Social Sciences (2023) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 2 for Social Sciences (2023) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 3 for Social Sciences (2023) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 4 for Social Sciences (2023) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 5 for Social Sciences (2023) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 1 for Biology (2024) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 2 for Biology (2024) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 3 for Biology (2024) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 4 for Biology (2024) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 5 for Biology (2024) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 1 for Biology (2024) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 2 for Biology (2024) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 3 for Biology (2024) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 4 for Biology (2024) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 5 for Biology (2024) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 1 for Biology (2024) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 2 for Biology (2024) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 3 for Biology (2024) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 4 for Biology (2024) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 5 for Biology (2024) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 1 for Psychology (2024) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 2 for Psychology (2024) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 3 for Psychology (2024) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 4 for Psychology (2024) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 5 for Psychology (2024) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 1 for Psychology (2024) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 2 for Psychology (2024) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 3 for Psychology (2024) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 4 for Psychology (2024) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 5 for Psychology (2024) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 1 for Psychology (2024) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 2 for Psychology (2024) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 3 for Psychology (2024) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 4 for Psychology (2024) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 5 for Psychology (2024) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 1 for Medicine (2024) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 2 for Medicine (2024) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 3 for Medicine (2024) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 4 for Medicine (2024) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 5 for Medicine (2024) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 1 for Medicine (2024) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 2 for Medicine (2024) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 3 for Medicine (2024) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 4 for Medicine (2024) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 5 for Medicine (2024) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 1 for Medicine (2024) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 2 for Medicine (2024) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 3 for Medicine (2024) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 4 for Medicine (2024) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 5 for Medicine (2024) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 1 for Engineering (2024) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 2 for Engineering (2024) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 3 for Engineering (2024) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 4 for Engineering (2024) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 5 for Engineering (2024) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 1 for Engineering (2024) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 2 for Engineering (2024) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 3 for Engineering (2024) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 4 for Engineering (2024) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 5 for Engineering (2024) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 1 for Engineering (2024) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 2 for Engineering (2024) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 3 for Engineering (2024) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 4 for Engineering (2024) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 5 for Engineering (2024) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 1 for Social Sciences (2024) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 2 for Social Sciences (2024) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 3 for Social Sciences (2024) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 4 for Social Sciences (2024) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 5 for Social Sciences (2024) with ML/AI ID C119857082...\n",
      "ðŸ“¦ Fetching page 1 for Social Sciences (2024) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 2 for Social Sciences (2024) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 3 for Social Sciences (2024) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 4 for Social Sciences (2024) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 5 for Social Sciences (2024) with ML/AI ID C154945302...\n",
      "ðŸ“¦ Fetching page 1 for Social Sciences (2024) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 2 for Social Sciences (2024) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 3 for Social Sciences (2024) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 4 for Social Sciences (2024) with ML/AI ID C203014093...\n",
      "ðŸ“¦ Fetching page 5 for Social Sciences (2024) with ML/AI ID C203014093...\n",
      "\n",
      "âœ… Final dataset saved to 'openalex non-cs 3.csv'\n",
      "ðŸ“Š Total papers collected after filtering: 3111\n",
      "ðŸ“Š Paper count by primary domain:\n",
      "Medicine           720\n",
      "Social Sciences    680\n",
      "Psychology         650\n",
      "Biology            549\n",
      "Engineering        512\n",
      "Name: domain_source, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# ðŸŽ¯ Target Domains and Concepts\n",
    "# -------------------------------\n",
    "primary_domains = {\n",
    "    \"Biology\": \"C86803240\",\n",
    "    \"Psychology\": \"C15744967\",\n",
    "    \"Medicine\": \"C71924100\",\n",
    "    \"Engineering\": \"C127413603\",\n",
    "    \"Social Sciences\": \"C17744445\"\n",
    "}\n",
    "\n",
    "ml_ai_concept_ids = [\n",
    "    \"C119857082\",   # Artificial Intelligence\n",
    "    \"C154945302\",   # Machine Learning\n",
    "    \"C203014093\"    # Deep Learning\n",
    "]\n",
    "\n",
    "required_keywords = [\"Artificial Intelligence\", \"Machine Learning\", \"Deep Learning\"]\n",
    "\n",
    "# -------------------------------\n",
    "# ðŸ§  Decode Abstract\n",
    "# -------------------------------\n",
    "def decode_abstract(abstract_index):\n",
    "    if not isinstance(abstract_index, dict):\n",
    "        return \"\"\n",
    "    words = sorted((idx, word) for word, indices in abstract_index.items() for idx in indices)\n",
    "    return \" \".join(word for _, word in words)\n",
    "\n",
    "# -------------------------------\n",
    "# âœ… Paper Filter Logic\n",
    "# -------------------------------\n",
    "def is_valid_paper(work, ml_ai_ids):\n",
    "    if not work.get(\"concepts\"):\n",
    "        return False\n",
    "\n",
    "    top_concept_id = work[\"concepts\"][0][\"id\"].replace(\"https://openalex.org/\", \"\")\n",
    "    if top_concept_id in ml_ai_ids:\n",
    "        return False\n",
    "\n",
    "    abstract_text = decode_abstract(work.get(\"abstract_inverted_index\"))\n",
    "    if len(abstract_text.split()) < 200:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "# -------------------------------\n",
    "# ðŸ“¦ Parse Work Metadata\n",
    "# -------------------------------\n",
    "def parse_work(work, domain_name):\n",
    "    return {\n",
    "        \"title\": work.get(\"title\"),\n",
    "        \"abstract\": decode_abstract(work.get(\"abstract_inverted_index\")),\n",
    "        \"publication_year\": work.get(\"publication_year\"),\n",
    "        \"oa_pdf\": work.get(\"primary_location\", {}).get(\"pdf_url\"),\n",
    "        \"publisher_url\": work.get(\"primary_location\", {}).get(\"landing_page_url\"),\n",
    "        \"concepts\": \"; \".join([c[\"display_name\"] for c in work.get(\"concepts\", [])]),\n",
    "        \"openalex_id\": work.get(\"id\"),\n",
    "        \"domain\": domain_name\n",
    "    }\n",
    "\n",
    "# -------------------------------\n",
    "# ðŸš€ Fetch Data from OpenAlex\n",
    "# -------------------------------\n",
    "def fetch_openalex_data(domain_name, domain_id, year, ml_ai_concept_ids, per_page=100, max_pages=5):\n",
    "    results = []\n",
    "    for ml_ai_id in ml_ai_concept_ids:\n",
    "        for page in range(1, max_pages + 1):\n",
    "            filter_query = f\"concepts.id:{domain_id},concepts.id:{ml_ai_id},publication_year:{year}\"\n",
    "            params = {\n",
    "                \"filter\": filter_query,\n",
    "                \"per-page\": per_page,\n",
    "                \"page\": page\n",
    "            }\n",
    "\n",
    "            print(f\"ðŸ“¦ Fetching page {page} for {domain_name} ({year}) with ML/AI ID {ml_ai_id}...\")\n",
    "\n",
    "            try:\n",
    "                response = requests.get(\"https://api.openalex.org/works\", params=params)\n",
    "                response.raise_for_status()\n",
    "                data = response.json()\n",
    "\n",
    "                for work in data.get(\"results\", []):\n",
    "                    if is_valid_paper(work, ml_ai_concept_ids):\n",
    "                        results.append(parse_work(work, domain_name))\n",
    "\n",
    "                # â³ Fixed wait between requests\n",
    "                time.sleep(2)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error on page {page}: {e}\")\n",
    "                continue\n",
    "\n",
    "    return results\n",
    "\n",
    "# -------------------------------\n",
    "# ðŸ” Collect Data for All Years\n",
    "# -------------------------------\n",
    "def collect_papers_for_years(years: Union[str, List[str]], ml_ai_ids, per_page=100, max_pages=5):\n",
    "    if isinstance(years, str):\n",
    "        years = [years]\n",
    "\n",
    "    all_results = []\n",
    "    for year in years:\n",
    "        for domain_name, domain_id in primary_domains.items():\n",
    "            batch = fetch_openalex_data(domain_name, domain_id, year, ml_ai_ids, per_page, max_pages)\n",
    "            all_results.extend(batch)\n",
    "\n",
    "    return all_results\n",
    "\n",
    "# -------------------------------\n",
    "# ðŸ’¾ Final Save with Filtering\n",
    "# -------------------------------\n",
    "def save_results_to_csv(results, output_file):\n",
    "    df = pd.DataFrame(results)\n",
    "    df = df[df[\"concepts\"].apply(lambda x: any(term.lower() in x.lower() for term in required_keywords))]\n",
    "\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nâœ… Final dataset saved to '{output_file}'\")\n",
    "    print(f\"ðŸ“Š Total papers collected after filtering: {len(df)}\")\n",
    "    print(\"ðŸ“Š Paper count by primary domain:\")\n",
    "    print(df[\"domain\"].value_counts())\n",
    "\n",
    "# -------------------------------\n",
    "# ðŸŽ¬ Main Run Pipeline\n",
    "# -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    target_years = [\"2024\"]\n",
    "    output_filename = \"openalex non-cs.csv\"\n",
    "\n",
    "    final_results = collect_papers_for_years(target_years, ml_ai_concept_ids)\n",
    "    save_results_to_csv(final_results, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fce5ca0-a920-4369-b1e3-84a966801e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2816195-a26e-46e2-9375-c876718baf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: openalex_non_cs_2023.csv (1505 rows)\n",
      "âœ… Saved: openalex_non_cs_2024.csv (1606 rows)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "input_file = \"openalex non-cs.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Group by publication year and save each group as a separate CSV\n",
    "for year, group in df.groupby(\"publication_year\"):\n",
    "    output_file = f\"openalex_non_cs_{year}.csv\"\n",
    "    group.to_csv(output_file, index=False)\n",
    "    print(f\"âœ… Saved: {output_file} ({len(group)} rows)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65d964e-2143-4339-bf84-d808bab7a3fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e1d428-6638-469c-a97f-6882f09985ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7c8b92-f23b-43fb-aa7f-cf25026542ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd6a347-7036-4ea0-ac96-1f2495bc04bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
